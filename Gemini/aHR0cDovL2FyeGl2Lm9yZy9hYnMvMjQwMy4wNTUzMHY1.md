# Gemini 1.5: 수백만 토큰의 컨텍스트를 넘나드는 멀티모달 이해 능력

Gemini Team, Google

## 🧩 해결하려는 문제

기존 대규모 언어 모델(LLM)들은 컨텍스트 윈도우(예: Claude 3.0 200k, GPT-4 Turbo 128k)가 제한적이어서 수백만 토큰에 달하는 긴 문서, 수 시간 분량의 비디오 및 오디오와 같은 다양한 양식의 입력에서 미세한 정보를 기억하고 추론하는 데 한계가 있었습니다. 이 연구는 이러한 한계를 극복하고, 방대한 멀티모달 컨텍스트를 효율적으로 처리하며 정교한 이해와 추론을 가능하게 하는 차세대 모델을 개발하는 것을 목표로 합니다.

## ✨ 주요 기여

* **획기적인 컨텍스트 확장 및 리콜 성능**: Gemini 1.5 Pro는 텍스트(최대 1천만 토큰), 비디오(10.5시간), 오디오(107시간)에 걸쳐 '건초 더미 속 바늘 찾기'와 같은 장문 컨텍스트 검색 작업에서 99% 이상의 거의 완벽한 리콜 성능을 달성하여 기존 모델들을 압도합니다.
* **멀티모달 SoTA 달성**: 장문 문서 QA, 장문 비디오 QA, 장문 컨텍스트 자동 음성 인식(ASR) 분야에서 최첨단(SoTA) 성능을 향상시켰습니다.
* **핵심 역량 및 효율성 향상**: Gemini 1.5 Pro는 Gemini 1.0 Ultra의 광범위한 벤치마크 성능을 뛰어넘거나 동등한 수준을 유지하며, 훈련에 훨씬 적은 컴퓨팅 자원을 요구합니다. Gemini 1.5 Flash는 경량 모델임에도 불구하고 Gemini 1.0 Pro를 능가하며, 여러 벤치마크에서 1.0 Ultra와 유사한 성능을 보입니다.
* **인컨텍스트 학습 및 신규 기능**:
  * **저자원 언어 학습**: 전 세계 200명 미만의 화자를 가진 칼라망어(Kalamang) 문법 매뉴얼만으로 영어-칼라망어 번역을 인간 학습자와 유사한 수준으로 학습하는 능력을 선보였습니다.
  * **직업 생산성 향상**: 10가지 직업군에서 전문가들의 업무 시간 26~75% 절감에 기여하는 등 실제 시나리오에서 생산성 향상 잠재력을 입증했습니다.
  * **향상된 계획 및 분석**: 인컨텍스트 계획 능력과 비정형 멀티모달 데이터 분석(예: 이미지 구조화)에서 뛰어난 성능을 보였습니다.
* **안전성 및 견고성 강화**: Gemini 1.5 모델은 정책 위반 감소, 탈옥(jailbreak) 견고성 향상 등 안전성 및 책임성 평가에서 상당한 개선을 보였습니다.
* **수학적 추론 발전**: 수학 특화 Gemini 1.5 Pro 모델은 MATH 벤치마크에서 80.6%(단일 샘플) 또는 91.1%(256개 샘플)의 정확도를 달성하며 인간 전문가 수준에 버금가는 성능을 입증했습니다.
* **경량 모델 Flash-8B 소개**: 10억 단위 파라미터를 가진 모델 중 100만 개 이상의 토큰 컨텍스트를 지원하는 효율적인 Flash-8B 모델을 개발하여 고급 AI 기술의 접근성을 확장했습니다.

## 📎 관련 연구

* **긴 컨텍스트 모델 발전**: Shannon의 2-gram 모델부터 현대 Transformer 기반 모델(수십만 토큰)에 이르기까지 언어 모델의 컨텍스트 길이 확장이 연구되어 왔습니다.
* **현대 긴 컨텍스트 LLM**: Anthropic의 Claude 2 (100k 토큰) 및 Claude 3 (최대 1M 토큰), OpenAI의 GPT-4 Turbo (128k 토큰) 등은 컨텍스트 확장을 시도했습니다.
* **긴 컨텍스트 활성화 기법**: 새로운 아키텍처(Ainslie et al., 2023; Gu & Dao, 2023; Zaheer et al., 2020), 후처리 수정(Chen et al., 2023b; Press et al., 2021), 검색 증강 모델(Guu et al., 2020), 메모리 증강 모델(Bulatov et al., 2022) 등이 포함됩니다.
* **MoE (Mixture-of-Experts) 아키텍처**: Google의 MoE 연구(Clark et al., 2022; Fedus et al., 2021; Shazeer et al., 2017)를 기반으로 합니다.
* **평가 벤치마크**:
  * **긴 컨텍스트 리콜**: Kamradt (2023)의 "건초 더미 속 바늘 찾기" 평가 방식.
  * **인컨텍스트 언어 학습**: Tanzer et al. (2023)의 MTOB 벤치마크.
  * **수학**: Hendrycks et al. (2021b)의 MATH, MAA (2024)의 AIME, Fang et al. (2024)의 MathOdyssey, Srivastava et al. (2024)의 Functional MATH.
  * **일반 추론**: Srivastava et al. (2022)의 BigBench-Hard, Hendrycks et al. (2021a)의 MMLU, Zellers et al. (2019)의 Hellaswag.
  * **코딩**: Chen et al. (2021)의 HumanEval.
  * **다국어**: Kocmi et al. (2023)의 WMT23, Shi et al. (2023a)의 MGSM.
  * **함수 호출**: Yan et al. (2024)의 Berkeley Function Calling Leaderboard.
  * **멀티모달 시각**: Yue et al. (2023)의 MMMU, Lu et al. (2023)의 MathVista, Masry et al. (2022)의 ChartQA, Mathew et al. (2021)의 DocVQA, Wu & Xie (2023)의 V\* Benchmark.
  * **오디오**: Zhang et al. (2023b)의 USM, OpenAI (2023)의 Whisper, Conneau et al. (2023)의 FLEURS.
* **안전성 연구**: Carlini et al. (2024)의 탈옥 공격, Parrish et al. (2021)의 BBQ 데이터셋, Nasr et al. (2023)의 훈련 데이터 암기.

## 🛠️ 방법론

* **모델 아키텍처**:
  * **Gemini 1.5 Pro**: Gemini 1.0의 연구 발전을 기반으로 하는 희소 전문가 혼합(Sparse Mixture-of-Expert, MoE) Transformer 기반 모델. 1천만 토큰에 이르는 장문 컨텍스트 이해를 가능하게 하는 아키텍처 변경을 통합했습니다. 네이티브 멀티모달 모델로, 다양한 양식의 데이터를 혼합하여 처리할 수 있습니다.
  * **Gemini 1.5 Flash**: 200만 개 이상의 토큰 컨텍스트와 Gemini 1.5 Pro와 동일한 멀티모달 기능을 가진 Transformer 디코더 모델. 효율적인 TPU 활용과 낮은 서비스 지연 시간을 위해 설계되었습니다. 대규모 Gemini 1.5 Pro 모델로부터 온라인 증류(online distilled) 방식을 통해 학습되었습니다.
* **훈련 인프라 및 데이터셋**:
  * Google의 TPUv4 가속기(4096 칩 포드)를 사용하여 다양한 멀티모달 및 다국어 데이터로 훈련되었습니다. 훈련 데이터셋에는 웹 문서, 코드, 이미지, 오디오, 비디오 콘텐츠가 포함됩니다.
  * 지도 미세 조정(Supervised Fine-Tuning, SFT) 및 인간 피드백 강화 학습(Reinforcement Learning from Human Feedback, RLHF)을 통해 모델을 정렬했습니다.
* **평가 방법론**:
  * **질적 장문 컨텍스트 멀티모달 평가**: JAX 코드베이스 분석, 칼라망어 번역, `레 미제라블` 장면 식별, `셜록 주니어` 영화 질의응답 등 새로운 기능을 수동으로 탐색하고 스트레스 테스트를 진행했습니다.
  * **양적 장문 컨텍스트 멀티모달 평가**:
    * **진단 평가**: 텍스트(최대 1천만 토큰) 및 코드(최대 1천만 토큰)에 대한 NLL(Negative Log-Likelihood)을 통한 다음 토큰 예측 개선도 측정, 텍스트, 비디오, 오디오 양식에 대한 "건초 더미 속 바늘 찾기" 검색 작업.
    * **현실 세계 평가**: 인컨텍스트 언어 학습(칼라망어 ASR 포함), 장문 문서 QA, 장문 컨텍스트 ASR, 장문 컨텍스트 비디오 QA(1H-VideoQA), 인컨텍스트 계획, 비정형 멀티모달 데이터 분석(이미지 구조화) 등.
  * **양적 핵심 역량 평가**: 텍스트, 비전, 오디오 등 세 가지 양식에 걸쳐 광범위한 기존 벤치마크 및 내부 벤치마크를 활용하여 모델의 핵심 성능을 평가했습니다.
* **안전성, 보안 및 책임성**:
  * **체계적인 접근 방식**: 잠재적 영향 평가, 정책 설정, 안전성 훈련(데이터 필터링, SFT, RLHF), 레드팀 활동, 외부 및 보증 평가, 책임성 및 안전성 위원회(RSC) 검토, 모델 카드 작성 과정을 따랐습니다.
  * **세부 평가**: 정책 위반(텍스트, 이미지, 오디오, 탈옥 견고성, 장문 컨텍스트), 유용성(품질, 어조, 효과적인 거부), 보안 및 프라이버시(프롬프트 주입, 암기), 대표성 해악(텍스트, 이미지, 오디오)을 평가했습니다.
  * **위험 능력 평가**: 자기 증식, 공격적 사이버 보안, 코드 취약점 탐지, CBRN(화학, 생물, 방사능, 핵) 지식, 설득력 등 극단적 위험과 관련된 능력도 평가했습니다.

## 📊 결과

* **장문 컨텍스트 성능**:
  * **리콜**: 텍스트(1천만 토큰까지 >99%), 비디오(10.5시간 100%), 오디오(107시간 100%)에서 거의 완벽한 리콜을 달성했습니다. Gemini 1.5 Flash는 200만 토큰까지 비디오 >99.8%, 오디오 >99.1%를 달성했습니다.
  * **예측 성능**: NLL(음의 로그 우도)이 텍스트(100만 토큰) 및 코드(1천만 토큰)에서 단조적으로 감소하여 긴 컨텍스트를 효과적으로 활용함을 입증했습니다.
  * **인컨텍스트 언어 학습**: 칼라망어 번역(영어→칼라망어)에서 인간 학습자와 유사한 수준인 5.46/6점을 기록했습니다.
  * **장문 문서 QA**: 71만 토큰의 `레 미제라블`을 컨텍스트로 사용했을 때, Gemini 1.5 Pro는 검색 증강 방식의 Gemini 1.5 Pro(4k 토큰)보다 78% 더 나은 답변을 제공했고, GPT-4 Turbo보다 83% 더 나은 답변을 제공했습니다.
  * **장문 컨텍스트 ASR**: 15분 비디오에서 5.5%의 WER(단어 오류율)을 달성하여 Whisper(7.3%) 및 USM(8.8%)을 능가했습니다.
  * **비정형 멀티모달 데이터 분석**: 이미지 구조화 작업에서 GPT-4 Turbo보다 9%(절대값) 또는 27%(상대값) 정확도 향상을 보였습니다.
* **핵심 역량 성능 (Gemini 1.0 시리즈 대비)**:
  * **Gemini 1.5 Pro**: Gemini 1.0 Pro의 모든 벤치마크에서 일관되게 우수한 성능을 보였고, 훈련 컴퓨팅 요구량이 훨씬 적음에도 불구하고 Gemini 1.0 Ultra와 동등하거나 능가하는 성능을 달성했습니다.
  * **Gemini 1.5 Flash**: Gemini 1.0 Pro보다 우수했으며, 여러 벤치마크에서 Gemini 1.0 Ultra와 유사한 수준의 성능을 보였습니다.
  * **수학 및 과학**: MATH 벤치마크에서 1.0 Ultra 대비 +14.5% 향상을 포함하여 전반적으로 크게 개선되었습니다.
  * **코딩**: HumanEval 및 Natural2Code에서 1.0 Ultra를 능가하며 가장 뛰어난 성능을 보였습니다.
  * **직업 생산성**: 1.5 Pro는 평균 56.4%의 업무 시간 절감을 달성했습니다.
* **수학 특화 Gemini 1.5 Pro**: MATH 벤치마크에서 80.6% (단일 샘플), 91.1% (256개 샘플)의 정확도를 달성하여 SoTA를 경신했습니다.
* **Flash-8B**: 더 작은 크기에도 불구하고 Gemini 1.5 Flash의 80-90%에 해당하는 멀티모달 성능과 200만 토큰까지의 인상적인 장문 컨텍스트 스케일링을 보여주었습니다.
* **안전성 및 책임성**:
  * **정책 위반**: Gemini 1.0 Ultra 대비 텍스트-텍스트(-58%), 이미지-텍스트(-62%), 오디오-텍스트(-43%) 정책 위반율이 크게 감소했습니다.
  * **탈옥 공격**: 견고성이 향상되었으나, 향상된 지시 따르기 능력 때문에 정교하게 수작업으로 만들어진 프롬프트 주입 공격에는 여전히 취약함을 보였습니다.
  * **암기**: 기존 모델보다 민감한 개인 데이터를 덜 암기했으며, 긴 프롬프트는 모델 이탈(divergence)을 더 쉽게 유발했습니다.

## 🧠 통찰 및 논의

* **세대적 도약**: Gemini 1.5 시리즈는 효율성, 멀티모달리티, 장문 컨텍스트 추론 및 다운스트림 성능 면에서 이전 세대 모델에 비해 상당한 도약을 이루었습니다.
* **새로운 애플리케이션 가능성**: 최대 1천만 토큰의 전례 없는 컨텍스트 윈도우는 전체 코드베이스 이해, 여러 시간 분량의 비디오 분석, 전체 문법 책으로 새로운 언어 학습과 같이 이전에는 불가능했던 새로운 실제 애플리케이션을 가능하게 합니다.
* **성능 저하 없는 확장**: 장문 컨텍스트 기능의 향상이 모델의 핵심 멀티모달 기능(단문 컨텍스트 작업 성능)을 희생시키지 않았으며, 오히려 여러 측면에서 개선되었음을 확인했습니다.
* **효율성 강조**: Gemini 1.5 Flash는 고성능이면서도 효율적인 장문 컨텍스트 모델이 배포에 적합하며, 고급 AI 기술에 대한 접근성을 높일 수 있음을 보여줍니다.
* **새로운 평가 과제**: 수백만 토큰에 이르는 장문 및 멀티모달 컨텍스트를 처리하는 모델의 기능을 평가하는 것은 새로운 과제입니다. 기존 벤치마크는 종종 부적절하며, 길이와 복잡성을 모두 요구하는 새로운 벤치마크 개발과 "다중 바늘 건초 더미 찾기"와 같은 혁신적인 평가 방법론이 필요합니다.
* **예상치 못한 취약점**: 모델의 지시 따르기 능력이 향상되면서, 역설적으로 수작업으로 제작된 프롬프트 주입 공격에 더 취약해질 수 있다는 점은 모델 개발 시 새로운 종류의 안전성 평가가 필요함을 시사합니다.
* **지속적인 연구 필요성**: 장문 컨텍스트 능력의 한계를 이해하고, 새로운 양식(예: 오디오)에서의 안전성 및 편향 문제를 해결하며, 정교한 적대적 공격을 완화하기 위한 지속적인 연구가 중요합니다.

## 📌 TL;DR

**문제**: 기존 LLM은 컨텍스트가 짧고 멀티모달 추론 능력이 제한적이어서 실제 세계의 복잡한 데이터를 처리하는 데 어려움이 있었습니다.

**방법**: Google은 장문 컨텍스트(최대 1천만 토큰) 멀티모달 모델인 Gemini 1.5 Pro와 효율적인 경량 모델인 Gemini 1.5 Flash를 공개했습니다. 이 모델들은 방대한 멀티모달 데이터로 훈련되었으며, 진단 및 실제 장문 컨텍스트 작업, 핵심 벤치마크, 안전성 평가 전반에 걸쳐 포괄적으로 평가되었습니다.

**발견**: Gemini 1.5 모델은 멀티모달 장문 컨텍스트 검색(텍스트 1천만, 비디오 10.5시간, 오디오 107시간)에서 거의 완벽한 리콜을 달성했습니다. 또한, 장문 문서 QA, 인컨텍스트 언어 학습(칼라망어 번역), 직업 생산성 향상(56.4% 시간 절약), 수학적 추론(수학 특화 Pro 모델 MATH 91.1%) 등 다양한 작업에서 이전 Gemini 1.0 모델 및 다른 SoTA 모델을 능가했습니다. 이러한 성능 도약은 높은 컴퓨팅 효율성과 강력한 안전성 개선을 통해 이루어졌으며, 전례 없는 실제 애플리케이션의 가능성을 열었습니다.
