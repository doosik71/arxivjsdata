# Gemini Robotics: Bringing AI into the Physical World

Gemini Robotics Team, Google DeepMind

## 🧩 Problem to Solve

최근 대규모 멀티모달 모델(LMM)의 발전은 디지털 영역에서 놀라운 일반화 능력을 보였으나, 이를 로봇과 같은 물리적 에이전트에 적용하는 것은 여전히 큰 과제입니다. 범용 로봇은 물리적 세계를 이해하고, 유능하고 안전하게 상호작용할 수 있어야 합니다. 이는 3D 환경 인식, 복잡한 객체 간 관계 해석, 직관적인 물리 이해와 같은 견고한 인간 수준의 "신체화된 추론(Embodied Reasoning)" 능력을 요구하며, 나아가 이러한 이해를 바탕으로 물리적 세계에 직접적인 영향을 미치는 "행동"을 학습해야 합니다. 본 연구는 Gemini 2.0 기반의 최첨단 AI 모델을 통해 이러한 신체화된 추론 및 행동 능력을 로봇에 부여하는 것을 목표로 합니다.

## ✨ Key Contributions

* **ERQA (Embodied Reasoning Question Answering) 벤치마크**: 멀티모달 모델의 신체화된 추론 능력을 평가하기 위해 특별히 설계된 오픈 소스 벤치마크를 도입하여, 기존 벤치마크의 원자적(atomic) 능력 평가를 넘어선 광범위한 평가를 가능하게 했습니다.
* **Gemini Robotics-ER**: Gemini 2.0을 기반으로 개발된 VLM(Vision-Language Model)으로, 물리적 세계에 대한 강화된 공간 및 시간 이해를 통해 3D 지각, 정밀 포인팅, 궤적 및 잡기(grasp) 예측 등 강력한 신체화된 추론 능력을 제공합니다.
* **Gemini Robotics**: Gemini Robotics-ER의 강력한 신체화된 추론 능력을 실제 로봇의 정교한 저수준 제어와 연결하는 최첨단 VLA(Vision-Language-Action) 모델입니다. 이 모델은 고주파수(50Hz)의 정교한 제어를 가능하게 하며, 다양한 로봇 작업에 대한 견고한 일반화와 빠른 적응력을 제공합니다.
* **책임감 있는 개발**: 대규모 로봇 공학 파운데이션 모델 개발과 관련된 중요한 안전 고려 사항을 논의하고, Google AI Principles에 따라 잠재적 위험을 완화하기 위한 지침과 ASIMOV-datasets을 활용한 안전 평가 방법을 제시합니다.

## 📎 Related Works

* **기존 로봇 제어 방법**: 이전 연구들은 로봇 제어를 위해 여러 모델을 조합해야 했습니다 (예: Ahn et al., 2022; Kwon et al., 2024; Liang et al., 2023; Vemprala et al., 2023). 본 연구의 Gemini 2.0은 단일 모델로 이러한 기능을 통합했습니다.
* **소수 데모 학습**: Di Palo and Johns (2024)의 방법을 확장하여 인컨텍스트(in-context) 모방 학습을 통해 로봇이 소수의 데모로 새로운 행동을 학습하도록 지원합니다.
* **비교 기준 모델**: $\pi_0$ (pi-zero) VLA 모델 (Beyer et al., 2024; Black et al., 2024) 및 ALOHA Unleashed (Zhao et al., 2025)에서 영감을 받은 멀티태스크 확산 정책(Chi et al., 2024)과 비교하여 성능을 평가했습니다.
* **안전 연구**: ASIMOV-datasets (Sermanet et al., 2025a,b)을 활용한 안전 벤치마킹 및 헌법적 AI(Constitutional AI) 방법 (Ahn et al., 2024; Bai et al., 2022)을 참조하여 모델의 안전성을 강화했습니다.

## 🛠️ Methodology

1. **Gemini 2.0 기반**: 가장 진보된 멀티모달 파운데이션 모델인 Gemini 2.0의 고급 멀티모달 이해 및 추론 능력을 활용합니다.
2. **Gemini Robotics-ER (Embodied Reasoning) 개발**:
    * **훈련**: Gemini 2.0에 로봇 공학 특정 훈련을 추가하여 물리적 세계에 대한 공간 및 시간 이해를 강화합니다.
    * **능력**: 2D/3D 객체 탐지, 포인팅, 궤적 예측, 잡기 예측, 다중 시점(multi-view) 일치, 3D 바운딩 박스 예측 등을 가능하게 합니다.
    * **응용**: 로봇 액션 데이터 없이도 코드 생성(zero-shot) 또는 인컨텍스트 학습(few-shot)을 통한 로봇 제어를 지원합니다.
3. **Gemini Robotics (Vision-Language-Action) 개발**:
    * **아키텍처**: 클라우드 기반의 VLA 백본(Gemini Robotics backbone)과 로봇 온보드 컴퓨터에서 실행되는 로컬 액션 디코더(Gemini Robotics decoder)로 구성됩니다.
        * 백본은 Gemini Robotics-ER의 정제된 버전으로, 추론 지연 시간을 160ms 미만으로 최적화합니다.
        * 로컬 디코더는 백본의 지연 시간을 보상하여 종단 간 약 250ms의 지연 시간과 50Hz의 실시간 제어 주파수를 달성합니다.
    * **데이터**: 12개월 동안 ALOHA 2 로봇으로 수집된 수천 시간의 대규모 실제 로봇 조작 데이터셋을 사용하여 미세 조정됩니다. 이 데이터셋은 다양한 작업, 객체, 난이도, 에피소드 길이 및 정교한 조작 요구 사항을 포함합니다. 또한 웹 문서, 코드, 멀티모달 콘텐츠와 같은 비-액션 데이터도 포함됩니다.
    * **특수화(Specialization)**: 선택적 미세 조정 단계를 통해 오리가미 접기나 카드 게임과 같은 고도로 정교하고 장기적인 작업을 수행하거나, 100개 미만의 데모로 새로운 단기 작업을 학습하며, 바이-암(bi-arm) 플랫폼이나 휴머노이드와 같은 완전히 새로운 로봇 형태에 적응할 수 있습니다.
4. **안전 메커니즘**: Gemini Safety 정책과 결합하여 콘텐츠 안전 및 의미론적 행동 안전을 강화합니다. ASIMOV-datasets을 활용하여 시각 및 텍스트 기반 안전 질의응답을 훈련하고, 헌법적 AI 기법을 통해 위험한 지시에 대한 거부율을 96%로 높입니다.

## 📊 Results

* **신체화된 추론 능력 (ERQA)**: Gemini 2.0 Flash 및 Pro Experimental 모델은 ERQA 벤치마크, RealworldQA, BLINK에서 모두 새로운 SOTA(State-Of-The-Art) 성능을 달성했습니다. 특히 Chain-of-Thought (CoT) 프롬프팅을 사용했을 때 성능이 크게 향상되었습니다 (Gemini 2.0 Pro Experimental: 48.3% $\rightarrow$ 54.8%). Gemini Robotics-ER은 2D 포인팅 및 3D 탐지 벤치마크에서도 기존 전문 모델을 능가하는 SOTA를 기록했습니다.
* **제로샷 및 소수샷 로봇 제어**:
  * **제로샷 제어 (ALOHA 2 Sim)**: Gemini Robotics-ER은 Gemini 2.0 Flash보다 약 2배 높은 53%의 평균 성공률을 달성하며, 강화된 신체화된 추론 능력이 로봇 작업에 크게 기여함을 입증했습니다.
  * **소수샷 제어 (ALOHA 2 Sim/Real)**: 10개의 데모만으로도 Gemini Robotics-ER은 시뮬레이션 및 실제 환경에서 65%의 성공률을 보여, 제로샷 접근 방식보다 성능이 크게 향상되었음을 확인했습니다. 이는 특히 물체 인계, 옷 접기 등 정교하고 양손 조작이 필요한 작업에서 두드러졌습니다.
* **Gemini Robotics의 범용성**:
  * **다양한 정교한 조작 작업**: out-of-the-box 상태에서 20개 작업 중 절반 이상에서 80%를 초과하는 성공률을 기록했으며, 특히 변형 가능한 객체 조작에서 베이스라인 모델을 크게 능가했습니다.
  * **언어 지시 추종**: 훈련 중 보지 못한 객체와 장면에서도 미세 조정된 언어 지시를 정확하게 따르는 능력을 보였습니다.
  * **견고한 일반화**: 시각적(방해물, 배경, 조명), 지시(오타, 다국어, 재표현), 행동(초기 객체 위치, 새로운 객체 인스턴스) 등 세 가지 유형의 변화에 대해 베이스라인 모델보다 지속적으로 우수한 일반화 성능을 달성했습니다.
* **특수화를 통한 장기적 정교함**: 추가 미세 조정을 통해 "오리가미 여우 접기" (평균 성공률 79%) 및 "점심 도시락 싸기" (100% 성공률)와 같은 매우 복잡하고 장기적인 정교한 작업을 성공적으로 수행했습니다.
* **새로운 작업에 대한 빠른 적응**: 100개 이하의 데모로 8개 신규 단기 작업 중 7개에서 70% 이상의 성공률을 달성했으며, 두 작업에서는 100% 성공률을 기록하며 빠른 학습 능력을 입증했습니다.
* **새로운 로봇 형태 적응**: 적은 양의 데이터만으로 바이-암 Franka 로봇 (산업용 작업에서 63% 성공률) 및 Apollo 휴머노이드 로봇에 성공적으로 적응하여, 새로운 형태에서도 강건성과 일반화 능력을 유지함을 보여주었습니다.
* **안전 평가**: Gemini Robotics-ER은 ASIMOV-Multimodal (헌법적 AI 적용 시 88%) 및 ASIMOV-Injury (헌법적 AI 적용 시 88%) 벤치마크에서 강력한 안전 정렬 정확도를 보였습니다.

## 🧠 Insights & Discussion

* **함의**: 본 연구는 Gemini 2.0의 세계 지식과 추론 능력을 로봇 공학에 적용하여 물리적 세계에서 범용 AI의 잠재력을 실현하는 데 중요한 진전을 이루었습니다. 이는 로봇 시스템이 세계를 이해하고, 학습하며, 지시받는 방식에 패러다임의 변화를 가져올 것이며, 로봇 공학 활용의 기술적 장벽을 낮추어 일상생활에 지능형 로봇이 배치될 가능성을 높입니다.
* **성공 요인**:
    1. 강화된 신체화된 추론 능력을 갖춘 강력한 VLM 백본.
    2. 방대한 로봇 행동 데이터와 다양한 비-로봇 데이터를 결합한 로봇 공학 특정 훈련 방식.
    3. 낮은 지연 시간 로봇 제어를 위해 설계된 독특한 아키텍처.
* **제한 사항**:
  * Gemini 2.0 및 Gemini Robotics-ER은 긴 비디오에서 공간 관계를 이해하는 데 어려움을 겪거나, 미세한 로봇 제어 작업에 필요한 수치 예측 정밀도가 부족할 수 있습니다.
  * Gemini Robotics는 아직 새로운 상황에서 다단계 추론과 정밀한 정교한 움직임이 동시에 요구되는 복잡한 시나리오를 처리하는 데 개선의 여지가 있습니다.
* **향후 연구**: 추상적 추론과 정밀한 실행의 원활한 통합, 시뮬레이션을 활용한 시각적으로 다양하고 접촉이 풍부한 데이터 생성 및 실제 세계로의 전이, 새로운 로봇 유형에 대한 적응에 필요한 데이터 양 감소 및 궁극적인 제로샷 교차-형태 전이(cross-embodiment transfer)에 중점을 둘 것입니다.
* **안전**: 본 모델은 Google AI Principles에 따라 책임감 있게 개발되었으며, 잠재적 위험 완화를 위해 다양한 안전 전략이 논의되었습니다. 앞으로도 기술 발전과 함께 안전 및 사회적 영향에 대한 지속적인 노력이 중요합니다.

## 📌 TL;DR

본 논문은 대규모 멀티모달 모델인 Gemini 2.0을 기반으로 로봇의 물리적 세계 상호작용 능력을 혁신하는 **Gemini Robotics** 모델군을 소개합니다. 핵심 문제는 디지털 AI의 우수성을 로봇의 견고한 '신체화된 추론' 및 '능동적 행동' 능력으로 변환하는 것입니다. 이를 위해 연구진은 강화된 추론 VLM인 **Gemini Robotics-ER**과 실제 로봇을 정교하게 제어하는 VLA 모델인 **Gemini Robotics**를 개발했습니다. 이 모델은 새로운 **ERQA 벤치마크**에서 뛰어난 성능을 보였고, 복잡한 조작 작업, 언어 지시 추종, 다양한 환경 변화에 대한 강력한 일반화 능력을 입증했습니다. 특히, 소수의 데모로 신규 작업을 빠르게 학습하고, 새로운 로봇 형태에 적응하며, 오리가미 접기나 카드 게임 같은 고도로 정교한 장기 작업을 수행할 수 있도록 전문화될 수 있음을 보여주었습니다. 또한, ASIMOV-datasets을 활용한 안전성 평가와 헌법적 AI 메커니즘을 통해 책임감 있는 개발을 강조합니다.
