{
  "title": "CMamba: Learned Image Compression with State Space Models",
  "authors": "Zhuojie Wu, Heming Du, Shuyun Wang, Ming Lu, Haiyang Sun, Yandong Guo, Xin Yu",
  "year": 2025,
  "url": "http://arxiv.org/abs/2502.04988v1",
  "abstract": "Learned Image Compression (LIC) has explored various architectures, such as\nConvolutional Neural Networks (CNNs) and transformers, in modeling image\ncontent distributions in order to achieve compression effectiveness. However,\nachieving high rate-distortion performance while maintaining low computational\ncomplexity (\\ie, parameters, FLOPs, and latency) remains challenging. In this\npaper, we propose a hybrid Convolution and State Space Models (SSMs) based\nimage compression framework, termed \\textit{CMamba}, to achieve superior\nrate-distortion performance with low computational complexity. Specifically,\nCMamba introduces two key components: a Content-Adaptive SSM (CA-SSM) module\nand a Context-Aware Entropy (CAE) module. First, we observed that SSMs excel in\nmodeling overall content but tend to lose high-frequency details. In contrast,\nCNNs are proficient at capturing local details. Motivated by this, we propose\nthe CA-SSM module that can dynamically fuse global content extracted by SSM\nblocks and local details captured by CNN blocks in both encoding and decoding\nstages. As a result, important image content is well preserved during\ncompression. Second, our proposed CAE module is designed to reduce spatial and\nchannel redundancies in latent representations after encoding. Specifically,\nour CAE leverages SSMs to parameterize the spatial content in latent\nrepresentations. Benefiting from SSMs, CAE significantly improves spatial\ncompression efficiency while reducing spatial content redundancies. Moreover,\nalong the channel dimension, CAE reduces inter-channel redundancies of latent\nrepresentations via an autoregressive manner, which can fully exploit prior\nknowledge from previous channels without sacrificing efficiency. Experimental\nresults demonstrate that CMamba achieves superior rate-distortion performance."
}