{
  "title": "DeepSSM: Deep State-Space Model for 3D Human Motion Prediction",
  "authors": "Xiaoli Liu, Jianqin Yin, Huaping Liu, Jun Liu",
  "year": 2020,
  "url": "http://arxiv.org/abs/2005.12155v4",
  "abstract": "Predicting future human motion plays a significant role in human-machine\ninteractions for various real-life applications. A unified formulation and\nmulti-order modeling are two critical perspectives for analyzing and\nrepresenting human motion. In contrast to prior works, we improve the\nmulti-order modeling ability of human motion systems for more accurate\npredictions by building a deep state-space model (DeepSSM). The DeepSSM\nutilizes the advantages of both the state-space theory and the deep network.\nSpecifically, we formulate the human motion system as the state-space model of\na dynamic system and model the motion system by the state-space theory,\noffering a unified formulation for diverse human motion systems. Moreover, a\nnovel deep network is designed to parameterize this system, which jointly\nmodels the state-state transition and state-observation transition processes.\nIn this way, the state of a system is updated by the multi-order information of\na time-varying human motion sequence. Multiple future poses are recursively\npredicted via the state-observation transition. To further improve the model\nability of the system, a novel loss, WT-MPJPE (Weighted Temporal Mean Per Joint\nPosition Error), is introduced to optimize the model. The proposed loss\nencourages the system to achieve more accurate predictions by increasing\nweights to the early time steps. The experiments on two benchmark datasets\n(i.e., Human3.6M and 3DPW) confirm that our method achieves state-of-the-art\nperformance with improved accuracy of at least 2.2mm per joint. The code will\nbe available at: \\url{https://github.com/lily2lab/DeepSSM.git}."
}