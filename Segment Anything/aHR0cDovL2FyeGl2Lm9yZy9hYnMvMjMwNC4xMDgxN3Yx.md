# CAN SAM COUNT ANYTHING? AN EMPIRICAL STUDY ON SAM COUNTING

Zhiheng Ma, Xiaopeng Hong, Qinnan Shangguan

## 🧩 Problem to Solve

본 연구는 최근 출시된 Segment Anything Model (SAM)이 몇 개의 예시 바운딩 박스를 통해 학습되지 않은 카테고리의 객체를 세는 어려운 작업인 Few-Shot 객체 카운팅에 효과적으로 활용될 수 있는지 탐구합니다. SAM이 추가적인 미세 조정 없이 이 작업을 성공적으로 수행할 수 있는지가 핵심 질문입니다.

## ✨ Key Contributions

* SAM의 Few-Shot 객체 카운팅 성능에 대한 포괄적인 실증 연구를 수행했습니다.
* SAM의 원본 이미지 특징을 활용하여 Few-Shot 카운팅 작업을 위한 SAM 적용 방법을 제안했습니다. 이는 추가적인 zero-shot 객체 검출기나 분류기 없이 SAM 자체의 기능을 활용하여 계산 비용을 절약합니다.
* SAM의 성능을 기존의 Few-Shot 카운팅 방법들과 FSC-147 및 MS-COCO 데이터셋에서 비교 평가했습니다.
* 미세 조정 없는 SAM의 Few-Shot 카운팅 성능이 현재 만족스럽지 못하며, 특히 작고 밀집된 객체에 대해 성능이 크게 저하됨을 발견했습니다.
* SAM의 성능 저하 원인으로 밀집된 객체를 하나의 마스크로 분할하는 경향과 의미론적 클래스 주석이 부족한 학습 데이터셋을 지적했습니다.

## 📎 Related Works

* **Segment Anything Model (SAM)** [3]: Meta AI에서 발표한 클래스 불특정 분할 모델.
* **Grounding DINO** [4], **CLIP** [5]: 본 연구에서는 사용되지 않았지만 zero-shot 객체 검출/분류를 위한 관련 대규모 모델.
* **기존 Few-Shot 카운팅 방법**: Segment [8], GMN [9], CFOCNet [10], FamNet [6], LaoNet [11], BMNet+ [15], SAFECount [16], HMFENet [17] 등 다양한 최신 및 초기 Few-Shot 객체 카운팅 모델들이 비교 대상으로 언급되었습니다.

## 🛠️ Methodology

본 연구는 SAM을 Few-Shot 객체 카운팅에 적용하기 위해 다음과 같은 단계를 따릅니다.

1. **밀집 이미지 특징 추출**: 주어진 이미지에 대해 SAM의 이미지 인코더(ViT-H)를 사용하여 밀집 이미지 특징을 추출합니다.
2. **참조 객체 특징 생성**: 제공된 바운딩 박스를 프롬프트로 사용하여 참조 예시의 분할 마스크를 생성합니다. 이 마스크들을 밀집 이미지 특징과 곱한 후 평균하여 참조 객체의 특징 벡터를 생성합니다.
3. **모든 마스크 및 특징 생성**: 포인트 그리드(각 면에 32개 포인트)를 프롬프트로 사용하여 이미지 내의 "모든 것"을 분할합니다. 출력된 마스크들을 밀집 이미지 특징과 곱한 후 평균하여 모든 마스크의 특징 벡터를 생성합니다.
4. **표적 객체 카운팅**: 예측된 마스크의 특징 벡터와 참조 예시의 특징 벡터 간의 코사인 유사도를 계산합니다. 코사인 유사도가 미리 정해진 임계값을 초과하면 해당 마스크를 표적 객체로 간주합니다. 모든 표적 객체의 수를 합산하여 최종 카운트를 얻습니다.

* 이 방법은 추가적인 외부 모델(예: Grounding DINO, CLIP) 없이 SAM의 내장 이미지 특징을 활용하여 계산 비용을 절약합니다.

## 📊 Results

* **MS-COCO val2017 데이터셋 (Table 1)**: SAM의 평균 MAE는 3.87, RMSE는 8.03으로, 기존 Few-Shot 방법들(예: LaoNet의 MAE 1.73, RMSE 2.93)보다 성능이 낮았습니다. 하지만 COCO 데이터셋에 작고 밀집된 객체가 적어 성능 격차가 *크게 두드러지지는 않았습니다* (평균 MAE 약 2 단위 차이).
* **FSC-147 데이터셋 (Table 2)**:
  * **3-shot 설정**: SAM의 MAE는 31.20, RMSE는 100.83으로, 최신 Few-Shot 방법들(예: HMFENet의 MAE 13.10, RMSE 44.90)에 비해 *현저히 낮은 성능*을 보였습니다 (MAE에서 10 이상 차이).
  * **1-shot 설정**: SAM의 MAE는 36.68, RMSE는 116.75로, 이 역시 최신 방법들(예: LaoNet의 MAE 17.11, RMSE 56.81)에 비해 *현저히 낮은 성능*을 나타냈습니다.
* **시각화 (Figure 1)**:
  * **정확한 카운트 예시**: 비교적 드문드문 분포된 객체에 대해서는 정확한 카운트 예측을 보였습니다.
  * **성능 저하 예시**: 작고 밀집된 객체(예: 포도)를 하나의 객체로 잘못 분할하거나, 다른 카테고리의 과일을 표적 객체로 오인하는 등 예측 카운트와 실제 카운트 간에 상당한 차이가 발생했습니다.

## 🧠 Insights & Discussion

* SAM은 일반적인 분할 작업에서 인상적인 성능을 보이지만, 현재 상태로는 SOTA Few-Shot 카운팅 방법들에 뒤처집니다. 특히 작고 밀집된 객체에 대한 카운팅에서 취약점을 드러냈습니다.
* 이러한 성능 저하의 주요 원인은 두 가지로 분석됩니다:
    1. **단일 마스크 분할 경향**: SAM이 같은 카테고리의 밀집된 객체들을 하나의 마스크로 묶어 분할하는 경향이 있습니다. 이는 개별 객체 카운팅에 직접적인 문제를 야기합니다.
    2. **의미론적 클래스 주석 부족**: SAM은 의미론적 클래스 주석이 없는 마스크로 학습되었기 때문에, 다양한 객체들을 명확하게 구별하는 능력이 제한적입니다.
* 그럼에도 불구하고, 객체 카운팅 작업에 SAM을 적응시키기 위한 추가적인 연구는 여전히 가치가 있습니다.

## 📌 TL;DR

SAM의 Few-Shot 객체 카운팅 능력을 평가한 결과, 미세 조정 없이 적용했을 때 최신 방법보다 성능이 저조함을 발견했습니다. SAM은 밀집된 객체를 하나의 마스크로 분할하거나 의미론적 클래스 정보가 부족하여 작고 밀집된 객체 카운팅에서 특히 취약점을 보였습니다. 하지만 SAM을 객체 카운팅에 활용하기 위한 추가 연구의 가치는 여전히 높습니다.
