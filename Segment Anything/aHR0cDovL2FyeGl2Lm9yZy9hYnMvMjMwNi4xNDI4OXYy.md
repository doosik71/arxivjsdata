# Faster Segment Anything: Towards Lightweight SAM for Mobile Applications

Chaoning Zhang, Dongshen Han, Yu Qiao, Jung Uk Kim, Sung-Ho Bae, Seungkyu Lee, Choong Seon Hong

## 🧩 Problem to Solve

Segment Anything Model (SAM)은 뛰어난 제로샷 전이 성능과 다양한 비전 애플리케이션에서의 활용성으로 주목받고 있습니다. 하지만 $\text{SAM}$의 핵심 구성 요소인 이미지 인코더($\text{ViT-H}$ 기반, 632M 파라미터)가 매우 무거워 모바일 폰과 같은 자원 제한적인 엣지 디바이스에서 실행하기 어렵다는 문제가 있습니다. 기존 $\text{SAM}$ 논문에서 제시된 방식으로 가벼운 이미지 인코더로 $\text{SAM}$을 재학습하는 것은 막대한 컴퓨팅 자원을 요구하며(128개 $\text{GPU}$로 며칠 소요), 이미지 인코더와 마스크 디코더 간의 결합된 최적화 문제로 인해 만족스러운 성능을 얻기 어렵습니다.

## ✨ Key Contributions

* **MobileSAM 제안**: 원본 $\text{SAM}$의 강력한 성능을 유지하면서 모바일 애플리케이션에 적합한 경량 $\text{SAM}$ 모델인 $\text{MobileSAM}$을 개발했습니다.
* **디커플드 증류(Decoupled Distillation) 방법론 도입**: 이미지 인코더와 마스크 디코더의 결합된 최적화 문제를 해결하기 위해, 원본 $\text{SAM}$의 무거운 이미지 인코더($\text{ViT-H}$)로부터 경량 이미지 인코더로 지식을 분리하여 증류하는 효율적인 학습 방식을 제안했습니다.
* **획기적인 모델 경량화**: $\text{MobileSAM}$은 원본 $\text{SAM}$보다 60배 이상 작고, 이미지 인코더만으로는 100배 이상 작습니다.
* **성능 유지**: 경량화에도 불구하고, $\text{MobileSAM}$은 원본 $\text{SAM}$과 대등한 성능을 보입니다.
* **빠른 추론 속도**: 단일 $\text{GPU}$에서 이미지 당 약 10ms (인코더 8ms, 디코더 4ms)의 추론 속도를 달성했습니다.
* **경쟁 모델 대비 우위**: 동시 개발된 $\text{FastSAM}$보다 약 5배 빠르고 7배 작으면서도 우수한 성능을 보여, 모바일 애플리케이션에 더 적합합니다.
* **$\text{CPU}$ 호환성 입증**: $\text{CPU}$ 환경에서도 비교적 원활하게 실행됨을 입증했습니다.

## 📎 Related Works

* **SAM의 일반화 및 다재다능함**: $\text{SAM}$ 출시 이후 의료 영상, 위장 물체, 투명 물체 등 다양한 실제 시나리오에서의 성능 평가, 적대적 공격 및 손상에 대한 강건성 평가, 텍스트 기반 분할, 이미지 편집, 인페인팅, 비디오 객체 추적, 3D 객체 재구성 등 $\text{SAM}$의 활용성을 탐구하는 많은 연구가 진행되었습니다.
* **경량 및 효율적인 $\text{ViT}$**: 초기 경량 $\text{CNN}$($\text{MobileNet}$ 등)에서 발전하여 $\text{ViT}$ 아키텍처를 경량화하고 효율화하려는 노력($\text{Deit-Tiny}$, $\text{MobileViT}$, $\text{EfficientFormer}$, $\text{EfficientViT}$, $\text{Next-ViT}$, $\text{TinyViT}$ 등)들이 있었으며, 본 연구의 경량 이미지 인코더 선택에 영감을 주었습니다.

## 🛠️ Methodology

* **연구 목표**: 원본 $\text{SAM}$의 무거운 $\text{ViT-H}$ 이미지 인코더를 경량 인코더로 교체하여 모바일 친화적인 $\text{SAM}$($\text{MobileSAM}$)을 구축하고, 원본 $\text{SAM}$의 모든 기능과 특성을 유지하는 것입니다.
* **결합된 증류(Coupled Distillation)의 문제점**: 새로운 $\text{SAM}$을 작은 이미지 인코더로 재학습하는 기존 방식은 이미지 인코더와 마스크 디코더의 결합된 최적화 문제로 인해 높은 컴퓨팅 자원이 필요하며 학습이 어렵습니다.
* **제안된 디커플드 증류(Decoupled Distillation)**:
    1. **이미지 인코더 증류**: 원본 $\text{SAM}$의 $\text{ViT-H}$ 이미지 인코더(교사 모델)에서 경량 이미지 인코더(학생 모델, 예를 들어 $\text{TinyViT}$)로 지식을 증류합니다. 이 과정에서는 교사와 학생 인코더가 생성하는 이미지 임베딩 간의 $\text{MSE}$ (Mean Squared Error) 손실을 최소화합니다.
    2. **마스크 디코더 미세 조정(선택 사항)**: 원본 $\text{SAM}$의 마스크 디코더는 이미 경량이며, 증류된 경량 이미지 인코더와 자동으로 호환되도록 설계되었기 때문에 특별한 미세 조정은 필수적이지 않습니다. 하지만 필요시 성능 향상을 위해 선택적으로 미세 조정을 수행할 수 있습니다.
* **학습 효율성**: $\text{SA-1B}$ 데이터셋의 1%만 사용하여 단일 $\text{GPU}$에서 하루 이내에 $\text{MobileSAM}$ 학습을 완료할 수 있습니다. 교사 이미지 인코더의 임베딩을 미리 저장하여 학습 시간을 단축했습니다.
* **경량 이미지 인코더**: $\text{Deit-Tiny}$보다 더 나은 성능을 보이는 5M 파라미터의 $\text{TinyViT}$를 채택했습니다.

## 📊 Results

* **모델 크기 및 속도**: $\text{MobileSAM}$은 총 9.66M 파라미터(이미지 인코더 5.78M)로, 원본 $\text{SAM}$보다 60배 이상 작습니다. 단일 $\text{GPU}$에서 이미지 당 약 10ms의 추론 속도(인코더 8ms, 디코더 4ms)를 기록했습니다.
* **성능 비교 (mIoU)**: 원본 $\text{SAM}$이 예측한 마스크를 ground-truth로 가정했을 때, $\text{MobileSAM}$은 0.7447의 $\text{mIoU}$를 달성하여 원본 $\text{SAM}$과 대등한 성능을 보였습니다. 디커플드 증류 방식($\text{mIoU}$ 0.75)은 결합된 증류 방식($\text{mIoU}$ 0.72)보다 적은 자원으로 우수한 성능을 보여주었습니다.
* **정성적 결과**: 포인트 프롬프트 및 박스 프롬프트 모두에서 원본 $\text{SAM}$과 유사하게 만족스러운 마스크 예측 결과를 보였습니다.
* **$\text{FastSAM}$과의 비교**:
  * **크기**: $\text{MobileSAM}$ (9.66M)은 $\text{FastSAM}$ (68M)보다 약 7배 작습니다.
  * **속도**: $\text{MobileSAM}$ (12ms)은 $\text{FastSAM}$ (64ms)보다 약 5배 빠릅니다.
  * **$\text{mIoU}$**: "Segment Anything" 모드에서 $\text{MobileSAM}$은 $\text{FastSAM}$ ($\text{mIoU}$ 0.27-0.41)보다 훨씬 높은 $\text{mIoU}$ (0.71-0.74)를 달성하여 우수한 마스크 예측 품질을 입증했습니다.
  * **"Segment Everything"**: $\text{MobileSAM}$은 원본 $\text{SAM}$과 잘 일치하는 객체 제안을 생성했지만, $\text{FastSAM}$은 종종 일부 객체 예측에 실패하고 부드럽지 않은 경계를 가진 마스크를 생성했습니다.
* **어블레이션 스터디**: 배치 크기와 학습 에폭을 늘리면 $\text{MobileSAM}$의 성능($\text{mIoU}$)이 향상됨을 확인했습니다.

## 🧠 Insights & Discussion

* **디커플드 증류의 중요성**: $\text{SAM}$과 같은 대규모 모델의 경량화를 위해서는 이미지 인코더와 마스크 디코더의 최적화를 분리하는 것이 핵심적인 통찰입니다. 이 "디커플드 증류" 방식은 제한된 자원에서도 효율적이고 효과적인 학습을 가능하게 하여, 복잡한 결합 최적화의 어려움을 피할 수 있습니다.
* **모바일 친화성 달성**: $\text{MobileSAM}$은 원본 $\text{SAM}$의 주요 병목 현상인 무거운 이미지 인코더 문제를 성공적으로 해결하여, 강력한 $\text{SAM}$ 파이프라인이 자원 제약적인 엣지 디바이스 및 모바일 애플리케이션에서 실행 가능하도록 만들었습니다.
* **플러그-앤-플레이 호환성**: $\text{MobileSAM}$은 원본 $\text{SAM}$의 마스크 디코더를 그대로 유지하고 이미지 인코더만 교체하므로, 기존 $\text{SAM}$ 기반 프로젝트에 거의 노력 없이 쉽게 통합될 수 있는 "플러그-앤-플레이" 솔루션을 제공합니다.
* **향후 개선점**: 마스크 디코더 미세 조정이 선택적이지만 성능 향상에 기여할 수 있다는 점은 향후 연구에서 추가적인 성능 최적화의 가능성을 시사합니다.

## 📌 TL;DR

$\text{SAM}$은 강력하지만 무거운 이미지 인코더($\text{ViT-H}$)로 인해 모바일 장치에 부적합합니다. 이 연구는 이 문제를 해결하기 위해 **"디커플드 증류(decoupled distillation)"** 방식을 제안합니다. 이는 원본 $\text{SAM}$의 무거운 이미지 인코더에서 경량 이미지 인코더(예: $\text{TinyViT}$)로 지식을 효율적으로 증류하고, 원본의 경량 마스크 디코더는 그대로 활용하는 방식입니다. 결과적으로 개발된 **MobileSAM**은 원본 $\text{SAM}$보다 60배 이상 작으면서도 유사한 성능을 달성하며, 동시 개발된 $\text{FastSAM}$보다 5배 빠르고 7배 작으면서 우수한 마스크 예측 품질을 보입니다. 이는 $\text{SAM}$을 모바일 애플리케이션에서 활용할 수 있는 중요한 단계를 제시합니다.
