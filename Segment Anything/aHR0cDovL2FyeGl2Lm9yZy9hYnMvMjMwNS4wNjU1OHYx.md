# Segment and Track Anything

Yangming Cheng, Liulei Li, Yuanyou Xu, Xiaodi Li, Zongxin Yang, Wenguan Wang, Yi Yang

## 🧩 Problem to Solve

비디오 분할은 다양한 실제 애플리케이션에서 중요하지만, 비지도, 반지도, 대화형, 언어 유도 등 여러 하위 작업으로 나뉘어 각 분야의 다양한 요구사항을 충족하는 통합 프레임워크가 부족합니다. 최근 주목받는 Segment Anything Model (SAM)은 이미지 분할에 강력하지만, 비디오의 시간적 일관성을 고려하지 않아 비디오에 직접 적용 시 최적의 성능을 내지 못하며, 의미론적 레이블을 출력하지 않아 언어 유도형 작업과 같은 고수준의 이해가 필요한 비디오 분할 작업에는 적합하지 않습니다.

## ✨ Key Contributions

* SAM을 비디오 분할에 적용하고 확장한 통합 비디오 분할 프레임워크인 SAM-Track을 제안합니다. SAM-Track은 시간적 일관성을 고려하여 비디오 내 모든 객체를 정확하고 효율적으로 추적 및 분할할 수 있도록 합니다.
* SAM, DeAOT(VOT 2022 챌린지 1위 수상 모델), Grounding-DINO를 결합하여 두 가지 추적 모드를 지원합니다: 사용자 친화적인 멀티모달 객체 선택을 위한 '대화형 모드'와 비디오의 후속 프레임에 나타나는 새로운 객체를 자동으로 추적하는 '자동 모드'.
* DAVIS-2016 Val (92.0%), DAVIS-2017 Test (79.2%) 벤치마크 및 드론, 자율 주행, 의료 영상 등 다양한 실제 시나리오에서 뛰어난 성능과 실용성을 입증합니다.

## 📎 Related Works

* **DeAOT [16, 18, 20, 21, 22]**: AOT 기반의 VOS(Video Object Segmentation) 모델로, 동일한 고차원 임베딩 공간에서 다중 타겟을 식별하여 단일 객체 추적 속도로 다중 객체 추적을 가능하게 합니다. 계층적 Gated Propagation Module (GPM)을 사용하여 객체 불특정(object-agnostic) 및 객체 특정(object-specific) 임베딩을 과거 프레임에서 현재 프레임으로 전파합니다. VOT 2022 챌린지 4개 트랙에서 1위를 차지했습니다.
* **Segment Anything Model (SAM) [5]**: 대규모 이미지 분할 모델로, 점, 상자, 텍스트 등 유연한 프롬프트를 통해 고품질 객체 마스크를 생성하며, 뛰어난 제로샷 성능과 대화형 분할을 지원합니다.
* **Grounding-DINO [8]**: 개방형 객체 탐지기로, 언어를 폐쇄형 탐지기에 여러 단계에서 통합하여 언어 이해 능력이 뛰어나 Referring Object Detection을 수행할 수 있습니다. 텍스트 카테고리나 대상 객체에 대한 상세 설명을 입력받아 각 타겟의 최소 외부 사각형(bounding box)을 반환합니다.

## 🛠️ Methodology

SAM-Track은 SAM, DeAOT, Grounding-DINO를 통합하여 다양한 요구사항에 맞는 비디오 분할을 제공하는 통합 프레임워크입니다.

* **1. 대화형 추적 모드 (Interactive Tracking Mode)**
  * **초기 주석 획득**: 사용자는 비디오의 기준 프레임에서 클릭, 스트로크, 텍스트와 같은 멀티모달 상호작용을 통해 관심 객체를 선택합니다.
  * **Grounding-DINO 통합**: SAM의 의미론적 정보 부족을 보완하기 위해 Grounding-DINO를 통합합니다. Grounding-DINO는 자연어 명령(예: "person", "car")을 입력받아 비디오 내 관심 객체의 바운딩 박스를 탐지합니다.
  * **SAM 마스크 생성**: Grounding-DINO가 탐지한 바운딩 박스를 SAM의 프롬프트로 사용하여 각 객체의 정확한 마스크를 생성합니다.
  * **DeAOT 추적**: SAM으로 생성된 마스크를 DeAOT의 초기 주석으로 사용하여 이후 프레임에서 객체를 추적합니다. DeAOT는 GPM을 통해 시각적 임베딩과 ID 임베딩을 전파하여 프레임별로 객체를 효율적으로 추적합니다.

* **2. 자동 추적 모드 (Automatic Tracking Mode)**
  * **새로운 객체 추적**: 비디오 중간에 나타나는 새로운 관심 객체를 자동으로 추적합니다.
  * **두 가지 방법**:
    * **Segment Everything**: SAM의 `segment-everything` 기능을 사용하여 키 프레임의 모든 객체 마스크를 얻고, 이를 기반으로 DeAOT가 기존 객체와 새로 나타난 객체를 함께 추적합니다.
    * **Object of Interest Segmentation**: Grounding-DINO와 SAM을 사용하여 새로운 객체 주석을 얻습니다. Grounding-DINO는 $n$번째 프레임마다 미리 정해진 텍스트 프롬프트에 따라 객체를 탐지하고, SAM이 마스크를 생성하면 DeAOT가 이를 추적합니다.
  * **새로운 객체 정의 (Comparing Mask Results, CMR)**:
    * 새로운 객체의 ID가 기존 객체와 혼동되는 문제를 완화하기 위해 CMR을 사용합니다.
    * 매 키 프레임에서 DeAOT의 추적 결과와 SAM의 주석 결과를 비교합니다.
    * DeAOT가 추적하지 않는 SAM 주석 객체를 새로운 객체로 정의합니다.
    * 새로운 객체 마스크 $N$은 DeAOT 추적 결과의 배경 $T_{0}$와 SAM 주석 결과 $S$를 사용하여 $N = T_{0} \cdot S$로 얻어집니다.
    * 객체 $x$의 SAM 주석에서의 크기 $x_{s}$와 새로운 객체 마스크 $N$에서의 크기 $x_{n}$의 비율이 임계값 $t$보다 크면 해당 객체는 새로운 객체로 정의됩니다.
        $$ \text{CMR}(x) = \begin{cases} 1, & \text{if } \frac{x_n}{x_s} > t \\ 0, & \text{else} \end{cases} $$

* **3. 융합 추적 모드 (Fusion Tracking Mode)**
  * 대화형 모드와 자동 모드를 동시에 선택적으로 활용하여 다양한 애플리케이션의 요구사항을 충족합니다. 대화형 모드는 초기 프레임의 객체를 설정하고, 자동 모드는 비디오 진행 중에 나타나는 새로운 객체를 추적합니다.

## 📊 Results

* **정량적 결과**:
  * DAVIS-2016 Val 벤치마크에서 AvgJ 92.0%, AvgF 90.3%, J&F 93.6%의 성능을 달성했습니다 (클릭 초기화).
  * DAVIS-2017 Test 벤치마크에서 AvgJ 79.2%, AvgF 75.3%, J&F 83.1%의 성능을 달성했습니다 (클릭 초기화).
  * 이러한 결과는 다른 최신 VOS 모델들과 비교하여 경쟁력 있는 성능을 보여주며, 특히 R50-DeAOT-L 모델을 기반으로 한 SAM-Track의 효율적인 대화형 주석 생성 능력과 강력한 로버스트함을 강조합니다.

* **정성적 결과**:
  * 복잡한 추적 시나리오에서도 여러 객체를 동시에 효과적으로 추적하는 능력을 시각적으로 입증했습니다.
  * 의료 분야, 스마트 도시, 자율 주행, 스포츠 분석 등 다양한 실제 응용 분야에서 대화형, 자동 및 융합 추적 모드를 사용하여 우수한 결과를 시연했습니다.

## 🧠 Insights & Discussion

* **통합 및 확장성**: SAM-Track은 SAM의 강력한 이미지 분할 능력을 DeAOT의 효율적인 비디오 객체 추적 및 Grounding-DINO의 개방형 객체 탐지 능력과 결합하여 비디오 객체 추적의 시간적 일관성 및 의미론적 이해 문제를 해결합니다. 이는 SAM의 적용 범위를 비디오 분야로 크게 확장시킵니다.
* **다용성**: 클릭, 스트로크, 텍스트와 같은 멀티모달 상호작용 방식과 새로운 객체를 자동으로 추적하는 기능을 통해 드론 기술, 자율 주행, 의료 영상, 증강 현실, 생물학 분석 등 광범위한 실제 시나리오에서 다양한 요구사항을 충족할 수 있습니다.
* **효율성**: DeAOT의 빠른 추론 속도 덕분에 다수의 객체를 동시에 효율적으로 추적할 수 있어 스마트 도시나 자율 주행과 같이 많은 객체가 등장하는 환경에서 특히 유용합니다.
* **제로샷 추적 능력**: 의료 분야에서 희귀 세포나 기관처럼 훈련 샘플이 부족한 경우에도 SAM-Track의 클릭 기반 제로샷 추적 능력은 맞춤형 추적기 없이도 객체 추적을 가능하게 합니다.
* **자동 추적의 중요성**: 비디오 중간에 새로운 객체가 계속 나타나는 스마트 도시 및 자율 주행 환경에서 자동 추적 모드는 사용자의 개입 없이 이러한 객체들을 지속적으로 추적할 수 있는 핵심 기능을 제공합니다.
* **의의**: SAM-Track은 비디오 객체 분할 모델의 신뢰할 수 있는 기준선 역할을 하며, 실제 환경에서의 VOS 모델 적용을 가속화할 잠재력을 보여줍니다.

## 📌 TL;DR

**문제**: 기존 SAM은 비디오 객체 추적/분할 시 시간적 일관성 및 의미론적 이해가 부족하며, 다양한 애플리케이션 요구사항을 충족하는 통합 비디오 분할 프레임워크가 부재합니다.
**제안**: SAM, 고효율 다중 객체 추적 모델 DeAOT, 개방형 객체 탐지 모델 Grounding-DINO를 통합한 'Segment And Track Anything (SAM-Track)' 프레임워크를 제안합니다.
**방법**: SAM-Track은 클릭, 스트로크, 텍스트를 통한 사용자 친화적인 '대화형 추적 모드'와 Grounding-DINO 및 마스크 비교(CMR)를 활용하여 비디오 중간에 나타나는 새로운 객체를 자동으로 추적하는 '자동 추적 모드'를 제공하며, 두 모드를 융합하여 사용할 수 있습니다.
**결과**: DAVIS 벤치마크에서 경쟁력 있는 성능을 달성했으며, 드론, 자율 주행, 의료 영상 등 다양한 실제 시나리오에서 효율성과 다용성을 입증하여 실제 VOS 애플리케이션의 잠재력을 크게 향상시켰습니다.
