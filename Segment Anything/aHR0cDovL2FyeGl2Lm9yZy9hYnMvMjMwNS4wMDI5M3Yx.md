# Polyp-SAM: Transfer SAM for Polyp Segmentation

Yuheng Li, Mingzhe Hu, Xiaofeng Yang

## 🧩 Problem to Solve

대장 용종은 대장암의 중요한 전구체이며, 용종의 자동 분할은 대장암 오진율을 크게 줄이고 의사의 주석 효율성을 향상시킬 수 있습니다. 그러나 대규모 분할 네트워크를 훈련하기 위한 대장 내시경 데이터는 제한적이며, 이는 의료 이미지 분할의 주요 과제입니다. 최근 등장한 Segment Anything Model (SAM)은 자연 및 의료 이미지 분할에서 뛰어난 성능을 보여주었지만, SAM을 대장 용종 분할에 최적화하고 그 잠재력을 완전히 탐색하기 위한 효과적인 전이 학습 전략에 대한 연구가 필요합니다.

## ✨ Key Contributions

* 대장 용종 분할을 위해 SAM을 파인튜닝한 Polyp-SAM을 제안했습니다.
* 다섯 가지 공개 데이터셋을 통해 평가한 결과, Polyp-SAM은 두 가지 데이터셋에서 최첨단(state-of-the-art) 성능을 달성했으며, 나머지 세 가지 데이터셋에서도 88% 이상의 Dice 점수로 인상적인 성능을 보였습니다.
* SAM의 인코더를 파인튜닝하지 않거나(디코더만 파인튜닝) 전체 인코더를 파인튜닝하는 두 가지 전이 학습 전략을 비교했습니다. 모든 구성 요소를 파인튜닝하는 것이 일반적으로 더 나은 성능을 보였으나, 디코더만 파인튜닝하는 경우에 비해 성능 향상의 폭이 제한적임을 확인했습니다.
* Polyp-SAM이 다기관 데이터에 대한 우수한 일반화 능력을 가지고 있음을 입증했습니다.
* 경량화된 ViT-B 모델이 더 복잡한 ViT-L 모델보다 의료 이미지 응용 분야에 더 적합할 수 있음을 시사했습니다.

## 📎 Related Works

* **U-Net** [4] 및 **U-Net++** [5, 19]: 의료 영상 분할 분야에서 널리 사용되는 컨볼루션 신경망 아키텍처.
* **DCRNet** [20], **C2FNet** [21], **LDNet** [22], **Polyp-PVT** [23], **HSNet** [24]: 기존의 대장 용종 분할 최신 방법들.
* **Segment Anything Model (SAM)** [11]: 이미지 분할을 위한 대규모 파운데이션 모델.
* **SAM의 의료 이미지 분할 적용 연구** [12-14]: SAM의 의료 분야 잠재력을 탐구한 최근 연구들.
* **전이 학습 (Transfer Learning)** [6, 7]: 대규모 자연 이미지 데이터셋에서 학습된 지식을 의료 분야의 특정 문제 해결에 활용하는 기법.

## 🛠️ Methodology

* **데이터셋**: Kvasir, CVC-ClinicDB, CVC-ColonDB, ETIS, CVC-300 등 다섯 가지 공개 대장 내시경 데이터셋 사용. 훈련 세트는 Kvasir 900장과 CVC-ClinicDB 550장을 혼합하여 구성했으며, 나머지는 테스트에 사용했습니다.
* **SAM 아키텍처**: SAM의 이미지 인코더, 프롬프트 인코더, 마스크 디코더의 세 가지 핵심 구성 요소를 활용했습니다.
  * **이미지 인코더**: 최대 $1024 \times 1024$ 해상도를 처리하도록 수정된 Masked Autoencoder (MAE) 기반의 ViT 백본.
  * **프롬프트 인코더**: 포인트, 경계 상자, 텍스트, 마스크와 같은 다양한 사용자 입력에 맞춰 설계됨. 본 연구에서는 주로 경계 상자 프롬프트 사용.
  * **마스크 디코더**: 동적 마스크 예측 헤드와 IoU 점수 회귀 헤드가 포함된 두 개의 트랜스포머 레이어로 구성된 경량 설계.
* **전처리 및 프롬프트 생성**:
  * SAM 인코더 요구 사항에 따라 모든 이미지를 $3 \times 1024 \times 1024$로 크기 조정.
  * SAM 디코더의 출력 마스크는 원래 이미지 해상도로 다시 크기 조정.
  * 경계 상자가 가장 효과적인 프롬프트로 확인되어 사용. 경계 상자가 없는 데이터셋의 경우, 실제 마스크에서 자동으로 추출하여 사용했습니다.
* **Polyp-SAM 전이 학습 전략**:
    1. **디코더만 파인튜닝**: SAM의 이미지 인코더와 프롬프트 인코더를 고정하고 마스크 디코더만 파인튜닝했습니다 (Fig. 1a).
    2. **모든 구성 요소 파인튜닝**: SAM의 이미지 인코더, 프롬프트 인코더, 마스크 디코더를 모두 파인튜닝했습니다 (Fig. 1b).
  * 기본 모델로 ViT-B (Polyp-SAM-B)와 ViT-L (Polyp-SAM-L)을 모두 평가했습니다.
* **훈련 상세**:
  * 유효 배치 크기: 48 (그레디언트 누적 사용).
  * 손실 함수: Dice Loss.
  * 옵티마이저: AdamW.
  * 학습률: 4e-6, 선형 웜업 및 코사인 어닐링 스케줄러 사용.
  * 훈련 데이터의 80%는 훈련에, 20%는 검증에 사용.
  * 하드웨어: Intel Xeon E5-2603 v4 CPU, Tesla V100-PCIE GPU (32GB 2개).
* **평가 지표**: Dice Similarity Coefficient (DSC) 및 mean Intersection over Union (mIoU).

## 📊 Results

* **전이 학습 전략 비교 (Table 1)**: 모든 SAM 구성 요소를 파인튜닝하는 전략이 디코더만 파인튜닝하는 전략보다 일관되게 더 나은 성능을 보였지만, DSC는 0-3%, mIoU는 0.1-4%의 제한적인 개선을 보였습니다.
* **다기관 일반화 연구 (Table 2)**:
  * Polyp-SAM-B는 CVC-ColonDB (89.4% DSC), CVC-300 (92.4% DSC), ETIS (90.3% DSC)에서 기존 방법들을 능가하며 최첨단 성능을 달성했습니다.
  * Polyp-SAM-L은 CVC-300 (92.9% DSC, 88.9% mIoU)과 ETIS (90.5% DSC, 86.0% mIoU)에서 최첨단 성능을 달성했습니다.
  * 전반적으로 Polyp-SAM-B와 Polyp-SAM-L 모두 다기관 데이터에서 합리적인 성능을 보였습니다.
* **교차 데이터셋 일반화 연구 (Table 3)**: 훈련 데이터셋 (Kvasir 및 CVC-ClinicDB)으로 파인튜닝한 후 CVC-ColonDB에서 직접 평가했을 때, Polyp-SAM-B는 90.6% DSC와 85.5% mIoU로 최첨단 성능을 달성하며 우수한 일반화 능력을 입증했습니다. Polyp-SAM-L은 88.1% DSC와 82.5% mIoU로 두 번째로 좋은 결과를 기록했습니다.
* **성능 비교**: 계산 복잡성이 높은 Polyp-SAM-L이 경량 Polyp-SAM-B를 모든 데이터셋에서 능가하지는 못했습니다. 이는 경량 ViT-B 모델이 의료 이미지 응용 분야에 더 적합할 수 있음을 시사합니다.
* **실패 사례 (Figure 4)**: Polyp-SAM은 여러 개의 산발적인 용종을 탐지하는 데 어려움을 겪는 경우가 관찰되었습니다.

## 🧠 Insights & Discussion

* Polyp-SAM은 기존 방법들과 비교하여 다섯 가지 공개 대장 용종 데이터셋에서 뛰어난 성능을 보였으며, 특히 교차 데이터셋 평가에서 SOTA를 달성하며 다양한 임상 대장 내시경 데이터의 분포 변화에 대한 강력한 견고성을 입증했습니다.
* 경량 모델인 Polyp-SAM-B는 더 복잡한 Polyp-SAM-L을 일부 데이터셋에서 능가하며, 의료 영상 애플리케이션에 더 적합할 수 있음을 시사합니다.
* SAM의 모든 구성 요소를 파인튜닝하는 것이 디코더만 파인튜닝하는 것보다 약간 더 나은 성능을 제공하지만, 그 성능 향상 폭은 제한적입니다.
* **한계점**:
  * 여러 개의 산발적인 용종이 있는 경우 성능 저하가 발생하며, 마스크 디코더를 조정하여 여러 분할 마스크를 출력하도록 개선할 여지가 있습니다.
  * 최적의 성능을 위해 경계 상자 형태의 프롬프트 (Ground Truth에서 추출)에 의존한다는 점이 완전한 종단 간(end-to-end) 대장 용종 분할 모델 개발에 병목 현상이 될 수 있습니다.
  * SAM은 이미지 분할 모델이지만, 실제 임상 적용은 비디오 분할 모델을 필요로 하므로, 공간 및 시간 정보를 사용하여 여러 프레임을 결합하는 연구가 필요합니다.
* 이 연구는 SAM을 의료 이미지 분할 작업에 적용하는 데 큰 잠재력을 보여줍니다.

## 📌 TL;DR

**문제**: 제한된 의료 데이터로 인해 대장 용종의 자동 분할을 위한 대규모 딥러닝 모델 훈련이 어렵습니다.

**방법**: 본 연구는 대장 용종 분할을 위해 Segment Anything Model (SAM)을 파인튜닝한 Polyp-SAM을 제안합니다. 이미지 인코더와 프롬프트 인코더를 고정하고 마스크 디코더만 파인튜닝하는 전략과 SAM의 모든 구성 요소를 파인튜닝하는 두 가지 전이 학습 전략을 비교했습니다. 경계 상자를 프롬프트로 사용하여 대장 용종 마스크를 생성했습니다.

**주요 결과**: Polyp-SAM은 다섯 가지 공개 데이터셋 중 CVC-ColonDB와 CVC-300에서 최첨단 성능을 달성했으며, 나머지 데이터셋에서도 88% 이상의 높은 Dice 점수를 기록했습니다. 모든 구성 요소를 파인튜닝하는 것이 디코더만 파인튜닝하는 것보다 약간 더 나은 성능을 보였지만, 경량 ViT-B 모델이 더 복잡한 ViT-L 모델보다 의료 이미지 애플리케이션에 더 적합할 수 있음을 발견했습니다. Polyp-SAM은 다양한 데이터셋에 걸쳐 우수한 일반화 능력을 입증했습니다.
