# SAD: Segment Any RGBD

Jun Cen, Yizheng Wu, Kewei Wang, Xingyi Li, Jingkang Yang, Yixuan Pei, Lingdong Kong, Ziwei Liu, Qifeng Chen

## 🧩 Problem to Solve

Segment Anything Model (SAM)은 2D RGB 이미지 분할에 강력한 성능을 보여주지만, 주로 텍스처 정보에 의존하여 기하학적 정보는 덜 활용하고 과분할(over-segmentation)을 유발하는 경향이 있습니다. 이 논문은 SAM의 이러한 한계를 극복하고, 기하학적 정보를 풍부하게 담은 분할 결과를 얻는 방법을 모색합니다.

## ✨ Key Contributions

* **깊이 맵 기반 기하학적 정보 활용**: 인간이 깊이 맵을 통해 객체를 식별하는 능력에서 영감을 받아, 렌더링된 깊이 맵을 SAM의 입력으로 사용하여 기하학적 정보를 직접 추출하는 Segment Any RGBD (SAD) 모델을 제안합니다.
* **과분할 문제 완화**: 렌더링된 깊이 이미지를 사용함으로써 RGB 이미지 입력 시 발생하는 SAM의 과분할 문제를 줄입니다.
* **오픈-어휘 의미론적 분할 통합**: 오픈-어휘 의미론적 분할(Open-Vocabulary Semantic Segmentation, OVSeg)을 프레임워크에 통합하여, SAM 마스크에 의미론적 정보를 부여하고 3D 파놉틱(panoptic) 분할을 가능하게 합니다.
* **3D 시각화 가능**: 분할된 결과를 깊이 맵 기반으로 3D 세계에 투영하여 입체적인 시각화를 제공합니다.
* **SAM 기반 모델 중 최초**: 렌더링된 깊이 이미지를 SAM에 직접 입력하여 분할하는 최초의 시도입니다.

## 📎 Related Works

* **Segment Anything Model (SAM)** [6]: 2D 이미지 분할을 위한 대규모 Vision Transformer 기반의 파운데이션 모델로, 다양한 이미지에 대한 제로샷(zero-shot) 분할 능력을 가지고 있습니다.
* **Open-Vocabulary Semantic Segmentation (OVSeg)** [7]: 텍스트 형식의 클래스 후보를 사용하여 학습 시 보지 못한 카테고리도 의미론적으로 분할할 수 있는 기법입니다.
* **SAM 기반 3D 프로젝트**: SSA [1], Anything-3D [8], SAM 3D [2]와 같이 이전에 제안된 SAM 기반 프로젝트들은 주로 RGB 이미지를 입력으로 사용했습니다.

## 🛠️ Methodology

SAD는 SAM과 OVSeg를 활용하여 깊이 맵에서 파생된 기하학적 정보를 이용해 의미론적 분할 결과를 얻습니다. 과정은 다음과 같습니다:

1. **깊이 맵 렌더링**:
    * 깊이 맵 ($R^{H \times W}$)은 RGB 이미지보다 기하학적 정보를 강조하는 특성을 가집니다.
    * `colormap` 함수 [5] (예: Viridis, Gray, Plasma, Cividis, Purples)를 사용하여 깊이 맵을 RGB 공간 ($R^{H \times W \times 3}$)으로 렌더링합니다.
    * 렌더링된 깊이 맵은 SAM의 입력으로 사용됩니다.
2. **SAM을 이용한 분할**:
    * 렌더링된 깊이 이미지를 SAM에 입력하여 초기 SAM 마스크를 생성합니다.
    * 이 마스크들은 클래스에 구애받지 않으며 여전히 과분할된 상태입니다.
3. **OVSeg를 이용한 의미론적 분할**:
    * RGB 이미지를 입력으로 사용하고 텍스트 프롬프트(text prompts)를 활용하여 OVSeg로부터 조악한(coarse) 의미론적 마스크를 생성합니다.
    * 이 마스크들은 SAM 마스크의 과분할된 부분을 클러스터링하는 데 도움을 주고, 세분화된 SAM 결과에 카테고리 정보를 제공합니다.
4. **의미론적 투표 (Semantic Voting)**:
    * 각 SAM 마스크의 픽셀에 대해 해당 픽셀의 OVSeg 마스크에서 예측된 클래스를 찾습니다.
    * 각 세그먼트(segment) 내 픽셀들의 다수결 원칙에 따라 해당 세그먼트의 클래스를 할당합니다.
    * 동일한 클래스에 속하는 인접한 세그먼트들을 클러스터링합니다.
5. **3D 세계로 투영**:
    * 최종 의미론적 분할 결과는 깊이 맵을 기반으로 3D 세계에 투영되어 입체적인 시각화를 가능하게 합니다.

## 📊 Results

* **정성적 결과**: Sailvos3D [4] 및 ScanNet [3] 데이터셋에서 제안된 SAD 방법이 깊이 맵 입력을 활용하여 기하학적 의미론적 분할 결과를 향상시킴을 시각적으로 입증했습니다.
* **RGB 이미지 입력과의 비교**:
  * RGB 이미지는 텍스처 정보를 주로 포착하여 SAM이 더 많은 마스크를 생성하고 과분할 경향을 보입니다.
  * 렌더링된 깊이 이미지 입력은 SAM의 과분할 문제를 완화합니다 (예: 테이블이 RGB에서는 4개 부분으로 분할되고 하나가 의자로 오분류된 반면, 깊이 이미지에서는 정확히 분할 및 분류됨).
  * 단, 매우 근접한 두 객체의 경우 깊이 이미지에서는 하나의 객체로 분할될 수 있으며 (예: 의자), 이 경우 RGB 이미지의 텍스처 정보가 객체를 정확히 구별하는 데 중요할 수 있습니다.

## 🧠 Insights & Discussion

* SAD는 SAM이 RGB 이미지에서 텍스처 정보에 과도하게 의존하여 기하학적 정보를 놓치는 문제를 깊이 맵을 활용하여 효과적으로 해결합니다.
* 렌더링된 깊이 맵을 SAM에 입력함으로써, SAM이 기하학적 특징에 집중하게 되어 객체의 형태를 더 잘 반영하는 분할 결과를 얻을 수 있습니다. 이는 과분할을 줄이는 데 크게 기여합니다.
* SAM의 강력한 제로샷 분할 능력과 OVSeg의 오픈-어휘 의미론적 분류 능력을 결합하여, 단순한 객체 분할을 넘어 의미론적으로 풍부하고 3D 공간에서 시각화 가능한 파놉틱 분할을 달성합니다.
* 제안된 방법은 근접한 객체들을 구별하는 데 있어 RGB 이미지의 텍스처 정보가 여전히 중요한 역할을 한다는 한계를 인정하며, 향후 두 정보를 효과적으로 융합하는 연구의 가능성을 시사합니다.

## 📌 TL;DR

SAM의 텍스처 의존성으로 인한 과분할 문제를 해결하기 위해, SAD는 렌더링된 깊이 맵을 SAM에 입력하여 기하학적 정보를 활용합니다. 이 방법은 SAM 마스크의 과분할을 줄이고, OVSeg와 결합하여 조악한 의미론적 마스크를 통해 SAM 마스크에 정확한 클래스를 할당하여 3D 파놉틱 분할을 달성합니다. 결과적으로 SAD는 깊이 맵의 기하학적 정보를 활용하여 더 정확하고 상황 인지적인 분할 결과를 제공합니다.
