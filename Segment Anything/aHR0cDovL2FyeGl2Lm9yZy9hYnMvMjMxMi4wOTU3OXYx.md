# MobileSAMv2: Faster Segment Anything to Everything

Chaoning Zhang, Dongshen Han, Sheng Zheng, Jinwoo Choi, Tae-Ho Kim, Choong Seon Hong

## 🧩 Problem to Solve

Segment Anything Model (SAM)은 `Segment Anything (SegAny)` 및 `Segment Everything (SegEvery)` 두 가지 세분화 작업을 처리합니다. `SegAny` 작업의 속도 저하는 이미지 인코더의 무거움 때문이었고, 이는 MobileSAM에 의해 해결되었습니다. 그러나 `SegEvery` 작업의 효율성 병목 현상은 마스크 디코더에 있습니다. 이는 중복된 그리드-서치 프롬프트로 수많은 마스크를 생성한 다음 유효한 마스크를 얻기 위해 필터링해야 하기 때문입니다. 이 과정은 특히 고밀도 그리드를 사용할 때 매우 느려집니다.

## ✨ Key Contributions

* SAM의 `SegEvery` 작업이 느린 원인을 파악하고, 기본 그리드-서치 포인트 프롬프트를 객체 인식 박스 프롬프트로 대체하여 속도를 크게 향상시키면서 전반적으로 우수한 성능을 달성했습니다.
* 제안된 객체 인식 프롬프트 샘플링 전략이 MobileSAM의 경량화된 이미지 인코더와 호환됨을 입증하여 효율적인 `SegAny` 및 `SegEvery`를 위한 통합 프레임워크에 기여했습니다.

## 📎 Related Works

* **SAM의 발전**: SAM 출시 이후 의료 영상, 위장 객체, 투명 객체 등 다양한 분야에서 성능이 연구되었으며, 적대적 공격 및 로버스트니스 평가가 이루어졌습니다.
* **SAM의 활용**: Grounded-SAM은 Grounding DINO와 결합하여 텍스트 기반 프롬프트 가능한 세분화를 지원하며, Semantic-SAM은 CLIP을 사용하여 마스크에 레이블을 할당합니다. 또한 이미지 편집, 인페인팅, 비디오 객체 추적, 3D 객체 재구성 등 다양한 응용 분야에서 활용됩니다.
* **클래스 불가지론적 세분화**: 객체를 전체적으로 다루는 기존의 방식과 달리, SAM은 모든 객체와 의미 있는 부분들을 세분화하는 `SegEvery` 작업을 해결합니다.

## 🛠️ Methodology

1. **동기 및 프레임워크**: `SegEvery`의 기존 접근 방식은 중복 마스크 생성 후 필터링하는 방식인데, 이를 유효한 프롬프트로만 마스크 디코더를 프롬프트하여 간소화합니다. 핵심은 기본 그리드-서치 프롬프트 샘플링을 객체 인식 프롬프트 샘플링으로 대체하는 것입니다.
2. **객체 인식 프롬프트 샘플링**:
    * 객체 발견을 위해 YOLOv8과 같은 최신 객체 감지 네트워크를 사용합니다. 이 모델은 개방형 데이터셋(SA-1B의 하위 집합)으로 훈련됩니다.
    * NMS(Non-Maximum Suppression)를 적용하여 중복되는 바운딩 박스를 필터링합니다.
    * 프롬프트로는 점(point) 대신 **바운딩 박스(box)**를 직접 사용합니다. 박스 프롬프트는 점 프롬프트의 모호성 문제를 줄이고 고품질 마스크를 생성하며, 추가 마스크 필터링 필요성을 완화하여 `SegEvery` 효율성에 더 유리합니다.
3. **프롬프트 기반 마스크 디코딩**:
    * SAM [14]을 따라 프롬프트 기반 마스크 디코딩을 배치(batch) 방식으로 수행합니다. 여기서 배치는 이미지 샘플의 수가 아닌 프롬프트의 수입니다.
    * 바운딩 박스를 직접 프롬프트로 사용하여 중심점을 도출하는 과정을 생략합니다. 이 방법은 추가 비용 없이 성능 향상을 가져옵니다.
    * 객체 인식 방식으로 샘플링된 프롬프트는 대부분 유효하므로, 마스크 필터링이 필수가 아니며 선택 사항으로 처리하여 효율성을 더욱 높입니다.

## 📊 Results

* **효율성 비교**: 제안된 객체 인식 프롬프트 샘플링 전략은 마스크 디코더의 효율성을 최소 16배 이상 향상시킵니다. (예: 64x64 그리드-서치 6464ms vs. MobileSAMv2 97ms) 이는 프롬프트 수를 획기적으로 줄인 결과입니다.
* **성능 비교 (mask AR@1000)**:
  * SAM의 기본 그리드-서치(64x64 포인트, 멀티 마스크) 대비, MobileSAMv2 (최대 320 박스 프롬프트)는 59.3% vs 59.2%로 동등하거나 약간 더 우수한 성능을 달성합니다.
  * 특히 `multi-mask` 옵션을 비활성화했을 때, 박스 프롬프트는 포인트 프롬프트 대비 성능이 크게 향상됩니다.
  * `K` 값이 작을 때 (예: AR@100, AR@10), MobileSAMv2는 훨씬 적은 수의 프롬프트로도 SAM보다 더 높은 성능을 보입니다.
  * 전반적으로, 제안된 접근 방식은 LVIS 데이터셋에서 마스크 AR@K 메트릭 기준으로 평균 3.6% (42.5% vs. 38.9%)의 성능 향상을 가져옵니다.
* **경량 이미지 인코더와의 호환성**: MobileSAMv2는 MobileSAM 프로젝트의 경량화된 이미지 인코더(예: EfficientViT-L2)와 호환됩니다. ViT-H 대비 약간의 성능 저하(59.2%에서 56.3%)가 있지만, 이미지 인코더 속도 향상(400ms 이상에서 20ms)을 고려할 때 가치 있는 교환입니다.

## 🧠 Insights & Discussion

* **프롬프트-프리(Prompt-free) 방식과의 비교**: FastSAM과 같은 프롬프트-프리 접근 방식은 속도는 빠르지만, 마스크 경계 품질이 떨어져 성능 저하가 발생합니다. SAM과 MobileSAMv2와 같은 프롬프트 인식(prompt-aware) 방식은 훨씬 더 세밀한 경계를 가진 마스크를 생성합니다.
* **과세분화(Over-segmentation) 방지**: SAM은 과세분화 경향이 있지만, MobileSAMv2는 객체 인식(object-aware) 특성 덕분에 이러한 경향을 완화합니다.
* **프롬프트 수의 영향**: 마스크 AR 성능은 프롬프트 수가 증가함에 따라 향상되지만, 약 320개의 프롬프트에서 포화 상태에 도달합니다. MobileSAMv2는 기본적으로 최대 320개의 박스 프롬프트를 사용합니다.
* **통합 프레임워크**: MobileSAMv2는 `SegEvery` 속도 향상을, MobileSAM은 `SegAny` 속도 향상을 목표로 하여 서로 직교하는 문제를 해결합니다. 이 둘의 결합은 효율적인 `SegAny` 및 `SegEvery`를 위한 통합 프레임워크를 구축하는 데 기여합니다.
* **향후 연구**: 더 나은 이미지 인코더 및 객체 발견 모델을 탐색하는 것이 필요합니다.

## 📌 TL;DR

MobileSAMv2는 SAM의 `SegEverything (SegEvery)` 작업의 주요 병목인 마스크 디코더의 비효율성을 해결합니다. 기존의 중복 그리드-서치 프롬프트 대신 **객체 인식 바운딩 박스 프롬프트**를 사용하여 마스크 생성 및 필터링 시간을 대폭 줄입니다. 이 방법은 마스크 디코더의 속도를 최소 16배 향상시키면서, `mask AR@K`에서 평균 3.6%의 성능 향상을 달성합니다. 또한 MobileSAM의 경량 이미지 인코더와 호환되어 효율적인 `SegAny`와 `SegEvery`를 위한 통합 프레임워크를 제공합니다.
