# SANeRF-HQ: Segment Anything for NeRF in High Quality

Yichen Liu, Benran Hu, Chi-Keung Tang, Yu-Wing Tai

## 🧩 Problem to Solve

기존 NeRF (Neural Radiance Fields) 기반 3D 객체 분할 방법들은 복잡한 장면에서 객체를 정확하고 일관되게 분할하는 데 어려움을 겪습니다. 특히, SAM(Segment Anything Model)과 같은 2D 분할 모델을 NeRF에 통합하려는 초기 시도들은 새로운 시점(novel views)에서의 마스크 품질과 다중 시점 일관성이 만족스럽지 못하다는 한계를 가집니다. 본 논문은 이러한 문제를 해결하여 주어진 장면에서 모든 대상 객체의 고품질 3D 분할을 달성하는 것을 목표로 합니다.

## ✨ Key Contributions

* NeRF에서 더 정확한 분할 경계와 더 나은 다중 시점 일관성을 통해 고품질 3D 객체 분할을 생성하기 위한 SANeRF-HQ 프레임워크를 제안합니다.
* 고품질 Ground-truth가 있는 도전적인 데이터셋에 대한 정량적 평가를 통해 제안하는 방법의 유효성을 검증합니다.
* 2D 기반 모델을 NeRF에 통합하고 이를 다양한 3D 분할 작업으로 확장하는 일반적인 프레임워크를 제시합니다.

## 📎 Related Works

* **2D 객체 분할:** SAM(Segment Anything Model), DINOv2와 같은 시각 재단 모델(visual foundation models)이 텍스트 프롬프트 기반의 제로샷(zero-shot) 분할에서 뛰어난 성능을 보이며 개방형(open-world) 분할의 발전을 이끌었습니다.
* **NeRF 내 3D 분할:** Semantic-NeRF는 3D Semantic Label 인코딩을 통해 의미론적 분할을 시도했으며, Instance-NeRF와 같은 방법들은 3D 객체 인스턴스 분할에서 시점 간 불일치 해결에 집중했습니다. LERF와 ISRF는 DINO나 CLIP과 같은 사전 학습된 2D 특징을 3D 특징 필드로 통합하는 연구를 진행했습니다.
* **SAM과 NeRF 결합:** SA3D는 SAM을 NeRF 렌더링 이미지에 적용하여 단일 뷰 2D 마스크로부터 3D 분할을 시도했으나, 초기 마스크 의존성 및 복잡한 구조 분할에서의 모호성 문제가 있었습니다. SAN은 SAM 인코더를 신경 필드에 증류하여 새로운 시점에서 SAM 특징 맵을 렌더링했으나, 낮은 해상도의 특징 맵으로 인해 마스크 경계에 앨리어싱(aliasing)이 발생하고 시점 간 일관성이 떨어지는 문제가 있었습니다.

## 🛠️ Methodology

SANeRF-HQ는 사전 학습된 NeRF 모델을 활용하여 사용자 프롬프트에 기반한 고품질 3D 객체 분할을 수행합니다. 핵심 구성 요소는 다음과 같습니다:

1. **Feature Container (특징 컨테이너):**
    * **캐싱(Caching):** 여러 뷰의 SAM 특징을 미리 계산하여 저장합니다. 이는 정확한 2D 마스크 생성을 가능하게 하지만, 메모리 제약이 있으며 캐싱되지 않은 새 뷰에 대한 프롬프트의 경우 인코더 실행에 추가 시간이 소요됩니다.
    * **특징 필드 증류(Feature Field Distillation):** SAM 특징을 신경 필드를 사용하여 3D 공간으로 증류합니다. $$ \hat{F}(r) = \sum_{k=1}^{K} \hat{T}(t_k)\alpha(\sigma(t_k)\delta_k)f(t_k) $$ 여기서 $f(t_k)$는 3D 위치 $(x,y,z)$에서 추출된 SAM 임베딩입니다. 이는 임의의 시점에서 특징 맵을 효율적으로 렌더링할 수 있게 하지만, SAM 인코더의 낮은 해상도로 인해 렌더링된 특징 맵에 앨리어싱이 발생하여 마스크 경계의 정확도가 떨어질 수 있습니다.

2. **Mask Decoder (마스크 디코더):**
    * 특징 컨테이너에서 얻은 특징 맵과 사용자 입력 프롬프트(2D/3D 포인트, 텍스트)를 받아 2D 마스크를 생성합니다. 이는 SAM 디코더와 유사한 아키텍처를 가집니다.
    * 3D 포인트 프롬프트는 NeRF의 깊이 추정($$ \hat{D}(r) = \sum_{k=1}^{K} \hat{T}(t_k)\alpha(\sigma(t_k)\delta_k)t_k $$)과 카메라 자세를 이용하여 2D 포인트로부터 역투영하여 얻습니다.

3. **Mask Aggregator (마스크 통합자):**
    * **Object Field (객체 필드):** 디코더에서 생성된 여러 뷰의 2D 마스크를 3D 공간으로 통합하여 고품질의 일관된 3D 마스크를 생성합니다. 객체 마스크는 뷰 불변성(view invariance)을 가지는 $L$차원 객체 식별 벡터 $i = f(x; \Theta_o)$로 표현됩니다.
        $$ \hat{M}(r) = \text{Softmax} \left( \sum_{k=1}^{K} \hat{T}(t_k)\alpha(\sigma(t_k)\delta_k)i(t_k) \right) $$
        이 객체 필드는 NeRF의 볼륨 밀도 $\sigma$를 활용하여 3D 기하학적 정보에 기반한 구조를 인식합니다. 교차 엔트로피 손실 $L_o$로 훈련됩니다.
    * **Ray-Pair RGB Loss (레이 쌍 RGB 손실):** 객체 경계에서의 분할 오류를 줄이기 위해 색상 및 공간 정보를 통합합니다. 유사한 RGB 색상을 가진 레이들이 유사한 객체 식별 예측을 가지도록 장려합니다.
        $$ L_{RGB}(R) = \frac{1}{|K|} \sum_{r_k \in K} \frac{1}{|S_k|} \sum_{r_s \in S_k} f(\hat{M}(r_k), \hat{M}(r_s)) $$
        여기서 $f$는 두 확률 벡터 간의 거리 함수입니다. 오류 맵 기반의 샘플링 전략을 사용하여 손실을 오류가 큰 지역에 집중적으로 적용합니다. 전체 손실 함수는 $L = L_o(R) + \frac{1}{|T|} \sum_{p \in T} L_{RGB}(R_p)$입니다.

## 📊 Results

SANeRF-HQ는 Mip-NeRF 360, LERF, LLFF, 3D-FRONT 등 다양한 합성 및 실제 세계 데이터셋에서 최신 방법론(SA3D, ISRF, SAN 등) 대비 뛰어난 정량적 및 정성적 성능을 보였습니다.

* **정량적 결과:** 모든 데이터셋에서 mIoU 및 Acc(Accuracy) 지표에서 다른 방법들을 능가했습니다. 특히, SA3D와 ISRF 대비 분할 경계의 정확도와 다중 뷰 일관성에서 상당한 개선을 보였습니다. (예: Mip-NeRF 360에서 mIoU 91.0%, LERF에서 90.7%)
* **어블레이션 연구:**
  * **SAM 모델 및 특징 컨테이너:** HQ-SAM과 캐시 컨테이너 조합이 전반적으로 가장 좋은 성능을 보였습니다. 특징 증류와 캐싱 간의 성능 차이는 크지 않아 계산 비용이 중요한 요소로 작용할 수 있음을 시사했습니다.
  * **마스크 통합자:** 직접적인 2D SAM 마스크는 뷰 일관성을 보장하지 못하며 앨리어싱 문제를 겪었으나, SANeRF-HQ의 마스크 통합자는 3D 기하학적 정보를 활용하여 일관되고 고품질의 3D 마스크를 생성했습니다.
  * **Ray-Pair RGB Loss:** 마스크 품질을 약간 향상시켰으며, 특히 누락된 내부 영역과 경계를 복구하는 데 도움이 되었습니다.
* **다양한 분할 작업:** Grounding-DINO와 통합하여 텍스트 프롬프트 기반 분할 및 NeRF 렌더링 비디오와 SAM의 자동 분할 기능을 활용한 자동 3D 분할도 가능함을 보여주었습니다.

## 🧠 Insights & Discussion

SANeRF-HQ는 SAM의 개방형 객체 분할 능력과 NeRF의 다중 시점 정보 통합 능력을 결합하여 3D 분할 분야에 크게 기여했습니다. 특히 밀도 필드와 RGB 유사성을 활용하여 분할 경계의 정확도를 높이고 다중 뷰 일관성을 향상시킨 점이 핵심입니다. 이를 통해 복잡한 시나리오에서도 높은 품질의 분할 결과를 얻을 수 있음을 입증했습니다.

**장점:**

* 높은 분할 정확도와 다중 시점 일관성.
* 다양한 사용자 프롬프트(2D/3D 포인트, 텍스트)에 대한 유연한 지원.
* NeRF 기반의 3D 기하학적 정보를 활용한 견고한 분할.
* 4D 동적 NeRF 분할로의 확장 가능성을 제시.

**한계:**

* NeRF와 SAM의 성능에 의존하며, 장면의 복잡성이나 NeRF 품질에 영향을 받을 수 있습니다.
* Ray-Pair RGB Loss는 색상과 음영이 유사한 인접 객체에 대해서는 덜 효과적일 수 있습니다.
* 비교적 작거나 부분적으로 가려진 객체, 배경에 있는 객체 등 도전적인 시나리오에서도 견고한 성능을 보였으나, 모든 경우를 완벽하게 처리하는 것은 아닙니다.

## 📌 TL;DR

SANeRF-HQ는 SAM의 제로샷 2D 분할 능력과 NeRF의 3D 장면 표현을 결합하여 고품질 3D 객체 분할을 위한 새로운 프레임워크를 제시합니다. 이 방법은 NeRF의 밀도 필드와 RGB 유사성을 활용하는 마스크 통합자(Mask Aggregator)를 통해 기존 방법들이 겪던 부정확한 경계와 다중 뷰 비일관성 문제를 해결합니다. 다양한 데이터셋에서 우수한 성능을 입증했으며, 텍스트 프롬프트 기반 및 동적 NeRF 분할로의 확장 가능성도 보여주었습니다.
