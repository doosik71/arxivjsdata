# Segment anything, from space?

Simiao Ren, Francesco Luzi, Saad Lahrichi, Kaleb Kassaw, Leslie M. Collins, Kyle Bradbury, Jordan M. Malof

## 🧩 Problem to Solve

최근 개발된 이미지 분할용 파운데이션 모델인 SAM(Segment Anything Model)은 자연 이미지에서 인상적인 제로샷(zero-shot) 분할 성능을 보여주었습니다. 이 연구는 SAM의 이러한 뛰어난 성능이 항공 이미지(overhead imagery), 즉 위성이나 드론으로 촬영된 이미지 작업에도 확장될 수 있는지 평가하는 것을 목표로 합니다. 항공 이미지는 자연 이미지와는 다른 독특한 특성과 대상 객체를 가지므로, SAM의 일반화 가능성과 잠재적 한계를 체계적으로 조사할 필요가 있습니다.

## ✨ Key Contributions

* **최초의 포괄적 평가**: 다양한 항공 이미지 벤치마크 데이터셋을 사용하여 SAM의 성능을 체계적이고 포괄적으로 조사한 최초의 연구입니다.
* **두 가지 핵심 시나리오 분석**: SAM의 두 가지 주요 잠재적 응용 시나리오인 '모델 구성(Model Composition)'과 '상호작용적 주석(Interactive Annotation)'에 대한 성능을 평가했습니다.
* **고유한 실패 사례 식별**: 항공 이미지에서 SAM이 겪는 고유한 체계적 실패 사례들을 식별하고, 이는 향후 연구 방향을 제시합니다.
* **연구 커뮤니티 가이드라인 제시**: 항공 이미지 분야 연구자들이 SAM을 활용할 때 고려해야 할 유용한 지침을 제공합니다.

## 📎 Related Works

* **파운데이션 모델**: BERT [9], GPT-3 [4] (자연어 처리), CLIP [24], ALIGN [14] (텍스트-이미지).
* **Segment Anything Model (SAM)**: Kirillov et al. [18]이 개발한 최초의 분할 전용 파운데이션 모델로, 포인트, 바운딩 박스, 마스크 등 저비용 프롬프트를 통해 객체 분할을 수행합니다.
* **SAM의 최근 응용**: 이미지 디헤이징 [15], 이미지 태깅 [34], 그림자 분할 [29], 수중 음파 탐지기 분할 [28], 전경 분할 [30], 전자 현미경 분할 [7, 19], 다양한 의료 영상 분할 [1, 10-12, 17, 20, 28, 32].
* **원격 감지 분야 SAM 응용**: 행성 지질학적 특징 [16], 빙하 [26] 및 해빙 [31] 분할, 도로 및 건물 분할 [13, 33]. 본 연구는 이들 선행 연구보다 더 포괄적인 평가를 수행합니다.
* **상호작용적 분할 모델**: RITM [25] (SAM 성능 비교를 위한 베이스라인).
* **U-Net 기반 모델**: [21] 등을 포함한 지도 학습 모델들은 SAM과 비교하기 위한 베이스라인으로 사용됩니다.

## 🛠️ Methodology

연구진은 8개의 공개 항공 이미지 벤치마크 데이터셋(예: Solar, Inria, DeepGlobe Buildings/Roads/Land, 38-Cloud, SpaceNet 2, Parcel Delineation)을 사용하여 SAM을 평가했습니다. 이 데이터셋들은 다양한 객체 클래스(건물, 도로, 구름, 작물), 해상도 (0.3m – 30m), 지리적 위치를 포함합니다.

1. **모델 구성(Model Composition) 실험**:
    * **프롬프트 생성**: 다른 비전 모델이 생성한 프롬프트(바운딩 박스 또는 포인트)를 모방하여 SAM에 제공합니다.
    * **U-Net 모델**: 각 벤치마크 데이터셋에 대해 U-Net 분할 모델(`U-Net (ours)`)을 훈련하여 바운딩 박스 프롬프트를 생성합니다. 기존의 최첨단(SOTA) U-Net 모델(`U-Net (SOTA)`)과도 비교합니다.
    * **바운딩 박스 프롬프트**: `U-Net (ours)` 모델의 출력 마스크에서 인스턴스 레벨의 바운딩 박스를 추출하여 SAM에 입력합니다. SAM의 분할 결과($$\hat{m}_{i}$$)를 통합하여 클래스 레벨 마스크($$\hat{m} = \bigcup_{i} \hat{m}_{i}$$)를 생성하고 IoU를 측정합니다.
    * **포인트 프롬프트**: 그라운드 트루스 마스크 내에서 임의의 점 또는 중심점을 선택하여 포인트 프롬프트를 생성합니다. SAM은 3개의 후보 마스크와 예측 IoU($$\hat{c}_{k}$$)를 반환하며, 이 중 가장 높은 예측 IoU를 가진 마스크($$\hat{m}^{*}$$)를 선택합니다.

2. **상호작용적 주석(Interactive Annotation) 실험**:
    * **프롬프트 생성**: 인간 주석자가 제공하는 프롬프트를 모방하여 그라운드 트루스 마스크로부터 프롬프트를 생성합니다.
    * **바운딩 박스 프롬프트**: 그라운드 트루스 마스크에서 추출한 바운딩 박스를 SAM에 입력합니다.
    * **단일 포인트 프롬프트**: 그라운드 트루스 마스크 내의 임의점 또는 중심점을 SAM에 입력합니다. SAM이 반환하는 3개의 후보 마스크 중, *실제 IoU*($$c_{k}^{t}$$)가 가장 높은 마스크($$\hat{m}^{*}$$)를 선택합니다. RITM [25] 모델과 비교합니다.
    * **반복적 포인트 프롬프트**: 인간 주석자가 반복적으로 마스크를 개선하는 시나리오를 모방합니다. 초기 중심점 프롬프트에서 시작하여, SAM의 이전 출력 마스크($$\hat{m}^{*}_{t}$$)의 가장 큰 오류 영역(오탐 또는 미탐) 중앙에 새로운 포인트 프롬프트($$p_{t+1}$$)를 생성하여 SAM에 입력합니다. 반복 횟수($$T$$)에 따른 SAM 및 RITM의 성능 변화를 평가합니다.

3. **추가 분석**: 이미지 해상도에 대한 SAM의 민감도(이미지 업샘플링 실험)와 특정 객체 클래스(예: 도로)에서 인스턴스 분할의 부적절성(ill-posedness)을 조사합니다.

## 📊 Results

* **모델 구성**:
  * 지도 학습된 U-Net 모델(특히 SOTA)이 거의 항상 가장 높은 IoU를 달성했습니다.
  * SAM은 바운딩 박스 프롬프트에 비해 포인트 프롬프트에서 일관되게 낮은 성능을 보였습니다.
  * 대부분의 항공 이미지 벤치마크(특히 건물 및 도로)에서 SAM과 지도 학습 모델 간의 성능 격차가 자연 이미지보다 훨씬 컸습니다.
  * 도로와 같이 '객체 인스턴스' 개념이 잘 정의되지 않는 클래스에서는 SAM의 성능이 매우 낮았습니다 (IoU < 0.10).
  * 전반적으로, SAM은 일부 경우에 지도 학습 모델에 필적하는 경쟁력 있는 제로샷 결과를 제공할 수 있지만, 대부분의 경우 성능이 낮고 특정 시나리오에서는 완전히 실패했습니다.

* **상호작용적 주석**:
  * SAM은 베이스라인 상호작용적 주석 모델인 RITM을 거의 항상 능가했으며, 종종 상당한 차이(예: Solar 데이터셋에서 50 IoU 포인트, Inria+DG Buildings에서 45 IoU 포인트)로 우수했습니다.
  * 프롬프트 정보량이 감소함에 따라(바운딩 박스 > 중심점 > 임의점), SAM의 IoU는 감소하는 경향을 보였습니다.
  * 다중 포인트(반복적 개선) 프롬프트는 SAM과 RITM 모두에서 IoU를 꾸준히 향상시켰습니다. SAM은 적은 수의 포인트에서 가장 큰 성능 우위를 보였으며, $$T=10$$ 포인트에서는 10개 벤치마크 중 6개에서 IoU $\ge 0.75$를 달성했습니다.
  * 전반적인 IoU는 자연 이미지에 대한 SAM의 결과에 비해 낮았지만, 실제 주석 시나리오에서 유용할 만큼 충분히 높은 경우가 많았습니다.

* **추가 분석**:
  * **해상도 민감성**: 이미지 업샘플링이 (정보량 증가 없이) SAM의 IoU를 크게 향상시키거나 저하시킬 수 있음을 발견했습니다. 이는 SAM이 훈련 과정에서 특정 객체 크기(픽셀 단위)에 편향될 수 있음을 시사합니다.
  * **인스턴스 분할의 부적절성**: 도로와 같이 공간적으로 연결된 대규모 객체는 개별 '인스턴스'를 정의하기 어렵기 때문에, SAM은 이러한 클래스에서 매우 저조한 성능을 보였습니다.

## 🧠 Insights & Discussion

* SAM의 항공 이미지 성능은 상당히 가변적입니다. 일부 작업에서는 잘 일반화되지만, 지도 학습 모델에 비하면 복잡하거나 정의가 모호한 객체에서 성능이 떨어집니다.
* 자연 이미지 학습으로 인한 '객체성(objectness)' 개념에 대한 편향이 항공 이미지의 고유한 객체(예: 건물, 도로)에 잘 적용되지 않을 수 있습니다.
* 도로와 같이 인스턴스 분할이 적합하지 않은 클래스의 경우, SAM은 심각한 어려움을 겪습니다. 이는 이러한 카테고리에는 인스턴스 레벨 분할 대신 클래스 레벨 분할이 더 적합할 수 있음을 의미합니다.
* SAM의 디코더 부분(모델의 작은 부분)을 항공 이미지에 특화된 특징으로 미세 조정하거나, 특정 클래스에 대해 클래스 레벨 분할을 위해 재훈련하는 것이 성능과 신뢰성을 크게 향상시킬 수 있습니다.
* 이미지 해상도에 대한 민감성은 SAM이 '선호하는' 객체 픽셀 크기에 맞춰 이미지를 조정하는 것이 성능에 도움이 될 수 있음을 시사합니다.

## 📌 TL;DR

**문제**: 자연 이미지 분할 파운데이션 모델인 SAM이 다양한 항공 이미지(예: 위성 이미지) 작업에 효과적으로 일반화될 수 있는가?

**방법**: 8개의 항공 이미지 벤치마크 데이터셋에서 SAM의 제로샷 성능을 두 가지 시나리오로 평가했다: 1) **모델 구성** (다른 비전 모델의 바운딩 박스 또는 포인트 출력으로 SAM 프롬프트), 2) **상호작용적 주석** (인간이 에뮬레이션한 포인트/박스 프롬프트로 SAM의 주석 보조 기능 평가).

**결과**:

* SAM은 최첨단 상호작용적 주석 베이스라인(RITM)보다 크게 우수하여, 특히 적은 수의 프롬프트로도 강력한 주석 도구임을 입증했다.
* 모델 구성에서는 SAM의 성능이 가변적이다. 일부 경우에서는 기존 지도 학습 모델에 필적하지만, 정보량이 적은 프롬프트(포인트 vs. 박스)에서는 대개 성능이 낮았다.
* 특정 항공 이미지 특성에서 심각한 어려움을 겪는다: 복잡한 구조의 객체(건물), 매우 작은 객체(태양광 패널), 그리고 특히 '인스턴스' 개념이 불분명한 객체(예: 도로, 거의 완전히 실패).
* SAM은 이미지 해상도에 민감하여, 자연 이미지 훈련에서 접한 객체 크기에 대한 편향을 시사했다.

**시사점**: SAM의 디코더를 항공 이미지 특정 특징으로 미세 조정하거나 클래스 레벨 분할을 위해 재훈련하면 현재의 한계를 극복하고 성능을 크게 향상시킬 수 있다.
