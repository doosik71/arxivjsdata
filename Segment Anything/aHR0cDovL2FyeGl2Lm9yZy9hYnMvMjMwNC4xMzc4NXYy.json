{
  "url": "http://arxiv.org/abs/2304.13785v2",
  "title": "Customized Segment Anything Model for Medical Image Segmentation",
  "authors": "Kaidong Zhang, Dong Liu",
  "year": 2023,
  "abstract": "We propose SAMed, a general solution for medical image segmentation.\nDifferent from the previous methods, SAMed is built upon the large-scale image\nsegmentation model, Segment Anything Model (SAM), to explore the new research\nparadigm of customizing large-scale models for medical image segmentation.\nSAMed applies the low-rank-based (LoRA) finetuning strategy to the SAM image\nencoder and finetunes it together with the prompt encoder and the mask decoder\non labeled medical image segmentation datasets. We also observe the warmup\nfinetuning strategy and the AdamW optimizer lead SAMed to successful\nconvergence and lower loss. Different from SAM, SAMed could perform semantic\nsegmentation on medical images. Our trained SAMed model achieves 81.88 DSC and\n20.64 HD on the Synapse multi-organ segmentation dataset, which is on par with\nthe state-of-the-art methods. We conduct extensive experiments to validate the\neffectiveness of our design. Since SAMed only updates a small fraction of the\nSAM parameters, its deployment cost and storage cost are quite marginal in\npractical usage. The code of SAMed is available at\nhttps://github.com/hitachinsk/SAMed.",
  "citation": 405
}