# Conditional Convolutions for Instance Segmentation

Zhi Tian, Chunhua Shen, Hao Chen

## 🧩 Problem to Solve

현재 최고의 성능을 보이는 인스턴스 분할(Instance Segmentation) 방법들, 예를 들어 Mask R-CNN은 ROI(Region-of-Interest) 연산(ROIPool 또는 ROIAlign)에 의존하여 최종 인스턴스 마스크를 얻습니다. 이러한 ROI 기반 방식은 다음과 같은 문제점을 안고 있습니다.

1. **불규칙한 형태의 객체 처리 비효율성**: ROI가 축 정렬된 바운딩 박스인 경우, 불규칙한 객체에 대해 배경이나 다른 객체와 같은 불필요한 이미지 내용을 과도하게 포함할 수 있습니다.
2. **높은 연산 복잡도**: 마스크 헤드가 전경 객체와 배경을 구분하기 위해 상대적으로 넓은 수용 필드(receptive field)를 필요로 하여 많은 3x3 컨볼루션 계층과 채널(예: Mask R-CNN에서 256개 채널의 4개 3x3 컨볼루션)이 필요하며, 이는 인스턴스 수에 따라 추론 시간이 크게 변동하는 원인이 됩니다.
3. **마스크 해상도 제한**: ROI는 일반적으로 크기가 다르므로, 일괄 처리를 위해 동일한 크기(예: Mask R-CNN의 14x14)로 조정하는 과정이 필요하며, 이는 인스턴스 분할의 출력 해상도를 제한하여 큰 인스턴스의 경계 세부 정보를 손실시킬 수 있습니다.
완전 컨볼루션 네트워크(FCNs)는 인스턴스 분할에서 유사한 외모를 가진 객체들을 구분하는 데 어려움을 겪습니다. 예를 들어, 두 사람 A와 B가 유사하게 보일 때 FCN은 A의 마스크를 예측할 때 B를 배경으로 처리해야 하는데, 이는 외모가 유사하기 때문에 어렵습니다. 기존 방법들은 ROI 크롭핑을 통해 명시적으로 객체의 위치 정보를 제공하여 이 문제를 해결합니다.

## ✨ Key Contributions

- **새로운 인스턴스 분할 프레임워크 제안**: CondInst(conditional convolutions for instance segmentation)를 제안하여 기존 방식의 한계를 극복하고, 새로운 관점에서 인스턴스 분할을 해결했습니다.
- **향상된 성능 및 속도**: Mask R-CNN과 같은 기존 최첨단 방법보다 정확도와 추론 속도 모두에서 우수한 성능을 달성했으며, 추가적인 긴 훈련 스케줄이 필요하지 않습니다.
- **완전 컨볼루션 방식**: CondInst는 완전 컨볼루션 네트워크로, ROI 크롭핑 및 특징 정렬(feature alignment) 연산을 제거하여 고해상도 인스턴스 마스크를 더 정확한 경계와 함께 생성할 수 있습니다.
- **동적 인스턴스 인식 네트워크**: 고정된 가중치를 가진 네트워크를 사용하는 대신, 각 인스턴스에 맞춰 동적으로 생성되는 인스턴스 인식 네트워크(조건부 컨볼루션)를 활용합니다.
- **매우 가벼운 마스크 헤드**: 동적으로 생성되는 조건부 컨볼루션의 향상된 용량 덕분에 마스크 헤드를 매우 작고 간결하게 구성할 수 있습니다 (예: 8개 채널을 가진 3개의 컨볼루션 레이어). 이로 인해 추론 시간이 크게 단축됩니다. 예를 들어, 기본 탐지기 FCOS에 비해 약 $10\%$의 추가 연산 시간만으로 100개의 인스턴스를 처리할 수 있습니다.

## 📎 Related Works

- **조건부 컨볼루션 (Conditional Convolutions)**: 동적 필터 네트워크(Dynamic Filter Networks) [20] 및 CondConv [41]와 같이, 고정된 필터 대신 입력에 따라 동적으로 필터를 생성하는 아이디어에서 영감을 받았습니다. CondInst는 이를 인스턴스 분할이라는 더 도전적인 태스크에 적용합니다.
- **인스턴스 분할 (Instance Segmentation)**:
  - **Mask R-CNN 계열**: Mask R-CNN [14]은 객체 탐지(바운딩 박스) 후 ROI 연산을 통해 특징을 추출하고, 컴팩트한 FCN 헤드로 마스크를 얻는 지배적인 프레임워크입니다. 많은 고성능 모델 [7, 18, 25]이 Mask R-CNN을 기반으로 합니다.
  - **FCN 기반 방식**: InstanceFCN [10]은 최초의 완전 컨볼루션 인스턴스 분할 방법으로, 위치에 민감한 스코어 맵을 예측합니다. 다른 방법들 [12, 30, 31, 32]은 먼저 분할을 수행한 다음 동일 인스턴스의 픽셀을 조합하는 방식을 시도했으나, Mask R-CNN을 능가하는 정확도와 속도를 달성하지 못했습니다.
  - **최근 연구**: YOLACT [4]와 BlendMask [6]는 Mask R-CNN의 재구성으로 볼 수 있으며, SOLO [38], PolarMask [40], EmbedMask [44] 등도 FCN 기반 또는 새로운 마스크 표현 방식을 탐구합니다.
- **AdaptIS [35]**: FiLM [33]을 사용하여 파놉틱 분할을 해결하며, 인스턴스 정보를 배치 정규화 계수에 인코딩합니다. CondInst는 이를 컨볼루션 필터에 직접 인코딩하여 훨씬 강력한 용량을 가집니다.

## 🛠️ Methodology

1. **전체 아키텍처**:
    - 객체 탐지기 FCOS [37]를 기반으로 구축되어, FCOS의 단순성과 유연성, 앵커 박스(anchor-box) 제거의 이점을 활용합니다.
    - 백본 네트워크(예: ResNet-50)와 FPN(Feature Pyramid Networks) [21]의 특징 맵 $P_3, P_4, P_5, P_6, P_7$을 활용합니다.
    - 각 FPN 레벨에서 인스턴스 관련 예측을 수행하는 헤드(head)들이 적용됩니다.
    - **Classification Head**: FCOS와 유사하게, 해당 위치와 연관된 인스턴스의 클래스를 예측합니다.
    - **Controller Head**: 마스크 헤드의 필터 파라미터($\theta_{x,y}$)를 동적으로 생성합니다. 이 헤드는 인스턴스의 중심 영역에 조건화됩니다.
    - **Mask Branch**:
        - FPN 레벨 $P_3$에 연결되어 입력 이미지 해상도의 $1/8$에 해당하는 특징 맵($F_{\text{mask}} \in \mathbb{R}^{H_{\text{mask}} \times W_{\text{mask}} \times C_{\text{mask}}}$)을 출력합니다.
        - $F_{\text{mask}}$는 4개의 3x3 컨볼루션과 128개 채널을 가지며, 마지막 레이어에서 채널 수를 8개($C_{\text{mask}}=8$)로 줄입니다.
        - $F_{\text{mask}}$는 해당 인스턴스의 중심 위치 $(x,y)$에 대한 상대 좌표 맵 $O_{x,y}$와 결합되어($\tilde{F}_{x,y}$) 마스크 헤드의 입력이 됩니다.
    - **Mask Head**:
        - 컨트롤러 헤드에서 동적으로 생성된 필터 파라미터 $\theta_{x,y}$를 사용합니다.
        - 세 개의 $1 \times 1$ 컨볼루션으로 구성된 매우 컴팩트한 FCN입니다 (각각 8개 채널, ReLU 활성화 함수 사용, 마지막 레이어는 1개 출력 채널에 Sigmoid). 총 169개의 파라미터만 가집니다.
        - 클래스 불가지론적(class-agnostic) 마스크를 예측합니다.
        - 최종 예측 마스크는 $F_{\text{mask}}$ 해상도의 4배로 이중 선형 업샘플링되어 원본 이미지 해상도의 $1/2$이 됩니다.

2. **네트워크 출력 및 훈련 목표**:
    - FCOS와 유사하게, FPN 특징 맵의 각 위치는 인스턴스와 연관되거나(양성 샘플) 배경(음성 샘플)으로 간주됩니다.
    - **손실 함수**: 전체 손실 함수는 FCOS의 손실($L_{\text{fcos}}$)과 인스턴스 마스크 손실($L_{\text{mask}}$)의 합으로 정의됩니다.
        $$L_{\text{overall}} = L_{\text{fcos}} + \lambda L_{\text{mask}}$$
        $L_{\text{mask}}$는 Dice Loss [29]를 사용하며 다음과 같습니다.
        $$L_{\text{mask}}(\{\theta_{x,y}\}) = \frac{1}{N_{\text{pos}}} \sum_{x,y} \mathbf{1}_{\{c^*_{x,y}>0\}} L_{\text{dice}}(\text{MaskHead}(\tilde{F}_{x,y}; \theta_{x,y}), M^*_{x,y})$$
        여기서 $N_{\text{pos}}$는 양성 위치의 수, $\mathbf{1}_{\{c^*_{x,y}>0\}}$는 지시 함수, $c^*_{x,y}$는 위치 $(x,y)$에 해당하는 인스턴스의 클래스 레이블, $M^*_{x,y}$는 해당 인스턴스의 정답 마스크입니다.
    - 보조 Semantic Segmentation 태스크를 추가하여 성능을 더욱 향상시킬 수 있습니다.

3. **추론**:
    - FCOS의 단계를 따라 분류 신뢰도, 중심도 점수, 박스 예측, 동적으로 생성된 필터 파라미터를 얻습니다.
    - 박스 기반 NMS(비최대 억제, threshold $0.6$, 상위 100개 박스)를 사용하여 중복 탐지를 제거합니다. 이때 박스는 NMS에만 사용되며 ROI 연산에는 관여하지 않습니다.
    - NMS 후 남아있는 각 탐지된 인스턴스에 대해, 해당 인스턴스에 특화된 마스크 헤드(동적으로 생성된 필터 사용)를 $\tilde{F}_{x,y}$에 적용하여 인스턴스 마스크를 예측합니다.
    - 마스크 헤드의 연산 오버헤드는 매우 작아(100개 탐지에 대해 5ms 미만), 기본 FCOS 탐지기에 약 $10\%$의 추가 연산 시간만 소요됩니다.
    - 박스 탐지 없이 마스크 기반 NMS를 사용하여 바운딩 박스 예측을 완전히 제거할 수도 있습니다.

## 📊 Results

- **마스크 헤드 아키텍처**: 마스크 헤드의 깊이(depth)와 너비(width)에 비교적 둔감하며, 3개의 1x1 컨볼루션과 8개의 채널을 가진 기본 마스크 헤드가 100개의 인스턴스당 4.5ms만 소요되는 것으로 나타났습니다. 이는 Mask R-CNN 마스크 헤드(2.3M 파라미터, 11.4ms) 대비 훨씬 효율적입니다.
- **마스크 브랜치 설계**: 마스크 브랜치 출력 채널 수($C_{\text{mask}}$)는 2에서 16 사이에서 성능 변화가 거의 없으며, 8이 최적입니다. 특히, 마스크 예측에 **상대 좌표**를 사용하는 것이 매우 중요하며, 이를 제거하면 마스크 AP가 $35.7\%$에서 $31.4\%$로 크게 감소합니다. 이는 생성된 필터가 외모뿐만 아니라 객체의 형태(및 상대 위치) 정보를 인코딩함을 시사합니다.
- **마스크 예측 업샘플링**: 마스크 예측의 업샘플링은 최종 성능에 결정적입니다. 업샘플링이 없으면(1/8 해상도) 마스크 AP가 $34.4\%$에 불과했지만, 2배 업샘플링(1/4 해상도) 시 $1.4\%$ 향상(특히 작은 객체에서 큰 향상)을 보였고, 4배 업샘플링(1/2 해상도) 시 $35.7\%$로 유사한 성능을 유지하면서 고해상도 마스크를 제공합니다.
- **바운딩 박스 탐지 없는 CondInst**: 마스크 기반 NMS를 사용하면 바운딩 박스 기반 NMS와 동일한 전체 성능($35.7\%$ AP)을 얻을 수 있어, CondInst가 박스 탐지 없이도 작동할 수 있음을 보여줍니다.
- **최첨단 방법과의 비교 (MS-COCO test-dev)**:
  - $1\times$ 훈련 스케줄에서 CondInst(35.4% AP, 49ms)는 원본 Mask R-CNN(34.6% AP, 65ms)을 능가했습니다.
  - Detectron2의 Mask R-CNN*보다도 향상된 성능(35.9% AP vs 35.5% AP)을 비슷한 속도(49ms)로 달성했습니다.
  - 더 긴 훈련 스케줄($3\times$) 또는 더 강력한 백본(ResNet-101) 사용 시에도 일관된 성능 향상을 보였습니다.
  - 보조 Semantic Segmentation 태스크를 추가하면 추론 시간 증가 없이 성능이 더욱 향상됩니다 (ResNet-50에서 $37.8\%$ $\rightarrow$ $38.8\%$, ResNet-101에서 $39.1\%$ $\rightarrow$ $40.1\%$).
  - TensorMask [9] 및 YOLACT-700 [4]과 같은 다른 최신 방법들보다도 훨씬 우수한 정확도와 속도를 보였습니다.
- **정성적 결과**: YOLACT-700 및 Mask R-CNN에 비해 더 많은 세부 정보를 보존하고 더 높은 품질의 인스턴스 분할 결과를 생성합니다.

## 🧠 Insights & Discussion

CondInst는 ROI 기반 인스턴스 분할 방법의 주요 단점들을 효과적으로 해결합니다. ROI 연산을 제거함으로써 파이프라인을 단순화하고, 추론 속도를 높이며, 고해상도 마스크 예측을 가능하게 합니다. 동적으로 생성되는, 인스턴스에 조건화된 컨볼루션을 사용하는 것이 핵심 혁신이며, 이를 통해 매우 간결한 마스크 헤드만으로도 뛰어난 성능을 달성할 수 있습니다. 상대 좌표 정보의 도입은 동적으로 생성된 필터가 인스턴스의 형태와 상대적 위치를 이해하고, 해당 인스턴스의 픽셀에만 반응하도록 돕는 결정적인 요소입니다. 이는 바운딩 박스에 의존하지 않고도 형태 정보를 암묵적으로 인코딩하는 유연한 방법입니다. CondInst는 기존의 고정 가중치 네트워크가 잘린 ROI를 처리하는 방식에서 벗어나, 동적으로 인스턴스에 조건화된 네트워크가 전체 특징 맵을 처리하는 새로운 패러다임을 제시합니다.

## 📌 TL;DR

- **문제**: 기존 인스턴스 분할(예: Mask R-CNN)은 ROI(Region-of-Interest) 연산에 의존하며, 이는 불규칙한 객체 처리, 높은 연산량, 낮은 마스크 해상도 등의 단점을 가집니다. 일반적인 FCN은 유사한 객체를 구분하기 어렵습니다.
- **제안 방법**: CondInst(Conditional Convolutions for Instance Segmentation)는 각 인스턴스에 따라 동적으로 필터를 생성하는 *조건부 컨볼루션* 기반의 마스크 헤드를 제안합니다. 이 마스크 헤드는 ROI 연산 없이 전체 특징 맵에 적용되어 인스턴스 마스크를 예측합니다. FCOS 탐지기를 기반으로 하며, 마스크 브랜치의 특징 맵에 상대 좌표를 추가하여 마스크 헤드에 입력합니다.
- **핵심 결과**: CondInst는 기존 Mask R-CNN보다 정확도(COCO test-dev에서 Mask R-CNN보다 $0.8\%$ AP 향상)와 추론 속도(49ms vs 65ms) 모두에서 뛰어난 성능을 달성했습니다. 동적으로 생성되는 필터 덕분에 마스크 헤드는 매우 가볍고(총 169개 파라미터), ROI 연산이 없어 고해상도 마스크를 생성하며, 상대 좌표 정보가 마스크 예측에 결정적인 역할을 함을 확인했습니다. 박스 탐지 없이 마스크 기반 NMS로도 동일한 성능을 유지할 수 있어 파이프라인 단순화의 가능성을 보여주었습니다.
