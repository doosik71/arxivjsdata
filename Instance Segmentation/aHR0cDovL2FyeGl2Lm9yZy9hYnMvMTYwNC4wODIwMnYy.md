# Amodal Instance Segmentation

Ke Li, Jitendra Malik

## 🧩 Problem to Solve

이 논문은 **비모달 인스턴스 분할(Amodal Instance Segmentation)** 문제에 초점을 맞춥니다. 비모달 인스턴스 분할은 이미지 내 각 객체의 보이는 부분뿐만 아니라 **가려진(occluded) 부분까지 포함하여 전체 영역을 예측**하는 것을 목표로 합니다. 기존에는 이와 관련된 공개 데이터셋이 부족하여 비모달 분할 방법론 개발에 큰 어려움이 있었습니다. 따라서 본 연구의 주요 과제는 비모달 분할을 위한 지도 학습 데이터의 부족 문제를 해결하면서 효과적인 비모달 인스턴스 분할 방법을 개발하는 것입니다.

## ✨ Key Contributions

* **최초의 비모달 인스턴스 분할 방법 제시**: 공개적으로 사용 가능한 비모달 분할 어노테이션이 없는 상황에서, 저자들의 지식 범위 내에서 최초로 비모달 인스턴스 분할 방법을 제안했습니다.
* **합성 훈련 데이터 생성 전략**: 기존의 **모달 인스턴스 분할(Modal Instance Segmentation)** 어노테이션만을 활용하여 합성 가려짐(synthetic occlusion)을 생성하고, 이를 통해 비모달 분할을 위한 훈련 데이터를 효과적으로 생성하는 독창적인 방법을 제시했습니다.
* **반복적 바운딩 박스 확장($Iterative\ Bounding\ Box\ Expansion$)**: 예측된 비모달 분할 히트맵으로부터 비모달 바운딩 박스를 추론하기 위한 새로운 반복적 확장 전략을 도입했습니다.
* **실제 가려짐에 대한 효과 입증**: 합성 데이터로 훈련되었음에도 불구하고, 실제 가려짐이 있는 이미지에서 비모달 마스크를 효과적으로 예측할 수 있음을 정성적 및 정량적으로 입증했습니다.

## 📎 Related Works

* **초기 영역 분할 연구**: 형상-배경 분할(figure-ground segmentation), 의미 분할(semantic segmentation)에 대한 연구 (예: Arbeláez et al. [1], Farabet et al. [10]).
* **인스턴스 분할 연구**: 개별 객체 인스턴스의 픽셀을 식별하는 연구 (예: DPM [11], SDS [18], Hypercolumn net [19], Iterative Instance Segmentation (IIS) [27], Multi-Task Network Cascades [7]). R-CNN [14], Fast R-CNN [13], Faster R-CNN [32] 등 객체 검출기와 결합하는 방식도 포함됩니다.
* **비모달 완성(Amodal Completion) 연구**:
  * Kar et al. [21]은 객체의 비모달 바운딩 박스 예측 문제를 다루었습니다.
  * Gupta et al. [16]은 깊이 정보를 사용하여 평면 표면의 가려진 부분을 완성하는 연구를 수행했습니다.
  * Zhu et al. [40]은 비모달 분할 어노테이션을 수집했으나, 당시에는 공개되지 않았습니다.
  * 이 논문은 범용 비모달 분할에 대한 최초의 알고리즘적 연구로 평가됩니다.

## 🛠️ Methodology

본 논문은 모달 인스턴스 분할 데이터로부터 비모달 훈련 데이터를 생성하고, 이를 활용하여 합성곱 신경망(CNN)을 훈련시키는 방법을 제안합니다.

* **훈련 데이터 생성**:
    1. **합성 가려짐 생성**: PASCAL VOC 2012 trainset의 SBD (Semantic Boundaries) 어노테이션 [17]을 데이터 소스로 활용합니다. 메인 객체가 포함된 이미지 패치를 무작위로 자르고, 다른 이미지에서 추출한 객체 인스턴스를 그 위에 겹쳐 합성 가려짐을 만듭니다. 이때, 겹쳐지는 객체의 모달 분할 마스크를 알파 매트(alpha matte)로 사용합니다.
    2. **모달 바운딩 박스 샘플링**: 합성 패치에서 메인 객체의 보이는 부분을 둘러싸는 가장 작은 바운딩 박스를 찾고, 시험 시간의 노이즈를 시뮬레이션하기 위해 이를 무작위로 흔들어($jitter$) 사용합니다.
    3. **비모달 마스크 생성**: 메인 객체의 원래 모달 분할 마스크(가려지지 않은 전체 마스크)를 합성 패치의 **참 비모달 마스크**로 사용합니다. 객체에 속하는 픽셀은 양성, 배경은 음성, 다른 객체는 알 수 없음(unknown)으로 레이블링합니다.
  * 데이터는 훈련 중에 동적으로 생성됩니다.
* **모델 아키텍처**:
  * Hypercolumn [19] 아키텍처를 기반으로 한 Iterative Instance Segmentation (IIS) [27]에서 사용된 CNN 아키텍처를 채택합니다. VGG 16-layer net [33]을 기반으로 하며, "O-Net"으로 불립니다.
  * 이 아키텍처는 저수준(finer scale) 및 고수준(coarser scale) 이미지 특징을 모두 활용하기 위해 여러 중간 레이어의 업샘플링된 특징 맵 합계를 최종 히트맵 예측에 사용합니다.
  * 입력은 이미지 패치, 모달 분할 히트맵, 객체 카테고리이며, 출력은 비모달 분할 히트맵입니다.
* **추론 (Testing)**:
    1. **초기 비모달 바운딩 박스 설정**: 주어진 모달 바운딩 박스를 초기 비모달 바운딩 박스로 설정합니다.
    2. **반복적 바운딩 박스 확장**: 각 반복에서 현재 비모달 바운딩 박스 내부의 패치를 CNN에 입력하여 확장된 영역(원래 바운딩 박스 바로 바깥 영역 포함)의 비모달 분할 히트맵을 예측합니다.
    3. **확장 기준**: 원래 바운딩 박스의 상하좌우 영역에서 평균 히트 강도($average\ heat\ intensity$)를 계산하고, 이 값이 임계값(실험에서 0.1)을 초과하면 해당 방향으로 바운딩 박스를 확장합니다.
    4. **반복 종료**: 모든 방향에서 평균 히트 강도가 임계값 미만이 될 때까지 이 과정을 반복합니다.
    5. **최종 마스크 추출**: 최종 비모달 분할 히트맵에서 강도가 0.7을 초과하는 픽셀을 비모달 마스크로 간주하고, 모달 분할 마스크는 모달 히트맵에서 0.8을 임계값으로 사용합니다.
* **훈련 (Training)**:
  * IIS 모델의 가중치로 초기화된 상태에서 확률적 경사 하강법(SGD)을 사용하여 모델을 종단 간(end-to-end) 훈련합니다.
  * 손실 함수는 알려진 진실 레이블(ground truth labels)을 가진 모든 픽셀에 대한 픽셀별 음의 로그 우도(pixel-wise negative log likelihood) 합입니다.
  * 훈련은 50,000회 반복, 학습률 $10^{-5}$, 가중치 감쇠 $10^{-3}$, 모멘텀 0.9로 진행됩니다.

## 📊 Results

* **정성적 결과**:
  * 제안된 방법은 PASCAL VOC 2012 valset의 실제 가려진 객체에 대해 비모달 마스크를 성공적으로 예측했습니다.
  * 합성 가려짐으로 훈련되었음에도 불구하고, 실제 가려짐으로 인한 객체의 숨겨진 부분에 대해 그럴듯한 가설을 제시할 수 있었습니다 (예: 카약 위의 개).
  * 예상외로 모달 예측이 좋지 않은 이미지에서도 제안된 방법은 상당히 좋은 비모달 마스크를 생성했습니다.
  * 가려지지 않은 객체에 대해서도 비모달 예측은 모달 예측과 유사하거나 더 정확하여, 가려짐에 대한 강건함(robustness)을 통해 이미지의 저수준 패턴 변화에 대한 강건함도 얻었음을 시사합니다.
* **간접 정량적 평가 (PASCAL VOC 2012 valset)**:
  * 모달 마스크와 비모달 마스크의 **영역 비율($Area\ Ratio = \frac{area (modal\ mask \cap amodal\ mask)}{area (amodal\ mask)}$)**을 사용하여 가려짐 여부를 예측했습니다.
  * 가려지지 않은 객체는 높은 영역 비율을 보인 반면, 가려진 객체는 약 0.75에서 피크를 이루는 낮은 영역 비율 분포를 보였습니다.
  * 이 영역 비율을 기반으로 가려짐 부재를 예측하는 분류기는 **평균 정밀도(Average Precision, AP)** 77.17%를 달성했습니다.
* **직접 정량적 평가 (수동 어노테이션된 100개 객체)**:
  * 새롭게 수집한 비모달 분할 어노테이션 셋(PASCAL VOC 2012 valset의 100개 객체)을 통해 성능을 직접 평가했습니다.
  * **IoU (Intersection-over-Union)** 기준으로, 제안된 방법은 최신 모달 분할 방법인 IIS보다 훨씬 정확했습니다. 예를 들어, 50% IoU cutoff에서 정확도는 제안된 방법이 80.0%인 반면, IIS는 68.0%였습니다. 70% IoU cutoff에서는 제안된 방법이 48.0%, IIS는 37.0%였습니다.
  * 정확도 곡선 아래 면적($Area\ Under\ Curve$) 또한 제안된 방법이 64.3으로 IIS의 57.5보다 우수했습니다.
  * 제안된 방법은 객체의 73%에서 IIS보다 나은 마스크를 생성했으며, 나머지 27%에서도 IoU 감소는 대부분 5% 미만이었습니다.
* **결합된 검출 및 분할 성능 (Faster R-CNN + Segmentation)**:
  * Faster R-CNN [32]을 검출 시스템으로 사용했을 때, 제안된 방법과 결합된 파이프라인은 IIS와 결합된 파이프라인보다 $mAP_r$ (mean region average precision)에서 우수한 성능을 보였습니다. 50% IoU에서 제안된 방법은 45.2%, IIS는 34.1%였고, 70% IoU에서는 제안된 방법이 22.6%, IIS는 14.0%였습니다.
* **Ablation Analysis (보충 자료)**: 모달 분할 예측을 입력으로 제공하는 것과 동적인 샘플 생성 방식 모두 성능 향상에 중요한 요소임을 확인했습니다.

## 🧠 Insights & Discussion

* **고급 가려짐 추론 가능성**: 비모달 분할 시스템은 가려진 객체의 깊이 순서 추론, 실제 물리적 크기 추정 등 정교한 가려짐 추론을 가능하게 합니다.
* **합성 데이터의 일반화 능력**: 합성 가려짐 데이터로 훈련된 모델이 실제 이미지의 가려짐에 대해서도 그럴듯한 비모달 마스크를 예측할 수 있음을 보여주며, 이는 데이터 부족 문제를 우회하는 효과적인 전략임을 입증합니다.
* **모델의 강건성 향상**: 비모달 분할을 학습함으로써 모델은 가려짐뿐만 아니라 이미지 내 저수준 패턴의 변화에도 강건해져, 가려지지 않은 객체에 대해서도 모달 분할 모델보다 더 정확한 예측을 할 수 있습니다.
* **한계점**:
  * 관절형 객체(articulated objects)와 같이 가려진 부분의 구성이 다양할 수 있는 경우 (예: 사람의 다리 자세), 여전히 모호성이 존재하여 단일 "정답"을 예측하기 어려울 수 있습니다.
  * 훈련 세트에 희귀한 포즈가 부족하거나, 인접한 객체들의 외관이 유사하거나, 모달 예측 자체에 오류가 있는 경우 잘못된 예측이 발생할 수 있습니다.

## 📌 TL;DR

이 논문은 가려진 부분까지 포함하여 객체의 전체 영역을 분할하는 **비모달 인스턴스 분할**이라는 새로운 컴퓨터 비전 문제를 해결합니다. 공개 훈련 데이터가 없다는 문제에 대응하여, 기존 **모달 분할** 데이터셋을 활용해 **합성 가려짐** 훈련 데이터를 동적으로 생성하는 기발한 방법을 제안합니다. 이 합성 데이터로 훈련된 CNN 모델은 **반복적 바운딩 박스 확장** 전략을 통해 비모달 마스크와 바운딩 박스를 예측합니다. 결과적으로, 제안된 방법은 실제 가려짐이 있는 이미지에서 효과적인 비모달 완성을 수행하며, 최신 모달 분할 방법보다 크게 향상된 성능을 보여, 비모달 분할 연구의 선구적인 발걸음을 내딛었습니다.
