# ISTR: End-to-End Instance Segmentation with Transformers

Jie Hu, Liujuan Cao, Yao Lu, ShengChuan Zhang, Yan Wang, Ke Li, Feiyue Huang, Ling Shao, and Rongrong Ji

---

## 🧩 Problem to Solve

기존 인스턴스 분할(Instance Segmentation) 방법들은 수작업으로 설계된 NMS(Non-Maximum Suppression)와 같은 후처리 단계에 의존하거나, 인스턴스 분할을 여러 종속적인 하위 작업(예: Top-down 또는 Bottom-up 프레임워크)으로 분해하여 엔드-투-엔드(End-to-End) 학습을 어렵게 만들었습니다. 특히 객체 탐지(Object Detection)의 경우 이분 매칭(bipartite matching) 기반의 세트 손실(set loss)을 통해 NMS를 제거하며 엔드-투-엔드 학습이 가능해졌으나, 인스턴스 분할은 마스크의 차원(dimension)이 훨씬 높아 이 접근 방식을 직접 적용하기 어렵습니다. 마스크 헤드를 학습시키기 위한 충분한 샘플 부족이 주된 원인입니다.

## ✨ Key Contributions

* **최초의 엔드-투-엔드 인스턴스 분할 트랜스포머(ISTR) 제안**: 기존의 NMS 또는 Top-down/Bottom-up 프레임워크 없이 인스턴스 분할을 수행하는 첫 번째 엔드-투-엔드 트랜스포머 기반 프레임워크를 선보였습니다.
* **저차원 마스크 임베딩 활용**: 고차원 마스크 대신 저차원 마스크 임베딩을 예측하여, 적은 수의 매칭된 샘플로도 효과적인 학습을 가능하게 하고 마스크에 대한 이분 매칭 비용 설계를 용이하게 했습니다.
* **재귀적 정제(Recurrent Refinement) 전략**: 검출과 분할을 동시에 수행하는 재귀적 정제 전략을 통해 기존 방식과 다른 새로운 관점을 제시하고 성능을 향상시켰습니다.
* **최첨단 성능 달성**: 추가적인 기법 없이 MS COCO 데이터셋에서 강력한 정확도와 런타임 성능을 달성하여 인스턴스 레벨 인식의 견고한 기준선을 제시했습니다.

## 📎 Related Works

* **인스턴스 분할**: Top-down (Mask R-CNN, CondInst, BlendMask), Bottom-up (MEInst), 단일 샷(SOLO, SOLOv2) 등 다양한 접근 방식이 존재합니다. ISTR은 이러한 방식과 다르게 박스 및 마스크 임베딩 세트를 직접 예측합니다.
* **엔드-투-엔드 인스턴스 레벨 인식**: 이전 연구들(DETR, Sparse R-CNN)은 주로 객체 탐지에 집중했으며, 인스턴스 분할에 대한 초기 엔드-투-엔드 시도는 소규모 데이터셋에만 적용되었습니다. ISTR은 마스크 임베딩의 유사도 지표를 이분 매칭 비용으로 사용하여 트랜스포머를 인스턴스 분할에 통합했습니다.
* **컴퓨터 비전의 트랜스포머**: 자연어 처리에서 성공한 트랜스포머(Transformer)는 이미지 인식, 객체 탐지, 분할 등 다양한 컴퓨터 비전 작업에 활용되고 있으며, ISTR은 이를 인스턴스 분할에 적용했습니다.
* **다중 작업 학습**: Mask R-CNN과 같은 기존 연구들은 검출과 분할을 동시에 학습하는 이점을 보여주었으며, ISTR 역시 검출과 분할의 동시 처리에서 성능 향상을 확인했습니다.

## 🛠️ Methodology

ISTR은 다음 구성 요소들로 이루어진 엔드-투-엔드 프레임워크입니다.

1. **마스크 임베딩($r_i$)**:
    * 원래 마스크 $M = \{m_i \in \mathbb{R}^{s^2} | i=1, ..., n\}$와 재구성된 마스크 $f(g(M))$ 간의 상호 정보량(mutual information)을 최대화하는 일반화된 목적 함수를 제안합니다.
    * 이는 인코더 $g(\cdot)$와 디코더 $f(\cdot)$를 선형 변환으로 가정할 때, PCA(Principal Component Analysis)의 목적 함수와 동일해지며, 마스크 정보를 저차원 임베딩으로 효과적으로 표현합니다.
    * 이 논문에서는 PCA의 닫힌 형식(closed-form) 솔루션을 사용하여 마스크 인코더와 디코더를 미리 학습하고 고정합니다.
2. **이분 매칭 비용 및 세트 예측 손실**:
    * 예측 $\tilde{Y} = \{\tilde{b}_i, \tilde{c}_i, \tilde{r}_i | i=1, ..., k\}$와 Ground Truth $Y = \{b_i, c_i, m_i | i=1, ..., n\}$ 간의 매칭을 위해 이분 매칭 비용을 정의합니다.
    * **박스 매칭 비용 $C_{\text{box}}$**: L1 손실과 GIoU(Generalized IoU) 손실의 가중 합으로 구성됩니다.
    * **클래스 매칭 비용 $C_{\text{cls}}$**: 예측 클래스 확률에 기반합니다.
    * **마스크 매칭 비용 $C_{\text{mask}}$**: 예측된 마스크 임베딩 $\tilde{r}_{\sigma(i)}$과 Ground Truth 마스크의 인코딩된 임베딩 $g(m_i)$ 간의 L2 정규화된 코사인 유사도(cosine similarity)를 사용합니다.
    * **세트 예측 손실 $L_{\text{set}}$**: 매칭된 예측에 대해 박스 손실 $L_{\text{box}}$ (GIoU), 클래스 손실 $L_{\text{cls}}$ (Focal Loss), 마스크 손실 $L_{\text{mask}}$를 사용합니다. 마스크 손실은 임베딩 레벨 L2 손실 $L_{\text{L2}}(g(m_i), \tilde{r}_{\sigma^*(i)})$과 픽셀 레벨 Dice 손실 $L_{\text{dice}}(m_i, f(\tilde{r}_{\sigma^*(i)}))$의 조합입니다.
3. **인스턴스 분할 트랜스포머(ISTR) 아키텍처**:
    * **백본**: ResNet-FPN을 사용하여 P2~P5 레벨의 특징 피라미드를 추출합니다.
    * **쿼리 박스**: $k$개의 학습 가능한 쿼리 박스 $\tilde{B}_0$는 RoIAlign을 통해 RoI 특징을 추출하는 데 사용됩니다.
    * **이미지 특징 및 위치 임베딩**: FPN 특징 맵을 평균 풀링하여 이미지 특징을 얻고, 학습 가능한 위치 임베딩을 추가합니다.
    * **트랜스포머 인코더 및 동적 어텐션**: 이미지 특징과 위치 임베딩의 합은 self-attention 모듈을 통과하며, RoI 특징 $U_i$에 조건을 부여하는 동적 어텐션(dynamic attention) 모듈을 사용하여 RoI와 이미지 특징을 융합합니다.
    * **예측 헤드**: 클래스 헤드, 박스 헤드, 마스크 헤드, 그리고 미리 학습된 고정 마스크 디코더로 구성됩니다. 마스크 헤드는 마스크 임베딩을 출력하고, 디코더가 이를 마스크로 재구성합니다.
    * **재귀적 정제 전략**: 예측된 박스를 사용하여 쿼리 박스 $\tilde{B}_i$를 N 단계에 걸쳐 재귀적으로 업데이트하여 검출과 분할을 동시에 정제합니다.

## 📊 Results

* **MS COCO 데이터셋 성능**: ResNet50-FPN 백본 사용 시 46.8/38.6 box/mask AP를, ResNet101-FPN 사용 시 48.1/39.9 box/mask AP를 달성했습니다. 이는 Mask R-CNN, CondInst, BlendMask, SOLOv2 등 기존 SOTA 방법들을 능가하는 결과입니다.
* **작은 객체에 대한 우수한 성능**: ResNet101-FPN 기반 ISTR의 AP$_{m}^{\text{S}}$는 SOLOv2보다 5.5포인트 높아 작은 객체 분할에 강점을 보였습니다. 이분 매칭 비용이 작은 객체를 훈련에서 걸러내지 않기 때문으로 분석됩니다.
* **마스크 임베딩의 효과**: 고차원 마스크를 직접 예측하는 것보다 저차원 마스크 임베딩($l=60$ 또는 $l=80$)을 예측하는 것이 마스크 AP에서 더 나은 성능을 보였습니다. 이는 적은 수의 샘플로 고차원 마스크를 효과적으로 학습하기 어렵다는 문제를 해결합니다.
* **비용 함수 및 손실 함수의 중요성**: 마스크 매칭 비용으로 코사인 유사도를 사용하는 것이 가장 큰 성능 향상을 가져왔습니다. 마스크 손실에서는 픽셀 수준의 Dice 손실과 임베딩 수준의 L2 손실을 함께 사용하는 것이 최상의 결과를 도출했습니다.
* **동적 어텐션의 효과**: RoI 및 이미지 특징 융합에 다중 헤드 어텐션(multi-head attention) 대신 동적 어텐션(dynamic attention)을 사용하는 것이 마스크 및 박스 AP에서 크게 향상되었습니다. 단일 투영(single projection)이 객체 간의 관계 학습에 더 효과적임을 시사합니다.
* **재귀적 정제 전략**: 6단계의 재귀적 정제 과정을 통해 마스크와 바운딩 박스가 점진적으로 정교해지는 것을 정량적/정성적 결과로 확인했습니다.

## 🧠 Insights & Discussion

* **엔드-투-엔드 인스턴스 분할의 가능성**: ISTR은 트랜스포머와 저차원 마스크 임베딩을 사용하여 인스턴스 분할에 대한 진정한 엔드-투-엔드 프레임워크를 성공적으로 구현했습니다. 이는 NMS와 같은 복잡한 후처리 없이도 최첨단 성능을 달성할 수 있음을 입증합니다.
* **마스크 임베딩의 효율성**: 고차원 마스크를 직접 다루는 대신 저차원 임베딩을 예측하는 전략은 학습 효율성을 높이고, 매칭 샘플이 적을 때 발생하는 성능 저하 문제를 해결하는 핵심 요소입니다. 비록 PCA로 얻은 마스크 임베딩이 "준최적(suboptimal)"임에도 불구하고 강력한 성능을 보여주었습니다.
* **재귀적 정제와 동시 처리**: 검출과 분할을 동시에 재귀적으로 정제하는 전략은 기존의 순차적인(top-down) 또는 분해적인(bottom-up) 접근 방식과 차별화되며, 두 작업의 상호 이점을 활용하여 전반적인 성능을 향상시킵니다.
* **제한 및 향후 연구**: 현재 ISTR은 PCA 기반의 준최적 마스크 임베딩을 사용하고 있으며, 더 미세한 마스크를 학습할 수 있는 여지가 있습니다. 미래에는 마스크 디코더 학습 방식 또는 마스크 임베딩 생성 방식을 개선하여 더욱 정교한 마스크 분할을 달성할 수 있을 것으로 예상됩니다.

## 📌 TL;DR

ISTR은 NMS와 같은 후처리 없이 엔드-투-엔드 인스턴스 분할을 위한 새로운 트랜스포머 기반 프레임워크를 제안합니다. 이 방법은 고차원 마스크 대신 저차원 마스크 임베딩을 예측하고, 이를 이분 매칭 및 세트 손실에 활용합니다. 또한, 재귀적 정제 전략을 통해 검출과 분할을 동시에 수행하며 예측을 점진적으로 개선합니다. MS COCO 데이터셋에서 SOTA 성능을 달성하여 엔드-투-엔드 인스턴스 분할의 강력한 가능성을 보여주었습니다.
