# Fully Convolutional Instance-aware Semantic Segmentation

Yi Li, Haozhi Qi, Jifeng Dai, Xiangyang Ji, Yichen Wei

## 🧩 Problem to Solve

기존의 FCN(Fully Convolutional Networks)은 픽셀 단위의 의미론적 분할(Semantic Segmentation)에서는 뛰어난 성능을 보이지만, 개별 객체 인스턴스를 감지하고 분할해야 하는 인스턴스 인식 의미론적 분할(Instance-aware Semantic Segmentation) 태스크에는 적합하지 않습니다. FCN은 변환 불변성(translation invariant)을 가지므로, 같은 픽셀이라도 객체 내에서의 상대적 위치에 따라 다른 의미를 가질 수 있는 인스턴스 분할 문제를 다룰 수 없습니다.

기존의 인스턴스 인식 분할 접근 방식들은 주로 다음과 같은 단점을 가집니다:

* **공간 정보 손실**: ROI(Region of Interest) 풀링 단계에서 특징(feature)을 고정된 크기로 warping하거나 resizing하면서 공간적 세부 정보가 손실됩니다.
* **과도한 매개변수화**: 마지막 단계의 FC(Fully Connected) 레이어가 지역 가중치 공유(local weight sharing) 없이 태스크를 과도하게 매개변수화합니다.
* **비효율적인 ROI별 연산**: 각 ROI에 대한 네트워크 연산이 공유되지 않아 많은 수의 ROI 처리 시 속도가 느립니다 (예: MNC [8]는 이미지당 1.4초 소요).
* **제한적인 InstanceFCN**: InstanceFCN [5]은 위치-민감(position-sensitive) 점수 맵을 도입했지만, 객체 카테고리를 인식하지 못하며, 마스크 제안(mask proposal)만을 생성하고, 검출을 위해 별도의 네트워크가 필요하며, 시간이 많이 소요되는 이미지 피라미드 스캔을 사용합니다.

이 논문은 기존 FCN의 장점을 활용하면서 이러한 한계를 극복하는, 효율적이고 정확한 엔드투엔드(end-to-end) 완전 컨볼루션 인스턴스 인식 의미론적 분할 솔루션을 제시하는 것을 목표로 합니다.

## ✨ Key Contributions

* **최초의 완전 컨볼루션 엔드투엔드 솔루션 제안**: 인스턴스 인식 의미론적 분할을 위한 최초의 완전 컨볼루션(fully convolutional) 엔드투엔드 솔루션인 FCIS(Fully Convolutional Instance-aware Semantic Segmentation)를 제안했습니다.
* **위치-민감 내부/외부 점수 맵 도입**: 객체 내 픽셀의 상대적 위치 정보를 인코딩하기 위해 `k \times k` 크기의 위치-민감 점수 맵을 확장하여, `inside` 및 `outside` 점수 맵을 도입했습니다.
* **혁신적인 통합 프레임워크**: 객체 분할 및 검출 서브 태스크를 동시에 공동으로 수행하는 새로운 `joint formulation`을 제안하여, 추가 매개변수 없이 기본 컨볼루션 표현과 점수 맵을 완전히 공유합니다.
* **효율적인 네트워크 구조**: ROI 풀링, 특징 warping/resizing, 또는 FC 레이어 없이 간단하고 빠른 ROI별 연산이 가능하여, 효율성이 크게 향상되었습니다.
* **최고 수준의 성능 달성**: 정확도와 효율성 면에서 모두 최첨단 성능을 달성했으며, COCO 2016 분할(segmentation) 챌린지에서 압도적인 차이로 1위를 차지했습니다. 이전 1위 모델인 MNC [8]보다 약 6배 빠르고, 정확도도 크게 향상되었습니다.

## 📎 Related Works

* **의미론적 이미지 분할 (Semantic Image Segmentation)**: FCN [29] 기반의 접근 방식이 지배적이며, 전역 문맥(global context) [28], 다중 스케일 특징 융합 [4], 디컨볼루션(deconvolution) [31], CRF(Conditional Random Fields) 통합 [3, 43, 37, 24], 약한 지도학습 [6, 23, 19, 20] 등이 연구되었습니다.
* **객체 세그먼트 제안 (Object Segment Proposal)**: MCG [1], Selective Search [41]와 같은 전통적인 방법과 DeepMask [32], SharpMask [33], 그리고 본 연구에 영감을 준 InstanceFCN [5]과 같은 딥러닝 기반 방법이 있습니다.
* **인스턴스 인식 의미론적 분할 (Instance-aware Semantic Segmentation)**: SDS [15], Hypercolumn [16], CFM [7], MNC [8], MultiPathNet [42] 등 대부분의 최신 방법들은 분할과 검출을 별도의 서브 네트워크로 순차적으로 수행합니다. FCN 출력을 클러스터링/그룹화하여 확장하려는 시도 [22, 26]도 있었지만, 복잡한 수작업 후처리에 의존하며 엔드투엔드 방식이 아니었습니다.
* **객체 검출을 위한 FCN (FCNs for Object Detection)**: InstanceFCN [5]의 "위치-민감 점수 맵" 아이디어는 R-FCN [9]에서 객체 검출을 위한 완전 컨볼루션 접근 방식으로 적용되었으나, 인스턴스 분할 태스크는 고려하지 않았습니다.

## 🛠️ Methodology

FCIS는 ResNet [18]을 백본으로 사용하는 엔드투엔드 완전 컨볼루션 네트워크입니다. 주요 방법론은 다음과 같습니다:

1. **위치-민감 점수 맵 매개변수화 (Position-sensitive Score Map Parameterization)**:
    * FCN의 변환 불변성 문제를 해결하기 위해, 객체의 $k \times k$ 셀에 해당하는 $k^2$개의 위치-민감 점수 맵을 사용합니다. 각 점수 맵은 특정 상대적 위치에서 픽셀이 객체 인스턴스에 속할 확률을 나타냅니다. (기본적으로 $k=7$ 사용).
    * 이전 InstanceFCN [5]의 아이디어를 확장하여, `inside` 및 `outside` 점수 맵을 도입하여 객체 분할과 검출을 동시에 수행합니다.
2. **공동 마스크 예측 및 분류 (Joint Mask Prediction and Classification)**:
    * 주어진 ROI에 대해, $k \times k$ 셀에 해당하는 점수 맵을 조립(assembling)하여 픽셀별 점수 맵을 생성합니다.
    * 각 픽셀에 대해 `inside` 및 `outside` 두 가지 점수를 계산합니다. 이 점수는 검출 및 분할 질문에 공동으로 답변합니다:
        * `high inside, low outside`: 검출+, 분할+
        * `low inside, high outside`: 검출+, 분할-
        * `both low`: 검출-, 분할-
    * **검출 (Detection)**: 픽셀별 확률에 대해 `max` 연산을 수행하여 `detection+`와 `detection-`를 구분합니다. ROI의 최종 분류 점수는 모든 픽셀의 검출 가능성을 평균 풀링(average pooling)한 후 소프트맥스(softmax)를 적용하여 얻습니다.
    * **분할 (Segmentation)**: 각 픽셀에 대해 `inside`와 `outside` 점수에 소프트맥스를 적용하여 `segmentation+`와 `segmentation-`를 구분합니다. ROI의 최종 전경(foreground) 마스크는 픽셀별 분할 점수들의 합으로 구성됩니다.
    * `inside`/`outside` 분류기는 분할 및 검출 손실로부터 역전파된 기울기를 모두 받아 공동으로 훈련됩니다.
3. **네트워크 아키텍처 (End-to-End Solution Architecture)**:
    * ResNet [18]의 마지막 FC 레이어를 제거하고 컨볼루션 레이어만 유지하여 2048 채널의 특징 맵을 얻습니다.
    * `1 \times 1` 컨볼루션 레이어를 추가하여 채널 수를 1024로 줄입니다.
    * 유효 특징 스트라이드(effective feature stride)를 32에서 16으로 줄이기 위해 `conv5` 블록의 첫 번째 컨볼루션 레이어 스트라이드를 2에서 1로 변경하고, 필드 오브 뷰(field of view) 유지를 위해 `conv5`의 모든 컨볼루션 레이어에 `dilation`을 2로 설정하는 "hole algorithm" (또는 `à trous` convolution)을 적용합니다.
    * ROI 생성을 위해 `conv4` 레이어 위에 RPN(Region Proposal Network) [34]을 추가합니다.
    * `conv5` 특징 맵에서 `1 \times 1` 컨볼루션 레이어를 통해 $2k^2 \times (C+1)$ ($C$는 객체 카테고리 수, 1은 배경) 점수 맵을 생성합니다.
    * 초기 ROI를 개선하기 위해 `conv5` 특징 맵 위에 `1 \times 1` 컨볼루션 레이어를 가진 바운딩 박스(bbox) 회귀 브랜치도 추가합니다.
4. **추론 (Inference)**:
    * RPN에서 300개의 ROI를 생성하고 bbox 회귀를 통해 정제합니다.
    * 각 ROI에 대해 분류 점수와 전경 마스크를 얻습니다.
    * IoU(Intersection-over-Union) 임계값 0.3의 NMS(Non-Maximum Suppression)를 사용하여 중복되는 ROI를 제거합니다.
    * 마스크 투표(mask voting) [8]를 통해 최종 마스크를 얻습니다. (해당 ROI와 IoU가 0.5보다 높은 모든 ROI의 전경 마스크를 분류 점수로 가중 평균하고 이진화합니다.)
5. **훈련 (Training)**:
    * ROI는 가장 가까운 실제 객체와의 box IoU가 0.5보다 크면 `positive`로 간주합니다.
    * 세 가지 손실 함수를 동일한 가중치로 사용합니다: `C+1` 카테고리에 대한 소프트맥스 검출 손실, 실제 카테고리의 전경 마스크에 대한 소프트맥스 분할 손실, 그리고 bbox 회귀 손실 [12]. 마지막 두 손실은 `positive` ROI에만 적용됩니다.
    * ImageNet [10]으로 사전 학습된 ResNet 모델로 초기화합니다.
    * SGD(Stochastic Gradient Descent) 최적화를 사용하며, 온라인 하드 예제 마이닝(OHEM) [38]을 적용하여 각 미니 배치에서 손실이 높은 128개의 ROI를 선택하여 역전파합니다. RPN과 FCIS는 특징 공유를 위해 공동으로 훈련됩니다.

## 📊 Results

* **PASCAL VOC 2012 검증 세트 (Ablation Study)**:
  * `naïve MNC` (FC 레이어 사용): mAP_r@0.5=59.1%, mAP_r@0.7=36.0%. 이는 기존 MNC [8]보다 낮으며, 인스턴스 인식 분할에서 변환 불변 특성이 중요함을 입증합니다.
  * `InstFCN + R-FCN` (분리된 서브 태스크): mAP_r@0.5=62.7%, mAP_r@0.7=41.5%. FCIS보다 성능이 떨어지고 추론 속도도 느립니다 (1.27초/이미지).
  * `FCIS (translation invariant)` ($k=1$): mAP_r@0.5=52.5%, mAP_r@0.7=38.5%. 위치-민감 점수 맵의 중요성을 강조합니다.
  * `FCIS (separate score maps)` (별도 점수 맵): mAP_r@0.5=63.9%, mAP_r@0.7=49.7%. 공동 공식화(joint formulation)의 효과를 입증합니다.
  * **FCIS (최종 모델)**: mAP_r@0.5=65.7%, mAP_r@0.7=52.1%. 모든 비교 대상보다 우수하며, 엔드투엔드 솔루션의 효과를 검증합니다.
* **COCO test-dev 세트 (MNC [8]와 비교)**:
  * FCIS (ResNet-101, OHEM 없음): mAP_r@[0.5:0.95]=28.8%, mAP_r@0.5=48.7%.
  * MNC (ResNet-101, OHEM 없음): mAP_r@[0.5:0.95]=24.6%, mAP_r@0.5=44.3%.
  * **정확도**: FCIS는 MNC보다 mAP_r@[0.5:0.95]에서 4.2% (상대적으로 17%) 더 높으며, 특히 큰 객체에서 성능 향상이 두드러집니다.
  * **속도**: FCIS는 Nvidia K40 GPU에서 이미지당 0.24초 소요되어 MNC보다 약 6배 빠릅니다. 훈련 속도 또한 약 4배 빠릅니다.
  * **OHEM 적용**: FCIS는 ROI당 연산 비용이 매우 낮아 OHEM을 쉽게 적용할 수 있으며, 이로 인해 mAP_r@[0.5:0.95]가 29.2%로 추가 개선됩니다.
* **다양한 깊이의 네트워크 사용**: ResNet-50 (27.1%)에서 ResNet-101 (29.2%)로 깊이를 늘리면 정확도가 향상되지만, ResNet-152 (29.5%)에서는 포화 상태를 보입니다.
* **COCO 2016 분할 챌린지 1위**:
  * FCIS 기본 모델 (mAP_r@[0.5:0.95]=29.2%)은 이미 2015년 우승작인 MNC+++ [8] (28.4%)보다 높은 성능을 보였습니다.
  * 다중 스케일 테스트 (+2.8%), 수평 뒤집기 (+0.7%), 다중 스케일 훈련 (+0.9%) 등 추가적인 기법을 적용하여 mAP_r@[0.5:0.95]를 33.6%로 끌어올렸습니다.
  * 6개의 네트워크 앙상블을 통해 최종적으로 37.6% mAP_r@[0.5:0.95] 및 59.9% mAP_r@0.5를 달성했습니다. 이는 2위인 G-RMI (33.8%)보다 3.8% (상대적으로 11%) 높은 점수입니다.
* **COCO 객체 검출**: 인스턴스 마스크의 경계 상자를 객체 검출 결과로 사용하여 mAP_b@[0.5:0.95] 39.7%를 달성, COCO 객체 검출 리더보드에서 2위를 기록했습니다.

## 🧠 Insights & Discussion

이 논문은 인스턴스 인식 의미론적 분할 분야에서 중요한 발전을 이루었으며, 특히 FCN의 장점을 최대한 활용하여 정확도와 효율성 모두에서 기존 한계를 극복했습니다.

* **변환 불변성 문제 해결**: FCN의 근본적인 문제였던 변환 불변성을 위치-민감 점수 맵과 `inside`/`outside` 개념을 도입함으로써 성공적으로 해결했습니다. 이는 픽셀이 객체 내에서 차지하는 상대적 위치를 효과적으로 인코딩하여 인스턴스별 특징을 구분할 수 있게 합니다.
* **엔드투엔드 통합의 중요성**: 분할과 검출 태스크를 별도로 처리하던 기존 방식과 달리, 단일 완전 컨볼루션 네트워크 내에서 이 두 태스크를 `joint formulation`으로 통합함으로써, 태스크 간의 강력한 상관관계를 효과적으로 활용하고 불필요한 설계 선택을 제거했습니다. 이는 매개변수를 추가하지 않으면서도 성능을 향상시키는 결과를 가져왔습니다.
* **효율성 극대화**: ROI 풀링에서 발생하는 공간 정보 손실과 FC 레이어의 과도한 매개변수화 문제를 해결함으로써, 네트워크가 공간적 세부 정보를 더 잘 보존하고 계산 비용을 크게 절감할 수 있었습니다. 특히 ROI별 연산이 매우 가볍다는 점은 OHEM과 같은 훈련 전략을 더 효율적으로 적용할 수 있게 하여 추가적인 성능 향상을 이끌어냈습니다.
* **확장성과 적용성**: ResNet과 같은 강력한 백본 네트워크 위에 FCIS를 구축하여 다양한 깊이의 네트워크에서도 효과적으로 작동함을 보여주었으며, 다중 스케일 추론/훈련 및 앙상블과 같은 일반적인 기법들과 결합하여 더욱 높은 성능을 달성할 수 있음을 입증했습니다. 이는 FCIS가 실제 응용 분야에서 매우 유용할 수 있음을 시사합니다.

이 연구는 인스턴스 인식 분할 분야의 패러다임을 한 단계 발전시켰으며, 향후 관련 연구의 중요한 기반을 제공합니다.

## 📌 TL;DR

**문제**: 기존 FCN은 인스턴스 인식 의미론적 분할의 변환 불변성 문제를 해결하지 못하고, 이전 방법들은 ROI 풀링으로 인한 공간 정보 손실과 비효율적인 ROI별 연산으로 인해 느리고 부정확했습니다.

**제안 방법**: FCIS는 인스턴스 인식 의미론적 분할을 위한 최초의 엔드투엔드 완전 컨볼루션 솔루션입니다. 이 방법은 객체 내 픽셀의 상대적 위치를 인코딩하는 *위치-민감 내부/외부 점수 맵*을 도입하고, 객체 검출과 분할을 동시에 수행하는 *새로운 공동 공식화(joint formulation)*를 사용합니다. 이를 통해 특징 공유를 극대화하고, ROI별 연산을 단순화하며, 특징 warping이나 FC 레이어를 사용하지 않아 효율성을 크게 높였습니다.

**주요 결과**: FCIS는 PASCAL VOC 및 COCO 데이터셋에서 최첨단 정확도와 효율성을 달성하며, COCO 2016 분할 챌린지에서 1위를 차지했습니다. 기존의 강력한 모델인 MNC에 비해 약 6배 빠르면서도 훨씬 높은 정확도를 보여주었으며, 특히 큰 객체에서 공간 정보를 더 잘 보존하여 탁월한 성능을 발휘했습니다.
