# Bridging Category-level and Instance-level Semantic Image Segmentation

Zifeng Wu, Chunhua Shen, Anton van den Hengel

## 🧩 Problem to Solve

본 논문은 이미지의 인스턴스 수준(instance-level) 의미론적 분할 문제를 다룹니다. 기존의 지배적인 접근 방식은 먼저 객체의 바운딩 박스를 예측한 다음 해당 박스 내에서 분할을 수행하는 "탐지 후 분할(detect-then-segment)" 방식입니다. 이 논문은 이와 다른 파이프라인을 제안합니다. 즉, 범주 수준(category-level) 의미론적 분할의 강점을 활용하여 그 위에 인스턴스 수준 분할을 구축하는 새로운 접근 방식을 개발하는 것이 주요 목표입니다. 이는 의미론적 범주 마스크의 각 픽셀에 대해 해당 인스턴스의 바운딩 박스를 직접 회귀 예측하여 인스턴스를 추출하는 방식입니다.

## ✨ Key Contributions

* **새로운 인스턴스 분할 접근 방식 제안**: 의미론적 스코어 맵을 Hough-like 맵으로 변환하여 다른 의미론적 객체 인스턴스를 쉽게 탐지할 수 있는 간단하면서도 효과적인 방법을 제안합니다.
* **온라인 부트스트래핑 학습 방법 도입**: 학습 과정에서 온라인 부트스트래핑 방법을 제안하며, 이는 의미론적 범주 분할과 인스턴스 수준 분할 모두에서 우수한 성능을 달성하는 데 매우 중요함을 보여줍니다.
* **FCRN(Fully Convolutional Residual Network) 광범위한 평가**: 네트워크 깊이, 특징 맵 해상도, FoV(Field-of-View) 크기를 포함하여 FCRN의 다양한 변형을 광범위하게 평가하여 최적의 구성을 찾아냅니다.
* **최첨단 의미론적 분할 성능 달성**: 잔여 블록에 드롭아웃(dropout), 최상위 선형 분류기를 다층 비선형 분류기로 대체, 다중 뷰 테스팅 기법을 적용하여 PASCAL VOC 2012 데이터셋에서 현재 최고인 79.1%의 평균 IoU(Intersection-over-Union) 점수를 달성합니다.
* **최첨단 인스턴스 분할 성능 달성**: PASCAL VOC 2012 데이터셋에서 이전 최고 성능과 동등하거나 더 나은 인스턴스 수준 분할 결과를 달성합니다. 특히 겹침 0.7에서의 평균 영역 AP($mAP_{0.7}^r$)를 41.5%에서 46.6%로 5.1% 크게 향상시켰습니다.

## 📎 Related Works

* **매우 깊은 컨볼루션 네트워크**: AlexNet [14], VGGNet [5], GoogLeNet [15]을 거쳐 ResNet [6, 7]이 더 깊은 네트워크와 더 나은 특징 학습의 중요성을 보여주었습니다.
* **의미론적 분할을 위한 완전 컨볼루션 네트워크 (FCN)**: Long et al. [1]이 FCN 프레임워크를 제안했으며, Chen et al. [2]은 atrous 알고리즘(또는 hole algorithm)과 dense CRF [17]를 통해 성능을 향상시켰습니다. Zheng et al. [18]은 CRF를 RNN으로 시뮬레이션했으며, Lin et al. [3]은 CRF를 컨볼루션 레이어와 함께 공동으로 훈련하여 문맥 정보를 활용했습니다.
* **바운딩 박스 탐지 기반 인스턴스 분할**: 대부분의 최신 인스턴스 분할 방법 [8, 9, 10]은 Fast R-CNN [11]과 같은 바운딩 박스 탐지 방법을 기반으로 하며, 객체를 탐지한 후 해당 박스 내에서 마스크를 생성합니다.
* **깊은 컨볼루션 네트워크 학습을 위한 온라인 부트스트래핑**: Loshchilov and Hutter [20]는 이미지 분류에서 미니배치 선택을 연구했고, Shrivastava et al. [21]은 객체 탐지에서 어려운 RoI(Region-of-Interest)를 선택했습니다. 본 논문은 픽셀 샘플에 대한 온라인 부트스트래핑을 제안한 첫 번째 연구라고 주장합니다.

## 🛠️ Methodology

본 논문은 의미론적 범주 분할 모델 위에 인스턴스 수준 분할을 구축하는 방법을 제안하며, 핵심 구성 요소로 온라인 부트스트래핑과 FCRN(Fully Convolutional Residual Network)을 사용합니다.

### 1. 인스턴스 분할 파이프라인

제안된 접근 방식의 파이프라인은 다음과 같습니다 (그림 1 참조):

* **1단계**: 의미론적 범주 분할을 통해 **범주별 스코어 맵**을 계산합니다.
* **2단계**: 딥 완전 컨볼루션 회귀 네트워크를 사용하여 **범주별 변환 맵**을 계산합니다. 이 네트워크는 각 픽셀에서 해당 픽셀이 속한 인스턴스의 바운딩 박스 중심까지의 수직/수평 오프셋과 인스턴스의 높이/너비를 예측합니다.
* **3단계**: 획득한 변환 맵을 해당 스코어 맵에 적용합니다. 배경 픽셀은 무시하고, 상위 n개의 가장 높은 점수를 가진 픽셀을 사용하여 인스턴스 Recall rate을 향상시킵니다.
* **4단계**: 변환된 맵에 비최대 억제(NMS)를 적용하여 지역 최대값(인스턴스 가설)을 탐색합니다.
* **5단계**: 억제된 모든 픽셀을 추적하여 각 인스턴스 가설에 대한 마스크를 복구합니다.
* **6단계**: 영역 기반 NMS [8]를 통해 최종 인스턴스 분할 결과를 생성합니다.
* **학습**: 의미론적 분할 네트워크는 로지스틱 회귀 손실로, 지역화 네트워크는 smooth $L_1$ 손실로 개별적으로 학습됩니다. 다른 크기의 인스턴스 기여도를 균형 있게 맞추기 위해 픽셀에 손실 가중치를 부여합니다.

### 2. 온라인 부트스트래핑(Online Bootstrapping)

네트워크가 학습 중 어려운 픽셀에 집중하도록 하는 방법입니다.

* **의미론적 범주 분할**:
  * 손실 함수는 다음과 같이 정의됩니다:
        $$
        \mathcal{L} = - \frac{1}{\sum_{i} \sum_{j} \mathbf{1}\{y_i=j \text{ and } p_{ij} < t\}} \left( \sum_{i} \sum_{j} \mathbf{1}\{y_i=j \text{ and } p_{ij} < t\} \log p_{ij} \right)
        $$
  * 여기서 $\mathbf{1}\{\cdot\}$은 조건이 참일 때 1, 그렇지 않을 때 0입니다. $t \in (0,1]$은 임계값이며, 현재 모델에 너무 쉬운 픽셀(손실이 $t$ 미만)은 학습에서 제외됩니다. $t$는 미니배치 성능에 따라 동적으로 조절되어 충분한 수의 픽셀이 유지되도록 합니다.
* **지역화 네트워크**: 예측된 바운딩 박스와 Ground-Truth 바운딩 박스 간의 IoU(Intersection-over-Union) 점수를 임계값으로 사용하여 '쉬운' 픽셀을 정의하고 제외합니다.
* **효과**: 픽셀 레이블링 작업에서 흔한 문제인 편향된 학습 데이터(예: 배경 픽셀이 객체 픽셀보다 많은 경우)의 균형을 자동으로 맞춰줍니다.

### 3. 완전 컨볼루션 잔여 네트워크 (FCRN)

ResNet [6]을 기반으로 의미론적 분할에 최적화된 네트워크를 구축합니다.

* ResNet을 기반으로 FCRN을 초기화하고, 선형 분류 레이어를 공간 위치별 예측을 위한 컨볼루션 레이어로 대체합니다.
* **7x7 풀링 레이어 제거**: FoV를 넓힐 수 있지만, 인접 픽셀의 특징을 평활화하여 픽셀별 구별이 필요한 작업에는 부적합할 수 있으므로 제거합니다.
* **Atrous (Hole) Algorithm 활용**: 특징 맵의 해상도가 너무 낮은 문제를 해결하기 위해 다운샘플링 부분을 건너뛰고 후속 컨볼루션 커널의 팽창(dilation)을 증가시킵니다. 이는 가중치를 변경하지 않고도 특징 맵의 해상도를 높이고, 파라미터 수를 폭발시키지 않고도 넓은 FoV를 구현할 수 있게 합니다.

## 📊 Results

* **의미론적 범주 분할**:
  * **PASCAL VOC 2012**: `test` 세트에서 79.1%의 평균 IoU(mIoU)를 달성하여 이전 최고 기록 75.3%를 3.8% 초과하며 최첨단 성능을 기록했습니다. 20개 객체 범주 중 18개에서 1위를 차지했습니다. 네트워크 깊이(101-레이어가 최적), 특징 맵 해상도, FoV(392가 최적)를 높이는 것이 성능 향상에 기여했습니다.
  * **Cityscapes**: `val` 세트에서 74.6%의 mIoU를 달성하여 이전 최고 기록 68.6% 대비 상당한 향상을 보였습니다.
  * **PASCAL-Context**: `val` 세트에서 44.5%의 mIoU를 달성하여 이전 최고 기록 43.3%보다 우수한 성능을 보였습니다.

* **인스턴스 수준 분할**:
  * **PASCAL VOC 2012**: `val` 세트에서 이전 최고 성능과 동등하거나 더 나은 결과를 달성했습니다. 특히, 겹침 0.7에서의 평균 영역 AP($mAP_{0.7}^r$)를 41.5%에서 46.6%로 5.1% 크게 향상시켰습니다.
  * 의미론적 분할 네트워크를 COCO 데이터셋으로 사전 학습 시 성능이 2.0% 추가 향상되었으며, Ground-Truth 마스크로 스코어 맵을 생성했을 때는 $mAP_{0.5}^r$ 73.0%, $mAP_{0.7}^r$ 60.6%로 크게 증가하여 의미론적 분할 정확도 개선 시 잠재력을 입증했습니다.

* **온라인 부트스트래핑의 중요성**:
  * 의미론적 분할에서 PASCAL VOC 2012에서 mIoU를 3.1% 향상시켰고, Cityscapes에서는 데이터 편향 문제가 더 심각하여 mIoU를 3.1% 크게 향상시켰습니다.
  * 훈련 데이터에 덜 자주 나타나는 범주(예: PASCAL VOC의 '소', '말', Cityscapes의 '신호등', '기차')에 대해 성능을 명확하게 향상시켰습니다.
  * 지역화 네트워크 성능에도 뚜렷한 기여를 했습니다.

## 🧠 Insights & Discussion

* **의미**: 본 논문은 범주 수준 의미론적 분할 모델의 강점을 활용하여 인스턴스 수준 분할을 수행하는 새로운 파이프라인의 엄청난 잠재력을 보여줍니다. 이는 기존의 "탐지 후 분할" 방식과는 근본적으로 다른 접근 방식이며, 고성능 의미론적 분할 모델을 효과적으로 활용합니다.
* **의미론적 분할의 중요성**: 실험 결과는 의미론적 범주 수준 분할의 정확도가 향상될수록 제안된 인스턴스 수준 분할 방법의 성능이 크게 개선될 수 있음을 명확하게 보여줍니다. 이는 두 작업 간의 강력한 시너지 효과를 시사합니다.
* **온라인 부트스트래핑의 영향**: 온라인 부트스트래핑은 네트워크가 "어려운" 픽셀에 집중하도록 함으로써 학습 효율성을 높이고, 데이터셋의 클래스 불균형 문제를 자동으로 완화하는 데 중요한 역할을 합니다. 특히 드물게 나타나는 카테고리의 성능을 크게 개선했습니다.
* **한계**: '자전거'나 '의자'와 같이 다양성이 크거나 가려진 상황이 많고, 정교한 주석을 요구하는 일부 어려운 범주에서는 여전히 개선의 여지가 있음을 보여줍니다. 이는 해당 범주에 대한 더 많은 훈련 데이터가 필요함을 시사합니다. 또한, COCO 데이터셋으로 사전 학습했을 때 PASCAL VOC에서의 제한적인 개선은 도메인 적응에 대한 추가 연구의 필요성을 제기합니다.

## 📌 TL;DR

본 논문은 범주 수준 의미론적 분할을 기반으로 하는 새로운 인스턴스 수준 이미지 분할 방법을 제안합니다. 이 방법은 각 픽셀에 대해 해당 인스턴스의 바운딩 박스를 회귀 예측하여 의미론적 스코어 맵을 Hough-like 맵으로 변환한 다음, NMS를 통해 인스턴스를 추출합니다. 특히, 학습 중 어려운 픽셀에 집중하는 온라인 부트스트래핑 방식을 도입하여 PASCAL VOC 2012 데이터셋에서 의미론적 분할(79.1% mIoU)과 인스턴스 분할($mAP_{0.7}^r$ 46.6%) 모두에서 최첨단 성능을 달성했습니다. 이는 의미론적 분할의 강점을 인스턴스 분할에 효과적으로 연결하는 새로운 패러다임을 제시합니다.
