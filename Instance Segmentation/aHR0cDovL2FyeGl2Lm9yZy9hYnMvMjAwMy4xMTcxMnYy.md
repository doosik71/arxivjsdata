# Mask Encoding for Single Shot Instance Segmentation

Rufeng Zhang, Zhi Tian, Chunhua Shen, Mingyu You, Youliang Yan

## 🧩 Problem to Solve

- 인스턴스 분할은 Mask R-CNN과 같은 투-스테이지(two-stage) 방법이 지배적이지만, 이는 이미지 내 인스턴스 수에 따라 런타임이 제약되어 효율성이 떨어집니다.
- 원-스테이지(one-stage) 인스턴스 분할 방법들은 마스크를 효과적으로 표현하기 어렵다는 문제로 인해 Mask R-CNN 수준의 정확도를 달성하기 어려웠습니다.
- 기존의 윤곽선 기반(contour-based) 원-스테이지 방법(예: ESE-Seg, PolarMask)은 단일 윤곽선으로 인스턴스를 표현하므로 "텅 빈 감소(hollow decay)"와 같은 체계적인 아티팩트(artifacts)를 보였습니다.
- 목표는 효율적이면서도 마스크를 간결하게 표현하여 정확도를 높일 수 있는 간단한 단일 샷 인스턴스 분할 프레임워크를 개발하는 것입니다.

## ✨ Key Contributions

- **컴팩트한 마스크 인코딩 제안:** 2차원 인스턴스 마스크를 압축된 고정 차원 표현 벡터로 인코딩하는 새로운 방식을 제안합니다. 이 벡터는 원본 마스크의 중복성을 활용하며, 효율적인 재구성을 가능하게 합니다.
  - 인코딩은 PCA(Principal Component Analysis), 희소 코딩(sparse coding), 오토인코더(autoencoders)와 같은 딕셔너리 학습(dictionary learning) 방법을 통해 수행할 수 있으며, 간단한 PCA만으로도 충분함을 보여줍니다.
- **MEInst 프레임워크 도입:** 마스크 인코딩 기반 인스턴스 분할(MEInst)이라는 단일 샷 인스턴스 분할 프레임워크를 소개합니다. 이는 FCOS [29]에 마스크 계수 회귀(mask coefficient regression)를 위한 마스크 브랜치를 추가하여 구현됩니다.
  - 제안된 마스크 인코딩은 객체 탐지기의 메커니즘과 완전히 독립적이어서 다른 탐지기에도 쉽게 통합될 수 있습니다.
- **경쟁력 있는 성능 달성:** 간단하고 유연한 원-스테이지 인스턴스 분할 방법으로, MS-COCO test-dev에서 38.2%의 마스크 AP를 달성하여 정확도와 속도 사이의 균형을 이룹니다.

## 📎 Related Works

- **투-스테이지 인스턴스 분할:**
  - Mask R-CNN [13]: 객체 탐지 후 각 프로포절(proposal) 내에서 픽셀 분류를 수행하는 투-스테이지 파이프라인의 선구자입니다.
  - Mask R-CNN 이후의 발전: PANet [22] (경로 통합), Mask Scoring R-CNN [15] (마스크 품질 예측).
- **원-스테이지 인스턴스 분할:**
  - InstanceCut [16]: 인스턴스-불가지론적(instance-agnostic) 분할 및 인스턴스-특정 경계(instance-specific boundaries)라는 두 가지 병렬 서브 태스크로 접근합니다.
  - TensorMask [7]: 4D 텐서로 마스크를 표현합니다.
  - YOLACT [3], BlendMask [4]: 실시간 속도를 목표로 글로벌 프로토타입(prototypes)과 선형 계수를 사용합니다.
  - PolarMask [32], ESE-Seg [33]: 윤곽선 계수 또는 극좌표 표현을 통해 마스크를 직접 예측하는 파라메트릭(parametric) 방식입니다.
  - SOLO [30] 및 SOLOv2 [31]: FCN-유사(FCN-like) 프레임워크입니다.

## 🛠️ Methodology

1. **네트워크 아키텍처:**
    - FCOS [29] 탐지기를 기반으로 백본(Backbone), 특징 피라미드 네트워크(FPN), 그리고 분류(classification), 바운딩 박스 회귀(box regression), 중심성(center-ness)을 위한 두 개의 태스크 헤드(task-specific heads)를 포함합니다.
    - 여기에 인코딩된 마스크 계수를 예측하는 **병렬 마스크 회귀 브랜치(mask regression branch)**를 추가합니다.
    - 성능 향상을 위해 프레임워크의 일부를 재설계했습니다(예: DCN(Deformable Convolutional Networks) 활용).
2. **마스크 인코딩:**
    - **컴팩트 표현:**
        - GT(Ground Truth) 마스크 $M' \in \mathbb{R}^{H \times W}$ (이진, 클래스 불가지론적)를 벡터 $u \in \mathbb{R}^{HW}$로 평탄화(flatten)합니다.
        - PCA를 사용하여 $u$를 압축된 고정 차원 표현 벡터 $v \in \mathbb{R}^N$ ($N \ll HW$)로 변환합니다: $v = Tu$.
        - $v$는 재구성 행렬 $W$를 통해 원래 마스크 $\tilde{u} = Wv$로 복구될 수 있습니다.
        - 행렬 $T$와 $W$는 훈련 세트에서 재구성 오차 $\sum_u \|u - WTu\|^2$를 최소화하여 학습되며, 이 과정은 오프라인으로 수행됩니다.
    - **마스크 재구성:**
        - NMS(Non-Maximum Suppression) 후, 예측된 계수 벡터 $\hat{v}$를 사용하여 2D 마스크 $M'$를 효율적으로 재구성합니다($M' = W\hat{v}$). 이 행렬 곱셈은 계산 비용이 미미합니다.
    - **손실 함수:**
        - 마스크 손실 $L_{mask} = \frac{1_{obj}}{N} \sum_i d_{mask}(\hat{y}_i, y_i)$로 정의되며, $l_2$ 손실 함수를 $d_{mask}$로 사용합니다.
        - 전체 손실은 $L = \lambda_{det} \cdot L_{det} + \lambda_{mask} \cdot L_{mask}$이며, $L_{det}$는 분류, 바운딩 박스 회귀, 중심성 손실을 포함합니다. 실험에서는 $\lambda_{det} = \lambda_{mask} = 1$로 설정합니다.
3. **박스와 마스크 간의 상관관계:**
    - 객체 탐지기의 품질이 인스턴스 분할 성능에 미치는 영향을 분석했습니다.
    - FCOS가 Mask R-CNN보다 전반적인 탐지 성능($AP_{bb}$)이 우수하더라도, 더 많은 오탐지(false-positive) 박스와 작은 유효 수용장(Effective Receptive Field, ERF)으로 인해 마스크 AP가 낮을 수 있음을 발견했습니다.
    - 이 문제를 해결하기 위해, 다중 헤드(multi-head) 브랜치의 마지막 합성곱 계층에 **DCN(Deformable Convolution Networks)** [36]을 적용하여 ERF를 확장하고 중요한 영역에 집중하도록 하여 오탐지 박스를 줄입니다.

## 📊 Results

- **MS-COCO val2017 벤치마크:**
  - MEInst는 단일 모델(ResNeXt-101-FPN 백본) 및 단일 스케일 테스트에서 **36.9%의 마스크 AP**를 달성했습니다.
  - 기존 윤곽선 기반 방법인 ESE-Seg [33]보다 $AP_{50}$에서 11.8%, $AP_{75}$에서 16.5% 향상되는 등 큰 폭의 성능 개선을 보였습니다.
  - PolarMask [32]와 유사한 계산 복잡도로 더 높은 정확도를 달성했습니다.
  - **어블레이션 연구(Ablation Study):**
    - **인코딩 표현 차원:** 차원이 증가함에 따라 성능이 꾸준히 향상되다가 $N=60$에서 포화 상태에 도달합니다.
    - **마스크 인코딩의 효과:** 명시적 마스크 인코딩은 암묵적 인코딩 또는 고차원 마스크 직접 출력보다 최적화에 유리하며 더 나은 성능을 보였습니다.
    - **손실 함수:** $l_2$ 손실이 smooth-$l_1$, $l_1$, 코사인 유사도 손실 중에서 가장 좋은 성능을 나타냈습니다.
    - **넓은 수용장(Large Receptive Field):** 대형 커널(Large Kernel, LK)과 DCN 사용은 AP를 유의미하게 향상시켰습니다(특히 DCN은 1.5% AP 상승).
    - **마스크 학습의 객체 탐지 개선 효과:** 마스크 예측을 함께 학습하면 FCOS의 바운딩 박스 $AP_{bb}$가 0.8% 향상되었습니다.
- **MS-COCO test-dev:**
  - 최종 모델(MEInst ResNeXt-101-FPN-DCN 36X)은 **38.2% 마스크 AP**를 달성하여 원-스테이지 방법 중 최고 수준이며, 특히 작은 객체에 대해서는 Mask R-CNN보다 우수했습니다.

## 🧠 Insights & Discussion

- **장점:**
  - **효율성:** 원-스테이지 프레임워크로서 인스턴스 수에 관계없이 안정적인 추론 속도를 제공합니다.
  - **컴팩트한 표현:** 복잡한 2D 마스크 예측을 고정 차원 벡터 회귀 문제로 단순화하여, 기존 원-스테이지 탐지기에 쉽게 통합될 수 있습니다.
  - **"분리된(Disjointed)" 객체 처리:** 윤곽선 기반 방법의 "hollow decay" 문제를 겪지 않고, 복잡하거나 분리된 형상의 객체를 더 잘 표현하고 처리할 수 있습니다.
  - **작은 객체에 대한 우위:** 작은 객체에 대해서는 Mask R-CNN보다 우수한 성능을 보입니다. 이는 Mask R-CNN의 픽셀 단위 마스크 예측 헤드가 작은 객체에 어려움을 겪는 반면, MEInst의 단일 특징 벡터가 효과적으로 작동하기 때문으로 분석됩니다.
  - **일반성:** FCOS, RetinaNet, YOLO와 같은 대부분의 원-스테이지 탐지 프레임워크와 호환됩니다.
- **한계:**
  - **큰 객체에 대한 성능:** 매우 큰 객체의 경우, 압축된 표현 벡터가 마스크의 모든 미세한 세부 사항을 담기 어려울 수 있어 Mask R-CNN보다 성능이 떨어질 수 있습니다. 향후 연구에서는 디테일을 인코딩하기 위한 추가 모듈을 탐색할 계획입니다.
- **의의:** MEInst는 마스크 표현의 난제를 효과적으로 해결함으로써, 간단하고 유연한 원-스테이지 인스턴스 분할 방법이 투-스테이지 방법과 경쟁할 만한 정확도를 달성할 수 있음을 입증했습니다. 또한 다중 작업 학습(mask prediction이 탐지 성능 향상)의 이점도 보여주었습니다.

## 📌 TL;DR

MEInst는 기존 투-스테이지 인스턴스 분할 방법의 비효율성과 원-스테이지 방법의 마스크 표현 한계를 극복하기 위해 제안된 단일 샷 인스턴스 분할 프레임워크입니다. 이 모델은 2D 인스턴스 마스크를 PCA를 통해 압축된 고정 차원 벡터로 인코딩하고, 이를 FCOS 기반의 객체 탐지기에 병렬 마스크 회귀 브랜치로 추가하여 마스크 예측을 회귀 문제로 처리합니다. 이를 통해 윤곽선 기반 방법의 "텅 빈 감소" 문제를 해결하고 복잡한 객체 형상을 더 잘 표현하며, MS-COCO test-dev에서 38.2% 마스크 AP를 달성하여 높은 정확도와 실시간에 가까운 속도를 균형 있게 제공합니다. 특히 작은 객체 분할에서 Mask R-CNN보다 우수한 성능을 보이며, 원-스테이지 방법의 경쟁력을 크게 향상시켰습니다.
