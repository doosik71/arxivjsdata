# Pixelwise Instance Segmentation with a Dynamically Instantiated Network

Anurag Arnab, Philip H.S Torr

## 🧩 Problem to Solve

기존의 이미지 이해 작업들은 각각의 한계를 가집니다. **의미론적 분할(Semantic Segmentation)**은 모든 픽셀에 객체 클래스를 할당하지만, 동일 객체의 다른 **인스턴스**들을 구분하지 못합니다. 반면 **객체 감지(Object Detection)**는 객체 인스턴스를 구분하지만, 거친 경계 상자(bounding box) 수준에서만 작동합니다. **인스턴스 분할(Instance Segmentation)**은 이 두 작업의 교차점에 위치하며, 픽셀 단위로 각 객체 인스턴스를 정확하게 지역화하는 것을 목표로 합니다.

기존 인스턴스 분할 접근 방식들은 주로 객체 감지 파이프라인을 수정하여 분할을 생성합니다. 하지만 이러한 방식들은 다음과 같은 문제점을 안고 있습니다:

* 초기 제안(proposal)의 품질에 의존하여, 오검출(false detections)이나 부정확한 경계 상자 위치 지정 오류로부터 복구하기 어렵습니다.
* 전체 이미지를 고려하지 않고 독립적인 제안들을 처리하므로, 객체 간의 가려짐(occlusions)을 제대로 다루지 못합니다.
* 종종 픽셀이 여러 인스턴스에 속할 수 있는 모호한 상황을 초래하거나, 복잡한 후처리 과정이 필요합니다.

## ✨ Key Contributions

* **엔드투엔드(End-to-End) 인스턴스 분할 시스템 제안**: 픽셀별 객체 클래스 및 인스턴스 ID 레이블을 모두 할당하는 분할 맵을 생성합니다.
* **시맨틱 분할 기반 접근 방식**: 초기 시맨틱 분할 모듈의 출력을 활용하여 인스턴스 서브네트워크로 전달하는 독특한 아키텍처를 가집니다. 이는 대부분의 객체 감지 기반 접근 방식과 대조됩니다.
* **동적 인스턴스 서브네트워크**: 이미지당 가변적인 수의 인스턴스를 생성하도록 동적으로 인스턴스화됩니다. 객체 감지기(object detector) 출력과 조건부 랜덤 필드(CRF)를 결합하여 인스턴스를 예측합니다.
* **후처리 불필요**: 복잡한 후처리 과정 없이 인스턴스 분할 맵을 직접 출력합니다.
* **전역적 이미지 추론**: 전체 이미지를 포괄적으로 고려하여 예측하므로, 한 픽셀이 여러 인스턴스에 속할 수 있는 문제를 방지하고 객체 간 가려짐을 더 잘 처리합니다.
* **정확도 향상**: 높은 $AP_r$ (Average Precision over regions) 임계값에서 상당한 성능 향상을 보여, 더 정밀하고 정확한 분할을 달성합니다.
* **시맨틱 분할 성능 향상**: 인스턴스 분할을 위해 파인튜닝하는 과정에서 시맨틱 분할 작업의 성능도 향상됨을 입증했습니다.
* **견고성**: 오탐지(false positive detections) 및 부정확하게 지역화된 경계 상자에 대해 강건합니다.

## 📎 Related Works

* **초기 인스턴스 분할**: Winn과 Shotton [51]의 픽셀 단위 분류기와 비대칭 쌍체 포텐셜(pairwise potential)을 사용한 CRF, 그리고 [54]의 DPM 기반 깊이 순서 지정 방식.
* **객체 감지 기반 접근 방식**: Hariharan 등 [19]의 **SDS (Simultaneous Detection and Segmentation)**는 R-CNN 파이프라인을 기반으로 하며, 경계 상자를 분할로 정제합니다. [20, 8, 30] 등 다수의 후속 연구가 이 파이프라인을 확장했습니다. 하지만 초기 제안의 품질에 의존하고 여러 모듈과 후처리 단계를 포함합니다.
* **엔드투엔드 감지 및 분할**: Dai 등 [12]는 Faster-RCNN 프레임워크를 확장하여 박스 제안을 생성하고 마스크를 분류하는 엔드투엔드 네트워크를 제안했습니다. Liu 등 [37]도 유사한 접근 방식을 따랐습니다.
* **객체 감지기 없는 접근 방식**: Zhang 등 [57, 58]은 이미지 내 각 픽셀의 깊이 순서를 예측하여 자동차 인스턴스를 분할했지만, MRF 기반으로 최대 인스턴스 수를 가정합니다. [45]는 RNN을 사용하여 가변적인 수의 인스턴스를 처리했지만 단일 객체 클래스에만 적용됩니다. Liang 등 [33]은 제안 없는(proposal-free) 방식으로 시맨틱 분할 네트워크를 기반으로 인스턴스 경계 상자를 예측했습니다.
* **CRF를 이용한 시맨틱 분할 및 객체 감지 결합**: Arnab 등 [3]은 초기 시맨틱 분할과 객체 감지기 출력을 CRF로 결합했지만, 엔드투엔드가 아니었고 경계 상자 오류 및 가려짐에 대한 복원력이 떨어졌습니다.

본 논문은 [3]과 유사하게 초기 시맨틱 분할 서브네트워크와 객체 감지기 출력을 사용하지만, **시맨틱 및 인스턴스 분할 성능을 모두 향상시키는 최초의 엔드투엔드 학습 방식**이며, 감지기 오류 및 가려짐을 더 잘 처리하고, 후처리 없이 인스턴스 분할 맵을 생성하며, 가변적인 수의 인스턴스를 처리할 수 있다는 점에서 차별화됩니다.

## 🛠️ Methodology

본 논문의 네트워크는 초기 **시맨틱 분할 서브네트워크**와 그 출력을 받아 인스턴스를 추론하는 **인스턴스 분할 서브네트워크**로 구성되며, 전체 파이프라인은 엔드투엔드로 학습됩니다.

### 1. 시맨틱 분할 서브네트워크

* **아키텍처**: FCN8s [38] (VGG [47] 기반)를 사용합니다.
* **CRF 통합**: 이 모듈의 마지막 레이어로 **밀집 연결 쌍체 포텐셜(densely-connected pairwise potentials)**을 포함하는 조건부 랜덤 필드(CRF)의 평균 필드(mean field) 추론을 포함합니다 [26, 60].
* **고차 감지 포텐셜**: [2]에서 설명된 고차 감지 포텐셜을 추가하여 시맨틱 분할 품질을 향상시키고, 객체 감지 정보와의 일관성을 장려하며, 감지 점수를 재조정합니다.
* **출력**: 픽셀 $i$가 레이블 $l \in L$을 가질 확률을 나타내는 텐서 $Q_{i}(l)$를 출력합니다.

### 2. 인스턴스 분할 서브네트워크

* **입력**: 시맨틱 분할 예측 $Q$와 $D$개의 객체 감지 결과 (각 감지는 $(l_k, s_k, B_k)$ 형태: 클래스, 신뢰도, 경계 상자 픽셀 집합)를 입력으로 받습니다. $D$는 이미지마다 가변적입니다.
* **인스턴스 CRF**: 이미지 내 각 픽셀 $i$에 대한 다항 랜덤 변수 $V_i$를 정의하여, 픽셀을 특정 객체 감지 또는 배경 레이블에 할당합니다.
  * **에너지 함수**:
    $$ E(V=v) = \sum_i U(v_i) + \sum_{i \lt j} P(v_i,v_j) $$
  * **단항 에너지 $U(v_i)$ (Eq. 2)**: 세 가지 항의 가중 합으로 구성되며, 가중치 $w_1, w_2, w_3$는 역전파를 통해 학습됩니다.
    * **Box Term ($\psi_{Box}$, Eq. 3)**: 픽셀이 감지의 경계 상자 $B_k$ 내에 있을 때, 해당 픽셀이 감지 $k$에 할당되도록 장려합니다. 픽셀의 시맨틱 클래스 확률 $Q_i(l_k)$와 감지 점수 $s_k$에 비례합니다.
        $$ \psi_{Box}(V_i=k) = \begin{cases} Q_i(l_k)s_k & \text{if } i \in B_k \\ 0 & \text{otherwise} \end{cases} $$
    * **Global Term ($\psi_{Global}$, Eq. 4)**: 경계 상자에 의존하지 않고, 픽셀 $i$의 시맨틱 분할 예측 $Q_i$만을 사용하여, 감지된 객체 클래스에 대한 시맨틱 분할 신뢰도에 비례합니다. 경계 상자가 객체 전체를 덮지 못하는 경우를 보완합니다.
        $$ \psi_{Global}(V_i=k) = Q_i(l_k) $$
    * **Shape Term ($\psi_{Shape}$, Eq. 5, 6)**: 객체 모양 사전 지식을 활용하여 가려짐을 해결합니다. 미리 정의된 모양 템플릿 $T$ 중 해당 경계 상자 내에서 시맨틱 분할 예측과 가장 잘 일치하는 템플릿 $t^*$를 선택하고, 이를 유나리 포텐셜에 반영합니다. 이는 완전히 미분 가능(differentiable)한 방식으로 구현됩니다.
  * **쌍체 에너지 $P(v_i, v_j)$**: 밀집 연결 가우시안 포텐셜 [26]로 구성되어, 유사한 외형과 가까운 공간에 있는 픽셀이 동일한 객체 인스턴스에 속하도록 장려합니다.
* **추론**: 평균 필드(mean field) 추론을 사용하여 에너지 함수를 근사적으로 최소화하며, 이는 순환 신경망(RNN)으로 언롤링되어 엔드투엔드 학습이 가능합니다 [60].
* **동적 인스턴스화**: 이미지별로 가변적인 수의 인스턴스를 처리하기 위해 CRF의 레이블 수가 동적으로 인스턴스화됩니다. 가중치는 클래스에 특정되지 않습니다.

### 3. 손실 함수 (Loss Function)

* 인스턴스 레이블링의 순열(permutation) 불변성을 다루기 위해, 예측 $P$와 지면 진실(ground truth) $G$ 사이의 IoU (Intersection over Union)를 최대화하는 방식으로 지면 진실 $G^*$를 "매칭"하여 사용합니다 (Eq. 7).
$$ G^* = \arg \max_{m \in M} \text{IoU}(m, P) $$
* 매칭된 $G^*$와 $P$에 대해 일반적인 **교차 엔트로피 손실 함수**를 적용합니다. 이 매칭 과정은 최대 가중 이분 매칭(maximum-weight bipartite matching) 문제로 효율적으로 해결될 수 있습니다.

### 4. 네트워크 학습

* **사전 학습**: FCN8s와 CRF로 구성된 시맨틱 분할 네트워크를 표준 교차 엔트로피 손실로 사전 학습합니다.
* **파인튜닝**: 사전 학습된 네트워크에 인스턴스 분할 서브네트워크를 추가하고, 섹션 3.4의 인스턴스 분할 손실 함수를 사용하여 엔드투엔드로 파인튜닝합니다.
* **학습 설정**: 낮은 학습률, 배치 크기 1, 그리고 기울기 클리핑(gradient clipping)을 사용하여 학습 안정성을 확보합니다.

## 📊 Results

* **VOC 2012 검증 세트에서의 개별 포텐셜 및 엔드투엔드 학습 효과 (표 1)**:
  * 각 단항 포텐셜(Box, Global, Shape)은 $AP_r^{vol}$ 및 Matching IoU 측면에서 인스턴스 분할 성능을 개선합니다.
  * 'Global' 항은 높은 $AP_r$ 임계값 (0.9)에서 특히 큰 개선을 보여 경계 상자 지역화 오류를 극복하는 데 효과적임을 입증했습니다.
  * 'Shape' 항은 가려진 인스턴스를 복구하는 데 기여했습니다.
  * 엔드투엔드 학습은 모든 $AP_r$ 임계값에서 일관되게 성능을 향상시켰습니다.
* **VOC 검증 세트 SOTA 비교 (표 2)**:
  * $AP_r$ 임계값 0.7 이상에서 가장 높은 성능을 달성하여, 기존 방법보다 더 세부적이고 정확한 분할을 생성함을 보여주었습니다. 특히 IoU 0.9에서 이전 SOTA인 MPA [37] 대비 6.6% (상대적 36%) 개선을 달성했습니다.
  * $AP_r^{vol}$은 57.5%로 최고 기록을 달성했습니다.
  * MPA [37]보다 훨씬 빠른 추론 속도 (1.5s vs 8.7s)를 보여주었습니다.
* **SBD 데이터세트 결과 (표 3)**:
  * 높은 $AP_r$ 임계값에서 상당한 개선을 보였으며 (IoU 0.7에서 이전 SOTA [30] 대비 1.5% 개선), $AP_r^{vol}$에서도 3.4% 개선을 이루었습니다.
  * "Matching IoU" 측정에서 MNC [12]보다 8.3% 향상되었습니다.
  * 별도의 후처리 없이 단일 포워드 패스로 결과를 얻었습니다.
* **시맨틱 분할 성능 개선 (표 4)**:
  * 인스턴스 분할을 위한 파인튜닝 후, VOC 데이터세트에서 시맨틱 분할 Mean IoU가 0.9%, SBD 데이터세트에서 1% 향상되었습니다.
* **Cityscapes 결과 (표 5)**:
  * Cityscapes 데이터세트에서 새로운 SOTA를 달성하며, 기존 최고의 공개된 방법 [49] 및 동시 연구 [21]를 크게 뛰어넘었습니다.

## 🧠 Insights & Discussion

* **핵심 시사점**: 본 논문의 접근 방식은 기존의 객체 감지 기반 인스턴스 분할 방법과 달리 시맨틱 분할을 초기 단계로 활용하여, 매우 정밀하고 정확한 픽셀 수준의 분할을 가능하게 합니다. 특히 높은 IoU 임계값에서의 성능 우위는 이 방법이 객체의 미세한 경계를 얼마나 잘 잡아내는지를 보여줍니다.
* **장점**:
  * **엔드투엔드 학습 및 후처리 불필요**: 복잡한 수동 후처리 단계 없이 단일 네트워크로 최종 인스턴스 분할 맵을 생성합니다.
  * **전역적 추론**: 이미지 전체를 고려하여 예측하므로, 픽셀이 여러 인스턴스에 중복 할당되는 문제를 피하고 가려짐 처리에 강점을 보입니다.
  * **견고성**: 외부 객체 감지기의 오탐지나 경계 상자 지역화 오류에 대해 강건한 성능을 보입니다.
  * **상호 이점**: 인스턴스 분할 학습이 시맨틱 분할 성능까지 개선시킨다는 점은 두 작업 간의 깊은 연관성을 강조하며, 다중 작업 학습의 가능성을 시사합니다.
* **제한 사항**:
  * 일부 클래스(예: 자전거, 의자, 식탁, 화분)에서 성능이 상대적으로 낮은 경향이 있으며, 이는 현재 시맨틱 분할 시스템의 공통적인 어려움과 관련될 수 있습니다.
  * 외부 객체 감지기에 여전히 의존하며, 감지기에 의해 객체가 놓쳐진 경우 인스턴스 분할도 실패할 수 있습니다. 향후에는 객체 감지기를 시스템의 엔드투엔드 학습에 통합하는 것이 목표입니다.
* **중요성**: 시맨틱 분할 중심의 접근 방식을 통해 인스턴스 분할 분야에 새로운 방향을 제시했으며, 동적 CRF와 미분 가능한 모양 사전 지식(shape priors)의 도입은 기술적 진보를 보여줍니다.

## 📌 TL;DR

**문제**: 기존 인스턴스 분할은 객체 감지 파이프라인에 의존하여 출력의 정밀도가 낮고, 가려짐 처리 및 오검출 복구에 취약하며, 복잡한 후처리가 필요하다는 한계가 있습니다.

**제안 방법**: 본 논문은 **"동적으로 인스턴스화되는 네트워크를 이용한 픽셀별 인스턴스 분할"**을 제안합니다. 이 방법은 초기 **시맨틱 분할 모듈**로 시작하여, 그 출력과 외부 **객체 감지기**의 정보를 활용하는 **동적 인스턴스 서브네트워크**로 이어지는 엔드투엔드 학습 시스템입니다. 인스턴스 서브네트워크는 객체 경계 상자, 전역 시맨틱 분할 정보, 그리고 미분 가능한 모양 사전 지식(shape prior)을 통합하는 **CRF(Conditional Random Field)**를 사용하여 픽셀별로 객체 클래스와 인스턴스 ID를 동시에 예측합니다. 이 시스템은 이미지마다 가변적인 수의 인스턴스를 처리하며, 전체 이미지를 전역적으로 추론하고 후처리 과정이 필요 없습니다.

**주요 결과**: 제안된 방법은 VOC, SBD, Cityscapes 데이터세트에서 **최첨단 성능**을 달성했으며, 특히 **높은 IoU 임계값**에서 기존 방법들을 크게 능가하여 매우 정밀하고 정확한 분할을 생성합니다. 또한, 인스턴스 분할 학습 과정에서 **시맨틱 분할 성능까지 향상**됨을 입증했으며, 객체 감지기의 오탐지 및 부정확한 경계 상자에 대해 견고함을 보여주었습니다.
