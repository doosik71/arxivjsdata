# Deep Watershed Transform for Instance Segmentation

Min Bai, Raquel Urtasun

## 🧩 Problem to Solve

본 논문은 각 픽셀의 의미론적 클래스를 식별할 뿐만 아니라 각 픽셀을 물리적 객체 인스턴스와 연결하는 인스턴스 분할(Instance Segmentation)이라는 도전적인 과제를 다룹니다. 특히 자율주행 차량과 같은 실제 환경의 복잡한 거리 장면에서 객체의 크기, 부분적 가려짐, 반사 등으로 인해 인스턴스 분할이 더욱 어려워집니다. 기존 접근 방식들은 조건부 랜덤 필드(CRF), 순환 신경망(RNN), 객체 제안(Object Proposal) 또는 템플릿 매칭과 같은 복잡한 파이프라인을 사용하는 경향이 있습니다.

## ✨ Key Contributions

* **간단하면서도 강력한 종단간(End-to-End) CNN 제시**: 기존의 복잡한 파이프라인 대신 간단하고 직관적인 종단간 컨볼루션 신경망을 제안합니다.
* **고전적 워터셰드 변환과 딥러닝의 결합**: 고전적인 워터셰드 변환(Watershed Transform)의 개념을 현대 딥러닝과 통합하여 새로운 에너지 맵 학습 방식을 제안합니다.
* **객체 인스턴스를 명확히 표현하는 에너지 맵**: 객체 인스턴스가 에너지 분지(energy basins)로 명확하게 표현되고, 분할 능선(dividing ridges)이 모두 동일한 에너지 높이를 갖는 에너지 맵을 학습합니다.
* **단일 에너지 레벨 컷을 통한 인스턴스 추출**: 학습된 에너지 맵에서 단일 에너지 레벨 컷을 수행하여 과분할(over-segmentation) 없이 직접적으로 객체 인스턴스에 해당하는 연결된 구성요소를 추출합니다.
* **State-of-the-Art 성능 달성**: Cityscapes 인스턴스 레벨 분할 태스크에서 기존 최고 성능을 두 배 이상 뛰어넘는 결과를 달성했습니다.
* **일정한 런타임**: RNN과 같은 반복적인 전략에 의존하지 않아 객체 인스턴스 수에 관계없이 일정한 런타임을 가집니다.

## 📎 Related Works

* **제안 기반(Proposal based) 방법**: 객체 세그먼트 제안(e.g., [1]), CNN 특징을 사용한 제안 선택(e.g., [12]), 계층적 신경망을 통한 바운딩 박스 제안 및 마스크 정제(e.g., [7]), 딥 CNN을 사용한 분할 제안(e.g., [20, 22]), R-CNN 모델을 사용한 인스턴스 바운딩 박스 제안 및 정제(e.g., [31]) 등이 있습니다.
* **딥 구조 모델(Deep structured models)**: CNN으로 지역 인스턴스 모호성 해결 및 라벨링을 수행한 후 전역 CRF를 사용하여 인스턴스 라벨 일관성을 달성하는 방법(e.g., [32, 33]), 객체 탐지 제안과 딥 고차 CRF를 결합한 픽셀 할당 방법(e.g., [2]) 등이 있습니다.
* **템플릿 매칭(Template matching)**: CNN으로 이미지 특징을 추출하여 객체 인스턴스 내 각 픽셀에 섹터 라벨을 할당하고, 템플릿 매칭으로 인스턴스 중심 제안과 픽셀을 연결하는 방법(e.g., [28])이 있습니다.
* **순환 네트워크(Recurrent Networks)**: CNN으로 특징 추출 후 RNN이 한 번에 하나의 객체에 대한 인스턴스 라벨을 생성하는 방법(e.g., [24]), ConvLSTM 구조를 포함한 복잡한 파이프라인으로 바운딩 박스 및 분할 네트워크를 지시하는 방법(e.g., [23]) 등이 있습니다.
* **CNN 기반 방법**: 단일 CNN으로 인스턴스 수, 바운딩 박스 좌표, 카테고리 신뢰도 점수를 동시 예측하고 일반 클러스터링으로 그룹화하는 방법(e.g., [15]), 객체의 기본 모양을 학습하는 딥 CNN을 제안하는 방법(e.g., [13]) 등이 있습니다.

## 🛠️ Methodology

본 논문은 워터셰드 변환의 에너지 맵을 직접 학습하는 "Deep Watershed Transform" 방법을 제안합니다. 이 방법은 두 개의 서브 네트워크로 구성됩니다: Direction Network (DN)와 Watershed Transform Network (WTN).

1. **입력 준비**:
    * 원본 RGB 이미지에 PSPNet [34]에서 얻은 이진화된 의미론적 분할(semantic segmentation) 결과를 게이트(gated)하여 관련 영역에 초점을 맞춥니다.
    * 의미론적 분할 결과는 네 번째 채널로 RGB 이미지에 추가됩니다.

2. **Direction Network (DN) 학습**:
    * **목표**: 각 픽셀에서 에너지 하강 방향을 추정하도록 네트워크의 첫 부분을 사전 훈련합니다. 이 방향은 객체 인스턴스 경계에서 가장 가까운 점으로부터 멀어지는 단위 벡터로 매개변수화됩니다.
    * **Ground Truth**: 픽셀 $p$가 속한 인스턴스 경계까지의 거리 변환(distance transform) $D_{gt}(p)$의 정규화된 그래디언트 $\tilde{u}_{p,gt} = \frac{\nabla D_{gt}(p)}{|\nabla D_{gt}(p)|}$를 사용합니다.
    * **출력**: 입력 이미지 해상도와 동일한 2채널 단위 벡터 맵을 출력합니다. 출력의 정규화 계층은 각 채널의 제곱합이 1이 되도록 제한합니다.
    * **아키텍처**: VGG16 [27]의 첫 13개 계층을 수정하여 사용합니다. 공간 해상도 손실을 피하기 위해 pooling 계층을 수정하고, multi-scale 정보 통합 스킴을 활용합니다.
    * **손실 함수**: 각도 도메인에서의 평균 제곱 오차(Mean Squared Error) $l_{direction} = \sum_{p \in P_{obj}} w_p \| \cos^{-1} \langle \tilde{u}_{p,GT}, \tilde{u}_{p,pred} \rangle \|^2$를 사용합니다. 여기서 $P_{obj}$는 객체 인스턴스에 속하는 픽셀들의 집합이며, $w_p$는 객체 인스턴스 면적의 역제곱근에 비례하는 가중치입니다.

3. **Watershed Transform Network (WTN) 학습**:
    * **목표**: DN의 2채널 단위 벡터 맵을 입력으로 받아 이산화된 수정된 워터셰드 변환 에너지 맵을 생성합니다.
    * **출력**: $K=16$개의 가능한 에너지 값을 가진 이산화된 맵을 출력합니다. 에너지 레벨 0은 배경 또는 인스턴스 경계에서 2픽셀 이내의 영역을 나타내고, 높은 에너지 레벨은 객체 인스턴스 내부 영역을 나타냅니다.
    * **아키텍처**: 두 개의 $5 \times 5$ 컨볼루션 필터 블록과 $2 \times 2$ 평균 풀링 후, $1 \times 1$ 컨볼루션 및 입력 해상도로 업샘플링을 포함하는 일반적인 CNN 구조입니다.
    * **손실 함수**: 수정된 교차 엔트로피 손실 $l_{watershed} = \sum_{p \in P_{obj}} \sum_{k=1}^{K} w_p c_k (\bar{t}_{p,k} \log \bar{y}_{p,k} + t_{p,k} \log y_{p,k})$를 사용합니다. 여기서 $t_{p,k}$는 픽셀 $p$의 one-hot 타겟 벡터의 $k$번째 요소, $y_{p,k}$는 네트워크 출력의 $k$번째 채널, $w_p$는 작은 객체의 중요도를 조절하는 계수, $c_k$는 각 이산화 클래스에 특화된 스케일링 상수입니다. 낮은 에너지 레벨의 오류에 더 큰 페널티를 부여하기 위해 $c_k$는 증가하는 순서로 선택됩니다.

4. **종단간 미세 조정(End-to-End Fine-tuning)**:
    * 사전 훈련된 DN과 WTN 모델을 연결하여 전체 네트워크를 RGB 이미지와 PSPNet의 의미론적 분할 출력을 입력으로, Ground Truth 거리 변환을 훈련 타겟으로 사용하여 미세 조정합니다.

5. **에너지 컷 및 인스턴스 추출**:
    * 워터셰드 변환 출력에서 특정 에너지 레벨로 컷을 수행합니다 (작은 객체는 레벨 1, 큰 객체는 레벨 2).
    * 결과 이미지는 팽창(dilation)되어 경계 침식(boundary erosion)을 상쇄하고, 연결된 구성요소(connected components)를 식별하여 인스턴스를 추출합니다.
    * 제안된 인스턴스는 기본적인 구멍 채우기(hole-filling)로 추가 정제되고, 작고 불필요한 인스턴스는 제거됩니다.

## 📊 Results

* **Cityscapes 벤치마크 최고 성능 달성**: Cityscapes 인스턴스 분할 벤치마크에서 기존 State-of-the-Art 성능을 2배 이상 상회하는 결과를 보여주었습니다 (AP 기준 19.4%). 이전 최고 기록인 [28]의 8.9% AP를 크게 뛰어넘었습니다.
* **클래스별 성능 향상**: 모든 의미론적 클래스에서 AP 점수가 크게 향상되었습니다. 예를 들어, Car 클래스에서는 22.5%에서 31.5%로, Person 클래스에서는 12.5%에서 15.5%로 향상되었습니다.
* **의미론적 분할 소스의 영향**: PSPNet [34]을 의미론적 분할 소스로 사용했을 때 LRR [9]을 사용했을 때보다 더 높은 인스턴스 분할 AP를 달성하여, 더 나은 의미론적 분할이 모델 성능 향상에 기여함을 입증했습니다.
* **Confidence Score 추정의 영향**: Cityscapes 벤치마크의 AP 점수 계산에 필요한 인스턴스별 신뢰도 점수는 버스, 트럭, 기차 클래스에 대해 의미론적 분할 softmax 신뢰도를 기반으로 약한 순위를 매겼고, 다른 클래스는 무작위 순위를 사용했습니다. Oracle IoU를 사용한 최적의 순위를 적용했을 때 AP가 6.34%까지 증가할 수 있음을 보여주었으며, 이는 AP 메트릭의 한계를 시사합니다.
* **muCov 메트릭 강조**: AP의 한계점을 보완하기 위해 픽셀당 단일 인스턴스 라벨을 강제하는 muCov [26] 메트릭의 사용을 권장하며, 본 모델은 이 메트릭에서 68.0%의 높은 점수를 기록했습니다.

## 🧠 Insights & Discussion

* **직관적인 접근 방식의 효과**: 본 논문은 복잡한 구조 없이 고전적인 워터셰드 변환 아이디어를 딥러닝에 적용하여 우수한 인스턴스 분할 성능을 달성했습니다. 이는 직관적인 개념이 현대 딥러닝과 결합될 때 강력한 시너지를 낼 수 있음을 시사합니다.
* **중간 훈련 타겟의 중요성**: Direction Network(DN)를 통해 에너지 하강 방향을 예측하는 중간 훈련 타겟은 네트워크가 정확한 픽셀 수준 경계 위치를 학습하도록 강력한 신호를 제공하며, 최종 모델의 성능 향상에 기여합니다.
* **제한 사항 및 향후 연구**:
  * **가려짐(Occlusion)으로 인한 객체 분할**: 가려짐으로 인해 여러 조각으로 분리된 객체를 현재 방법으로는 하나의 구성요소로 병합하지 못하는 한계가 있습니다. 이는 대부분의 상향식(bottom-up) 그룹화 접근 방식의 단점입니다. 향후 상향식 접근 방식과 하향식(top-down) 추론 접근 방식의 결합을 통해 이 문제를 완화할 수 있을 것으로 예상합니다.
  * **의미론적 분할 오류의 전파**: 의미론적 분할 결과에 의존하므로, 의미론적 분할의 오류(예: 기차를 버스로 식별)는 본 방법으로 수정할 수 없습니다. 향후 의미론적 분할을 soft gating으로 사용하거나 의미론적 및 인스턴스 분할을 공동으로 추론하는 방법을 탐색할 수 있습니다.
  * **복잡한 장면의 인스턴스 분할 오류**: 사람 그룹과 같은 매우 복잡한 장면에서 객체가 잘못 분리되거나 융합되는 경우가 발생합니다.
* **AP 메트릭의 한계**: AP 점수가 실제 분할 품질보다 인스턴스 순위 결정에 더 민감하여, 픽셀당 단일 인스턴스 라벨을 예측하는 접근 방식에 불리할 수 있음을 지적합니다. muCov와 같은 다른 메트릭의 사용을 제안합니다.

## 📌 TL;DR

본 논문은 기존 인스턴스 분할 방법들의 복잡한 파이프라인 문제를 해결하기 위해 고전적인 워터셰드 변환과 딥러닝을 결합한 "Deep Watershed Transform" 모델을 제안합니다. 이 모델은 각 객체 인스턴스가 명확한 에너지 분지로, 분할 능선은 동일한 높이로 표현되는 에너지 맵을 학습합니다. 이 맵에 단일 에너지 레벨 컷을 적용하여 객체 인스턴스를 직접 추출합니다. Direction Network (DN)와 Watershed Transform Network (WTN)로 구성된 종단간 CNN은 Cityscapes 벤치마크에서 기존 최고 성능을 두 배 이상 뛰어넘는 정확도를 달성하며, RNN 없이 일정한 런타임을 제공합니다. 하지만 가려짐으로 인한 객체 분할 문제와 의미론적 분할 오류 전파와 같은 한계점을 가지고 있으며, 이는 향후 상향식-하향식 결합 및 공동 분할 연구를 통해 개선될 수 있습니다.
