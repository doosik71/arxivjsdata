# PersonLab: Person Pose Estimation and Instance Segmentation with a Bottom-Up, Part-Based, Geometric Embedding Model

George Papandreou, Tyler Zhu, Liang-Chieh Chen, Spyros Gidaris, Jonathan Tompson, Kevin Murphy

## 🧩 Problem to Solve

본 논문은 다수의 사람이 등장하는 이미지에서 사람의 포즈 추정(pose estimation)과 인스턴스 분할(instance segmentation)이라는 두 가지 도전적인 문제를 해결하고자 합니다. 특히, 혼잡하고 복잡한 환경에서도 각 사람 인스턴스를 식별하고, 얼굴 및 신체 키포인트를 정확하게 찾아내며, 개별 인스턴스 마스크를 추정하는 통합된 접근 방식을 제안합니다. 기존의 상향식(bottom-up) 방식은 키포인트 그룹화에 어려움이 있었고, 하향식(top-down) 방식은 사람 수에 따라 계산 비용이 증가하는 단점이 있었습니다. 본 연구는 이 두 가지 태스크를 효율적인 단일샷(single-shot) 모델로, 바운딩 박스(box-free) 없이 상향식으로 접근하여 해결하는 것을 목표로 합니다.

## ✨ Key Contributions

* **박스 없는(Box-free) 상향식 통합 모델**: 키포인트 추정 및 인스턴스 분할을 위한 효율적인 단일샷 모델인 PersonLab을 제안합니다. 이 모델은 사람 수와 관계없이 추론 시간이 거의 일정합니다.
* **부분 기반 모델링(Part-based Modeling)**: 시맨틱 수준의 추론(semantic-level reasoning)과 객체-부분 연관성(object-part associations)을 부분 기반 모델링을 통해 동시에 처리합니다.
* **상대적 변위(Relative Displacements) 예측**: 개별 키포인트를 탐지하고 키포인트 간의 상대적 변위를 예측하여 키포인트를 사람 인스턴스로 그룹화합니다.
* **부분 유도 기하 임베딩 디스크립터(Part-induced Geometric Embedding Descriptor)**: 시맨틱 사람 픽셀을 해당 사람 인스턴스와 연결하여 인스턴스 수준의 사람 분할을 가능하게 하는 기하 임베딩을 제안합니다.
* **반복 오프셋 정제(Recurrent Offset Refinement)**: 중거리(mid-range) 및 장거리(long-range) 오프셋 예측의 정확도를 향상시키기 위해 단거리(short-range) 오프셋을 활용한 반복 정제 기법을 도입했습니다.
* **경쟁력 있는 성능 달성**: COCO 데이터셋에서 키포인트 추정 및 인스턴스 분할 모두에서 기존의 모든 상향식 시스템을 능가하는 동시에, 일부 강력한 하향식 방법보다도 우수한 결과를 달성했습니다. 특히, 상향식 방법 중 최초로 COCO 인스턴스 분할 태스크에서 경쟁력 있는 결과를 보고했습니다.

## 📎 Related Works

* **포즈 추정(Pose Estimation)**:
  * **초기 모델**: 딥러닝 이전에는 부분 기반 그래픽 모델($part-based\ graphical\ models$)을 사용하여 신체 부위 간의 풍부한 의존성을 포착하는 모델이 연구되었습니다 [6, 7].
  * **최근 딥러닝 기반**: 단일/다중 사람 포즈 추정에서 SOTA 성능을 달성했습니다 [17-34].
  * **하향식(Top-down)**: 사람 바운딩 박스를 먼저 감지한 후 각 박스 내에서 포즈를 추정합니다 (예: G-RMI [33], Mask R-CNN [34], CPN [37]).
  * **상향식(Bottom-up)**: 신체 부위를 먼저 감지한 후 이를 사람 인스턴스로 그룹화합니다 (예: CMU-Pose [32], Associative Embedding [2]). 본 논문은 이 범주에 속합니다.
* **인스턴스 분할(Instance Segmentation)**:
  * **하향식(Top-down)**: 객체 감지 모델을 활용하여 마스크 제안을 분류하거나 바운딩 박스 제안을 정제하여 분할 결과를 얻습니다 (예: FCIS [3], Mask R-CNN [34]).
  * **상향식(Bottom-up)**: 픽셀 수준 예측을 각 객체 인스턴스와 연관시킵니다. 임베딩 기반 접근 방식이 많으며, 학습된 임베딩 공간에서 유사한 값을 가진 픽셀 예측을 그룹화합니다 (예: [2, 61, 62]). 본 논문은 픽셀 수준 예측을 객체 인스턴스와 연관시키는 상향식 접근 방식을 사용합니다.

## 🛠️ Methodology

PersonLab은 단일 CNN 모델을 기반으로 하며, 포즈 추정 모듈과 인스턴스 분할 모듈로 구성됩니다.

### 1. 사람 감지 및 포즈 추정 모듈 (Pose Estimation Module)

* **키포인트 감지**:
  * **히트맵 ($p_k(x)$)**: 각 키포인트 유형 ($k$)에 대해 이미지 내 모든 사람의 해당 키포인트 주변에 반지름 $R$의 디스크 영역을 1로 예측하는 이진 분류 작업을 수행합니다.
  * **단거리 오프셋 ($S_k(x)$)**: 키포인트 디스크 내의 각 픽셀 $x$에서 가장 가까운 해당 키포인트 $y_{j,k}$까지의 2D 변위 벡터를 예측하여 키포인트 위치 정확도를 높입니다.
  * **Hough 투표**: 히트맵과 단거리 오프셋을 Hough 투표로 통합하여 정밀한 Hough 스코어 맵 $h_k(x)$를 생성합니다.
* **키포인트를 사람 인스턴스로 그룹화**:
  * **중거리 쌍별 오프셋 ($M_{k,l}(x)$)**: 사람의 키네마틱 그래프(kinematic graph)에서 인접한 키포인트 쌍 ($k,l$)을 연결하는 2D 오프셋 필드를 예측합니다. 이는 같은 사람 인스턴스 내의 한 키포인트에서 다른 키포인트로 이동하는 데 사용됩니다.
  * **반복 오프셋 정제 (Recurrent Offset Refinement)**: 중거리 오프셋 $M_{k,l}(x)$를 단거리 오프셋 $S_l(x')$를 사용하여 반복적으로 정제합니다. $M_{k,l}(x) \leftarrow x' + S_l(x')$, 여기서 $x' = M_{k,l}(x)$입니다. 이는 장거리 예측의 정확도를 크게 향상시킵니다.
  * **빠른 그리디 디코딩 (Fast Greedy Decoding)**: Hough 스코어 맵의 지역 최대값을 후보 키포인트로 삼아, 스코어 내림차순으로 우선순위 큐에서 요소를 추출합니다. NMS (Non-Maximum Suppression)를 적용하여 겹치는 키포인트를 제거하고, 중거리 오프셋을 따라 키네마틱 그래프의 에지를 연결하여 사람 인스턴스를 형성합니다.
  * **키포인트 및 인스턴스 수준 스코어링**: 제안된 Expected-OKS 스코어 ($s_{j,k} = p_k(y_{j,k}) \int_{x \in D_R(y_{j,k})} \hat{h}_k(x) \exp(-\frac{(x-y_{j,k})^2}{2\lambda_j^2 \kappa_k^2}) dx$)를 사용하여 키포인트별 신뢰도를 계산하고, 이를 평균하여 인스턴스 수준의 스코어 ($h_j = (1/K)\sum_k s_{j,k}$)를 얻습니다. 소프트 NMS (soft-NMS)를 적용하여 최종 인스턴스를 선정합니다.

### 2. 인스턴스 수준 사람 분할 모듈 (Instance Segmentation Module)

* **시맨틱 사람 분할 (Semantic Person Segmentation)**: 단일 1x1 합성곱 레이어를 사용하여 각 픽셀 $x_i$가 적어도 한 명의 사람에 속할 확률 $p_S(x_i)$를 예측하는 표준 완전 합성곱 방식으로 시맨틱 분할을 수행합니다.
* **기하 임베딩을 통한 세그먼트와 인스턴스 연관 (Associating Segments with Instances via Geometric Embeddings)**:
  * **장거리 오프셋 ($L_k(x)$)**: 주석이 달린 사람 인스턴스 $j$의 분할 마스크 내에 있는 각 픽셀 $x$에서 해당 인스턴스의 $k$-번째 키포인트 $y_{j,k}$까지의 변위 벡터를 예측합니다 ($L_k(x) = y_{j,k} - x$).
  * **반복 장거리 오프셋 정제**: 장거리 오프셋도 단거리 오프셋을 사용하여 반복적으로 정제하여 정확도를 높입니다.
  * **임베딩 표현 ($G(x)$)**: $G(x) = (G_k(x))_{k=1,...,K}$ 로 정의하며, 여기서 $G_k(x) = x + L_k(x)$입니다. 이는 각 픽셀 $x$에서 해당 인스턴스의 모든 키포인트 절대 위치에 대한 로컬 추정치를 나타냅니다.
  * **임베딩 거리 측정 ($D_{i,j}$)**: 픽셀 $x_i$가 인스턴스 $j$에 속하는지 판단하기 위해 $D_{i,j} = \frac{1}{\sum_k p_k(y_{j,k})} \sum_{k=1}^K p_k(y_{j,k}) \frac{1}{\lambda_j} \|G_k(x_i) - y_{j,k}\|$와 같은 거리 측정법을 사용합니다. 여기서 $p_k(y_{j,k})$는 키포인트 존재 확률, $\lambda_j$는 인스턴스 스케일입니다. 이 방식은 표준 임베딩 기반 기술보다 훨씬 빠릅니다 ($O(N_S \cdot M)$ vs $O(N_S^2)$).
  * **최종 인스턴스 분할**: 시맨틱 분할 확률 $p_S(x_i) \ge 0.5$인 픽셀 $x_i$를 찾고, 임베딩 거리 $D_{i,j} \le t$ (여기서 $t=0.25$)를 만족하는 모든 감지된 사람 인스턴스 $j$에 픽셀을 할당합니다.
* **누락된 키포인트 주석 보충 (Imputing Missing Keypoint Annotations)**: COCO 데이터셋의 작은 사람 인스턴스에 대한 누락된 키포인트 주석을 단일 사람 포즈 추정기로 보충하여 훈련에 활용합니다. 이는 작은 객체에 대한 인스턴스 분할 성능에 특히 중요합니다.

## 📊 Results

* **COCO 키포인트 추정 (`test-dev` split)**:
  * ResNet-152 기반 모델과 멀티 스케일 추론 사용 시 **0.687 AP**를 달성하여, 이전의 모든 상향식 포즈 추정 시스템(Associative Embedding [2]의 0.655 AP)을 크게 능가했습니다.
  * Mask R-CNN [34] (0.631 AP) 및 G-RMI [33] (0.649 AP)와 같은 강력한 하향식 방법보다도 우수합니다.
* **COCO 인스턴스 분할 (사람 카테고리, `test-dev` split)**:
  * ResNet-152 기반 모델과 멀티 스케일 추론 사용 시 **0.417 AP**를 달성했습니다.
  * 이는 FCIS [3] (0.386 AP)보다 우수한 성능입니다.
  * 본 방법은 COCO 인스턴스 분할 태스크에서 경쟁력 있는 결과를 보고한 최초의 박스 없는 상향식 방법입니다.
* **COCO 인스턴스 분할 (사람 카테고리, `val` split)**:
  * Mask R-CNN [34]과 유사한 성능을 보였으나, 작은 인스턴스에서는 Mask R-CNN이 더 우수했습니다.

## 🧠 Insights & Discussion

* **효율성 및 확장성**: PersonLab은 바운딩 박스 감지 단계가 없는 상향식 접근 방식이므로, 이미지 내 사람 수와 무관하게 일정한 추론 시간을 유지하여 효율적입니다. 이는 실시간 애플리케이션 및 모바일 환경 배포에 유리합니다.
* **반복 오프셋 정제의 중요성**: 중거리 및 장거리 오프셋의 반복 정제 기법은 특히 큰 객체 인스턴스에서 오프셋 예측의 정확도를 획기적으로 향상시켜, 키포인트 그룹화 및 분할 성능에 크게 기여했습니다.
* **기하 임베딩의 해석 가능성 및 효율성**: 제안된 기하 임베딩은 각 픽셀에서 해당 인스턴스의 키포인트 절대 위치를 추정하는 직관적인 해석을 제공하며, 픽셀 쌍 간의 거리를 계산할 필요가 없어 기존 임베딩 기반 방식보다 훨씬 효율적인 연관성 알고리즘을 가능하게 합니다.
* **작은 객체 처리의 중요성**: 작은 인스턴스의 누락된 키포인트 주석을 보충하는 것은 COCO 인스턴스 분할 태스크에서 작은 객체에 대한 성능을 크게 향상시키는 데 필수적임을 실험을 통해 입증했습니다.
* **한계점**: 제안된 방법은 인스턴스 분할 태스크를 위해 키포인트 수준의 주석에 의존합니다. 향후에는 약한 지도 학습(weakly supervised learning)을 통해 이러한 한계를 극복하고, 부분 발견(part discovery) 방식을 탐색할 계획입니다.

## 📌 TL;DR

PersonLab은 다중 사람 포즈 추정 및 인스턴스 분할을 위한 **박스 없는(box-free) 상향식(bottom-up) 단일샷 모델**입니다. 이 모델은 **키포인트 탐지 및 상대적 변위 예측**을 통해 포즈를 추정하고, **부분 유도 기하 임베딩 디스크립터**와 **반복 오프셋 정제**를 사용하여 픽셀을 사람 인스턴스에 효율적으로 할당하여 분할을 수행합니다. COCO 데이터셋에서 기존 상향식 방법을 크게 능가하며, 일부 하향식 방법보다도 우수한 성능을 달성하여 **다중 사람 시각 이해를 위한 효율적이고 강력한 통합 솔루션**임을 입증했습니다.
