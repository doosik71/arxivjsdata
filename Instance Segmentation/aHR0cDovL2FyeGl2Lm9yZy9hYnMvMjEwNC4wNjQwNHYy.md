# Pointly-Supervised Instance Segmentation

Bowen Cheng, Omkar Parkhi, Alexander Kirillov

## 🧩 Problem to Solve

인스턴스 분할(Instance Segmentation)은 객체를 픽셀 단위로 정확하게 분리하는 마스크를 생성해야 합니다. 하지만 훈련 데이터에 필요한 픽셀 단위 마스크 주석(annotation)은 이미지 수준 분류 라벨이나 바운딩 박스(bounding box) 주석에 비해 훨씬 복잡하고 시간 소모적입니다. 예를 들어, COCO 데이터셋에서 폴리곤 기반 마스크 하나를 주석하는 데 평균 79.2초가 걸리는 반면, 바운딩 박스는 약 7초로 11배 빠릅니다. 기존의 약지도(weakly-supervised) 인스턴스 분할 방법들은 대규모 데이터셋(예: COCO)에서 완전 지도(fully-supervised) 방법에 비해 성능이 크게 뒤처지는 경향이 있었습니다. 따라서, 논문은 고성능 인스턴스 분할을 위해 반드시 전체 마스크 훈련 데이터가 필요한지, 그리고 더 쉽게 수집할 수 있는 효과적인 주석 방식이 있는지에 대한 질문을 던집니다.

## ✨ Key Contributions

* **새로운 점 기반 주석 스킴 제안:** 객체 바운딩 박스와 각 박스 내에서 무작위로 샘플링된 점들(객체 또는 배경)에 대한 이진 레이블을 수집하는 간단한 주석 방식을 제안합니다. 이 방식은 기존 전체 마스크 주석보다 약 5배 빠릅니다.
* **기존 모델의 원활한 훈련 가능성 입증:** Mask R-CNN, PointRend, CondInst와 같은 기존 인스턴스 분할 모델들이 아키텍처나 훈련 파이프라인 변경 없이 제안된 점 기반 지도 방식으로 원활하게 훈련될 수 있음을 보여줍니다.
* **높은 성능 달성:** COCO, PASCAL VOC, Cityscapes, LVIS 데이터셋에서 객체당 10개의 주석된 무작위 점만 사용하여 훈련된 Mask R-CNN이 완전 지도 성능의 94%–98%를 달성하여 약지도 인스턴스 분할의 강력한 기준점을 제시합니다.
* **Implicit PointRend 제안:** 점 기반 주석에 더 적합하도록 PointRend 모듈을 수정한 새로운 아키텍처인 Implicit PointRend를 제안합니다. 이 모듈은 더 간결하며 단일 점 수준 마스크 손실을 사용합니다.
* **성능 향상 및 효율성:** Implicit PointRend는 점 기반 지도에서 기존 PointRend를 능가하며, 10개의 점만으로 완전 지도 Mask R-CNN과 동등한 성능을 달성합니다. 동일한 주석 예산으로 비교했을 때, 점 기반 주석 방식이 다른 지도 방식(전체 마스크, 바운딩 박스)보다 훨씬 우수한 성능을 보여줍니다.
* **추가적인 성능 개선 방법 탐구:** 점 기반 데이터 증강, 자가 훈련(self-training), 전이 학습(transfer learning)을 통해 완전 지도와의 성능 격차를 더욱 줄일 수 있음을 보여줍니다.

## 📎 Related Works

* **완전 지도 인스턴스 분할:** Mask R-CNN [19], YOLACT++ [6], CondInst [52] 등 마스크를 직접 예측하는 방식과 InstanceCut [24] 등 간접적으로 마스크를 형성하는 바텀업(bottom-up) 방식이 있습니다. 본 연구는 마스크를 직접 예측하는 방식에 초점을 맞춥니다.
* **약지도 인스턴스 분할:**
  * **이미지 레벨 레이블:** 이미지 레벨 범주 레이블을 사용하여 분할 제안(segmentation proposals)을 재정렬하거나 [61] 의사(pseudo) Ground Truth를 생성합니다 [1, 2, 62]. 소규모 데이터셋에서는 유망하지만, COCO와 같은 대규모 데이터셋에서는 경쟁력이 부족합니다.
  * **바운딩 박스 지도:** SDI [23], BBTP [21], BoxInst [53]와 같은 방법들이 바운딩 박스를 활용합니다. 특히 BoxInst [53]는 COCO에서 완전 지도 성능의 85%를 달성하여 이전 방법들을 능가했지만, 본 연구의 점 기반 지도 방식은 이보다 훨씬 더 완전 지도 성능에 근접합니다.
* **점 기반 지도 (Point-based supervision):** 액션 감지 [37, 38], 객체 감지 [42, 46], 객체 개수 세기 [27], 시맨틱 분할 [4, 44] 등 다양한 태스크에서 연구되었습니다.
  * **대화형 분할 (Interactive segmentation):** 점 클릭은 종종 대화형 파이프라인에서 사용되어 [5, 29, 30, 35, 59] 반복적인 추론(inference)을 필요로 하며 복잡합니다.
  * **단일 점 지도:** Laradji et al. [28]은 인스턴스당 단일 점을 사용하여 제안 기반 인스턴스 분할을 제안했습니다.
* **본 연구의 차별점:** 기존 연구들이 주석자의 클릭을 사용한 것과 달리, 본 연구는 바운딩 박스 내에서 무작위로 점 위치를 샘플링하고 주석자에게 객체 또는 배경으로 분류하도록 요청합니다. 이는 주석자 편향을 줄이고 대규모 데이터셋에서의 시뮬레이션을 가능하게 합니다.

## 🛠️ Methodology

1. **점 기반 주석 형식 및 수집 ($P_N$):**
    * **주석 형식:** 표준 바운딩 박스와 각 객체 바운딩 박스 내에 무작위로 샘플링된 $N$개의 점에 대한 이진(객체/배경) 레이블을 수집합니다. 이를 $P_N$이라고 명명합니다.
    * **무작위 점 샘플링:** 주석자의 클릭 대신 무작위로 점을 샘플링하여 주석자 편향을 줄입니다 [4].
    * **수집 및 시뮬레이션:** 먼저 바운딩 박스를 수집한 다음, 각 객체에 대해 바운딩 박스 내에서 $N$개의 무작위 점을 생성하고 주석자가 이진 분류합니다. 완전한 인스턴스 분할 Ground Truth가 있는 데이터셋의 경우, 이 과정을 시뮬레이션하여 쉽게 데이터를 생성할 수 있습니다.
    * **주석 시간:** 바운딩 박스(7초)와 10개의 점 분류(0.9초/점)를 포함하여 객체당 총 16초($P_{10}$)가 소요됩니다. 이는 COCO의 폴리곤 기반 마스크 주석(79.2초)보다 약 5배 빠릅니다.
    * **주석 품질:** COCO Ground Truth 마스크와 약 90%의 일치율을 보이며, LVIS 마스크와는 약 95%의 일치율을 보입니다. 5%의 레이블 오류에도 성능 저하가 미미하여 견고함을 보여줍니다.

2. **점 기반 훈련:**
    * **기존 모델 적용:** Mask R-CNN [19], CondInst [52], PointRend [25]와 같이 정규 그리드에서 마스크 예측을 수행하는 기존 인스턴스 분할 모델에 점 기반 지도를 적용합니다.
    * **손실 계산:** 모델의 그리드 예측에서 Ground Truth 점 위치의 예측값을 양선형 보간(bilinear interpolation)으로 얻은 후, 이 예측값과 Ground Truth 레이블에 표준 마스크 손실(예: 교차 엔트로피 손실)을 적용합니다.
    * **데이터 증강:** 훈련 중 매 반복마다 사용 가능한 Ground Truth 점의 절반만 샘플링하는 간단한 점 기반 데이터 증강 전략을 제안합니다 (예: $P_{10}$의 경우 5개 점). 이는 더 긴 훈련 스케줄이나 고용량 백본 모델에서 데이터의 가변성 감소로 인한 과적합을 완화합니다.

3. **Implicit PointRend 모델:**
    * **기존 PointRend의 한계:** PointRend는 조악한 마스크(coarse mask) 예측을 사용하여 영역별 컨텍스트를 제공하지만, 7x7의 낮은 해상도로 인해 점 기반 지도에 비효율적이며 마스크 손실이 이중으로 필요합니다.
    * **Implicit PointRend 아키텍처:**
        * 객체별로 최종 점 수준 마스크 예측을 수행하는 함수(Point Head)의 매개변수를 생성하는 "매개변수 헤드(parameter head)"를 도입합니다.
        * Point Head는 점의 위치(바운딩 박스에 대한 상대적 좌표, 푸리에 특징 [51]으로 인코딩)와 이미지 특징을 입력으로 받아 마스크 예측을 수행합니다.
        * **단일 점 수준 마스크 손실:** 조악한 마스크 예측이 필요 없으므로 단일 점 수준 마스크 손실만 사용합니다 (이진 교차 엔트로피).
        * **$L_2$ 손실:** 예측된 매개변수가 무한정 커지는 것을 방지하기 위해 $L_2$ 손실을 추가합니다.
    * **추론:** PointRend와 동일한 적응형 세분화(adaptive subdivision) [55] 전략을 따릅니다.
    * **훈련:** PointRend와 달리 중요도 점 샘플링(importance point sampling) 없이 균일 점 샘플링 전략을 사용합니다.

## 📊 Results

* **$P_{10}$ 지도 성능:** Mask R-CNN 모델이 COCO, PASCAL VOC, Cityscapes, LVIS의 다양한 데이터셋에서 완전 지도 Mask R-CNN 성능의 94%~98%를 달성했습니다. 예를 들어, COCO에서 완전 지도 37.2 AP 대비 $P_{10}$ 지도로 36.1 AP (97%)를 기록했습니다.
* **점 개수 영향:** 점 수가 수십 개에 이를 때까지 성능이 빠르게 향상되며, 이후로는 수확 체감(diminishing returns)을 보입니다. 10개 점($P_{10}$)이 주석 시간과 성능 사이에서 좋은 균형점을 제공합니다.
* **주석 품질 및 위치 견고성:** 5%의 레이블 오류에 대해 0.2~0.4 AP 정도만 감소했으며, 무작위 점 샘플링 위치의 변동에 대해서도 0.1 AP의 낮은 성능 변동을 보였습니다.
* **다양한 모델 적용:** Mask R-CNN, CondInst, PointRend 모두 점 기반 지도로 훈련 가능하며, 유사한 성능을 보였으나 PointRend는 마스크 지도 대비 점 지도에서 성능 격차가 더 컸습니다.
* **점 기반 데이터 증강 효과:** ResNeXt-101과 같은 고용량 백본 모델에서 0.4 AP 성능 향상을 가져왔으며, CondInst와 PointRend에도 도움이 되었습니다.
* **자가 훈련(Self-training):** 10점 지도 Mask R-CNN (36.1 AP)에 자가 훈련을 적용하면 36.7 AP (+0.6 AP)로, 완전 지도 Mask R-CNN 성능의 98%에 도달했습니다.
* **전이 학습(Transfer learning):** COCO에서 점 기반 사전 훈련(pre-training)이 마스크 기반 사전 훈련만큼 효과적임을 확인했습니다.
* **주석 시간 대 성능 비교:** 동일한 주석 예산(노동 시간) 하에서, 점 기반 지도로 훈련된 Mask R-CNN이 완전 마스크 지도 및 바운딩 박스 지도(BoxInst [53])보다 훨씬 우수한 성능을 달성했습니다.
* **Implicit PointRend 성능:**
  * 점 기반 지도($P_{10}$)에서 기존 PointRend (35.7 AP)보다 우수한 36.9 AP를 달성했습니다.
  * 완전 마스크 지도에서도 기존 PointRend와 동등한 38.5 AP를 달성했습니다.
  * 특히 ResNeXt-101 백본을 사용하고 10점 지도로 훈련된 Implicit PointRend는 완전 지도 Mask R-CNN의 성능(39.5 AP)을 능가하는 39.7 AP를 기록했습니다.

## 🧠 Insights & Discussion

* 이 연구는 인스턴스 분할을 위한 **매우 간단하면서도 효과적인** 점 기반 주석 방식을 제시하며, 데이터 수집의 병목 현상을 크게 완화할 수 있음을 보여줍니다. 이는 실용적인 관점에서 매우 중요합니다.
* 기존 모델에 대한 높은 호환성과 최소한의 수정으로 고성능을 달성할 수 있다는 점은 이 방식의 **광범위한 적용 가능성**을 시사합니다.
* 점 기반 데이터 증강, 자가 훈련, 전이 학습과 같은 추가 기술을 통해 완전 지도와의 성능 격차를 더욱 줄일 수 있으며, 이는 **약지도 학습의 잠재력**을 극대화하는 방안을 제시합니다.
* Implicit PointRend의 성공은 점 기반 지도에 특화된 아키텍처 설계가 중요하다는 것을 보여줍니다. 특히, 객체별로 매개변수를 생성하여 마스크를 암묵적으로 표현하는 방식이 점 수준 예측에 효과적이며, 기존 PointRend의 조악한 마스크 헤드의 한계를 극복했습니다.
* 주석 오류나 점 샘플링 위치에 대한 견고성은 실제 환경에서의 주석 과정에서 발생할 수 있는 불확실성에 대해 모델이 강건하다는 것을 의미하며, 추가적인 검증 단계의 필요성을 줄여줍니다.
* 제한점으로는, 기본 설정에서는 완전 지도를 완전히 따라잡지는 못하며 (자가 훈련 등 추가 기법 필요), Implicit PointRend의 고정된 특징 맵 크기(예: $p_2$ FPN 레벨의 14x14)는 매우 큰 객체에 대한 정확한 분할에 한계가 있을 수 있다는 점이 언급됩니다.

## 📌 TL;DR

인스턴스 분할을 위한 픽셀 마스크 주석은 비용이 많이 들고 시간이 오래 걸리는 문제입니다. 본 논문은 이 문제를 해결하기 위해 **바운딩 박스와 객체당 10개의 무작위 점**에 대한 이진 레이블만 사용하는 "점 기반 지도" 방식을 제안합니다. 이 방식은 기존 마스크 주석보다 **약 5배 빠르지만**, Mask R-CNN 모델이 완전 지도 성능의 **94%–98%**를 달성할 수 있음을 입증합니다. 또한, 점 기반 지도에 특화된 새로운 모듈인 **Implicit PointRend**를 개발하여, 10개의 점만으로 완전 지도 Mask R-CNN에 필적하거나 능가하는 성능을 달성하여, 제한된 주석 예산에서도 고품질 인스턴스 분할이 가능함을 보여줍니다.
