# Proposal-free Network for Instance-level Object Segmentation

Xiaodan Liang, Yunchao Wei, Xiaohui Shen, Jianchao Yang, Liang Lin, Shuicheng Yan

## 🧩 Problem to Solve

기존 인스턴스 레벨 객체 분할 방법들은 대부분 영역 제안(region proposal) 방식에 의존하는데, 이는 정확한 제안 생성이 어렵고, 계산 비용이 많이 들며(수천 개의 영역, 이미지당 1초 이상), 심한 폐색(occlusion) 상황에서는 실패하는 경우가 많습니다.
이러한 방법들은 일반적으로 복잡한 전처리(영역 제안 생성) 및 후처리(NMS, 그래프 컷 추론) 단계를 포함하며, 각기 독립적인 단계로 훈련됩니다.
본 연구의 목표는 영역 제안 과정 없이 인스턴스 레벨 객체 분할을 각 카테고리의 인스턴스별로 정확하고 효율적으로 엔드투엔드 방식으로 수행하는 것입니다.

---

## ✨ Key Contributions

* **Proposal-Free Network (PFN) 제안**: 명시적인 영역 제안(region proposal) 생성 없이, 다양한 카테고리의 인스턴스 개수와 픽셀 단위 정보(바운딩 박스 좌표, 카테고리 신뢰도)를 직접 출력하는 새로운 엔드투엔드 네트워크를 제안합니다.
* **직접적인 인스턴스 위치 추론**: 각 픽셀이 속한 인스턴스의 바운딩 박스 좌표(중심, 좌상단, 우하단)를 직접 예측합니다. 유사한 위치를 예측하는 픽셀들은 하나의 인스턴스로 클러스터링됩니다.
* **통합 최적화**: 카테고리 레벨 분할, 픽셀 단위 인스턴스 위치 예측, 인스턴스 개수 예측을 하나의 통합된 심층 컨볼루션 신경망 내에서 엔드투엔드 방식으로 공동 최적화합니다.
* **다중 스케일 예측 및 좌표 맵 활용**: 다중 스케일 예측 스트림과 공간 좌표 맵을 특징으로 통합하여 위치 예측의 정확도와 견고성을 향상시킵니다.
* **뛰어난 성능 달성**: PASCAL VOC 2012 벤치마크에서 기존 제안 기반 방법들(43.8% 및 46.3%)을 크게 능가하는 58.7%의 AP$_{r}$ (0.5 IoU 기준)로 최첨단 성능을 달성했으며, 처리 속도 또한 훨씬 빠릅니다(이미지당 1초 vs. ~40초).
* **더욱 간결하고 직접적인 방식**: 복잡한 전처리 및 후처리 단계에 의존하는 기존 방법들과 비교하여 훨씬 더 간결하고 직접적인 파이프라인을 제공합니다.

---

## 📎 Related Works

* **객체 탐지 (Object Detection)**: 전통적으로 영역 제안(예: Selective Search [31], EdgeBox [36], RPN [24])에 의존한 후 분류를 수행합니다. YOLO [23]는 바운딩 박스와 클래스 확률을 위한 제안 없는(proposal-free) 접근 방식을 도입했습니다. PFN은 YOLO와 제안 없는 아이디어를 공유하지만, 거친 바운딩 박스 대신 미세한 분할 마스크를 생성합니다.
* **의미론적 분할 (Semantic Segmentation)**: 각 이미지에 픽셀 단위 레이블을 할당하지만, 인스턴스를 구별하지 않습니다(예: FCN [17], DeepLab [1], CRF-RNN [35]). 이러한 방법들은 픽셀 단위 교차 엔트로피 손실을 사용하며, 가변적인 인스턴스 개수를 직접 처리할 수 없습니다.
* **인스턴스 레벨 객체 분할 (Instance-level Object Segmentation)**: 최근 접근 방식(예: SDS [9], Chen et al. [16])은 대부분 영역 제안과 복잡한 후처리(예: 그래프 컷, 정수 이차 계획법 [30])를 활용합니다. PFN은 픽셀 단위 인스턴스 위치 맵을 직접 예측하고 단순한 클러스터링을 사용하여, 제안 기반 방법의 복잡성과 한계를 피합니다. Zhang et al. [34]는 패치에 대한 깊이 순서 인스턴스 레이블을 예측했지만, PFN의 데이터 기반 접근 방식과는 달리 제한된 수의 인스턴스만 처리했습니다.

---

## 🛠️ Methodology

PFN은 VGG-16 기반의 심층 컨볼루션 신경망을 사용하여 다음 세 가지 서브 태스크를 해결합니다.

* **카테고리 레벨 분할 예측**:
  * 사전 훈련된 VGG-16 분류 네트워크 [27]를 기반으로 "DeepLab-CRF-LargeFOV" [1] 구조를 fine-tuning하여 $C+1$ 개의 신뢰도 맵을 예측합니다.
  * 픽셀 단위 교차 엔트로피 손실을 사용하여 최적화하며, 테스트 시에는 Fully-Connected CRF [1]를 적용하여 부드러운 분할 맵을 생성합니다.
  * 이 단계는 인스턴스 레벨 네트워크를 위한 좋은 초기 학습을 제공합니다. (두 개의 별도 단계로 훈련하는 것이 통합 훈련보다 성능이 좋음을 실험으로 검증합니다.)
* **픽셀 단위 인스턴스 위치 예측**:
  * 각 픽셀 $i$ 에 대해, 해당 픽셀이 속한 객체 인스턴스의 바운딩 박스 정보인 6차원 벡터 $t_i = (c_x/w_s, c_y/h_s, l_x/w_s, l_y/h_s, r_x/w_s, r_y/h_s)$ 를 예측합니다. (중심 좌표 $c_x, c_y$, 좌상단 $l_x, l_y$, 우하단 $r_x, r_y$를 해당 인스턴스의 너비 $w_s$와 높이 $h_s$로 정규화)
  * 손실 함수는 foreground 픽셀에 대해서만 활성화되는 smooth-L1 loss $R(t_i - t_i^*)$ 를 사용합니다.
  * **다중 스케일 예측**: VGG-16의 초기 레이어(미세한 로컬 디테일)와 깊은 레이어(글로벌 의미 정보)에서 추출된 특징을 5개의 스트림으로 결합하여 최종 예측을 수행합니다. 각 스트림에는 개별적인 심층 감독(deep supervision)이 적용됩니다.
  * **좌표 맵**: 각 스트림의 두 번째 컨볼루션 레이어에서 픽셀의 공간 좌표($i_x, i_y$)를 추가 특징 맵으로 통합하여 인스턴스 위치 예측의 정확도를 높입니다. 이는 절대 위치보다는 상대적인 공간 오프셋을 학습하는 데 도움이 됩니다.
* **인스턴스 개수 예측**:
  * 마지막 컨볼루션 레이어의 특징 맵과 인스턴스 위치 예측 맵을 연결하여 퓨전 특징 맵을 생성합니다.
  * 이 퓨전 특징 맵을 사용하여 각 카테고리별 객체 인스턴스 개수 $g = [g_1, g_2, ..., g_C]$ 를 예측하는 $C$ 차원 벡터를 출력합니다.
  * Euclidean loss $L_n(g, g^*) = \frac{1}{C} \sum_{c=1}^C ||g_c - g_c^*||_2^2$ 를 사용하여 최적화합니다.
* **네트워크 훈련**:
  * 전체 인스턴스 레벨 네트워크는 위치 예측 손실 $L_o$ 와 개수 예측 손실 $L_n$ 를 결합한 총 손실 $L = \lambda L_o + L_n$ 를 사용하여 엔드투엔드 방식으로 훈련됩니다. 여기서 $\lambda$는 클래스 균형을 위한 파라미터(본 연구에서는 10)입니다.
  * 카테고리 레벨 네트워크로 초기화된 파라미터를 사용하여 fine-tuning합니다.
* **테스트 단계**:
  * 카테고리 레벨 분할 네트워크와 인스턴스 레벨 네트워크를 통해 픽셀 단위 인스턴스 위치 $t$ 와 인스턴스 개수 $g$ 를 얻습니다.
  * 각 카테고리별로 예측된 인스턴스 위치 $t$ 를 기반으로 **스펙트럴 클러스터링 (spectral clustering)** [18]을 수행합니다. 이때 인스턴스 개수 $g$ 가 클러스터 개수를 지정합니다.
  * 픽셀 유사도 $w_{i,j}$는 위치 벡터 $t_i, t_j$와 공간 좌표 $q_i, q_j$의 유사도를 결합한 가우시안 함수로 계산됩니다:
        $$w_{i,j} = \exp\left(-\frac{||t_i - t_j||^2}{|t_i|^2 2\sigma^2}\right) + \exp\left(-\frac{||q_i - q_j||^2}{|q_i|^2 2\sigma^2}\right)$$
  * **후처리**:
    * 인스턴스 개수 예측 $g$ 를 활용하여 카테고리 레벨 분할 결과 $p$ 의 일관성을 개선합니다 (예: 예측된 카테고리에 없는 픽셀을 배경으로 재분류하거나, 단일 카테고리 예측 시 모든 객체 픽셀을 해당 카테고리로 변환).
    * 클러스터링 결과 중 픽셀 수가 특정 임계값(전체 마스크 픽셀의 0.1%) 미만인 작은 클러스터는 배경 노이즈로 간주하여 제거합니다.

---

## 📊 Results

* **PASCAL VOC 2012 벤치마크**:
  * AP$_{r}$ (IoU 0.5 기준): PFN은 58.7%를 달성하여 기존 최첨단 방법인 SDS [9]의 43.8%와 Chen et al. [16]의 46.3%를 크게 능가합니다. (AlexNet 기반 PFN도 50.9%로 기존 최첨단을 넘어섰습니다.)
  * 높은 IoU 점수(0.6-0.9)에서의 AP$_{r}$에서도 PFN은 훨씬 뛰어난 성능을 보입니다. 특히 IoU 0.9에서 PFN은 15.7%를 기록한 반면, SDS는 0.9%, Chen et al.은 2.6%에 불과하여, 엄격한 위치 정확도 요구 사항에서 PFN의 효과를 입증합니다.
  * 작은 객체 인스턴스(새, 의자) 또는 심한 폐색이 있는 객체(테이블, 소파)에서 PFN이 특히 큰 성능 향상(예: 새 74.2% vs. SDS 60.1%, 소파 64.4% vs. SDS 26.9%)을 보입니다.
* **AP$_{r}$vol**: IoU 0.1~0.9의 AP$_{r}$ 평균값을 나타내는 AP$_{r}$vol 지표에서도 PFN은 52.3%의 높은 성능을 달성했습니다.
* **추론 속도**: PFN은 이미지당 약 1초로 매우 빠르게 작동하며, 이는 40초 이상이 소요되는 기존 제안 기반 방법들보다 훨씬 효율적입니다.

---

## 🧠 Insights & Discussion

* **두 단계 훈련의 중요성**: 카테고리 레벨 분할과 인스턴스 레벨 분할을 위한 두 단계 순차적 훈련이 단일 통합 네트워크 훈련보다 더 나은 성능을 보여줍니다. 이는 두 태스크의 학습 목표가 다르기 때문입니다.
* **인스턴스 위치 예측의 견고성**: 중심, 좌상단, 우하단 코너를 포함하는 6차원 바운딩 박스 정보 예측이 다른 위치 표현 방식보다 (예: 2차원 오프셋, 2차원 중심) 더 견고하고 정확한 결과를 제공합니다. 이는 중복 정보가 모델 조합 효과를 가져오기 때문입니다.
* **네트워크 구조의 영향**:
  * **다중 스케일 퓨징**: 로컬 미세 디테일과 글로벌 의미 정보를 결합하는 다중 스케일 예측이 픽셀 단위 인스턴스 위치 예측 정확도를 크게 향상시킵니다.
  * **좌표 맵 활용**: 픽셀의 공간 좌표를 추가 특징으로 사용하는 것이 인스턴스 위치 예측 정확도를 0.7% 향상시켜, 상대적인 공간 오프셋 학습에 도움이 됩니다.
  * **퓨징 방식**: 특징 맵을 단순히 합산하는 것보다 연결(concatenation)하는 것이 더 효과적입니다.
* **인스턴스 개수 예측의 상호 보완성**:
  * 카테고리 레벨 정보를 포함하는 인스턴스 개수 예측은 픽셀 단위 인스턴스 위치 예측과 상호 보완적인 관계에 있으며, 공동 최적화가 더 나은 결과를 가져옵니다.
  * 인스턴스 개수 예측은 최종 분할 결과의 일관성을 높이는 데 중요한 역할을 합니다.
* **테스트 전략의 효과**:
  * 유사도 계산 시 공간 좌표를 포함하는 것이 클러스터링의 로컬 연결성을 강화하여 3.4% AP$_{r}$ 향상을 가져옵니다.
  * 인스턴스 개수 예측을 통한 카테고리 레벨 분할 결과 정제 및 작은 클러스터 제거가 최종 성능 향상에 기여합니다.
* **한계점 및 향후 과제**:
  * PFN은 심한 폐색이 있는 인스턴스나 매우 작은 객체 인스턴스를 분할하는 데 여전히 어려움을 겪습니다.
  * 현재 카테고리 레벨 분할의 정확도가 인스턴스 레벨 분할 성능의 상한선을 제한하고 있습니다. 더 나은 카테고리 레벨 분할 네트워크를 활용하면 성능이 더욱 향상될 수 있습니다.
  * 향후 더 복잡한 실내외 환경의 다중 인스턴스 시나리오로 확장할 계획입니다.

---

## 📌 TL;DR

이 논문은 영역 제안(region proposal) 단계가 필요 없는 인스턴스 레벨 객체 분할을 위한 엔드투엔드 심층 학습 모델인 PFN(Proposal-Free Network)을 소개합니다. PFN은 픽셀 단위 인스턴스 바운딩 박스 좌표와 카테고리별 총 인스턴스 개수를 직접 예측합니다. 이를 위해 카테고리 레벨 및 인스턴스 레벨 분할을 포함하는 두 단계 훈련 프로세스를 사용하며, 다중 스케일 예측 및 공간 좌표 맵을 통합합니다. 예측 후, 간단한 스펙트럴 클러스터링(예측된 인스턴스 개수 활용)과 후처리를 통해 최종 인스턴스 마스크를 생성합니다. PFN은 PASCAL VOC 2012에서 기존 제안 기반 최첨단 방법들을 크게 능가하여 0.5 IoU에서 58.7% AP$_{r}$을 달성했으며, 훨씬 빠르고 간단한 방식입니다.
