# Attention-Based Transformers for Instance Segmentation of Cells in Microstructures

Tim Prangemeier, Christoph Reich, Heinz Koeppl

## 🧩 Problem to Solve

생의학 분야, 특히 현미경 이미징에서 개별 객체 인스턴스(예: 세포, 종양)를 정확하게 감지하고 분할하는 것은 중요한 과제입니다. 미세구조 환경 내 효모 세포와 같은 단일 세포 현미경 데이터의 정량화를 위한 인스턴스 분할은 주요 병목 현상입니다. 기존의 많은 자동화 방법은 인스턴스 감지를 위해 후처리가 필요하거나 수동 입력에 의존하여 실시간 모니터링 및 고급 폐쇄 루프 실험 설계에 한계가 있었습니다. 빠르고 정확한 종단 간(end-to-end) 인스턴스 분할 방법의 개발이 절실합니다.

## ✨ Key Contributions

* **새로운 어텐션 기반 트랜스포머 제안**: 생의학 샘플의 직접적인 종단 간 인스턴스 분할을 위한 새로운 어텐션 기반 감지 트랜스포머(Cell-DETR)를 제시했습니다. 이는 생의학 데이터에 감지 트랜스포머를 적용한 첫 사례입니다.
* **최첨단 성능 달성**: 일반적인 인스턴스 분할 방법인 Mask R-CNN과 동등한 분할 성능을 달성하면서도 더 간단하고 빠릅니다.
* **애플리케이션별 성능 향상**: 미세구조 환경 내 효모 세포 분할에서 기존의 최첨단 의미론적 분할 도구를 능가하며, 개별 객체 인스턴스를 직접 예측합니다.
* **효율성 증대**: 빠르고 정확한 인스턴스 분할 성능은 후속 데이터 처리의 정보 수율을 높이고, 실험의 온라인 모니터링 및 폐쇄 루프 최적 실험 설계를 가능하게 합니다.
* **아키텍처 단순화**: Cell-DETR은 Mask R-CNN의 비최대 억제(NMS) 및 ROI 풀링과 같은 수작업으로 설계된 구성 요소를 피하여 더 간단한 아키텍처와 적은 파라미터를 가집니다.

## 📎 Related Works

* **일반 인스턴스 분할**: Mask R-CNN [1]은 CNN 백본, 영역 제안, NMS, ROI 풀링 및 다중 예측 헤드를 결합한 제안 기반 인스턴스 분할 모델입니다.
* **어텐션 기반/트랜스포머 방법**: DETR [8]은 최근 팬옵틱 분할을 위해 제안된 어텐션 기반 감지 트랜스포머로, 최첨단 성능을 달성하면서도 비교적 간단한 아키텍처를 가집니다.
* **생의학 분할 (미세구조 내 효모)**:
  * U-Net [6], [19], [24]은 인코더-디코더 아키텍처를 가진 컨볼루션 신경망(CNN)으로, 이전에 미세구조 환경 내 효모의 의미론적 분할에서 최첨단 성능($J_{c} = 0.82$)을 보였습니다.
  * DISCO [16]는 템플릿 매칭, SVM, 활성 윤곽선과 같은 전통적인 방법을 기반으로 한 이전의 최첨단 도구였으나, U-Net에 의해 대체되었습니다. ($J_{c} \sim 0.70$)

## 🛠️ Methodology

1. **데이터셋 구축**:
    * 다양한 실험에서 얻은 419개의 효모 세포 미세유체 트랩 이미지 샘플을 사용했습니다.
    * 세 가지 클래스(효모 세포, 트랩, 배경/객체 없음)로 어노테이션되었으며, 각 인스턴스에는 경계 상자, 클래스, 픽셀 단위 분할 맵이 포함됩니다.
    * 데이터는 훈련(76%), 검증(12%), 테스트(12%) 세트로 분할되었습니다.
2. **Cell-DETR 아키텍처**:
    * 기존 DETR [8] 아키텍처를 비겹침 인스턴스 분할에 맞게 조정하고 추론 속도를 높이기 위해 크기를 줄였습니다. (원본 대비 약 1/10의 파라미터 수)
    * **CNN 인코더 백본**: 입력 이미지에서 특징을 추출합니다 (4개의 ResNet-like 블록).
    * **트랜스포머 인코더-디코더**: 이미지 특징 간의 어텐션을 결정하고 $N=20$개의 객체 쿼리에 대한 어텐션 영역을 예측합니다 (인코더 블록 3개, 디코더 블록 2개). 학습된 위치 인코딩을 사용합니다.
    * **경계 상자 및 클래스 예측 헤드**: 트랜스포머 출력을 경계 상자와 클래스(객체 없음, 트랩, 세포) 예측으로 매핑하는 FFNN입니다.
    * **분할 헤드**: 멀티 헤드 어텐션 메커니즘과 CNN 디코더로 구성됩니다. 비겹침 분할을 위해 모든 쿼리에 대해 소프트맥스를 사용합니다.
    * **Cell-DETR A vs. B**: Cell-DETR A는 Leaky ReLU [28] 활성화 함수와 표준 컨볼루션을 사용하고, Cell-DETR B는 Padé 활성화 함수 [29]와 변형 가능한 컨볼루션(v2) [30], 픽셀 적응형 컨볼루션 [31]을 사용합니다 (표 I 참조).
3. **훈련 과정**:
    * **손실 함수**: 클래스 예측($L_p$), 경계 상자($L_b$), 분할($L_s$) 손실의 가중 합으로 구성된 결합 손실 $L$을 사용하여 종단 간 훈련합니다.
        * $L_p$: 클래스별 가중 교차 엔트로피.
        * $L_b$: 일반화된 Intersection-over-Union ($L_J$) [33] 및 L1 손실의 합.
        * $L_s$: Focal Loss ($L_F$) [34]와 Sørensen-Dice Loss ($L_D$) [6], [8]의 가중 합.
    * **최적화**: AdamW [36] 옵티마이저를 사용했으며, 데이터 증강(탄성 변형, 수평 뒤집기, 노이즈 추가)을 적용했습니다.
4. **평가**:
    * 정량적 분석을 위해 Jaccard index ($J_{k}$), Sørensen-Dice 계수 ($D$), 평균 인스턴스 Jaccard index ($\bar{J}_{I}$), 분류 정확도, 경계 상자 Jaccard index ($J_{b}$)를 사용했습니다.
    * U-Net [6] 및 Mask R-CNN [1]과 비교 평가를 진행했습니다.

## 📊 Results

* **Cell-DETR 변형 모델(A, B) 성능**:
  * Cell-DETR B는 약간 더 나은 분할 성능을 보였습니다 ($\bar{J}_{I} = 0.85$, $J_{c} = 0.84$). 이는 Cell-DETR A ($\bar{J}_{I} = 0.84$, $J_{c} = 0.83$)보다 약간 높습니다.
  * 두 모델 모두 0.96의 높은 분할 정확도를 달성했습니다.
  * 클래스 분류 정확도는 1.0, 경계 상자 $J_{b}$는 0.81로 매우 우수했습니다.
  * Cell-DETR A의 추론 시간은 9.0 ms, Cell-DETR B는 21.2 ms로, 모두 실시간 실험 모니터링에 충분히 빠릅니다.
* **최첨단 방법과의 비교 (Cell-DETR B 기준)**:
  * **세포 클래스 Jaccard index ($J_{c}$)**: Cell-DETR B ($0.84$)는 Mask R-CNN ($0.84$)과 동등했으며, U-Net ($0.82$) 및 DISCO ($\sim0.70$)를 능가했습니다.
  * **추론 시간**:
    * U-Net: 1.8 ms (가장 빠르나 인스턴스 감지를 위한 추가 후처리 필요, 총 ~20 ms).
    * Cell-DETR A: 9.0 ms.
    * Cell-DETR B: 21.2 ms.
    * Mask R-CNN: 29.8 ms.
    * DISCO: $\sim1300$ ms (가장 느림).
  * Cell-DETR B는 Mask R-CNN보다 빠르면서도 유사한 분할 성능을 제공합니다.
* **실제 적용 예시**: Cell-DETR은 명시야 이미지를 기반으로 개별 세포 인스턴스를 감지하고, 그 분할 마스크를 형광 채널에서 개별 세포 형광 측정에 성공적으로 사용될 수 있음을 입증했습니다.

## 🧠 Insights & Discussion

* **Cell-DETR의 장점**: Mask R-CNN과 비교하여 아키텍처가 더 간단하고, 비최대 억제(NMS) 및 ROI 풀링과 같은 수작업으로 설계된 구성 요소를 피합니다. 이는 하이퍼파라미터 의존성을 줄이고 단일 결합 손실 함수로 종단 간 훈련을 용이하게 합니다. 결과적으로 Mask R-CNN보다 구현이 쉽고, 파라미터 수가 적으며, 동일한 분할 성능에 대해 더 빠릅니다.
* **학습 과정 분석**: 분류 손실($L_p$)이 가장 먼저 수렴하여 네트워크가 이미지 내 객체의 수와 클래스를 먼저 학습하고, 이어서 경계 상자 손실($L_b$)이 수렴하여 객체의 대략적인 위치를 학습하며, 마지막으로 분할 손실($L_s$)이 수렴하여 픽셀 단위 분할 맵을 정제하는 방식으로 학습이 진행됨을 확인했습니다.
* **생의학 적용에 대한 중요성**: Cell-DETR은 미세구조 내 효모 세포의 견고하고 반복 가능한 인스턴스 분할을 제공하여 기존 의미론적 분할 방법의 성능을 능가합니다. 또한 개별 객체 인스턴스를 직접 감지하고 거의 100%의 정확도로 분류합니다. 이는 세포 추적을 용이하게 하고, 실험 정보 수율을 높이며, 인간의 개입 없이 Cell-DETR을 사용할 수 있도록 합니다.
* **제한 및 향후 전망**: 현재 모델은 특정 미세유체 구성 및 트랩 형상에 대해 훈련되었습니다. 데이터셋을 확장하여 더 많은 클래스나 트랩 형상을 포함하면 활용도를 넓힐 수 있습니다. 또한 어텐션 메커니즘의 미래 발전을 통합(예: 축 어텐션(axial-attention) [26]으로 CNN 요소를 대체)하여 성능을 더욱 향상시킬 수 있는 플랫폼을 제공합니다. Cell-DETR의 빠른 런타임과 정확한 인스턴스 분할은 약 1000개의 트랩을 사용하는 일반적인 실험에서 온라인 모니터링 및 폐쇄 루프 최적 실험 설계를 가능하게 하여 향후 실험 데이터 수율과 생물학적 통찰력을 크게 높일 잠재력을 가집니다.

## 📌 TL;DR

* **문제**: 생의학 현미경 이미지(특히 미세구조 내 효모 세포)에서 개별 객체 인스턴스를 빠르고 정확하게 분할하는 것은 세포 분석의 주요 병목 현상이었다. 기존 방법은 후처리가 필요하거나 느렸다.
* **제안 방법**: 저자들은 **Cell-DETR**이라는 새로운 어텐션 기반 트랜스포머를 제안하여 생의학 샘플의 직접적인 종단 간 인스턴스 분할을 수행한다. 이는 DETR 아키텍처를 기반으로 하면서 크기를 줄이고 특정 생물학적 활성화 함수와 컨볼루션을 통합하여 최적화되었으며, 하나의 결합된 손실 함수로 종단 간 훈련된다.
* **주요 결과**: Cell-DETR은 미세구조 내 효모 세포에 대해 기존 의미론적 분할 방법을 능가하며, 최첨단 인스턴스 분할 방법인 Mask R-CNN과 동등한 분할 성능($J_{c} = 0.84$)을 달성했다. Mask R-CNN보다 더 간단하고, 적은 파라미터를 가지며, 최대 30% 더 빨랐다. 빠른 추론 시간(9.0ms - 21.2ms)은 온라인 모니터링 및 폐쇄 루프 최적 실험 설계를 가능하게 하여 실험 처리량과 정보 수율을 크게 향상시킨다.
