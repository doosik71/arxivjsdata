# Pixel Recurrent Neural Networks

Aäron van den Oord, Nal Kalchbrenner, Koray Kavukcuoglu

## 🧩 Problem to Solve

자연 이미지의 분포를 모델링하는 것은 비지도 학습의 핵심 문제이며, 이는 표현력 있고(expressive), 다루기 쉬우며(tractable), 확장 가능한(scalable) 이미지 모델을 필요로 합니다. 이미지는 고차원적이고 고도로 구조화되어 있어, 이러한 분포를 추정하는 것은 매우 어렵습니다. 기존의 확률적 잠재 변수 모델(예: VAE)은 종종 다루기 어려운 추론 단계를 수반하거나, 픽셀 간의 복잡한 비선형적이고 장거리 상관관계를 효과적으로 모델링하는 데 한계가 있습니다. 이 연구는 이러한 복잡한 종속성을 완전히 포착하면서도 계산적으로 효율적인 생성 모델을 구축하는 것을 목표로 합니다.

## ✨ Key Contributions

- **새로운 2차원 순환 신경망(RNN) 레이어 설계:** 이미지를 공간적 두 차원에 걸쳐 순차적으로 예측하는 데 효과적인 Row LSTM과 Diagonal BiLSTM을 제안하여, 픽셀 간의 완전한 종속성을 인코딩합니다.
- **마스크드 컨볼루션(Masked Convolutions) 도입:** 픽셀의 순차적 예측과 RGB 색상 채널 간의 종속성을 올바르게 유지하기 위해 컨볼루션 레이어에 마스크를 적용하는 기술을 개발했습니다.
- **잔차 연결(Residual Connections)의 효과적인 사용:** 깊은 RNN에서 훈련을 개선하고 수렴 속도를 높이기 위해 LSTM 레이어 주변에 잔차 연결을 통합했습니다.
- **이산 픽셀 값 모델링:** 픽셀 값을 연속적인 값으로 모델링하는 이전 접근 방식과 달리, 다항 분포(softmax 레이어 사용)를 통해 픽셀을 이산적인 값으로 모델링하여 표현 및 학습 상의 이점을 얻었습니다.
- **PixelCNN 아키텍처 제안:** 고정된 종속성 범위를 가지며 마스크드 컨볼루션을 사용하는 순수 컨볼루션 네트워크인 PixelCNN을 소개하여, 훈련 시 병렬화 이점을 제공합니다.
- **Multi-Scale PixelRNN:** 작은 스케일의 이미지를 먼저 생성한 후, 이를 조건으로 더 큰 스케일의 이미지를 생성하는 멀티-스케일 아키텍처를 제시했습니다.
- **최첨단 성능 달성:** MNIST 및 CIFAR-10 데이터셋에서 이전의 최첨단(state-of-the-art) 결과보다 훨씬 우수한 로그-우도(log-likelihood) 점수를 달성했습니다.
- **ImageNet 벤치마크 제공:** 대규모 ImageNet 데이터셋(32x32 및 64x64 픽셀)에 대한 생성 모델의 로그-우도 벤치마크를 처음으로 제시했습니다.
- **고품질 이미지 샘플 및 완성:** 모델에서 생성된 샘플 이미지가 선명하고 다양하며 전역적으로 일관성이 있음을 보여주며, 이미지 완성(inpainting) 작업에서도 높은 품질을 달성했습니다.

## 📎 Related Works

- **생성 모델:** 확률적 잠재 변수 모델 (예: VAE, Kingma & Welling, 2013; Rezende et al., 2014), 자기회귀 모델 (예: NADE, Larochelle & Murray, 2011), 완전 가시 신경망 (Neal, 1992; Bengio & Bengio, 2000).
- **순환 신경망 (RNN):** 필기체 생성 (Graves, 2013), 문자 예측 (Sutskever et al., 2011), 기계 번역 (Kalchbrenner & Blunsom, 2013) 등 다양한 순차 문제에서 뛰어난 성능을 보였습니다.
- **2차원 RNN:** 회색조 이미지 및 텍스처 모델링 (Theis & Bethge, 2015)에 적용되었습니다.
- **LSTM 유닛:** Hochreiter & Schmidhuber, 1997; Graves & Schmidhuber, 2009.
- **잔차 연결:** 깊은 네트워크 훈련에 효과적임이 입증됨 (He et al., 2015).
- **마스크드 자기회귀 모델:** MADE (Germain et al., 2015)와 같은 비컨볼루션 모델에서 마스크를 사용한 예시가 있습니다.
- **깊은 RNN에서의 게이팅:** Kalchbrenner et al., 2015; Zhang et al., 2016.
- **생성 모델 평가:** 연속 및 이산 분포 모델의 로그-우도 비교 방법 (Theis et al., 2015).

## 🛠️ Methodology

1. **픽셀 단위 이미지 생성:**

   - 이미지 $x$의 결합 분포 $p(x)$를 픽셀 단위 조건부 분포의 곱으로 분해합니다: $p(x) = \prod_{i=1}^{n^2} p(x_i | x_1, ..., x_{i-1})$. 여기서 $x_i$는 이전에 생성된 모든 픽셀 $x_1, ..., x_{i-1}$에 조건화됩니다.
   - 각 픽셀 $x_i$는 RGB 세 개의 채널로 구성되며, 각 채널은 다른 채널과 이전에 생성된 픽셀에 조건화됩니다: $p(x_{i,R}|x_{\lt i})p(x_{i,G}|x_{\lt i},x_{i,R})p(x_{i,B}|x_{\lt i},x_{i,R},x_{i,G})$.
   - 픽셀 값은 256개의 이산 값 중 하나를 가지는 것으로 모델링되며, softmax 레이어를 통해 다항 분포로 출력됩니다.

2. **PixelRNN 아키텍처:**

   - **Row LSTM:**
     - 이미지를 위에서 아래로 행(row) 단위로 처리합니다.
     - 각 행에 대한 특징을 $k \times 1$ 크기의 1D 컨볼루션을 사용하여 한 번에 계산합니다.
     - 대략 삼각형 형태의 수용 필드를 가집니다 (현재 픽셀의 위쪽 및 왼쪽 컨텍스트).
     - LSTM 셀의 인풋-스테이트(input-to-state) 및 스테이트-스테이트(state-to-state) 컴포넌트에 컨볼루션을 적용합니다.
   - **Diagonal BiLSTM:**
     - 계산 병렬화와 전체 이미지 크기에 대한 완전한 컨텍스트 캡처를 위해 설계되었습니다.
     - 입력 맵을 대각선 방향으로 컨볼루션이 용이하도록 각 행을 한 칸씩 오프셋하여 기울입니다(skew).
     - 각 방향에서 $1 \times 1$ 컨볼루션(인풋-스테이트)과 $2 \times 1$ 열 방향 컨볼루션(스테이트-스테이트)을 사용하여 LSTM 상태를 대각선을 따라 한 번에 계산합니다.
     - 두 방향의 출력 맵을 결합하여 미래 픽셀을 보지 않도록 처리합니다.

3. **PixelCNN 아키텍처:**

   - 표준 컨볼루션 레이어를 사용하여 유한한(bounded) 수용 필드를 캡처합니다.
   - 풀링 레이어 없이 입력의 공간 해상도를 유지하며, 각 위치에서 조건부 분포를 출력합니다.
   - 미래 컨텍스트를 보지 않도록 마스크드 컨볼루션을 사용합니다.
   - 훈련 및 테스트 이미지 평가 시 PixelRNN에 비해 병렬화 이점을 가집니다 (이미지 생성은 여전히 순차적).

4. **Multi-Scale PixelRNN:**

   - 비조건부 PixelRNN으로 작은 $s \times s$ 스케일의 이미지를 생성합니다.
   - 조건부 PixelRNN은 생성된 $s \times s$ 이미지를 업샘플링하여 추가 입력(바이어스)으로 받아 더 큰 $n \times n$ 이미지를 생성합니다.

5. **공통 구성 요소:**
   - **Masked Convolutions (마스크드 컨볼루션):**
     - **Mask A:** 첫 번째 컨볼루션 레이어에 적용되며, 현재 픽셀의 이전에 예측된 채널과 인접 픽셀에만 연결을 허용합니다 (현재 픽셀의 자신의 채널에는 연결 안 됨).
     - **Mask B:** 이후의 모든 인풋-스테이트 컨볼루션에 적용되며, Mask A의 제한을 완화하여 현재 픽셀의 자신의 채널에도 연결을 허용합니다.
   - **Residual Connections (잔차 연결):** 깊은 네트워크에서 훈련을 안정화하고 신호 전파를 개선하기 위해 한 LSTM 레이어에서 다음 LSTM 레이어로 잔차 연결을 사용합니다.
   - **Discrete Softmax Output (이산 소프트맥스 출력):** 각 RGB 채널의 256개 이산 값에 대한 확률을 출력하기 위해 소프트맥스 레이어를 사용합니다.

## 📊 Results

- **MNIST:** Diagonal BiLSTM 모델은 79.20 nats의 음의 로그-우도(Negative Log-Likelihood)를 달성하여 이전 최첨단 (80.97 nats)을 능가했습니다.
- **CIFAR-10:**
  - Diagonal BiLSTM: 3.00 bits/dim으로 최고의 성능을 기록했습니다.
  - Row LSTM: 3.07 bits/dim.
  - PixelCNN: 3.14 bits/dim.
  - 모든 모델이 이전 최첨단 (RIDE의 3.47 bits/dim)을 크게 개선했으며, 수용 필드가 넓을수록 성능이 향상됨을 보여주었습니다.
- **ImageNet:** 32x32 이미지에 대해 3.86 bits/dim, 64x64 이미지에 대해 3.63 bits/dim의 새로운 벤치마크를 제공했습니다.
- **이산 Softmax 분포의 효과:** Row LSTM 모델에서 이산 Softmax를 사용했을 때 (3.06 bits/dim) 연속 분포인 MCGSM (3.22 bits/dim)보다 더 좋은 성능을 보였습니다.
- **잔차 연결의 효과:** 12-레이어 Row LSTM 모델에서 잔차 연결을 사용했을 때 (3.07 bits/dim) 사용하지 않았을 때 (3.22 bits/dim)보다 성능이 향상되었으며, 깊이 증가에 따라 성능 개선이 지속되었습니다.
- **정성적 결과:**
  - 모델에서 생성된 샘플 이미지는 선명하고 다양하며 전역적으로 일관성이 있었습니다.
  - Multi-Scale 모델은 64x64 ImageNet 이미지에서 전역적 구조를 더 잘 포착하여, 단일 스케일 모델보다 시각적으로 더 일관성 있는 샘플을 생성했습니다.
  - 이미지 완성(Image Completion) 예시에서는 모델이 높은 다양성과 함께 물, 나무와 같은 복잡한 질감을 사실적으로 재현하는 능력을 보여주었습니다.

## 🧠 Insights & Discussion

- **자기회귀 모델의 잠재력:** 이 연구는 자연 이미지의 복잡한 픽셀 분포를 모델링하는 데 있어 자기회귀(autoregressive) 접근 방식의 강력한 잠재력을 입증했습니다. 특히, 2차원 RNN을 통해 모든 픽셀 간의 종속성을 효과적으로 포착할 수 있음을 보여주었습니다.
- **아키텍처 설계의 중요성:** Row LSTM 및 Diagonal BiLSTM과 같은 혁신적인 2D RNN 레이어는 픽셀 간의 장거리 및 지역적 상관관계를 모두 모델링하는 데 필수적입니다. 넓은 수용 필드를 가진 Diagonal BiLSTM이 가장 뛰어난 성능을 보인다는 점은 이미지의 전역적 구조 이해가 중요함을 시사합니다.
- **이산 분포의 이점:** 픽셀 값을 이산 변수로 모델링하고 소프트맥스 출력을 사용하는 것이 연속 분포에 비해 더 간단한 구현과 우수한 성능을 제공하며, 다중 모달 분포를 자연스럽게 표현하고 [0, 255] 범위를 벗어나는 문제를 회피할 수 있게 합니다.
- **깊이의 중요성과 잔차 연결:** 깊은 네트워크가 더 나은 성능을 달성할 수 있음을 확인했으며, 잔차 연결은 이러한 깊은 RNN 모델의 훈련 안정성을 높이고 수렴을 가속화하는 데 결정적인 역할을 합니다.
- **확장성 및 미래 전망:** 모델이 커질수록 성능이 지속적으로 향상되는 경향을 보이며, 활용 가능한 무한한 이미지 데이터를 고려할 때, 더 많은 계산 자원과 더 큰 모델을 통해 추가적인 성능 개선이 가능할 것으로 예상됩니다. 현재 모델 크기의 주요 제약은 계산 시간과 GPU 메모리입니다.
- **생성 속도:** 훈련 및 평가 시 병렬화가 가능하지만, 이미지 생성 과정은 본질적으로 픽셀 단위로 순차적이라는 한계가 있습니다.

## 📌 TL;DR

이 논문은 자연 이미지의 생성 모델링을 위한 Pixel Recurrent Neural Networks (PixelRNNs)를 제안합니다. 이미지 픽셀의 복잡한 분포를 표현력 있고, 다루기 쉬우며, 확장 가능한 방식으로 모델링하는 것이 주요 과제입니다. 저자들은 Row LSTM 및 Diagonal BiLSTM과 같은 새로운 2차원 RNN 레이어를 도입하고, 마스크드 컨볼루션과 잔차 연결을 사용하여 깊은 네트워크의 훈련을 개선했습니다. 픽셀 값은 이산적인 값으로 모델링되며 softmax 출력을 통해 예측됩니다. 이 모델은 MNIST와 CIFAR-10 데이터셋에서 이전 최첨단 성능을 크게 뛰어넘었으며, ImageNet 데이터셋에 대한 새로운 벤치마크를 제공했습니다. PixelRNNs는 시각적으로 선명하고, 다양하며, 전역적으로 일관성 있는 이미지를 생성하여 지역적 및 장거리 공간 종속성을 효과적으로 학습했음을 입증합니다.
