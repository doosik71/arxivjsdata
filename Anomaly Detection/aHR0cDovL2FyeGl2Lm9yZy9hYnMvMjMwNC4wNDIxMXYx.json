{
  "title": "AGAD: Adversarial Generative Anomaly Detection",
  "authors": "Jian Shi, Ni Zhang",
  "year": 2023,
  "url": "http://arxiv.org/abs/2304.04211v1",
  "abstract": "Anomaly detection suffered from the lack of anomalies due to the diversity of\nabnormalities and the difficulties of obtaining large-scale anomaly data.\nSemi-supervised anomaly detection methods are often used to solely leverage\nnormal data to detect abnormalities that deviated from the learnt normality\ndistributions. Meanwhile, given the fact that limited anomaly data can be\nobtained with a minor cost in practice, some researches also investigated\nanomaly detection methods under supervised scenarios with limited anomaly data.\nIn order to address the lack of abnormal data for robust anomaly detection, we\npropose Adversarial Generative Anomaly Detection (AGAD), a self-contrast-based\nanomaly detection paradigm that learns to detect anomalies by generating\n\\textit{contextual adversarial information} from the massive normal examples.\nEssentially, our method generates pseudo-anomaly data for both supervised and\nsemi-supervised anomaly detection scenarios. Extensive experiments are carried\nout on multiple benchmark datasets and real-world datasets, the results show\nsignificant improvement in both supervised and semi-supervised scenarios.\nImportantly, our approach is data-efficient that can boost up the detection\naccuracy with no more than 5% anomalous training data.",
  "citation": 1
}