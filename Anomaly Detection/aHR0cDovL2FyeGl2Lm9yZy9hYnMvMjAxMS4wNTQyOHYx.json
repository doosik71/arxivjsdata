{
  "title": "Self-Supervised Out-of-Distribution Detection in Brain CT Scans",
  "authors": "Abinav Ravi Venkatakrishnan, Seong Tae Kim, Rami Eisawy, Franz Pfister, Nassir Navab",
  "year": 2020,
  "url": "http://arxiv.org/abs/2011.05428v1",
  "abstract": "Medical imaging data suffers from the limited availability of annotation\nbecause annotating 3D medical data is a time-consuming and expensive task.\nMoreover, even if the annotation is available, supervised learning-based\napproaches suffer highly imbalanced data. Most of the scans during the\nscreening are from normal subjects, but there are also large variations in\nabnormal cases. To address these issues, recently, unsupervised deep anomaly\ndetection methods that train the model on large-sized normal scans and detect\nabnormal scans by calculating reconstruction error have been reported. In this\npaper, we propose a novel self-supervised learning technique for anomaly\ndetection. Our architecture largely consists of two parts: 1) Reconstruction\nand 2) predicting geometric transformations. By training the network to predict\ngeometric transformations, the model could learn better image features and\ndistribution of normal scans. In the test time, the geometric transformation\npredictor can assign the anomaly score by calculating the error between\ngeometric transformation and prediction. Moreover, we further use\nself-supervised learning with context restoration for pretraining our model. By\ncomparative experiments on clinical brain CT scans, the effectiveness of the\nproposed method has been verified.",
  "citation": 21
}