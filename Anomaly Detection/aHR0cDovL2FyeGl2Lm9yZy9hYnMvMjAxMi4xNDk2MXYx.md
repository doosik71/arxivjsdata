# Towards Fair Deep Anomaly Detection

Hongjing Zhang, Ian Davidson

## 🧩 Problem to Solve

이상 감지는 데이터 과학의 근본적인 문제이며, 최근 딥러닝 기반 이상 감지 방법론들은 특히 복잡한 데이터에서 뛰어난 성능을 보였습니다. 본 연구는 정상 샘플로부터만 매핑을 학습하는 딥 원-클래스 분류 기반 이상 감지(Deep SVDD)에 초점을 맞춥니다. 그러나 딥러닝이 수행하는 비선형 변환은 잠재적으로 사회적 편향과 관련된 패턴을 찾아낼 수 있습니다. 민감 속성(예: 성별, 인종)과 관련된 편향된 예측을 생성하여 특정 보호 그룹에 불균형한 수의 이상치를 할당하는 것이 그 예입니다. 딥 이상 감지에 공정성을 추가하는 주요 과제는 **공정하고 정확한 이상 예측을 동시에 보장**하는 것입니다.

## ✨ Key Contributions

- 기존 딥 이상 감지(Deep Anomaly Detection) 접근 방식이 복잡한 특징을 추출하는 딥러너의 능력 때문에 불공정한 결과를 초래함을 입증했습니다.
- 딥 표현 학습(Deep Representation Learning) 맥락에서 공정한 이상 감지(Fair Anomaly Detection) 문제를 다루었으며, 공정하면서도 고품질의 예측이 동시에 필요하다는 점 때문에 이 분야가 아직 충분히 연구되지 않았고 도전적임을 강조했습니다.
- 이러한 과제를 해결하기 위해 새로운 공정 이상 감지 아키텍처(Deep Fair SVDD)를 제안하고, 적대적 학습(Adversarial Learning)을 사용하여 불공정성을 제거했습니다. 이는 공정성을 정규화 항이나 제약 조건으로 인코딩하는 기존 방식과 차별화됩니다.
- 딥 이상 감지 문제에 대한 두 가지 효과적인 그룹 수준 공정성 측정 지표를 제안했습니다:
  - 이상 그룹에 대한 인구통계학적 동등성(Demographic Parity)에서 영감을 받은 공정성 측정 ($p\%$-rule, 수식 3).
  - 전체적인 공정성을 계산하기 위한 Wasserstein 거리 기반의 매개변수 없는 측정 지표 (수식 4).
- 제안된 방법이 전통적인 테이블형 데이터셋, 얼굴 데이터셋, 숫자 이미지 등 여러 유형의 데이터셋에서 효과적임을 시연했으며, 이상 감지 성능(AUC 점수)에 미미한 손실만으로 불공정성을 크게 줄일 수 있음을 보여주었습니다.
- 매개변수 분석, 특징 시각화, 런타임 분석을 포함하여 제안된 모델의 강점과 한계를 심층적으로 분석했습니다.

## 📎 Related Works

- **딥 이상 감지 (Deep Anomaly Detection):** 재구성 기반(예: Autoencoder [1, 10, 24, 27, 31, 35, 42]), GAN 기반(예: AnoGAN [14, 36, 44]), Deep SVDD [33], 자기 지도 학습 기반(예: 이미지 회전 예측 [19, 20, 25, 41]) 등의 다양한 딥러닝 기법들이 이상 감지 성능 향상에 초점을 맞추어 왔습니다.
- **이상 감지의 공정성 (Fairness in Anomaly Detection):** 기존 딥 이상 감지 알고리즘의 공정성을 감사하는 연구 [13]와 LOF(Local Outlier Factor) [6] 같은 비-딥 방법론의 공정성 문제를 연구하고 완화하는 연구 [15]가 있었지만, 딥 이상 감지 알고리즘의 공정성을 다룬 선행 연구는 없었습니다.
- **공정성을 위한 적대적 학습 (Adversarial Learning for Fairness):** 적대적 네트워크를 활용하여 불공정성을 제거하는 연구들로, 급여 예측의 통계적 동등성 확보 [4], 지도 학습 및 단어 임베딩 편향 제거 [45], 텍스트 데이터에서 인구 통계 속성 유출 완화 [17], 단어 벡터 감성 편향 감소 [40] 등이 있습니다.

## 🛠️ Methodology

본 논문은 딥 이상 감지 문제에 대한 공정한 설명을 학습하는 Deep Fair SVDD 모델을 제안합니다. 이 모델은 적대적 학습을 통해 정상 데이터의 압축되고 공정한 표현을 학습합니다.

1. **가정**: 훈련 데이터 $X$는 정상 인스턴스만 포함하며, 각 훈련 인스턴스에 대한 이진 보호 상태 변수 $Z$에 접근 가능하다고 가정합니다.

2. **아키텍처**:

   - **인코더 네트워크 $f(\theta)$**: 입력 데이터 $X$를 저차원 임베딩 공간으로 매핑하는 신경망입니다. 목표는 모든 정상 데이터를 미리 정해진 중심 $c$에 가깝게 클러스터링하는 것입니다. 이 과정은 다음 $L_{SVDD}$ 손실 함수를 최소화하여 수행됩니다.
     $$ L*{SVDD} = \frac{1}{M} \sum*{i=1}^{M} ||f(\mathbf{x}_i; \theta) - c||^2 + \frac{\alpha}{2} \sum_{l=1}^{L} ||\theta_l||^2 $$
        여기서 $M$은 훈련 인스턴스의 수, $\mathbf{x}_i$는 $i$-번째 인스턴스, $\theta$는 인코더의 매개변수, $c$는 미리 정해진 데이터 중심, $\alpha$는 가중치 감쇠(weight decay) 하이퍼파라미터, $\theta_l$은 $l$-번째 레이어의 가중치입니다.

   - **분별자 네트워크 $g(\theta_d)$**: 인코더 $f(\theta)$에 의해 학습된 임베딩 $f(X; \theta)$를 기반으로 보호 상태 변수 $Z$의 값을 분류하는 네트워크입니다. $Z$가 이진 변수이므로 시그모이드 함수와 교차 엔트로피 손실을 사용하여 훈련됩니다.
     $$ L*D = -\frac{1}{M} \sum*{i=1}^{M} (z_i \cdot \log(\hat{z}\_i) + (1 - z_i) \cdot \log(1 - \hat{z}\_i)) $$
        여기서 $z_i$는 실제 보호 상태, $\hat{z}_i$는 예측된 보호 상태, $\theta_d$는 분별자의 매개변수입니다.

3. **적대적 학습**:

   - 학습된 임베딩 $f(X; \theta)$가 민감 속성 $Z$와 통계적으로 독립되도록 ($\mathrm{p}(f(X; \theta)|z=0) = \mathrm{p}(f(X; \theta)|z=1)$), 인코더 $f(\theta)$는 분별자 $g(\theta_d)$를 속이도록 훈련됩니다.
   - 이를 위해 적대적 손실 $L_{Adv}$가 정의됩니다.
     $$ L*{Adv} = L*{SVDD} - \lambda L*D $$
        여기서 $\lambda$는 양수 하이퍼파라미터로, 분별자 손실 항의 가중치를 조절합니다. $L*{Adv}$를 최소화하는 것은 $L_{SVDD}$를 최소화하면서 동시에 $L_D$를 최대화하는 것과 같습니다 (분별자를 속이는 것).
   - **교대 최적화**: 인코더와 분별자는 미니맥스(min-max) 솔루션을 찾을 때까지 교대로 훈련됩니다.
     - 분별자 $g(\theta_d)$의 매개변수를 고정하고, 인코더 $f(\theta)$를 $L_{SVDD} - \lambda L_D$를 최소화하도록 훈련합니다.
     - 인코더 $f(\theta)$의 매개변수를 고정하고, 분별자 $g(\theta_d)$를 $L_D$를 최소화하도록 훈련합니다.

4. **이상 점수 계산**: 훈련이 수렴하면, 테스트 인스턴스 $\mathbf{x}$에 대한 이상 점수는 다음과 같이 계산됩니다.
   $$ S(\mathbf{x}) = ||f(\mathbf{x}; \theta) - c||^2 $$
   이상 점수가 클수록 이상치일 확률이 높습니다.

5. **공정성 측정 지표**:
   - **Fairness by $p\%$-rule**: 특정 임계값 $t$를 기준으로 이상치로 분류된 인스턴스($s(\mathbf{x}) > t$) 내에서 보호 상태 변수 $z=0$과 $z=1$ 그룹의 비율을 비교합니다. 0에서 1 사이의 값을 가지며, 1에 가까울수록 공정합니다. 이는 이상 그룹의 공정성을 측정합니다.
     $$ \min\left(\frac{P(s(\mathbf{x})>t|z=1)}{P(s(\mathbf{x})>t|z=0)}, \frac{P(s(\mathbf{x})>t|z=0)}{P(s(\mathbf{x})>t|z=1)}\right) \ge \frac{p}{100} $$
   - **Fairness by distribution distance**: 이상 점수 임계값 $t$에 독립적으로, 보호 상태 변수 $z=0$과 $z=1$에 대한 이상 점수 분포 $P$와 $Q$ 사이의 Wasserstein-1 거리(Earth-Mover Distance)를 계산하여 전체적인 공정성을 측정합니다. 이 값이 작을수록 공정합니다.
     $$ W(P,Q) = \inf*{\gamma \in \Pi(P,Q)} E*{(\mathbf{x},\mathbf{y}) \sim \gamma}[||\mathbf{x}-\mathbf{y}||] $$

## 📊 Results

- **기존 딥 이상 감지 알고리즘의 불공정성**: Deep SVDD와 DCAE는 원본 및 균형 잡힌 훈련 세트 모두에서 상당한 불공정성을 보였습니다. 특히, 대부분의 경우 미국 평등고용기회위원회(EEOC)가 권장하는 $80\%$-rule을 충족하지 못했습니다. 균형 잡힌 훈련 세트를 사용하더라도 공정성 개선은 미미한 수준에 그쳤습니다.
- **Deep Fair SVDD의 공정성 및 성능**:
  - **공정성**: Deep Fair SVDD는 모든 4개 데이터셋(COMPAS, celebA, MNIST-Invert, MNIST-USPS)에서 Deep SVDD 및 DCAE보다 훨씬 우수한 공정성을 달성했습니다. $p\%$-rule 지표는 $80\%$ 규칙을 만족했으며, 분포 거리 지표 또한 더 낮은 값을 보여 전반적인 공정성 향상을 입증했습니다.
  - **이상 감지 성능(AUC)**: Deep Fair SVDD는 공정성을 크게 향상시키면서도 이상 감지 성능(AUC)에서 최소한의 손실을 보였습니다. 특히 celebA 데이터셋에서는 공정성 제약이 오히려 AUC를 약간 향상시키는 결과(0.570 -> 0.585)를 보였습니다.
- **공정성-성능 트레이드오프**: 하이퍼파라미터 $\lambda$ 값 증가에 따라 $p\%$-rule 공정성은 증가하는 경향을 보였습니다. 대부분의 데이터셋에서 AUC 점수는 $\lambda$ 증가에 따라 약간 감소했지만, celebA에서는 $\lambda$ 증가 시 $p\%$-rule과 AUC 모두 증가하여 공정성 제약이 성능에 긍정적인 영향을 미칠 수 있음을 시사했습니다.
- **이상 예측 분석**: Deep SVDD와 Deep Fair SVDD의 이상 예측 사이에는 높은 오버랩 비율(0.70-0.82)이 관찰되었습니다. Deep Fair SVDD는 비-오버랩 인스턴스 분석을 통해 "이상으로 분류되기 쉬운" 인스턴스를 이상 그룹으로 이동시키고, "정상으로 분류되기 쉬운" 인스턴스를 정상 그룹으로 이동시키는 방식으로 공정성을 향상시키는 것으로 나타났습니다.
- **임베딩 시각화**: t-SNE를 이용한 임베딩 시각화 결과, Deep SVDD는 특정 보호 상태 변수에 의해 지배되는 영역을 보였으나, Deep Fair SVDD는 보호 상태 변수와 독립적으로 잘 혼합된 임베딩을 학습하여 공정한 표현을 생성했음을 시각적으로 입증했습니다.
- **런타임 분석**: 적대적 학습의 미니맥스 최적화 과정으로 인해 Deep Fair SVDD의 훈련 시간은 Deep SVDD보다 더 길었습니다.

## 🧠 Insights & Discussion

본 연구는 딥 이상 감지 모델이 민감 속성과 관련된 사회적 편향을 학습하여 불공정한 예측을 할 수 있다는 중요한 문제점을 제기하고, 이를 해결하기 위한 효과적인 접근 방식인 Deep Fair SVDD를 제시합니다. 핵심적인 통찰은 적대적 학습을 통해 민감 속성과 통계적으로 독립적인 특징 표현을 학습함으로써, 이상 감지 성능의 최소한의 손실로 공정성을 크게 향상시킬 수 있다는 것입니다. 이는 공정성이 단순히 부가적인 제약이 아니라 모델의 견고성과 신뢰성을 높이는 데 기여할 수 있음을 시사합니다. 특히, CelebA 데이터셋에서 공정성 제약이 오히려 이상 감지 성능을 개선한 사례는, 특정 상황에서 공정성 학습이 유용한 추가 정보를 제공할 수 있음을 보여줍니다.

이 연구의 한계점은 그룹 수준 공정성(group-level fairness)에 초점을 맞추고 단일 이진 보호 상태 변수에 국한했다는 점입니다. 개별 수준 공정성(individual-level fairness)이나 다중 보호 상태 변수, 다중 상태 변수를 고려하는 복잡한 시나리오에서는 추가적인 연구가 필요합니다. 또한, 적대적 학습으로 인한 훈련 시간 증가 문제도 해결해야 할 과제입니다. 향후 연구는 다중 보호 상태 변수, 반지도 이상 감지 설정으로의 확장, 훈련 효율성 및 확장성 개선에 집중될 수 있습니다.

## 📌 TL;DR

딥 이상 감지 모델이 사회적 편향을 학습하여 불공정한 예측을 할 수 있으며, 공정성과 정확도를 동시에 달성하는 것이 어렵다는 문제를 해결하기 위해, 본 연구는 새로운 **Deep Fair SVDD** 모델을 제안합니다. 이 모델은 Deep SVDD 아키텍처에 **적대적 학습**을 통합하여, 학습된 임베딩이 민감 속성(예: 성별, 인종)과 통계적으로 독립되도록 강제합니다. 제안된 두 가지 공정성 측정 지표($p\%$-rule과 분포 거리)를 통해, 기존 딥 이상 감지 모델이 불공정하다는 것을 입증하고, Deep Fair SVDD가 **이상 감지 성능의 최소한의 손실로 공정성을 크게 향상**시킴을 다양한 데이터셋에서 보여주었습니다. 이는 적대적 학습을 통해 민감 속성과 무관한 공정한 특징 표현을 학습함으로써 달성됩니다.
