{
  "title": "ADTR: Anomaly Detection Transformer with Feature Reconstruction",
  "authors": "Zhiyuan You, Kai Yang, Wenhan Luo, Lei Cui, Yu Zheng, Xinyi Le",
  "year": 2022,
  "url": "http://arxiv.org/abs/2209.01816v3",
  "abstract": "Anomaly detection with only prior knowledge from normal samples attracts more\nattention because of the lack of anomaly samples. Existing CNN-based pixel\nreconstruction approaches suffer from two concerns. First, the reconstruction\nsource and target are raw pixel values that contain indistinguishable semantic\ninformation. Second, CNN tends to reconstruct both normal samples and anomalies\nwell, making them still hard to distinguish. In this paper, we propose Anomaly\nDetection TRansformer (ADTR) to apply a transformer to reconstruct pre-trained\nfeatures. The pre-trained features contain distinguishable semantic\ninformation. Also, the adoption of transformer limits to reconstruct anomalies\nwell such that anomalies could be detected easily once the reconstruction\nfails. Moreover, we propose novel loss functions to make our approach\ncompatible with the normal-sample-only case and the anomaly-available case with\nboth image-level and pixel-level labeled anomalies. The performance could be\nfurther improved by adding simple synthetic or external irrelevant anomalies.\nExtensive experiments are conducted on anomaly detection datasets including\nMVTec-AD and CIFAR-10. Our method achieves superior performance compared with\nall baselines."
}