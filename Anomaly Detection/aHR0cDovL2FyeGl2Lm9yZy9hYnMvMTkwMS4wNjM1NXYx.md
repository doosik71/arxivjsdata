# Robust Anomaly Detection in Images using Adversarial Autoencoders

Laura Beggel, Michael Pfeiffer, Bernd Bischl

## 🧩 Problem to Solve

이미지 기반 이상 탐지(Anomaly Detection)는 시각 품질 검사, 감시 또는 의료 영상 분석과 같은 실제 적용 분야에서 매우 중요합니다. 오토인코더(Autoencoder, AE)는 정상 이미지를 재구성하도록 학습하여 재구성 오차가 특정 임계값을 초과하는 이미지를 이상으로 분류합니다. 그러나 이 접근 방식은 훈련 데이터에 소량의 이상치(outliers)가 포함되어 있을 때 심각한 문제에 직면합니다. 오토인코더를 계속 훈련하면 필연적으로 이상치의 재구성 오차가 줄어들어 이상 탐지 성능이 저하됩니다.

## ✨ Key Contributions

- **잠재 공간의 결합 기준:** 적대적 오토인코더(Adversarial Autoencoders, AAE)를 사용하여 잠재 표현에 사전 분포를 부여하고, 재구성 오차($L(x, x')$)와 잠재 공간 내 가능도($p(f(x))$)를 결합한 새로운 이상 점수 기준을 제안합니다. 이는 이상치가 낮은 가능도를 가질 것으로 예상되는 점을 활용하여 탐지 성능을 향상시킵니다.
- **훈련 샘플 거부를 위한 반복적 정제 방법(ITSR):** 훈련 세트에 있는 잠재적 이상치를 저차원 잠재 공간에서 1-클래스 SVM(1-class SVM) 변형을 통해 식별하고, 비정상적인 관측치를 제거함으로써 오염된 데이터에 대한 견고성을 높이는 방법을 제시합니다.
- **재훈련 방법:** 잠재 공간과 이미지 공간 모두에서 분리도를 높이는 재훈련 방법을 제안합니다. 이는 훈련 중 존재하는 이상치에 대해 오토인코더 기반 이상 탐지기의 견고성을 크게 향상시킵니다.

## 📎 Related Works

- **오토인코더(AE):** 비선형 차원 축소 및 특징 추출(Hinton & Salakhutdinov, 2006)에 사용되었으며, 훈련 데이터 분포 모델링 능력이 이상 탐지에 적합함(Japkowicz et al., 1995)이 인식되었습니다.
- **정규화된 오토인코더:** 디노이징 오토인코더(Denoising Autoencoders, Vincent et al., 2008)는 노이즈가 손상된 입력에서 이미지를 재구성하는 법을 학습하며, 재구성 오차와 데이터 생성 밀도 간의 연관성이 확립되었습니다(Alain & Bengio, 2014; Bengio et al., 2013).
- **심층 구조 에너지 기반 모델(Deep Structured Energy Based Models):** 에너지 점수를 기반으로 한 이상 탐지 기준이 재구성 오차보다 우수함이 입증되었습니다(Zhai et al., 2016).
- **적대적 오토인코더(AAE):** 재구성 오차와 적대적 훈련 기준(Goodfellow et al., 2014)을 결합하여 입력 데이터의 생성 모델을 학습합니다(Makhzani et al., 2015). AAE를 이상 탐지에 처음 적용한 연구(Leveau & Joly, 2017)에서는 가우시안 혼합 모델을 사전 분포로 사용했습니다.
- **견고한 오토인코더:** 견고한 심층 오토인코더(Robust deep autoencoders, Zhou & Paffenroth, 2017)는 디노이징 오토인코더와 견고한 PCA(Robust PCA)를 결합하여 훈련 중 이상치 문제에 대응합니다.
- **심층 학습 및 커널 기반 방법:** 딥 빌리프 네트워크(Deep Belief Network)와 1-클래스 SVM을 결합하여 고차원 데이터의 이상 탐지를 수행하는 방법이 제안되었습니다(Erfani et al., 2016).

## 🛠️ Methodology

본 연구는 적대적 오토인코더(AAE)를 기반으로 훈련 세트의 이상치에 대한 견고성을 향상시키는 **반복적 훈련 세트 정제(Iterative Training Set Refinement, ITSR)** 방법을 제안합니다.

1. **AAE 기반 이상 탐지 점수:**

   - AAE는 잠재 표현 $z$에 사전 분포 $p(z)$를 부여하여 정상 및 이상치 인스턴스를 잠재 공간에서 분리하는 데 도움을 줍니다.
   - 새로운 예시 $y$는 다음 두 기준 중 하나라도 만족하면 이상치로 분류됩니다: $L(y,y') > T_{\text{rec}}$ 또는 $p(f(y)) < T_{\text{prior}}$.
     - $L(y,y')$는 재구성 오차를 나타냅니다.
     - $p(f(y))$는 잠재 표현 $f(y)$가 사전 분포 $p(z)$ 하에서 가질 가능도를 나타냅니다.
     - $T_{\text{rec}}$는 훈련 세트 재구성 오차의 $90$번째 백분위수입니다.
     - $T_{\text{prior}}$는 훈련 세트 가능도의 $10$번째 백분위수입니다.

2. **반복적 훈련 세트 정제 (ITSR) 절차:** 훈련 과정을 세 단계로 나눕니다.
   - **사전 훈련(Pretraining):** AAE를 완전한 훈련 세트에 대해 고정된 에포크 수만큼 훈련합니다. 이때 모든 훈련 샘플 $x_i$에는 동일한 가중치 $w_i = 1$이 부여됩니다.
   - **탐지 및 정제(Detection and Refinement):**
     - 훈련 데이터의 잠재 표현에 1-클래스 SVM(RBF 커널 사용, $\nu = 0.02$)을 적용하여 이상치 후보 $\hat{A}$를 식별합니다.
     - $\hat{A}$에 속하는 모든 인스턴스에는 새로운 가중치 $w_i = 0$이 할당되어 이후 훈련에서 제외됩니다.
     - 모델은 축소된 훈련 세트 $X \setminus \hat{A}$에 대해 짧은 에포크 수만큼 다시 훈련됩니다.
     - 이 두 단계는 $d$회(예: $d=10$) 반복됩니다.
   - **재훈련(Re-training):**
     - 탐지된 이상치 후보에 대해 재구성 오차가 증가하도록 모델을 재훈련합니다.
     - $L(x_i, f(g(x_i))) > T_{\text{retrain}}$를 만족하는 $x_i \in \hat{A}$에 대해 가중치 $w_i$를 음수($w_{\text{anomaly}} < 0$)로 설정하여 해당 이상치 재구성을 강제로 악화시킵니다.
     - $T_{\text{retrain}}$은 $\hat{A}$ 내 재구성 오차의 $80$번째 백분위수($p_{0.8}(L(x, f(g(x))) | x \in \hat{A})$)로 설정됩니다.

## 📊 Results

- **향상된 균형 정확도(BAcc):** ITSR 모델은 훈련 세트에 5%의 이상치가 포함된 모든 시나리오(MNIST 및 Fashion-MNIST)에서 표준 오토인코더(AE) 및 적대적 오토인코더(AAE)보다 더 나은 균형 정확도를 보였습니다.
  - MNIST 실험에서 ITSR은 기존 AE에 비해 BAcc를 30% 이상, AAE에 비해 20% 이상 향상시켰습니다.
  - Fashion-MNIST의 가장 어려운 사례('티셔츠' vs. '풀오버')에서는 AAE에 비해 30%의 가장 큰 개선을 보였습니다.
- **낮은 이상치 비율에서의 성능:** 훈련 세트 내 이상치 비율이 1% 또는 0.1%로 낮아져도 ITSR은 여전히 우수한 성능을 유지했습니다.
- **관찰된 이상치에 대한 견고성:** ITSR은 훈련 중 '관찰된' 이상치(훈련 세트에 포함된 것과 동일한 유형의 이상치)에 대한 정확도를 크게 향상시켰습니다. 이는 표준 AE 및 AAE가 이 경우 성능이 저하되는 것과 대조됩니다.
- **미관찰된 이상치에 대한 영향:** ITSR은 '미관찰된' 이상치(훈련되지 않은 새로운 유형의 이상치)에 대해서도 다른 방법들과 비슷하거나 약간 더 나은 성능을 보였습니다. 이는 ITSR이 정상 클래스에 대한 모델 정확도를 높이면서 새로운 유형의 이상치 탐지에는 부정적인 영향을 미 미치지 않음을 시사합니다.
- **재구성 오차의 변화:** ITSR 적용 후, 정상 이미지의 재구성 오차는 거의 변하지 않았지만, 이상치 이미지의 재구성 오차는 크게 증가했습니다. 이는 ITSR 모델이 저차원 잠재 공간에서 정상 클래스를 견고하게 표현하고 원본 공간으로 재구성하는 방법을 학습하는 동시에, 훈련 중 존재하는 이상치에 둔감해졌음을 의미합니다.

## 🧠 Insights & Discussion

- **훈련 데이터 오염에 대한 견고성:** ITSR은 훈련 데이터에 이상치가 존재할 때 오토인코더의 취약성을 효과적으로 해결하여, 실제 시나리오에서 훈련 데이터의 완벽한 정제 필요성을 줄여줍니다. 이는 전문 지식을 통한 수동 데이터 검수 비용과 시간을 절감하는 데 큰 이점을 제공합니다.
- **정상 클래스 모델링 집중:** 이 방법은 AAE의 잠재 공간에서 직접 작동하며, 학습 과정을 정상(다수) 클래스의 진정한 데이터 다양체(manifold)에 집중시킵니다. 이를 통해 모델은 정상 데이터의 본질적인 특징을 더욱 정확하게 학습하고 이상치에 대한 재구성 능력을 의도적으로 저하시켜 분리도를 높입니다.
- **범용성 및 확장 가능성:** 본 연구는 이미지 데이터에만 적용되었지만, 이 접근 방식은 스펙트로그램 또는 시계열과 같은 다른 고차원 데이터 유형에도 쉽게 확장될 수 있습니다. 또한, 준지도 학습(semi-supervised setting)이나 능동 학습(active learning) 환경으로 확장하여 1-클래스 SVM으로 식별된 경계 근처 인스턴스에 대한 레이블 쿼리를 수행할 수 있습니다.
- **실용적 이점:** ITSR은 이상치 비율이 매우 낮은 품질 검사 등 실제 시나리오에서 큰 매력을 가집니다. 전문가가 잠재적으로 매우 큰 훈련 세트를 검사하여 정상 인스턴스만 선별하는 대신, 가공되지 않은 데이터 세트를 사용하여 ITSR이 훈련에서 잠재적 이상치를 제외하도록 할 수 있습니다.

## 📌 TL;DR

오토인코더 기반 이상 탐지는 훈련 데이터 오염에 취약합니다. 이 문제를 해결하기 위해, 본 논문은 적대적 오토인코더(AAE)를 활용하여 재구성 오차와 잠재 공간 가능도를 결합한 이상 점수를 사용하고, **반복적 훈련 세트 정제(ITSR)** 방법을 제안합니다. ITSR은 훈련 데이터 내의 잠재적 이상치를 1-클래스 SVM으로 식별하고 반복적으로 제외한 후 재훈련함으로써, 이상치가 포함된 훈련 세트에 대한 탐지 견고성과 정확도를 크게 향상시킵니다. 특히, 훈련 중 관찰된 이상치에 대한 성능 개선이 두드러지며, 미관찰된 이상치에 대해서도 동등하거나 더 나은 성능을 유지합니다.
