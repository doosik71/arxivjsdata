{
  "title": "Are We Using Autoencoders in a Wrong Way?",
  "authors": "Gabriele Martino, Davide Moroni, Massimo Martinelli",
  "year": 2023,
  "url": "http://arxiv.org/abs/2309.01532v1",
  "abstract": "Autoencoders are certainly among the most studied and used Deep Learning\nmodels: the idea behind them is to train a model in order to reconstruct the\nsame input data. The peculiarity of these models is to compress the information\nthrough a bottleneck, creating what is called Latent Space. Autoencoders are\ngenerally used for dimensionality reduction, anomaly detection and feature\nextraction. These models have been extensively studied and updated, given their\nhigh simplicity and power. Examples are (i) the Denoising Autoencoder, where\nthe model is trained to reconstruct an image from a noisy one; (ii) Sparse\nAutoencoder, where the bottleneck is created by a regularization term in the\nloss function; (iii) Variational Autoencoder, where the latent space is used to\ngenerate new consistent data. In this article, we revisited the standard\ntraining for the undercomplete Autoencoder modifying the shape of the latent\nspace without using any explicit regularization term in the loss function. We\nforced the model to reconstruct not the same observation in input, but another\none sampled from the same class distribution. We also explored the behaviour of\nthe latent space in the case of reconstruction of a random sample from the\nwhole dataset.",
  "citation": 2
}