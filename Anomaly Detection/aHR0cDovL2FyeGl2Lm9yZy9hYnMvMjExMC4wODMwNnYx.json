{
  "title": "Memory-augmented Adversarial Autoencoders for Multivariate Time-series\n  Anomaly Detection with Deep Reconstruction and Prediction",
  "authors": "Qinfeng Xiao, Shikuan Shao, Jing Wang",
  "year": 2021,
  "url": "http://arxiv.org/abs/2110.08306v1",
  "abstract": "Detecting anomalies for multivariate time-series without manual supervision\ncontinues a challenging problem due to the increased scale of dimensions and\ncomplexity of today's IT monitoring systems. Recent progress of unsupervised\ntime-series anomaly detection mainly use deep autoencoders to solve this\nproblem, i.e. training on normal samples and producing significant\nreconstruction error on abnormal inputs. However, in practice, autoencoders can\nreconstruct anomalies so well, due to powerful capabilites of neural networks.\nBesides, these approaches can be ineffective for identifying non-point\nanomalies, e.g. contextual anomalies and collective anomalies, since they\nsolely utilze a point-wise reconstruction objective. To tackle the above\nissues, we propose MemAAE (\\textit{Memory-augmented Adversarial Autoencoders\nwith Deep Reconstruction and Prediction}), a novel unsupervised anomaly\ndetection method for time-series. By jointly training two complementary proxy\ntasks, reconstruction and prediction, with a shared network architecture, we\nshow that detecting anomalies via multiple tasks obtains superior performance\nrather than single-task training. Additionally, a compressive memory module is\nintroduced to preserve normal patterns, avoiding unexpected generalization on\nabnormal inputs. Through extensive experiments, MemAAE achieves an overall F1\nscore of 0.90 on four public datasets, significantly outperforming the best\nbaseline by 0.02."
}