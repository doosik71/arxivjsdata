# DASVDD: Deep Autoencoding Support Vector Data Descriptor for Anomaly Detection

Hadi Hojjati, and Narges Armanfard

## 🧩 Problem to Solve

이 논문은 정상 데이터만으로 학습된 모델을 사용하여 비정상 샘플을 탐지하는 **원-클래스 이상 탐지(One-class Anomaly Detection)** 문제에 초점을 맞춥니다. 기존의 딥 이상 탐지(Deep Anomaly Detection) 방법들은 종종 신경망을 사용하여 데이터를 보다 유익한 표현 공간으로 매핑한 다음 이상 탐지 알고리즘을 적용합니다. 특히, **Deep Support Vector Data Descriptor (DSVDD)**는 데이터의 저차원 표현에서 둘러싸는 초구(hypersphere)의 부피를 최소화하지만, **"초구 붕괴(hypersphere collapse)"** 문제에 직면합니다. 이는 네트워크가 모든 입력을 잠재 표현 공간의 상수점으로 매핑하는 자명한 솔루션(예: 모든 가중치가 0인 상태)으로 수렴하는 현상입니다. DSVDD는 이 문제를 방지하기 위해 초구 중심을 고정하고 네트워크 바이어스를 0으로 설정하는 등의 제약을 가하는데, 이는 알고리즘의 성능과 효율성을 제한합니다.

## ✨ Key Contributions

- **초구 붕괴 문제 방지**: 다른 딥 SVDD 알고리즘이 겪는 초구 붕괴 문제를 방지하는 SVDD 기반 이상 탐지 접근 방식을 제안합니다. 손실 함수에 오토인코더의 재구성 오류(reconstruction error) 항을 포함하여 모든 가중치가 0이 되는 자명한 솔루션을 방지합니다.
- **학습 가능한 초구 중심**: 다른 SVDD 기반 딥 모델과는 달리, 제안하는 모델에서는 초구의 중심 $c$가 자유로운 최적화 매개변수이며 학습 과정에서 최적화될 수 있습니다. 이는 미리 정의된 값으로 중심을 강제하는 것으로 인해 발생할 수 있는 차선책을 피합니다.
- **반복적인 학습 전략**: 네트워크의 재구성 손실과 DSVDD 손실을 동시에 최소화하기 위한 반복적인 학습 전략을 제안합니다. 이 전략은 총 손실 함수가 두 손실 중 어느 하나로 붕괴되는 것을 방지하고 안정적인 학습 절차를 제공합니다.
- **하이퍼파라미터 $\gamma$ 튜닝 접근 방식**: 두 손실 함수의 기여도를 균형 있게 조절하는 하이퍼파라미터 $\gamma$에 대한 효과적인 튜닝 접근 방식을 학습 전에 제안합니다.
- **범용적인 이상 탐지**: 특정 도메인 모델과 달리, 입력과 관련된 변환을 사용하지 않아 범용적인 이상 탐지에 적합합니다. 이미지, 음성, 생체 의료 데이터, 네트워크 데이터, 산업 음향 녹음 등 다양한 유형의 데이터셋에서 효율성을 입증했습니다.

## 📎 Related Works

- **고전적 이상 탐지**: One-Class SVM (OCSVM), Kernel Density Estimation (KDE), Isolation Forests (IF) 등이 있습니다.
- **오토인코더(AE) 기반 딥 이상 탐지**: Autoencoders (AEs), Variational AEs (VAEs) 등이 있으며, 재구성 오류를 이상 점수로 사용하거나 잠재 표현을 고전적 AD 알고리즘에 입력합니다. 하지만 오토인코더가 때때로 이상치를 정확하게 재구성할 수 있다는 한계가 있습니다.
- **생성적 적대 신경망(GAN) 기반 딥 이상 탐지**: AnoGAN, EGBAD 등이 있으며, 생성 네트워크가 정상 데이터 패턴을 학습하도록 하여 생성된 샘플과 입력 간의 잔차를 이상 점수로 사용합니다. 시간 비효율성, 학습 중 수렴 실패, 모드 붕괴 등의 문제점을 가지고 있습니다.
- **Deep SVDD (DSVDD)**: 이상 탐지 작업을 직접적으로 이상 점수를 최소화함으로써 수행하는 몇 안 되는 접근 방식 중 하나입니다. 뛰어난 성능을 보였지만, 초구 붕괴 문제로 인해 $c$를 고정하고 바이어스를 0으로 설정하며, 특정 활성화 함수 사용을 제한하는 등의 제약을 가해야 했습니다.
- **DSVDD 초구 붕괴 문제 해결 시도**: Flow-based 모델 (Sendera et al. [21]) 또는 무작위 노이즈 추가 및 미니배치 분산의 작은 값에 페널티를 주는 두 가지 정규화 항 사용 (Chong et al. [35]) 등이 제안되었으나, 표현력 제한이나 일반화 문제, 그리고 $c$를 튜닝하지 않는다는 한계가 있습니다.
- **자기 지도 학습(Self-supervised learning) 기반 AD**: CSI, GEOM과 같은 방법들이 시각 이상 탐지에서 유망한 결과를 보였지만, 특정 데이터 유형에 국한되며 대규모 배치와 많은 학습 에포크, 그리고 데이터셋에 대한 도메인 지식이 필요한 전제 작업 설계가 필요합니다.

## 🛠️ Methodology

DASVDD는 딥 오토인코더와 Support Vector Data Descriptor (SVDD)의 두 가지 주요 구성 요소로 이루어집니다.

1. **DASVDD 이상 점수 및 목적 함수**:

   - 인코더 $h(.)$와 디코더 $g(.)$를 가지는 오토인코더를 사용합니다. 입력 샘플 $x$에 대해 잠재 표현 $z=h(x;\theta_e)$를 계산하고, 재구성된 출력은 $\hat{x}=g(z;\theta_d)$입니다.
   - 이상 점수 $S(x)$는 재구성 오류 항과 잠재 표현이 초구 중심 $c^*$로부터의 거리 항을 결합하여 정의됩니다:
     $$ S(x) = \| \hat{x} - x \|^2 + \gamma \| z - c^\* \|^2 $$
        여기서 $\gamma$는 두 항의 기여도를 균형 있게 조절하는 하이퍼파라미터입니다.
   - 목적 함수는 정상 데이터에 대한 이상 점수를 최소화하는 것입니다:
     $$ \min*{\theta_e, \theta_d, c} \frac{1}{n} \sum*{i=1}^n \left( \| g(h(x_i; \theta_e); \theta_d) - x_i \|^2 + \gamma \| h(x_i; \theta_e) - c \|^2 \right) + \lambda \| \Theta \|\_F $$
        $\lambda \| \Theta \|_F$는 가중치 감소 정규화 항입니다.
   - **초구 붕괴 방지**: 재구성 오류 항($\| \hat{x} - x \|^2$)을 포함함으로써, 모든 가중치가 0이 되는 자명한 해로 수렴하는 것을 방지합니다. 네트워크가 정상 샘플을 재구성하지 못하면 재구성 오류가 커지므로, 네트워크는 자명한 해를 피하고 의미 있는 표현을 학습하게 됩니다. 따라서 $c$와 네트워크 바이어스를 학습 가능한 매개변수로 설정할 수 있습니다.

2. **최적화 및 학습 전략**:

   - AE와 SVDD를 공동으로 학습하기 위해 반복적인 전략을 사용합니다:
     - 각 학습 에포크에서 배치 데이터의 $\kappa$($0 < \kappa < 1$) 부분을 사용하여 네트워크 매개변수 $\theta_e$와 $\theta_d$를 학습하고, 이때 초구 중심 $c$는 고정합니다. Adam 옵티마이저를 사용합니다.
     - 나머지 $(1-\kappa)$ 부분을 사용하여 초구 중심 $c$를 학습하고, 이때 네트워크 매개변수는 고정합니다. $c$에 대한 최적값은 배치 샘플의 잠재 표현 평균으로 쉽게 계산될 수 있습니다:
       $$ c = \frac{1}{|B|} \sum\_{i=1}^{|B|} h(x_i; \theta_e) $$
            AdaGrad와 같은 적응형 학습률 옵티마이저를 사용하여 $c$를 업데이트합니다. 이 전략은 안정적인 학습 과정을 보장합니다.

3. **하이퍼파라미터 $\gamma$의 선택**:
   - 적절한 $\gamma$ 값은 데이터셋 특성 및 네트워크 아키텍처에 따라 달라지므로, 학습 전에 $\gamma$를 자동으로 선택하는 휴리스틱 접근 방식을 제안합니다.
   - $\gamma$는 초기 네트워크 매개변수 $\theta_e^{(0)}, \theta_d^{(0)}$ 및 초기 초구 중심 $c^{(0)}$ (일반적으로 0)을 사용하여 $T$번 반복하여 계산된 평균 재구성 오류와 SVDD 항의 비율로 정의됩니다:
     $$ \gamma = \frac{1}{T} \sum*{t=1}^T \frac{1}{N} \sum*{i=1}^N \frac{\| g(h(x_i; \theta_e^{(0)}), \theta_d^{(0)}) - x_i \|^2}{\| h(x_i; \theta_e^{(0)}) - c^{(0)} \|^2} $$
        여기서 $T$는 반복 횟수(예: 10)입니다. 이 방법은 안정적인 학습을 위한 적절한 $\gamma$ 값을 찾아줍니다.

## 📊 Results

- **성능 우수성**: DASVDD는 7개의 벤치마크 데이터셋(MNIST, CIFAR10, Fashion MNIST, Speech, PIMA, AWID 3, MIMII)에서 AUC(Area Under ROC Curve) 기준으로 OCSVM, KDE, IF, AE, VAE, DAGMM, AnoGAN, PixCNN, AND, OCGAN, DSVDD 등 최신 이상 탐지 알고리즘보다 뛰어난 평균 성능을 보였습니다.
- **다양한 데이터셋에서의 강건성**: 이미지, 음성, 생체 의료, 네트워크 침입 탐지, 산업 음향 녹음 등 다양한 데이터 유형과 복잡성에서 일관되고 강건한 성능을 입증했습니다. 특히, 이미지 데이터셋에서 DAGMM과 같이 완전히 실패하는 모델과 달리, DASVDD는 모든 작업에서 허용 가능한 성능을 달성했습니다.
- **초구 붕괴 문제 해결 확인**: 학습 중 초구 중심 $c$가 성공적으로 학습되고 네트워크 바이어스가 0이 아닌 값을 유지하며 수렴함을 시각적으로 확인하여, 초구 붕괴 문제가 발생하지 않음을 입증했습니다. $c$를 고정했을 때 모델 성능이 저하되는 것을 보여주며 학습 가능한 $c$의 중요성을 강조했습니다.
- **하이퍼파라미터 분석**:
  - $\gamma$ 값의 자동 선택 전략이 효과적이며, DASVDD는 $\gamma$ 값의 넓은 범위에 걸쳐 강건한 성능을 보였습니다.
  - $\kappa$ (네트워크와 $c$ 학습에 사용되는 데이터 비율)의 경우, $\kappa=0.9$가 MNIST 데이터셋에서 최적의 성능을 제공하며, $\kappa=1$ (즉, $c$ 고정) 또는 너무 작은 $\kappa$ 값은 성능을 저하시켰습니다.
  - $T$ ($\gamma$ 계산을 위한 반복 횟수)는 $T=10$ 이상에서 성능 향상이 둔화됨을 보여주며, 적절한 균형점을 제시했습니다.
  - 잠재 표현(latent representation)의 크기는 MNIST, FMNIST, CIFAR-10 데이터셋에서 네트워크 성능에 크게 영향을 미치지 않았으며, 과완전 오토인코더(overcomplete autoencoder)에서도 좋은 결과를 얻을 수 있음을 보여주었습니다.

## 🧠 Insights & Discussion

- **초구 붕괴 문제에 대한 근본적인 해결책**: DASVDD의 핵심 통찰은 오토인코더의 재구성 오류를 이상 점수와 목적 함수에 통합함으로써 DSVDD의 초구 붕괴 문제를 효과적으로 해결했다는 점입니다. 이는 단순히 SVDD 손실만 최소화하는 것이 아니라, 네트워크가 정상 데이터를 정확하게 재구성하도록 강제하여 자명한 (모든 가중치가 0인) 솔루션으로 수렴하는 것을 방지합니다. 이로 인해 초구 중심 $c$와 네트워크 바이어스를 학습 가능한 매개변수로 설정할 수 있게 되어 모델의 유연성과 성능이 향상됩니다.
- **학습 가능한 중심의 이점**: DSVDD와 달리 $c$를 학습 과정에서 최적화할 수 있게 함으로써, 모델은 데이터의 실제 분포에 더 잘 맞는 초구 중심을 찾아 차선책이 아닌 더 나은 솔루션에 도달할 수 있습니다.
- **안정적인 학습 절차**: 재구성 손실과 SVDD 손실을 반복적으로 최소화하는 독특한 학습 전략은 두 손실 항 간의 균형을 유지하고 학습 과정의 안정적인 수렴을 보장합니다. 이는 한 손실 항이 다른 손실 항을 압도하여 모델이 원하는 대로 학습되지 않는 문제를 방지합니다.
- **범용성과 적용 범위**: DASVDD는 데이터 유형에 특화된 변환(예: 이미지 증강)에 의존하지 않으므로, 다양한 응용 분야의 이질적인 데이터셋에 널리 적용될 수 있습니다. 이는 모델의 실용성을 크게 높입니다.
- **제한 및 향후 연구**: 제안된 $\gamma$ 선택 휴리스틱은 효과적이지만, 모든 작업에 대한 최적의 $\gamma$ 값을 찾는 것이 미래 연구의 주제가 될 수 있습니다. 또한, 다른 도메인에서의 효율성 탐구와 새로운 하이퍼파라미터 튜닝 및 네트워크 아키텍처 제안을 통해 성능을 개선하는 것도 가능합니다.

## 📌 TL;DR

**문제**: 기존 딥 이상 탐지, 특히 DSVDD는 "초구 붕괴" 문제로 인해 자명한 솔루션으로 수렴하며, 이를 피하기 위해 네트워크 아키텍처에 엄격한 제약을 가해야 했습니다.
**제안 방법**: DASVDD는 딥 오토인코더와 SVDD를 결합하여, 오토인코더의 잠재 표현에서 최소 부피의 초구를 학습하는 동시에 재구성 오류를 최소화합니다. 재구성 오류 항을 이상 점수 및 목적 함수에 포함함으로써, 초구 붕괴를 자연스럽게 방지하고 초구 중심 $c$와 네트워크 바이어스를 학습 가능한 매개변수로 설정할 수 있습니다. 또한, 재구성 손실과 SVDD 손실을 균형 있게 최적화하는 반복적인 학습 전략과 하이퍼파라미터 $\gamma$를 자동으로 튜닝하는 휴리스틱을 제안합니다.
**주요 결과**: DASVDD는 7개의 다양한 벤치마크 데이터셋에서 최신 이상 탐지 방법들을 능가하는 우수한 성능을 달성했습니다. 초구 붕괴 문제를 성공적으로 회피하며, 학습 가능한 $c$를 통해 더 나은 최적화를 가능하게 하고, 이미지, 음성 등 다양한 데이터 유형에 걸쳐 강건하고 범용적인 이상 탐지 능력을 보여주었습니다.
