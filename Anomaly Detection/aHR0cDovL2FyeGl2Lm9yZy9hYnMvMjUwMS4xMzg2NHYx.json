{
  "url": "http://arxiv.org/abs/2501.13864v1",
  "title": "Autoencoders for Anomaly Detection are Unreliable",
  "authors": "Roel Bouman, Tom Heskes",
  "year": 2025,
  "abstract": "Autoencoders are frequently used for anomaly detection, both in the\nunsupervised and semi-supervised settings. They rely on the assumption that\nwhen trained using the reconstruction loss, they will be able to reconstruct\nnormal data more accurately than anomalous data. Some recent works have posited\nthat this assumption may not always hold, but little has been done to study the\nvalidity of the assumption in theory. In this work we show that this assumption\nindeed does not hold, and illustrate that anomalies, lying far away from normal\ndata, can be perfectly reconstructed in practice. We revisit the theory of\nfailure of linear autoencoders for anomaly detection by showing how they can\nperfectly reconstruct out of bounds, or extrapolate undesirably, and note how\nthis can be dangerous in safety critical applications. We connect this to\nnon-linear autoencoders through experiments on both tabular data and real-world\nimage data, the two primary application areas of autoencoders for anomaly\ndetection.",
  "citation": 3
}