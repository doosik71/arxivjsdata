{
  "title": "Understanding the Effect of Bias in Deep Anomaly Detection",
  "authors": "Ziyu Ye, Yuxin Chen, Haitao Zheng",
  "year": 2021,
  "url": "http://arxiv.org/abs/2105.07346v1",
  "abstract": "Anomaly detection presents a unique challenge in machine learning, due to the\nscarcity of labeled anomaly data. Recent work attempts to mitigate such\nproblems by augmenting training of deep anomaly detection models with\nadditional labeled anomaly samples. However, the labeled data often does not\nalign with the target distribution and introduces harmful bias to the trained\nmodel. In this paper, we aim to understand the effect of a biased anomaly set\non anomaly detection. Concretely, we view anomaly detection as a supervised\nlearning task where the objective is to optimize the recall at a given false\npositive rate. We formally study the relative scoring bias of an anomaly\ndetector, defined as the difference in performance with respect to a baseline\nanomaly detector. We establish the first finite sample rates for estimating the\nrelative scoring bias for deep anomaly detection, and empirically validate our\ntheoretical results on both synthetic and real-world datasets. We also provide\nan extensive empirical study on how a biased training anomaly set affects the\nanomaly score function and therefore the detection performance on different\nanomaly classes. Our study demonstrates scenarios in which the biased anomaly\nset can be useful or problematic, and provides a solid benchmark for future\nresearch."
}