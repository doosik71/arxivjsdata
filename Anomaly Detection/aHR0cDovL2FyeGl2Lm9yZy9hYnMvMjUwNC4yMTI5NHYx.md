# Learning Multi-view Multi-class Anomaly Detection

Qianzi Yu, Yang Cao, Yu Kang

## 🧩 Problem to Solve

최근 산업 분야의 이상 감지(Anomaly Detection)는 각 카테고리별로 모델을 학습시키는 대신 통합 모델을 훈련하는 추세입니다. 그러나 기존의 다중 클래스 이상 감지(Multi-Class Anomaly Detection, MCAD) 모델은 다양한 뷰(view)에서 얻은 정보를 효과적으로 모델링하고 상호 보완적인 정보를 활용하는 데 실패하여 다중 뷰 시나리오에서 성능이 저조합니다. 특히 다음과 같은 문제에 직면합니다:

* **시점 데이터의 불일치:** 일부 이상은 특정 뷰에서만 보이고 다른 뷰에서는 보이지 않을 수 있어 작업의 난이도를 높입니다.
* **뷰 간 상관관계 활용 부족:** 서로 다른 뷰의 이미지는 상호 의존적이거나 공유된 특징을 가질 수 있지만, 기존 단일 뷰 감지 방법은 이러한 교차 뷰 정보를 충분히 활용하지 못합니다.
* **객체 가장자리 이상 감지 난이도:** 객체의 가장자리에 위치한 이상은 뷰 간 정렬 문제를 야기하여 감지 정확도를 떨어뜨릴 수 있습니다.

## ✨ Key Contributions

본 논문은 다중 뷰 다중 클래스 이상 감지(Multi-View Multi-Class Anomaly Detection, MVMCAD)를 위한 인코더-디코더 프레임워크를 제안하며, 다음과 같은 핵심 기여를 합니다:

* **통합 모델 프레임워크:** 다중 클래스 및 다중 뷰 이상 감지를 단일 프레임워크 내에서 해결하는 MVMCAD 모델을 제안합니다.
* **반동결 인코더 (Semi-Frozen Encoder, SFE):** 안정적인 교차 뷰 특징 모델링과 효율적인 데이터 분포 적응을 위해 사전 인코더 우선 강화 메커니즘이 추가된 반동결 인코더를 제안합니다.
* **이상 증폭 모듈 (Anomaly Amplification Module, AAM):** 전역 토큰 상호작용을 모델링하고 정상 영역을 억제하여 이상 신호를 증폭시켜 다중 뷰 설정에서 감지 성능을 향상시키는 모듈을 제안합니다.
* **교차 특징 손실 (Cross-Feature Loss, CFL):** 얕은 인코더 특징과 깊은 디코더 특징을 서로 정렬하여 모델이 다양한 의미론적 수준의 이상에 대한 민감도를 높이도록 돕는 손실 함수를 제안합니다.
* **최첨단 성능 달성:** Real-IAD 데이터셋에 대한 광범위한 실험을 통해 이미지 수준 및 픽셀 수준 이상 감지에서 최첨단 성능을 달성하여 제안 방법의 효과를 검증했습니다.

## 📎 Related Works

본 연구는 주로 산업 이상 감지 및 다중 뷰 학습 분야의 기존 연구를 참조합니다.

* **산업 이상 감지 (Industrial Anomaly Detection):**
  * 이상 데이터 희소성으로 인한 비지도 학습 방법이 주로 사용됩니다.
  * 최근에는 각 클래스별로 개별 모델을 훈련하는 대신 [24]와 같이 여러 카테고리를 통합적으로 처리하는 모델이 연구되고 있습니다.
  * 주요 방법론은 깊은 특징 임베딩([2], [6]), 재구성 기반([8], [9]), 합성 기반([14], [26])으로 분류됩니다.
  * 참조된 최신 연구: UniAD [24], RD4AD [5], SimpleNet [17], DeSTSeg [28], DiAD [12], MambaAD [11], Dinomaly [10] 등이 있습니다.
* **다중 뷰 학습 (Multi-view Learning):**
  * 다중 뷰 특징 융합 방법은 3D 객체 인식([20]), 자율 주행을 위한 3D 객체 감지 네트워크([3]), 위장 객체 감지([18]), 보조 운전 인식을 위한 비전 기반 방법([23]) 등 다양한 분야에서 사용됩니다.
  * 이상 감지 분야에서는 MVAD [13]가 다중 뷰 이상 감지를 위한 선구적인 프레임워크를 제안했지만, 다중 클래스 시나리오를 처리하는 능력은 부족합니다.

## 🛠️ Methodology

제안된 MVMCAD 모델은 반동결 인코더(Semi-Frozen Encoder, SFE), 이상 증폭 모듈(Anomaly Amplification Module, AAM), 교차 특징 손실(Cross-Feature Loss, CFL)로 구성된 인코더-디코더 프레임워크입니다.

1. **모델 개요:**
   * 입력 이미지 $x_0$는 SFE를 통과하여 초기 특징 $f_i$를 얻습니다.
   * $f_i$는 AAM을 통해 중간 특징 $f_m = \{f_1, f_2\}$으로 변환됩니다. $f_m$은 정상 영역에서 벗어난 특징을 강조합니다.
   * 디코더는 $f_m$을 재구성하도록 학습하며, SFE의 특징 $f_e = \{f_{e1}, f_{e2}\}$과 $f_m$을 교차 특징 손실을 통해 정렬합니다.
   * 추론 시에는 픽셀 단위 재구성 오차를 사용하여 이상 히트맵과 최종 이상 점수 $S$를 계산합니다.
2. **반동결 인코더 (Semi-Frozen Encoder, SFE):**
   * 학습 가능한 사전 인코더(pre-encoder)와 고정된 백본(frozen backbone)으로 구성되어 뷰 간 공유 구조 적응을 제공하며 시각적 표현 능력을 보존합니다.
   * 사전 인코더는 부분 레이어를 미세 조정하여 다중 뷰 이미지에 대한 적응성을 높입니다.
   * **가중 정규화:** 입력 이미지 $X_{c,h,w}$에 대해 $\tilde{X}_{c,h,w} = BN(X) = \gamma_c \cdot \frac{X_{c,h,w} - \mu_c}{\sigma_c}$를 수행합니다. 가중치 $\alpha_c = \frac{|\gamma_c|}{\sum_{k=1}^{C} |\gamma_k|}$를 정의합니다.
   * **가중 결과:** $X^{ch}_{c,h,w} = \sigma(\alpha_c \cdot \tilde{X}_{c,h,w}) \cdot X_{c,h,w}$로 계산됩니다.
   * **채널 평균:** 특징 맵 $X^{ch}_{c,h,w}$의 채널 평균을 계산하여 특징 일관성을 개선합니다: $\beta_{h,w} = \frac{M_{h,w}}{\sum_{h'=1}^{H} \sum_{w'=1}^{W} M_{h',w'}}$ ($M_{h,w} = \frac{1}{C} \sum_{c=1}^{C} X^{ch}_{c,h,w}$).
   * **최종 우선 메커니즘 출력:** $X^{prior}_{c,h,w} = \sigma(\beta_{h,w} \cdot X^{ch}_{c,h,w}) \cdot X^{ch}_{c,h,w}$.
   * 처리된 특징은 고정된 인코더 $\varepsilon$에 입력되어 초기 특징 $f_i = \varepsilon(\text{Patch}(X^{prior}_{c,h,w}))$를 얻습니다.
13. **이상 증폭 모듈 (Anomaly Amplification Module, AAM):**
   * 전역 토큰 수준의 문맥적 관계를 파악하고, 정상 영역을 나타낼 가능성이 높은 토큰을 억제하여 이상 영역의 표현을 강조합니다.
   * 입력 $f_i \in \mathbb{R}^{B \times N \times D}$에서 쿼리 $Q$, 키 $K$, 값 $V$ 행렬을 계산합니다: $Q = f_i W_Q, K = f_i W_K, V = f_i W_V$.
   * 가중치 합 $F = W_F(\text{Softmax}(\frac{QK^{\top}}{\sqrt{d_k}})V)$를 계산합니다.
   * $F$를 정규화합니다: $\hat{F} = \text{Normalize}(F, \text{dim}=N)$.
   * 토큰 유사도 점수 $\text{Sim} = \sum_{j=1}^{N} \|\hat{F}_j\|_2 \cdot \gamma$를 계산하고, 소프트 어텐션 분포 $\Pi = \text{Softmax}(\text{Sim})$를 정의합니다.
   * 억제 기반 어텐션 팩터 $\text{Att} = \frac{1}{1 + (\Pi^{\top} \cdot F^2)}$를 계산합니다.
   * 최종 출력은 $f_m = W_{out}(-(F \cdot \Pi) \cdot \text{Att})$입니다.
4. **교차 특징 손실 (Cross-Feature Loss, CFL):**
   * 다양한 의미론적 수준에서 나타나는 이상을 포착하기 위해 얕은 인코더 특징과 깊은 디코더 특징, 그리고 깊은 인코더 특징과 얕은 디코더 특징을 정렬합니다.
   * 인코더의 특징 $\{f_{e1}, f_{e2}\}$과 AAM의 특징 $f_m = \{f_1, f_2\}$를 사용합니다.
   * 유사도 점수: $\text{Score} = 1 - \cos(z_1, z_2)$ (코사인 유사도 사용).
   * 상위 10%의 유사도 점수 집합 $I = \{i | \text{Score}_i \geq h\}$를 선택합니다.
   * 교차 특징 손실은 다음과 같이 계산됩니다:
    $$ L_{\text{cross}} = \frac{1}{2} \left( \frac{1}{|I|} \sum_{i \in I} \text{Score}(f_{e1}, f_2) + \frac{1}{|I|} \sum_{i \in I} \text{Score}(f_{e2}, f_1) \right) $$

## 📊 Results

제안된 MVMCAD 모델은 Real-IAD 데이터셋에 대한 광범위한 실험을 통해 최첨단 성능을 달성했습니다.

* **이미지 수준 이상 감지:**
  * AUROC/AP/F$_{1}$-max 점수에서 91.0/88.6/82.1을 기록하여 이전 최우수 방법(Dinomaly) 대비 각각 +1.7, +1.8, +1.9의 상당한 성능 향상을 보였습니다.
  * 대부분의 객체 카테고리에서 기존 7가지 기준선 모델을 능가하며 다양한 산업 객체에 대한 뛰어난 일반화 능력을 입증했습니다.
* **픽셀 수준 이상 위치 파악:**
  * AUROC/AP/F$_{1}$-max/AUPRO 점수에서 99.1/43.9/48.2/95.2를 달성하여 이전 SOTA 대비 각각 +0.3, +1.1, +1.1, +1.3의 개선을 보였습니다.
  * AP 및 F$_{1}$-max의 상당한 향상은 모델이 이상을 더 정확하게 감지할 뿐만 아니라 픽셀 수준에서 더 정밀하게 위치를 파악할 수 있음을 나타냅니다.
* **시각화 결과:**
  * 이상 맵(Anomaly Map) 시각화 실험을 통해 모델이 작거나 미묘한 결함까지 포함하여 다양한 객체 유형의 이상을 정밀하게 위치 파악할 수 있음을 보여주었습니다. 이는 강력한 일반화 능력과 정교한 이상 인식 능력을 시사합니다.
* **제안 구성 요소의 기여도 (Ablation Study):**
  * SFE, AAM, CFL 세 가지 구성 요소를 모두 사용했을 때 가장 높은 이미지 수준 성능(AUROC, AP, F$_{1}$-max가 각각 91.0%, 88.6%, 82.1%)을 달성했습니다.
  * 픽셀 수준에서는 AUROC와 AUPRO가 가장 높았지만, AP와 F$_{1}$-max는 세 구성 요소 모두 사용 시 약간 낮아지는 경향을 보였습니다. 이는 AAM의 과도한 증폭 효과 때문일 수 있으며, 특정 로컬 영역에 대한 과도한 강조가 픽셀 수준의 정확도를 저해할 수 있음을 시사합니다.
* **계산 속도 및 메모리 사용량:**
  * 제안된 SFE 및 AAM 모듈이 메모리 사용량을 크게 늘리거나 추론 속도를 눈에 띄게 줄이지 않는 것으로 나타났습니다.

## 🧠 Insights & Discussion

* **의미:** MVMCAD는 다중 뷰 이미지에서 발생하는 이상 감지의 고유한 도전 과제(시점 간 불일치, 뷰 간 상관관계 부족, 가장자리 이상)를 효과적으로 해결합니다. 통합 모델 접근 방식은 배포를 단순화하고 추론 속도를 향상시킵니다. SFE, AAM, CFL의 조합은 다양한 의미론적 수준의 이상에 대한 모델의 감도와 강건성을 크게 향상시킵니다. 특히 Real-IAD와 같은 복잡한 실제 데이터셋에서 이미지 및 픽셀 수준 모두에서 최첨단 성능을 달성하여 그 실용적 가치를 입증했습니다.
* **한계 및 향후 연구:**
  * **계산 효율성:** 트랜스포머 기반의 인코더-디코더 프레임워크는 제안된 구성 요소가 계산 비용을 크게 늘리지 않음에도 불구하고 여전히 다른 방법에 비해 상대적으로 느린 학습 및 추론 시간을 가집니다.
  * **픽셀 수준 정확도:** 이상 증폭 모듈(AAM)이 픽셀 수준 이상 신호를 과도하게 증폭시켜 모델이 픽셀 수준 이상에 효과적으로 반응하는 데 어려움을 겪을 수 있으며, 이로 인해 픽셀 수준 AP 및 F$_{1}$-max 지표가 약간 감소할 수 있습니다. AAM 모듈의 가중치를 줄이는 시도는 전체 성능 저하로 이어졌습니다.
  * **향후 과제:** 프레임워크의 학습 및 추론 효율성을 개선하고, 픽셀 수준 정확도와 전반적인 성능의 균형을 맞출 수 있는 적응형 이상 증폭 전략을 개발하는 데 중점을 둘 것입니다.

## 📌 TL;DR

* **문제:** 기존 모델은 다중 뷰 다중 클래스 이상 감지에서 뷰 간 정보 불일치 및 활용 부족으로 인해 성능이 저조합니다.
* **제안 방법:** MVMCAD는 반동결 인코더(SFE)로 다중 뷰 데이터에 적응하고, 이상 증폭 모듈(AAM)로 이상 신호를 강조하며, 교차 특징 손실(CFL)로 다양한 의미론적 수준의 이상을 포착하는 인코더-디코더 프레임워크입니다.
* **주요 결과:** Real-IAD 데이터셋에서 이미지 수준 이상 감지 (AUROC/AP/F$_{1}$-max: 91.0/88.6/82.1) 및 픽셀 수준 이상 위치 파악 (AUROC/AP/F$_{1}$-max/AUPRO: 99.1/43.9/48.2/95.2) 모두에서 최첨단 성능을 달성하여, 복잡한 다중 뷰 다중 클래스 시나리오에서 뛰어난 성능과 일반화 능력을 입증했습니다.
