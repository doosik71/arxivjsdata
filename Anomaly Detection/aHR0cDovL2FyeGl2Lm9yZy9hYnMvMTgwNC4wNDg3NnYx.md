# Group Anomaly Detection using Deep Generative Models

Raghavendra Chalapathy, Edward Toth, and Sanjay Chawla

## 🧩 해결할 문제

기존의 이상 감지 연구는 개별 데이터 포인트의 이상(점 이상)에 초점을 맞춥니다. 이 논문은 **그룹 이상 감지(Group Anomaly Detection, GAD)**를 다루며, 특히 개별 점의 이상보다는 **비정상적인 그룹 분포**를 보이는 데이터 포인트의 집합을 식별하는 것을 목표로 합니다. 예를 들어, 이미지 내 픽셀이나 시각적 특징들의 비정상적인 혼합이 그룹 이상으로 간주될 수 있습니다. GAD는 고에너지 입자 물리학, 소셜 미디어, 의료 영상과 같은 실제 응용 분야에서 비정상적인 현상을 탐지하는 데 중요합니다. 기존의 점 기반 이상 감지 방법으로는 이러한 그룹 수준의 편차를 감지하기 어렵고, 고차원 데이터(예: 이미지)에서 그룹 분포를 효과적으로 특징화하는 것이 도전 과제입니다.

## ✨ 주요 기여

- 그룹 참조 함수를 사용하여 그룹 이상 감지(GAD) 문제에 대한 심층 생성 모델(DGM)을 공식화했습니다.
- 심층 생성 모델이 다양한 이미지 응용 분야에 적용되었음에도 불구하고, GAD 문제에 적용된 것은 이 논문이 최초입니다.
- 합성 데이터셋과 실제 데이터셋에 대한 광범위한 실험을 통해, 다른 GAD 기술과 비교하여 그룹 이상 감지에서 심층 생성 모델의 효과와 견고함을 입증했습니다.

## 📎 관련 연구

- 그룹 이상 감지(GAD)는 최근에 발전된 최신 기술을 포함하는 연구의 신흥 분야입니다.
- 초기 이상 감지 연구는 그룹 이상을 간략하게 언급했지만, 최근 연구들은 GAD 방법에 대한 더 상세한 설명을 제공합니다. 본 논문은 그룹 멤버십이 사전에 알려진 경우(예: 이미지 응용)를 탐구합니다.
- 이미지 이상 감지에 대한 이전 연구들은 GAD와 관련될 수 있습니다:
  - **점 기반 GAD**: 유방 촬영 이미지의 암세포 또는 비정상적인 의자 모양 감지.
  - **분포 기반 GAD**: 이어붙인 장면 이미지 또는 비정상적인 RGB 비율을 가진 은하 클러스터 감지. 본 논문은 특히 분포 기반 GAD에 중점을 둡니다.
- GAD는 고에너지 입자 물리학, 유체 역학, 토픽 모델링, 소셜 미디어 등 다양한 분야에 응용됩니다.
- 심층 학습, 특히 생성 모델은 비디오 이상 감지에 적용되었으나, GAD 문제로 공식화된 적은 없습니다. 본 연구는 GAD에서 심층 생성 모델(DGM)을 위해 오토인코더를 활용합니다.

## 🛠️ 방법론

이 논문은 그룹 이상 감지를 위해 심층 생성 모델(DGM)인 **변이형 오토인코더(Variational Autoencoder, VAE)**와 **적대적 오토인코더(Adversarial Autoencoder, AAE)**를 제안합니다.

1. **그룹 표현**:

   - 각 그룹 $G_m$ (예: $N_m$개의 픽셀과 $V$개의 특징을 가진 이미지)이 주어집니다.
   - **특징화 함수(characterization function)** $f: R^{N_m \times V} \to R^D$는 그룹 분포의 속성을 추출합니다. VAE의 경우 이 함수는 각 그룹의 잠재 공간에 대한 평균($\mu_m$)과 표준 편차($\sigma_m$)를 출력합니다.
   - **결합 함수(aggregation function)** $g: R^{M \times D} \to R^D$는 특징화된 그룹 정보를 결합하여 **그룹 참조($G^{(ref)}$)**를 생성합니다.

2. **DGM 기반 그룹 참조($G^{(ref)}$) 생성 (Algorithm 1)**:

   - **학습**: AAE 및 VAE는 입력 그룹 $G$에 대해 인코더 $f_\phi$와 디코더 $g_\psi$를 학습합니다.
   - **VAE**: 모든 그룹 $G_m$으로부터 평균($\mu_m$)과 표준 편차($\sigma_m$)를 인코딩합니다. 이들의 평균값 $(\mu, \sigma)$로부터 잠재 변수 $z \sim N(\mu, \sigma)$를 샘플링하고, 이를 디코더 $g_\psi$에 넣어 그룹 참조 $G^{(ref)}$를 재구성합니다.
   - **AAE**: 학습된 인코더 $f_\phi$를 통해 입력 그룹 $G$로부터 잠재 표현 $z$를 샘플링합니다. 이 $z$를 디코더 $g_\psi$에 넣어 $G^{(ref)}$를 재구성합니다.

3. **이상 점수 계산**:

   - 훈련된 모델을 사용하여 각 그룹 $G_m$과 그룹 참조 $G^{(ref)}$ 사이의 거리 $d(G^{(ref)}, G_m)$를 계산합니다.
   - 이 거리가 멀수록 해당 그룹은 더 이상적인 것으로 간주됩니다.
   - 이상 점수는 내림차순으로 정렬되며, $G^{(ref)}$로부터 가장 멀리 떨어진 그룹들이 이상 그룹으로 식별됩니다.

4. **기본 DGM 메커니즘**:

   - **오토인코더(Autoencoder, AE)**: 입력 $G_m$과 재구성된 출력 $\hat{G}_m$ 간의 재구성 손실 $L_r(G_m, \hat{G}_m) = ||G_m - \hat{G}_m||^2$을 최소화하여 학습됩니다. 재구성 오류를 이상 점수로 사용합니다.
   - **변이형 오토인코더(Variational Autoencoder, VAE)**: AE에 추가적으로 인코딩된 잠재 변수 $z$가 사전 분포 $P(z)$를 따르도록 제약합니다. 손실 함수는 재구성 손실과 쿨백-라이블러(Kullback-Leibler, KL) 발산 $KL(f_\phi(z|x) || g_\psi(z))$의 합으로 구성됩니다.
   - **적대적 오토인코더(Adversarial Autoencoder, AAE)**: VAE의 KL 발산 항의 분석적 해법 부재를 극복하기 위해 적대적 학습을 사용합니다. 인코더가 생성하는 잠재 공간 분포를 사전 분포와 일치시키기 위해 판별자(discriminator)를 훈련시킵니다. 인코더와 디코더는 재구성 손실을 최소화하고, 인코더는 판별자를 속여 잠재 표현이 사전 분포와 유사하게 보이도록 학습합니다.

5. **비교 방법 (기준선)**:
   - **가우시안 혼합 모델의 혼합(Mixture of Gaussian Mixture Models, MGMM)**: 계층적 생성 접근 방식으로, 각 그룹이 가우시안 혼합을 따르며 여러 정규 혼합 비율이 가능하다고 가정합니다.
   - **원-클래스 서포트 측정 머신(One-Class Support Measure Machines, OCSMM)**: 각 그룹을 평균 임베딩 함수로 특징화한 후, 정규 그룹 행동과 이상 그룹을 구분하는 마진을 최대화합니다.
   - **원-클래스 서포트 벡터 머신(One-Class Support Vector Machines, OCSVM)**: 그룹 분포가 단일 값으로 축소될 경우 적용 가능하며, 파라미터화된 초평면으로 데이터 포인트를 분리합니다. 이미지 데이터에서는 시각적 특징을 k-means로 클러스터링하여 히스토그램으로 변환하는 전처리 과정이 필요합니다.

## 📊 결과

- **데이터셋**: 합성 데이터셋(회전된 가우시안 분포)과 실제 이미지 데이터셋에서 실험이 수행되었습니다. 실제 데이터셋으로는 `cifar-10`을 활용하여 "고양이 이미지 속 호랑이", "회전된 고양이", "고양이와 개"와 같은 다양한 유형의 그룹 이상을 감지하고, `scene` 이미지 데이터셋에서 "이어붙인 장면 이미지"를 감지했습니다.
- **평가 지표**: 특히 클래스 불균형 데이터셋에서 더 적합한 AUPRC(Area Under the Precision-Recall Curve)와 AUROC(Area Under the ROC Curve)가 성능 평가에 사용되었습니다.
- **주요 발견 사항**:
  - **합성 데이터**: 그룹 크기가 작을 때($M=550$), 기존 GAD 방법이 더 높은 성능을 보였으나, 학습 데이터셋 크기가 클 때($M=5050$), AAE와 VAE는 완벽한 점수(AUPRC/AUROC = 1.0000)를 달성하여 DGM이 최적의 훈련을 위해 더 많은 데이터를 필요로 함을 시사합니다.
  - **실제 이미지 데이터**: AAE는 대부분의 실제 이미지 실험(고양이 이미지 속 호랑이, 회전된 고양이, 고양이와 개)에서 가장 높은 감지 성능을 보였으며, 종종 완벽하거나 거의 완벽한 점수를 달성했습니다. VAE 또한 AAE 다음으로 우수한 성능을 보였습니다. 그룹 크기가 작았던 `scene` 데이터셋($M=366$)의 경우, DGM의 성능은 상대적으로 낮았으며, OCSMM이 가장 좋은 성능을 보였습니다.
- **계산 시간**: MGMM, OCSMM, OCSVM은 소규모 데이터셋에서 더 빨랐지만, DGM(AAE, VAE)은 더 많은 시간(예: 6.5-8.5분 대 수 초)이 소요되었습니다. 그러나 DGM은 GPU를 활용할 수 있으며, 전통적인 방법은 총 관측치 $N$에 대해 $O(N^2)$ 복잡도를 겪으므로, 대규모에서는 DGM이 더 효율적일 수 있습니다.

## 🧠 통찰 및 논의

- **GAD를 위한 DGM의 효과**: 심층 생성 모델(AAE 및 VAE)은 복잡한 이미지 기반 시나리오에서 분포 기반 그룹 이상을 감지하는 데 매우 효과적이고 견고하며, 그룹 분포의 견고한 표현을 학습하는 능력을 입증했습니다.
- **데이터 볼륨 의존성**: DGM은 최적의 훈련을 위해 **많은 수의 그룹 관측치**를 필요로 합니다. 대규모 데이터셋에서 우수한 성능을 보였지만, 소규모 데이터셋에서는 한계를 드러냈습니다.
- **귀납적 특성**: DGM은 정규 그룹 분포의 매니폴드를 학습하여 보지 못한 데이터 포인트에도 일반화할 수 있는 귀납적 이상 감지기입니다.
- **계산 시간 트레이드오프**: DGM은 소규모 데이터셋에서 CPU 훈련 시 시간이 더 걸리지만, GPU 활용 능력과 대규모 데이터에서의 복잡도($O(N^2)$에 비해) 이점으로 인해 향후 대규모 GAD에 유망한 방향을 제시합니다.
- **참신성**: 이 연구는 특히 분포 기반 이상을 위한 GAD 문제에 심층 생성 모델을 공식화하고 적용한 최초의 논문이며, 새로운 연구 방향을 제시합니다.
- **한계**: DGM을 효과적으로 훈련하기 위해 대규모 데이터셋이 필요하다는 점이 주된 한계입니다.
- **향후 방향**: 시계열 그룹의 시간적 변화를 감지하기 위해 순환 신경망을 사용하는 등, 시퀀스 그룹 이상 감지로의 확장을 제안합니다.

## 📌 TL;DR

이 논문은 이미지 데이터의 비정상적인 그룹 분포를 목표로 하는 그룹 이상 감지(GAD)를 위해 심층 생성 모델(AAE, VAE)을 제안합니다. 점 이상에 초점을 맞춘 전통적인 방법과 달리, DGM은 정상 그룹 행동의 참조를 학습하고 편차를 기반으로 이상을 식별합니다. 합성 및 실제 이미지 데이터셋에 대한 실험 결과, DGM, 특히 AAE는 충분한 훈련 데이터가 주어질 때 우수한 성능을 달성함을 보여주었습니다. 이는 소규모 데이터셋에서는 계산 비용이 더 높을 수 있지만, 복잡한 그룹 표현을 학습하는 데 DGM의 효과를 입증한 첫 번째 GAD 적용 사례입니다.
