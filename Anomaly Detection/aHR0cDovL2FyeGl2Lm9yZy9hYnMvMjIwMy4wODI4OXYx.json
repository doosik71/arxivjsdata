{
  "title": "Driving Anomaly Detection Using Conditional Generative Adversarial\n  Network",
  "authors": "Yuning Qiu, Teruhisa Misu, Carlos Busso",
  "year": 2022,
  "url": "http://arxiv.org/abs/2203.08289v1",
  "abstract": "Anomaly driving detection is an important problem in advanced driver\nassistance systems (ADAS). It is important to identify potential hazard\nscenarios as early as possible to avoid potential accidents. This study\nproposes an unsupervised method to quantify driving anomalies using a\nconditional generative adversarial network (GAN). The approach predicts\nupcoming driving scenarios by conditioning the models on the previously\nobserved signals. The system uses the difference of the output from the\ndiscriminator between the predicted and actual signals as a metric to quantify\nthe anomaly degree of a driving segment. We take a driver-centric approach,\nconsidering physiological signals from the driver and controller area\nnetwork-Bus (CAN-Bus) signals from the vehicle. The approach is implemented\nwith convolutional neural networks (CNNs) to extract discriminative feature\nrepresentations, and with long short-term memory (LSTM) cells to capture\ntemporal information. The study is implemented and evaluated with the driving\nanomaly dataset (DAD), which includes 250 hours of naturalistic recordings\nmanually annotated with driving events. The experimental results reveal that\nrecordings annotated with events that are likely to be anomalous, such as\navoiding on-road pedestrians and traffic rule violations, have higher anomaly\nscores than recordings without any event annotation. The results are validated\nwith perceptual evaluations, where annotators are asked to assess the risk and\nfamiliarity of the videos detected with high anomaly scores. The results\nindicate that the driving segments with higher anomaly scores are more risky\nand less regularly seen on the road than other driving segments, validating the\nproposed unsupervised approach."
}