{
  "title": "Towards Fair Deep Anomaly Detection",
  "authors": "Hongjing Zhang, Ian Davidson",
  "year": 2020,
  "url": "http://arxiv.org/abs/2012.14961v1",
  "abstract": "Anomaly detection aims to find instances that are considered unusual and is a\nfundamental problem of data science. Recently, deep anomaly detection methods\nwere shown to achieve superior results particularly in complex data such as\nimages. Our work focuses on deep one-class classification for anomaly detection\nwhich learns a mapping only from the normal samples. However, the non-linear\ntransformation performed by deep learning can potentially find patterns\nassociated with social bias. The challenge with adding fairness to deep anomaly\ndetection is to ensure both making fair and correct anomaly predictions\nsimultaneously. In this paper, we propose a new architecture for the fair\nanomaly detection approach (Deep Fair SVDD) and train it using an adversarial\nnetwork to de-correlate the relationships between the sensitive attributes and\nthe learned representations. This differs from how fairness is typically added\nnamely as a regularizer or a constraint. Further, we propose two effective\nfairness measures and empirically demonstrate that existing deep anomaly\ndetection methods are unfair. We show that our proposed approach can remove the\nunfairness largely with minimal loss on the anomaly detection performance.\nLastly, we conduct an in-depth analysis to show the strength and limitations of\nour proposed model, including parameter analysis, feature visualization, and\nrun-time analysis."
}