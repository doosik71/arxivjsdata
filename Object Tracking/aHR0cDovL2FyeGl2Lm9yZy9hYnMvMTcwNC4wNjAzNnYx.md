# Correlation Filter 기반 추적을 위한 종단간(End-to-end) 표현 학습
Jack Valmadre, Luca Bertinetto, João F. Henriques, Andrea Vedaldi, Philip H. S. Torr

## 🧩 Problem to Solve
객체 추적은 초기 프레임의 단일 바운딩 박스만으로 보이지 않는 객체 클래스를 추적해야 하므로 온라인 학습이 필수적입니다. 기존의 딥러닝 기반 추적 방법은 두 가지 문제에 직면합니다. 첫째, 온라인 학습(예: SGD)은 훈련 데이터가 매우 제한적이고 모델 파라미터가 많아 어렵고 비용이 많이 듭니다. 둘째, 샴(Siamese) 네트워크는 오프라인에서 학습된 고정 임베딩을 사용하여 유사성을 기반으로 객체를 추적하지만, 비디오별 단서를 활용한 온라인 적응 능력이 부족합니다.

한편, 상관 필터(Correlation Filter, CF)는 푸리에 도메인에서 능률적인 릿지 회귀 문제를 풀어 이미지와 그 변환을 구별하는 선형 템플릿을 학습하는 효율적인 온라인 학습 알고리즘입니다. 그러나 기존의 CF 기반 추적기는 미리 학습된 CNN 특징을 단순히 활용했을 뿐, CNN과 CF가 긴밀하게 통합되어 종단간 방식으로 학습되지 않았습니다. 이로 인해 CNN 특징이 CF의 특정 작업에 최적화되지 못하는 한계가 있었습니다. 본 연구는 CF 학습자를 딥 뉴럴 네트워크의 미분 가능한 레이어로 해석하여 이 한계를 극복하고, CF에 긴밀하게 결합된 딥 특징을 학습하는 것을 목표로 합니다.

## ✨ Key Contributions
*   **미분 가능한 상관 필터 레이어**: 폐쇄형 해를 갖는 상관 필터 학습자를 딥 뉴럴 네트워크의 미분 가능한 레이어로 통합했습니다. 이를 통해 오류가 CF를 통해 CNN 특징으로 역전파될 수 있도록 하여 특징과 CF가 함께 학습될 수 있도록 했습니다.
*   **CF 기울기의 폐쇄형 표현**: 상관 필터의 미분(기울기)에 대한 폐쇄형 표현을 푸리에 도메인에서 효율적으로 유도하여, 대규모 선형 시스템의 해를 미분하는 문제를 해결했습니다.
*   **CFNet 아키텍처 제안**: 비대칭 샴 네트워크인 CFNet을 제안하여, 훈련 이미지에서 선형 템플릿을 학습하고 이를 테스트 이미지에 적용하여 교차 상관을 수행하는 구조를 갖습니다.
*   **경량 네트워크 성능 향상**: 본 방법론이 몇 천 개의 파라미터만 갖는 초경량 네트워크가 높은 프레임 속도에서 최첨단 성능을 달성할 수 있도록 중요한 실용적 이점을 제공함을 입증했습니다.
*   **심층 네트워크와의 관계 분석**: 상관 필터 계층을 통합하는 것이 네트워크 깊이가 얕을 때 성능을 크게 향상시키지만, 네트워크가 충분히 깊을 때는 그 효과가 줄어든다는 점을 발견하고 논의했습니다.

## 📎 Related Works
*   **상관 필터(CF) 기반 추적**: Bolme et al. [4]의 초기 연구 이후, 주기적 경계 효과 완화(Danelljan et al. [8], Kiani Galoogahi et al. [16]), 다중 해상도 특징 맵 통합(Ma et al. [22], Danelljan et al. [9]), 그리고 견고한 손실 함수 사용(Rodriguez et al. [27]) 등 다양한 개선 노력이 있었습니다.
*   **샴(Siamese) 네트워크 기반 추적**: 최근 Held et al. [13], Tao et al. [29], Bertinetto et al. [3] 등에 의해 도입되어 단순성과 경쟁력 있는 성능으로 주목받았습니다. 본 연구는 완전-컨볼루션 샴 아키텍처(Bertinetto et al. [3])를 기반으로 합니다.
*   **최적화 문제 해를 통한 역전파**: Ionescu et al. [15]는 SVD, Murray [25]는 Cholesky 분해를 통해 역전파 형태를 제시했습니다. 본 연구는 순환(circulant) 구조를 가진 선형 방정식 시스템의 해를 통해 효율적인 역전파 절차를 제공합니다.
*   **반복적 최적화의 RNN 해석**: 반복 과정을 순환 신경망으로 처리하고 고정된 수의 반복을 명시적으로 언롤링하는 접근 방식(Zheng et al. [37])이나 SGD 학습 절차 전체를 통한 역전파(Maclaurin et al. [24])도 있지만, CF는 폐쇄형 해를 가지므로 본 연구에서는 필요하지 않습니다.
*   **메타 학습**: 학습 알고리즘으로 해석될 수 있는 피드포워드 아키텍처를 제안하는 최근 연구(Bertinetto et al. [1], Vinyals et al. [31])와는 달리, 본 연구는 이미 널리 사용되는 기존 학습 문제에 기울기를 전파합니다.

## 🛠️ Methodology
본 논문은 기존의 완전-컨볼루션 샴 네트워크(SiamFC)를 수정하여 상관 필터(CF) 블록을 통합한 CFNet 아키텍처를 제안합니다.

1.  **완전-컨볼루션 샴 네트워크 기반**:
    *   훈련 이미지($x'$)와 테스트 이미지($z'$) 쌍을 입력으로 받습니다.
    *   CNN $f_{\rho}$를 통해 두 이미지의 특징 맵 $f_{\rho}(x')$와 $f_{\rho}(z')$를 추출합니다.
    *   두 특징 맵을 교차 상관($f_{\rho}(x') * f_{\rho}(z')$)하여 응답 맵(response map)을 생성합니다. 이 맵의 최대값이 객체의 위치를 나타냅니다.
    *   오프라인에서 로지스틱 손실 $\mathcal{L}(g_{\rho}(x'_i, z'_i), c_i)$를 최소화하여 네트워크를 훈련합니다.

2.  **CFNet 아키텍처**:
    *   응답 맵 계산 전에 CF 블록을 도입합니다.
    *   $h_{\rho,s,b}(x',z') = s\omega(f_{\rho}(x')) * f_{\rho}(z') + b$
    *   CF 블록 $\omega(x)$는 훈련 특징 맵 $x=f_{\rho}(x')$로부터 표준 CF 템플릿 $w$를 계산합니다. 이는 푸리에 도메인에서 릿지 회귀 문제를 풀어 얻어집니다.
    *   스칼라 파라미터 $s$(스케일)와 $b$(바이어스)를 추가하여 점수 범위를 로지스틱 회귀에 적합하게 조정합니다.
    *   순환 경계 효과를 줄이기 위해 특징 맵 $x$에 코사인 윈도우를 곱하고 최종 템플릿은 잘라냅니다.
    *   이 순방향(forward pass) 과정은 표준 CF 추적기의 동작과 일치하지만, 본 논문의 핵심은 이 CF 블록을 통해 역전파(back-propagation)가 가능하도록 만드는 것입니다.

3.  **상관 필터 역전파(Differentiable Correlation Filter Layer)**:
    *   상관 필터 문제는 $\arg \min_w \frac{1}{2n}\|w * x - y\|^2 + \frac{\lambda}{2}\|w\|^2$ 형태로 정의됩니다. 여기서 $w$는 템플릿, $x$는 입력 이미지, $y$는 원하는 응답입니다.
    *   이 문제의 해는 푸리에 도메인에서 폐쇄형으로 표현됩니다:
        $$
        \hat{k} = \frac{1}{n}(\hat{x}^* \circ \hat{x}) + \lambda\mathbf{1} \\
        \hat{\alpha} = \frac{1}{n}\hat{k}^{-1} \circ \hat{y} \\
        \hat{w} = \hat{\alpha}^* \circ \hat{x}
        $$
        여기서 $\hat{\cdot}$은 이산 푸리에 변환(DFT), $^*$는 복소 켤레, $\circ$는 요소별 곱셈입니다.
    *   역전파를 위해, 위의 푸리에 도메인 방정식들에 대한 미분(differentials)을 계산한 다음, 이 선형 맵의 수반(adjoint)을 사용하여 기울기 표현을 유도합니다. 예를 들어, $\hat{\nabla}_{x}\mathcal{L} = \hat{\alpha} \circ \hat{\nabla}_{w}\mathcal{L} + \frac{2}{n}\hat{x} \circ \text{Re}\{\hat{\nabla}_{k}\mathcal{L}\}$와 같은 최종 역전파 맵이 도출됩니다.
    *   이러한 방식을 통해 CF 학습자의 입력(특징 맵 $x$)에 대한 기울기를 효율적으로 계산하여 종단간 학습이 가능하게 합니다. 다채널 이미지에 대한 확장도 자연스럽게 이루어집니다.

4.  **추적 알고리즘**:
    *   매 프레임마다 새로운 템플릿을 계산하고 이를 이전 템플릿과 이동 평균 방식으로 결합합니다.
    *   객체의 새 위치는 응답 맵에서 가장 높은 점수를 갖는 위치로 결정됩니다.

## 📊 Results
*   **평가 기준**: OTB-2013, OTB-50, OTB-100 벤치마크를 테스트 세트로, VOT-2014/2016 및 Temple-Color 영상을 검증 세트로 사용했습니다. 성능은 평균 오버랩(IoU)과 성공률(AUC)로 측정했습니다.
*   **샴 네트워크 베이스라인과의 비교**:
    *   CFNet은 얕은 네트워크(깊이 1, 2)에서 베이스라인보다 훨씬 우수한 성능을 보였습니다 (각각 상대적 31%, 13% 향상).
    *   깊은 네트워크(깊이 3, 4, 5)에서는 성능 차이가 미미했습니다. CFNet의 성능은 네트워크 깊이에 크게 영향을 받지 않고 빠르게 포화된 반면, 베이스라인은 깊이에 따라 꾸준히 향상되었습니다.
    *   이는 CF의 적응 능력이 충분히 표현력이 강한 임베딩 함수가 주어졌을 때는 덜 중요해짐을 시사합니다.
*   **특징 전이 실험**:
    *   `Baseline+CF`(오프라인 학습된 베이스라인 특징에 CF 적용)는 깊은 레이어에서 CFNet과 유사한 성능을 보였지만, 얕은 레이어에서는 CFNet의 종단간 학습이 결정적이었습니다.
    *   `ImageNet+CF`(ImageNet 사전 학습 특징에 CF 적용)는 CFNet과 Baseline 실험보다 현저히 낮은 성능을 보였습니다. 이는 분류를 위해 학습된 깊은 레이어 특징이 추적에 필요한 위치 불변성이 너무 커서 적합하지 않음을 나타냅니다.
*   **온라인 적응의 중요성**:
    *   `CFNet-const`(라그랑주 승수가 오프라인에서 학습되어 고정된 버전)와 비교했을 때, CFNet은 지속적으로 더 나은 성능을 보였습니다. 이는 역 컨볼루션 문제의 해(온라인 적응)를 통한 역전파의 중요성을 입증합니다.
*   **최첨단 성능 비교**:
    *   CFNet-conv2는 Baseline-conv5와 필적하는 정확도를 보였으며, 이는 약 30배 적은 파라미터로 달성되었습니다.
    *   전반적으로 제안된 CFNet 변형(CFNet-conv2, CFNet-conv5, Baseline+CF-conv3)은 기존의 실시간 최첨단 추적기(SiamFC-3s, Staple, LCT 등)에 비해 미미하게 우수하거나 필적하는 성능을 달성했습니다.
*   **속도 및 실용적 이점**:
    *   2-레이어 CFNet(CFNet-conv2)은 75 FPS로 실행되며, 5-레이어 베이스라인의 4% 미만의 파라미터(600KB 저장 공간)를 사용하여 높은 정확도를 제공합니다.
    *   이는 제한된 메모리를 가진 임베디드 장치에 특히 유용하며, 기존의 딥 CF 기반 방법보다 훨씬 빠릅니다.

## 🧠 Insights & Discussion
본 연구는 상관 필터를 딥 뉴럴 네트워크의 미분 가능한 레이어로 성공적으로 통합하여 종단간 특징 학습을 가능하게 했습니다. 핵심적인 통찰은 상관 필터 레이어가 특히 얕은 네트워크에서 특징 표현의 한계를 보완하는 데 매우 효과적이라는 것입니다. 얕은 네트워크는 표현력이 제한적일 수 있지만, CF의 온라인 적응 능력은 이러한 네트워크가 고성능을 발휘하도록 돕습니다. 그러나 네트워크가 충분히 깊어지면, 대규모 데이터로 학습된 딥 특징 자체의 표현력이 매우 뛰어나기 때문에, CF 레이어를 통한 명시적인 온라인 적응의 이점은 상대적으로 감소합니다. 이는 딥러닝이 충분한 데이터가 주어졌을 때 얼마나 강력한지를 보여주는 증거입니다.

실용적인 측면에서 CFNet은 매우 중요한 기여를 합니다. 특히 2-레이어 CFNet은 최첨단 성능을 유지하면서도 매우 적은 파라미터와 높은 프레임 속도를 자랑하여, 자원 제약이 있는 환경(예: 임베디드 시스템)에 매우 적합합니다. 이는 정확도와 속도 사이의 트레이드오프에서 강력한 옵션을 제공합니다. 본 연구는 경량 모델의 성능을 향상시키는 새로운 패러다임을 제시하며, 학습 알고리즘 자체를 네트워크에 통합하는 메타 학습의 방향성과도 연결될 수 있습니다.

한계점으로는 바운딩 박스 회귀, 다중 단서 앙상블, 광학 흐름과 같은 추가적인 추적 개선 기술을 포함하지 않았다는 점이 있습니다. 향후 연구는 시간에 따른 적응(adaptation over time)을 고려하거나, 원샷 학습(one-shot learning) 및 도메인 적응(domain adaptation)과 같은 관련 작업의 학습 문제에 대한 역전파로 확장을 모색할 수 있습니다.

## 📌 TL;DR
상관 필터(CF)의 효율적인 온라인 적응 능력과 딥 CNN의 강력한 특징 학습 능력을 결합하기 위해, 본 논문은 CF 학습자를 딥 뉴럴 네트워크의 미분 가능한 레이어로 통합한 **CFNet**을 제안합니다. CF의 폐쇄형 해에 대한 기울기를 푸리에 도메인에서 효율적으로 유도하여 종단간 학습을 가능하게 합니다. 실험 결과, CFNet은 **경량의 얕은 네트워크**에서도 최첨단 추적 성능을 달성하며 **높은 프레임 속도**를 유지하여 메모리 제약이 있는 환경에 특히 유용함을 입증했습니다. 깊은 네트워크에서는 CF 레이어의 성능 기여가 줄어들어, 충분히 강력한 딥 특징이 온라인 적응의 필요성을 대체할 수 있음을 시사합니다.