{
  "title": "SiamTHN: Siamese Target Highlight Network for Visual Tracking",
  "authors": "Jiahao Bao, Kaiqiang Chen, Xian Sun, Liangjin Zhao, Wenhui Diao, Menglong Yan",
  "year": 2023,
  "url": "http://arxiv.org/abs/2303.12304v1",
  "abstract": "Siamese network based trackers develop rapidly in the field of visual object\ntracking in recent years. The majority of siamese network based trackers now in\nuse treat each channel in the feature maps generated by the backbone network\nequally, making the similarity response map sensitive to background influence\nand hence challenging to focus on the target region. Additionally, there are no\nstructural links between the classification and regression branches in these\ntrackers, and the two branches are optimized separately during training.\nTherefore, there is a misalignment between the classification and regression\nbranches, which results in less accurate tracking results. In this paper, a\nTarget Highlight Module is proposed to help the generated similarity response\nmaps to be more focused on the target region. To reduce the misalignment and\nproduce more precise tracking results, we propose a corrective loss to train\nthe model. The two branches of the model are jointly tuned with the use of\ncorrective loss to produce more reliable prediction results. Experiments on 5\nchallenging benchmark datasets reveal that the method outperforms current\nmodels in terms of performance, and runs at 38 fps, proving its effectiveness\nand efficiency."
}