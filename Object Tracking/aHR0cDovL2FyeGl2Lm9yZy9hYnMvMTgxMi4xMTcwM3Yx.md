# SiamRPN++: Evolution of Siamese Visual Tracking with Very Deep Networks

Bo Li, Wei Wu, Qiang Wang, Fangyi Zhang, Junliang Xing, Junjie Yan

## 🧩 Problem to Solve

Siamese 네트워크 기반 트래커는 타겟 템플릿과 탐색 영역 간의 컨볼루션 특징 교차 상관을 통해 시각 추적을 수행합니다. 그러나 기존 Siamese 트래커는 최신 알고리즘에 비해 정확도 격차가 존재하며, ResNet-50과 같이 깊은 네트워크의 강력한 특징 표현 능력을 충분히 활용하지 못했습니다. 이는 깊은 네트워크 사용 시 엄격한 변환 불변성(strict translation invariance)이 손상되기 때문으로 분석되었습니다.

## ✨ Key Contributions

- 깊은 네트워크를 Siamese 트래커에 적용할 때 정확도가 저하되는 핵심 이유가 엄격한 변환 불변성 파괴 때문임을 이론적 분석 및 실험을 통해 증명했습니다.
- 공간 인지 샘플링(spatial aware sampling) 전략을 제안하여 공간 불변성 제약을 해결하고, ResNet 아키텍처 기반의 Siamese 트래커를 성공적으로 학습시켰습니다.
- 교차 상관 연산을 위한 계층별 특징 결합(layer-wise feature aggregation) 구조를 제안하여, 다양한 레벨에서 학습된 특징들을 활용함으로써 추적 정확도를 향상시켰습니다.
- 깊이별 분리 교차 상관(depth-wise separable correlation) 구조를 제안하여 모델 크기를 줄이고 학습 과정을 안정화했으며, 의미론적으로 풍부한 상관 맵을 생성하도록 했습니다.
- 제안된 SiamRPN++는 OTB2015, VOT2018, UAV123, LaSOT, TrackingNet 등 5개 주요 추적 벤치마크에서 현재까지 최고의 결과를 달성하며, 35 FPS로 효율적으로 작동합니다.

## 📎 Related Works

- **Siamese 네트워크 기반 트래커:** SiamFC [1], CFNet [41], DaSiamRPN [52] 등 시각 추적 문제를 교차 상관 문제로 정식화하여 높은 효율성을 보입니다. 그러나 기존 Siamese 트래커는 AlexNet과 유사한 얕은 네트워크 아키텍처를 기반으로 하여 깊은 네트워크의 이점을 충분히 활용하지 못했습니다.
- **상관 필터(Correlation Filter, CF) 기반 트래커:** ECO [5], MDNet [32] 등은 딥 피처 표현과 함께 최첨단 정확도를 달성했습니다.
- **깊은 아키텍처:** AlexNet [23] 이후 VGGNet [37], ResNet [14], MobileNet [18] 등 다양한 정교한 딥 네트워크 아키텍처가 제안되었습니다. 기존 딥 비주얼 트래커에서는 AlexNet 또는 VGGNet을 기반으로 한 얕은 네트워크를 사용했는데, 이는 얕은 특징이 객체의 정확한 위치 파악에 기여한다는 인식이 있었기 때문입니다.

## 🛠️ Methodology

1. **Siamese 네트워크 분석:**
   - Siamese 트래커의 내재적 제약인 '엄격한 변환 불변성'($f(z,x[\Delta\tau_{j}]) = f(z,x)[\Delta\tau_{j}]$)과 '구조 대칭성'($f(z,x') = f(x',z)$)을 분석했습니다.
   - 깊은 네트워크에 포함된 패딩(padding)이 엄격한 변환 불변성을 손상시켜 '중심 편향(center bias)'을 유발함을 밝혀냈습니다. 이는 학습된 모델이 이미지 중앙에 있는 객체에 더 강하게 반응하게 만듭니다.
2. **공간 인지 샘플링(Spatial Aware Sampling) 전략:**
   - 학습 시 무작위 번역(random translation, 예를 들어 $\pm 32$ 픽셀 또는 $\pm 64$ 픽셀)을 적용하여 양성 샘플의 확률 분포를 균일하게 만들었습니다. 이는 모델이 중심 편향에 빠지는 것을 방지하고, 깊은 네트워크를 성공적으로 학습할 수 있게 합니다.
3. **ResNet 기반 Siamese 트래킹:**
   - ResNet-50 백본 네트워크를 수정하여 `conv4` 및 `conv5` 블록의 유효 스트라이드(effective stride)를 16/32 픽셀에서 8 픽셀로 줄이기 위해 확장 컨볼루션(dilated convolutions)을 사용했습니다. 이는 밀집된 예측에 적합하도록 특징 맵의 공간 해상도를 유지합니다.
   - 각 블록 출력에 $1 \times 1$ 컨볼루션 레이어를 추가하여 채널 수를 256으로 줄였습니다.
   - 템플릿 특징으로 중앙 $7 \times 7$ 영역만 잘라내어 계산 부담을 줄였습니다.
   - 학습 시 ResNet 특징 추출기 부분의 학습률을 RPN 부분보다 10배 낮게 설정하여 특징 표현이 추적 작업에 더 적합하도록 미세 조정(fine-tuning)했습니다. 전체 네트워크를 종단 간(end-to-end) 방식으로 공동 학습했습니다.
4. **계층별 특징 결합(Layer-wise Aggregation):**
   - ResNet-50의 마지막 세 잔여 블록(conv3, conv4, conv5)에서 추출된 다중 레벨 특징($F_{3}, F_{4}, F_{5}$)을 활용합니다.
   - 각 레벨의 특징은 개별적인 Siamese RPN 모듈에 입력됩니다.
   - 각 RPN 모듈의 출력(분류 점수 $S_{l}$ 및 바운딩 박스 회귀 $B_{l}$)은 가중치 합계를 통해 최종 결과로 결합됩니다:
     $$S_{all} = \sum_{l=3}^{5} \alpha_{l} \cdot S_{l}, \quad B_{all} = \sum_{l=3}^{5} \beta_{l} \cdot B_{l}$$
   - 여기서 $\alpha_{l}$과 $\beta_{l}$은 네트워크와 함께 종단 간 최적화되는 학습 가능한 가중치입니다. 이 접근 방식은 저수준의 위치 정보와 고수준의 의미론적 정보를 모두 활용하여 정확도와 강건성을 높입니다.
5. **깊이별 분리 교차 상관(Depthwise Cross Correlation, DW-XCorr):**
   - 기존 SiamRPN에서 사용된 Up-Channel Cross Correlation (UP-XCorr) 레이어를 DW-XCorr로 대체했습니다. DW-XCorr는 UP-XCorr보다 파라미터 수가 10배 적어 계산 비용과 메모리 사용량을 크게 줄입니다.
   - 템플릿 및 탐색 브랜치는 공유되지 않는 컨볼루션 레이어를 통과한 후, 채널별로 상관 연산을 수행합니다.
   - 추가적인 conv-bn-relu 블록이 다양한 채널 출력을 융합하며, 최종 컨볼루션 레이어가 분류 또는 회귀 출력을 생성합니다.
   - 이 구조는 두 브랜치의 파라미터 분포를 균형 있게 만들어 학습 과정을 더욱 안정화하며, 각 채널이 특정 의미론적 정보를 나타내는 현상을 보였습니다 (예: 특정 채널은 자동차, 특정 채널은 사람/얼굴에 강하게 반응).

## 📊 Results

- **최첨단 성능 달성:** OTB2015, VOT2018, UAV123, LaSOT, TrackingNet 등 5개의 주요 벤치마크에서 일관되게 최상의 추적 결과를 얻었습니다.
- **OTB2015:** 이전 DaSiamRPN 대비 오버랩 AUC에서 3.8%, 정밀도에서 3.4% 향상되었습니다. Siamese 트래커 중 OTB2015에서 SOTA 성능을 달성한 최초의 사례입니다.
- **VOT2018:** EAO 0.414, 정확도 0.600, AO 0.498로 모든 기준에서 1위를 차지했습니다. VOT2018 챌린지 우승자인 LADCF보다 EAO에서 2.5%p, MFT보다 정확도에서 9.5%p 높은 성능을 보였습니다. DaSiamRPN 대비 강건성(robustness)에서 10.3%p의 큰 향상을 이뤘습니다.
- **VOT2018-LT (장기 추적):** DaSiamLT 대비 F-score에서 2.2%p, 당시 최고 트래커 대비 1.9%p 향상된 성능을 보였고, 21 FPS로 동작했습니다.
- **UAV123:** 성공 점수(success score) 0.613으로 DaSiamRPN(0.586) 및 ECO(0.525)를 크게 능가했습니다.
- **LaSOT:** AUC 49.6%를 달성했으며, MDNet 대비 정규화된 거리 정밀도(normalized distance precision)와 AUC를 각각 23.7%p, 24.9%p 향상시켰습니다.
- **TrackingNet:** AUC 73.3%, P 69.4%, P_norm 80.0%로 모든 지표에서 최고 점수를 기록했으며, 2위 DaSiamRPN 대비 AUC에서 9.5%p, P에서 10.3%p, P_norm에서 6.6%p 높은 성능을 보였습니다.
- **속도:** ResNet-50 백본으로 35 FPS의 실시간 추적 속도를 제공합니다. ResNet-18 또는 MobileNetV2 백본을 사용한 빠른 변형 모델은 70 FPS 이상의 속도로 경쟁력 있는 성능을 유지합니다.
- **어블레이션 스터디:**
  - **백본 아키텍처:** AlexNet에서 ResNet-50으로 변경 시 성능이 크게 향상되었으며, 백본의 미세 조정이 성능에 결정적인 영향을 미침을 확인했습니다.
  - **계층별 특징 결합:** 단일 RPN 모듈 대비 여러 레이어(conv3, conv4, conv5)를 결합했을 때 정확도와 강건성이 꾸준히 향상되었습니다.
  - **깊이별 교차 상관:** DW-XCorr는 UP-XCorr 대비 VOT2018에서 2.3%p, OTB2015에서 0.8%p의 성능 향상을 가져왔으며, 이는 균형 잡힌 파라미터 분포와 안정적인 학습에 기인합니다.

## 🧠 Insights & Discussion

- 이 연구의 핵심 통찰은 깊은 신경망을 Siamese 트래커에 성공적으로 통합하기 위해서는 네트워크 패딩으로 인해 발생하는 변환 불변성 손상 문제를 해결해야 한다는 것입니다. 제안된 공간 인지 샘플링 전략이 이 문제를 효과적으로 완화하여 ResNet과 같은 깊은 모델의 활용을 가능하게 했습니다.
- 계층별 특징 결합은 깊은 네트워크의 풍부한 계층적 특징(정확한 위치를 위한 저수준 특징과 의미론적 정보를 위한 고수준 특징)을 효과적으로 활용하여, 추적의 정확도와 특히 모션 블러나 큰 변형과 같은 어려운 시나리오에서의 강건성을 향상시켰습니다.
- 깊이별 교차 상관은 모델의 복잡성을 줄이고 추론 속도를 높일 뿐만 아니라, 학습 안정성을 개선하고 의미론적으로 해석 가능한 채널별 특징을 생성하는 부수적인 이점도 제공합니다. 이는 특정 객체 카테고리에 대한 채널별 반응을 통해 시각적으로 입증되었습니다.
- SiamRPN++는 이전 Siamese 트래커의 주요 약점이었던 강건성을 크게 개선했지만, 여전히 온라인 업데이트에 의존하는 일부 상관 필터 기반 방법보다는 부족한 부분이 있습니다. 이는 온라인 적응이 매우 중요한 특정 시나리오에서 추가 개선의 여지를 시사합니다.
- 다양하고 대규모의 데이터셋(LaSOT, TrackingNet)에서 일관된 SOTA 성능을 달성한 것은 SiamRPN++의 뛰어난 일반화 능력을 입증하며, 실제 응용 분야에서의 실용성을 높입니다.

## 📌 TL;DR

- **문제:** 기존 Siamese 트래커는 깊은 네트워크(ResNet)를 활용하기 어렵고, 엄격한 변환 불변성 부족으로 인해 정확도에 한계가 있었습니다.
- **제안 방법:** 이 논문은 깊은 네트워크에서 발생하는 변환 불변성 파괴 문제가 패딩(padding) 때문임을 밝히고, 이를 해결하기 위해 '공간 인지 샘플링(spatial aware sampling)' 전략을 도입했습니다. 또한, 깊은 네트워크의 이점을 최대한 활용하기 위해 '계층별 특징 결합(layer-wise aggregation)'과 '깊이별 교차 상관(depth-wise cross correlation)' 구조를 제안했습니다.
- **주요 성과:** 제안된 SiamRPN++는 OTB2015, VOT2018, UAV123, LaSOT, TrackingNet 등 5개의 주요 벤치마크에서 SOTA(State-of-the-Art) 성능을 달성했으며, 실시간(35 FPS 이상)으로 동작합니다. 이는 Siamese 트래커가 깊은 네트워크의 잠재력을 완전히 활용할 수 있음을 증명했습니다.
