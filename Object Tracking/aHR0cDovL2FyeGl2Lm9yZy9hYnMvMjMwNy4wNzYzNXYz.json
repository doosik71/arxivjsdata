{
  "url": "http://arxiv.org/abs/2307.07635v3",
  "title": "CoTracker: It is Better to Track Together",
  "authors": "Nikita Karaev, Ignacio Rocco, Benjamin Graham, Natalia Neverova, Andrea Vedaldi, Christian Rupprecht",
  "year": 2023,
  "abstract": "We introduce CoTracker, a transformer-based model that tracks a large number\nof 2D points in long video sequences. Differently from most existing approaches\nthat track points independently, CoTracker tracks them jointly, accounting for\ntheir dependencies. We show that joint tracking significantly improves tracking\naccuracy and robustness, and allows CoTracker to track occluded points and\npoints outside of the camera view. We also introduce several innovations for\nthis class of trackers, including using token proxies that significantly\nimprove memory efficiency and allow CoTracker to track 70k points jointly and\nsimultaneously at inference on a single GPU. CoTracker is an online algorithm\nthat operates causally on short windows. However, it is trained utilizing\nunrolled windows as a recurrent network, maintaining tracks for long periods of\ntime even when points are occluded or leave the field of view. Quantitatively,\nCoTracker substantially outperforms prior trackers on standard point-tracking\nbenchmarks."
}