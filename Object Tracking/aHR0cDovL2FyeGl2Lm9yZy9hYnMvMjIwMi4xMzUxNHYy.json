{
  "url": "http://arxiv.org/abs/2202.13514v2",
  "title": "StrongSORT: Make DeepSORT Great Again",
  "authors": "Yunhao Du, Zhicheng Zhao, Yang Song, Yanyun Zhao, Fei Su, Tao Gong, Hongying Meng",
  "year": 2022,
  "abstract": "Recently, Multi-Object Tracking (MOT) has attracted rising attention, and\naccordingly, remarkable progresses have been achieved. However, the existing\nmethods tend to use various basic models (e.g, detector and embedding model),\nand different training or inference tricks, etc. As a result, the construction\nof a good baseline for a fair comparison is essential. In this paper, a classic\ntracker, i.e., DeepSORT, is first revisited, and then is significantly improved\nfrom multiple perspectives such as object detection, feature embedding, and\ntrajectory association. The proposed tracker, named StrongSORT, contributes a\nstrong and fair baseline for the MOT community. Moreover, two lightweight and\nplug-and-play algorithms are proposed to address two inherent \"missing\"\nproblems of MOT: missing association and missing detection. Specifically,\nunlike most methods, which associate short tracklets into complete trajectories\nat high computation complexity, we propose an appearance-free link model\n(AFLink) to perform global association without appearance information, and\nachieve a good balance between speed and accuracy. Furthermore, we propose a\nGaussian-smoothed interpolation (GSI) based on Gaussian process regression to\nrelieve the missing detection. AFLink and GSI can be easily plugged into\nvarious trackers with a negligible extra computational cost (1.7 ms and 7.1 ms\nper image, respectively, on MOT17). Finally, by fusing StrongSORT with AFLink\nand GSI, the final tracker (StrongSORT++) achieves state-of-the-art results on\nmultiple public benchmarks, i.e., MOT17, MOT20, DanceTrack and KITTI. Codes are\navailable at https://github.com/dyhBUPT/StrongSORT and\nhttps://github.com/open-mmlab/mmtracking."
}