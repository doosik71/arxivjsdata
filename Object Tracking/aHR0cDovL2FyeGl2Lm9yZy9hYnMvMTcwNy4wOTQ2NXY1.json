{
  "url": "http://arxiv.org/abs/1707.09465v5",
  "title": "Curriculum Domain Adaptation for Semantic Segmentation of Urban Scenes",
  "authors": "Yang Zhang, Philip David, Boqing Gong",
  "year": 2017,
  "abstract": "During the last half decade, convolutional neural networks (CNNs) have\ntriumphed over semantic segmentation, which is one of the core tasks in many\napplications such as autonomous driving. However, to train CNNs requires a\nconsiderable amount of data, which is difficult to collect and laborious to\nannotate. Recent advances in computer graphics make it possible to train CNNs\non photo-realistic synthetic imagery with computer-generated annotations.\nDespite this, the domain mismatch between the real images and the synthetic\ndata cripples the models' performance. Hence, we propose a curriculum-style\nlearning approach to minimize the domain gap in urban scenery semantic\nsegmentation. The curriculum domain adaptation solves easy tasks first to infer\nnecessary properties about the target domain; in particular, the first task is\nto learn global label distributions over images and local distributions over\nlandmark superpixels. These are easy to estimate because images of urban scenes\nhave strong idiosyncrasies (e.g., the size and spatial relations of buildings,\nstreets, cars, etc.). We then train a segmentation network while regularizing\nits predictions in the target domain to follow those inferred properties. In\nexperiments, our method outperforms the baselines on two datasets and two\nbackbone networks. We also report extensive ablation studies about our\napproach."
}