# Learning Spatio-Temporal Transformer for Visual Tracking
Bin Yan, Houwen Peng, Jianlong Fu, Dong Wang, Huchuan Lu

## 🧩 Problem to Solve
기존 시각 객체 추적 방법론들은 컨볼루션 신경망(CNN)에 기반하고 있어, 공간적 또는 시간적 범위에서 인접한 영역만 처리하므로 이미지 내용과 피처 간의 장거리 의존성을 모델링하는 데 한계가 있습니다. 이러한 단점은 객체의 크기 변화가 크거나 시야에 자주 나타났다가 사라지는 시나리오에서 전역 컨텍스트 정보가 중요할 때 모델의 성능을 저하시킬 수 있습니다. 또한, 기존 추적 파이프라인은 바운딩 박스 제안 및 코사인 윈도우, 바운딩 박스 스무딩과 같은 복잡한 후처리 단계를 필요로 하여 하이퍼파라미터에 민감하고 추적 과정을 복잡하게 만듭니다.

## ✨ Key Contributions
*   **새로운 트랜스포머 기반 추적 아키텍처 제안:** 비디오 시퀀스에서 공간 및 시간 정보 모두의 전역 피처 의존성을 포착할 수 있는 STARK(Spatio-Temporal Transformer Network for Visual Tracking)를 제안합니다.
*   **간소화된 엔드-투-엔드 파이프라인:** 제안된 방법은 기존 추적 파이프라인을 크게 간소화하여 코사인 윈도우, 바운딩 박스 스무딩과 같은 후처리 단계가 필요 없는 완전한 엔드-투-엔드 방식으로 동작합니다. 객체 추적을 제안(proposal)이나 사전 정의된 앵커(anchor) 없이 직접적인 바운딩 박스 예측 문제로 전환합니다.
*   **최고 수준의 성능 및 실시간 속도 달성:** 5개의 도전적인 단기 및 장기 벤치마크에서 최신 기술(state-of-the-art) 성능을 달성하는 동시에 실시간 속도로 작동합니다.

## 📎 Related Works
*   **언어 및 비전 분야의 트랜스포머:** Vaswani et al. [46]의 오리지널 트랜스포머에서 영감을 받았으며, 최근 객체 탐지 모델 DETR [5]에 기반합니다. DETR은 객체 탐지, 본 연구는 객체 추적이라는 점에서 차이가 있으며, 네트워크 입력(DETR은 전체 이미지, 본 연구는 검색 영역 및 두 개의 템플릿), 쿼리 설계 및 학습 전략(DETR은 100개의 쿼리 및 Hungarian 알고리즘 사용, 본 연구는 단일 쿼리 및 Hungarian 알고리즘 미사용), 바운딩 박스 헤드(DETR은 3-레이어 퍼셉트론, 본 연구는 코너 기반 헤드) 등에서 차별점을 가집니다. 또한, 최근의 트랜스포머 기반 추적 연구인 TransTrack [44] 및 TrackFormer [35]와도 입력(본 연구는 초기 템플릿, 동적 템플릿, 검색 영역의 세 가지), 객체 쿼리 업데이트 방식 등에서 차이를 보입니다.
*   **공간-시간 정보 활용:** 기존 추적기는 공간 정보만 활용하는 시아미즈(Siamese) 기반 [2, 26, 25, 60, 29]와 공간 및 시간 정보를 함께 활용하는 방법으로 나뉩니다. 후자의 경우 경사 기반(gradient-based) [37, 9, 3] 및 경사 없는(gradient-free) [54, 57, 8] 방식으로 분류되는데, 대부분의 방법은 공간과 시간 정보를 분리하여 처리하는 경향이 있습니다. 본 연구는 트랜스포머를 통해 공간 및 시간 정보를 통합하여 학습합니다.
*   **추적 파이프라인 및 후처리:** 기존 추적기 [25, 51, 60, 47]는 복잡한 파이프라인과 다수의 후처리 단계를 포함하여 하이퍼파라미터에 민감했습니다. 본 연구는 단일 바운딩 박스를 직접 예측하여 이러한 복잡성을 해소합니다.

## 🛠️ Methodology
본 논문은 `STARK`라는 시각 객체 추적을 위한 공간-시간 트랜스포머 네트워크를 제안합니다.

1.  **단순한 트랜스포머 기반 베이스라인 (공간 전용 추적):**
    *   **백본(Backbone):** ResNet [15]을 사용하여 초기 대상 객체 템플릿 $z \in R^{3 \times H_{z} \times W_{z}}$와 현재 프레임의 검색 영역 $x \in R^{3 \times H_{x} \times W_{x}}$에서 피처 맵 $f_{z}$, $f_{x}$를 추출합니다.
    *   **인코더(Encoder):** 백본에서 출력된 피처 맵들의 채널 수를 줄인 후, 공간 차원을 따라 평탄화(flatten)하고 연결(concatenate)하여 트랜스포머 인코더의 입력 시퀀스를 생성합니다. 인코더는 다중 헤드 셀프-어텐션과 피드포워드 네트워크로 구성되며, 원본 트랜스포머의 순열 불변성을 해결하기 위해 위치 임베딩을 추가합니다.
    *   **디코더(Decoder):** 단일 타겟 쿼리(DETR [5]와 달리 하나의 바운딩 박스만 예측하므로)와 인코더의 강화된 피처 시퀀스를 입력으로 받습니다. 셀프-어텐션, 인코더-디코더 어텐션, 피드포워드 네트워크로 구성되며, 타겟 쿼리가 템플릿 및 검색 영역의 모든 위치에 주의를 기울여 최종 바운딩 박스 예측을 위한 견고한 표현을 학습합니다.
    *   **헤드(Head) (코너 기반 예측):**
        *   검색 영역 피처와 디코더의 출력 임베딩 간의 유사도를 계산합니다.
        *   유사도 점수를 검색 영역 피처와 요소별로 곱하여 중요 영역을 강화합니다.
        *   새로운 피처 시퀀스를 피처 맵 $f \in R^{d \times H_{s}^{s} \times W_{s}^{s}}$로 재구성한 후, 단순 완전 컨볼루션 네트워크(FCN)에 입력합니다.
        *   FCN은 객체 바운딩 박스의 좌상단($P_{tl}(x,y)$) 및 우하단($P_{br}(x,y)$) 코너에 대한 확률 맵을 출력합니다.
        *   예측된 코너 좌표 $(\hat{x}_{tl}, \hat{y}_{tl})$ 및 $(\hat{x}_{br}, \hat{y}_{br})$은 각 코너 확률 분포의 기댓값을 계산하여 얻습니다:
        $$(\hat{x}_{tl}, \hat{y}_{tl}) = \left(\sum_{y=0}^H \sum_{x=0}^W x \cdot P_{tl}(x,y), \sum_{y=0}^H \sum_{x=0}^W y \cdot P_{tl}(x,y)\right)$$
        및 유사하게 우하단 코너에 대해 계산합니다.
    *   **학습 및 추론:** L1 손실과 IoU 손실 [41]의 조합으로 엔드-투-엔드 학습됩니다. 분류 손실 및 Hungarian 알고리즘은 사용되지 않습니다. 추론 시에는 첫 프레임의 템플릿 이미지가 고정되며, 후처리 없이 예측된 박스가 최종 결과로 사용됩니다.

2.  **공간-시간 트랜스포머 추적 (STARK-ST):**
    *   **입력:** 초기 템플릿 외에 동적으로 업데이트되는 템플릿을 추가 입력으로 도입하여 시간 경과에 따른 객체 외관 변화를 포착합니다. 인코더는 이 세 가지 입력 간의 전역 관계를 모델링하여 판별적인 공간-시간 피처를 추출합니다.
    *   **스코어 헤드(Score Head):** 현재 상태가 신뢰할 수 있는지 판단하는 단순한 3-레이어 퍼셉트론 형태의 스코어 예측 헤드를 추가합니다. 이 점수가 임계값 $\tau$보다 높을 때만 동적 템플릿이 업데이트됩니다.
    *   **학습 및 추론:**
        *   **2단계 학습:**
            1.  **위치 파악(Localization) 단계:** 스코어 헤드를 제외한 전체 네트워크를 위치 파악 관련 손실(식 2)로 학습시켜 모델이 위치 파악 능력을 학습하도록 합니다.
            2.  **분류(Classification) 단계:** 스코어 헤드만 이진 교차 엔트로피 손실(식 3)로 최적화하며, 다른 파라미터는 고정시켜 위치 파악 능력에 영향을 주지 않도록 합니다.
        *   **추론:** 동적 템플릿은 업데이트 간격 $T_u$에 도달하고 예측된 신뢰도 점수가 임계값 $\tau$보다 높을 때만 업데이트됩니다.

## 📊 Results
*   **전반적 성능:** STARK는 GOT-10K, TrackingNet, VOT2020 (단기), LaSOT, VOT2020-LT (장기) 등 5가지 벤치마크에서 기존의 최첨단 추적기들을 능가하는 새로운 SOTA 성능을 달성하면서 실시간 속도를 유지합니다.
*   **GOT-10K:** STARK-ST101 (ResNet-101 백본)은 Siam R-CNN [47]보다 AO 스코어에서 3.9% 높은 68.8%를 달성했습니다.
*   **TrackingNet:** STARK-ST101은 AUC 82.0%를 달성하여 Siam R-CNN [47]보다 0.8% 우수합니다.
*   **VOT2020:** STARK-ST50+AR (AlphaRef [22]의 정제 모듈 추가)은 EAO 0.505를 달성하여 AlphaRef [22] 및 OceanPlus [60]와 같은 기존 SOTA 추적기들을 뛰어넘습니다.
*   **LaSOT:** STARK-ST101은 성공률 67.1%로 Siam R-CNN [47]보다 2.3% 높습니다.
*   **VOT2020-LT:** STARK-ST50 및 STARK-ST101은 F-스코어 70.2% 및 70.1%를 달성하여 모든 이전 방법들을 능가하며, LTMU$_{B}$ [8]와 같은 복잡한 프레임워크에 비해 훨씬 단순한 구조를 가집니다.
*   **속도, FLOPs, 파라미터:** STARK-S50은 40fps 이상으로 실시간 작동하며, SiamRPN++ [25]에 비해 FLOPs는 4배, 파라미터는 2배 적습니다. STARK-ST는 동적 템플릿 추가에도 불구하고 FLOPs 및 파라미터 증가가 미미하여 거의 비용 없이 시간 정보를 활용함을 보여줍니다. STARK-ST101은 Siam R-CNN (5fps)보다 6배 빠른 31.7fps로 작동합니다.

## 🧠 Insights & Discussion
*   **구성 요소별 분석:**
    *   **인코더:** 인코더 제거 시 성능이 5.3% 크게 하락하여, 템플릿과 검색 영역 피처 간의 깊은 상호 작용이 핵심임을 보여줍니다.
    *   **디코더:** 디코더 제거 시 성능이 1.9% 하락하여 인코더보다는 덜 중요하지만 여전히 의미 있는 역할을 합니다.
    *   **위치 인코딩:** 위치 인코딩 제거 시 성능 하락이 0.2%에 불과하여 본 방법에서는 핵심 구성 요소가 아님을 시사합니다.
    *   **코너 예측 헤드:** DETR [5]의 MLP 헤드로 교체 시 성능이 2.7% 낮아져, 제안된 코너 기반 헤드가 더 정확한 박스 예측을 제공함을 입증합니다.
    *   **스코어 헤드:** 스코어 헤드 제거 시 성능이 64.5%로 동적 템플릿을 사용하지 않는 STARK-S50보다도 낮아져, 신뢰할 수 없는 템플릿을 걸러내는 것이 매우 중요함을 보여줍니다.
*   **다른 프레임워크와의 비교:**
    *   **템플릿 이미지를 쿼리로 사용하는 방식:** 본 제안 방식보다 5.2% 낮은 성능을 보였습니다. 템플릿에서 검색 영역으로의 정보 흐름이 부족하여 판별력이 약화되는 것으로 추정됩니다.
    *   **Hungarian 알고리즘 사용 (K개의 쿼리):** 2.7% 낮은 성능을 보였습니다. 훈련 초기 일부 쿼리가 더 정확한 예측을 하고, 이것이 다시 선택되어 성능 격차가 커지는 "마태 효과(Matthew effect)"가 발생했습니다.
    *   **쿼리 임베딩 업데이트 (TrackFormer [35]와 유사):** 1.6% 낮은 성능을 보였습니다. 추가 동적 템플릿에 비해 업데이트 가능한 쿼리 임베딩이 제공하는 추가 정보가 적기 때문으로 추정됩니다.
    *   **위치 파악 및 분류 동시 학습:** 3.9% 낮은 성능을 보였습니다. 스코어 헤드 최적화가 박스 헤드 훈련을 방해하고, 두 태스크가 다른 데이터 요구사항(위치 파악은 타겟 포함, 분류는 균형 분포)을 가지기 때문입니다.
*   **어텐션 맵 시각화:**
    *   **인코더 어텐션:** 추적 대상에 집중하고 배경과 잘 분리되며, 대상과 방해물 간의 강력한 판별력을 보입니다.
    *   **디코더 어텐션:** 템플릿에서는 대상의 좌상단에, 검색 영역에서는 대상의 경계에 집중하는 경향을 보이며, 방해물에 강건합니다.

## 📌 TL;DR
기존 CNN 기반 추적기가 장거리 공간-시간 의존성 모델링에 취약하고 복잡한 후처리 과정으로 비효율적이라는 문제에 대응하여, 본 논문은 **STARK**라는 새로운 엔드-투-엔드 트랜스포머 기반 추적 프레임워크를 제안합니다. STARK는 인코더-디코더 트랜스포머를 핵심으로 사용하여 초기 및 동적 템플릿, 검색 영역 간의 전역 공간-시간 관계를 효과적으로 학습하고, 제안(proposal)이나 앵커(anchor) 없이 새로운 코너 기반 헤드를 통해 바운딩 박스를 직접 예측합니다. 또한, 스코어 헤드를 도입하여 동적 템플릿 업데이트의 신뢰성을 제어합니다. 그 결과, STARK는 주요 단기 및 장기 벤치마크에서 기존 최고 성능을 뛰어넘는 동시에, 후처리 단계를 완전히 제거하여 추적 파이프라인을 크게 간소화하고 실시간 속도로 작동함을 입증했습니다. 특히 인코더의 역할과 코너 기반 예측 헤드의 정확성이 중요한 기여 요인으로 분석됩니다.