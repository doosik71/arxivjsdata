{
  "title": "SiamVGG: Visual Tracking using Deeper Siamese Networks",
  "authors": "Yuhong Li, Xiaofan Zhang, Deming Chen",
  "year": 2019,
  "url": "http://arxiv.org/abs/1902.02804v4",
  "abstract": "Recently, we have seen a rapid development of Deep Neural Network (DNN) based\nvisual tracking solutions. Some trackers combine the DNN-based solutions with\nDiscriminative Correlation Filters (DCF) to extract semantic features and\nsuccessfully deliver the state-of-the-art tracking accuracy. However, these\nsolutions are highly compute-intensive, which require long processing time,\nresulting unsecured real-time performance. To deliver both high accuracy and\nreliable real-time performance, we propose a novel tracker called\nSiamVGG\\footnote{https://github.com/leeyeehoo/SiamVGG}. It combines a\nConvolutional Neural Network (CNN) backbone and a cross-correlation operator,\nand takes advantage of the features from exemplary images for more accurate\nobject tracking. The architecture of SiamVGG is customized from VGG-16 with the\nparameters shared by both exemplary images and desired input video frames. We\ndemonstrate the proposed SiamVGG on OTB-2013/50/100 and VOT 2015/2016/2017\ndatasets with the state-of-the-art accuracy while maintaining a decent\nreal-time performance of 50 FPS running on a GTX 1080Ti. Our design can achieve\n2% higher Expected Average Overlap (EAO) compared to the ECO and C-COT in\nVOT2017 Challenge."
}