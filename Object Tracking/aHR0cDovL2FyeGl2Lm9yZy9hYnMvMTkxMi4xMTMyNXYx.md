# Adaptive Distraction Context Aware Tracking Based on Correlation Filter
Fei Feng, Xiao-Jun Wu, Tianyang Xu, Josef Kittler, Xue-Feng Zhu

---

## 🧩 Problem to Solve
기존의 판별 상관 필터(CF) 기반 시각 객체 추적 알고리즘은 다음과 같은 문제점을 가지고 있습니다:
*   추적 과정에서 목표물과 유사한 객체(방해물)가 필터 설계에 간섭하여 추적 실패를 유발할 수 있습니다 (예: Figure 1(a)처럼 유사한 이미지 블록을 목표물로 오인).
*   분류기 훈련에 단일 모델을 사용하며, 순환 행렬(circulant matrix)로 인해 생성된 훈련 샘플(특히 탐색 영역 가장자리에 있는 목표물)이 음성 샘플로 오인될 수 있습니다.
*   목표물이 가려지거나(occlusion) 회전(rotation)할 때 분류기가 실패할 수 있습니다 (예: Figure 1(b)).

## ✨ Key Contributions
*   **적응형 방해 컨텍스트 인식 추적(Adaptive Distraction Context Aware Tracking, ADCACF)** 알고리즘을 제안합니다.
*   이전 프레임의 응답 맵(response map)에서 목표물과 유사한 이미지 블록(주요 피크 외의 2차 피크)을 **적응적으로 찾아 강력한 음성 샘플**로 활용합니다.
*   이러한 음성 샘플을 분류기 훈련에 포함하여, 유사한 이미지 블록이 분류기에 미치는 영향을 줄이고 추적 정확도를 향상시킵니다.
*   목표물의 외관과 혼란스러운 배경 간의 **구분 능력(discriminative power)을 강화**하고 오탐지(false detections)를 억제합니다.
*   가려짐(occlusion) 및 회전(rotation)과 같은 **급격한 변화에도 강건하게 대처**하며, 목표물 주변의 방해물을 적응적으로 음성 샘플로 사용하여 추적 정확도를 높입니다.

## 📎 Related Works
*   **상관 필터(CF) 기반 추적 알고리즘**:
    *   **MOSSE [6]**: 상관 필터 개념을 추적에 처음 적용했습니다.
    *   **KCF [7]**: 순환 행렬을 도입하고 HOG 특징을 사용하여 계산 효율성을 높였습니다.
    *   **SRDCF [8]**: 목표물의 스케일 변화 및 순환 행렬로 인한 비자연적인 경계 샘플 문제를 해결했습니다.
    *   **CSRDCF [9]**: 채널 및 공간 신뢰도를 고려한 판별 상관 필터입니다.
    *   **CN [10] / Staple [11]**: 색상 특징(color names, 컬러 히스토그램)을 CF 프레임워크에 도입했습니다.
    *   **DCFCA [12]**: 더 많은 배경 정보를 훈련에 포함하여 필터 판별력을 높였으나, 고정된 샘플링 방식을 사용합니다.
*   **CF 프레임워크를 사용하지 않는 추적 알고리즘**:
    *   **ASLA [13]**: 희소 표현(sparse representation)과 적응형 구조화된 지역 희소 외관 모델(adaptive structured local sparse appearance model)을 결합했습니다.
    *   **IVT [14]**: 증분 학습(incremental learning) 기반의 시각 추적 알고리즘입니다.
    *   **CT [15]**: 압축 추적(Compressive Tracking) 알고리즘입니다.

## 🛠️ Methodology
1.  **상관 필터 재구성**:
    *   기존 CF 알고리즘의 최적화 목적 함수는 다음과 같습니다:
        $$ \min_{w} \frac{1}{2n} \sum_{i=0}^{n-1} \|y_i - w^T x_i\|^2 + \frac{\lambda}{2} \|w\|^2 $$
        여기서 $w$는 필터, $x_i$는 훈련 샘플, $y_i$는 목표 응답, $\lambda$는 정규화 파라미터입니다.
    *   주파수 도메인에서 필터 $w$는 다음과 같이 빠르게 학습됩니다:
        $$ \hat{w} = \frac{\hat{x}^* \hat{y}}{\hat{x}^* \hat{x} + \lambda} $$
        여기서 $\hat{x}$와 $\hat{y}$는 $x$와 $y$의 푸리에 변환이며, $*$는 복소 공액(complex conjugate)입니다.
    *   새 프레임에서 목표물 위치를 찾기 위해, 훈련된 필터 $w$와 후보 이미지 $z$를 합성곱하여 응답 맵 $R$을 얻습니다:
        $$ R = w \star z \quad \iff \quad \hat{R} = \hat{w} \odot \hat{z}^* $$
2.  **방해 컨텍스트 인식 훈련**:
    *   프레임 $t$에서, 이전 프레임의 모델 $w_{t-1}$과 후보 이미지 $z$를 사용하여 응답 맵 $R$을 계산합니다.
    *   $R$에서 최대 피크는 목표물의 위치이며, 2차 피크들은 잠재적인 방해물(distractor) 또는 가려진(occlusion) 객체로 간주됩니다.
    *   이러한 2차 피크에 해당하는 이미지 블록($d_i$)을 **강력한 음성 샘플**로 정의하고, 이들이 필터에 낮은 응답을 생성하도록 새로운 최적화 목적 함수에 추가합니다:
        $$ \min_{w} \frac{1}{2n} \sum_{i=0}^{n-1} \|y_i - w^T x_i\|^2 + \frac{1}{2k} \sum_{i=1}^{k} \|0 - w^T d_i\|^2 + \frac{\lambda_1}{2} \|w\|^2 + \frac{\lambda_2}{2} \|w\|^2 $$
        여기서 $k$는 추가된 음성 샘플의 수이며, 음성 샘플에 대한 목표 응답은 0입니다. $\lambda_1, \lambda_2$는 정규화 파라미터입니다.
    *   이 목적 함수의 주파수 도메인 해는 다음과 같습니다:
        $$ \hat{w} = \frac{\hat{x}^* \hat{y}}{\hat{x}^* \hat{x} + \sum_{i=1}^{k} \hat{d}_i^* \hat{d}_i + \lambda_1 + \lambda_2} $$
3.  **관심 지점(Interest Point) 선택 전략**:
    *   응답 맵 $R$에서 얻은 관심 지점 중, 목표물과 **가까운 지점**만 음성 샘플로 포함합니다. 너무 먼 지점은 제외합니다.
    *   관심 지점의 응답 값이 실제 목표물 응답 값의 **20% 이상인 경우**에만 방해 블록으로 고려합니다.
    *   응답 맵에서 가장 높은 3개의 피크($F_1, F_2, F_3$)를 내림차순으로 정렬합니다. $F_1$은 목표물 위치로 간주하고, $F_2$와 $F_3$는 음성 샘플 후보로 사용됩니다.
4.  **특징 추출 및 차원 축소**:
    *   색상 이미지의 경우 HOG (31차원) 및 CN (10차원) 특징을 사용합니다.
    *   회색 이미지의 경우 Intensity Channel (IC) 및 HOG 특징을 사용합니다.
    *   훈련 과정의 계산 복잡성을 줄이기 위해 PCA를 사용하여 특징 차원을 축소합니다 (HOG: 10차원, CN: 3차원).
5.  **모델 업데이트**: 표준 CF 알고리즘과 유사하게 온라인 적응형 업데이트 규칙을 사용하여 모델을 갱신합니다: $w_t = (1-\theta)w_{t-1} + \theta w_{new}$.

## 📊 Results
*   **평가 벤치마크**: OTB100 [2] 및 Tcolor-128 [3] 데이터셋에서 다른 9개 알고리즘(KCF, CSRDCF, SRDCF, DCFCA, Staple, CSK, ASLA, IVT, CT)과 비교 평가되었습니다.
*   **성능 지표**: 성공률(Success Rate, SR), SR의 AUC(Area Under Curve), 초당 프레임 수(FPS)를 사용했습니다.
*   **종합 성능 (AUC)**:
    *   **OTB100**: ADCACF는 0.605의 AUC로 1위를 차지했으며, SRDCF(0.597)보다 약간 높았습니다.
    *   **Tcolor-128**: ADCACF는 0.497의 AUC로 Staple(0.496)보다 약간 높은 1위를 차지했습니다.
*   **속도 (FPS)**: ADCACF는 46.75 FPS를 기록하여 비교된 10개 알고리즘 중 6위에 해당하며, KCF(366.95 FPS)보다는 느리지만 실시간 추적에 충분한 속도를 보였습니다.
*   **속성별 평가**:
    *   **강점**: 배경 혼란(Background Clutter, BC), 모션 블러(Motion Blur, MB), 회전(In-plane Rotation/Out-of-plane rotation, IPR/OPR), 가려짐(Occlusion, OCC), 시야 이탈(Out of View, OV) 속성에서 뛰어난 성능을 보였습니다. 이는 목표물과 유사한 이미지 콘텐츠를 적응적으로 음성 샘플로 사용하여 필터의 판별력을 효과적으로 향상시킨 결과입니다.
    *   **약점**: 조명 변화(Illumination Variations, IV), 빠른 움직임(Fast Motion, FM), 변형(Deformation, DEF) 속성에서는 다른 알고리즘에 비해 성능이 낮았습니다. 이는 색상 히스토그램과 같은 통계적 특징을 사용하지 않고, 순환 행렬로 인한 훈련 샘플 왜곡에 대한 억제 항이 없기 때문으로 분석됩니다.
*   **파라미터 민감도 분석**: HOG 셀 크기, CN 셀 크기, $\lambda_2$ 정규화 파라미터 변화에 대해 알고리즘이 상대적으로 둔감하며, 이는 알고리즘의 **강건성(robustness)**을 시사합니다.

## 🧠 Insights & Discussion
*   **핵심 기여 및 강점**: ADCACF는 이전 프레임의 응답 맵에서 목표물과 유사하거나 방해가 되는 이미지 블록을 적응적으로 찾아 음성 샘플로 사용함으로써, 다음 프레임의 탐지 과정에서 이러한 방해 블록이나 가려짐의 영향을 효과적으로 억제합니다. 이 혁신적인 메커니즘은 추적 과정의 강건성을 높이고 방해 영역 및 가려짐으로 인한 추적 드리프트(drift)를 줄입니다.
*   **한계점**: 알고리즘은 목표물 변형, 빠른 움직임, 조명 변화가 있는 시퀀스에서는 아직 충분히 강건하지 못합니다. 특히, 색상 히스토그램과 같은 통계적 특징을 사용하지 않기 때문에 조명 변화에 민감합니다. 또한 순환 행렬로 인한 훈련 샘플의 왜곡을 해결하기 위한 억제 항이 없어 일부 왜곡된 훈련 샘플이 분류기 훈련에 간섭할 수 있습니다.
*   **향후 연구**: 목표물 변형, 빠른 움직임, 조명 변화에 대한 강건성을 개선하고, 순환 행렬로 인한 훈련 샘플 왜곡 문제를 해결하는 데 초점을 맞출 것입니다.

## 📌 TL;DR
*   **문제**: 기존 상관 필터 기반 추적기는 목표물과 유사한 방해물, 가려짐, 회전에 취약하며, 이는 음성 샘플 처리의 한계에서 기인합니다.
*   **제안 방법**: ADCACF는 응답 맵에서 2차 피크들을 적응적으로 강력한 음성 샘플로 식별하여, 이를 상관 필터 훈련 목적 함수에 통합함으로써 판별력을 강화합니다.
*   **핵심 결과**: ADCACF는 OTB100 및 Tcolor-128 벤치마크에서 SOTA 성능을 달성했으며, 특히 배경 혼란, 가려짐, 모션 블러, 회전에 매우 강건하여 방해 객체 억제에 효과적임을 입증했습니다.