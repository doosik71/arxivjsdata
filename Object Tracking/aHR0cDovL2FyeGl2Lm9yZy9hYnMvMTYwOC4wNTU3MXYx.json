{
  "url": "http://arxiv.org/abs/1608.05571v1",
  "title": "Learning Spatially Regularized Correlation Filters for Visual Tracking",
  "authors": "Martin Danelljan, Gustav HÃ¤ger, Fahad Shahbaz Khan, Michael Felsberg",
  "year": 2016,
  "abstract": "Robust and accurate visual tracking is one of the most challenging computer\nvision problems. Due to the inherent lack of training data, a robust approach\nfor constructing a target appearance model is crucial. Recently,\ndiscriminatively learned correlation filters (DCF) have been successfully\napplied to address this problem for tracking. These methods utilize a periodic\nassumption of the training samples to efficiently learn a classifier on all\npatches in the target neighborhood. However, the periodic assumption also\nintroduces unwanted boundary effects, which severely degrade the quality of the\ntracking model.\n  We propose Spatially Regularized Discriminative Correlation Filters (SRDCF)\nfor tracking. A spatial regularization component is introduced in the learning\nto penalize correlation filter coefficients depending on their spatial\nlocation. Our SRDCF formulation allows the correlation filters to be learned on\na significantly larger set of negative training samples, without corrupting the\npositive samples. We further propose an optimization strategy, based on the\niterative Gauss-Seidel method, for efficient online learning of our SRDCF.\nExperiments are performed on four benchmark datasets: OTB-2013, ALOV++,\nOTB-2015, and VOT2014. Our approach achieves state-of-the-art results on all\nfour datasets. On OTB-2013 and OTB-2015, we obtain an absolute gain of 8.0% and\n8.2% respectively, in mean overlap precision, compared to the best existing\ntrackers."
}