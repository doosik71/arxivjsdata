{
  "url": "http://arxiv.org/abs/2003.06761v2",
  "title": "Siamese Box Adaptive Network for Visual Tracking",
  "authors": "Zedu Chen, Bineng Zhong, Guorong Li, Shengping Zhang, Rongrong Ji",
  "year": 2020,
  "abstract": "Most of the existing trackers usually rely on either a multi-scale searching\nscheme or pre-defined anchor boxes to accurately estimate the scale and aspect\nratio of a target. Unfortunately, they typically call for tedious and heuristic\nconfigurations. To address this issue, we propose a simple yet effective visual\ntracking framework (named Siamese Box Adaptive Network, SiamBAN) by exploiting\nthe expressive power of the fully convolutional network (FCN). SiamBAN views\nthe visual tracking problem as a parallel classification and regression\nproblem, and thus directly classifies objects and regresses their bounding\nboxes in a unified FCN. The no-prior box design avoids hyper-parameters\nassociated with the candidate boxes, making SiamBAN more flexible and general.\nExtensive experiments on visual tracking benchmarks including VOT2018, VOT2019,\nOTB100, NFS, UAV123, and LaSOT demonstrate that SiamBAN achieves\nstate-of-the-art performance and runs at 40 FPS, confirming its effectiveness\nand efficiency. The code will be available at https://github.com/hqucv/siamban."
}