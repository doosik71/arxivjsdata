{
  "title": "Spatio-Temporal Matching for Siamese Visual Tracking",
  "authors": "Jinpu Zhang, Yuehuan Wang",
  "year": 2021,
  "url": "http://arxiv.org/abs/2105.02408v1",
  "abstract": "Similarity matching is a core operation in Siamese trackers. Most Siamese\ntrackers carry out similarity learning via cross correlation that originates\nfrom the image matching field. However, unlike 2-D image matching, the matching\nnetwork in object tracking requires 4-D information (height, width, channel and\ntime). Cross correlation neglects the information from channel and time\ndimensions, and thus produces ambiguous matching. This paper proposes a\nspatio-temporal matching process to thoroughly explore the capability of 4-D\nmatching in space (height, width and channel) and time. In spatial matching, we\nintroduce a space-variant channel-guided correlation (SVC-Corr) to recalibrate\nchannel-wise feature responses for each spatial location, which can guide the\ngeneration of the target-aware matching features. In temporal matching, we\ninvestigate the time-domain context relations of the target and the background\nand develop an aberrance repressed module (ARM). By restricting the abrupt\nalteration in the interframe response maps, our ARM can clearly suppress\naberrances and thus enables more robust and accurate object tracking.\nFurthermore, a novel anchor-free tracking framework is presented to accommodate\nthese innovations. Experiments on challenging benchmarks including OTB100,\nVOT2018, VOT2020, GOT-10k, and LaSOT demonstrate the state-of-the-art\nperformance of the proposed method."
}