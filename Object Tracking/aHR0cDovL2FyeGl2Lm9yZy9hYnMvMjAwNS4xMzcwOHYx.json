{
  "title": "AFAT: Adaptive Failure-Aware Tracker for Robust Visual Object Tracking",
  "authors": "Tianyang Xu, Zhen-Hua Feng, Xiao-Jun Wu, Josef Kittler",
  "year": 2020,
  "url": "http://arxiv.org/abs/2005.13708v1",
  "abstract": "Siamese approaches have achieved promising performance in visual object\ntracking recently. The key to the success of Siamese trackers is to learn\nappearance-invariant feature embedding functions via pair-wise offline training\non large-scale video datasets. However, the Siamese paradigm uses one-shot\nlearning to model the online tracking task, which impedes online adaptation in\nthe tracking process. Additionally, the uncertainty of an online tracking\nresponse is not measured, leading to the problem of ignoring potential\nfailures. In this paper, we advocate online adaptation in the tracking stage.\nTo this end, we propose a failure-aware system, realised by a Quality\nPrediction Network (QPN), based on convolutional and LSTM modules in the\ndecision stage, enabling online reporting of potential tracking failures.\nSpecifically, sequential response maps from previous successive frames as well\nas current frame are collected to predict the tracking confidence, realising\nspatio-temporal fusion in the decision level. In addition, we further provide\nan Adaptive Failure-Aware Tracker (AFAT) by combing the state-of-the-art\nSiamese trackers with our system. The experimental results obtained on standard\nbenchmarking datasets demonstrate the effectiveness of the proposed\nfailure-aware system and the merits of our AFAT tracker, with outstanding and\nbalanced performance in both accuracy and speed."
}