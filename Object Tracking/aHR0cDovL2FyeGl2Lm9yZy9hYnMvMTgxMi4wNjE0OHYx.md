# Siamese Cascaded Region Proposal Networks for Real-Time Visual Tracking

Heng Fan, Haibin Ling

## 🧩 Problem to Solve

기존의 원-스테이지 샴(Siamese)-RPN 트래커는 유사한 방해물(distractors)이 존재하거나 대상의 스케일 변화가 큰 경우 성능이 저하되는 문제가 있었습니다. 이러한 문제의 주요 원인은 다음과 같습니다:

1. **불균형한 훈련 샘플 분포**: 긍정 샘플이 음성 샘플보다 훨씬 적고, 대부분의 음성 샘플이 쉽게 분류되는 '쉬운 음성'이어서 분류기의 판별력이 저하됩니다. 이로 인해 유사한 배경 방해물과 대상을 구분하기 어렵습니다.
2. **저수준 공간 특징 활용 부족**: 기존 샴 트래커는 주로 고수준의 의미론적 정보를 담고 있는 마지막 레이어의 특징만 사용합니다. 그러나 추적에서는 배경 방해물과 대상이 동일한 범주에 속하거나 유사한 의미 특징을 가질 수 있어, 고수준 특징만으로는 충분히 판별하기 어렵습니다.
3. **정확한 위치 파악의 어려움**: 원-스테이지 샴-RPN은 미리 정의된 앵커 박스를 사용하여 단일 회귀(regression) 단계로 대상을 위치 파악합니다. 모델 프리(model-free) 시각 추적에서는 대상의 사전 정보가 없어 스케일 변화를 정확히 예측하기 어렵기 때문에, 단일 회귀만으로는 정확한 위치 파악이 어렵습니다.

## ✨ Key Contributions

이 논문은 위에서 언급된 문제들을 해결하기 위해 다음과 같은 핵심 기여를 제시합니다:

- **다단계 캐스케이드 RPN (C-RPN) 프레임워크 제안**: 어려운 음성 샘플링(hard negative sampling)을 수행하여 클래스 불균형 문제를 해결하고, 단계별로 RPN의 판별력을 높입니다. 각 RPN은 이전 단계 RPN의 출력을 훈련 샘플로 활용하여 순차적으로 더욱 판별적인 분류기를 학습합니다.
- **다단계 회귀를 통한 정확한 위치 파악**: 여러 RPN을 통해 다단계 회귀를 수행하여 대상의 바운딩 박스 위치와 형태를 점진적으로 정제합니다. 이전 단계의 앵커 박스 조정 결과를 다음 단계의 초기화로 사용하여 보다 정확한 위치 파악을 가능하게 합니다.
- **새로운 특징 전이 블록 (FTB) 설계**: 다단계 특징을 효과적으로 활용하기 위해 고수준의 의미론적 특징과 저수준의 공간적 특징을 융합하는 FTB를 제안합니다. 이는 복잡한 배경 속에서 대상의 판별력을 더욱 향상시킵니다.
- **실시간 성능을 갖춘 최신 기술 달성**: OTB-2013, OTB-2015, VOT-2016, VOT-2017, LaSOT, TrackingNet 등 광범위한 6개 벤치마크에서 기존 최신 기술보다 우수한 성능을 일관되게 달성하며 실시간 추적을 가능하게 합니다.

## 📎 Related Works

이 논문은 다음과 같은 이전 연구들과 관련이 있습니다:

- **딥 트래킹 (Deep Tracking)**: CNN(Convolutional Neural Network)을 시각 추적에 적용하여 객체 외형 모델링 및 특징 표현을 학습합니다. (예: FCNT [48], MDNet [34], VITAL [42] 등)
- **샴 네트워크 기반 트래킹 (Siamese Tracking)**: 대규모 비디오 데이터셋에서 오프라인으로 유사성 함수를 학습하여 추적을 매칭 문제로 공식화합니다. (예: SiamFC [2], GOTURN [18], CFNet [45]) 특히, RPN을 샴 네트워크에 도입한 SiamRPN [22]은 높은 성능과 효율성을 달성하여 이 논문의 기본 모델이 됩니다.
- **다단계 특징 (Multi-level Features)**: 신경망의 다른 레이어에서 추출된 특징들이 추적 성능 향상에 유용하다는 것이 입증되었습니다. (예: Ma et al. [31], Wang et al. [48]) 본 연구는 이러한 다단계 특징 활용과 관련되지만, 독립적인 모델에 별도로 특징을 사용하는 대신 FTB를 통해 계층 간 특징 융합을 제안한다는 점에서 차별화됩니다.
- **객체 탐지 (Object Detection)**: Faster R-CNN [37]과 같은 2단계 객체 탐지기는 클래스 불균형 문제 해결과 정확한 위치 파악을 위해 2단계 회귀를 사용하며, C-RPN의 다단계 접근 방식에 영감을 주었습니다.

## 🛠️ Methodology

제안된 샴 캐스케이드 RPN (C-RPN)은 샴 네트워크와 캐스케이드 RPN의 두 가지 주요 서브 네트워크로 구성됩니다.

1. **샴 네트워크 (Siamese Network)**

   - 수정된 AlexNet [21]을 백본으로 사용합니다.
   - 대상 템플릿 $z$와 검색 영역 $x$에서 특징을 추출하는 두 개의 동일한 브랜치로 구성되며, 파라미터를 공유합니다.
   - 기존 SiamRPN이 마지막 레이어 특징만 사용하는 것과 달리, C-RPN은 여러 레이어의 특징($\phi_i(z)$ 및 $\phi_i(x)$)을 활용하여 모델 견고성을 향상시킵니다.

2. **캐스케이드 RPN (Cascaded RPN)**

   - $L$개의 RPN이 순차적으로 연결된 형태입니다 (논문에서는 $L=3$).
   - 각 $l$-번째 RPN ($RPN_l$)은 현재 레이어의 특징과 이전 고수준 레이어로부터 FTB를 통해 융합된 특징 $\Phi_l(z)$ 및 $\Phi_l(x)$를 입력으로 받습니다.
   - **분류 및 회귀**: 각 RPN은 앵커에 대한 분류 점수($\{c^l_i\}$)와 회귀 오프셋($\{r^l_i\}$)을 동시에 출력합니다. 이는 상관 필터(correlation) 연산을 통해 계산됩니다:
     $$
     \{c^l_i\} = \text{corr}([\Phi_l(z)]_{cls}, [\Phi_l(x)]_{cls}) \\
     \{r^l_i\} = \text{corr}([\Phi_l(z)]_{reg}, [\Phi_l(x)]_{reg})
     $$
   - **어려운 음성 샘플링 (Hard Negative Sampling)**: $RPN_l$에서 계산된 분류 점수를 바탕으로 음성 신뢰도($c^l_{i(neg)}$)가 미리 설정된 임계값 $\theta$보다 큰 '쉬운 음성' 앵커들을 걸러냅니다. 나머지 앵커들은 '어려운 예시'로 간주되어 다음 단계 $RPN_{l+1}$의 훈련 샘플로 사용됩니다. 이 과정을 통해 훈련 샘플 분포가 점진적으로 균형을 이루고, 각 RPN은 어려운 방해물을 구별하는 데 더 판별적이 됩니다.
   - **앵커 박스 정제 (Anchor Box Refinement)**: $RPN_l$의 회귀 결과($\{r^l_i\}$)를 사용하여 다음 단계 $RPN_{l+1}$의 앵커 박스($A_{l+1}$)의 중심 위치와 크기를 정제합니다. 이는 단일 단계 회귀보다 더 정확한 위치 파악을 가능하게 합니다. 앵커 박스 조정은 다음과 같이 이루어집니다:
     $$
     x^l_a = x^l_a + w^{l-1}_a r^{l-1}_{i(x)} \\
     y^l_a = y^l_a + h^{l-1}_a r^{l-1}_{i(y)} \\
     w^l_a = w^{l-1}_a \exp(r^{l-1}_{i(w)}) \\
     h^l_a = h^{l-1}_a \exp(r^{l-1}_{i(h)})
     $$
     ($l=1$일 때는 미리 정의된 앵커 박스를 사용합니다.)

3. **특징 전이 블록 (Feature Transfer Block, FTB)**

   - 저수준 레이어 특징($\phi_l(\cdot)$)과 이전 단계에서 융합된 고수준 특징($\Phi_{l-1}(\cdot)$)을 융합하여 $RPN_l$에 사용될 융합 특징($\Phi_l(\cdot)$)을 생성합니다:
     $$
     \Phi_l(z) = \text{FTB}(\Phi_{l-1}(z), \phi_l(z)) \\
     \Phi_l(x) = \text{FTB}(\Phi_{l-1}(x), \phi_l(x))
     $$
   - 디컨볼루션 레이어를 사용하여 다른 소스의 특징 차원을 일치시키고, 원소별 합(element-wise summation)으로 특징을 융합한 후 ReLU를 적용합니다.
   - 모든 RPN에 대해 동일한 앵커의 그라운드 트루스(ground truth)를 보장하기 위해, 융합된 특징을 보간(interpolation)하여 출력 분류 맵과 회귀 맵이 동일한 해상도를 갖도록 합니다.

4. **훈련 (Training)**

   - C-RPN은 엔드-투-엔드(end-to-end) 방식으로 훈련됩니다.
   - 각 RPN의 손실 함수 $\mathcal{L}_{RPN_l}$은 분류 손실($L_{cls}$, 소프트맥스 손실)과 회귀 손실($L_{loc}$, smooth $L_1$ 손실)의 합으로 구성됩니다.
   - 총 손실 함수 $\mathcal{L}_{CRPN}$은 모든 RPN의 손실 함수를 합한 것입니다: $\mathcal{L}_{CRPN} = \sum_{l=1}^L \mathcal{L}_{RPN_l}$.
   - 훈련 샘플은 객체 탐지 전략에 따라 IoU(Intersection over Union) 임계값($\tau_{pos}=0.6$, $\tau_{neg}=0.3$)으로 긍정/음성 샘플을 정의합니다.

5. **추적 (Tracking)**
   - 추적은 다단계 탐지(multi-stage detection)로 공식화됩니다.
   - 첫 프레임에서 대상 템플릿의 특징 임베딩을 사전 계산합니다.
   - 새로운 프레임에서는 이전 프레임 결과를 기반으로 관심 영역(ROI)을 추출하고 C-RPN을 사용하여 탐지를 수행합니다.
   - 각 단계에서 RPN은 분류 점수와 회귀 오프셋을 출력하며, 음성 점수가 높은 앵커는 버려지고 나머지는 다음 단계로 넘어가 정제됩니다.
   - 마지막 단계 $L$ 후, 남아있는 앵커들은 대상 제안으로 간주되며, 이 중에서 최적의 하나가 최종 추적 결과로 선택됩니다.

## 📊 Results

C-RPN은 다양한 벤치마크에서 최첨단 성능과 실시간 속도를 달성했습니다.

- **OTB-2013 및 OTB-2015**:

  - 두 벤치마크 모두에서 가장 우수한 성능을 달성했습니다.
  - OTB-2013에서 0.675, OTB-2015에서 0.663의 정밀도(precision) 점수를 기록했습니다.
  - 원-스테이지 SiamRPN 대비 OTB-2013에서 1.9%, OTB-2015에서 2.6%의 성능 향상을 보였습니다.
  - 추가 훈련 데이터 없이 DaSiamRPN보다 우수한 성능을 달성했습니다. C-RPN은 약 36 fps로 실행됩니다.

- **VOT-2016 및 VOT-2017**:

  - VOT-2016에서 EAO(Expected Average Overlap) 0.363으로 최고 성능을 기록하며, 기준 SiamRPN보다 크게 앞섰습니다. 정확도와 견고성 모두에서 우수했습니다.
  - VOT-2017에서도 기준 EAO 0.289, 실시간 EAO 0.273으로 모든 다른 트래커를 능가하며 최고 성능을 달성했습니다.

- **LaSOT**:

  - 두 가지 프로토콜 모두에서 다른 모든 최신 트래커를 크게 능가했습니다.
  - 프로토콜 I에서 0.459, 프로토콜 II에서 0.455의 SUC(Success) 점수를 기록했습니다.
  - 두 번째로 좋은 트래커인 MDNet보다 각각 4.6%, 5.8% 더 높은 성능을 보였습니다. C-RPN은 LaSOT에서 약 23 fps로 실행되어 MDNet (약 1 fps)보다 훨씬 효율적입니다.

- **TrackingNet**:

  - 모든 세 가지 지표(PRE, NPRE, SUC)에서 최고의 결과를 달성했습니다.
  - PRE 0.619, NPRE 0.746, SUC 0.669를 기록하며 MDNet보다 각각 5.4%, 4.1%, 6.3% 더 높은 성능을 보였습니다. C-RPN은 약 32 fps로 효율적으로 실행됩니다.

- **요소 연구 (Ablation Experiment)**:
  - **단계 수**: 1단계에서 2단계로 늘리면 성능이 크게 향상되었고(LaSOT SUC 2.9%p, VOT-2017 EAO 3.5%p), 3단계로 늘리면 추가적인 개선이 있었습니다(각각 0.9%p, 0.6%p). 이는 대부분의 어려운 배경 문제가 2단계에서 처리됨을 시사합니다.
  - **음성 앵커 필터링 (Negative Anchor Filtering, NAF)**: NAF를 제거하면 성능이 저하되어(LaSOT SUC 1.6%p, VOT-2017 EAO 0.7%p), 균형 잡힌 훈련 샘플이 판별적인 RPN 훈련에 중요함을 입증했습니다.
  - **특징 전이 블록 (FTB)**: FTB를 사용하지 않으면 성능이 저하되어(LaSOT SUC 1.3%p, VOT-2017 EAO 1.1%p), 다단계 특징 융합이 성능 향상에 효과적임을 확인했습니다.

## 🧠 Insights & Discussion

C-RPN의 결과는 복잡한 시각 추적 문제에 대한 효과적인 해결책을 제시합니다.

- **어려운 음성 샘플링의 중요성**: 캐스케이드 구조를 통해 단계적으로 '쉬운 음성' 앵커를 제거하고 '어려운 음성' 앵커에 집중하여 훈련 샘플의 불균형을 해소한 것이 핵심입니다. 이는 분류기의 판별력을 크게 향상시켜 유사한 방해물에 대한 강건성을 높였습니다.
- **다단계 회귀의 효과**: 여러 RPN이 순차적으로 앵커 박스를 정제함으로써, 단일 회귀로는 어려웠던 큰 스케일 변화에 대한 정확한 위치 파악이 가능해졌습니다. 이는 예측의 정확도를 점진적으로 높이는 효과를 가져옵니다.
- **다단계 특징 활용의 이점**: 특징 전이 블록(FTB)을 통해 고수준의 의미론적 특징과 저수준의 공간적 특징을 융합함으로써 RPN의 판별력이 더욱 강화되었습니다. 이는 복잡한 배경에서도 대상을 더 잘 구분할 수 있게 합니다.
- **효율성과 성능의 균형**: C-RPN은 높은 정확도와 함께 실시간 추적 속도를 유지합니다. 이는 오프라인 학습된 강력한 샴 네트워크와 효율적인 RPN 구조의 장점을 결합한 결과입니다.
- **향후 연구 방향**: 더 많은 단계를 추가하면 추가적인 성능 향상이 있을 수 있지만, 계산 비용 증가를 고려해야 합니다. 미래에는 성능 손실 없이 단계 수를 늘리거나, 더욱 효율적인 다단계 아키텍처를 탐색할 수 있을 것입니다.

## 📌 TL;DR

이 논문은 유사한 방해물과 큰 스케일 변화에 취약했던 기존 샴-RPN 트래커의 한계를 극복하기 위해 **샴 캐스케이드 영역 제안 네트워크 (C-RPN)**를 제안합니다. C-RPN은 여러 개의 RPN을 순차적으로 연결하여 **어려운 음성 샘플링**을 통해 분류기 판별력을 높이고, **다단계 회귀**를 통해 대상 바운딩 박스를 정밀하게 정제합니다. 또한, **특징 전이 블록 (FTB)**을 도입하여 고수준 및 저수준 특징을 효과적으로 융합합니다. 결과적으로 C-RPN은 다양한 벤치마크에서 **최신 기술 성능을 달성하면서 실시간 추적**이 가능함을 입증했습니다.
