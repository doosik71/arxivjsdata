{
  "url": "http://arxiv.org/abs/1912.08531v1",
  "title": "GlobalTrack: A Simple and Strong Baseline for Long-term Tracking",
  "authors": "Lianghua Huang, Xin Zhao, Kaiqi Huang",
  "year": 2019,
  "abstract": "A key capability of a long-term tracker is to search for targets in very\nlarge areas (typically the entire image) to handle possible target absences or\ntracking failures. However, currently there is a lack of such a strong baseline\nfor global instance search. In this work, we aim to bridge this gap.\nSpecifically, we propose GlobalTrack, a pure global instance search based\ntracker that makes no assumption on the temporal consistency of the target's\npositions and scales. GlobalTrack is developed based on two-stage object\ndetectors, and it is able to perform full-image and multi-scale search of\narbitrary instances with only a single query as the guide. We further propose a\ncross-query loss to improve the robustness of our approach against distractors.\nWith no online learning, no punishment on position or scale changes, no scale\nsmoothing and no trajectory refinement, our pure global instance search based\ntracker achieves comparable, sometimes much better performance on four\nlarge-scale tracking benchmarks (i.e., 52.1% AUC on LaSOT, 63.8% success rate\non TLP, 60.3% MaxGM on OxUvA and 75.4% normalized precision on TrackingNet),\ncompared to state-of-the-art approaches that typically require complex\npost-processing. More importantly, our tracker runs without cumulative errors,\ni.e., any type of temporary tracking failures will not affect its performance\non future frames, making it ideal for long-term tracking. We hope this work\nwill be a strong baseline for long-term tracking and will stimulate future\nworks in this area. Code is available at\nhttps://github.com/huanglianghua/GlobalTrack."
}