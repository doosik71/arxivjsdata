{
  "title": "Siamese Cascaded Region Proposal Networks for Real-Time Visual Tracking",
  "authors": "Heng Fan, Haibin Ling",
  "year": 2018,
  "url": "http://arxiv.org/abs/1812.06148v1",
  "abstract": "Region proposal networks (RPN) have been recently combined with the Siamese\nnetwork for tracking, and shown excellent accuracy with high efficiency.\nNevertheless, previously proposed one-stage Siamese-RPN trackers degenerate in\npresence of similar distractors and large scale variation. Addressing these\nissues, we propose a multi-stage tracking framework, Siamese Cascaded RPN\n(C-RPN), which consists of a sequence of RPNs cascaded from deep high-level to\nshallow low-level layers in a Siamese network. Compared to previous solutions,\nC-RPN has several advantages: (1) Each RPN is trained using the outputs of RPN\nin the previous stage. Such process stimulates hard negative sampling,\nresulting in more balanced training samples. Consequently, the RPNs are\nsequentially more discriminative in distinguishing difficult background (i.e.,\nsimilar distractors). (2) Multi-level features are fully leveraged through a\nnovel feature transfer block (FTB) for each RPN, further improving the\ndiscriminability of C-RPN using both high-level semantic and low-level spatial\ninformation. (3) With multiple steps of regressions, C-RPN progressively\nrefines the location and shape of the target in each RPN with adjusted anchor\nboxes in the previous stage, which makes localization more accurate. C-RPN is\ntrained end-to-end with the multi-task loss function. In inference, C-RPN is\ndeployed as it is, without any temporal adaption, for real-time tracking. In\nextensive experiments on OTB-2013, OTB-2015, VOT-2016, VOT-2017, LaSOT and\nTrackingNet, C-RPN consistently achieves state-of-the-art results and runs in\nreal-time."
}