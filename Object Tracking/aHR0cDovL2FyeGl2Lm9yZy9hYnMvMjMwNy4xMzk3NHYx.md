# Tracking Anything in High Quality
Jiawen Zhu, Zhenyu Chen, Zeqi Hao, Shijie Chang, Lu Zhang, Dong Wang, Huchuan Lu, Bin Luo, Jun-Yan He, Jin-Peng Lan, Hanyuan Chen, Chenyang Li

## 🧩 Problem to Solve
시각 객체 추적은 컴퓨터 비전의 핵심 비디오 작업이며, 특히 VOTS2023 챌린지 같은 까다로운 시나리오에서 다음과 같은 난제들을 해결하는 것이 목표입니다.
- **장기 시퀀스:** 10,000 프레임 이상에 달하는 긴 비디오에서 객체의 외형 변화에 적응하고 환경 변화를 식별해야 합니다.
- **객체 출현/소멸:** 추적 대상이 시야에서 벗어났다가 다시 나타나는 경우를 처리해야 합니다.
- **복합적인 도전:** 빠른 움직임, 빈번한 가려짐, 방해물, 작은 객체 등 다양한 난제 속에서도 정확한 객체 마스크를 추정해야 합니다.
기존의 비디오 객체 분할(VOS) 방법들은 이러한 복잡하고 예외적인 상황에 대한 일반화 능력이 제한적이었습니다.

## ✨ Key Contributions
- 비디오에서 객체를 고품질로 추적하기 위한 프레임워크인 **HQTrack**을 제안했습니다.
- VMOS(Video Multi-Object Segmenter)와 MR(Mask Refiner)의 두 가지 주요 구성 요소로 HQTrack을 구축했습니다.
- VMOS는 기존 DeAOT를 개선하여 1/8 스케일의 GPM(Gated Propagation Module)을 계단식으로 연결하여 작은 객체 인지 능력을 향상하고, InternImage-T를 특징 추출기(인코더)로 사용하여 객체 식별 능력을 강화했습니다.
- 사전 학습된 HQ-SAM 모델을 MR로 활용하여 VMOS에서 생성된 추적 마스크의 품질을 추가로 개선했습니다.
- VMOS와 MR의 결과 마스크 간의 IoU(Intersection over Union) 점수를 기반으로 최종 마스크를 선택하는 메커니즘을 설계하여, MR이 잘못된 객체를 예측하는 경우를 방지했습니다.
- VOTS2023 챌린지에서 테스트 시간 데이터 증강(TTA)이나 모델 앙상블과 같은 기법 없이도 2위를 달성하며, 제안된 패러다임의 효과를 입증했습니다.

## 📎 Related Works
- **객체 추적:** 온라인 업데이트 트래커, Siamese 트래커(TransT, Mixformer 등).
- **비디오 객체 분할(VOS):** 공간-시간 메모리(STM) 네트워크, AOT, DeAOT(VMOS의 기반).
- **이미지 분할:** SAM(Segment Anything Model), HQ-SAM(HQTrack의 MR로 사용).
- **백본 네트워크:** ResNet, InternImage(HQTrack의 VMOS 인코더).

## 🛠️ Methodology
HQTrack은 비디오와 첫 프레임 참조(마스크 주석)가 주어지면, VMOS가 각 프레임에 대해 대상 객체를 분할하고, MR이 이 마스크를 정제하는 2단계 파이프라인으로 구성됩니다.

- **VMOS (Video Multi-object Segmenter):**
    - DeAOT [38]의 개선된 변형으로, 단일 전파 프로세스 내에서 다중 객체 모델링을 수행합니다.
    - **다중 스케일 전파:** 1/8 스케일 GPM을 계단식으로 연결하여 4배 스케일까지 전파 과정을 확장, 작은 객체 인지 능력을 향상했습니다.
    - **강화된 특징 추출:** InternImage-T [33]를 인코더로 사용하여 객체 식별 능력을 강화했습니다.
    - **메모리 효율성:** 장기 메모리 사용량을 절약하기 위해 초기 프레임을 제외한 8개의 고정된 길이의 장기 메모리를 사용합니다.

- **MR (Mask Refiner):**
    - 사전 학습된 HQ-SAM [14] 모델(ViT-H 백본 사용)을 활용합니다.
    - VMOS가 예측한 마스크의 외곽 바운딩 박스를 HQ-SAM의 박스 프롬프트로 사용하여 원본 이미지와 함께 입력합니다.
    - **마스크 선택기:** VMOS와 HQ-SAM이 정제한 마스크 간의 IoU 점수를 계산합니다. IoU 점수가 임계값 $\tau$ (실험 결과 $\tau=0.1$이 최적)보다 높으면 정제된 마스크를 최종 출력으로 선택하고, 그렇지 않으면 VMOS 마스크를 유지하여 HQ-SAM이 완전히 다른 객체를 예측하는 것을 방지합니다.

- **훈련 및 추론:**
    - VMOS 훈련은 두 단계로 진행됩니다: 1) 정적 이미지 데이터셋에서 생성된 합성 비디오 시퀀스로 사전 학습. 2) DAVIS, YoutubeVOS, VIPSeg, BURST, MOTS, OVIS와 같은 다중 객체 분할 데이터셋으로 미세 조정.
    - 추론 시에는 테스트 시간 증강(TTA)이나 모델 앙상블을 사용하지 않습니다.

## 📊 Results
- **VOTS2023 검증 세트 (개별 구성 요소 분석):**
    - 개별 추적보다 공동 추적(Joint tracking)이 더 우수한 성능을 보였습니다.
    - VMOS에 InternImage-T 백본을 적용하여 AUC 점수가 0.576에서 0.611로 크게 향상되었습니다.
    - 다중 스케일 전파 메커니즘을 추가하여 AUC 점수가 0.611에서 0.650으로 추가 향상되었습니다.
    - 장기 메모리 간격(G)은 50일 때 최적의 성능을 보였습니다.
    - MR의 임계값 $\tau=0.1$ 설정 시 가장 유망한 결과(AUC 0.708)를 나타내며, 선택적 마스크 정제의 중요성을 확인했습니다.
- **VOTS2023 테스트 세트 (최종 챌린지 결과):**
    - HQTrack은 0.615의 인상적인 품질 점수(AUC)를 달성했습니다.
    - VOTS2023 챌린지에서 2위를 차지했습니다.
    - 질적 결과는 HQTrack이 장기 객체 추적, 다중 객체 처리, 방해물 처리, 외형 변화, 빠른 움직임, 스케일 변화 등 다양한 도전 과제에서 강력한 추적 능력을 보여줍니다.

## 🧠 Insights & Discussion
- HQTrack은 비디오에서 "무엇이든" 고품질로 추적하는 복합적인 문제를 해결하는 데 매우 강력하고 효과적인 솔루션을 제공합니다.
- VMOS의 InternImage-T 백본과 다중 스케일 전파는 작은 객체와 복잡한 시나리오에서 뛰어난 성능을 발휘하며, 이는 기존 VOS 모델의 한계를 극복하는 데 기여합니다.
- HQ-SAM을 마스크 정제기로 사용함으로써 섬세하고 복잡한 구조의 마스크 품질을 크게 향상시킬 수 있음을 입증했습니다.
- IoU 기반의 마스크 선택 메커니즘은 HQ-SAM의 강력한 정제 능력을 활용하면서도, 때때로 발생하는 예측 오류나 객체 정의 불일치로 인한 성능 저하를 방지하는 데 필수적입니다.
- 테스트 시간 증강이나 모델 앙상블 없이 챌린지에서 2위를 달성한 것은 HQTrack 아키텍처 자체의 견고함과 효과성을 강력히 시사합니다. 이는 실제 배포 시 복잡성 감소에도 도움이 될 수 있습니다.
- 이 연구는 최신 대규모 기초 모델(SAM)을 기존 비디오 객체 추적 파이프라인에 효과적으로 통합하는 성공적인 방법을 제시합니다.

## 📌 TL;DR
**문제:** 장기간의 복잡한 비디오 시퀀스에서 다중 객체를 고품질 마스크로 정확하게 추적 및 분할하는 것이 어려웠습니다.
**방법:** HQTrack은 **VMOS** (개선된 DeAOT 기반 비디오 다중 객체 분할기, InternImage-T 백본 및 다중 스케일 전파 적용)와 **MR** (사전 학습된 HQ-SAM 기반 마스크 정제기, IoU 기반 마스크 선택 기능 포함)로 구성됩니다.
**결과:** HQTrack은 VOTS2023 챌린지에서 2위를 차지하며, 강력한 비디오 분할기와 선별적으로 적용되는 마스크 정제기를 결합하여 고품질의 객체 추적 및 분할 성능을 달성했습니다.