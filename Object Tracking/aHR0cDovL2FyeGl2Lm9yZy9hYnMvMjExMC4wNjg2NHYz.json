{
  "url": "http://arxiv.org/abs/2110.06864v3",
  "title": "ByteTrack: Multi-Object Tracking by Associating Every Detection Box",
  "authors": "Yifu Zhang, Peize Sun, Yi Jiang, Dongdong Yu, Fucheng Weng, Zehuan Yuan, Ping Luo, Wenyu Liu, Xinggang Wang",
  "year": 2021,
  "abstract": "Multi-object tracking (MOT) aims at estimating bounding boxes and identities\nof objects in videos. Most methods obtain identities by associating detection\nboxes whose scores are higher than a threshold. The objects with low detection\nscores, e.g. occluded objects, are simply thrown away, which brings\nnon-negligible true object missing and fragmented trajectories. To solve this\nproblem, we present a simple, effective and generic association method,\ntracking by associating almost every detection box instead of only the high\nscore ones. For the low score detection boxes, we utilize their similarities\nwith tracklets to recover true objects and filter out the background\ndetections. When applied to 9 different state-of-the-art trackers, our method\nachieves consistent improvement on IDF1 score ranging from 1 to 10 points. To\nput forwards the state-of-the-art performance of MOT, we design a simple and\nstrong tracker, named ByteTrack. For the first time, we achieve 80.3 MOTA, 77.3\nIDF1 and 63.1 HOTA on the test set of MOT17 with 30 FPS running speed on a\nsingle V100 GPU. ByteTrack also achieves state-of-the-art performance on MOT20,\nHiEve and BDD100K tracking benchmarks. The source code, pre-trained models with\ndeploy versions and tutorials of applying to other trackers are released at\nhttps://github.com/ifzhang/ByteTrack."
}