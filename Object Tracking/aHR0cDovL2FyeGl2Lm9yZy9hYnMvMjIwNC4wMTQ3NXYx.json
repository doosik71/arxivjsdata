{
  "url": "http://arxiv.org/abs/2204.01475v1",
  "title": "Unsupervised Learning of Accurate Siamese Tracking",
  "authors": "Qiuhong Shen, Lei Qiao, Jinyang Guo, Peixia Li, Xin Li, Bo Li, Weitao Feng, Weihao Gan, Wei Wu, Wanli Ouyang",
  "year": 2022,
  "abstract": "Unsupervised learning has been popular in various computer vision tasks,\nincluding visual object tracking. However, prior unsupervised tracking\napproaches rely heavily on spatial supervision from template-search pairs and\nare still unable to track objects with strong variation over a long time span.\nAs unlimited self-supervision signals can be obtained by tracking a video along\na cycle in time, we investigate evolving a Siamese tracker by tracking videos\nforward-backward. We present a novel unsupervised tracking framework, in which\nwe can learn temporal correspondence both on the classification branch and\nregression branch. Specifically, to propagate reliable template feature in the\nforward propagation process so that the tracker can be trained in the cycle, we\nfirst propose a consistency propagation transformation. We then identify an\nill-posed penalty problem in conventional cycle training in backward\npropagation process. Thus, a differentiable region mask is proposed to select\nfeatures as well as to implicitly penalize tracking errors on intermediate\nframes. Moreover, since noisy labels may degrade training, we propose a\nmask-guided loss reweighting strategy to assign dynamic weights based on the\nquality of pseudo labels. In extensive experiments, our tracker outperforms\npreceding unsupervised methods by a substantial margin, performing on par with\nsupervised methods on large-scale datasets such as TrackingNet and LaSOT. Code\nis available at https://github.com/FlorinShum/ULAST."
}