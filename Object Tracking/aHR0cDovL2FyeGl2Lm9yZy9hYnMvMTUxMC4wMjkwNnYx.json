{
  "title": "Temporal Dynamic Appearance Modeling for Online Multi-Person Tracking",
  "authors": "Min Yang, Yunde Jia",
  "year": 2015,
  "url": "http://arxiv.org/abs/1510.02906v1",
  "abstract": "Robust online multi-person tracking requires the correct associations of\nonline detection responses with existing trajectories. We address this problem\nby developing a novel appearance modeling approach to provide accurate\nappearance affinities to guide data association. In contrast to most existing\nalgorithms that only consider the spatial structure of human appearances, we\nexploit the temporal dynamic characteristics within temporal appearance\nsequences to discriminate different persons. The temporal dynamic makes a\nsufficient complement to the spatial structure of varying appearances in the\nfeature space, which significantly improves the affinity measurement between\ntrajectories and detections. We propose a feature selection algorithm to\ndescribe the appearance variations with mid-level semantic features, and\ndemonstrate its usefulness in terms of temporal dynamic appearance modeling.\nMoreover, the appearance model is learned incrementally by alternatively\nevaluating newly-observed appearances and adjusting the model parameters to be\nsuitable for online tracking. Reliable tracking of multiple persons in complex\nscenes is achieved by incorporating the learned model into an online\ntracking-by-detection framework. Our experiments on the challenging benchmark\nMOTChallenge 2015 demonstrate that our method outperforms the state-of-the-art\nmulti-person tracking algorithms."
}