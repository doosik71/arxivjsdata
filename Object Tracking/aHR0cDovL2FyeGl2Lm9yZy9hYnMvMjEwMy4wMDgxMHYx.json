{
  "title": "MFST: Multi-Features Siamese Tracker",
  "authors": "Zhenxi Li, Guillaume-Alexandre Bilodeau, Wassim Bouachir",
  "year": 2021,
  "url": "http://arxiv.org/abs/2103.00810v1",
  "abstract": "Siamese trackers have recently achieved interesting results due to their\nbalance between accuracy and speed. This success is mainly due to the fact that\ndeep similarity networks were specifically designed to address the image\nsimilarity problem. Therefore, they are inherently more appropriate than\nclassical CNNs for the tracking task. However, Siamese trackers rely on the\nlast convolutional layers for similarity analysis and target search, which\nrestricts their performance. In this paper, we argue that using a single\nconvolutional layer as feature representation is not the optimal choice within\nthe deep similarity framework, as multiple convolutional layers provide several\nabstraction levels in characterizing an object. Starting from this motivation,\nwe present the Multi-Features Siamese Tracker (MFST), a novel tracking\nalgorithm exploiting several hierarchical feature maps for robust deep\nsimilarity tracking. MFST proceeds by fusing hierarchical features to ensure a\nricher and more efficient representation. Moreover, we handle appearance\nvariation by calibrating deep features extracted from two different CNN models.\nBased on this advanced feature representation, our algorithm achieves high\ntracking accuracy, while outperforming several state-of-the-art trackers,\nincluding standard Siamese trackers. The code and trained models are available\nat https://github.com/zhenxili96/MFST."
}