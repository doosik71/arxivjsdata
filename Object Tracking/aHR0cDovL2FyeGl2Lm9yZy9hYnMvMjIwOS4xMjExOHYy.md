# BURST: A Benchmark for Unifying Object Recognition, Segmentation and Tracking in Video
Ali Athar, Jonathon Luiten, Paul Voigtlaender, Tarasha Khurana, Achal Dave, Bastian Leibe, Deva Ramanan

## 🧩 Problem to Solve
기존의 비디오 객체 추적 및 분할 벤치마크(예: VOS, MOTS)는 서로 다른 데이터셋과 평가 지표(J&F, mAP, sMOTSA 등)를 사용하기 때문에 각 연구 하위 커뮤니티 간의 상호 작용이 부족합니다. 이로 인해 발표되는 연구들은 특정 벤치마크에만 초점을 맞추어 상호 비교가 어렵고, 여러 태스크를 다룰 수 있는 범용적인 방법론 개발이 저해됩니다. 본 연구는 이러한 문제점을 해결하여 연구 커뮤니티 간의 응집력을 높이고 지식 교환을 촉진하는 것을 목표로 합니다.

## ✨ Key Contributions
*   **BURST 데이터셋 제안**: 수천 개의 다양하고 고품질의 객체 마스크 주석이 포함된 대규모 비디오 데이터셋을 구축했습니다.
*   **통합 벤치마크 제공**: 비디오 내 객체 추적 및 분할과 관련된 6가지 태스크로 구성된 벤치마크를 제시했습니다.
*   **일관된 평가 및 데이터**: 모든 태스크가 동일한 데이터와 HOTA(Higher-Order Tracking Accuracy) 및 OWTA(Open-World Tracking Accuracy)와 같은 비교 가능한 지표로 평가되도록 하여 연구자들이 여러 태스크를 통합적으로 고려할 수 있도록 했습니다.
*   **기준선(Baselines) 제시**: 모든 태스크에 대한 여러 기준선을 시연하고, 한 태스크를 위한 접근 방식이 정량화 가능하고 설명 가능한 성능 차이와 함께 다른 태스크에 적용될 수 있음을 보였습니다.
*   **반자동 주석 파이프라인**: 훈련 세트의 마스크 주석 시간 밀도를 높이기 위한 반자동 파이프라인을 개발하여 인적 주석 노력을 크게 줄였습니다.

## 📎 Related Works
*   **비디오 객체 분할 (VOS)**: DAVIS [24], YouTube-VOS [37], VOT [15]
*   **다중 객체 추적 및 분할 (MOTS)**: BDD [40], KITTI [8], MOTS-Challenge [32], YouTube-VIS [38], OVIS [25]
*   **오픈 월드 객체 추적**: UVO [34], OWTB [18]
*   **기반 데이터셋**: TAO [6] (BURST는 TAO 비디오를 기반으로 픽셀 단위 마스크로 재주석됨)
*   **이미지 수준 인스턴스 분할**: COCO [17], LVIS [10], OpenImages [16] (객체 클래스 정의 및 연합 주석의 배경)
*   **평가 지표**: MOTA [28], sMOTSA [32], mAP (기존 벤치마크에서 사용되던 지표들)

## 🛠️ Methodology
1.  **데이터셋 구축**:
    *   기존 TAO [6] 데이터셋의 비디오를 활용하여 1fps로 주석된 바운딩 박스 위에 픽셀 단위의 마스크를 재주석했습니다.
    *   훈련 세트의 시간적 밀도를 1fps에서 6fps로 높이기 위해 반자동 절차를 사용했습니다.
2.  **반자동 마스크 주석 densification**:
    *   **자동 마스크 전파**: STCN [5] 및 AOT-L [39]과 같은 SOTA VOS 방법을 사용하여 마스크를 시간적으로 전파합니다. 각 마스크에 대해 5가지 다른 전파 결과(순방향/역방향, STCN의 양방향)를 얻습니다.
    *   **합의 마스크 생성**: 5가지 전파된 마스크에 대해 픽셀별 다수결 투표를 수행하여 최종 '합의 마스크'를 생성합니다.
    *   **마스크 품질 평가**: 합의 마스크에 대한 품질 점수 `Q`를 계산합니다. 이는 5가지 전파된 마스크와 합의 마스크 간의 IoU 평균입니다. 또한 마스크 픽셀 영역도 고려합니다.
    *   **수동 재주석**: `Q` 점수가 0.8 미만이거나 마스크 영역이 750픽셀 미만인 '낮은 품질' 마스크를 수동으로 재주석합니다. 이를 통해 수동 주석 노력을 16.9%로 크게 줄였습니다.
3.  **BURST 태스크 분류**:
    *   **Exemplar-guided (가이드 제공)**: 객체가 처음 등장하는 프레임에서 주어진 큐(마스크, 바운딩 박스, 점)를 기반으로 객체를 추적/분할합니다.
        *   Mask: 분할 마스크가 주어짐.
        *   Box: 바운딩 박스 좌표가 주어짐.
        *   Point: 객체 내의 단일 픽셀 좌표가 주어짐.
    *   **Class-guided (클래스 기반)**: 사전 정의된 객체 클래스 세트에 속하는 모든 객체를 추적/분할하고 클래스 레이블을 할당합니다.
        *   Common: COCO [17]의 78개 일반 클래스.
        *   Long-tailed: LVIS [10]의 482개 클래스(희귀 클래스 포함).
        *   Open-world: '알려진' 클래스(Common) 외에 '알 수 없는' 클래스(Uncommon)의 객체도 추적/분할해야 합니다.
4.  **통합 평가 지표**:
    *   **HOTA (Higher-Order Tracking Accuracy)** [20]: 모든 태스크에 사용되며, 프레임 수준 감지 정확도(DetA)와 시간적 연관 정확도(AssA)의 기하 평균으로 계산됩니다.
        *   $HOTA = \sqrt{DetA \cdot AssA}$
        *   $DetA = \frac{|TP|}{|TP|+|FN|+|FP|}$
        *   $AssA = \frac{1}{|TP|} \sum_{c \in \{TP\}} A(c)$, 여기서 $A(c)$는 특정 감지의 연관 점수입니다.
    *   **OWTA (Open-World Tracking Accuracy)** [18]: Open-world 태스크에 사용되며, DetA 대신 DetRe(Detection Recall)를 사용하여 오탐(false positives)에 대한 페널티를 부여하지 않습니다.
        *   $OWTA = \sqrt{DetRe \cdot AssA}$
        *   $DetRe = \frac{|TP|}{|TP|+|FN|}$
5.  **기준선 구현**:
    *   '추적-by-감지(tracking-by-detection)' 패러다임을 광범위하게 활용하여 각 태스크에 대한 기준선을 구축했습니다.
    *   STCN [5] 및 간단한 바운딩 박스 추적기를 포함합니다. 박스/포인트 가이드 태스크의 경우 MaskRCNN의 PointRend [14] 또는 최고 일치 감지를 사용하여 초기 마스크를 생성합니다. 클래스 가이드 태스크의 경우 Mask2Former [4] (COCO 훈련) 또는 Mask-RCNN [11] (LVIS 훈련)에서 얻은 이미지 수준 감지를 사용합니다.

## 📊 Results
*   **Mask-guided 태스크**: STCN [5]이 박스 추적기보다 일관되게 우수한 성능을 보였습니다. 특히 희귀 클래스($HOTA_{unc}$)에서 STCN은 49.2(검증 세트)를 달성한 반면, 박스 추적기는 13.6에 그쳤습니다.
*   **Box-guided/Point-guided 태스크**: 마스크 가이드 태스크에 비해 전반적으로 낮은 점수를 보였습니다. 이는 추가적인 '박스 $\rightarrow$ 마스크' 또는 '포인트 $\rightarrow$ 마스크' 회귀 단계 때문입니다. 박스 가이드에서는 PointRend가 일치하는 감지를 사용하는 것보다 훨씬 더 좋은 성능을 보였습니다.
*   **Common Class-guided 태스크**: STCN 기반 추적기가 박스 추적기보다 우수했습니다(51.2 대 45.5 $HOTA_{com}$). STCN 기반 마스크 전파가 시간적 연관에 더 정확했기 때문입니다.
*   **Long-tail Class-guided 태스크**: Common 태스크에 비해 점수가 현저히 낮았습니다. 이는 더 큰 클래스 세트에 대해 사용된 객체 감지기의 품질이 좋지 않았기 때문입니다. 이 태스크에서는 STCN 추적기보다 박스 추적기가 더 나은 성능을 보였는데, 입력 마스크 품질이 좋지 않을 때 STCN이 잘못된 마스크 전파를 수행하는 경향이 있기 때문입니다.
*   **Open-world 태스크**: 모든 방법에서 'Uncommon' 클래스에 대한 성능 저하가 관찰되었습니다. STCN 추적기가 가장 높은 $HOTA_{all}$ 점수(64.6)를 달성했지만, OWTB [18]는 $HOTA_{unc}$에서 38.8로 다른 기준선보다 월등히 높은 성능을 보였습니다.
*   **태스크 간 비교**:
    *   $HOTA_{com}$의 경우 마스크 Exemplar-guided가 Common Class-guided보다 약간 높았지만, 예상만큼 큰 차이는 아니었습니다. 이는 Exemplar-guided 방법이 객체를 잃으면 회복하지 못하는 반면, Class-guided 방법은 지속적으로 새로운 감지를 수행하기 때문입니다.
    *   $HOTA_{unc}$의 경우 Exemplar-guided 방법이 Class-guided보다 훨씬 우수했습니다(19.5 대 3.6). Exemplar-guided 방법은 클래스에 구애받지 않고 마스크를 전파할 수 있지만, 현재 Class-guided 방법은 이미지별 객체 감지 및 분류 품질에 매우 민감하기 때문입니다.

## 🧠 Insights & Discussion
*   **통합의 중요성**: BURST 벤치마크는 서로 다른 비디오 객체 추적 및 분할 태스크를 한데 모아 연구 커뮤니티 간의 지식 교환을 촉진하고, 여러 태스크를 다룰 수 있는 범용적인 방법론 개발을 가속화하는 데 기여합니다.
*   **HOTA의 유용성**: HOTA와 같은 일관된 지표는 다양한 방법과 태스크 간의 직접적인 정량적 비교를 가능하게 하여 각 방법의 강점과 약점을 심층적으로 분석할 수 있게 합니다. 예를 들어, Exemplar-guided와 Class-guided 방법의 DetA와 AssA를 비교함으로써 프레임별 감지 및 시간적 연관 품질의 차이를 명확히 이해할 수 있었습니다.
*   **도전 과제**: Long-tail 클래스와 '알 수 없는' 객체에 대한 현재 방법론의 성능은 여전히 낮습니다. 이는 이 분야에 대한 추가 연구가 절실히 필요함을 보여주는 중요한 한계점입니다. 특히, Class-guided 태스크의 경우 객체 감지기의 품질이 전체 성능에 큰 영향을 미칩니다.
*   **데이터셋의 가치**: BURST는 방대한 양의 다양하고 고품질 주석을 제공하여, 객체 추적 방법론의 일반화 능력과 다양한 시나리오에서의 강건성을 평가하는 데 귀중한 자원이 될 것입니다.

## 📌 TL;DR
비디오 객체 인식, 분할 및 추적 벤치마크들의 분절 문제를 해결하기 위해, 본 논문은 **BURST**를 제안합니다. BURST는 다양한 비디오와 픽셀 단위 마스크 주석을 포함하는 대규모 데이터셋이며, **6가지 관련 태스크를 통합된 HOTA/OWTA 지표로 평가**합니다. 반자동 주석 파이프라인으로 효율성을 높였으며, 제시된 기준선들은 태스크 간 방법론 적용 가능성을 보여주지만, **Long-tail 및 Open-world 클래스에서는 여전히 성능 개선의 여지가 크다**는 것을 시사합니다.