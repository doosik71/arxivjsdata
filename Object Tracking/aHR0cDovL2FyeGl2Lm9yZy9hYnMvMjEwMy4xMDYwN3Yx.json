{
  "title": "DCF-ASN: Coarse-to-fine Real-time Visual Tracking via Discriminative\n  Correlation Filter and Attentional Siamese Network",
  "authors": "Xizhe Xue, Ying Li, Xiaoyue Yin, Qiang Shen",
  "year": 2021,
  "url": "http://arxiv.org/abs/2103.10607v1",
  "abstract": "Discriminative correlation filters (DCF) and siamese networks have achieved\npromising performance on visual tracking tasks thanks to their superior\ncomputational efficiency and reliable similarity metric learning, respectively.\nHowever, how to effectively take advantages of powerful deep networks, while\nmaintaining the real-time response of DCF, remains a challenging problem.\nEmbedding the cross-correlation operator as a separate layer into siamese\nnetworks is a popular choice to enhance the tracking accuracy. Being a key\ncomponent of such a network, the correlation layer is updated online together\nwith other parts of the network. Yet, when facing serious disturbance, fused\ntrackers may still drift away from the target completely due to accumulated\nerrors. To address these issues, we propose a coarse-to-fine tracking\nframework, which roughly infers the target state via an online-updating DCF\nmodule first and subsequently, finely locates the target through an\noffline-training asymmetric siamese network (ASN). Benefitting from the\nguidance of DCF and the learned channel weights obtained through exploiting the\ngiven ground-truth template, ASN refines feature representation and implements\nprecise target localization. Systematic experiments on five popular tracking\ndatasets demonstrate that the proposed DCF-ASN achieves the state-of-the-art\nperformance while exhibiting good tracking efficiency."
}