# Real-time Multi-Object Tracking Based on Bi-directional Matching
Huilan Luo, Zehua Zeng

## 🧩 Problem to Solve

다중 객체 추적(MOT) 분야에서 실시간 성능과 높은 추적 정확도를 동시에 달성하는 것은 중요한 과제입니다. 특히, 객체의 상당 부분이 가려지거나(occlusion) 일시적으로 이미지에서 사라질 때, 대부분의 기존 추적 알고리즘은 추적 중단(tracking interruption)을 겪으며 잘못된 새 ID를 할당하는 문제(identity switches)가 발생합니다. 또한, 외형 특징(appearance features) 추출은 시간이 많이 소요되어 실시간 추적에 제약을 줍니다.

## ✨ Key Contributions

*   **양방향 매칭 알고리즘 제안:** 양방향 움직임 예측 정보를 활용하여 객체 가려짐(occlusion) 문제를 효과적으로 해결하고 추적 실패를 줄이는 알고리즘을 제안했습니다. 매칭에 실패한 객체들을 임시로 저장하는 '고립 영역(stranded area)' 개념을 도입하여 재출현하는 객체의 ID를 보존합니다.
*   **어텐션 업샘플링 모듈 설계:** 다단계 특징 결합(multi-level feature aggregations)을 최적화하고 모델 훈련 속도를 가속화하는 어텐션 기반 업샘플링 모듈을 개발하여 추적 정확도를 향상시켰습니다.
*   **실시간 양방향 추적 아키텍처 구축:** 제안된 알고리즘은 MOT17 챌린지에서 63.4% MOTA, 55.3% IDF1의 높은 추적 성능을 달성하면서 20.1 FPS의 실시간 추적 속도를 제공합니다.

## 📎 Related Works

*   **검출 기반 추적(Tracking-by-detection) 방법론:**
    *   **POI [18]:** Faster R-CNN, GoogLeNet, Kalman 필터 및 헝가리안 알고리즘을 사용하여 객체 위치 정보와 외형 정보를 결합합니다.
    *   **SORT [16]:** 외형 특징 추출 과정을 제거하여 실시간 추적을 달성했으나 성능 저하가 있었습니다.
    *   **DeepSORT [6]:** SORT의 단점을 보완하기 위해 ResNet을 통한 외형 특징 추출을 다시 도입하고 캐스케이드 매칭(cascade matching) 알고리즘을 설계하여 속도와 정확도를 균형 잡았습니다.
    *   **JDE [23]:** 객체 특징 추출을 객체 검출 단계에 통합하여 추적 속도를 개선했습니다.
    *   **CenterTrack [7]:** CenterNet과 같은 앵커 프리(anchor-free) 객체 검출 네트워크를 사용하여 구조 복잡성을 줄이고 그리디 매칭(greedy matching)을 통해 추적합니다.
*   **업샘플링 최적화 방법론:**
    *   **FairMOT [24], CornerNet [30]:** DLA-Net, Hourglass 네트워크와 같은 백본 네트워크를 사용하여 다중 스케일 특징 융합을 강화합니다.
    *   **Deformable Convolution (DCN) [17]:** 최근 앵커 프리 검출 및 MOT 알고리즘에서 사용되었으나, 병렬 최적화의 어려움으로 훈련 시간이 증가합니다.
*   **매칭 알고리즘:**
    *   **전통적인 방법 [6], [16]:** Kalman 필터로 객체 위치를 예측하고, 헝가리안 방법을 사용하여 거리 또는 외형 유사도 기반으로 매칭합니다.
    *   **CenterTrack [7]:** 현재 프레임 정보를 기반으로 이전 프레임의 객체 위치를 역추적(backward prediction)하고 그리디 매칭을 수행합니다.
    *   **DeepSORT [6]:** 가려짐으로 인한 추적 중단을 줄이기 위해 캐스케이드 매칭을 도입했습니다.

## 🛠️ Methodology

본 논문에서 제안하는 양방향 추적 모델은 입력, 다운샘플링, 업샘플링, 출력, 그리고 두 단계의 매칭 과정으로 구성됩니다.

1.  **아키텍처 개요:**
    *   **입력 단계:** 현재 및 이전 프레임의 RGB 이미지와 이전 프레임의 히트맵을 입력받아 초기 특징을 추출하고 융합합니다.
    *   **다운샘플링 단계:** DLA-Net [29]을 사용하여 입력 특징 맵을 4단계에 걸쳐 다운샘플링하며 채널 수를 두 배로 늘립니다.
    *   **업샘플링 단계:** 제안된 어텐션 업샘플링 모듈을 통해 다중 스케일 특징 맵을 융합하여 원본 입력 이미지 크기의 1/4 해상도를 가진 최종 특징 맵을 생성합니다.
    *   **출력 단계:** 최종 특징 맵은 히트맵, 중심점 오프셋, 객체 너비/높이, 바운딩 박스 네 가장자리 오프셋, 양방향 움직임 벡터 등 총 6가지 출력을 학습하는 6개의 브랜치로 분기됩니다.
    *   **매칭 단계:** 이후 두 단계의 매칭 과정에서 이러한 출력 정보를 활용합니다.

2.  **어텐션 업샘플링 모듈 (Attentional Up-sampling):**
    *   DLA 네트워크 기반으로, 고수준 특징을 어텐션 업샘플링 모듈을 사용하여 업샘플링한 후 다음 저수준 특징과 결합하는 방식으로 작동합니다.
    *   공간 어텐션과 채널 어텐션 메커니즘을 순차적으로 적용하여 객체 위치 및 움직임 정보에 대한 중요도를 높이고 모델 훈련 속도를 가속화합니다.
    *   **채널 어텐션:** Squeeze-and-Excitation 방식을 사용하여 채널 간 정보 교환을 통해 특징 필터링을 개선합니다. 수식은 다음과 같습니다:
        $$F_{ca}(F) = F \otimes \sigma(C_s(F))$$
        여기서 $C_s$는 차원을 줄였다가 다시 늘려 차원 간 정보 교환을 가능하게 하는 컨볼루션 연산을 나타냅니다.
    *   **공간 어텐션:** 채널 차원을 따라 글로벌 평균 풀링(Global Average Pooling)과 글로벌 최대 풀링(Global Maximum Pooling)을 각각 수행한 후 결과를 연결하고, $7 \times 7$ 컨볼루션 레이어와 시그모이드 함수를 적용하여 최종 공간 어텐션 가중치를 생성합니다. 수식은 다음과 같습니다:
        $$F_{sa}(F) = F \otimes \sigma(f^{7 \times 7}([AvgPool(F); MaxPool(F)]))$$
    *   최종적으로 역컨볼루션(deconvolution) 레이어를 통해 특징 맵의 해상도를 두 배로 늘립니다.

3.  **여섯 가지 출력 브랜치 (Six Output Branches):**
    *   **히트맵 및 오프셋:** 객체 중심점 위치의 2차원 정규 분포를 히트맵 레이블로 사용하며 (Eq. (4), (5)), Focal Loss (Eq. (6))를 사용하여 불균형 샘플 문제를 완화합니다.
    *   **객체 크기 및 오프셋:** 객체 너비/높이 및 바운딩 박스 네 가장자리까지의 오프셋을 예측하여 더 정확한 객체 크기 정보를 얻습니다.
    *   **양방향 움직임 예측:** 가려짐 문제 해결을 위해 두 가지 움직임 벡터를 학습합니다.
        *   이전 프레임 상대 움직임 벡터 (Backward motion vector): 첫 번째 매칭 단계에서 현재 객체의 이전 프레임 위치를 예측하는 데 사용됩니다.
        *   미래 프레임 상대 움직임 벡터 (Forward motion vector): 고립 영역 내 객체들이 미래 프레임에서 재출현할 때 위치를 예측하여 매칭을 돕는 데 사용됩니다.
    *   **손실 함수:** 총 손실 함수는 6개 브랜치 손실의 가중치 합으로 구성됩니다 (Eq. (7)). 히트맵 브랜치에는 Focal Loss, 나머지 브랜치에는 Smooth L1 Loss가 사용됩니다.
        $$L_{total} = L_{hm} + L_{off} + L_{wh} + L_{edge} + L_{bv} + L_{fv}$$

4.  **양방향 매칭 알고리즘 (Bi-directional Matching Algorithm):**
    *   객체 움직임의 연속성을 가정하여 거리 기반 그리디 매칭(greedy matching)을 사용합니다.
    *   **거리 행렬 계산 (Algorithm 1):** 현재 프레임에서 검출된 객체의 이전 프레임 위치를 역방향 움직임 벡터로 예측하여, 두 프레임 간 객체들의 거리 행렬을 계산합니다. 거리가 바운딩 박스 면적보다 크면 무한대로 간주하여 매칭에서 제외합니다.
    *   **제안된 양방향 매칭 (Algorithm 2):**
        *   **첫 번째 매칭:** 현재 프레임의 객체와 이전 프레임의 트랙 간에 거리 기반 그리디 매칭을 수행합니다. 성공적으로 매칭된 객체는 이전 ID를 계승합니다.
        *   **고립 영역 (Stranded Area):** 첫 번째 매칭에서 매칭되지 않은 이전 프레임의 트랙들은 '고립 영역'에 임시 저장됩니다. 이 영역 내의 객체 위치는 순방향 움직임 벡터를 사용하여 지속적으로 업데이트됩니다.
        *   **두 번째 매칭:** 첫 번째 매칭에서 매칭되지 않은 현재 프레임의 객체(새로운 객체 또는 재출현 객체)는 먼저 고립 영역 내의 객체들과 매칭을 시도합니다. 이를 통해 가려졌던 객체가 다시 나타날 때 새로운 ID를 할당하는 오류를 방지하고 궤적의 연속성을 유지합니다.
        *   고립 영역 내 객체에는 '생명 값(life value)'이 부여되어 시간이 지남에 따라 감소하며, 0이 되면 제거됩니다. 두 번째 매칭에서도 실패한 객체는 새로운 객체로 간주되어 새 ID가 할당됩니다.

## 📊 Results

*   **MOT17 데이터셋 성능:** 제안된 알고리즘은 MOT17 챌린지에서 63.4% MOTA, 55.3% IDF1을 달성하며 20.1 FPS의 추적 속도를 보였습니다.
*   **어텐션 업샘플링 모듈 성능 (표 1, 표 2):**
    *   IDF1, MT, ML 지표에서 다른 업샘플링 방법(일반 컨볼루션, 변형 가능 컨볼루션, 비대칭 컨볼루션)보다 우수한 성능을 보였습니다.
    *   변형 가능 컨볼루션 및 비대칭 컨볼루션보다 적은 파라미터 수와 빠른 훈련 속도를 가졌습니다 (변형 가능 컨볼루션 대비 3배 이상 빠름).
*   **양방향 추적 알고리즘 성능 (표 3, 그림 4, 그림 5):**
    *   기존 CenterTrack 대비 IDF1이 향상되고 ID 변경(IDs)이 감소했습니다.
    *   가려졌던 객체가 재출현했을 때, CenterTrack은 새 ID를 할당했지만, 본 연구의 양방향 추적 알고리즘은 기존 ID를 유지하며 추적 궤적의 연속성을 보존함을 질적으로 입증했습니다.
    *   훈련 전반에 걸쳐 IDF1 값이 더 안정적이고 높게 유지됨을 보여주었습니다.
*   **가려짐 문제 해결 능력 (표 4, 그림 6):**
    *   MOT17 데이터셋에 임의 가려짐을 추가하여 테스트했을 때, 가려짐 비율이 증가할수록 양방향 추적 알고리즘의 성능 향상 폭(MOTA, IDF1, IDs)이 단방향 추적 방법에 비해 더욱 두드러지게 나타나, 가려짐 상황에서의 강건성을 입증했습니다.
*   **최신 SOTA 방법론과의 비교 (표 5):**
    *   TubeTK, TPM, SST 등 다른 최신 MOT 알고리즘과 비교했을 때, 본 연구의 모델은 단순한 검출 모델을 사용했음에도 불구하고 대부분의 지표에서 뛰어난 성능을 보였습니다.
    *   특히 20.1 FPS의 빠른 추적 속도를 유지하면서 MOTA 63.4%, IDF1 55.3%를 달성하여 속도와 정확도 측면에서 모두 경쟁력을 보였습니다. (GSDT는 더 높은 성능을 보였으나, 추가적인 GNN 사용과 더 많은 데이터셋을 통한 사전 훈련으로 속도가 느렸습니다.)

## 🧠 Insights & Discussion

본 연구는 양방향 움직임 예측 정보와 '고립 영역'을 활용한 양방향 매칭 알고리즘이 객체 가려짐으로 인한 추적 중단과 ID 변경 문제를 효과적으로 해결함을 보여줍니다. 이는 추적 궤적의 연속성을 크게 향상시키며, 실시간 다중 객체 추적의 핵심 과제를 해결하는 데 기여합니다. 또한, 제안된 어텐션 업샘플링 모듈은 정확도와 훈련 효율성이라는 두 마리 토끼를 모두 잡을 수 있음을 입증했습니다.

이 연구는 외형 특징에 의존하지 않고도 높은 성능을 달성하여 실시간 추적의 가능성을 확장합니다. 비록 간단한 검출 모델을 사용했지만, 매칭 알고리즘과 특징 융합 단계의 혁신을 통해 복잡한 SOTA 모델들과도 견줄 만한 성능을 보여주었다는 점에서 의미가 있습니다. 향후 연구는 객체 움직임 예측의 정확도를 더욱 높이고 움직임 벡터 훈련 샘플의 불균형 분포 문제를 해결하는 데 집중할 수 있습니다.

## 📌 TL;DR

*   **문제:** 객체 가려짐 또는 일시적 소실은 다중 객체 추적 시 ID 변경을 유발하여 추적 성능을 저해합니다.
*   **방법:** 본 논문은 실시간 다중 객체 추적을 위해 양방향 움직임 예측 정보와 '고립 영역'을 활용하는 양방향 매칭 알고리즘을 제안합니다. 또한, 정확도와 훈련 효율성을 높이는 어텐션 업샘플링 모듈을 도입합니다.
*   **결과:** 제안된 방법은 MOT17 데이터셋에서 ID 변경을 효과적으로 줄여 (더 높은 IDF1, 더 낮은 IDs) 가려짐 상황에 강건한 성능을 보였습니다. 20.1 FPS의 실시간 속도로 63.4% MOTA, 55.3% IDF1을 달성하며 속도와 정확도 모두에서 경쟁력 있는 결과를 나타냈습니다.