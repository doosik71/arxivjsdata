# FairMOT: On the Fairness of Detection and Re-Identification in Multiple Object Tracking
Yifu Zhang, Chunyu Wang, Xinggang Wang, Wenjun Zeng, Wenyu Liu

## 🧩 Problem to Solve

다중 객체 추적(MOT) 분야에서 객체 탐지(object detection)와 재식별(re-ID)을 단일 네트워크로 통합하는 원샷(one-shot) 학습 방식은 계산 효율성 측면에서 매력적입니다. 그러나 본 논문은 이 두 작업 간에 **경쟁**이 발생하여 성능 저하로 이어진다고 지적합니다. 특히, 기존 원샷 트래커는 재식별을 탐지에 **종속적인 작업**으로 취급하여 네트워크가 탐지에 **편향**되어 재식별 성능이 저하되는 **불공평성(unfairness)** 문제가 발생합니다. 이로 인해 ID 스위치(ID switches)가 증가하는 등의 추적 정확도 문제가 발생합니다. 논문은 이러한 불공평성의 주요 원인으로 세 가지를 지목합니다:
1.  **앵커(anchors) 사용으로 인한 모호성:** 앵커 기반 방식은 하나의 앵커가 여러 ID에 대응하거나 여러 앵커가 하나의 ID에 대응할 수 있어 재식별 특징 학습에 모호성을 유발합니다.
2.  **특징 공유로 인한 충돌:** 탐지 작업은 고수준 특징을, 재식별 작업은 저수준 특징을 필요로 하므로, 특징을 공유할 때 두 작업 간에 **특징 충돌(feature conflict)**이 발생합니다.
3.  **특징 차원 불균형:** 기존 재식별 특징은 고차원인 반면, 탐지 특징은 저차원인 경우가 많아 두 작업의 특징 차원 차이가 성능 저하를 야기합니다.

## ✨ Key Contributions

*   앵커 기반 원샷 MOT 아키텍처가 효과적인 재식별 특징 학습에 한계가 있음을 경험적으로 입증하고, 이 문제가 추적 성능을 심각하게 저해함을 밝혀냈습니다.
*   위에서 언급된 불공평성 문제를 해결하기 위해 CenterNet 기반의 간단하면서도 효과적인 접근 방식인 **FairMOT**를 제안합니다. FairMOT는 단순한 조합이 아닌, 심층적인 경험적 연구를 통해 좋은 추적 결과를 달성하는 데 중요한 여러 세부 설계를 포함합니다.
*   FairMOT는 높은 탐지 및 추적 정확도를 달성하며, 2DMOT15, MOT16, MOT17, MOT20 등 여러 공개 데이터셋에서 기존 SOTA(State-Of-The-Art) 방법들을 큰 폭으로 능가함을 입증했습니다.
*   앵커 프리(anchor-free) 방식, 동종(homogeneous) 브랜치 구조, 저차원 재식별 특징의 효과를 강조하며 MOT에서 탐지-재식별 관계에 대한 통찰을 제공합니다.

## 📎 Related Works

본 연구는 "검출 후 추적(tracking-by-detection)" 패러다임을 따르는 기존 MOT 방법들을 분류하고 비교합니다.

*   **개별 모델 기반(Separate Models):**
    *   **탐지 방법:** Faster R-CNN, DPM, SDP 등 강력한 탐지기를 활용하며, MOT17과 같은 벤치마크는 사전 탐지 결과를 제공합니다.
    *   **추적 방법:**
        *   **위치 및 동작 단서 기반:** SORT, IOU-Tracker (Kalman Filter, IoU 사용). 혼잡하거나 빠른 움직임에 취약할 수 있습니다.
        *   **외모 단서 기반:** DeepSORT (re-ID 네트워크로 특징 추출 후 매칭). 외모 특징의 안정성 덕분에 손실된 트랙 재초기화에 강합니다.
    *   **오프라인 방법:** 시퀀스 전체에 대한 전역 최적화 수행 (min-cost flow, GNNs 등). 높은 정확도를 보이지만 실시간 처리가 어렵습니다.
    *   **장점/한계:** 각 작업에 최적화된 모델을 개발할 수 있으나, 보통 속도가 느려 실시간 추론이 어렵습니다.

*   **단일 모델 기반(Single Model / One-shot trackers):**
    *   **공동 탐지 및 재식별:** Track R-CNN, JDE (단일 네트워크에서 탐지 및 re-ID 특징 추출). 추론 시간을 단축하지만, 기존에는 정확도가 낮았습니다. 본 연구는 이 클래스에 속하며 정확도 저하의 원인을 분석합니다.
    *   **공동 탐지 및 동작 예측:** CenterTrack (객체 중심 변위 예측), Tracktor (바운딩 박스 회귀를 통한 ID 전파). 인접 프레임 간 연관에 중점을 둡니다.
    *   **멀티태스크 학습:** Uncertainty loss, GradNorm, MGDA 등 다양한 손실 균형 기법이 연구되고 있습니다.
    *   **비디오 객체 탐지(VOD):** 추적을 활용하여 어려운 프레임의 탐지 성능을 향상시키는 관련 분야입니다.

## 🛠️ Methodology

FairMOT는 CenterNet을 기반으로 구축되었으며, 탐지 및 재식별 작업을 동등하게 처리하는 동종(homogeneous) 브랜치 구조를 특징으로 합니다.

*   **백본 네트워크:**
    *   정확도와 속도의 균형을 위해 **ResNet-34**를 기본 백본으로 채택합니다.
    *   멀티 레이어 특징 융합(multi-layer feature fusion)을 위해 **강화된 DLA (Deep Layer Aggregation)**를 적용합니다. 이 DLA는 낮은 수준과 높은 수준 특징 사이에 더 많은 스킵 연결을 가지며, 변형 가능한 컨볼루션(deformable convolution)을 사용하여 객체 스케일 및 자세에 따라 수용 필드를 동적으로 조정하여 정렬 문제를 완화합니다.
    *   최종 특징 맵의 해상도는 입력 이미지의 $1/4$입니다.

*   **탐지 브랜치:**
    *   **히트맵 헤드($L_{heat}$):** 객체 중심의 위치를 추정합니다. ground-truth 객체 중심과 가까울수록 응답값이 1에 가깝고, 멀어질수록 지수적으로 감소하는 히트맵을 생성합니다. Focal Loss를 사용하여 훈련합니다.
        $$ L_{heat} = - \frac{1}{N} \sum_{xy} \begin{cases} (1-\hat{M}_{xy})^\alpha \log(\hat{M}_{xy}) & M_{xy} = 1 \\ (1-M_{xy})^\beta (\hat{M}_{xy})^\alpha \log(1-\hat{M}_{xy}) & \text{otherwise} \end{cases} $$
        여기서 $N$은 이미지 내 객체 수, $\hat{M}$은 예측된 히트맵, $M$은 ground-truth 히트맵입니다.
    *   **박스 오프셋 및 크기 헤드($L_{box}$):** 다운샘플링으로 인한 양자화 오류를 줄이기 위해 객체 중심에 대한 연속적인 오프셋과 객체의 높이 및 너비를 추정합니다. $L_1$ 손실을 사용하여 훈련합니다.
        $$ L_{box} = \sum_{i=1}^N \|o_i - \hat{o}_i\|_1 + \lambda_s \|s_i - \hat{s}_i\|_1 $$
        여기서 $o_i, s_i$는 ground-truth 오프셋 및 크기, $\hat{o}_i, \hat{s}_i$는 예측값입니다.

*   **재식별 브랜치:**
    *   객체를 구분할 수 있는 특징을 생성하는 것이 목표입니다. 백본 특징 위에 $128$개의 커널을 가진 컨볼루션 레이어를 적용하여 각 위치에 대한 재식별 특징을 추출합니다.
    *   **재식별 손실($L_{identity}$):** 훈련 세트에서 동일 ID를 가진 모든 객체 인스턴스를 동일 클래스로 간주하고 분류 작업으로 학습합니다. 오직 객체 중심에서 추출된 재식별 특징 벡터만 훈련에 사용됩니다.
        $$ L_{identity} = - \sum_{i=1}^N \sum_{k=1}^K L_i(k) \log(p(k)) $$
        여기서 $K$는 훈련 데이터의 총 ID 수, $L_i(k)$는 ground-truth 클래스 레이블의 원-핫 표현, $p(k)$는 예측된 클래스 분포입니다.

*   **FairMOT 훈련:**
    *   탐지 손실($L_{detection} = L_{heat} + L_{box}$)과 재식별 손실($L_{identity}$)을 함께 훈련합니다.
    *   **불확실성 손실(Uncertainty Loss):** (Kendall et al., 2018)에서 제안된 불확실성 손실을 사용하여 두 작업의 손실을 자동으로 균형을 맞춥니다.
        $$ L_{total} = \frac{1}{2} \left( \frac{1}{e^{w_1}} L_{detection} + \frac{1}{e^{w_2}} L_{identity} + w_1 + w_2 \right) $$
        여기서 $w_1, w_2$는 학습 가능한 파라미터입니다.
    *   **단일 이미지 훈련(Single Image Training):** COCO, CrowdHuman 같은 이미지 레벨 탐지 데이터셋으로 FairMOT를 사전 훈련하는 방법을 제안합니다. 각 바운딩 박스에 고유 ID를 할당하여 각 객체 인스턴스를 별도의 클래스로 간주하고, 다양한 이미지 변환(HSV, 회전, 스케일링, 변환, 전단)을 적용합니다. 이는 인간 탐지 성능을 향상시키고, 추적기의 연관 능력을 강화하며, 도메인 일반화 능력을 향상시킵니다.

*   **온라인 추론:**
    *   네트워크는 $1088 \times 608$ 크기의 프레임을 입력으로 받습니다.
    *   예측된 히트맵에서 NMS(Non-Maximum Suppression)를 통해 피크 키포인트를 추출하고, 해당 위치에서 바운딩 박스 및 ID 임베딩을 계산합니다.
    *   **온라인 데이터 연관:** MOTDT(Chen et al., 2018a)의 계층적 온라인 데이터 연관 방식을 따릅니다.
        *   **1단계:** Kalman Filter(동작 예측)와 재식별 특징(외모 유사성)을 융합하여 초기 매칭을 수행합니다. Mahalanobis 거리와 코사인 거리를 사용하며, 가중치 $\lambda=0.98$로 융합합니다. Hungarian 알고리즘을 사용하여 매칭 임계값 $\tau_1=0.4$로 매칭합니다.
        *   **2단계:** 1단계에서 매칭되지 않은 탐지 및 트랙렛에 대해 바운딩 박스 IoU(Intersection over Union) 기반으로 매칭을 시도합니다(매칭 임계값 $\tau_2=0.5$).
        *   트랙렛의 외모 특징을 매 스텝 업데이트하고, 매칭되지 않은 탐지는 새로운 트랙으로 초기화하며, 매칭되지 않은 트랙렛은 30프레임 동안 유지하여 재출현 시 재식별할 수 있도록 합니다.

## 📊 Results

FairMOT는 다양한 벤치마크와 어블레이션 연구를 통해 뛰어난 성능을 입증했습니다.

*   **MOTChallenge 벤치마크 결과:**
    *   2DMOT15, MOT16, MOT17, MOT20 데이터셋의 테스트 세트에서 모든 온라인 및 오프라인 트래커 중 **1위**를 차지했습니다.
    *   특히, 기존 원샷 트래커인 JDE (Wang et al., 2020b) 대비 2DMOT15에서 MOTA는 $67.5 \rightarrow 77.2$로, IDF1은 $66.7 \rightarrow 79.8$로, ID 스위치는 $218 \rightarrow 80$으로 크게 개선되었습니다.
    *   Track R-CNN (Voigtlaender et al., 2019) 대비 IDF1 ($49.4 \rightarrow 64.0$) 및 ID 스위치($294 \rightarrow 96$)에서 현저히 우수한 성능을 보였습니다.
    *   단일 RTX 2080Ti GPU에서 **30 FPS**의 실시간 추론 속도를 달성했습니다.

*   **어블레이션 연구 결과:**
    *   **재식별 특징 추출 전략:** 객체 중심에서 특징을 샘플링하는 **Center** 방식이 ROI-Align이나 POS-Anchor 방식보다 월등히 높은 IDF1 및 TPR을 보이며, ID 스위치를 크게 줄였습니다. Bi-linear Interpolation (Center-BI)은 더 정확한 특징 샘플링으로 TPR을 추가적으로 향상시켰습니다.
    *   **멀티태스크 손실 균형:** "Uncertainty-task" 방식이 좋은 균형을 이루었으며, "GradNorm"이 가장 좋은 추적 정확도를 보였으나 훈련 시간이 길었습니다.
    *   **다중 계층 특징 융합(MLFF):** ResNet 단독 사용보다 FPN, DLA-34, HRNet-W18과 같은 다중 계층 특징 융합 구조를 가진 백본이 MOTA, IDF1, TPR에서 현저히 높은 성능을 달성하여 특징 충돌 완화에 효과적임을 입증했습니다. DLA-34가 특히 다양한 스케일 객체에 강점을 보였습니다.
    *   **재식별 특징 차원:** JDE와 FairMOT 모두에서 **$64$ 차원**의 저차원 재식별 특징이 $512$ 차원보다 MOTA에서 더 나은 성능을 보였습니다. 이는 탐지 정확도를 덜 해치고, MOT 작업의 특성상 낮은 차원 특징으로도 충분히 식별력이 있기 때문으로 분석됩니다.
    *   **데이터 연관 방법:** 바운딩 박스 IoU, 재식별 특징, Kalman Filter를 모두 활용할 때 가장 좋은 추적 성능(높은 MOTA, IDF1, 낮은 IDs)을 달성했습니다. 재식별 특징과 Kalman Filter는 ID 스위치를 크게 줄이는 데 기여했습니다.

*   **단일 이미지 훈련 효과:**
    *   CrowdHuman 데이터셋으로 사전 훈련된 모델은 MOT17에서 직접 추적기로 사용될 수 있었으며, 심지어 MOT17 데이터셋만으로 훈련하거나 다른 대규모 데이터셋과 조합하여 훈련한 것보다 더 높은 MOTA($73.7$)를 달성하여 데이터 효율성과 강력한 도메인 일반화 능력을 입증했습니다.

*   **정성적 결과:**
    *   MOT17 테스트셋 시각화 결과는 보행자 교차, 혼잡한 장면, 심한 가려짐, 큰 스케일 변화 등 도전적인 시나리오에서도 FairMOT가 정확한 ID와 바운딩 박스 추적을 유지함을 보여줍니다.

## 🧠 Insights & Discussion

FairMOT는 기존 원샷 MOT 방법론의 "불공평성" 문제를 근본적으로 해결함으로써 다음과 같은 중요한 통찰과 함의를 제공합니다.

*   **앵커 불공평성 해소:** 앵커 프리(anchor-free) CenterNet을 기반으로 객체 중심(center point)에서만 재식별 특징을 추출하는 전략은 기존 앵커 기반 방식이 가지던 **모호성(ambiguity)**(하나의 앵커가 여러 ID에, 여러 앵커가 한 ID에 대응)을 제거합니다. 이는 재식별 특징 학습의 **공정성**을 확보하고, 결과적으로 ID 스위치를 획기적으로 줄이는 핵심 요인이 됩니다.
*   **특징 공유 충돌 완화:** 탐지(고수준)와 재식별(저수준)이 요구하는 특징의 차이에서 발생하는 **특징 충돌**은 다중 계층 특징 융합(DLA-34)을 통해 효과적으로 완화됩니다. 이 구조는 각 작업이 융합된 특징에서 자신의 목적에 맞는 정보를 자유롭게 추출할 수 있도록 하여, 네트워크가 특정 작업에 편향되지 않고 두 작업 모두에서 높은 성능을 발휘하도록 돕습니다.
*   **재식별 특징 차원 최적화:** 본 연구는 MOT 작업에서는 고차원의 재식별 특징이 항상 좋은 것이 아님을 밝혀냈습니다. 저차원($64$) 재식별 특징이 오히려 탐지 정확도를 덜 해치고 전반적인 MOT 성능과 효율성을 높인다는 "일반적인 규칙"을 제시합니다. 이는 MOT가 일반적인 Re-ID 작업(대규모 후보군 매칭)과 달리 인접 프레임 간의 소수 객체 매칭에 중점을 두기 때문이며, MOT에 특화된 특징 설계의 중요성을 강조합니다.
*   **실용적 가치 및 효율성:** FairMOT는 높은 정확도를 유지하면서도 실시간 추론 속도를 달성하여 실제 응용 분야에 매우 매력적입니다. 특히, 단일 이미지 훈련 방식은 ID 주석이 없는 데이터셋으로도 강력한 사전 훈련 모델을 얻을 수 있게 하여, 데이터 주석 작업의 부담을 크게 줄이는 실용적인 이점을 제공합니다.

전반적으로 FairMOT는 MOT의 핵심 과제인 탐지-재식별 통합 학습에서 발생하던 구조적 불공평성 문제를 체계적으로 분석하고, 이를 해결하는 효과적인 아키텍처 및 훈련 전략을 제시하여 해당 분야의 발전에 크게 기여했습니다.

## 📌 TL;DR

기존 원샷 다중 객체 추적(MOT)에서 탐지(detection)와 재식별(re-ID) 작업 간의 **불공평한 경쟁**으로 인한 성능 저하를 해결하고자 **FairMOT**가 제안되었습니다. FairMOT는 **앵커 프리(anchor-free)** CenterNet 기반의 동종 브랜치 구조를 통해 객체 중심에서만 재식별 특징을 추출하여 **모호성을 제거**하고, DLA-34와 같은 다중 계층 특징 융합 백본으로 **특징 충돌을 완화**합니다. 또한, **저차원 재식별 특징**이 MOT에서 더 높은 효율성과 전반적인 정확도를 가져옴을 발견했습니다. 결과적으로 FairMOT는 여러 MOT 벤치마크에서 기존 SOTA 방법들을 **크게 능가하는 추적 정확도**를 달성하면서도 **실시간 추론**이 가능하며, **단일 이미지 훈련**으로 데이터 효율성까지 높여 실제 응용에 매우 유용함을 입증했습니다.