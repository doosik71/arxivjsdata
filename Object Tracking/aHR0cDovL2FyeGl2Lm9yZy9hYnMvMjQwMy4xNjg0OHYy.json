{
  "url": "http://arxiv.org/abs/2403.16848v2",
  "title": "Multiple Object Tracking as ID Prediction",
  "authors": "Ruopeng Gao, Ji Qi, Limin Wang",
  "year": 2024,
  "abstract": "Multi-Object Tracking (MOT) has been a long-standing challenge in video\nunderstanding. A natural and intuitive approach is to split this task into two\nparts: object detection and association. Most mainstream methods employ\nmeticulously crafted heuristic techniques to maintain trajectory information\nand compute cost matrices for object matching. Although these methods can\nachieve notable tracking performance, they often require a series of elaborate\nhandcrafted modifications while facing complicated scenarios. We believe that\nmanually assumed priors limit the method's adaptability and flexibility in\nlearning optimal tracking capabilities from domain-specific data. Therefore, we\nintroduce a new perspective that treats Multiple Object Tracking as an\nin-context ID Prediction task, transforming the aforementioned object\nassociation into an end-to-end trainable task. Based on this, we propose a\nsimple yet effective method termed MOTIP. Given a set of trajectories carried\nwith ID information, MOTIP directly decodes the ID labels for current\ndetections to accomplish the association process. Without using tailored or\nsophisticated architectures, our method achieves state-of-the-art results\nacross multiple benchmarks by solely leveraging object-level features as\ntracking cues. The simplicity and impressive results of MOTIP leave substantial\nroom for future advancements, thereby making it a promising baseline for\nsubsequent research. Our code and checkpoints are released at\nhttps://github.com/MCG-NJU/MOTIP."
}