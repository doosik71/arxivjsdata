{
  "url": "http://arxiv.org/abs/2209.12118v2",
  "title": "BURST: A Benchmark for Unifying Object Recognition, Segmentation and\n  Tracking in Video",
  "authors": "Ali Athar, Jonathon Luiten, Paul Voigtlaender, Tarasha Khurana, Achal Dave, Bastian Leibe, Deva Ramanan",
  "year": 2022,
  "abstract": "Multiple existing benchmarks involve tracking and segmenting objects in video\ne.g., Video Object Segmentation (VOS) and Multi-Object Tracking and\nSegmentation (MOTS), but there is little interaction between them due to the\nuse of disparate benchmark datasets and metrics (e.g. J&F, mAP, sMOTSA). As a\nresult, published works usually target a particular benchmark, and are not\neasily comparable to each another. We believe that the development of\ngeneralized methods that can tackle multiple tasks requires greater cohesion\namong these research sub-communities. In this paper, we aim to facilitate this\nby proposing BURST, a dataset which contains thousands of diverse videos with\nhigh-quality object masks, and an associated benchmark with six tasks involving\nobject tracking and segmentation in video. All tasks are evaluated using the\nsame data and comparable metrics, which enables researchers to consider them in\nunison, and hence, more effectively pool knowledge from different methods\nacross different tasks. Additionally, we demonstrate several baselines for all\ntasks and show that approaches for one task can be applied to another with a\nquantifiable and explainable performance difference. Dataset annotations and\nevaluation code is available at: https://github.com/Ali2500/BURST-benchmark."
}