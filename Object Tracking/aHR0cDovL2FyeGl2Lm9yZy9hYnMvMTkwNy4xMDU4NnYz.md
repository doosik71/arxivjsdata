# Distilled Siamese Networks for Visual Tracking

Jianbing Shen, Yuanpei Liu, Xingping Dong, Xiankai Lu, Fahad Shahbaz Khan, and Steven Hoi

## 🧩 Problem to Solve

최근 Siamese 네트워크 기반의 추적기들은 실시간 객체 추적 분야에서 뛰어난 성능을 보여주었지만, 높은 메모리 비용으로 인해 모바일 기기와 같이 메모리 제약이 있는 환경에서의 적용이 제한적입니다. 모델 크기를 단순히 줄여 재훈련하는 방식은 추적 성능의 심각한 저하를 초래합니다. 따라서, 추적 정확도를 크게 손실하지 않으면서 Siamese 추적기의 메모리 비용을 줄이는 효과적인 방법을 개발하는 것이 주요 문제입니다.

## ✨ Key Contributions

- **새로운 Distilled Siamese Tracker (DST) 프레임워크 제안:** 대규모 Siamese 추적기(교사 모델)로부터 작고, 빠르며, 정확한 추적기(학생 모델)를 학습하기 위한 지식 증류(Knowledge Distillation, KD) 방법을 도입하여 시각 추적 분야에 KD를 최초로 적용했습니다.
- **교사-학생 지식 증류 (Teacher-Students Knowledge Distillation, TSsKD) 모델 개발:** 한 명의 교사와 여러 명의 학생이 서로 배우고 돕는 학교의 학습 메커니즘에서 영감을 받아, 교사-학생 지식 전달과 학생-학생 지식 공유를 포함하는 새로운 KD 모델을 제안했습니다.
- **Siamese Target Response (STR) 학습 알고리즘 도입:** 교사 네트워크의 지식을 효과적으로 포착하기 위해 추적에 특화된 지식 전달 접근법을 제안했습니다. 이는 중간 수준의 의미 단서(semantic cues)를 학습하고 오버피팅을 줄이기 위한 새로운 증류 손실(teacher soft loss, adaptive hard loss)을 포함합니다.
- **조건부 공유 손실(Conditional Sharing Loss) 제안:** 학생들 간의 상호 학습을 위해 신뢰할 수 있는 지식만 공유하고 부정확한 정보의 전파를 줄이는 조건부 손실을 통해 객체 변형(object deformation) 및 배경 혼란(background clutter)과 같은 까다로운 추적 속성을 해결하는 데 기여했습니다.
- 제안된 증류 추적기들은 기본 모델과 비교하여 최대 **18배 압축률**, **265 FPS**의 프레임 속도를 달성하면서도 유사한 추적 정확도를 유지했습니다.

## 📎 Related Works

- **시각 추적 및 Siamese 추적기:**
  - **DCF(Discriminative Correlation Filter) 기반 방법:** Bolme et al. [5]의 초기 작업, Danelljan et al. [14], [15], [17], [18], [19]의 스케일 추정 및 연속 연산자 개선, Dai et al. [13], Galoogahi et al. [35], [36], Ugur et al. [34], Sun et al. [65] 등의 연구.
  - **딥러닝 기반 추적:** Wang & Yeung [71]이 딥러닝을 추적에 처음 도입했으며, Qi et al. [55], Yang et al. [79] 등이 온라인 학습을 통해 정확도 향상.
  - **Siamese 추적기:** SINT [67]가 Siamese 네트워크를 추적에 도입, SiamFC [3]는 단순하고 효과적인 실시간 추적 프레임워크를 제안하며 광범위한 확장 연구 [43], [86], [45], [22], [84], [66], [56], [74]를 이끌었습니다. 특히 SiamRPN [43]은 RPN을 통합하여 위치 및 스케일 회귀를 통해 높은 속도와 정확도를 달성했습니다.
- **모델 압축 및 지식 증류(KD):**
  - **프루닝(Pruning) 및 양자화(Quantization):** Srinivas et al. [64], Han et al. [27], Gupta et al. [26] 등의 방법들이 신경망의 연산을 제거하거나 단순화하여 압축을 달성합니다.
  - **지식 증류(KD):** Bucilua et al. [6]의 초기 작업, Ba et al. [2] 및 Romero et al. [60]의 얕은/얇은 네트워크 성능 향상, Hinton et al. [32]의 '어두운 지식(dark knowledge)' 개념 도입. 그 외에 Zagoruyko & Komodakis [81], Czarnecki et al. [12], Furlanello et al. [24], Kim et al. [37], Zhang et al. [83] 등 다양한 KD 연구가 진행되었습니다. N2N [1]은 DRL을 이용한 자동화된 KD 아키텍처 생성을 다루며, Chen et al. [7] 및 Liu et al. [48]은 탐지 및 분할에 KD를 적용했습니다. 본 연구는 단순히 백본을 학습하는 것을 넘어, Siamese 추적기 자체의 효율성을 직접적으로 향상시키는 데 초점을 맞춥니다.

## 🛠️ Methodology

본 논문에서 제안하는 Distilled Siamese Tracker (DST) 프레임워크는 크게 두 가지 핵심 단계로 구성됩니다.

1. **"Dim" 학생 선택 (Deep Reinforcement Learning, DRL 기반):**

   - **MDP 모델링:** 네트워크 아키텍처 압축을 Markov Decision Process (MDP)로 모델링하여 최적의 압축 전략을 학습합니다.
   - **상태 공간($S$) 및 행동($A$):** 상태 공간은 교사 네트워크로부터 파생된 모든 가능한 축소된 네트워크 아키텍처 집합이며, 행동은 각 레이어의 채널 수를 변경하는 레이어 축소($a_{t} \in \{0.1, 0.2, \dots, 1\}$)입니다.
   - **보상 함수($R$):** 추적 정확도와 압축률 사이의 균형을 맞추기 위해 $R = C(2-C) \cdot \frac{acc_{s}}{acc_{t}}$으로 정의됩니다. 여기서 $C$는 압축률($1 - S_{s}/S_{t}$), $acc_{s}$와 $acc_{t}$는 각각 학생 및 교사 네트워크의 검증 정확도입니다.
   - **실용적인 추적 성능 평가:** 전체 데이터셋에서 작은 데이터셋을 구성하여 학생 네트워크의 성능을 평가합니다. 정확도($acc$)는 검증 서브셋에서 상위 $N$개 제안($p_{ij}$)과 실제 값($g_{i}$)의 오버랩($o$)을 계산합니다: $acc = \sum_{i=1}^{M} \sum_{j=1}^{N} o(g_{i}, p_{ij})$.
   - **학습 해결:** REINFORCE [76] 정책 기울기 알고리즘을 사용하여 정책 네트워크($\theta$)를 최적화합니다.

2. **교사-학생 지식 증류 (Teacher-Students Knowledge Distillation, TSsKD):**
   - **교사-학생 지식 전달:**
     - **Siamese Target Response (STR) 학습:** 교사의 응답 맵을 모방하도록 강제하여 배경 간섭 없이 중간 수준의 특징 맵을 학생에게 전달합니다. 3D 특징 맵을 2D 응답 맵으로 변환하는 매핑 함수 $F(U) = \sum_{C}^{i=1} |U_{i}|$를 사용합니다. 손실은 검색($L_{STR}^{x}$) 및 타겟($L_{STR}^{z}$) 브랜치에 대해 정의되며, $L_{STR} = L_{STR}^{x} + L_{STR}^{z}$입니다.
     - **증류 손실 ($L_{D}$):**
       - **Teacher Soft (TS) 손실 ($L_{TS}$):** 분류에 대한 KL 발산 ($L_{TS}^{cls} = KL(P_{s}, P_{t})$) 및 회귀 손실 ($L_{TS}^{reg}$)을 포함하며, 교사의 '어두운 지식(dark knowledge)'을 학생에게 전달합니다.
       - **Adaptive Hard (AH) 손실 ($L_{AH}$):** 실제 값(ground-truth)을 통합하며, 학생의 회귀 벡터가 교사보다 품질이 좋지 않을 때 실제 값에 가깝도록 유도하는 조건부 회귀 손실 ($L_{AH}^{reg}$)을 포함합니다.
       - 전체 증류 손실은 $L_{D} = \eta L_{TS} + \lambda L_{AH}$로 구성됩니다.
     - **총 교사-학생 손실:** $L_{KT} = \omega L_{STR} + \eta L_{TS} + \lambda L_{AH}$.
   - **학생-학생 지식 공유:**
     - "dim" 학생(s1)과 "intelligent" 학생(s2) 간의 상호 학습을 가능하게 합니다.
     - 분류를 위한 KL 발산($L_{KS}^{cls}$) 및 회귀를 위한 smooth $L_1$ 손실($L_{KS}^{reg}$)을 사용하여 $L_{KS}(s1||s2)$를 정의합니다.
     - **조건부 억제 가중 함수($\sigma(s1)$):** 공유되는 지식의 신뢰도를 제어하기 위해 $\sigma(s1) = f(e) \text{ if } L_{GT}(s2) - L_{GT}(t) < h \text{ else } 0$으로 정의됩니다. 이는 교사 대비 학생의 성능 격차($gap$)에 따라 신뢰할 수 있는 지식만 공유합니다.
     - 학생 s1에 대한 총 지식 증류 손실: $L_{KD}^{s1} = L_{KT}^{s1} + \sigma(s1)L_{KS}(s1||s2)$.
     - 학생 s2에 대한 총 지식 증류 손실: $L_{KD}^{s2} = L_{KT}^{s2} + \beta \cdot \sigma(s2)L_{KS}(s2||s1)$ (여기서 $\beta \in (0,1)$은 "dim" 학생의 신뢰도를 반영하는 할인 계수).
     - TSsKD의 전체 손실은 $L_{KD} = L_{KD}^{s1} + L_{KD}^{s2}$입니다.

## 📊 Results

- **"Dim" 학생 선택 결과:** SiamRPN(361.8 MB)은 19.7 MB의 DSTrpn으로, SiamFC(9.4 MB)는 0.7 MB의 DSTfc로 압축되어 최적의 아키텍처가 생성되었습니다.
- **손실 비교:** "Intelligent" 학생 모델이 "dim" 학생 모델보다 전체 학습 및 검증 과정에서 더 낮은 손실을 유지하며, 이는 "dim" 학생에게 신뢰할 수 있는 추가 지식을 제공하여 더 효과적인 지식 증류로 이어집니다.
- **벤치마크 성능:**
  - **OTB-100:** DSTrpn은 SiamRPN(90 FPS)보다 약 3배 빠른 265 FPS를 달성하면서도 유사하거나 약간 더 나은 정밀도 및 AUC 점수를 기록했습니다. DSTfc는 SiamFC(110 FPS)보다 2배 이상 빠른 230 FPS를 기록했습니다.
  - **VOT2019, LaSOT, TrackingNet:** 대규모 데이터셋에서 교사 모델과 거의 동일한 AUC 점수를 유지하며 강력한 일반화 성능을 입증했습니다. DSTrpn은 더 큰 모델 크기와 복잡한 전략을 사용하는 DaSiamRPN보다 우수한 성능을 보였습니다.
  - **FaceTracking:** 기존 모델과 비교할 만하거나 약간 더 나은 성능을 달성하여 제안된 KD 방법의 효과와 일반화 가능성을 입증했습니다.
- **정성적 평가:** OTB-100의 까다로운 시퀀스(예: Biker, Jogging-2, Subway)에서 DSTrpn은 SiamRPN보다 뛰어난 추적 성능을 보여주며, 특히 변형(Deformation), 빠른 움직임(Fast Motion), 가려짐(Occlusion), 배경 혼란(Background Clutter)과 같은 도전적인 상황에서 강인함을 보였습니다. OTB-100의 11가지 모든 도전 과제에서 최고의 성능을 달성했습니다 (그림 9).
- **어블레이션 연구:**
  - **지식 전달 구성 요소:** TS 손실, AH 손실, STR 손실 각각이 성능 향상에 기여함을 확인했습니다. STR의 가중치 전략과 새로운 증류 손실이 중요하며, 이들을 모두 결합했을 때 교사 모델과의 성능 격차가 크게 줄어들었습니다.
  - **다양한 학습 메커니즘:** NOKD(하드 레이블 학습)보다 TSKD(교사-학생 지식 증류)가, TSKD보다 TSsKD(학생-학생 지식 공유 포함)가 모든 학생의 성능을 향상시켰습니다. 특히 "dim" 학생의 AUC는 TSsKD를 통해 1.6%~2.2% 향상되었고, 도전적인 속성(변형, 배경 혼란)에서 4% 이상의 상당한 개선을 보였습니다.
- **추가 학생 수 실험:** 두 명의 학생만으로도 충분히 좋은 성능을 달성했으며, 학생 수를 더 늘려도 큰 성능 향상은 없었습니다.
- **모델 선택 감도 평가:** DRL 과정에서 생성된 다양한 모델들 간의 성능이 유사하여, 제안된 방법이 탐색된 네트워크 아키텍처에 강인함을 보여주었습니다.
- **CPU 속도:** CPU 환경에서 DSTrpn은 20 FPS, DSTfc는 30 FPS를 달성하여 SiamRPN(8 FPS), SiamFC(12 FPS)보다 월등히 빠른 실시간에 가까운 속도를 보였습니다.
- **SiamRPN++ 확장 실험:** TSsKD는 ResNet34 또는 ResNet18과 같은 더 작은 백본을 사용하는 SiamRPN++ 추적기의 성능을 크게 향상시켰습니다.

## 🧠 Insights & Discussion

본 연구는 Siamese 네트워크 기반 시각 추적기의 주요 한계점인 높은 메모리 비용 문제를 지식 증류를 통해 성공적으로 해결했습니다. 특히, "교사-학생-학생" 간의 상호작용을 모방한 TSsKD 모델은 단일 교사로부터 지식을 전달받는 것을 넘어 학생들 간의 지식 공유를 통해 학습의 깊이를 더했다는 점이 중요합니다.

Siamese Target Response (STR) 학습과 적응형 하드 손실(Adaptive Hard Loss)을 포함한 추적 특화 증류 전략은 단순히 검출 작업에 사용되는 KD 손실을 확장하는 것을 넘어, 시각 추적이라는 특정 작업의 특성을 효과적으로 반영했습니다. 또한, 조건부 지식 공유 메커니즘은 신뢰할 수 없는 정보의 전파를 막아 'dim' 학생의 성능을 안정적으로 향상시키는 데 기여했습니다.

결과적으로, 증류된 추적기들은 원본 대형 모델에 필적하는 정확도를 유지하면서도 모델 크기를 대폭 줄이고 프레임 속도를 비약적으로 높여 모바일 및 임베디드 환경에서의 실제 적용 가능성을 크게 확장했습니다. 특히, 특정 도전적인 시나리오에서 교사 모델을 능가하는 성능을 보인 것은 증류 과정이 단순한 압축을 넘어 모델의 강건성을 향상시킬 수 있음을 시사합니다. 이러한 증류 방법론은 향후 다양한 SOTA 딥 트래커의 실용화를 위한 중요한 기반이 될 것입니다.

## 📌 TL;DR

본 논문은 메모리 비용이 높은 Siamese 추적기를 위한 `Distilled Siamese Tracker (DST)` 프레임워크를 제안합니다. 이 프레임워크는 `교사-학생 지식 증류 (TSsKD)` 모델을 기반으로 하며, 교사로부터 지식을 전달받고 학생들끼리 지식을 공유하여 작고, 빠르며, 정확한 추적기를 학습합니다. `Siamese Target Response (STR)` 학습과 새로운 `증류 손실`을 통해 추적 특화 지식 전달을 최적화하고, `조건부 지식 공유`를 통해 학생들 간의 상호 학습을 강화합니다. 실험 결과, 제안된 증류 추적기는 원본 모델 대비 최대 `18배`의 압축률과 `265 FPS`의 고속을 달성하면서도 유사한 추적 정확도를 유지하여, 실제 모바일 환경에서의 적용 가능성을 크게 높였습니다.
