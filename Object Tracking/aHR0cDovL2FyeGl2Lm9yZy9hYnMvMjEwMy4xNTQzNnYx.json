{
  "url": "http://arxiv.org/abs/2103.15436v1",
  "title": "Transformer Tracking",
  "authors": "Xin Chen, Bin Yan, Jiawen Zhu, Dong Wang, Xiaoyun Yang, Huchuan Lu",
  "year": 2021,
  "abstract": "Correlation acts as a critical role in the tracking field, especially in\nrecent popular Siamese-based trackers. The correlation operation is a simple\nfusion manner to consider the similarity between the template and the search\nregion. However, the correlation operation itself is a local linear matching\nprocess, leading to lose semantic information and fall into local optimum\neasily, which may be the bottleneck of designing high-accuracy tracking\nalgorithms. Is there any better feature fusion method than correlation? To\naddress this issue, inspired by Transformer, this work presents a novel\nattention-based feature fusion network, which effectively combines the template\nand search region features solely using attention. Specifically, the proposed\nmethod includes an ego-context augment module based on self-attention and a\ncross-feature augment module based on cross-attention. Finally, we present a\nTransformer tracking (named TransT) method based on the Siamese-like feature\nextraction backbone, the designed attention-based fusion mechanism, and the\nclassification and regression head. Experiments show that our TransT achieves\nvery promising results on six challenging datasets, especially on large-scale\nLaSOT, TrackingNet, and GOT-10k benchmarks. Our tracker runs at approximatively\n50 fps on GPU. Code and models are available at\nhttps://github.com/chenxin-dlut/TransT.",
  "citation": 1746
}