{
  "title": "Adaptive Objectness for Object Tracking",
  "authors": "Pengpeng Liang, Chunyuan Liao, Xue Mei, Haibin Ling",
  "year": 2015,
  "url": "http://arxiv.org/abs/1501.00909v1",
  "abstract": "Object tracking is a long standing problem in vision. While great efforts\nhave been spent to improve tracking performance, a simple yet reliable prior\nknowledge is left unexploited: the target object in tracking must be an object\nother than non-object. The recently proposed and popularized objectness measure\nprovides a natural way to model such prior in visual tracking. Thus motivated,\nin this paper we propose to adapt objectness for visual object tracking.\nInstead of directly applying an existing objectness measure that is generic and\nhandles various objects and environments, we adapt it to be compatible to the\nspecific tracking sequence and object. More specifically, we use the newly\nproposed BING objectness as the base, and then train an object-adaptive\nobjectness for each tracking task. The training is implemented by using an\nadaptive support vector machine that integrates information from the specific\ntracking target into the BING measure. We emphasize that the benefit of the\nproposed adaptive objectness, named ADOBING, is generic. To show this, we\ncombine ADOBING with seven top performed trackers in recent evaluations. We run\nthe ADOBING-enhanced trackers with their base trackers on two popular\nbenchmarks, the CVPR2013 benchmark (50 sequences) and the Princeton Tracking\nBenchmark (100 sequences). On both benchmarks, our methods not only\nconsistently improve the base trackers, but also achieve the best known\nperformances. Noting that the way we integrate objectness in visual tracking is\ngeneric and straightforward, we expect even more improvement by using\ntracker-specific objectness."
}