# Tracking Anything in High Quality

Jiawen Zhu, Zhenyu Chen, Zeqi Hao, Shijie Chang, Lu Zhang, Dong Wang, Huchuan Lu, Bin Luo, Jun-Yan He, Jin-Peng Lan, Hanyuan Chen, Chenyang Li

## 🧩 Problem to Solve

시각 객체 추적(Visual Object Tracking, VOT)은 컴퓨터 비전의 근본적인 비디오 작업입니다. 특히 VOTS2023 챌린지와 같이 단기/장기, 단일/다중 객체 추적 및 마스크 기반 세분화가 통합된 일반 객체 추적은 다음과 같은 복잡한 문제를 야기합니다:

* **긴 시퀀스 처리:** 10,000프레임을 초과하는 긴 비디오 시퀀스에서 객체의 급격한 외형 변화와 환경 변화에 적응해야 하며, 메모리 기반 방법의 메모리 사용량 문제가 발생합니다.
* **객체의 출현 및 재출현:** 추적 대상이 시야를 벗어났다가 다시 나타나는 경우를 처리해야 합니다.
* **다양한 도전 과제:** 빠른 움직임, 빈번한 가려짐, 방해물, 작은 객체 등이 추적 정확도를 저해합니다.
* 기존 비디오 객체 세분화(VOS) 방법들은 이러한 VOTS2023의 특정 과제들을 해결하는 데 한계가 있습니다. 특히, SAM(Segment Anything Model)과 같은 대규모 세분화 모델은 복잡한 구조의 객체에서 예측 마스크의 품질이 떨어지는 경향이 있습니다.

## ✨ Key Contributions

* 고품질 비디오 내 객체 추적을 위한 **HQTrack 프레임워크**를 제안합니다.
* HQTrack은 **비디오 다중 객체 세분화기(VMOS)**와 **마스크 개선기(MR)**로 구성됩니다.
* VMOS는 기존 DeAOT를 개선하여 **1/8 스케일 GPM(Gated Propagation Module)을 계단식으로 연결**하여 작은 객체 인식 능력을 향상시키고, **Intern-T를 특징 추출기**로 사용하여 객체 식별 능력을 강화했습니다.
* MR은 사전 학습된 **HQ-SAM 모델**을 활용하여 VMOS의 추적 마스크를 개선하며, VMOS의 예측 마스크 외곽 상자를 프롬프트로 사용합니다.
* VMOS와 MR의 결과 마스크 간의 IoU(Intersection over Union) 점수를 기반으로 최종 마스크를 선택하는 **선택적 마스크 개선 메커니즘**을 도입하여 품질 저하를 방지합니다.
* 테스트 시 데이터 증강이나 모델 앙상블과 같은 기교 없이 VOTS2023 챌린지에서 **2위**를 차지하며 강력한 성능을 입증했습니다.

## 📎 Related Works

* **통합 추적:** 단일/다중 객체 및 박스/마스크 기반 추적의 통합에 대한 최근 연구 동향을 언급하며, SAM과 같은 지각 알고리즘의 발전을 배경으로 합니다.
* **VOT 챌린지:** VOT 및 VOTS2023 챌린지의 중요성을 강조하고, VOTS2023의 완화된 제약 조건(일반 객체 추적, 세분화 기반 위치 특정)에 따른 새로운 도전을 설명합니다.
* **딥러닝 기반 추적:**
  * **온라인 업데이트 추적기:** [3, 9]와 같은 이전 방법.
  * **샴 네트워크(Siamese Trackers):** [2, 31]와 같은 초기 발전.
  * **트랜스포머 기반 추적기:** [5, 8, 35, 39]와 같이 최근 컴퓨터 비전 분야를 휩쓴 트랜스포머 아키텍처를 활용한 SOTA 추적기들.
* **비디오 객체 세분화(VOS):**
  * 초기 방법: 모션 단서 [6, 28] 또는 온라인 학습 [4, 20]을 통한 마스크 전파.
  * 최근 방법: 공간-시간 메모리(STM) 네트워크 [24, 32]를 통한 외형 변화 및 가려짐 처리.
  * 다중 객체 세분화: AOT [37], DeAOT [38].

## 🛠️ Methodology

HQTrack은 비디오 다중 객체 세분화기(VMOS)와 마스크 개선기(MR)의 두 가지 주요 구성 요소로 이루어져 있습니다.

### 2.1. Pipeline

HQTrack의 파이프라인은 다음과 같습니다:

1. **초기 프레임 참조:** 비디오와 첫 번째 프레임의 객체 마스크 주석을 입력으로 받습니다.
2. **VMOS 처리:** VMOS는 첫 번째 프레임의 마스크를 시간 차원을 따라 현재 프레임으로 전파하여 대상 객체를 세분화합니다. 이 과정에서 외형/식별 정보와 장/단기 메모리 모델링을 활용합니다.
3. **바운딩 박스 추출:** VMOS가 예측한 대상 마스크에서 바운딩 박스를 추출합니다.
4. **MR(HQ-SAM) 개선:** 추출된 바운딩 박스를 프롬프트로 사용하여 HQ-SAM 모델에 입력하고, 원본 이미지와 함께 개선된 마스크를 얻습니다.
5. **마스크 선택:** 최종 결과를 VMOS와 MR의 마스크 중 하나로 선택하기 위한 마스크 선택기를 사용합니다.

### 2.2. Video Multi-object Segmenter (VMOS)

VMOS는 DeAOT [38]의 변형으로, 다음 개선 사항을 포함합니다:

* **멀티스케일 전파:** 특히 작은 객체를 인식하기 위해 8배 스케일의 GPM을 계단식으로 연결하고, 전파 과정을 여러 스케일(최대 4배 스케일)로 확장합니다. 기존 DeAOT는 16배 스케일에서만 전파를 수행하여 미세한 객체 단서가 손실될 수 있었습니다.
* **강력한 특징 추출기:** InternImage-T [33]를 인코더로 사용하여 객체 식별 능력을 향상시킵니다.
* **메모리 관리:** 긴 비디오 시퀀스 처리를 위해 고정된 길이(8개)의 장기 메모리를 사용하며, 초기 프레임을 제외한 이전 메모리는 폐기하여 메모리 사용량을 절약합니다.
* **학습:**
    1. **1단계 (사전 학습):** 정적 이미지 데이터셋 [7, 11, 12, 22, 27]에서 생성된 합성 비디오 시퀀스로 VMOS를 사전 학습합니다.
    2. **2단계 (미세 조정):** DAVIS [25], YoutubeVOS [34], VIPSeg [23], BURST [1], MOTS [30], OVIS [26]와 같은 다중 객체 세분화 데이터셋을 사용하여 학습합니다. 특히 OVIS는 가려진 객체 처리의 견고성을 높이는 데 사용됩니다.

### 2.3. Mask Refiner (MR)

MR은 사전 학습된 HQ-SAM [14] 모델입니다:

* **HQ-SAM 사용:** VMOS에서 예측된 마스크의 외곽 상자를 박스 프롬프트로 계산하고, 이를 원본 이미지와 함께 HQ-SAM (ViT-H 백본 사용)에 입력하여 개선된 마스크를 얻습니다.
* **선택적 개선:** VMOS 모델이 학습된 데이터셋의 한계로 인해 복잡한 시나리오에서 마스크 품질이 불충분할 수 있으므로, HQ-SAM과 같은 대규모 학습된 세분화 알고리즘을 사용하여 초기 세분화 결과를 개선합니다.
* **마스크 선택 메커니즘:** VMOS의 마스크와 HQ-SAM이 개선한 마스크 간의 IoU 점수를 계산합니다. IoU 점수가 임계값 $\tau$ (실험을 통해 $0.1$로 설정)보다 높으면 HQ-SAM의 개선된 마스크를 최종 출력으로 선택하고, 그렇지 않으면 VMOS의 마스크를 사용합니다. 이는 HQ-SAM이 다른 객체를 재예측하는 것을 방지하고 현재 객체 마스크를 개선하는 데 집중하도록 합니다.

## 📊 Results

* **VOTS2023 검증 세트 (Ablation Study):**
  * **개별 추적 vs. 공동 추적:** 다중 객체에 대해 개별 트래커를 초기화하는 것보다 모든 대상 객체를 단일 트래커로 공동 추적하는 것이 더 나은 성능(AUC 0.566 vs. 0.552)을 보였습니다. 이는 공동 추적이 대상 객체 간의 관계를 더 잘 이해하게 하여 방해 요소 간섭에 대한 견고성을 높이는 것으로 분석됩니다.
  * **VMOS 구성 요소 분석:**
    * 기본 DeAOT (AUC 0.576) 대비 InternImage-T 백본 사용 시 AUC 0.611로 향상되었습니다.
    * 여기에 멀티스케일 전파 메커니즘을 추가한 완전한 VMOS는 AUC 0.650으로 크게 향상되었습니다 (3.9%p 증가).
  * **장기 메모리 간격($G$)**: $G=50$일 때 가장 좋은 성능을 보였습니다 (AUC 0.669).
  * **마스크 개선기(MR) 분석:** 모든 마스크를 SAM으로 직접 개선하는 것은 때때로 저품질 마스크의 성능을 저해할 수 있습니다. VMOS와 SAM 마스크 간의 IoU 임계값 $\tau$를 사용하여 선택적으로 개선하는 전략이 효과적이며, $\tau=0.1$일 때 가장 유망한 결과(AUC 0.708)를 얻었습니다.
* **VOTS2023 테스트 세트 (최종 결과):**
  * VMOS (ResNet50 백본)의 AUC는 0.564입니다.
  * VMOS (InternImage-T 백본)는 AUC 0.596으로 3.2%p 향상됩니다.
  * VMOS에 SAM$_{H}$를 추가하여 마스크를 개선하면 AUC 0.610으로 1.4%p 더 향상됩니다.
  * HQTrack (VMOS + HQ-SAM$_{H}$ 및 선택 메커니즘)은 AUC 0.615를 달성하여 최종적으로 VMOS + SAM$_{H}$ 대비 0.9%p 향상된 성능을 보였습니다.
* **챌린지 순위:** VOTS2023 챌린지에서 종합 2위를 기록했습니다.
* **정성적 결과:** HQTrack은 장기 객체 추적, 다중 객체 동시 추적, 많은 방해물 존재 시의 정확한 객체 포착, 외형 변화, 빠른 움직임 및 스케일 변화 등 도전적인 시나리오에서 강력한 추적 능력을 보여주었습니다.

## 🧠 Insights & Discussion

* **공동 추적의 이점:** 여러 객체를 개별적으로 추적하는 대신, 단일 트래커로 공동 추적하는 방식은 객체 간의 관계를 더 잘 이해하고 방해 요소에 대한 견고성을 높이는 데 도움이 됩니다.
* **강력한 백본 및 멀티스케일 전파의 효과:** InternImage-T와 같은 최신 대규모 CNN 기반 모델을 특징 추출기로 사용하고, 작은 객체 인식을 위한 멀티스케일 전파를 도입함으로써 VMOS의 성능이 크게 향상되었습니다. 이는 세분화된 세부 정보가 중요한 추적-세분화 작업에서 특히 중요합니다.
* **대규모 사전 학습 모델의 현명한 활용:** HQ-SAM과 같은 대규모 세분화 모델은 마스크 품질 개선에 큰 잠재력을 가지고 있지만, 이를 맹목적으로 적용하는 것은 오히려 성능 저하를 초래할 수 있습니다. 제안된 IoU 기반 마스크 선택 메커니즘은 이러한 모델의 장점을 활용하면서도 예측 오류를 걸러내는 데 필수적입니다. 즉, 개선이 필요한 경우에만 적용하고, 그렇지 않은 경우에는 기존 마스크를 유지하는 전략이 효과적입니다.
* **실용성과 경쟁력:** HQTrack은 복잡한 VOTS2023 챌린지에서 특별한 테스트 시간 증강이나 모델 앙상블 없이도 2위를 달성하며, 실제 시나리오에서의 강력한 성능과 견고성을 입증했습니다. 이는 제안된 프레임워크의 설계가 매우 효과적임을 시사합니다.

## 📌 TL;DR

**문제:** VOTS2023 챌린지에서 요구하는 고품질의 다중 객체, 장기 비디오 추적 및 세분화는 긴 시퀀스, 객체의 출현/재출현, 빠른 움직임, 가려짐 등 복잡한 시나리오로 인해 어렵습니다.
**방법:** 본 논문은 **HQTrack**이라는 프레임워크를 제안합니다. 이는 **VMOS(Video Multi-object Segmenter)**와 **MR(Mask Refiner)**로 구성됩니다. VMOS는 InternImage-T 백본과 멀티스케일 전파 메커니즘을 포함한 개선된 DeAOT로, 비디오 프레임 내 다중 객체를 견고하게 추적합니다. MR은 HQ-SAM을 활용하여 VMOS의 초기 마스크를 고품질로 개선하며, VMOS 마스크와 개선된 마스크 간의 IoU 기반 선택 전략을 사용하여 품질 저하를 방지합니다.
**주요 결과:** HQTrack은 VOTS2023 챌린지에서 2위를 차지하며, 복잡한 비디오 환경에서 강력하고 정확한 "무엇이든 추적" (tracking anything) 및 세분화 능력을 성공적으로 입증했습니다.
