# Multi-scale MPU-Net 기반 3D 의료 영상 분할

Zeqiu.Yu, Shuo.Han, Ziheng.Song

## 🧩 Problem to Solve

암 진단 및 치료에서 고정밀 종양 분할은 매우 중요하지만, 3D 볼륨 기관의 불규칙한 입체 구조로 인해 완전 자동화된 표적 장기 분할은 어렵습니다. 기존의 U-Net은 전역 및 지역 특징을 학습하는 데 뛰어나지만, 공간적 장거리 관계 및 다중 스케일 컨텍스트 정보를 포착하는 능력에 한계가 있습니다. 또한, CNN 기반 네트워크는 내재적인 지역성으로 인해 장거리 상관 관계 포착이 제한적이며, Transformer는 2차 시간 복잡도와 내재적 제약으로 인해 긴 시퀀스에 직접 적용하기 어렵습니다. 의료 데이터셋 확보 및 주석의 어려움, 노이즈 및 환자 움직임에 대한 민감성, 학습 중 과적합, 긴 학습 시간, 기울기 소실 문제도 존재합니다.

## ✨ Key Contributions

* U-Net 프레임워크를 기반으로 하는 새로운 3D 의료 영상 모델인 **MPU-Net**을 제안하여 의료 영상의 의미론적 분할 효율성을 향상시켰습니다.
* 부피 의료 영상에서 장거리 의존 정보를 효과적으로 캡처하기 위해 **Position Attention Module (PAM)**을 활용했습니다.
* U-Net의 중첩된 네트워크를 재구성하여 PAM의 자기 주의 특징을 샘플링한 후, **스킵 연결(skip-connection)** 디코더를 사용하여 다양한 고해상도 CNN 특징을 융합하여 예측 분할 출력을 생성했습니다.
* FCNN의 주요 구조인 빠른 컨볼루션 레이어를 **Hierarchical Convolutional Neural Network (HCNN)**로 대체하여 장기 시퀀스 특징 추출 효율을 높였습니다.
* **Tversky 손실과 교차 엔트로피를 결합한 새로운 하이브리드 손실 함수**를 제안하여 모델이 고해상도 특징 정보를 더 잘 활용할 수 있도록 했습니다.
* 각 업샘플링 후에 다중 스케일 블록을 기반으로 한 **교차 주의(cross-attention) 메커니즘**을 도입하고, 다중 스케일 출력을 사용하여 다양한 해상도의 특징 정보 융합을 달성했습니다.
* 공개 데이터셋인 **LiTS 2017(Liver Tumor Segmentation Challenge 2017)**에서 제안된 프레임워크의 효과를 검증했으며, 벤치마크 모델인 U-Net 아키텍처보다 우수한 분할 성능을 입증했습니다.

## 📎 Related Works

이 연구는 주로 다음과 같은 기존 연구들의 한계를 보완하고 강점을 결합하고자 합니다.

* **전통적인 이미지 분할 기법**: 엣지 검출, 영역 기반, 엣지-영역 결합 기법, Chan-Vese 모델, Piecewise Smooth 모델, Local Binary Fitting 모델 등. 이들은 주로 지역 특징에 의존하거나 일반화 능력이 부족합니다.
* **Fully Convolutional Neural Network (FCNN)**: 픽셀 수준 예측을 위한 초기 엔드-투-엔드 학습 모델 [16].
* **R-CNN 계열**: R-CNN [52], Fast R-CNN [53], Faster R-CNN [55], Mask R-CNN [57] 등 객체 탐지에서 발전한 분할 기법.
* **U-Net 아키텍처**: 의료 영상 분할 분야의 벤치마크 모델 [89]. 2D U-Net [89]의 3D 확장인 3D U-Net [60] 및 그 변형들 (UNet++ [17], HyperDense-Net [22], H-DenseUNet [19], NAS-UNet [20], nnU-Net [65], MS-UNet [66])이 다양한 의료 영상 데이터셋에서 뛰어난 성능을 보였습니다.
* **어텐션 메커니즘**: 시스템이 가장 중요한 요소에 집중하도록 하는 개념 [71]. RNN에 성공적으로 적용되었으며 [72], 컴퓨터 비전 분야에도 도입됨 [70, 27]. 특히 **자기 주의(self-attention)** 메커니즘 [28]은 장거리 의존성 문제를 해결하는 데 효과적이며, 다양한 분야에서 활용됨 [67, 68, 69, 74, 75, 76, 77, 78, 79, 80, 81].
* **Transformer**: 어텐션 메커니즘에 전적으로 기반하며 루프와 컨볼루션을 제거한 모델 [28]. NLP 분야에서 큰 성공을 거두었으며, 의료 영상 분할에서도 TransBTS [82], TransUNet [73], UNETR [83], U-Net Transformer [84] 등 변형들이 도입되어 성능 향상을 이끌어냄.
* **Dual Attention Network**: 공간적 차원의 계산 비용을 줄이면서 전역 특징 상호 의존성을 효과적으로 캡처하는 **Position Attention Module (PAM)**을 개발 [92].

## 🛠️ Methodology

MPU-Net은 수축-확장(encoder-decoder) 모델을 기반으로 하며, CNN과 Position Attention Module (PAM)의 조합을 인코더로 사용하여 3D 의료 영상의 공간 및 깊이 정보를 포착합니다.

1. **전반적인 아키텍처 (Overall Architecture of MPU-Net)**:
    * 입력 3D 의료 영상 $x \in R^{H \times W \times L \times C}$를 픽셀 수준 이미지 $H \times W \times D \times C$로 예측합니다.
    * 인코더는 고수준 특징 표현으로 인코딩한 후, 스킵 연결을 사용하여 디코더로 전달되어 공간 해상도를 디코딩합니다.
    * 다중 스케일 예측을 전체 아키텍처에 통합하여 여러 중간 레이어의 특징을 집계하여 더 포괄적인 전역 지식을 얻습니다.
    * HCNN 프레임워크와 다중 스케일 블록을 사용하여 다양한 스케일에서 추출된 특징을 필터링하고 융합합니다.

2. **네트워크 인코더 (Network Encoder)**:
    * **영상 시퀀스화 (Image Sequentialization)**: 3D 의료 영상 $x \in R^{H \times W \times L \times C}$를 고정 크기 패치 $P \times P \times P$로 분할하여 평평하고 균일한 패치 시퀀스 $X = \{x_{i}\} \in R^{N \times (P^3 \cdot C)}$로 변환합니다. 여기서 $N = (H \times W \times L) / P^3$ 입니다. 이는 Transformer의 계산 복잡도를 줄입니다.
    * **지역 특징 정보 임베딩 (Embedding Local Feature Information)**: 벡터화된 패치 $x_i$는 학습 가능한 선형 레이어 (3x3x3 컨볼루션 레이어)를 사용하여 $d$-차원 공간으로 투영되어 채널 크기를 증가시킵니다. 각 패치의 위치 정보를 암호화하기 위해 학습 가능한 1차원 위치 임베딩 $PE = E_{pos} \in R^{N \times d}$를 추가하여 $z_0 = x + PE = W \times X + PE$를 생성합니다.
    * **위치 주의 모듈 (Position Attention Module, PAM)**: Dual Attention [92]에서 영감을 받았으며, 2차 계산 비용을 크게 낮춥니다.
        * 원본 정보 $F \in R^{C \times H \times W \times L}$에서 두 개의 동일한 모양의 텐서 $A$와 $B$를 생성합니다.
        * $A$와 $B$를 4차원 텐서에서 3차원 텐서로 평탄화하여 $(H \times W \times L)$ 차원을 1차원으로 접습니다.
        * 두 위치 점 $i$-th와 $j$-th 사이의 상관 관계 강도 $s_{ij}$는 내적 연산과 소프트맥스 함수를 사용하여 계산됩니다: $s_{ij} = \frac{\exp(A_i \cdot B_j)}{\sum_{k} \exp(A_i \cdot B_k)}$.
        * 원본 특징 맵 $F$에 위치 주의 값을 곱하고 컨볼루션 레이어를 통해 새로운 특징 맵 $C \in R^{C \times H \times W \times L}$를 생성합니다.
        * 최종 주의 특징 맵 $F_{PAM,i} = \lambda \sum_{j} (s_{ij} C_j) + F_i$는 학습 가능한 가중치 $\lambda$를 통해 원본 특징과 결합됩니다.

3. **네트워크 디코더 (Network Decoder)**:
    * **주의 게이트 블록 (Attention Gate Blocks)**: 각 업샘플링 단계에 추가되어 작은 객체에 대한 오탐지 예측을 줄입니다. 입력 특징 맵에 스케일링 계수 $\alpha_{i}^l \in [0,1]$를 곱하여 $x'_{i}^l = x_{i}^l \cdot \alpha_{i}^l$를 생성하고, 게이팅 신호 $g_i$를 적용하여 관련성 높은 정보에 집중하도록 합니다.
    * **HCNN 구조 및 다중 스케일 블록 (HCNN Structure and Multi-scale Block)**: 인코더의 마지막 레이어 출력 $z_K$를 HCNN [88]을 통해 처리하여 4차원 특징 맵으로 재구성합니다. 컨볼루션 블록은 차원을 줄이는 데 사용됩니다. HCNN 모듈은 다중 스케일 블록 내에 구축되며, 다양한 크기의 수용장(receptive field)을 가진 컨볼루션을 통해 특징을 융합합니다.
    * **특징 업샘플링 (Feature Up-sampling)**: 계단식 업샘플러(cascaded upsampler) [73]를 사용하여 숨겨진 특징 시퀀스를 디코딩합니다. 각 모듈은 3x 업샘플링 연산자, 2x2x2 컨볼루션 레이어, PReLU 레이어로 구성됩니다.
    * **다중 스케일 출력 (Multi-scale Output)**: 전역 및 지역 컨텍스트 정보를 더 잘 캡슐화하기 위해 여러 해상도의 특징들을 통합하여 최종 분할 마스크를 생성합니다: $F = fusion([X_0, X_1, X_2, X_3])$.

4. **손실 함수 (Loss Function)**:
    * Tversky 손실 [90]과 클래스 균형 교차 엔트로피 손실 [91]을 결합한 하이브리드 손실 함수를 사용합니다.
    * $Loss(G,P) = 1 - \frac{\sum_{i,j} P_{i,j} G_{i,j} + \epsilon}{\sum_{i,j} P_{i,j} G_{i,j} + \alpha \sum_{i,j} P_{i,j=0} G_{i,j=1} + \beta \sum_{i,j} P_{i,j=1} G_{i,j=0} + \epsilon} - \lambda (\sum_{i,j} G_{i,j} \log(P_{i,j}) + (1-G_{i,j}) \log(1-P_{i,j}))$
    * 여기서 $G$는 그라운드 트루스, $P$는 예측 확률입니다. Tversky 손실은 불균형 데이터에서 작은 병변을 더 잘 감지하기 위해 오탐지 및 오음성 매개변수를 균형 있게 조절하며, 교차 엔트로피는 분류 성능을 측정합니다.

## 📊 Results

* **데이터셋 및 설정**: LiTS 2017 데이터셋을 사용했습니다 (130개의 CT 스캔 중 88개 훈련, 22개 검증, 20개 테스트로 분할). 이미지 크기는 512x512 픽셀이며 256x256으로 다운샘플링되었습니다. 간 종양 분할을 위한 이진 분류 작업입니다. Adam 최적화 도구를 사용했으며, 배치 크기(batch size)는 1로 설정했습니다 (메모리 제약으로 인해). 초기 학습률은 1e-4이며, 100회 반복마다 1/2로 감소시켰습니다. 총 600회 반복, 20시간 학습을 진행했습니다.
* **평가 지표**: Dice 계수, Accuracy(정확도), Precision(정밀도), Specificity(특이도), IOU(Intersection Over Union), MCC(Matthews Correlation Coefficient)를 사용했습니다.
* **주요 결과 요약 (검증 세트 기준, 400-600회 반복 평균)**:
  * **MPU-Net**: Dice 93.49%, Accuracy 98.74%, Precision 97.31%, Specificity 99.74%, IOU 88.30%, MCC 93.08%.
  * **U-Net**: Dice 87.36%, Accuracy 97.89%, Precision 81.77%, Specificity 98.2%, IOU 77.72%, MCC 86.51%.
* **MPU-Net vs. U-Net 비교**:
  * MPU-Net은 Dice (6.13%↑), Precision (15.54%↑), IOU (10.58%↑), MCC (6.57%↑)에서 U-Net보다 훨씬 뛰어난 성능을 보였습니다.
  * Accuracy (0.85%↑)와 Specificity (1.54%↑)에서는 U-Net과 비교적 유사하거나 약간 우수한 성능을 보였습니다.
  * MPU-Net은 U-Net보다 약 10배 많은 파라미터 (2,255만개 vs 232만개)를 가지며, 에포크 당 학습 시간도 약 6배 더 길었습니다 (120초 vs 21초).
  * 두 모델 모두 약 100-200회 반복 후 수렴 경향을 보였으나, MPU-Net이 전반적으로 더 높은 최적 성능을 달성했습니다.
* **정성적 평가**: 시각화 결과, MPU-Net으로 분할된 종양 영역은 전문가 수동 분할 결과와 거의 일치하여 뛰어난 분할 능력을 입증했습니다. 일부 이미지에서 종양 경계가 부드럽지 않은 것은 데이터셋 자체의 압축 특성 때문입니다.

## 🧠 Insights & Discussion

* **일반화 능력**: 제안된 MPU-Net 모델은 3D U-Net에 전역 정보 획득 능력을 크게 향상시켰습니다. 대부분의 지표에서 90% 이상의 최적값을 달성하며, MSD, BTCV 등의 다른 의료 데이터셋(MRI 등)에 대한 확장 가능성을 보여줍니다. 모듈식 설계는 2D 분할 작업에도 적용될 수 있습니다.
* **한계점 및 오류**:
  * **초기 학습 불안정성**: 초기 반복에서 모델이 불안정하며, 파라미터 변화에 민감하고 낮은 간섭 방지 요소를 보입니다. 이는 하이퍼파라미터 부족 또는 어텐션 모듈의 정보 추출 및 중화 실패 때문일 수 있습니다. 다른 최적화 도구(SGD, AdamW)를 고려해볼 필요가 있습니다.
  * **학습률 스케줄**: 현재 학습률 감소 스케줄(100회 반복마다 절반)은 모델이 빠르게 다음 단계로 나아가지 못하게 하여 수렴을 늦출 수 있습니다. 특히 IOU 지표의 수렴 속도가 느린 경향을 보입니다.
  * **높은 계산 복잡성**: 약 2,000만 개에 달하는 파라미터로 인해 고성능 GPU 서버가 필요하며, 이는 초기 단계에서 빠른 수렴을 방해할 수 있습니다.
  * **모델 최적화 부족**: 현재 네트워크 설계는 최적화가 부족하고 모듈 간 통신이 불충분합니다 (예: Bi-LSTM 시도 실패).
  * **PAM 적용 한계**: 인코더의 모든 계층에 위치 주의 모듈을 적용하는 것이 이론적으로 가능하지만, 실험에서 3회 다운샘플링 후 정보 손실 문제로 인해 하나의 PAM 계층만 사용되었습니다.
  * **다중 스케일 출력 융합**: 현재는 단순 가중 평균 방식을 사용하며, Pyramid Pooling Module (PPM)을 시도했으나 충분한 결과를 얻지 못했습니다.
* **향후 연구 방향**:
  * **Informer 아키텍처 통합**: Transformer 모델의 개선된 형태인 Informer 구조(ProbSparse Self-Attention)를 3D 의료 영상 분할 네트워크에 통합하여 장거리 시퀀스 예측 문제를 더욱 효율적으로 해결하고 계산 효율성을 높일 계획입니다.
  * **Bi-LSTM 모듈 추가**: Multi-head ProbSparse Self-attention 모듈 이후에 Bi-LSTM을 추가하여 장기 의존성 문제를 해결하고 정보 포착 능력을 강화할 계획입니다.
  * 모델의 초기 불안정성, 학습률 스케줄, 계산 복잡성 등 현재 한계점을 해결하기 위한 추가 연구를 진행할 것입니다.
  * 간 종양 외 혈관, 뇌종양 등 다른 장기 볼륨 또는 평면 분할 프로젝트에 대한 일반화 능력을 평가할 것입니다.

## 📌 TL;DR

3D 의료 영상에서 종양의 정확한 자동 분할은 불규칙한 구조와 기존 U-Net의 한계로 어려움이 있었습니다. 이 연구는 U-Net 기반의 **Multi-scale MPU-Net**을 제안하여 이를 해결합니다. MPU-Net은 인코더에 **Position Attention Module (PAM)**을 도입하여 장거리 의존성 및 전역 컨텍스트 정보를 포착하며, 디코더에는 **Attention Gate, HCNN, 다중 스케일 블록**을 활용하여 다양한 해상도의 특징을 융합하고 **Tversky 손실과 교차 엔트로피를 결합한 하이브리드 손실 함수**를 사용합니다. LiTS 2017 데이터셋에서 벤치마크 U-Net 대비 Dice, Precision, IOU, MCC 등 주요 평가 지표에서 **월등히 향상된 성능**을 보였지만, 높은 계산 복잡도와 초기 훈련 불안정성 등의 한계가 있습니다. 향후 **Informer 아키텍처** 및 **Bi-LSTM** 통합을 통해 모델 성능을 더욱 개선할 계획입니다.
