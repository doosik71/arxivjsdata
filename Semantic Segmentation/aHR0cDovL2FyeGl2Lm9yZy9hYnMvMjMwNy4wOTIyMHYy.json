{
  "url": "http://arxiv.org/abs/2307.09220v2",
  "title": "A Survey on Open-Vocabulary Detection and Segmentation: Past, Present,\n  and Future",
  "authors": "Chaoyang Zhu, Long Chen",
  "year": 2023,
  "abstract": "As the most fundamental scene understanding tasks, object detection and\nsegmentation have made tremendous progress in deep learning era. Due to the\nexpensive manual labeling cost, the annotated categories in existing datasets\nare often small-scale and pre-defined, i.e., state-of-the-art fully-supervised\ndetectors and segmentors fail to generalize beyond the closed vocabulary. To\nresolve this limitation, in the last few years, the community has witnessed an\nincreasing attention toward Open-Vocabulary Detection (OVD) and Segmentation\n(OVS). By ``open-vocabulary'', we mean that the models can classify objects\nbeyond pre-defined categories. In this survey, we provide a comprehensive\nreview on recent developments of OVD and OVS. A taxonomy is first developed to\norganize different tasks and methodologies. We find that the permission and\nusage of weak supervision signals can well discriminate different\nmethodologies, including: visual-semantic space mapping, novel visual feature\nsynthesis, region-aware training, pseudo-labeling, knowledge distillation, and\ntransfer learning. The proposed taxonomy is universal across different tasks,\ncovering object detection, semantic/instance/panoptic segmentation, 3D and\nvideo understanding. The main design principles, key challenges, development\nroutes, methodology strengths, and weaknesses are thoroughly analyzed. In\naddition, we benchmark each task along with the vital components of each method\nin appendix and updated online at\nhttps://github.com/seanzhuh/awesome-open-vocabulary-detection-and-segmentation.\nFinally, several promising directions are provided and discussed to stimulate\nfuture research."
}