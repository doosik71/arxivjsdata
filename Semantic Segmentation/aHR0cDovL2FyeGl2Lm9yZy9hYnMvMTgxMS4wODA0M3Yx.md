# Recurrent Iterative Gating Networks for Semantic Segmentation
Rezaul Karim, Md Amirul Islam, Neil D. B. Bruce

## 🧩 Problem to Solve
시맨틱 분할(semantic segmentation)은 이미지 이해에 필수적이며, 자율 주행과 같은 다양한 응용 분야에서 중요합니다. 현재 딥러닝 기반 솔루션들은 높은 성능을 보이지만, 점차 모델이 깊고 복잡해지는 경향이 있습니다. 이는 풀링(pooling) 연산으로 인한 공간적 세밀도(spatial granularity) 손실의 위험을 증가시키고, 단일 순방향 전달(feedforward pass) 내에서 모든 픽셀에 대한 조밀한 예측을 수행할 때 관계형 추론(relational reasoning)을 어렵게 만듭니다. 본 연구는 이러한 문제점을 해결하기 위해, 초기 레이어부터 깊은 레이어까지의 정보 해석 과정을 신중하게 유도하여 더 간결하면서도 강력한 네트워크 아키텍처를 제안하고자 합니다. 특히, 생물학적 시각 시스템에서 영감을 받은 게이팅(gating) 및 순환(recurrence) 메커니즘을 통해 모호한 해석을 필터링하고, 의미론적 정보가 공간적 및 특징 공간적으로 효율적으로 전파되도록 하는 방법을 모색합니다.

## ✨ Key Contributions
- **RIGNet(Recurrent Iterative Gating Network) 제안:** 상향식(top-down) 방식으로 신경망 내 정보 흐름을 제어하는 순환 연결(recurrent connections)을 핵심 요소로 하는 새로운 반복적 게이팅 메커니즘을 도입했습니다.
- **공간적 및 특징 공간적 정보 전파 능력:** 반복적인 게이팅 메커니즘을 통해 게이팅이 공간적 범위(spatial extent)와 특징 공간(feature space) 모두에서 확산되어, 강한 식별력을 가진 특징이 덜 식별적인 영역으로도 전파될 수 있음을 보였습니다.
- **기존 네트워크와의 광범위한 호환성 및 성능 향상:** RIGNet 모듈이 ResNet, DeepLabV2와 같은 다양한 기존 네트워크 아키텍처와 폭넓게 호환되며, 그 성능을 크게 향상시킬 수 있음을 입증했습니다.
- **네트워크 깊이 대비 효율성 입증:** RIGNet 모듈이 적용된 얕은 네트워크(예: ResNet-50)가 RIGNet 모듈이 없는 훨씬 깊은 네트워크(예: ResNet-101)보다 더 나은 성능을 달성할 수 있음을 보여, 더 간결한 아키텍처로도 복잡한 문제를 효율적으로 해결할 수 있음을 입증했습니다.
- **조대-정밀(Coarse-to-Fine) 표현 학습:** 네트워크 아키텍처의 복잡성을 증가시키지 않으면서도 의미 있는 조대-정밀 표현을 개발하는 능력을 보여, 공간적 및 의미론적 맥락을 개선하고 상향식 주의(top-down attention)를 촉진합니다.

## 📎 Related Works
- **순방향 신경망(Feed-forward Neural Networks):** AlexNet [19], VGG [34], ResNet [13], GoogleNet [36] 등은 다양한 시각 인식 작업에서 큰 성공을 거두었지만, 내부적으로 순환(recurrence)이나 피드백(feedback) 메커니즘을 사용하지 않습니다. ResNet과 같은 잔차 연결(residual connections)을 가진 네트워크는 깊이로 인한 성능 저하를 해결했습니다.
- **피드백 기반 학습(Feedback-based Learning):** [31, 3, 38, 33, 40, 5, 6]과 같은 이전 연구들은 학습 과정에 피드백을 통합하는 아이디어를 탐구했습니다.
- **순환 신경망(Recurrent Neural Networks, RNN):** LSTM [35]과 같은 RNN이 시맨틱 분할 또는 장면 레이블링 작업에 사용되기도 했습니다 [3, 30, 15].
- **관련 피드백 접근 방식:**
    - **Feedback Networks [40]:** 이미지 분류에서 계층적 분류 학습을 위해 피드백 기반 학습을 제시했습니다.
    - **IEF [21]:** 각 타임스텝의 피드백을 기반으로 초기 예측을 반복적으로 수정하는 피드백 파이프라인을 제안했습니다.
    - **RCNN [31]:** CNN이 입력 이미지와 이전 반복의 레이블 예측을 입력으로 받는 순환 합성곱 신경망을 도입했습니다.
- **본 연구와의 차별점:** 기존의 많은 피드백 접근 방식이 초기 예측을 직접 반복적으로 수정하는 데 초점을 맞추거나, 레이어 단위(layer-wise) 또는 전체 네트워크(whole-network)에 걸쳐 순환을 적용하는 것과 달리, RIGNet은 정보를 네트워크를 통해 역방향으로 전파하여 압축된 표현을 학습하고 최종 예측을 암시적으로 수정합니다. RIGNet은 블록 단위(block-wise) 피드백을 적용하여 더 넓은 유효 수용장(effective field of view)과 추상화를 가능하게 하며, 생물학적 시각 시스템의 상향식 주의를 모방하여 공간 및 특징 공간에서 의미론적 맥락을 개선합니다.

## 🛠️ Methodology
RIGNet은 순환적 반복 게이팅(Recurrent Iterative Gating) 메커니즘을 기반으로 하며, 네트워크 내의 정보 흐름을 상향식으로 제어합니다.

- **RIGNet 기본 구성:**
    - **피드백 루프:** 네트워크의 특정 레이어/블록의 출력($f_{i+1}^{\theta}$)은 게이팅 모듈을 통해 이전 레이어로 피드백됩니다.
    - **정보 결합:** 피드백 신호는 이전 레이어의 표현($f_{i-1}^{\theta}$)과 결합(예: 요소별 곱셈)되어 다음 반복의 입력으로 사용됩니다.
    - **최종 출력:** 최종 예측은 마지막 반복에서 생성됩니다. 초기 반복에서는 게이팅이 없으며, 이후 반복에서는 이전 예측이 피드백 게이트에 의해 조절됩니다.

- **반복적 게이팅 메커니즘($u_i$):**
    - 게이팅은 레이어 단위가 아닌 **블록 단위(block-wise)**로 적용되어, 파라미터 오버헤드를 줄이고 더 풍부한 추상화된 의미 정보를 활용합니다.
    - $u_i$ (unroll iteration) 매개변수는 피드백 루프가 반복되는 횟수를 결정하며, $u_i=1$일 경우 RIGNet은 순수 순방향 신경망과 동일하게 동작합니다.

- **언롤(Unroll) 메커니즘:**
    - **순차 언롤(Sequential Unroll, S$_u$):** 각 블록 내에서 반복이 완료된 후 다음 블록으로 활성화가 전달됩니다. 이는 네트워크의 유효 깊이($l_e$)를 곱셈적으로 증가시킵니다: $l_e = l_f + l_r \times u_i$.
    - **병렬 언롤(Parallel Unroll, P$_u$):** 첫 번째 반복의 최종 표현을 모은 후, 깊은 레이어에서 얕은 레이어로 피드백이 진행됩니다. 순차 언롤보다 유효 깊이 증가 폭이 작습니다: $l_e = l_f + l_{rj} + l_{rk} \times u_i$. 각 반복 끝에 조대(coarse) 예측을 생성하는 이점을 가집니다.
    - **다중 범위 피드백을 포함한 병렬 언롤(Parallel Unroll with Multi Range Feedback, P$_{fu}$):** 기본 병렬 언롤에 더해 마지막 블록의 출력으로부터 장거리 피드백($f_i^c$)도 통합하여 생물학적 시각 시스템의 특징을 더욱 모방합니다.

- **반복적 게이팅 모듈 공식화 (기본 피드백 게이트):**
    - 각 피드백 게이트는 다음 단계의 특징 맵 $f_{i+1}^{\theta}$를 입력으로 받습니다.
    - **연산 순서:**
        1. 평균 풀링($A_p$)을 적용하여 $f'_{i+1}{\theta}$를 얻습니다.
        2. $3 \times 3$ 합성곱($C_{3 \times 3}$)을 적용하여 $f'_{i+1}{^b}$를 생성합니다.
        3. 시그모이드($\sigma$) 활성화 함수를 적용하고 선형 업샘플링($\xi$)을 통해 입력과 동일한 공간 해상도의 특징 맵 $f'_{i+1}{^b}$를 만듭니다.
        4. 최종적으로 $f'_{i+1}{^b}$와 이전 레이어의 특징 맵 $f_{i-1}^{\theta}$를 요소별 곱셈($\otimes$)하여 변조된 특징 맵 $f_i^r$을 얻습니다.
    - $$f'_{i+1}{^b} = \sigma(C_{3 \times 3}(A_p(f_{i+1}^{\theta}); \Theta))$$
    - $$f_i^r = f'_{i+1}{^b} \otimes f_{i-1}^{\theta}$$
    - 다중 범위 피드백 게이트는 마지막 블록의 출력을 추가적인 피드백으로 활용하여 더 풍부한 맥락 정보를 제공합니다.

## 📊 Results
RIGNet의 성능은 PASCAL VOC 2012 (시맨틱 분할) 및 COCO-Stuff (장면 파싱) 데이터셋에서 평가되었으며, mIoU, pAcc, mAcc 지표를 사용했습니다.

- **RIGNet 분석 결과:**
    - **게이팅 모듈 적용 단계:** 반복적 게이팅 모듈을 네트워크에 점진적으로 추가할수록 성능이 일관되게 향상되었습니다 (표 2). 특히 다중 범위 피드백을 포함한 병렬 언롤(P$_{fu}$) 방식이 가장 좋은 성능을 보였습니다.
    - **반복 횟수($u_i$):** 반복 횟수를 늘릴수록(2회, 4회, 6회) 전체 성능이 점진적으로 향상됨을 확인했습니다 (표 3). 놀랍게도, ResNet50-RIGNet이 $u_i=3$에서 더 깊은 ResNet101-FCN보다 우수한 성능을 달성하여, 반복 횟수 증가의 강력한 효과를 입증했습니다.
    - **피드백 게이트 설계:** 게이팅 모듈에서 곱셈($\otimes$)과 시그모이드($\sigma$) 활성화 함수의 조합이 가장 좋은 성능을 보였습니다 (표 4). 풀링 방식에서는 평균 풀링(Average Pool)이 더 깊은 네트워크(ResNet101-RIGNet)에서 우수한 결과를 나타냈습니다 (표 5).
    - **피드백 범위:** 블록 단위(block-wide) 게이팅 피드백 메커니즘이 네트워크 전체(network-wide) 순환 방식보다 훨씬 우수한 성능을 보였습니다 (표 6).

- **주요 데이터셋 성능:**
    - **PASCAL VOC 2012 (표 7):**
        - ResNet50-RIGNet($P_u$ 6..4, $u_i=6$)은 68.9%의 mIoU를 달성하여 기본 ResNet50-FCN(59.4%)을 크게 능가했습니다.
        - 특히, ResNet50-RIGNet(68.9%)은 더 깊은 ResNet101-FCN(65.3%)보다 높은 성능을 보였습니다.
        - DeepLabV2-RIGNet($P_u$ 6..4, $u_i=2$)은 75.9%의 mIoU로 DeepLabV2(74.9%)보다 우수했습니다.
        - 정성적 결과(그림 6)에서도 RIGNet이 기준 모델보다 더 정확한 분할 맵을 생성하며, 누락된 공간 세부 정보를 효과적으로 복구함을 보여주었습니다.
    - **COCO-Stuff (표 8):**
        - ResNet50-RIGNet($P_u$ 6..4, $u_i=6$)은 28.8%의 mIoU로 ResNet50-FCN(24.3%)보다 우수했습니다.
        - DeepLabV2-RIGNet($P_u$ 6..1, $u_i=2$)은 35.0%의 mIoU로 DeepLabV2(34.1%)보다 우수했습니다.
        - 복잡한 장면 파싱 태스크에서도 RIGNet의 일관된 성능 향상을 확인했습니다.

## 🧠 Insights & Discussion
- **간결한 네트워크의 효율성 입증:** RIGNet은 ResNet50-RIGNet이 ResNet101-FCN을 능가하는 결과로, 간결한 네트워크도 적절한 게이팅 구조를 통해 더 깊은 아키텍처보다 뛰어난 성능을 발휘할 수 있음을 명확하게 증명했습니다. 이는 네트워크의 효율성과 자원 활용 측면에서 중요한 함의를 가집니다.
- **정확도 및 의미론적 정교함 향상:** 정성적 결과(그림 6, 7)를 통해 RIGNet이 기준 모델보다 더 정밀하고 의미론적으로 풍부한 분할 결과를 생성함을 보여주었습니다. 이는 반복적 게이팅 메커니즘이 누락된 공간 세부 정보를 복구하고, 조대-정밀(coarse-to-fine) 정제를 가능하게 하기 때문입니다.
- **모델 표현력 강화:** 반복적 게이팅 블록의 깊이(RIG 블록)가 증가함에 따라 성능이 향상되는 것은 RIGNet이 상향식(top-down) 방식으로 의미론적 및 관계형 맥락을 통합하여 모델의 표현력을 향상시킴을 시사합니다.
- **일반성과 미래 연구 방향:** RIGNet은 사실상 모든 순방향 신경망에 적용 가능한 일반적인 메커니즘으로, 성능을 높이거나 더 간단한 네트워크를 사용할 수 있도록 합니다. 이는 단일 순방향 전달에서 발생하는 오류를 수정하는 강력한 능력을 보여주며, 향후 상향식 처리, 게이팅, 반복에 초점을 맞춘 피드백 기반 접근 방식 연구에 중요한 방향을 제시할 것으로 기대됩니다.

## 📌 TL;DR
- **문제:** 시맨틱 분할에서 깊은 신경망이 공간적 세밀도 손실 및 복잡성 문제를 야기합니다.
- **방법:** RIGNet(Recurrent Iterative Gating Network)은 네트워크 내에서 상위 레이어의 정보를 하위 레이어로 피드백하는 반복적 게이팅 메커니즘을 제안합니다. 이는 블록 단위 피드백을 통해 정보 흐름을 상향식(top-down)으로 제어하며, 공간 및 특징 공간에서 정보 전파 및 정제를 가능하게 합니다.
- **결과:** RIGNet은 PASCAL VOC 2012 및 COCO-Stuff 데이터셋에서 기준 모델을 크게 능가하는 성능을 보였습니다. 특히, RIGNet이 적용된 ResNet-50은 RIGNet이 없는 ResNet-101보다 더 나은 성능을 달성하여, 네트워크 구조의 복잡성을 증가시키지 않고도 높은 성능을 얻을 수 있는 일반적이고 효율적인 방법을 제시합니다. 이는 조대-정밀(coarse-to-fine) 표현을 개발하고 단일 순방향 전달의 오류를 수정하는 데 효과적입니다.