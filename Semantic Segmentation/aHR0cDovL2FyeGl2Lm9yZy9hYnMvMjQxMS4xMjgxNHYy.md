# Interactive Medical Image Segmentation: A Benchmark Dataset and Baseline

Junlong Cheng, Bin Fu, Jin Ye, Guoan Wang, Tianbin Li, Haoyu Wang, Ruoyu Li, He Yao, Junren Chen, JingWen Li, Yanzhou Su, Min Zhu, Junjun He

## 🧩 Problem to Solve

기존의 대규모, 다양하며, 고밀도로 주석이 달린 의료 영상 데이터셋의 부족은 대화형 의료 영상 분할(IMIS) 모델의 일반화 능력과 다양한 모델 간의 일관된 성능 평가를 제약해왔습니다. Segment Anything Model(SAM)과 같은 자연 영상 기반 모델은 의료 영상 도메인 특성 및 밀도 높은 주석의 부재로 인해 직접 적용하기 어렵다는 한계가 있습니다.

## ✨ Key Contributions

- **IMed-361M 벤치마크 데이터셋 도입**: 14가지 모달리티와 204가지 분할 대상을 포함하는 640만 개 이상의 의료 영상과 총 3억 6천 1백만 개의 마스크(평균 이미지당 56개 마스크)로 구성된, 규모, 다양성, 밀도 면에서 전례 없는 데이터셋을 구축했습니다.
- **자동화된 고밀도 대화형 마스크 생성**: 비전 파운데이션 모델의 객체 인식 능력을 활용하여 각 영상에 대해 밀도 높은 대화형 마스크를 자동으로 생성하고, 엄격한 품질 관리 및 세분성 관리를 통해 품질을 보증했습니다.
- **IMIS-Net 베이스라인 모델 개발**: 클릭, 바운딩 박스, 텍스트 프롬프트 및 이들의 조합을 포함한 대화형 입력을 통해 고품질 마스크 생성을 지원하는 IMIS 베이스라인 네트워크를 개발했습니다.
- **종합적인 성능 평가**: 기존 대화형 분할 모델들과 비교하여 탁월한 정확도와 확장성을 입증했습니다.
- **연구 활성화 기여**: 의료 컴퓨터 비전 분야의 파운데이션 모델 연구를 촉진하기 위해 IMed-361M 데이터셋과 모델을 공개했습니다.

## 📎 Related Works

- **데이터셋 관련**: 기존 의료 영상 데이터셋은 주로 단일 장기 또는 단일 병변에 초점을 맞추거나, 멀티태스크 요구사항에 따라 다중 장기/조직 주석 데이터셋으로 확장되었습니다. 최근에는 다양한 출처의 데이터를 통합하여 대규모 멀티모달 데이터셋(예: MedSAM, SAM-Med2D, Huang et al.)이 구축되었지만, SA-1B 데이터셋(평균 이미지당 100개 마스크)과 비교할 때 마스크의 양과 밀도(예: COSMOS, SA-Med2D-20M은 평균 이미지당 5개 미만 마스크)가 여전히 부족하여 밀집 분할 및 미세한 상호작용 지원에 한계가 있었습니다.
- **알고리즘 관련**: 대화형 분할(IMIS) 방법은 자동화된 방법보다 임상적 요구사항에 부합하는 고품질 결과를 생성하는 데 더 효과적입니다. 사용자 상호작용은 스크리블, 바운딩 박스, 클릭, 언어 프롬프트 등 다양한 형태로 나타납니다. 딥러닝 시대에는 사용자 프롬프트를 네트워크 입력 특징으로 직접 사용하는 방식이 탐구되었으며, SAM은 IMIS의 벤치마크 모델이 되었습니다. 하지만 기존 SAM 기반 접근 방식들은 제한된 상호작용 전략을 고려하고 평가의 일관성이 부족하다는 문제가 있었습니다.

## 🛠️ Methodology

IMIS-Net은 SAM을 파인튜닝하는 전략과 유사하게 이미지 인코더, 프롬프트 인코더, 마스크 디코더의 세 가지 핵심 구성 요소를 가집니다.

1. **데이터 수집 및 전처리**: 110개 이상의 공개 및 비공개 의료 영상 분할 데이터셋을 통합하여 640만 개의 이미지와 8천 7백 6십만 개의 수동 주석된 GT 마스크를 수집했습니다. 데이터는 SA-Med2D-20M 프로토콜에 따라 표준화되었으며, 종횡비가 너무 크거나 전경 영역이 작은 이미지와 마스크는 제외되었습니다. 주석의 충돌과 모호성을 해결하기 위해 표현을 표준화하고 수동 검토 및 수정을 거쳤습니다.
2. **대화형 마스크 자동 생성 및 품질 관리**: SAM의 객체 인식 기능을 활용하여 32x32 포인트 그리드를 사용하여 각 이미지에 대해 가능한 많은 마스크를 생성했습니다.
   - **정제 전략**: IoU 예측 신뢰도가 $0.85$ 이상인 마스크만 유지, IoU가 $0.7$ 이상인 중복 마스크에 대해 NMS(Non-Maximum Suppression) 적용, 전체 면적의 $80\%$ 이상을 차지하는 배경 마스크 제거.
   - **품질 관리 및 세분성 관리**: 원본 GT를 활용하여 생성된 마스크의 오류를 수정했습니다. GT에 다중 연결 영역이 있는 경우 생성된 마스크의 해당 영역을 GT로 대체하고, GT 바운딩 박스와 $95\%$ 이상 겹치는 생성된 마스크 영역을 유지하거나 GT 마스크로 대체했습니다. 형태학적 연산(erosion, dilation)을 적용하여 노이즈를 제거하고 작은 구멍을 채웠습니다.
3. **IMIS-Net 모델 설계**:
   - **이미지 인코더**: ViT-base 모델을 사용했으며, 입력 크기는 $1024 \times 1024 \times 3$, 패치 크기는 $16 \times 16 \times 3$입니다.
   - **프롬프트 인코더**: 포인트와 박스는 위치 인코딩과 학습된 임베딩의 합으로 표현되며, 텍스트는 CLIP의 텍스트 인코더를 사용하여 "A segmentation area of a[category]" 템플릿으로 200개 이상의 카테고리를 지원합니다.
   - **마스크 디코더**: 트랜스포머 디코더 블록을 사용하여 이미지 및 프롬프트 임베딩을 마스크로 매핑하며, 마스크 해상도는 전치 컨볼루션(transposed convolutions)을 통해 $256 \times 256$으로 확대된 후 이선형 보간(bilinear interpolation)으로 입력 크기에 맞춰집니다.
4. **훈련 전략**: 모델은 K($K=8$) 단계의 연속적인 대화형 분할을 시뮬레이션하여 훈련됩니다. 초기 상호작용은 GT 및 대화형 마스크를 기반으로 클릭 포인트(전경 영역에서 균일하게 샘플링) 및 바운딩 박스(5픽셀 오프셋)로 시뮬레이션됩니다. 이후 예측 오류 영역과 이전 예측의 저해상도 마스크를 기반으로 후속 수정이 이루어집니다. 이미지 인코더는 한 번만 인코딩하며, 이후 상호작용 훈련은 프롬프트 인코더와 마스크 디코더 파라미터만 업데이트합니다.
5. **훈련 설정**: Adam 옵티마이저($2 \times 10^{-5}$ 학습률), 72개의 NVIDIA 4090 GPU, 배치 크기 2. 각 이미지에서 5개의 타겟을 랜덤으로 선택하여 12 에폭 동안 훈련. Focal Loss와 Dice Loss를 $20:1$ 비율로 조합하여 사용했습니다.

## 📊 Results

- **주요 결과**:
  - 단일 상호작용 분할 태스크에서 IMIS-Net은 이미지 및 마스크 레벨 통계 모두에서 다른 시각 파운데이션 모델들을 능가했습니다. 바운딩 박스 상호작용이 클릭 상호작용보다 항상 더 나은 성능을 보였습니다.
  - 상호작용 횟수가 1회에서 9회로 증가함에 따라 모델 성능이 향상되었으며, 모델 간 성능 차이가 줄어들었습니다.
  - 프롬프트 포인트가 중심에 가까울수록 성능 향상이 더 컸고, 바운딩 박스 오프셋 시 모든 방법에서 성능이 $0.85\%-3.94\%$ 하락했으나, IMIS-Net의 하락 폭이 가장 작아 실용적인 견고성을 입증했습니다.
- **외부 데이터셋 평가**:
  - SegThor, TotalSegmentator MRI, ISLES 등 세 가지 외부 데이터셋에서 IMIS-Net이 가장 우수한 평균 성능을 달성했습니다.
  - 특히 TotalSegmentator MRI 데이터셋의 12개 주요 복부 장기 중 10개에서 IMIS-Net이 다른 모델을 능가했으며, 허혈성 뇌졸중 병변 분할에 초점을 맞춘 ISLES 데이터셋에서는 2위 모델인 SAM-Med2D보다 $3.56\%$ 더 높은 성능을 보였습니다. 이는 IMIS-Net의 강력한 일반화 능력을 입증합니다.
- **어블레이션 연구**:
  - **훈련 데이터 확장**: IMed-361M의 GT만으로 훈련했을 때 IMIS-Net의 성능은 좋지 않았지만, 대화형 마스크를 추가하자 Dice Score가 급격히 증가했습니다. 이는 모델이 훈련 데이터의 규모가 커질수록 더 잘 작동하며, 확장성이 있음을 보여줍니다.
  - **텍스트 및 조합 프롬프트**: 텍스트 프롬프트만 사용했을 때 $76.30\%$의 분할 성능을 달성했으며, 텍스트와 포인트 프롬프트를 결합했을 때 평균 Dice Score가 $11.95\%$ 증가했습니다. 세 번의 클릭 기반 수정 후 Dice Score는 $89.69\%$에 도달하여 다양한 프롬프트의 시너지 효과를 입증했습니다.
  - **모델 설계(디코더 차원 및 이미지 해상도)**: 훈련 이미지 해상도가 증가할수록 모델의 분할 성능이 향상되었습니다. 디코더 차원을 $256$에서 $768$로 늘렸을 때, 훈련 가능한 파라미터가 $24.16$M만 증가했음에도 모델 성능이 $84.97\%$에서 $90.60\%$로 향상되었습니다.

## 🧠 Insights & Discussion

IMed-361M 데이터셋은 대규모, 다양성, 고밀도 마스크를 특징으로 하며 기존 데이터셋의 한계를 극복했습니다. 이를 통해 개발된 IMIS-Net은 클릭, 바운딩 박스, 텍스트 프롬프트 등 다양한 상호작용 방식을 지원하며, 기존 파운데이션 모델 대비 우수한 성능과 강력한 전이성을 보여주었습니다. 특히, 유사한 성능을 달성하기 위해 더 적은 상호작용이 필요하다는 점은 실제 임상 환경에서의 실용성을 높입니다. 이러한 성과는 의료 영상 분야에서 파운데이션 모델 개발을 가속화하고 공정한 모델 평가의 기반을 마련할 것입니다. 하지만 대화형 마스크에 대한 의미론적 정보를 효과적으로 얻는 방법과 이를 보다 포괄적이고 미세한 의료 영상 분석 시나리오로 확장하는 것은 향후 연구가 필요한 과제입니다.

## 📌 TL;DR

의료 영상 분할은 대규모, 고품질 데이터셋 부족으로 한계가 있었습니다. 본 연구는 14가지 모달리티, 204가지 대상, 3억 6천 1백만 개 마스크를 포함하는 최대 규모의 **IMed-361M 데이터셋**을 구축했습니다. SAM 기반 자동 생성 및 GT 보정으로 고밀도 대화형 마스크를 확보하고, 이를 기반으로 **IMIS-Net 베이스라인 모델**을 개발했습니다. IMIS-Net은 클릭, 바운딩 박스, 텍스트 프롬프트 등 다양한 상호작용을 지원하며, 기존 모델 대비 우수한 성능과 강력한 일반화 능력을 입증했습니다. 이 데이터셋과 모델은 의료 AI 연구 및 임상 적용을 가속화할 것입니다.
