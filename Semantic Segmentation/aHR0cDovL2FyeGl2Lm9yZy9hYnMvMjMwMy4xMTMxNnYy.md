# Generative Semantic Segmentation

Jiaqi Chen, Jiachen Lu, Xiatian Zhu, Li Zhang

## 🧩 Problem to Solve

기존의 의미론적 분할(semantic segmentation) 방법들은 주로 이미지의 각 픽셀에 레이블을 할당하는 판별 학습(discriminative learning) 패러다임을 따릅니다. 이는 $p(c|x)$와 같은 조건부 확률의 로그-우도를 최적화하는 픽셀별 분류에 기반합니다. 이러한 방식은 픽셀의 관측치에 조건화되어 있으며, 특정 태스크에 특화되어 대규모 생성 모델의 풍부한 지식을 충분히 활용하기 어렵다는 한계가 있습니다. 본 논문은 이러한 한계를 해결하고, 의미론적 분할을 더욱 태스크에 구애받지 않으며 기성 생성 모델을 활용할 수 있는 **이미지 조건부 마스크 생성 문제**로 재구성하는 새로운 접근 방식을 제안합니다.

## ✨ Key Contributions

* 의미론적 분할을 이미지 조건부 마스크 생성 문제로 재구성하는 **생성적 의미론적 분할(Generative Semantic Segmentation, GSS) 접근 방식**을 제안합니다. 이는 기존의 판별 학습 기반 패러다임과는 개념적으로 다릅니다.
* 기존의 조건부 이미지 생성 프레임워크 내에서 GSS 모델을 구현하여, 태스크 특정 아키텍처 및 손실 함수의 **최소한의 수정으로 기성 생성 모델의 지식을 최대한 활용**할 수 있도록 합니다.
* 다양한 의미론적 분할 벤치마크에 대한 광범위한 실험을 통해 GSS가 표준 설정에서 기존 모델과 **경쟁적인 성능**을 보이며, 더 도전적인 교차 도메인 설정에서는 **새로운 최첨단 성능**을 달성함을 입증합니다.

## 📎 Related Works

* **의미론적 분할 (Semantic Segmentation):** FCN [32] 이후 PSPNet [57], DeepLabV2 [3], Nonlocal [49], CCNet [21], SETR [58], Segformer [52], MaskFormer [9], Mask2Former [8] 등 다양한 딥러닝 모델이 발전해왔습니다. 이들 대부분은 픽셀 단위 분류를 위한 판별 학습 패러다임을 따릅니다.
* **이미지 생성 (Image Generation):** VAE [24], GAN [19]과 같은 생성 모델들은 데이터 표현 학습(1단계)과 인코딩 확률 모델 구축(2단계)의 두 단계 훈련 과정을 따릅니다. 특히 VQVAE [45]는 이산 공간 이미지 표현 학습을 통해 언어-이미지 교차 모델 생성에 기여했습니다. Esser et al. [15]은 데이터 표현 학습의 중요성을 보여주었습니다.
* **시각 인식을 위한 생성 모델 (Generative Models for Visual Perception):** 이미지-이미지 변환 [22]과 같은 초기 시도들이 있었으나 성공률이 낮았습니다. GMMSeg [29]는 생성적 분할을 주장하지만 대부분 판별적 모델링에 가깝습니다. Pix2Seq [7], Unified-I/O [33] 등 시퀀스-투-시퀀스 접근법이 부상했으며, Pix2Seq-D [6]와 UViM [25]은 생성적 팬옵틱 분할을 시도했으나 반복적 디노이징이나 처음부터 모델을 훈련해야 하는 등 계산 효율성이 낮은 문제가 있었습니다. 본 논문은 'maskige' 개념을 도입하여 기성 데이터 표현 모델을 활용하여 효율성을 높입니다.

## 🛠️ Methodology

본 논문은 의미론적 분할을 이미지 조건부 마스크 생성 문제로 재정의하는 Generative Semantic Segmentation (GSS)를 제안합니다. 이는 기존의 픽셀별 판별 학습 방식과는 다른 개념입니다. GSS는 증거 하한(Evidence Lower Bound, ELBO) [24]을 최적화하며, 그 식은 다음과 같습니다:
$$E_{q_{\phi}(z|c)}[\log p_{\theta}(c|z)] - D_{KL}(q_{\phi}(z|c), p_{\psi}(z|x))$$
여기서 $x \in \mathbb{R}^{H \times W \times 3}$는 입력 이미지, $c \in \{0,1\}^{H \times W \times K}$는 $K$개 클래스의 분할 마스크입니다.

* $p_{\psi}$: 입력 이미지 $x$에 조건화된 잠재 토큰 $z$의 사전 분포(prior distribution)를 모델링하는 이미지 인코더 ($I_{\psi}$).
* $q_{\phi}$: 의미론적 분할 마스크 $c$를 이산 잠재 토큰 $z$로 인코딩하는 함수. maskige 인코더 ($E_{\phi}$, 사전 학습된 VQVAE 인코더 [45] 사용)와 선형 투영 $X$를 포함합니다.
* $p_{\theta}$: 이산 잠재 토큰 $z$에서 의미론적 분할 마스크 $c$를 디코딩하는 함수. maskige 디코더 ($D_{\theta}$, 사전 학습된 VQVAE 디코더 [45] 사용)와 $X^{-1}$ (X의 역 과정)을 포함합니다.

GSS 모델은 두 단계로 최적화됩니다:

1. **Stage I: 효율적인 잠재 후속 분포 학습 (Efficient Latent Posterior Learning)**
    * 이 단계는 잠재 변수가 대상 분할 마스크를 시뮬레이션할 수 있도록, 분할 마스크 $c$에 조건화된 잠재 변수 $z$의 후속 분포 $q_{\phi}(z|c)$를 학습하는 것을 목표로 합니다.
    * 핵심 아이디어는 분할 마스크 $c$를 'maskige'라는 특별한 형태의 RGB 이미지 $x^{(c)}$로 표현하는 것입니다. 각 카테고리는 특정 색상으로 표현됩니다.
    * 이러한 변환을 통해, 분할 마스크 재구성 문제를 이미지 재구성 문제로 전환할 수 있으며, 이는 DALL·E [40]와 같은 대규모 데이터셋으로 사전 학습된 기성 VQVAE 모델을 활용할 수 있게 합니다.
    * 최적화는 $\min_{X^{-1}} E_{q_{\hat{\phi}}(\hat{z}|X(c))} \|X^{-1}(\hat{x}^{(c)}) - c\|$를 목표로 하며, 여기서 $\hat{x}^{(c)}$는 재구성된 maskige입니다. $X$와 $X^{-1}$는 경량 변환 모듈로, VQVAE의 파라미터보다 훨씬 적어 효율적입니다.
    * **maskige 설계:** $X$와 $X^{-1}$의 구현 방식에 따라 GSS-FF(훈련 없음), GSS-FT, GSS-TF, GSS-TT (훈련 필요)와 같은 다양한 변형이 있습니다. GSS-FF는 '최대 거리 가정(maximal distance assumption)'을 통해 각 카테고리 색상 간의 거리를 최대화하는 $\beta$를 수동으로 설정하며, $X^{-1}$는 최소 제곱법으로 계산됩니다.
    * 훈련 과정에서 Gumbel-softmax 이완 기법 [35]을 사용하여 $X$ 함수를 엔드-투-엔드로 최적화할 수 있습니다.

2. **Stage II: 잠재 사전 분포 학습 (Latent Prior Learning)**
    * Stage I에서 $E_{\phi}$와 $D_{\theta}$ (VQVAE)의 파라미터가 고정된 상태에서, 이미지 인코더 $I_{\psi}$의 파라미터 $\psi$를 최적화하여 입력 이미지 $x$가 주어졌을 때 잠재 토큰 $z$의 사전 분포 $p_{\psi}(z|x)$를 학습합니다.
    * 목표는 $D_{KL}(q_{\phi}(z|c), p_{\psi}(z|x))$를 최소화하는 것이며, 이는 $z$의 이산 분포 간의 정렬을 측정하기 위해 교차 엔트로피 손실을 사용합니다.
    * **레이블 없는 영역 보조 학습:** 의미론적 분할 데이터셋의 일부는 레이블 없는 영역을 포함할 수 있습니다. 이를 해결하기 위해 보조 헤드 $p_{\xi}(\bar{c}|z)$를 도입하여 레이블 없는 픽셀에 의사 레이블(pseudo label)을 부여하고, 이를 최종 훈련 목표에 포함시켜 성능 저하를 방지합니다.

**생성적 추론 (Generative Inference):**

1. 이미지 인코더 $I_{\psi}$가 예측한 잠재 토큰 $z$를 maskige 디코더 $D_{\theta}$에 입력하여 예측된 maskige $\hat{x}^{(c)}$를 생성합니다.
2. 이 예측된 maskige $\hat{x}^{(c)}$에 역변환 $X^{-1}$를 적용하여 최종 분할 마스크 $\hat{c}$를 얻습니다.

## 📊 Results

* **잠재 후속 분포 학습 (Stage I) 분석:**
  * **GSS-FF** (훈련 없음)는 84.31 mIoU를 달성하며 매우 효율적입니다. 무작위 초기화된 GSS-FF-R(62.83 mIoU)보다 훨씬 우수하여, '최대 거리 가정'을 통한 $\beta$ 초기화의 중요성을 입증합니다.
  * **GSS-FT-W** (비선형 $X^{-1}$를 Shifted Window Transformer로 구현)가 87.73 mIoU로 가장 높은 성능을 보이며, 350 GPU 시간의 추가 훈련 비용이 발생하지만 효율적입니다.
* **VQVAE 설계 분석:**
  * 'maskige' 개념과 DALL·E [40]에서 사전 학습된 VQVAE를 사용하는 방식이 UViM [25] 또는 VQGAN [15] 스타일보다 재구성 성능(87.73 mIoU)과 효율성 면에서 가장 우수합니다. UViM은 maskige 없이 K-채널 분할 마스크를 직접 재구성하여 데이터셋별 훈련이 필요해 비용이 더 많이 듭니다.
* **잠재 사전 분포 학습 (Stage II) 분석:**
  * '레이블 없는 영역 보조(unlabeled area auxiliary)' 학습은 정확도를 3.1% (40.64%에서 43.72%) 향상시켜, 완전한 레이블링의 중요성을 보여줍니다.
  * Multi-Level Aggregation (MLA)은 추가로 2.3% (43.98%에서 46.29%)의 성능 향상을 가져옵니다.
* **단일 도메인 의미론적 분할:**
  * Cityscapes 및 ADE20K 벤치마크에서 기존 판별 모델(Maskformer, SETR 등)과 경쟁적인 성능을 달성합니다. 예를 들어, GSS는 Maskformer와 비슷한 성능을 보이며, GSS-FT-W는 Transformer 기반 SETR과 경쟁합니다.
  * UViM [25]과 비교했을 때, GSS-FF는 훨씬 높은 훈련 효율성에도 불구하고 UViM을 크게 능가합니다 (예: GSS-FT-W의 1단계 훈련은 329.5 GPU 시간, UViM은 1,900 TPU-v3 시간).
* **교차 도메인 의미론적 분할:**
  * MSeg 데이터셋에서 HRNet-W48 및 Swin-Large 백본 모두에서 모든 경쟁 모델(CCSA, MGDA, MSeg)보다 우수한 최첨단 성능을 달성합니다. 이는 생성 학습이 기존 판별 학습보다 더 도메인 일반적인 표현을 학습할 수 있음을 시사합니다.
  * MSeg에서 Cityscapes로 maskige를 전이해도 mIoU가 1%만 감소(80.5에서 79.5)하여 maskige의 도메인 일반성(domain generic) 특성을 입증합니다.
* **정성적 평가:** GSS는 UViM 및 VQGAN에 비해 거의 오류 없는 재구성(Stage I)과 선명하고 정확한 에지 분할(Stage II)을 보여줍니다. 특히, Cityscapes에서 원거리 보행자나 가는 기둥을 정확히 분할하고, ADE20K에서 복잡한 가구의 미세한 에지까지 잘 분할하는 것을 보여줍니다.

## 🧠 Insights & Discussion

* **개념적 전환의 의미:** GSS는 의미론적 분할의 패러다임을 픽셀별 판별 학습에서 이미지 조건부 마스크 생성으로 전환하는 중요한 개념적 변화를 가져옵니다. 이는 대규모 사전 학습된 생성 모델의 강력한 표현력을 활용할 수 있는 새로운 가능성을 열어줍니다.
* **효율성 및 도메인 일반화:** 'maskige' 개념과 효율적인 2단계 최적화 알고리즘 덕분에, GSS는 기존 판별 모델에 준하는 훈련 효율성을 유지하면서도 뛰어난 성능을 달성합니다. 특히, 이 방법은 교차 도메인 시나리오에서 강력한 도메인 일반화 능력을 보여주며, 이는 도메인별 모델 훈련의 부담을 줄이고 시스템 배포 및 관리를 용이하게 하는 실용적인 이점을 제공합니다.
* **한계:**
  * **경계 정밀도:** 생성 모델은 판별 모델보다 결정 경계가 덜 정밀하여, 분할된 객체 에지가 덜 정확할 수 있습니다.
  * **데이터 요구량:** 생성 모델은 전체 샘플 공간의 분포를 학습해야 하므로, 판별 모델보다 더 많은 데이터를 요구하는 경향이 있습니다. MSeg 데이터셋에서 Cityscapes나 ADE20K보다 성능이 더 좋은 것이 이를 간접적으로 시사합니다.
  * **색 공간의 한계:** 모든 카테고리를 색상으로 변환하는 'maskige'는 카테고리 수가 증가할수록 색 공간이 혼잡해져, 특히 객체 에지 근처에서 $X^{-1}$가 가장 가까운 카테고리 색상을 예측하는 데 혼란을 야기할 수 있습니다.
* **향후 연구:**
  * 인스턴스 레벨 분할(instance-level segmentation)로의 확장하여 이미지 내 개별 객체를 더욱 정밀하게 식별하고 분리하는 연구.
  * 분할, 2D 객체 탐지, 깊이 예측, 3D 탐지 등 여러 시각 태스크를 수행할 수 있는 통합 모델 연구.
  * GSS의 2단계 훈련이 잠재 사전 학습에 중점을 두는 점을 활용하여, 새로운 시각 태스크를 잠재 변수의 새로운 후속 분포를 통합함으로써 모델 아키텍처 변경 없이 추가하는 방안 탐색.

## 📌 TL;DR

기존 의미론적 분할의 픽셀별 판별 학습 한계를 극복하기 위해, **Generative Semantic Segmentation (GSS)**는 이 문제를 **이미지 조건부 마스크 생성**으로 재정의합니다. 핵심은 분할 마스크를 RGB 이미지와 유사한 **'maskige'**로 표현하여, 대규모 사전 학습된 VQVAE와 같은 기성 생성 모델을 효율적으로 활용하는 것입니다. GSS는 잠재 후속 분포 학습(maskige 재구성)과 잠재 사전 분포 학습(이미지 인코더 학습)의 **2단계 최적화**를 통해 작동하며, 특히 레이블 없는 영역 처리를 위한 보조 학습을 포함합니다. 결과적으로 GSS는 표준 분할 벤치마크에서 기존 판별 모델과 **경쟁적인 성능**을 보이며, 도전적인 교차 도메인 시나리오에서는 **새로운 최첨단 성능을 달성**하여 생성 학습의 효율성과 도메인 일반화 능력을 입증합니다.
