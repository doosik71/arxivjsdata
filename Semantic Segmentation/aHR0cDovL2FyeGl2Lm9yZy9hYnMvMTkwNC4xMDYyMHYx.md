# Bidirectional Learning for Domain Adaptation of Semantic Segmentation
Yunsheng Li, Lu Yuan, Nuno Vasconcelos

## 🧩 Problem to Solve
픽셀 단위의 레이블을 수동으로 주석(annotation)하는 것은 매우 비용이 많이 들고 시간이 많이 소요됩니다. 따라서 컴퓨터 그래픽으로 생성된 합성 이미지 데이터셋(소스 도메인)을 활용하여 신경망을 훈련하고, 이를 실제 이미지 데이터셋(타겟 도메인)에 적용하는 것이 필요합니다. 하지만 합성 데이터와 실제 데이터 사이의 **도메인 불일치(domain mismatch)**로 인해 모델 성능이 저하되는 문제가 발생합니다. 이 연구는 타겟 도메인에 레이블이 없는 **비지도 도메인 적응(Unsupervised Domain Adaptation)** 상황에서 의미론적 분할(semantic segmentation) 성능을 향상시키는 것을 목표로 합니다.

기존의 도메인 적응 기법들은 제한된 데이터셋에서만 작동하거나, 이미지-투-이미지 변환 모델(예: CycleGAN)의 품질에 지나치게 의존하여 변환 실패 시 후속 단계에서 보완이 어렵다는 한계가 있었습니다.

## ✨ Key Contributions
*   **양방향 학습(Bidirectional Learning) 시스템 제안:** 의미론적 분할을 위한 양방향 학습 시스템을 제시합니다. 이는 이미지 변환 모델(image translation model)과 분할 적응 모델(segmentation adaptation model)이 서로를 번갈아 학습하며 성능을 향상시키는 폐쇄 루프(closed loop) 구조입니다.
*   **자기-지도 학습(Self-supervised Learning, SSL) 알고리즘 도입:** 분할 적응 모델을 위한 자기-지도 학습 알고리즘을 제안합니다. 이는 변환된 이미지 결과를 기반으로 소스 도메인과 타겟 도메인을 특징 수준에서 점진적으로 정렬(align)합니다.
*   **새로운 지각 손실(Perceptual Loss) 함수 개발:** 이미지-투-이미지 변환에 새로운 지각 손실을 도입합니다. 이 손실 함수는 업데이트된 분할 적응 모델에 의해 변환 과정을 감독(supervise)합니다.

## 📎 Related Works
*   **일반적인 도메인 적응:**
    *   **통계적 매칭:** MMD(Maximum Mean Discrepancy) 손실, 평균 및 공분산과 같은 특징 분포 통계량을 최소화하여 도메인 불일치 감소 [8, 2, 21]. 분류 문제에 효과적이지만 분할에는 한계.
    *   **적대적 학습(Adversarial Learning):** 도메인 분류기가 특징이 어떤 도메인에서 왔는지 구별하지 못하도록 학습하여 도메인 간의 이동(shift)을 줄임 [34, 35]. 주로 작고 간단한 분류 데이터셋(MNIST, SVHN)에 적용.
*   **의미론적 분할을 위한 도메인 적응:**
    *   **초기 연구:** 특징 수준에서 전역적/지역적 정렬 수행 [13], 커리큘럼 도메인 적응 [37], 다중 판별자 사용 [33], 전경/배경 클래스 분리 처리 [31]. 시각적(외형, 스케일 등) 도메인 간극으로 인해 전이 가능한 지식 학습에 어려움.
    *   **이미지-투-이미지 변환 기반:** CycleGAN [38]과 같은 비쌍(unpaired) 이미지 변환 기술을 사용하여 가상 데이터를 실제 데이터처럼 변환한 후, 분할 모델을 훈련 [12, 36]. 변환 품질에 크게 의존한다는 한계 존재.
    *   **자기-훈련(Self-training):** 분할 모델이 반복적으로 훈련되는 자기-훈련 방법 [39]도 있으나, 이미지 변환 기법을 사용하지 않고 소스 데이터에서만 훈련됨.
*   **양방향 학습:** 신경망 기계 번역 [10, 23] 및 이미지 생성 [25] 분야에서 제안되었으며, 대규모 데이터 의존도를 줄이고 성능을 향상시키는 데 사용됨. 이 연구의 양방향 학습은 변환이 분할을, 분할이 변환을 상호 보완적으로 증진시키는 데 초점을 맞춤.

## 🛠️ Methodology
본 연구는 소스 데이터셋 $S$ (레이블 $Y_{\text{S}}$ 포함)와 타겟 데이터셋 $T$ (레이블 없음)를 사용하여 의미론적 분할 네트워크를 학습하는 것을 목표로 합니다.
핵심 아이디어는 이미지-투-이미지 변환 서브네트워크 $F$와 분할 적응 서브네트워크 $M$을 **양방향 학습**과 **자기-지도 학습**을 통해 반복적으로 개선하는 것입니다.

1.  **양방향 학습 (Bidirectional Learning):**
    *   **정방향 (Forward Direction, $F \to M$):**
        *   이미지 변환 모델 $F$를 훈련하여 소스 이미지 $S$를 타겟 도메인 스타일의 이미지 $S'$로 변환합니다. 이때 $S'$는 $S$와 동일한 레이블 $Y_{\text{S}}$를 유지합니다.
        *   변환된 $S'$와 실제 타겟 이미지 $T$를 사용하여 분할 적응 모델 $M$을 훈련합니다.
        *   $M$의 손실 함수는 다음과 같습니다:
            $$ \mathcal{L}_{\text{M}} = \lambda_{\text{adv}} \mathcal{L}_{\text{adv}}(M(S'), M(T)) + \mathcal{L}_{\text{seg}}(M(S'), Y_{\text{S}}) $$
            여기서 $\mathcal{L}_{\text{adv}}$는 $S'$와 $T$의 특징 표현 간 거리를 최소화하는 적대적 손실이며, $\mathcal{L}_{\text{seg}}$는 $S'$에 대한 의미론적 분할 손실입니다.
    *   **역방향 (Backward Direction, $M \to F$):**
        *   업데이트된 분할 적응 모델 $M$을 사용하여 이미지 변환 모델 $F$를 개선합니다.
        *   새로운 **지각 손실($\mathcal{L}_{\text{per}}$)**을 도입하여 원본 이미지와 변환된 이미지 간의 의미론적 일관성을 강제합니다. 이는 $M$의 특징을 사용하여 계산됩니다.
        *   $F$의 전체 손실 함수는 다음과 같습니다:
            $$ \mathcal{L}_{\text{F}} = \lambda_{\text{GAN}}[\mathcal{L}_{\text{GAN}}(S', T) + \mathcal{L}_{\text{GAN}}(S, T')] + \lambda_{\text{recon}}[\mathcal{L}_{\text{recon}}(S, F^{-1}(S')) + \mathcal{L}_{\text{recon}}(T, F(T'))] + \mathcal{L}_{\text{per}}(M(S), M(S')) + \mathcal{L}_{\text{per}}(M(T), M(T')) $$
            여기서 $\mathcal{L}_{\text{GAN}}$은 $S'$와 $T$의 분포를 유사하게 만드는 GAN 손실, $\mathcal{L}_{\text{recon}}$은 순환 일관성(cycle consistency)을 위한 이미지 재구성 손실입니다.
        *   새로 제안된 지각 손실 $\mathcal{L}_{\text{per}}$는 $M$을 통해 얻은 특징 간의 L1-norm 차이를 측정하며, 재구성 부분의 안정성을 위해 재구성된 이미지에 대한 항도 포함합니다:
            $$ \mathcal{L}_{\text{per}}(M(S), M(S')) = \lambda_{\text{per}} E_{I_{\text{S}} \sim S}[||M(I_{\text{S}}) - M(I'_{\text{S}})||_{1}] + \lambda_{\text{per_recon}} E_{I_{\text{S}} \sim S}[||M(F^{-1}(I'_{\text{S}})) - M(I_{\text{S}})||_{1}] $$

2.  **자기-지도 학습 (Self-supervised Learning, SSL) for $M$:**
    *   $M$의 예측 확률을 기반으로 타겟 데이터 $T$에서 높은 신뢰도를 가진 픽셀에 대한 의사 레이블(pseudo labels) $\hat{Y}_{\text{T}}$를 생성합니다.
    *   이 의사 레이블을 분할 손실에 추가하여 $M$을 훈련합니다.
    *   $M$의 손실 함수는 다음과 같이 수정됩니다:
        $$ \mathcal{L}_{\text{M}} = \lambda_{\text{adv}} \mathcal{L}_{\text{adv}}(M(S'), M(T)) + \mathcal{L}_{\text{seg}}(M(S'), Y_{\text{S}}) + \mathcal{L}_{\text{seg}}(M(T_{\text{ssl}}), \hat{Y}_{\text{T}}) $$
        여기서 $T_{\text{ssl}} \subset T$는 의사 레이블을 가진 타겟 데이터의 부분 집합입니다. $M$이 개선될수록 $T_{\text{ssl}}$의 크기가 커집니다. 픽셀 신뢰도를 판단하는 임계값으로 '최대 확률 임계값(Max Probability Threshold, MPT)'을 사용합니다.

3.  **훈련 과정 (Algorithm 1):**
    *   훈련은 두 개의 루프로 구성됩니다:
        *   **외부 루프:** 양방향 학습(즉, $F$와 $M$의 교대 훈련)을 담당합니다.
        *   **내부 루프:** 자기-지도 학습 프로세스를 구현하여 $M$을 반복적으로 업데이트합니다.

## 📊 Results
*   **데이터셋:** 소스 데이터셋으로 GTA5 [27] 또는 SYNTHIA [28]를 사용하고, 타겟 데이터셋으로 Cityscapes [5]를 사용합니다.
*   **모델 아키텍처:** 분할 모델은 ResNet101 [11] 백본을 가진 DeepLab V2 [3]와 VGG16 [32] 백본을 가진 FCN-8s [18]를 사용합니다. 이미지 변환 모델은 CycleGAN [38] 아키텍처를 기반으로 합니다.
*   **양방향 학습의 효과 (SSL 없이):**
    *   초기 모델($M^{(0)}$) 대비, 분할 적응 모델($M^{(1)}$) 또는 변환 모델($M^{(0)}(F^{(1)})$) 단독 적용 시 mIoU가 7% 이상 개선됩니다.
    *   양방향 학습의 첫 번째 반복($M^{(1)}_0(F^{(1)})$)은 추가 1.6% 개선을 보이며, 두 번째 반복($M^{(2)}_0(F^{(2)})$)에서 성능이 더욱 향상됩니다 (mIoU 43.3). 이는 각 모델이 상호 보완적임을 보여줍니다.
*   **자기-지도 학습(SSL)의 효과 (양방향 학습과 함께):**
    *   $k=1$일 때, SSL을 통해 $M^{(1)}_0(F^{(1)})$이 $M^{(1)}_2(F^{(1)})$으로 업데이트되면서 mIoU가 4.5% 향상됩니다 (42.7% $\to$ 47.2%). 이는 SSL이 잘 정렬된 데이터를 유지하고, 나머지 데이터를 적대적 학습을 통해 추가로 정렬하는 데 도움이 됨을 입증합니다.
    *   $k=2$일 때, SSL을 적용하지 않은 경우($M^{(2)}_0(F^{(2)})$) mIoU가 44.3%였으나, SSL 적용 후 $M^{(2)}_2(F^{(2)})$은 48.5%로 향상되어 첫 번째 반복보다 더 나은 결과를 달성합니다.
    *   분할 성능이 향상됨에 따라 마스크 맵에서 고신뢰도 예측 영역(흰색 영역)이 증가하는 것을 확인하여, SSL이 분할 성능 향상에 기여함을 시각적으로 증명합니다.
*   **하이퍼파라미터 학습:**
    *   **임계값(Threshold):** 예측 신뢰도와 선택된 픽셀 비율의 관계 분석을 통해 0.9가 선택된 레이블의 수와 품질 사이의 좋은 균형점임을 확인했습니다. 0.9보다 낮은 임계값은 부정확한 예측으로 인한 노이즈를 유발하며, 높은 임계값(0.95)은 활용 가능한 픽셀 수를 너무 줄입니다.
    *   **반복 횟수 $N$ (SSL):** $N=2$ 또는 $N=3$일 때 mIoU가 거의 증가하지 않고 픽셀 비율도 유사하게 유지되어, $N=2$가 적절한 선택임을 시사합니다.
*   **최신 기술(State-of-Art)과의 비교:**
    *   **GTA5 $\to$ Cityscapes:** ResNet101 백본 사용 시 본 연구 방법은 48.5 mIoU를 달성하여 Cycada(42.7), AdaptSegNet(41.4), DCAN(41.7), CLAN(43.2) 등 기존 SOTA 방법들을 크게 뛰어넘습니다(Cycada 대비 6% 개선). VGG16 백본 사용 시에도 41.3 mIoU로 SOTA를 달성합니다.
    *   **SYNTHIA $\to$ Cityscapes:** GTA5보다 도메인 간극이 크고 카테고리 중복이 적음에도 불구하고, 기존 방법들보다 최소 4% 이상 더 나은 성능을 보여줍니다.
*   **상한선(Upper Bound)과의 성능 격차:** 본 방법은 기존 방법들에 비해 성능 격차를 크게 줄였지만, 실제 데이터에 지상 진실(ground truth) 레이블로 직접 훈련된 모델의 상한선(예: GTA5 $\to$ Cityscapes, ResNet101 기준 65.1 mIoU)과 비교하면 여전히 최소 16.6%의 격차가 존재하여, 개선의 여지가 있음을 시사합니다.

## 🧠 Insights & Discussion
본 연구는 의미론적 분할을 위한 도메인 적응 문제에서 **양방향 학습**과 **자기-지도 학습**의 시너지를 성공적으로 입증했습니다.

*   **상호 보완적 학습:** 이미지 변환 모델이 시각적 도메인 간극을 줄이고, 분할 모델은 특징 수준의 정렬을 통해 성능을 향상시킵니다. 이 두 모델이 서로에게 긍정적인 피드백을 제공하며 반복적으로 개선되는 양방향 학습 방식은 단방향/순차적 학습의 한계를 극복합니다. 변환 모델의 실패가 후속 단계에 미치는 영향을 완화할 수 있습니다.
*   **효과적인 자기-지도 학습:** 높은 신뢰도의 의사 레이블을 활용한 자기-지도 학습은 타겟 도메인의 unlabeled 데이터를 효과적으로 활용하여 분할 적응 모델의 성능을 크게 향상시켰습니다. 이는 적대적 학습이 미처 정렬하지 못한 데이터에 집중하도록 돕습니다.
*   **새로운 지각 손실의 중요성:** 분할 모델의 특징을 활용한 지각 손실은 변환 모델이 단순한 외형 변환을 넘어 의미론적 일관성을 유지하도록 유도하여 변환 품질을 향상시키고, 이는 다시 분할 모델의 성능 향상으로 이어집니다.
*   **일반화 가능성:** 제안된 방법은 다양한 백본 네트워크(ResNet101, VGG16)와 다양한 소스 데이터셋(GTA5, SYNTHIA)에 대해 일관되게 최첨단 성능을 달성하여 그 일반성을 입증합니다.
*   **한계 및 향후 연구:** 비록 최신 기술에 비해 큰 성능 향상을 이루었지만, 여전히 완전 지도 학습 모델의 성능(상한선)과 상당한 격차가 존재합니다. 이 격차를 줄이는 것이 향후 연구의 중요한 방향이 될 수 있습니다.

## 📌 TL;DR
픽셀 단위 레이블링 비용과 합성-실제 도메인 간극으로 인한 의미론적 분할 성능 저하 문제를 해결하기 위해, 본 연구는 **양방향 학습** 프레임워크를 제안합니다. 이 프레임워크는 이미지 변환 모델과 분할 적응 모델이 서로를 반복적으로 개선하도록 하며, 분할 적응 모델의 성능 향상을 위해 **고신뢰도 의사 레이블 기반 자기-지도 학습**을 도입하고, 변환 모델의 의미론적 일관성을 높이기 위해 **새로운 지각 손실**을 활용합니다. 결과적으로 GTA5/SYNTHIA에서 Cityscapes로의 도메인 적응 작업에서 기존 최신 기술 대비 큰 폭의 성능 향상을 달성했습니다.