{
  "url": "http://arxiv.org/abs/1803.08904v1",
  "title": "Context Encoding for Semantic Segmentation",
  "authors": "Hang Zhang, Kristin Dana, Jianping Shi, Zhongyue Zhang, Xiaogang Wang, Ambrish Tyagi, Amit Agrawal",
  "year": 2018,
  "abstract": "Recent work has made significant progress in improving spatial resolution for\npixelwise labeling with Fully Convolutional Network (FCN) framework by\nemploying Dilated/Atrous convolution, utilizing multi-scale features and\nrefining boundaries. In this paper, we explore the impact of global contextual\ninformation in semantic segmentation by introducing the Context Encoding\nModule, which captures the semantic context of scenes and selectively\nhighlights class-dependent featuremaps. The proposed Context Encoding Module\nsignificantly improves semantic segmentation results with only marginal extra\ncomputation cost over FCN. Our approach has achieved new state-of-the-art\nresults 51.7% mIoU on PASCAL-Context, 85.9% mIoU on PASCAL VOC 2012. Our single\nmodel achieves a final score of 0.5567 on ADE20K test set, which surpass the\nwinning entry of COCO-Place Challenge in 2017. In addition, we also explore how\nthe Context Encoding Module can improve the feature representation of\nrelatively shallow networks for the image classification on CIFAR-10 dataset.\nOur 14 layer network has achieved an error rate of 3.45%, which is comparable\nwith state-of-the-art approaches with over 10 times more layers. The source\ncode for the complete system are publicly available."
}