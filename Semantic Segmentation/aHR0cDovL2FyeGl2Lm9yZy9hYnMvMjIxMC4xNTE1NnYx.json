{
  "title": "Towards Complex Backgrounds: A Unified Difference-Aware Decoder for\n  Binary Segmentation",
  "authors": "Jiepan Li, Wei He, Hongyan Zhang",
  "year": 2022,
  "url": "http://arxiv.org/abs/2210.15156v1",
  "abstract": "Binary segmentation is used to distinguish objects of interest from\nbackground, and is an active area of convolutional encoder-decoder network\nresearch. The current decoders are designed for specific objects based on the\ncommon backbones as the encoders, but cannot deal with complex backgrounds.\nInspired by the way human eyes detect objects of interest, a new unified\ndual-branch decoder paradigm named the difference-aware decoder is proposed in\nthis paper to explore the difference between the foreground and the background\nand separate the objects of interest in optical images. The difference-aware\ndecoder imitates the human eye in three stages using the multi-level features\noutput by the encoder. In Stage A, the first branch decoder of the\ndifference-aware decoder is used to obtain a guide map. The highest-level\nfeatures are enhanced with a novel field expansion module and a dual residual\nattention module, and are combined with the lowest-level features to obtain the\nguide map. In Stage B, the other branch decoder adopts a middle feature fusion\nmodule to make trade-offs between textural details and semantic information and\ngenerate background-aware features. In Stage C, the proposed difference-aware\nextractor, consisting of a difference guidance model and a difference\nenhancement module, fuses the guide map from Stage A and the background-aware\nfeatures from Stage B, to enlarge the differences between the foreground and\nthe background and output a final detection result. The results demonstrate\nthat the difference-aware decoder can achieve a higher accuracy than the other\nstate-of-the-art binary segmentation methods for these tasks.",
  "citation": 7
}