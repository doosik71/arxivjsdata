# Amodal Instance Segmentation

Ke Li, Jitendra Malik

## 🧩 Problem to Solve

이 논문은 이미지 내 각 객체의 **가시 부분과 가려진 부분(즉, 전체 객체)**을 모두 포함하는 영역을 예측하는 **비모달(amodal) 인스턴스 분할** 문제에 초점을 맞춥니다. 현재까지 비모달 분할 방법 개발은 공개적으로 사용 가능한 비모달 분할 주석 데이터의 부족으로 인해 어려움을 겪어왔습니다. 기존 인스턴스 분할(모달 분할)은 가시 영역만을 다룹니다.

이러한 비모달 분할의 본질적인 어려움은 다음과 같습니다:

- **데이터 부족**: 비모달 주석 데이터셋이 전무합니다.
- **모호성**: 가시 부분만으로는 가려진 부분의 형태에 대한 여러 그럴듯한 가설이 존재할 수 있습니다.
- **복잡성**: 가려짐 추론(occlusion reasoning)을 넘어 가려진 부분의 모양을 추정하고, 가려진 객체의 미미한 신호를 감지하면서 가리는 객체의 강한 신호에 오도되지 않아야 합니다.

## ✨ Key Contributions

- **최초의 비모달 인스턴스 분할 방법 제시**: 저자들은 이 연구가 비모달 인스턴스 분할을 위한 최초의 알고리즘적 접근 방식이라고 주장합니다.
- **합성 훈련 데이터 생성 전략**: 기존 모달 인스턴스 분할 주석만을 사용하여 비모달 훈련 데이터를 생성하는 새로운 방법을 제안합니다. 이는 비모달 데이터 부족 문제를 우회하는 핵심 기여입니다.
- **반복적 경계 상자 확장(Iterative Bounding Box Expansion) 기법 도입**: 테스트 시 비모달 경계 상자를 미리 알 필요 없이, 비모달 분할 히트맵에서 이를 반복적으로 추론하는 새로운 전략을 개발했습니다.
- **효과성 입증**: 합성 데이터로 훈련되었음에도 불구하고 실제 가려짐이 있는 이미지에서 비모달 마스크를 효과적으로 예측할 수 있음을 정성적 및 정량적으로 시연합니다.
- **가려지지 않은 객체에 대한 강건성**: 가려짐에 강건하도록 학습된 모델은 가려지지 않은 객체에 대해서도 모달 분할보다 더 정확하거나 유사한 예측을 수행하여 전반적인 강건성을 보여줍니다.

## 📎 Related Works

- **그림-배경 분할(Figure-Ground Segmentation)**: 객체 중심 이미지에서 전경 픽셀을 식별하는 초기 노력들. 상향식(bottom-up) 및 하향식(top-down) 접근 방식 결합, 클래스/객체 특정 템플릿 사용.
- **의미 분할(Semantic Segmentation)**: 더 복잡한 이미지에서 각 객체 범주에 속하는 픽셀을 식별하는 일반적인 문제. CRF 기반, 객체 감지 및 영역 제안 결합, FCN(완전 합성곱 네트워크) 또는 RNN(순환 신경망) 모델 사용 등.
- **인스턴스 분할(Instance Segmentation)**: 각 개별 객체 인스턴스에 속하는 픽셀을 식별하는 작업. 주로 객체 탐지기로 경계 상자를 찾은 후 해당 상자 내에서 그림-배경 분할을 수행하는 방식. DPM(Discriminatively Trained Part-based Models) 기반, CNN 기반 접근 방식 (SDS [18], Dai et al. [6], Hypercolumn net [19], Iterative Instance Segmentation (IIS) [27], Multi-Task Network Cascades [7]).
- **비모달 완성(Amodal Completion)**: 비모달 경계 상자 예측 (Kar et al. [21]), 깊이 정보를 이용한 평면 표면 완성 (Gupta et al. [16]) 등 일부 연구가 있었으나, 일반적인 목적의 비모달 분할에 대한 알고리즘 연구는 거의 없었습니다.
- **비모달 분할 주석 수집**: Zhu et al. [40]이 비모달 주석을 수집했지만, 현재 공개적으로 이용 가능하지 않습니다.

## 🛠️ Methodology

1. **훈련 데이터 생성**:
   - **핵심 아이디어**: 가려짐을 되돌리는 것은 어렵지만, 합성 가려짐을 추가하는 것은 쉽다는 점을 활용합니다.
   - **데이터 소스**: PASCAL VOC 2012 훈련 세트의 표준 모달 인스턴스 분할 주석(SBD)을 사용합니다.
   - **생성 절차**:
     - 주 객체(main object)를 포함하는 이미지 패치를 무작위로 자릅니다.
     - 다른 이미지에서 무작위 객체 인스턴스를 추출하여 주 객체 위에 모달 분할 마스크를 알파 매트로 사용하여 겹쳐 합성 패치를 생성합니다.
     - 합성 패치에서 주 객체의 가시 부분을 둘러싸는 가장 작은 경계 상자(모달 경계 상자)를 찾고, 테스트 시의 노이즈를 시뮬레이션하기 위해 이를 무작위로 흔듭니다.
     - 원본 모달 분할 마스크(합성 가려짐의 영향을 받지 않음)를 해당 합성 패치의 목표 비모달 분할 마스크로 사용합니다. 주 객체 픽셀은 양성, 배경 픽셀은 음성, 다른 객체 픽셀은 "알 수 없음"으로 레이블링합니다.
   - **구현 세부 사항**: 훈련 중 실시간으로 데이터 생성. 주 객체 경계 상자와 겹치도록 무작위 박스 샘플링, 겹칠 객체 수 (0~2) 선택, 주 객체의 가시 비율이 30% 미만으로 떨어지지 않도록 보장.
2. **모델 아키텍처**:
   - Convolutional Neural Network (CNN)를 사용합니다.
   - IIS [27] (Iterative Instance Segmentation)의 아키텍처를 기반으로 하며, 이는 Hariharan et al. [19]이 소개한 Hypercolumn 아키텍처를 따릅니다.
   - VGG 16-layer net [33]의 "O-Net" 버전을 기반으로 합니다.
   - 입력: 이미지 패치, 모달 분할 히트맵(IIS에서 생성), 객체 범주.
   - 출력: 비모달 분할 히트맵.
   - Hypercolumn 표현: 여러 중간 레이어의 업샘플링된 특징 맵 합계를 사용하여 저수준 및 고수준 이미지 특징을 활용합니다.
3. **훈련**:
   - IIS 모델의 가중치로 초기화하고 32개 패치의 미니 배치에서 모멘텀을 이용한 확률적 경사 하강법으로 End-to-end 훈련합니다.
   - 손실 함수: 지상 진실 레이블이 알려진 모든 픽셀에 대한 픽셀 단위 음의 로그 우도(negative log likelihood)의 합.
   - 훈련 상수 학습률 $10^{-5}$, 가중치 감소 $10^{-3}$, 모멘텀 0.9로 50,000회 반복.
4. **비모달 마스크 및 경계 상자 예측 (테스트)**:
   - 주어진 모달 경계 상자와 객체 범주(객체 탐지기에서 얻음)를 사용합니다.
   - IIS [27]를 사용하여 모달 분할 히트맵을 계산합니다.
   - **반복적 경계 상자 확장(Iterative Bounding Box Expansion)**:
     - 초기 비모달 경계 상자를 모달 경계 상자와 동일하게 설정합니다.
     - 각 반복에서 현재 비모달 경계 상자 내의 패치를 CNN에 입력합니다.
     - CNN은 확장된 비모달 경계 상자(원본 경계 상자 바로 바깥 영역 포함) 내의 비모달 분할 마스크를 예측합니다.
     - 원본 경계 상자의 상하좌우 영역에서 평균 히트 강도를 계산합니다.
     - 특정 방향의 평균 히트 강도가 임계값(0.1)을 초과하면 해당 방향으로 경계 상자를 확장하고 이를 다음 반복에 사용할 새로운 비모달 경계 상자로 설정합니다.
     - 모든 방향의 평균 히트 강도가 임계값 미만이 될 때까지 반복합니다.
   - 최종 비모달 분할 마스크는 해당 히트맵에서 강도가 0.7을 초과하는 모든 픽셀을 색칠하여 얻습니다. 모달 분할 마스크는 모달 히트맵을 0.8에서 임계값 처리하여 얻습니다.

## 📊 Results

- **데이터셋**: PASCAL VOC 2012 `valset`을 사용하고, 정량적 평가를 위해 100개의 가려진 객체에 대한 비모달 분할 마스크를 직접 주석화하여 새로운 데이터셋을 구축했습니다.
- **정성적 결과 (Fig. 5, 6, 7)**:
  - **성공적인 예측**: 주 객체 내부에 구멍이 생기는 '내부 가려짐'이든, 주 객체 경계 밖으로 확장되어야 하는 '외부 가려짐'이든 효과적으로 비모달 마스크를 예측합니다. 합성 데이터로 훈련되었음에도 불구하고 실제 가려짐에 대해 그럴듯한 가설을 제시합니다.
  - **강건성**: 심지어 모달 예측이 좋지 않은 일부 이미지에서도 상당히 좋은 비모달 마스크를 생성하며, 가려지지 않은 객체에 대해서는 모달 예측과 유사하거나 더 정확한 결과를 보여줍니다.
  - **오류 사례**: 드문 자세, 가려진 부분의 큰 변동성, 인접 객체의 유사한 외관, 또는 잘못된 모달 예측 등으로 인해 발생합니다.
- **간접 평가 (가려짐 유무 예측 - Fig. 8)**:
  - '면적 비율'($\frac{\text{area(modal mask} \cap \text{amodal mask)}}{\text{area(amodal mask)}}$)을 사용하여 객체가 가려진 정도를 측정합니다.
  - 가려지지 않은 객체는 면적 비율이 1에 가까운 분포를 보이며, 가려진 객체는 약 0.75에서 피크를 이루는 분포를 보여 모델이 가려진 객체에 대해서만 비모달 완성을 수행함을 확인합니다.
  - 면적 비율을 가려짐 유무 분류기로 사용하여 77.17%의 평균 정밀도(Average Precision)를 달성합니다.
- **직접 평가 (비모달 마스크 정확도 - Table 1, Fig. 9)**:
  - 수집된 100개 객체 데이터셋에서 제안된 방법의 IoU(Intersection-over-Union)를 IIS [27] (최첨단 모달 분할 방법)과 비교합니다.
  - 대부분의 경우(73%), 제안된 방법이 IIS보다 훨씬 더 정확한 마스크를 생성하며, 많은 경우 IoU가 20-50% 개선됩니다.
  - IoU 임계값 50%에서 정확도: 제안 방법 80.0% vs. IIS 68.0%.
  - IoU 임계값 70%에서 정확도: 제안 방법 48.0% vs. IIS 37.0%.
  - 정확도 곡선 아래 면적(AUC): 제안 방법 64.3 vs. IIS 57.5.
- **결합된 탐지 및 분할 성능 (Table 2)**:
  - Faster R-CNN [32]을 탐지 시스템으로 사용하여 전반적인 mAP$_r$ (mean region average precision)을 비교합니다.
  - 제안 방법 + Faster R-CNN 파이프라인이 IIS + Faster R-CNN 파이프라인보다 IoU 50%에서 11.1 포인트, IoU 70%에서 8.6 포인트 더 높은 성능을 보입니다.
- **어블레이션 분석 (Ablation Analysis)**: 모달 분할 예측을 입력으로 사용하는 것과 동적으로 다양한 가려짐 구성을 생성하는 것이 모두 성능 향상에 중요함을 확인했습니다.

## 🧠 Insights & Discussion

- 이 연구의 가장 중요한 통찰은 비모달 분할 주석의 부재라는 큰 제약을, **기존 모달 주석을 활용한 영리한 합성 데이터 생성 전략**으로 극복했다는 점입니다. 이는 실제 세계에서 비모달 데이터셋 구축이 매우 어렵기 때문에 실용적인 해결책을 제시합니다.
- 모델은 합성 데이터로 훈련되었음에도 불구하고 **실제 가려짐에 대해 그럴듯한 가설을 형성**할 수 있음을 보여주며, 이는 일반적인 객체 모양에 대한 암묵적인 지식을 학습했음을 시사합니다.
- **반복적 경계 상자 확장**은 가려진 객체의 정확한 전체 크기를 동적으로 추론하는 데 필수적이며, 이는 비모달 분할의 핵심 과제 중 하나입니다.
- 가려지지 않은 객체에 대해서도 모달 분할보다 더 좋은 성능을 보이는 것은, 모델이 가려짐 상황을 처리하며 습득한 강건성이 일반적인 이미지 이해 능력 향상으로 이어진다는 점을 시사합니다. 즉, 가려짐에 강건해지면서 저수준 패턴의 변화에 대해서도 강건해지는 효과를 얻습니다.
- 다만, 훈련 세트의 드문 자세, 가려진 부분 구성의 높은 변동성, 인접 객체의 외관 유사성, 또는 잘못된 모달 예측 등은 여전히 오류의 원인이 될 수 있습니다.

## 📌 TL;DR

비모달 인스턴스 분할은 객체의 가시 부분과 가려진 부분을 모두 예측하는 과제이지만, 훈련 데이터가 부족했습니다. 이 논문은 **최초의 비모달 인스턴스 분할 방법**을 제안하며, **기존 모달 분할 주석으로 합성 가려짐 데이터를 생성**하여 이 문제를 해결했습니다. 제안된 방법은 합성 데이터를 사용했음에도 불구하고 **실제 이미지에서 가려진 객체의 전체 형태를 효과적으로 예측**하고, **반복적 경계 상자 확장 기법**을 통해 비모달 경계 상자를 추론하여 기존 모달 분할 방법을 뛰어넘는 성능을 달성했습니다.
