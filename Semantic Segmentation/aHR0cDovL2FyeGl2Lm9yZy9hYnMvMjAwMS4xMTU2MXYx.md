# Dual Convolutional LSTM Network for Referring Image Segmentation

Linwei Ye, Zhi Liu, Senior Member, IEEE, and Yang Wang

## 🧩 Problem to Solve

이 논문은 **참조 이미지 분할(Referring Image Segmentation)** 문제를 다룹니다. 이는 컴퓨터 비전과 자연어 이해의 교차점에 있는 문제로, 주어진 이미지와 자연어 참조 표현(문장)을 통해 해당 표현이 지칭하는 관심 객체를 이미지 내에서 정확하게 분할하는 것을 목표로 합니다. 기존 방법론들은 시각 및 텍스트 특징을 독립적으로 추출하거나, 참조 표현 내 모든 단어를 동등하게 처리하여 긴 표현에서 중요한 단어들을 효과적으로 포착하지 못하는 한계가 있었습니다.

## ✨ Key Contributions

* **이중 합성곱 LSTM (Dual ConvLSTM) 네트워크 제안:** 멀티모달 특징 인코더와 다단계 세그먼트 디코더를 활용하는 인코더-디코더 프레임워크를 참조 이미지 분할에 적용했습니다.
* **단어 주의(Word Attention) 기반 멀티모달 특징 인코더 (E-ConvLSTM):** E-ConvLSTM의 셀 (메모리) 상태에 단어 주의 메커니즘을 통합하여, 멀티모달 상호작용이 표현 내의 더 중요한 단어들을 향해 적응적으로 이루어지도록 학습하고 지칭 객체를 지역화합니다.
* **공간 주의(Spatial Attention) 기반 다단계 세그먼트 디코더 (D-ConvLSTM):** D-ConvLSTM은 여러 단계의 특징에 공간 주의를 적용하여 점진적으로 정교한 분할 마스크를 생성함으로써 참조 이미지 분할 결과를 개선합니다.
* **최첨단 성능 달성:** 제안된 이중 ConvLSTM 네트워크는 네 가지 공개 데이터셋에서 철저하게 평가되었으며, 기존 최첨단 방법론 대비 우수한 분할 성능을 입증했습니다.

## 📎 Related Works

* **객체 분할:** 의미론적 분할 (Semantic Segmentation), 인스턴스 분할 (Instance Segmentation), 돌출 객체 분할 (Salient Object Segmentation) 등. 이들은 사전 정의된 카테고리에 의존하거나, 복잡한 경우 모호할 수 있다는 한계가 있습니다.
* **시각-언어 결합:** 이미지 캡셔닝 (Image Captioning) [17], 시각 질의응답 (Visual Question Answering, VQA) [18], 시각적 접지 (Visual Grounding) [19, 20] 등이 있으며, 주로 바운딩 박스나 문장 생성에 초점을 맞춥니다.
* **기존 참조 이미지 분할:**
  * **독립적 특징 추출 및 결합:** 참조 표현과 시각 특징을 개별적으로 인코딩한 후 결합하는 방식 [7, 8, 9]. (예: RNN/LSTM으로 텍스트 특징 추출, CNN으로 시각 특징 추출 후 디컨볼루션 [7] 또는 순환적 개선 [8] 등을 통해 결합). 단점은 상세한 멀티모달 정보 포착의 어려움입니다.
  * **순차적 단어 처리:** 참조 표현의 각 단어를 순차적으로 처리하여 시각적 맥락과 상호작용 [11, 12]. 단점은 모든 단어를 동등하게 처리하여 중요하지 않은 단어로 인해 성능이 저하될 수 있다는 점입니다. (예: RMI [11], DMN [12])
  * **정교화 기법:** 다중 스케일 특징을 점진적으로 정교화하여 분할 마스크 개선 [8, 21]. (예: RRN [8], CMSA [21]).

## 🛠️ Methodology

본 논문은 인코더-디코더 프레임워크를 기반으로 하며, 인코더와 디코더 모두에 ConvLSTM을 활용합니다.

### 1. 멀티모달 특징 인코더 (E-ConvLSTM)

* **단어 임베딩 및 양방향 LSTM:** 각 단어 $w_l$을 임베딩 $e_l$하고, 양방향 LSTM을 통해 $h_l = [\vec{h_l}, \overleftarrow{h_l}]$과 같이 이전 및 미래 단어 관계를 고려한 벡터 표현을 생성합니다.
* **단어 주의 메커니즘:** 두 개의 선형 레이어를 사용하여 각 단어 $h_l$의 상대적 중요도를 나타내는 주의 가중치 $a_l$을 계산하고 소프트맥스 정규화를 적용합니다.
    $$a_l = \frac{\exp(W_{La} \tanh(W_{Lb} h_l))}{\sum_{k=1}^L \exp(W_{La} \tanh(W_{Lb} h_k))}$$
    이후 $r_l = a_l h_l$로 단어 벡터를 재가중합니다.
* **멀티모달 특징 생성:** 사전 훈련된 CNN (DeepLab-101)으로 시각 특징 $V \in \mathbb{R}^{W \times H \times C_v}$를 추출하고, 각 공간 위치에 8차원 공간 특징 (상대 수평/수직 좌표, 이미지 상대 크기)을 추가합니다. 각 단어의 벡터 표현 $r_l$을 $V$의 모든 공간 셀에 덧붙여 단어별 멀티모달 특징 맵 $M^e_l \in \mathbb{R}^{W \times H \times (C_v+8+C_r)}$을 생성합니다.
* **단어 주의 기반 멀티모달 상호작용 (E-ConvLSTM):** 표준 ConvLSTM을 수정하여 단어 주의 $a_l$를 셀 상태 $C^e_l$ 업데이트에 통합합니다.
    $$ (H^e_l, C^e_l) = \text{ConvLSTM}_E(M^e_l, H^e_{l-1}, C^e_{l-1}) $$
    $$ C^e_l = a_l \times i^e_l \odot g^e_l + (1-a_l) \times f^e_l \odot C^e_{l-1} $$
    이를 통해 ConvLSTM은 $a_l$이 높은 중요한 단어에 더 집중하여 멀티모달 상호작용을 유도합니다. 최종 단계의 은닉 상태 $H^e_L$가 인코더의 출력입니다.

### 2. 다단계 세그먼트 디코더 (D-ConvLSTM)

* **다단계 입력 특징:** 인코더의 마지막 은닉 상태 $H^e_L$를 여러 CNN 레이어 (예: Res5, Res4, Res3)에서 생성된 멀티모달 특징 $M^d_s$로 활용합니다.
* **공간 주의 메커니즘:** 각 다단계 특징 $M^d_s$에 7x7 합성곱 레이어와 시그모이드 함수를 적용하여 공간 주의를 생성하고, 이를 특징 맵에 곱하여 중요한 공간 영역에 집중하도록 합니다.
    $$ M^d_s = \sigma(W_s * M^d_s + b_s) \odot M^d_s $$
* **멀티모달 특징 정교화 (D-ConvLSTM):** D-ConvLSTM은 고수준에서 저수준 의미론으로 진행하며 공간 주의가 적용된 다단계 특징 $M^d_s$를 순차적으로 통합하고 정교화합니다.
    $$ (H^d_s, C^d_s) = \text{ConvLSTM}_D(M^d_s, H^d_{s-1}, C^d_{s-1}) $$
    최종 은닉 상태 $H^d_S$는 또 다른 합성곱 레이어를 거쳐 시그모이드 함수로 정규화된 2D 확률 점수 맵 $y \in (0,1)$을 생성합니다.
* **손실 함수:** 이진 교차 엔트로피 손실 함수를 사용하여 훈련합니다.
    $$ \text{Loss} = - \frac{1}{\Omega} \sum_{n=1}^\Omega (\hat{y}(n) \log y(n) + (1-\hat{y}(n)) \log(1-y(n))) $$

## 📊 Results

* **정량적 결과:** Google-Ref, UNC, UNC+, Referit 네 가지 데이터셋에서 SOTA (State-Of-The-Art) 성능을 달성했습니다. DCRF 후처리 적용 여부와 관계없이 일관되게 우수한 성능을 보였습니다. 특히 Google-Ref와 같이 참조 표현이 길고 복잡한 데이터셋에서 성능 향상이 두드러졌습니다.
* **어블레이션 연구:** UNC 검증 데이터셋에서 각 구성 요소의 효과를 입증했습니다.
  * 단어 주의 도입은 멀티모달 상호작용 결과를 개선했습니다.
  * 다단계 세그먼트 디코더의 멀티모달 특징 정교화는 분할 성능을 크게 향상시켰습니다.
  * 공간 주의는 중요한 공간 영역에 집중하여 특징 표현력을 강화하고 성능을 추가적으로 개선했습니다.
  * DCRF 후처리는 최종 분할 마스크의 정밀도를 더욱 높였습니다.
* **정성적 결과:** 복잡한 속성, 관계, 이질적인 구성 요소를 포함하는 객체, 큰 영역의 분할 등 다양한 시나리오에서 기존 방법보다 정확하고 명확한 경계의 분할 마스크를 생성했습니다. 긴 참조 표현에 대한 성능 우위도 시각적으로 확인되었습니다.
* **시각화:** E-ConvLSTM이 단어 처리 과정에서 의미를 이해하고 객체를 지역화하는 과정과 D-ConvLSTM이 다단계 특징을 통해 분할 마스크를 점진적으로 정교화하는 과정을 보여주었습니다. 또한, 네트워크가 데이터셋에 없는 표현에도 효과적으로 반응하는 일반화 능력을 입증했습니다.

## 🧠 Insights & Discussion

* **적응형 단어 주의의 중요성:** E-ConvLSTM에 통합된 단어 주의 메커니즘은 복잡하거나 긴 참조 표현에서 중요한 단어에 동적으로 집중하여 멀티모달 상호작용을 효과적으로 유도합니다. 이는 기존 방법론이 모든 단어를 동등하게 취급하여 발생하는 문제를 해결합니다.
* **다단계 정교화의 효과:** D-ConvLSTM 디코더가 여러 수준의 특징에 공간 주의를 적용하여 점진적으로 분할 마스크를 개선하는 방식은 객체의 정확한 경계를 식별하고 불필요한 배경 영역을 제거하는 데 기여합니다. 고수준 특징은 의미론적 객체 위치를, 저수준 특징은 미세한 경계 세부 정보를 제공합니다.
* **ConvLSTM의 역할:** ConvLSTM은 시각적 공간 정보와 언어적 순차 정보를 동시에 처리하는 데 탁월하며, 멀티모달 데이터의 공간-시간 상관관계를 효과적으로 포착합니다.
* **한계점:** 언어적 모호성 (예: 두루미와 참새의 혼동), 심한 폐색으로 인한 객체 식별 어려움, 브로콜리의 내부 간격과 같은 미세한 세부 사항에서 분할 오류가 발생할 수 있습니다. 향후 미세 조정 인식 기술을 통해 이러한 한계를 극복할 수 있을 것으로 예상됩니다.
* **공간 특징의 기여:** 시각 특징과 결합된 공간 특징은 유사한 외관을 가진 객체들을 구별하는 데 중요한 역할을 합니다.

## 📌 TL;DR

이 논문은 자연어 참조 표현으로 지칭된 객체를 분할하는 **참조 이미지 분할**을 위해 **이중 합성곱 LSTM (ConvLSTM) 네트워크**를 제안합니다. 이 모델은 **E-ConvLSTM 인코더**에서 단어 주의 메커니즘을 ConvLSTM 셀 상태에 통합하여 중요한 단어에 적응적으로 집중하고 멀티모달 상호작용을 통해 객체를 지역화합니다. 이어서 **D-ConvLSTM 디코더**는 다단계 특징에 공간 주의를 적용하여 분할 마스크를 점진적으로 정교화합니다. 이 접근 방식은 네 가지 주요 데이터셋에서 최첨단 성능을 달성하며, 특히 길고 복잡한 참조 표현에 대한 이해도를 크게 향상시켰습니다.
