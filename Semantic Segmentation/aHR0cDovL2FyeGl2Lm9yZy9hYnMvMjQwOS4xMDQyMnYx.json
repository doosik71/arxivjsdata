{
  "url": "http://arxiv.org/abs/2409.10422v1",
  "title": "Learning Semi-Supervised Medical Image Segmentation from Spatial\n  Registration",
  "authors": "Qianying Liu, Paul Henderson, Xiao Gu, Hang Dai, Fani Deligianni",
  "year": 2024,
  "abstract": "Semi-supervised medical image segmentation has shown promise in training\nmodels with limited labeled data and abundant unlabeled data. However,\nstate-of-the-art methods ignore a potentially valuable source of unsupervised\nsemantic information -- spatial registration transforms between image volumes.\nTo address this, we propose CCT-R, a contrastive cross-teaching framework\nincorporating registration information. To leverage the semantic information\navailable in registrations between volume pairs, CCT-R incorporates two\nproposed modules: Registration Supervision Loss (RSL) and Registration-Enhanced\nPositive Sampling (REPS). The RSL leverages segmentation knowledge derived from\ntransforms between labeled and unlabeled volume pairs, providing an additional\nsource of pseudo-labels. REPS enhances contrastive learning by identifying\nanatomically-corresponding positives across volumes using registration\ntransforms. Experimental results on two challenging medical segmentation\nbenchmarks demonstrate the effectiveness and superiority of CCT-R across\nvarious semi-supervised settings, with as few as one labeled case. Our code is\navailable at\nhttps://github.com/kathyliu579/ContrastiveCross-teachingWithRegistration."
}