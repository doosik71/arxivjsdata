# Beyond Single Stage Encoder-Decoder Networks: Deep Decoders for Semantic Image Segmentation
Gabriel L. Oliveira, Senthil Yogamani, Wolfram Burgard, Thomas Brox

## 🧩 Problem to Solve
기존 단일 인코더-디코더 기반의 의미론적 이미지 분할(Semantic Image Segmentation) 방법론들은 분할 품질 및 레이어당 효율성 측면에서 한계에 도달하고 있습니다. 이러한 단일 단계 디코더의 주요 병목 현상은 인코더 레이어에 디코더 레이어의 컨텍스트 정보를 피드백할 수 없다는 점이며, 이는 네트워크가 더 유익한 특징을 추출하는 것을 방해합니다.

## ✨ Key Contributions
*   **Deep Decoder (DD) 아키텍처 제안**: 여러 개의 얕은 네트워크를 활용하여 더 많은 정보 콘텐츠를 캡처하는 새로운 디코더 토폴로지를 제시합니다.
*   **새로운 스킵 연결 도입**: 인코더-디코더 간의 정보 흐름을 개선하기 위해 후방(backward) 및 스택형 잔차(stacked residual) 연결을 포함하는 새로운 토폴로지를 제안합니다.
*   **동적 가중치 함수 도입**: 소수 클래스(under-represented objects)에 대한 네트워크의 주의를 높이기 위해 클래스 균형을 재조정하는 가중치 함수를 소개합니다.
*   **최첨단 성능 달성**: CamVid, Gatech, Freiburg Forest 데이터셋에서 최신 기술(state-of-the-art)의 결과를 달성했습니다.
*   **범용성 입증**: 제안된 Deep Decoder가 DeepLab v2 및 v3+와 같은 기존 최첨단 분할 기술과 결합될 때 성능 향상을 가져옴을 입증합니다.
*   **광학 흐름(Optical Flow) 통합**: 광학 흐름 정보를 추가하여 순수 이미지 기반 의미론적 분할 성능을 더욱 향상시킬 수 있음을 보여줍니다.

## 📎 Related Works
이 연구는 심층 신경망을 사용하는 의미론적 분할의 최근 발전을 FCN(Fully Convolutional Networks)을 중심으로 검토합니다.
*   **FCN 확장**: 거친 가장자리 분할 및 객체 소실 문제를 완화하기 위해 컨텍스트, 해상도 및 경계 정렬을 탐색합니다.
    *   **컨텍스트 통합**: 확장된 컨볼루션(Dilated Convolutions) (Yu et al. 2016, DeepLab-V2), Zoom-out (Mostajabi et al. 2015), ParseNet (W. Liu et al. 2015), GCN (Peng et al. 2017) 등이 넓은 수용 영역을 통해 컨텍스트 정보를 캡처합니다.
    *   **해상도 복구**: LRN (Islam et al. 2017), DeconvNet (Noh et al. 2015), FC-Dense (Jegou et al. 2016), DPDB-Net (Oliveira et al. 2018) 등이 다운샘플링으로 인한 해상도 손실을 복구합니다.
    *   **경계 개선**: CRF 기반 (Adelaide, G. Lin et al. 2016) 및 양방향 필터(bilateral filter) (Barron et al. 2016; Jampani et al. 2016)를 통한 후처리 기법들이 사용됩니다.
*   **효율적인 네트워크**: Fast-Net (Oliveira et al. 2016), E-Net (Paszke et al. 2016), SegNet (Badrinarayanan et al. 2015) 등 효율성을 중시하는 아키텍처들이 있습니다.

본 연구는 기존 작업들과 달리, 분할 디코더에 대한 연구가 상대적으로 부족하며 병목 현상이 되고 있다는 점(Wojna et al. 2017)에 주목하여, 새로운 디코더의 잠재력을 탐색합니다.

## 🛠️ Methodology
제안하는 DD-Net 아키텍처는 DPDB(Dual Path Dense Block) 기반의 매크로 인코더와 새로 제안된 Deep Decoder로 구성됩니다.

1.  **Dual Path Dense Block (DPDB)** (인코더의 핵심 빌딩 블록)
    *   ResNet (특징 재사용)과 DenseNet (새로운 특징 탐색)의 장점을 결합한 효율적인 서브네트워크 아키텍처입니다.
    *   잔차 경로($x_{l,R} := f_{t}^{l}(x_{t}^{l,R}) = x_{l-1}^{l,R} + \phi_{t}^{l}(x_{l-1}^{l,R})$)와 Dense 경로($x_{l,D} := \sum^{l-1}_{t=0} N_{t}^{l}([x_{t}^{l,D}])$)로 구성됩니다.
    *   두 경로의 출력을 연결(concatenation)하여 특징 압축 문제를 방지하고 최종 변환 함수($G_l$)에 입력됩니다.

2.  **Deep Decoder (DD)**
    *   고해상도 예측을 복구하기 위해 여러 개의 얕은 인코더-디코더 네트워크 세트를 활용합니다.
    *   각 세트는 Dense Blocks를 사용하는 디코더-인코더로 구성되며, 세 개의 업샘플링 블록과 세 개의 다운샘플링 블록이 뒤따릅니다.
    *   **스킵 연결**:
        *   **순방향(Forward) 스킵 연결**: 첫 번째 인코더의 특징을 해당 해상도의 모든 후속 디코더에 연결하여 덜 손상된 공간 정보를 포함시킵니다. 트랜스포즈 컨볼루션(Transposed Convolution) 후 Dense Block으로 업샘플링된 특징과 연결됩니다.
        *   **후방(Backward) 스킵 연결**: 이전 디코더-인코더 유닛에서 현재 인코더로 컨텍스트 정보를 피드백하여 인코더가 더 높은 수준의 의미론적 정보를 조기에 이해하도록 돕습니다. 원소별 합(element-wise summation)으로 결합됩니다.
        *   **스택형 잔차(Stacked Residual Connection, SRC)**: 각 디코더의 고해상도 출력 간에 스킵 연결을 설치합니다. 이는 각 인코더-디코더 세트 간의 매크로 잔차 연결 역할을 하며 다단계 분할 마스크 예측을 생성합니다. 원소별 합으로 이전 디코더의 최종 특징과 합쳐져 다음 블록의 입력으로 사용됩니다.
    *   **심층 감독(Deep Supervision)**: 각 디코더 블록의 끝에 보조 감독 분기(auxiliary supervision branches)를 추가하여 깊은 네트워크에서의 기울기 전파 문제를 완화합니다.

3.  **동적 가중치 함수(Dynamic Weight Function)**
    *   클래스 불균형 문제를 해결하기 위해 각 픽셀의 클래스 빈도를 기반으로 가중치를 동적으로 할당합니다.
    *   작은 객체가 더 높은 가중치를 갖도록 $DW_{i} = \frac{C_{b} + \sum^{N}_{i=1} C_{i}}{C_{i}}$로 정의됩니다. (여기서 $N$은 클래스 수, $C_b$는 배경 픽셀 수, $C_i$는 클래스 $i$의 픽셀 수)
    *   과도한 가중치 변화를 막기 위해 하한($L$)을 두어 $DW_{\text{bounded},i} = \max(DW_{i}, L)$로 제한합니다. 배경 가중치는 항상 0입니다.

4.  **광학 흐름 증강 (Optical Flow Augmentation)**
    *   장면의 동적 변화에 대한 보완적인 정보를 제공하기 위해 광학 흐름을 추가 입력으로 사용합니다.
    *   FlowNet v2 모델(Ilg et al. 2017)을 사용하여 연속된 두 이미지 간의 흐름 맵을 예측합니다.
    *   흐름 정보(크기 및 방향)를 RGB 이미지에 채널로 추가하여 DD-Net의 입력으로 사용합니다 (조기 융합 방식).

## 📊 Results
*   **CamVid 데이터셋**: 평균 mIoU 73.2%를 달성하여 새로운 SOTA를 기록했으며, 두 번째로 우수한 SDN 대비 파라미터 수가 5배 적습니다. 사람, 전봇대, 표지판과 같은 도전적인 클래스에서 높은 세부 분할 성능을 보였으나, 나무 클래스 과분할 및 자동차 보닛과 도로 간 혼동이 일부 관찰되었습니다.
*   **Gatech 데이터셋**: 83.1%의 글로벌 정확도를 달성하며 기존 방법론들을 능가했습니다. 특히, 오염된 레이블 주석에도 불구하고 효과적인 예측을 수행했습니다.
*   **Freiburg Forest 데이터셋**: 90.2%의 mIoU로 SOTA를 달성했습니다. 특히 "트레일(trail)" 클래스(로봇 경로 계획에 중요)에서 높은 IoU를 보였습니다.

**세부 실험 (Ablation Studies)**:
*   **블록 학습 분석**: DPDB 블록이 Dense 블록에 비해 인코더에서 우수한 특징 학습 성능을 보였고, Deep Decoder는 단일 디코더 아키텍처보다 10.8%p 이상 높은 성능을 보였습니다.
*   **디코더의 특징 학습**: 업샘플링 후 Dense Block을 사용하는 것이 단순히 컨볼루션을 사용하는 것보다 1.9%p의 mIoU 향상을 가져왔습니다.
*   **디코더 깊이**: 디코더-인코더 유닛 수를 늘릴수록 성능이 일관되게 향상되었으며, 특히 보행자, 자전거 운전자와 같은 복잡한 클래스에서 뚜렷한 개선을 보였습니다.
*   **스킵 연결 및 해상도**: 순방향(F), 후방(B), 잔차(R) 연결을 모두 사용하는 FBR 모델이 가장 우수한 성능을 보였으며, 높은 해상도 입력(360x360)이 모든 클래스에서 더 나은 결과를 가져왔습니다.
*   **클래스 균형**: 제안된 동적 가중치 함수가 Median Frequency 및 Focal Loss보다 우수한 성능을 보였습니다. Focal Loss는 다중 클래스 학습에 해로울 수 있는 가중치 분포의 급격한 변화를 유발할 수 있습니다.
*   **네트워크 사전 훈련**: Cityscapes 데이터셋으로 사전 훈련하면 CamVid에서 6%p 이상의 mIoU 향상을 가져왔으며, Cityscapes의 다양성이 모델의 일반성을 높였습니다.
*   **최신 네트워크에 대한 Deep Decoder의 영향**:
    *   DeepLab v2에 Deep Decoder를 추가했을 때 mIoU가 2.5%p 증가했습니다.
    *   DeepLab v3+에 Deep Decoder를 추가했을 때 mIoU가 1.6%p 증가했습니다. 이는 강력한 기존 모델에서도 Deep Decoder가 유익함을 보여줍니다.
*   **성능 테스트 (런타임)**: TITAN V GPU에서 140ms 미만(7 FPS)의 빠른 순방향 처리 시간을 보였습니다. 인코더 블록 교체(DPDB -> Inverted Residual) 및 디코더 크기 축소를 통해 47ms(21 FPS)까지 최적화 가능함을 보여주며, 이는 로봇 애플리케이션에 적합함을 시사합니다.

**광학 흐름 증강 결과**:
*   DD-Net에 광학 흐름을 추가했을 때 Cityscapes 데이터셋에서 mIoU가 약 1.5%p 향상되었습니다.
*   하늘, 표지판, 보행자와 같은 특정 클래스에서 6%p 이상의 큰 폭의 개선이 관찰되었습니다. 이는 움직임 관련 클래스가 흐름 정보로부터 큰 이점을 얻을 수 있음을 나타냅니다.

## 🧠 Insights & Discussion
*   **Deep Decoder의 효율성**: 제안된 Deep Decoder는 기존 단일 인코더-디코더 모델의 한계를 극복하고, 더 많은 정보를 효과적으로 캡처하며, 거짓 양성(false positive) 검출을 줄이고, 깊은 구조에서도 효율적인 아키텍처를 제공합니다.
*   **스킵 연결의 중요성**: 후방 및 스택형 잔차 스킵 연결은 네트워크 내 정보 흐름을 크게 개선하여 분할 성능 향상에 기여합니다.
*   **동적 가중치 함수의 효과**: 클래스 불균형 문제에 대한 효과적인 해결책을 제시하며, 특히 소수 클래스에 대한 네트워크의 학습 능력을 향상시킵니다.
*   **사전 훈련의 가치**: Cityscapes와 같은 대규모 및 다양한 데이터셋에서의 사전 훈련은 모델의 특징 표현을 풍부하게 하여 성능을 크게 개선합니다.
*   **범용성 및 확장성**: Deep Decoder는 DeepLab v2/v3+와 같은 최신 분할 아키텍처에 통합되어도 성능 향상을 이끌어낼 수 있음을 보여주며, 이는 제안된 디코더의 일반성을 입증합니다.
*   **실시간 적용 가능성**: 최적화된 DD-Net 버전은 로봇 애플리케이션의 계산 제약 조건을 충족할 수 있는 실시간 프레임 속도를 달성합니다.
*   **다중 모달리티의 잠재력**: 광학 흐름과 같은 추가적인 모션 정보가 의미론적 분할 성능을 더욱 향상시킬 수 있음을 입증했으며, 특히 움직이는 객체에 대한 분할에 유용합니다.

**제한 사항**: Gatech 데이터셋과 같이 잘못 주석된 데이터셋의 경우, 추가 스킵 연결이 정량적 측정에는 부정적인 영향을 미칠 수 있으나, 정성적으로는 더 나은 예측을 제공할 수 있습니다. 또한, 특정 데이터셋의 단조로운 모션 패턴은 광학 흐름 증강의 잠재력을 완전히 발휘하지 못하게 할 수 있습니다.

## 📌 TL;DR
기존 단일 인코더-디코더 네트워크의 의미론적 분할 성능 한계를 극복하기 위해, 본 논문은 여러 개의 얕은 네트워크와 새로운 후방 및 스택형 잔차 스킵 연결을 특징으로 하는 **Deep Decoder (DD)** 아키텍처를 제안합니다. 또한, 소수 클래스에 대한 학습을 강화하기 위한 **동적 가중치 함수**를 도입했습니다. 제안된 DD-Net은 CamVid, Gatech, Freiburg Forest 데이터셋에서 최첨단 성능을 달성했으며, DeepLab v2/v3+와 같은 기존 SOTA 모델에 통합될 때도 일관된 성능 향상을 보였습니다. 추가적으로, 광학 흐름 정보를 보완적으로 활용하여 분할 정확도를 더욱 높일 수 있음을 입증했습니다. 이 연구는 효율적이고 정확한 의미론적 분할을 위한 새로운 디코더 디자인의 중요성을 강조하며, 특히 로봇 공학 분야에 중요한 실시간 처리 능력을 갖춘 최적화된 버전을 제공합니다.