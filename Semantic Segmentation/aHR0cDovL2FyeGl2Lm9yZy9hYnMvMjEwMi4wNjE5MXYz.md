# Unsupervised Semantic Segmentation by Contrasting Object Mask Proposals

Wouter Van Gansbeke, Simon Vandenhende, Stamatios Georgoulis, Luc Van Gool

## 🧩 Problem to Solve

기존의 지도학습 방식은 픽셀 단위의 정밀한 레이블링에 많은 시간과 비용이 소요됩니다. 이를 해결하기 위한 비지도 학습 방법은 아직 미개척 분야이며, 다음과 같은 한계가 있었습니다:

* 대부분의 연구가 작은 규모의 데이터셋이나 특정 시각 도메인(예: 위성 이미지에서 하늘과 식물 분리)에 국한되었습니다.
* 프록시 태스크(proxy task)나 종단간(end-to-end) 클러스터링에 의존했는데, 이는 저수준 이미지 특징(색상, 대비 등)에 취약하거나, 이미지 레벨의 정보 학습에 그쳐 픽셀 간 의미론적 차이를 구분하지 못하는 문제가 있었습니다.
* 특히 PASCAL과 같은 복잡하고 다양한 대규모 데이터셋에서 완전한 비지도 의미론적 분할을 수행하는 선행 연구가 부족했습니다.

## ✨ Key Contributions

* **새로운 2단계 프레임워크 제안**: 프록시 태스크나 종단간 클러스터링 방식에서 벗어나, 사전 결정된 중간 수준의 시각적 프라이어(object mask proposal)를 활용하여 픽셀 임베딩을 학습하는 프레임워크인 MaskContrast를 제안했습니다.
* **중간 수준 시각적 프라이어의 중요성 입증**: 객체 레벨 정보를 포함하는 중간 수준 프라이어가 저수준 시각적 단서(예: 경계선 감지)보다 의미론적으로 더 유용하다는 점을 강조하고 실험적으로 입증했습니다.
* **PASCAL 데이터셋에서의 비지도 학습 가능성**: 완전한 비지도 설정에서 PASCAL과 같은 도전적인 데이터셋에서 의미론적 분할 작업을 해결할 수 있는 최초의 방법론을 제시했습니다.
* **높은 전이 학습 성능**: 학습된 표현이 다른 데이터셋(COCO, DAVIS)에도 잘 전이되어, 중간 수준 시각적 프라이어가 자가 지도 표현 학습에 유용함을 보였습니다.

## 📎 Related Works

* **비지도 의미론적 분할**:
  * **종단간 클러스터링**: [36, 57]과 같은 연구들은 증강된 뷰 간의 이산 상호 정보(discrete mutual information)를 최대화하여 클러스터링 함수를 학습했으나, 작은 규모의 데이터셋에만 적용되었습니다.
  * **경계 기반 학습**: [31, 97]은 경계선에서 얻은 세그먼트를 사용하여 픽셀 임베딩을 학습했으나, 외부 감독(ImageNet 사전 학습, 경계선 주석)에 의존하거나 오프라인 클러스터링으로 이산 레이블을 얻기 어려웠습니다.
* **표현 학습 (프리텍스트 태스크)**: 이미지 채색 [32, 42, 96], 컨텍스트 예측 [19, 51], 직소 퍼즐 해결 [53, 55], 이미지 생성 [65], 클러스터링 [2, 8, 84], 노이즈 예측 [6], 인스턴스 판별 [80] 등 다양한 프리텍스트 태스크를 통해 시각적 표현을 학습했습니다. 본 논문은 이러한 프록시 태스크를 피합니다.
* **픽셀 레벨 표현 학습**: 이미지 레벨 표현 학습과 유사하게, 이미지 채색 [32, 42, 89, 96]이나 광학 흐름 [49, 90]과 같은 프록시 태스크를 통해 픽셀 레벨 표현을 학습했습니다. 본 논문은 프록시 태스크를 사용하지 않습니다.

## 🛠️ Methodology

제안된 **MaskContrast** 방법은 두 단계로 구성됩니다:

1. **객체 마스크 제안(Object Mask Proposals) 생성**:
    * **문제점**: 기존 프록시 태스크(예: 색상화)는 의미론과 무관한 저수준 특징에 민감할 수 있습니다.
    * **접근 방식**: 이러한 한계를 극복하기 위해 프록시 태스크를 사용하지 않고, 객체를 포함할 가능성이 높은 "객체 마스크 제안"을 추출합니다. 이 마스크는 픽셀 그룹화의 프라이어(prior) 역할을 합니다.
    * **마스크 획득**: 비지도 살리언시 추정기(unsupervised saliency estimator, 예: DeepUSPS [52])를 사용하여 레이블 없는 데이터셋에서 객체 마스크를 추출합니다. 이는 외부 감독 없이도 다양한 데이터셋에 잘 전이됩니다.

2. **살리언트 객체 대비를 통한 픽셀 임베딩 학습 (MaskContrast)**:
    * **목표**: 신경망 $\Phi_{\theta}: X \rightarrow Z$를 사용하여 이미지의 각 픽셀 $i$를 $D$-차원 정규화된 하이퍼스피어 상의 점 $z_i$로 매핑하는 픽셀 임베딩 함수를 학습합니다.
    * **MaskContrast 손실 함수**:
        * **끌어당기는 힘 (Pull-force)**: 동일한 객체 마스크에 속하는 픽셀 $i$와 $j$의 임베딩 $z_i, z_j$ 간의 유사도를 최대화합니다. 실제로는 픽셀 $z_i$와 해당 객체 마스크의 평균 임베딩 $z_{M_{X^+}}$ 간의 유사도를 최대화합니다. 여기서 $z_{M_n} = \frac{1}{|M_n|} \sum_{i \in M_n} z_i$ 입니다.
        * **밀어내는 힘 (Push-force)**: 임베딩 공간에서 모드 붕괴(mode collapse)를 방지하고, 시각적으로 유사한 객체 픽셀은 가깝게, dissimilar한 객체 픽셀은 멀리 매핑되도록 합니다. 이는 증강된 객체 뷰를 긍정 쌍으로, 다른 객체 뷰를 부정 쌍으로 사용하는 대조 학습(contrastive learning)으로 구현됩니다.
        * **픽셀 단위 손실 ($L_i$)**: 각 전경 픽셀 $i$에 대해 다음과 같이 정의됩니다:
            $$L_i = -\log \frac{\exp(z_i \cdot z_{M_{X^+}}/\tau)}{\sum_{k=0}^K \exp(z_i \cdot z_{M_{X_k^-}}/\tau)}$$
            여기서 $z_{M_{X^+}}$는 긍정 샘플 객체 마스크의 평균 임베딩, $z_{M_{X_k^-}}$는 부정 샘플 객체 마스크의 평균 임베딩이며, $\tau$는 온도 파라미터입니다.
        * **보조 살리언시 예측 헤드**: 배경 픽셀은 대조 학습에 사용되지 않으므로, 네트워크가 픽셀 임베딩을 단일 벡터로 붕괴시키는 것을 막기 위해 별도의 선형 헤드를 통해 살리언시 마스크를 예측하여 특징 공간을 정규화합니다.
    * 이 최적화 목표는 픽셀 소유권을 기반으로 픽셀 임베딩의 정렬을 최적화하고, 하이퍼스피어 $Z$ 상에 픽셀 임베딩을 균일하게 확산시키는 효과를 가집니다.

## 📊 Results

* **PASCAL 데이터셋 성능**:
  * **선형 분류기 (Linear Classifier)**: 기존 이미지 레벨 대조 학습(MoCo v2: 45.0% mIoU), 클러스터링 기반(IIC: 28.0% mIoU), 프록시 태스크 기반(Colorization: 25.5% mIoU) 방법들을 크게 능가했습니다. 비지도 살리언시 모델 기반 MaskContrast는 58.4% mIoU, 지도 살리언시 모델 기반 MaskContrast는 63.9% mIoU를 달성했습니다.
  * **K-Means 클러스터링**: MaskContrast는 PASCAL에서 K-Means를 사용하여 픽셀 임베딩을 의미론적 그룹으로 성공적으로 클러스터링할 수 있었습니다 (비지도 살리언시: 35.0% mIoU, 지도 살리언시: 44.2% mIoU). 이는 다른 선행 연구들이 10% 미만의 성능을 보인 것과 대조적입니다.
  * **의미론적 세그먼트 검색**: MoCo v2 (48.0%) 대비 MaskContrast (비지도 살리언시: 53.4%) 및 (지도 살리언시: 62.3%)로 7개 클래스에서 최첨단 성능을 달성했습니다.
* **전이 학습 (Transfer Learning)**:
  * MaskContrast는 ImageNet에서 사전 학습된 후 PASCAL, COCO, DAVIS-2016과 같은 새로운 데이터셋으로 전이될 때 뛰어난 성능 향상을 보였습니다. 예를 들어, COCO에서 MoCo v2의 35.2% mIoU를 MaskContrast (비지도 살리언시)가 45.0% mIoU로 향상시켰습니다.
  * DAVIS-2016 비디오 객체 분할 태스크에서도 MoCo v2의 77.1% J_m을 78.0% (비지도 살리언시) 및 82.0% (지도 살리언시)로 향상시키며 일반화 능력을 입증했습니다.
* **반지도 학습 (Semi-Supervised Learning)**:
  * MaskContrast는 제한된 레이블 데이터(1%, 2%, 5%, 12.5%, 100%)로 PASCAL에서 미세 조정(fine-tuning)할 때 사전 학습 전략으로 유용함을 보였습니다. 예를 들어, 1% 레이블로 미세 조정 시, ImageNet 사전 학습 모델(43.4% mIoU)보다 MaskContrast (비지도 살리언시)가 50.5% mIoU로 더 높은 성능을 보였습니다.

## 🧠 Insights & Discussion

* **의미론적 정보 학습**: MaskContrast의 2단계 프레임워크와 중간 수준 시각적 프라이어는 모델이 저수준 이미지 특징에 의존하는 것을 방지하고, 더 의미론적으로 풍부한 픽셀 임베딩을 학습하게 합니다.
* **비지도 분할의 선구적인 성과**: PASCAL과 같은 복잡한 데이터셋에서 완전한 비지도 설정으로 의미론적 분할 작업을 해결한 것은 중요한 진전입니다.
* **다양한 활용 가능성**: 학습된 픽셀 임베딩은 의미론적 세그먼트 검색, 전이 학습, 반지도 미세 조정 등 다양한 작업에 효과적으로 활용될 수 있음을 보여주었습니다.
* **한계점**: 객체 마스크 제안이 살리언시 추정기에 의해 획득되므로, 이미지당 감지할 수 있는 객체의 수가 제한될 수 있습니다. 이미지당 더 많은 객체가 존재하는 도전적인 데이터셋을 다루기 위해서는 추가적인 센서 데이터 [69]나 다른 마스크 추출 기법 [62]을 탐색할 필요가 있습니다.

## 📌 TL;DR

본 논문은 완전한 비지도 환경에서 의미론적 분할을 수행하기 위한 **MaskContrast**라는 새로운 2단계 프레임워크를 제안합니다. 이 방법은 먼저 비지도 살리언시 추정기를 사용하여 이미지에서 **객체 마스크 제안**을 추출하고(중간 수준 시각적 프라이어), 이를 기반으로 **대조 학습(contrastive learning)**을 통해 픽셀 임베딩을 학습합니다. 이 프라이어는 모델이 저수준 특징에 갇히는 것을 방지하고, 픽셀 임베딩이 의미론적으로 의미 있는 정보를 인코딩하도록 합니다. 실험 결과, MaskContrast는 PASCAL 데이터셋에서 선형 분류기, K-Means 클러스터링, 세그먼트 검색 등 다양한 평가 프로토콜에서 기존 비지도 및 자가 지도 방법들을 크게 능가했으며, COCO 및 DAVIS-2016 데이터셋으로의 뛰어난 전이 학습 및 반지도 미세 조정 성능을 입증하여 비지도 의미론적 분할 분야의 새로운 지평을 열었습니다.
