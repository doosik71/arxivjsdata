# Constrained Convolutional Neural Networks for Weakly Supervised Segmentation
Deepak Pathak, Philipp Krähenbühl, Trevor Darrell

## 🧩 Problem to Solve
기존의 CNN 기반 컴퓨터 비전 모델은 대규모의 완벽하게 레이블링된(fully supervised) 훈련 데이터, 특히 픽셀 단위의 상세한 레이블에 크게 의존합니다. 하지만 의미론적 분할(semantic segmentation)과 같은 구조화된 예측 문제의 경우, 픽셀 단위 레이블을 얻는 것은 비용이 많이 들고 시간이 오래 걸립니다. 이미지 레벨 태그나 바운딩 박스 주석과 같은 약한(weak) 수준의 주석은 획득 비용이 적지만, 이를 통해 픽셀 단위 레이블을 학습하는 것은 지역 최적점(local optima)에 빠지기 쉽다는 도전 과제를 안고 있습니다. 이 논문은 이러한 약한 수준의 주석(image-level tags)으로부터 밀집된 픽셀 단위의 레이블링을 학습하는 방법을 제안합니다.

## ✨ Key Contributions
*   CNN의 출력 공간(예측 레이블 분포)에 대한 임의의 선형 제약 조건(linear constraints)을 최적화하기 위한 새로운 손실 함수를 사용하는 CCNN(Constrained CNN) 방법을 제안합니다.
*   제안하는 손실 함수는 최적화하기 쉽고 표준 확률적 경사 하강법(SGD)에 직접 통합될 수 있습니다.
*   훈련 목표를 선형 모델에 대한 이중 볼록(biconvex) 최적화로 구성한 다음, 이를 비선형 심층 네트워크로 확장하는 핵심 아이디어를 사용합니다. 이는 제약 조건을 직접 네트워크 출력에 적용하는 대신, 잠재 확률 분포(latent probability distribution)를 도입하여 네트워크 출력이 이 잠재 분포를 따르도록 유도함으로써 가능합니다.
*   약한 감독 방식의 의미론적 이미지 분할(weakly supervised semantic image segmentation)에서 최신(state-of-the-art) 성능을 달성합니다.
*   약간의 추가적인 감독(예: 객체 크기 추정)을 추가하면 학습 알고리즘의 성능이 크게 향상될 수 있음을 보여줍니다.
*   제안된 프레임워크는 일반적이며 다양한 형태의 약한 감독을 통합할 수 있습니다.

## 📎 Related Works
*   **약한 감독 학습(Weakly Supervised Learning) 및 다중 인스턴스 학습(Multiple Instance Learning, MIL):** MI-SVM [2], LSVM [10]과 같은 이전 연구들은 종종 비볼록(non-convex) 문제에 직면하며 초기화에 민감합니다. 객체 탐지(object detection) 분야에 적용되었습니다 [31, 34].
*   **약한 감독 분할(Weak Segmentation) 및 장면 분석(Scene Parsing):** 전통적으로 그래픽 모델 [32, 33, 37]을 사용했습니다.
*   **CNN 기반 약한 감독 분할:** Pinheiro et al. [26] 및 Pathak et al. [25]은 MIL 프레임워크를 CNN 기반 의미론적 분할로 확장하여 반복적으로 예측을 강화합니다. 이들은 초기화에 민감하며 사전 훈련된 분류기가 필요합니다. CCNN은 초기화에 덜 민감하며 무작위 초기화에서도 좋은 솔루션을 찾습니다.
*   **EM-Adapt [24]:** MIL 프레임워크에 적응형 바이어스(adaptive bias)를 포함합니다. 본 논문에서는 EM-Adapt가 제약 최적화의 특수 사례임을 보여주며, CCNN이 더 일반적인 선형 제약 조건을 적용하여 더 나은 성능을 달성함을 입증합니다.
*   **인공 신경망을 이용한 제약 최적화:** Platt et al. [27]은 신경망 출력에 대한 등식 제약을 최적화했지만, 결과 목표 함수가 비볼록하여 직접 최소화가 어려웠습니다. CCNN은 볼록(convex) 최적화와 경사 기반(gradient-based) 최적화를 번갈아 수행합니다.
*   **일반화된 기대(Generalized Expectation) [22] 및 사후 정규화(Posterior Regularization) [12]:** 자연어 처리(NLP) 분야에서 파라메트릭 모델이 특정 기대 제약을 충족하도록 훈련시키는 것과 유사합니다. 특히 Ganchev et al. [12]의 접근 방식과 유사한 이중 공간(dual space)에서의 목적 함수를 사용합니다.

## 🛠️ Methodology
1.  **문제 정의:** 픽셀 단위 레이블링을 위해 CNN의 파라미터 $\theta$를 찾는 것이 목표입니다. 이 픽셀 단위 레이블링 $\tilde{Q}_{\text{I}}$는 각 이미지 $I$에 대해 주어진 선형 제약 조건 $A_{\text{I}}\tilde{Q}_{\text{I}} \ge \tilde{b}_{\text{I}}$를 만족해야 합니다.
2.  **잠재 확률 분포 도입:** 위 문제는 네트워크 파라미터 $\theta$에 대해 비볼록이므로, 최적화를 효율적으로 수행하기 위해 의미론적 레이블 $X$에 대한 잠재 확률 분포 $P(X)$를 도입합니다. 제약 조건은 $P(X)$에 적용하고, 네트워크 출력 $Q(X|\theta)$는 $P(X)$와 KL-diver전스(KL-divergence)를 최소화하도록 유도합니다. 즉, 다음 목적 함수를 최적화합니다.
    $$ \min_{\theta, P} D(P(X)||Q(X|\theta)) \\ \text{subject to } A\tilde{P} \ge \tilde{b}, \sum_X P(X) = 1 $$
    여기서 $D$는 KL-diver전스이며, $P$는 잠재 분포, $Q$는 CNN 출력 분포입니다.
3.  **교대 최적화(Alternating Optimization):**
    *   **잠재 분포 $P$ 최적화(CNN 파라미터 $\theta$ 고정 시):** 이 문제는 선형 제약 조건이 있는 볼록 최적화 문제입니다. 그 이중 함수 $L(\lambda) = \lambda^{\text{T}}\tilde{b} - \sum_{\text{i=1}}^{\text{n}} \log (\sum_{\text{l} \in L} \exp(f_{\text{i}}(l;\theta) + A_{\text{i;l}}^{\text{T}}\lambda))$를 투영된 경사 상승법(projected gradient ascent)을 사용하여 최적화합니다. 이는 일반적으로 50회 미만의 반복으로 빠르게 수렴합니다.
    *   **CNN 파라미터 $\theta$ 최적화(잠재 분포 $P$ 고정 시):** 이 문제는 표준 교차 엔트로피 손실 $L(\theta) = -\sum_{\text{i}} \sum_{x_{\text{i}}} p_{\text{i}}(x_{\text{i}}) \log q_{\text{i}}(x_{\text{i}}|\theta)$로 환원됩니다. 이는 Caffe [17]에 구현된 대로 역전파(back-propagation)와 확률적 경사 하강법(SGD)을 사용하여 최적화됩니다. 실제로는 SGD의 각 스텝에서 새로운 잠재 분포 $P$를 추론하며, 이는 더 빠른 수렴을 이끌어냅니다.
4.  **슬랙 변수(Slack Variable)를 통한 제약 조건 처리:** 모든 제약 조건이 동시에 충족 가능하지 않을 수 있으므로, 선형 제약 조건에 슬랙 변수 $\xi \in \mathbb{R}^{\text{k}}$와 힌지 손실(hinge loss) $\beta^{\text{T}}\xi$를 추가하여 제약 조건을 완화합니다: $A\tilde{P} \ge \tilde{b} - \xi, \xi \ge 0$. 이는 제약 조건의 충족 가능성을 보장하고, 상충하는 제약 조건들 사이의 균형을 조절합니다.
5.  **의미론적 분할을 위한 특정 제약 조건:**
    *   **억제 제약(Suppression constraint):** 이미지에 존재하지 않는 레이블 $l$에 대해 $\sum_{\text{i=1}}^{\text{n}} p_{\text{i}}(l) \le 0$.
    *   **전경 제약(Foreground constraint):** 이미지에 존재하는 레이블 $l$에 대해 $a_{\text{l}} \le \sum_{\text{i=1}}^{\text{n}} p_{\text{i}}(l)$. 기본값으로 $a_{\text{l}} = 0.05n$ (n은 출력 픽셀 수)를 사용합니다.
    *   **배경 제약(Background constraint):** 배경 레이블(0)에 대해 $a_{\text{0}} \le \sum_{\text{i=1}}^{\text{n}} p_{\text{i}}(0) \le b_{\text{0}}$. 기본값으로 $a_{\text{0}} = 0.3n, b_{\text{0}} = 0.7n$을 사용합니다.
    *   **크기 제약(Size constraint, 추가 감독):** 객체 클래스가 이미지의 10%보다 큰 경우 $a_{\text{l}} = 0.1n$으로 설정하고, 작은 클래스의 경우 $\sum_{\text{i=1}}^{\text{n}} p_{\text{i}}(l) \le b_{\text{l}}$ (예: $b_{\text{l}} < 0.01n$)와 같은 상한 제약을 추가합니다.
6.  **구현 상세:** VGG 16계층 네트워크 아키텍처를 기반으로 하며, ImageNet으로 사전 훈련된 후 FCN-8s [4] 방식으로 Pascal VOC에 파인튜닝됩니다. 배치 크기 1, 모멘텀 0.99, 초기 학습률 1e-6으로 60000 이터레이션 동안 훈련됩니다. 추론 시에는 선택적으로 완전 연결 조건부 무작위장(Fully Connected CRF) 모델 [18]을 사용하여 최종 분할을 정제할 수 있습니다.

## 📊 Results
*   **이미지 레벨 태그만을 사용한 학습:** Pascal VOC 2012 검증 세트에서 CCNN은 다른 약한 감독 분할 방법(MIL-FCN [25], MIL-Base [26], EM-Adapt [24])을 큰 차이로 능가했습니다. CRF를 적용한 CCNN은 35.3%의 mIoU(mean Intersection over Union)를 달성하여 EM-Adapt의 33.8% mIoU보다 높은 성능을 보였습니다.
*   **추가 감독(Additional Supervision)과 함께 학습:**
    *   원본 이미지의 무작위 잘라내기(random crops)를 사용한 CCNN은 36.4% mIoU를 달성하여 EM-Adapt(36.0% mIoU)를 약간 상회했습니다.
    *   "1비트 크기 정보"(객체 클래스가 이미지의 10%를 초과하는지 여부)와 같은 추가적인 단순 제약 조건을 통합했을 때, CCNN의 정확도는 CRF 적용 시 42.4% mIoU로 극적으로 증가했습니다. 이는 CCNN이 더 일반적인 제약 조건을 효과적으로 활용할 수 있음을 보여줍니다.
*   **Pascal VOC 2012 테스트 세트:** 이미지 태그와 크기 제약을 함께 사용한 CCNN(CRF 튜닝)은 45.1% mIoU를 기록하여, 이미지 태그만 사용한 경우(35.6% mIoU)보다 훨씬 높았으며, 완전 감독 방식(예: DeepLab-CRF [4]의 66.4% mIoU)에 더 가까워지는 잠재력을 보였습니다.
*   **파라미터 민감도:** 슬랙 변수 덕분에 CCNN은 제약 조건 경계 값의 정확한 설정에 매우 둔감하며, 모든 파라미터에 대해 평균 0.73%의 낮은 정확도 표준 편차를 보였습니다.
*   **준감독 학습(Semi-Supervised Learning):** CCNN은 추가적인 완전 감독 이미지 데이터가 제공될 때도 효과적으로 활용하여 성능을 향상시키는 것으로 나타났습니다.
*   **바운딩 박스 감독(Bounding Box Supervision):** 바운딩 박스 제약 조건만으로 54% IoU를 달성하여, 비슷한 수준의 다른 기본 모델(52.3%)과 경쟁적이지만, 픽셀 레벨 분할 정보를 더 적극적으로 활용하는 정교한 시스템(58.5-62.0%)에는 미치지 못했습니다.

## 🧠 Insights & Discussion
*   **제약 조건의 효과:** 선형 제약 조건은 약한 감독 설정에서 원하는 출력 공간을 자연스럽게 설명하는 효과적인 방법임을 입증했습니다. 이는 CNN이 요구하는 강력한 감독의 양을 줄일 수 있습니다.
*   **강건성(Robustness):** 제안된 CCNN 최적화는 이전의 MIL 기반 CNN 접근 방식(예: MIL-FCN)에 비해 초기화에 덜 민감하며, 임의의 무작위 초기화에서도 좋은 솔루션을 복구할 수 있습니다. 슬랙 변수는 제약 조건 파라미터 선택에 대한 강건성에 기여합니다.
*   **일반성(Generality):** CCNN 프레임워크는 일반적이므로 단순 이미지 태그를 넘어 객체 크기, 바운딩 박스 정보 등 다양한 형태의 약한 감독을 위한 임의의 선형 제약 조건을 통합할 수 있습니다.
*   **완전 감독과의 성능 격차:** CCNN은 약한 감독 방법론들 사이에서 성능 격차를 크게 줄였지만, 여전히 완전 감독 최신 모델과는 상당한 성능 격차가 존재합니다. 이 격차를 더 줄이려면 픽셀 단위의 분할 정보(제한적일지라도)를 더 강력하게 활용하는 것이 핵심으로 보입니다.
*   **계산 효율성:** 단일 이미지에 대한 제약 최적화는 CPU에서 30ms 미만으로 빠르며, 총 훈련 시간도 다른 방법론들과 비교할 때 경쟁력 있습니다.

## 📌 TL;DR
*   **문제:** 픽셀 단위 레이블링이 필요한 의미론적 분할은 데이터 레이블링 비용이 비쌉니다. 이미지 태그와 같은 약한 감독은 저렴하지만 효과적으로 활용하기 어렵습니다.
*   **방법:** CCNN은 CNN의 출력에 선형 제약 조건을 적용하는 새로운 손실 함수를 제안합니다. 비볼록 문제를 해결하기 위해, 제약 조건을 만족하는 잠재 확률 분포를 최적화하고, CNN이 이 분포를 따르도록 교대 볼록 및 경사 하강 단계를 통해 훈련합니다. 슬랙 변수는 제약 조건 간의 충돌을 유연하게 처리합니다.
*   **결과:** CCNN은 이미지 레벨 태그만으로 약한 감독 의미론적 분할에서 최신 성능을 달성합니다. 객체 크기 정보와 같은 최소한의 추가 감독을 통해 성능이 크게 향상되며, 이 방법은 파라미터 선택에 강건하고 표준 SGD에 잘 통합됩니다.