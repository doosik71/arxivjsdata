{
  "url": "http://arxiv.org/abs/1908.06391v2",
  "title": "PANet: Few-Shot Image Semantic Segmentation with Prototype Alignment",
  "authors": "Kaixin Wang, Jun Hao Liew, Yingtian Zou, Daquan Zhou, Jiashi Feng",
  "year": 2019,
  "abstract": "Despite the great progress made by deep CNNs in image semantic segmentation,\nthey typically require a large number of densely-annotated images for training\nand are difficult to generalize to unseen object categories. Few-shot\nsegmentation has thus been developed to learn to perform segmentation from only\na few annotated examples. In this paper, we tackle the challenging few-shot\nsegmentation problem from a metric learning perspective and present PANet, a\nnovel prototype alignment network to better utilize the information of the\nsupport set. Our PANet learns class-specific prototype representations from a\nfew support images within an embedding space and then performs segmentation\nover the query images through matching each pixel to the learned prototypes.\nWith non-parametric metric learning, PANet offers high-quality prototypes that\nare representative for each semantic class and meanwhile discriminative for\ndifferent classes. Moreover, PANet introduces a prototype alignment\nregularization between support and query. With this, PANet fully exploits\nknowledge from the support and provides better generalization on few-shot\nsegmentation. Significantly, our model achieves the mIoU score of 48.1% and\n55.7% on PASCAL-5i for 1-shot and 5-shot settings respectively, surpassing the\nstate-of-the-art method by 1.8% and 8.6%."
}