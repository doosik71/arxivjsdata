# Learning to Segment Object Candidates

Pedro O. Pinheiro, Ronan Collobert, Piotr Dollár

## 🧩 Problem to Solve

최신 객체 탐지 시스템은 (1) 객체 제안(object proposal)을 최대한 효율적으로 예측하고, (2) 이 후보 제안들을 객체 분류기에 전달하는 두 가지 핵심 단계에 의존합니다. 이 논문은 기존 객체 제안 방법론의 한계, 특히 엣지나 슈퍼픽셀과 같은 **로우-레벨 세그멘테이션 기능에 의존**하는 문제와 **제공하는 정보가 바운딩 박스로 제한**되어 있다는 점을 해결하고자 합니다. 본 연구는 딥러닝 기반의 새로운 접근 방식을 통해 **이미지 픽셀로부터 직접적으로 고품질의 클래스에 구애받지 않는 세그멘테이션 마스크 제안**을 생성하고, 동시에 해당 제안의 객체성을 평가하는 **점수(likelihood score)를 예측**함으로써, 더 적은 수의 제안으로도 높은 재현율(recall)을 달성하는 것을 목표로 합니다.

## ✨ Key Contributions

* **차별적인 컨볼루션 네트워크 기반의 객체 제안 방식 제안**: 기존의 로우-레벨 세그멘테이션(엣지, 슈퍼픽셀 등)에 의존하지 않고, 이미지 픽셀로부터 직접 클래스에 구애받지 않는(class-agnostic) 세그멘테이션 마스크를 학습하여 생성하는 새로운 프레임워크인 DeepMask를 소개합니다.
* **마스크와 객체 점수의 동시 학습**: 단일 컨볼루션 네트워크 내에서 세그멘테이션 마스크 예측과 해당 패치가 객체를 포함할 가능성을 나타내는 객체 점수 예측을 동시에 수행합니다.
* **월등한 성능 향상**: 최첨단 객체 제안 알고리즘보다 현저히 적은 수의 제안만으로도 훨씬 높은 객체 재현율을 달성함을 PASCAL VOC 및 MS COCO 데이터셋에서 입증했습니다. 특히, Fast R-CNN과 결합 시 적은 수의 DeepMask 제안으로도 기존 방법보다 높은 mAP를 달성합니다.
* **미학습 카테고리에 대한 일반화 능력**: 학습 시 보지 못했던 객체 카테고리에 대해서도 모델의 세그멘테이션 브랜치가 강력한 일반화 능력을 보임을 입증했습니다.
* **효율적인 전체 이미지 추론**: 훈련된 모델을 전체 이미지에 다중 스케일로 밀도 있게 적용하여 세그멘테이션 마스크와 객체 점수를 효율적으로 생성할 수 있습니다.

## 📎 Related Works

* **객체 탐지 프레임워크**: R-CNN [10], Fast R-CNN [9], SPP-Net [12, 15]과 같이 객체 제안을 전처리 단계로 활용하는 2단계 접근 방식.
* **기존 객체 제안 방법**:
  * **객체성 점수 매기기(Objectness scoring)**: Alexe et al. [1], EdgeBoxes [34].
  * **시드 세그멘테이션(Seed segmentation)**: Geodesic [16], RIGOR [14].
  * **슈퍼픽셀 병합(Superpixel merging)**: SelectiveSearch [31], MCG [24].
  * 이전의 세그멘테이션 마스크 생성 방식들은 대부분 슈퍼픽셀 또는 엣지와 같은 로우-레벨 세그멘테이션에 의존합니다.
* **컨볼루션 네트워크 기반 객체 제안**:
  * Multibox [6, 30]: 컨볼루션 네트워크를 사용하여 바운딩 박스 객체 제안을 생성하는 방식. DeepMask는 바운딩 박스 대신 세그멘테이션 마스크를 생성한다는 점에서 차이가 있습니다.
  * DeepBox [19]: EdgeBox에서 생성된 제안을 컨볼루션 네트워크로 재랭킹하는 방식.
  * Faster R-CNN의 Region Proposal Networks (RPN) [25]: DeepMask와 동시 연구로, 바운딩 박스 제안을 생성합니다. DeepMask는 바운딩 박스가 아닌 세그멘테이션 마스크를 생성한다는 점에서 구별됩니다.

## 🛠️ Methodology

본 논문은 "DeepMask"라고 불리는 단일 컨볼루션 네트워크를 사용하여 객체 제안을 생성합니다.

1. **네트워크 아키텍처 (DeepMask)**:
    * **공유 피처 추출 레이어**: ImageNet [5]으로 사전 학습된 VGG-A 아키텍처 [27]를 사용합니다. 마지막 완전 연결 레이어와 마지막 max-pooling 레이어를 제거하여 공간 정보를 보존하며, 입력 대비 $16 \times$ 다운샘플링된 $512 \times \frac{h}{16} \times \frac{w}{16}$ 크기의 피처 맵을 생성합니다.
    * **세그멘테이션 브랜치**: 공유 레이어의 피처 맵을 입력으로 받습니다.
        * $1 \times 1$ 컨볼루션 레이어(ReLU 포함) 후, 픽셀 분류 레이어를 사용하여 세그멘테이션 마스크를 예측합니다.
        * 픽셀 분류 레이어는 'low-rank' 방식(비선형성 없는 두 개의 선형 레이어)으로 구현되어 파라미터 수를 대폭 줄이면서 전체 피처 맵의 정보를 활용합니다.
        * 출력 마스크는 $56 \times 56$ 크기로 생성된 후, bilinear 업샘플링을 통해 원래 입력 패치 해상도($224 \times 224$)로 변환됩니다. 이 브랜치는 패치의 중심에 있는 **단일 객체**에 대한 마스크를 예측합니다.
    * **스코어링 브랜치**: 공유 레이어의 피처 맵을 입력으로 받습니다.
        * $2 \times 2$ max-pooling 레이어, 두 개의 완전 연결 레이어(ReLU, Dropout [28] 포함)를 거쳐 최종적으로 단일 '객체성(objectness)' 점수를 출력합니다. 이 점수는 패치에 객체가 **중심에 적절한 스케일로** 포함되어 있는지 여부를 나타냅니다.
2. **공동 학습 (Joint Learning)**:
    * 입력 패치 $x_k$, 바이너리 마스크 $m_k$, 객체 포함 여부 레이블 $y_k \in \{\pm 1\}$의 튜플 $(x_k, m_k, y_k)$로 구성된 학습 데이터를 사용합니다.
    * 손실 함수는 세그멘테이션 브랜치와 스코어링 브랜치 각각에 대한 이진 로지스틱 회귀 손실의 합으로 정의됩니다:
        $$L(\theta) = \sum_{k} \left( \frac{1+y_k}{2w_o h_o} \sum_{ij} \log(1 + e^{-m_{ij}^k f_{ij}^{segm}(x_k)}) + \lambda \log(1 + e^{-y_k f^{score}(x_k)}) \right)$$
        여기서 $f_{ij}^{segm}(x_k)$는 세그멘테이션 네트워크의 예측이고, $f^{score}(x_k)$는 객체 점수입니다. $\lambda = \frac{1}{32}$로 설정됩니다.
    * 세그멘테이션 브랜치의 오류는 $y_k = 1$ (즉, 긍정적인 객체 패치)일 때만 역전파됩니다. 이는 학습 중 보지 못한 객체 카테고리에 대한 일반화에 중요하다고 보고되었습니다.
    * 학습 데이터는 무작위로 지터링(translation, scale deformation, horizontal flip)되어 모델의 강건성을 높입니다.
3. **전체 이미지 추론 (Full Scene Inference)**:
    * 학습된 모델을 전체 이미지에 다중 스케일($2^{-2}$부터 $2^1$까지 $2^{1/2}$ 간격으로)과 다중 위치(16픽셀 스트라이드)에 걸쳐 밀도 있게 적용합니다.
    * 모든 계산은 컨볼루션 방식으로 효율적으로 수행됩니다. 스코어링 브랜치의 출력을 세그멘테이션 브랜치와 해상도를 맞추기 위해 'interleaving trick' [26]이 사용됩니다.
    * 생성된 연속적인 마스크 출력은 임계값(threshold)을 통해 이진 마스크로 변환됩니다.

## 📊 Results

* **월등한 평균 재현율 (AR)**: PASCAL VOC 2007 및 MS COCO 데이터셋에서 바운딩 박스 및 세그멘테이션 제안 모두에서 DeepMask가 기존의 모든 최첨단 방법(EdgeBoxes, SelectiveSearch, Geodesic, Rigor, MCG)보다 훨씬 높은 AR을 달성했습니다.
* **적은 제안 수로 높은 재현율**: DeepMask는 기존 방법들이 유사한 AR을 달성하기 위해 필요한 제안 수보다 **한 자릿수 이상 적은 수의 제안**으로도 높은 AR을 기록했습니다. 예를 들어, COCO에서 DeepMask는 100개의 세그멘테이션 제안으로 0.245의 AR을 달성했지만, 경쟁 방법들은 약 1000개의 제안이 필요했습니다.
* **객체 스케일별 성능**: 모든 모델이 작은 객체에서 성능이 저조했지만, DeepMaskZoom (추가적인 더 작은 스케일 적용)은 특히 작은 객체에서 성능을 향상시켰습니다.
* **정확한 로컬라이제이션**: 대부분의 IoU 임계값에서 DeepMask가 더 높은 재현율을 보였습니다. 다만, 매우 높은 IoU에서는 다른 모델보다 약간 뒤떨어지는 경향이 있는데, 이는 마스크 출력이 다운샘플링된 버전이기 때문일 수 있습니다.
* **일반화 능력**: 학습 중 보지 못한 60개의 COCO 카테고리에 대해 DeepMask20$^*$ (원래 DeepMask의 스코어링 네트워크 사용)은 DeepMask와 거의 동일한 성능을 보였습니다. 이는 세그멘테이션 브랜치가 학습된 카테고리에 제한되지 않고 매우 잘 일반화됨을 시사합니다.
* **객체 탐지 성능 향상**: Fast R-CNN [9]과 결합하여 PASCAL VOC 2007에서 평가했을 때, 100개의 DeepMask 제안으로 68.2% mAP를 달성하여 2000개의 SelectiveSearch 제안(66.9% mAP)을 능가했습니다. 500개의 DeepMask 제안으로는 69.9% mAP까지 향상되었습니다.
* **속도**: COCO 이미지당 평균 1.6초, PASCAL 이미지당 1.2초의 추론 속도를 보였으며, GPU 사용 시 가장 빠른 세그멘테이션 제안 방법들과 경쟁할 만한 수준(예: Geodesic은 ~1초, MCG는 ~30초)입니다.

## 🧠 Insights & Discussion

* **로우-레벨 피처 의존성 탈피**: DeepMask는 기존 객체 제안 방법론의 한계인 엣지, 슈퍼픽셀 등 로우-레벨 세그멘테이션에 대한 의존성 없이, 딥 컨볼루션 네트워크를 통해 이미지 픽셀에서 직접적으로 객체 세그멘테이션 마스크를 학습하고 생성할 수 있음을 성공적으로 입증했습니다. 이는 객체 제안 분야의 패러다임을 전환하는 중요한 통찰입니다.
* **공동 학습의 효율성 및 효과**: 마스크 예측과 객체 점수 예측을 단일 네트워크 내에서 공동으로 학습하는 방식은 모델의 용량을 줄이고 추론 속도를 높이며, 객체 제안의 질을 향상시키는 데 효과적입니다.
* **긍정 샘플 학습의 중요성**: 세그멘테이션 브랜치를 긍정 샘플에 대해서만 학습시키는 전략은 모델이 학습 중 보지 못한 객체 카테고리에 대해 뛰어난 일반화 능력을 발휘할 수 있게 하는 핵심 요인입니다. 이는 네트워크가 "어떤 객체든" 세그멘테이션 마스크를 생성하도록 유도합니다.
* **개선점**: 매우 높은 IoU에서 다른 모델보다 약간 떨어지는 성능은 현재 모델이 다운샘플링된 마스크를 출력하고 있기 때문일 수 있습니다. 향후 다중 스케일 접근 방식이나 스킵 연결(skip connection)을 통해 로컬라이제이션 정확도를 더욱 높일 수 있는 가능성이 있습니다.
* **실용적 의의**: DeepMask는 객체 탐지 시스템의 첫 단계에서 고품질의 세그멘테이션 제안을 효율적으로 제공함으로써, 기존의 바운딩 박스 기반 제안 방식으로는 불가능했던 정교한 객체 이해 및 탐지 성능 향상에 기여할 수 있습니다.

## 📌 TL;DR

DeepMask는 딥 컨볼루션 네트워크를 사용하여 이미지 픽셀로부터 직접 **클래스에 구애받지 않는 세그멘테이션 마스크**와 **객체성 점수**를 동시에 예측하는 새로운 객체 제안 방법입니다. 기존 로우-레벨 세그멘테이션(엣지, 슈퍼픽셀 등)에 의존하지 않고, 훨씬 적은 수의 제안만으로도 **월등히 높은 객체 재현율을 달성**하며, **미학습 카테고리에 대한 강력한 일반화 능력**을 보여줍니다. Fast R-CNN과의 통합을 통해 객체 탐지 성능을 크게 향상시키며, 효율적인 추론 속도를 제공하여 객체 탐지 전처리 단계의 효율성과 정확도를 혁신적으로 개선합니다.
