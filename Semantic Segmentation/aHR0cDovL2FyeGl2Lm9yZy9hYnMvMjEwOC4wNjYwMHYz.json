{
  "url": "http://arxiv.org/abs/2108.06600v3",
  "title": "A Self-Distillation Embedded Supervised Affinity Attention Model for\n  Few-Shot Segmentation",
  "authors": "Qi Zhao, Binghao Liu, Shuchang Lyu, Huojin Chen",
  "year": 2021,
  "abstract": "Few-shot segmentation focuses on the generalization of models to segment\nunseen object with limited annotated samples. However, existing approaches\nstill face two main challenges. First, huge feature distinction between support\nand query images causes knowledge transferring barrier, which harms the\nsegmentation performance. Second, limited support prototypes cannot adequately\nrepresent features of support objects, hard to guide high-quality query\nsegmentation. To deal with the above two issues, we propose self-distillation\nembedded supervised affinity attention model to improve the performance of\nfew-shot segmentation task. Specifically, the self-distillation guided\nprototype module uses self-distillation to align the features of support and\nquery. The supervised affinity attention module generates high-quality query\nattention map to provide sufficient object information. Extensive experiments\nprove that our model significantly improves the performance compared to\nexisting methods. Comprehensive ablation experiments and visualization studies\nalso show the significant effect of our method on few-shot segmentation task.\nOn COCO-20i dataset, we achieve new state-of-the-art results. Training code and\npretrained models are available at https://github.com/cv516Buaa/SD-AANet."
}