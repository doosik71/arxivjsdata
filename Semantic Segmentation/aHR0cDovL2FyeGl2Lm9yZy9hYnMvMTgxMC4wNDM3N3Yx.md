# Learning Deep Representations for Semantic Image Parsing: a Comprehensive Overview

Lili Huang, Jiefeng Peng, Ruimao Zhang, Guanbin Li, Liang Lin

## 🧩 Problem to Solve

의미론적 이미지 파싱은 이미지를 의미론적 영역으로 분해하고 입력의 구조적 표현을 구축하는 것을 목표로 하는 컴퓨터 비전 분야의 근본적이고 오랜 과제입니다. 특히, 최근 딥 러닝 기반의 표현 학습(deep representation learning)이 적용되면서 이 분야는 새로운 발전 단계에 진입했으며, 이 논문은 이러한 딥 러닝 기반 의미론적 이미지 파싱 연구의 전반적인 진행 상황을 종합적으로 정리하고자 합니다.

## ✨ Key Contributions

- **종합적인 개요 제공:** 범주 수준(Category-level) 의미론적 분할, 인스턴스 수준(Instance-level) 의미론적 분할, 그리고 분할을 넘어서(Beyond Segmentation)는 세 가지 레벨의 의미론적 이미지 파싱에 대한 딥 표현 학습 기반 연구를 독특한 관점에서 종합적으로 검토합니다.
- **모델 및 변형 논의:** 각 레벨의 의미론적 분할 태스크에 대한 일반적인 프레임워크와 관련 변형들을 상세히 설명하고, 각 방법론의 장단점을 논의합니다.
- **데이터셋 및 평가 지표 비교:** 다양한 벤치마크 데이터셋(11개)과 평가 지표(6개)에 대한 종합적인 비교 정보를 제공합니다.
- **미래 트렌드 및 과제 탐색:** 의미론적 이미지 파싱의 미래 연구 방향과 도전 과제를 제시합니다.

## 📎 Related Works

이 논문은 딥 러닝 기반 의미론적 이미지 파싱에 대한 서베이 논문으로, 다음과 같은 핵심 선행 연구 및 기술들을 기반으로 합니다.

- **전통적인 수제 특징 (Hand-crafted Features):** SIFT [7], HOG [8], LBP [9] 등은 표현 능력의 한계로 인해 딥 러닝으로 대체되었습니다.
- **딥 러닝 아키텍처:**
  - **합성곱 신경망 (CNNs):** 그리드 구조 데이터에 적합하며, 이미지 분류 [15] 및 의미론적 분할 [12, 13]에서 큰 성공을 거두었습니다.
  - **순환 신경망 (Recurrent Neural Networks - RNNs):** 시퀀스 데이터에 적합하며, LSTM [26]과 같은 변형들이 이미지 캡셔닝 [27] 등에서 효과를 보였습니다.
  - **재귀 신경망 (Recursive Neural Networks - RecNNs):** 계층적 공간 구조 데이터에 적합하며, 자연어 파싱 [16] 및 구조적 의미론적 파싱 [6]에 활용되었습니다.
- **선구적인 심층 모델:**
  - **FCN (Fully Convolutional Networks) [12]:** 범주 수준 의미론적 분할의 기본 아키텍처를 제시했습니다.
  - **DeepLab System [13]:** CNN과 Fully Connected CRF [48]를 통합하여 분할 성능을 향상시켰습니다.
  - **FCIS (Fully Convolutional Instance-aware Semantic Segmentation) [17]:** 인스턴스 수준 분할을 위한 완전 합성곱 엔드-투-엔드 솔루션입니다.
  - **CNN-RNN [6]:** 분할을 넘어선 구조화된 장면 파싱을 위한 모델입니다.
  - **Mask R-CNN [2]:** 인스턴스 분할을 위한 강력하고 유연한 프레임워크입니다.

## 🛠️ Methodology

이 서베이 논문은 딥 러닝 기반 의미론적 이미지 파싱 연구를 세 가지 주요 레벨로 분류하여 각 레벨의 핵심 방법론을 상세히 분석합니다.

1. **범주 수준 의미론적 분할 (Category-Level Semantic Segmentation)**

   - **정의:** 각 픽셀에 단일 객체 범주 레이블을 할당하는 태스크 (기본 분할 및 부분 분할 포함).
   - **주요 모델 유형:**
     - **영역 기반 네트워크 (Region-based Networks):** 초기 딥 모델로, 컨텍스트 정보 부족 및 비효율성 문제를 가졌습니다.
     - **완전 합성곱 프레임워크 (Fully Convolutional Frameworks):**
       - **FCN [12]:** 완전 연결 계층을 합성곱으로 변환하고 업샘플링 및 스킵 연결을 사용하여 공간 해상도를 유지합니다.
       - **DeepLab System [13]:** CNN에 완전 연결 CRF를 통합하여 경계 세부 정보를 개선합니다.
   - **CNN 개선 기법:**
     - **다운샘플-업샘플 연산:** 인코더-디코더 구조로 특징 추출 및 해상도 복구 (DeconvNet [49], SegNet [50], Co-CNN [47]).
     - **피라미드 모듈:** 다중 스케일 컨텍스트 정보 캡처 (DeepLabV2 [11]의 ASPP, PSPNet [1]).
     - **스킵 연결:** 저수준의 외형 특징과 고수준의 의미 정보를 결합하여 정확도를 높입니다 (FCN [12], U-Net [51], RefineNet [52]).
     - **아트러스 컨볼루션 (Atrous Convolution):** Dilated convolution이라고도 하며, 필터의 수용 영역을 넓혀 더 넓은 컨텍스트를 추가 계산 없이 얻습니다 (DeepLab [13], Dilated-Net [54]).
     - **거친-세밀한 개선 (Coarse-to-Fine Refinement):** 여러 단계에 걸쳐 예측을 점진적으로 정제합니다 (ATR [46], LC [55], IDW-CNN [58]).
   - **랜덤 필드 모델 통합:** MRF 또는 CRF [61]를 딥 러닝에 통합하여 컨텍스트 정보와 장거리 종속성을 모델링합니다 (DeepLab [13], FCDS [60], DPN [10]).
   - **순환 신경망 통합:** CNN의 지역 정보 한계를 보완하고 시공간적 종속성을 모델링합니다 (2D LSTM [31], LG-LSTM [26], Graph LSTM [32]).

2. **인스턴스 수준 의미론적 분할 (Instance-Level Semantic Segmentation)**

   - **정의:** 동일 범주 내의 개별 객체 인스턴스들을 구별하고 각각을 정확히 분할합니다. 객체 탐지 및 의미론적 분할을 동시에 수행합니다.
   - **주요 접근 방식:**
     - **제안 기반 프레임워크 (Proposal-Based Framework):** 객체 제안을 먼저 생성한 후, 각 제안에 대해 분할을 수행합니다 (SDS [68]). 초기 제안 품질에 성능이 크게 좌우됩니다.
     - **다중 작업 엔드-투-엔드 프레임워크 (Multi-Task End-to-End Framework):** 제안 생성과 분할을 하나의 통합된 프레임워크에서 처리하여 엔드-투-엔드 학습을 가능하게 합니다 (R2-IOS [69], MNC [77], FCIS [17], Mask R-CNN [2]).
     - **메트릭 학습 임베디드 모델 (Metric Learning Embedded Model):** 픽셀 또는 검출 간의 유사성을 측정하여 동일한 인스턴스에 속하는 요소들을 그룹화합니다 (Associative Embedding [81], Deep Metric Learning [83]).

3. **분할을 넘어서 (Beyond Segmentation)**
   - **정의:** 픽셀별 분할 외에 이미지 내의 기하학적 정보, 객체 간 관계, 계층적 구조 등 더 풍부하고 고수준의 정보를 예측합니다.
   - **주요 모델:**
     - **Hierarchical LSTM (H-LSTM) [30]:** 기하학적 속성 (하늘, 땅) 및 기하학적 상호작용 관계 (겹침, 지지)를 동시에 예측합니다.
     - **CNN-RNN 모델 [6]:** CNN으로 객체를 분할하고 RNN으로 객체 간의 계층적 구조 및 상호작용 관계를 학습합니다. 이미지 설명과 같은 약한 지도 정보를 활용합니다.
     - **IDW-CNN [58]:** 이미지 설명을 활용하여 객체 상호작용을 학습하고 분할 성능을 개선합니다.

**데이터셋 및 평가 지표:**

- **데이터셋:** PASCAL VOC, PASCAL-Part, ILSVRC 2016 (ADE20K), MS COCO, SIFT Flow, NYUDv2, SUN RGB-D, Fashionista, ATR, CityScapes 등 광범위한 2D/3D 데이터셋의 특성 및 활용 분야를 비교합니다.
- **평가 지표:**
  - **픽셀 기반 분할:** 픽셀 정확도(pixel-wise accuracy), 평균 정확도(mean accuracy), IoU (Intersection over Union), F1 점수(F1 score) 등을 사용합니다.
    - **픽셀 정확도:** $\sum_{i} n_{ii} / \sum_{i} t_{i}$
    - **평균 정확도:** $(1/K) \sum_{i} n_{ii} / \sum_{i} t_{i}$
    - **평균 IoU:** $(1/K) \sum_{i} n_{ii} / (t_{i} + \sum_{j} n_{ji} - n_{ii})$
  - **구조화된 장면 파싱:** 관계 정확도(relation accuracy) 및 구조 정확도(structure accuracy)로 평가합니다 [6].

## 📊 Results

이 서베이 논문은 딥 러닝이 의미론적 이미지 파싱 분야에 가져온 혁신적인 발전을 보여줍니다.

- **범주 수준 분할:** FCN 및 DeepLab과 같은 완전 합성곱 프레임워크가 기본적인 토대를 마련했으며, 다운샘플-업샘플, 피라미드 모듈, 스킵 연결, 아트러스 컨볼루션 등 다양한 CNN 개선 기법들이 세부 정보 유지 및 컨텍스트 정보 활용에 크게 기여하여 성능을 비약적으로 향상시켰습니다. CRF 및 RNN/LSTM과의 통합은 장거리 종속성 모델링에 효과적임을 입증했습니다.
- **인스턴스 수준 분할:** 초기 제안 기반 방법의 한계를 극복하기 위해 Multi-Task Network Cascades (MNC) 및 Mask R-CNN과 같은 엔드-투-엔드 다중 작업 프레임워크가 등장하며 최첨단 성능을 달성했습니다. 특히, Mask R-CNN은 객체 탐지와 분할 마스크 생성을 병렬로 수행하여 유연성과 높은 정확도를 보여주었습니다. 메트릭 학습 임베딩 모델은 픽셀 그룹화를 통해 인스턴스 분할을 수행하는 새로운 유망한 접근 방식으로 부상하고 있습니다.
- **분할을 넘어서:** 이 분야는 픽셀별 레이블링을 넘어 기하학적 속성, 객체 간의 관계 및 계층적 구조를 파악함으로써 인간의 인지에 더 가까운 상세한 장면 이해를 가능하게 합니다. 약한 지도 학습 기법 (예: 이미지 설명 활용)은 정교한 수동 주석의 필요성을 줄이는 데 중요한 역할을 합니다.

전반적으로, 딥 러닝 기반 모델들은 전통적인 수제 특징 기반 모델의 표현 능력 한계를 극복하며 모든 레벨의 의미론적 이미지 파싱 태스크에서 탁월한 성능을 시연했습니다.

## 🧠 Insights & Discussion

- **의미:** 딥 러닝은 의미론적 이미지 파싱 분야를 혁신적으로 발전시켰으며, 특히 이미지에서 풍부하고 추상적인 표현을 자동으로 학습하는 능력을 통해 복잡한 시각적 정보 분석을 가능하게 했습니다. 이는 컴퓨터 비전 시스템이 인간의 인지 능력에 더 가까운 방식으로 이미지를 이해할 수 있도록 돕습니다.
- **한계 (분야의 일반적인 도전 과제):**
  - **데이터셋 요구량:** 대부분의 딥 파싱 모델은 대규모의 학습 데이터를 필요로 하지만, 이러한 데이터셋을 수집하고 정교하게 주석을 다는 것은 매우 시간과 비용이 많이 드는 작업입니다.
  - **'Beyond Segmentation'의 복잡성:** 구조화된 장면 파싱과 같은 '분할을 넘어서'는 태스크는 이미지의 계층적 표현이 모호하고, 수동으로 주석된 정교한 데이터셋이 부족하다는 문제를 안고 있습니다.
- **미래 연구 방향:**
  - **다중 작업 기반 의미론적 파싱:** 자연어 이해(NLU)와 이미지 파싱을 통합하는 등 다양한 태스크를 함께 학습하여 모델의 강건성과 이해도를 높이는 방향이 유망합니다.
  - **데이터 효율적인 학습:** 대규모 주석 데이터의 의존도를 줄이기 위해 반지도(semi-supervised), 약지도(weakly supervised) 또는 비지도(unsupervised) 학습 알고리즘 개발이 중요합니다.
  - **비디오 파싱으로의 확장:** 이미지 파싱에서 얻은 아이디어와 기술을 시간적 종속성과 복잡한 움직임이 포함된 비디오 파싱이라는 더욱 도전적인 영역으로 확장하는 것이 다음 단계입니다.

## 📌 TL;DR

**문제:** 이미지를 의미론적 영역으로 분해하고 구조적 관계를 파악하는 의미론적 이미지 파싱의 복잡한 과제를 해결하기 위해 딥 러닝 기술의 발전 과정을 종합적으로 분석합니다.

**제안 방법 (본 서베이의 방법):** 이 논문은 의미론적 이미지 파싱 연구를 범주 수준, 인스턴스 수준, 그리고 분할을 넘어선 세 가지 레벨로 체계적으로 분류하여 핵심 딥 표현 학습 모델, 아키텍처 개선 기법(예: 스킵 연결, 아트러스 컨볼루션), 랜덤 필드 모델 및 순환 신경망과의 통합 방법론을 검토합니다. 또한, 주요 벤치마크 데이터셋과 평가 지표를 비교 분석하고 미래 연구 방향을 제시합니다.

**주요 발견:** 딥 러닝 모델, 특히 CNN 기반의 완전 합성곱 네트워크(FCN, DeepLab)와 인스턴스 인식 네트워크(Mask R-CNN)가 기존 방법을 훨씬 능가하는 성능을 달성했음을 확인했습니다. 아키텍처 개선(예: U-Net, PSPNet)과 컨텍스트 모델링 기법(예: CRF, LSTM)의 결합이 성능 향상에 결정적이었으며, 메트릭 학습 또한 새로운 트렌드로 부상하고 있습니다. 하지만 대규모 주석 데이터셋의 필요성과 비디오 파싱으로의 확장 등은 여전히 해결해야 할 주요 과제로 남아있습니다.
