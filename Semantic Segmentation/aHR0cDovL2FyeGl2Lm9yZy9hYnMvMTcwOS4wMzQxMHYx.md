# One-Shot Learning for Semantic Segmentation

Amirreza Shaban, Shray Bansal, Zhen Liu, Irfan Essa, Byron Boots

## 🧩 Problem to Solve

본 논문은 제한된 수의 레이블링된 데이터(예: 단 한 장의 이미지)만으로도 새로운 시맨틱 클래스에 대한 픽셀 단위 시맨틱 이미지 분할(semantic image segmentation)을 수행하는 `원-샷(one-shot)` 학습 문제를 다룹니다. 기존 딥러닝 모델은 분류 문제 해결에 강력하지만, 새로운 클래스를 학습하려면 방대한 양의 레이블링된 훈련 데이터가 필요하며, 적은 데이터로는 오버피팅(overfitting)되기 쉽습니다. 특히, 기존의 원-샷 이미지 분류 방식은 픽셀 단위 예측에 필요한 수많은 고밀도 피처(dense features)에 확장하기 어렵습니다.

## ✨ Key Contributions

- 새로운 원-샷 분할 기술을 제안하여 기존 베이스라인보다 우수한 성능을 보이며 훨씬 빠릅니다.
- 새로운 클래스에 대한 약한 레이블(weak labels) 없이도 본 기술이 작동함을 보여줍니다.
- 강력한 어노테이션(strong annotations)을 가진 소수의 클래스만으로도 메타 학습(meta-learning)이 효과적으로 수행될 수 있음을 입증합니다.
- PASCAL 데이터셋에서 도전적인 `k-샷(k-shot)` 시맨틱 분할 태스크를 위한 새로운 벤치마크를 설정합니다.

## 📎 Related Works

- **시맨틱 이미지 분할 (Semantic Image Segmentation):** CNN 기반 방법(예: FCN [26])은 픽셀 단위 분류의 효율성을 보여주었지만, 테스트 클래스에 대한 대규모 어노테이션된 훈련 데이터를 가정합니다. 본 연구는 이러한 가정을 따르지 않습니다.
- **약한 지도 학습 (Weak Supervision):** 경계 상자(bounding boxes) [9]나 이미지 레이블(image labels) [30, 31, 33]과 같은 불완전한 어노테이션으로 학습하여 비용이 많이 드는 픽셀 단위 어노테이션의 필요성을 줄입니다. 공동 분할(co-segmentation) [12, 35]은 유사한 의미론적 클래스의 이미지에서 객체를 찾아 분할하는 것을 목표로 합니다. 본 연구는 단일 레이블 예제로부터 새로운 시맨틱 클래스의 고수준 표현을 생성하도록 네트워크를 메타 학습한다는 점에서 차이가 있습니다.
- **소수 샷 학습 (Few-Shot Learning):** 훈련 중 본 클래스를 통해 습득한 지식을 소수의 훈련 예제로만 새로운 클래스에 일반화하는 것을 목표로 합니다 [25, 36, 39]. 베이스 분류기(base classifier)의 매개변수를 새로운 클래스에 적응시키는 판별적 방법 [1, 2, 14, 40]이 본 연구와 밀접하게 관련되어 있지만, 새로운 예제에 과적합될 위험이 있습니다. 매트릭 학습(metric learning) [22, 39]은 원-샷 이미지 분류에서 우수한 성능을 보였습니다. 본 연구는 이들의 아이디어를 조밀한 분류(dense classification) 작업에 맞게 변형하여 사용합니다.

## 🛠️ Methodology

본 논문은 `두 갈래 아키텍처(two-branched approach)`를 제안합니다.

1. **매개변수 생성 브랜치 (Conditioning Branch):**

   - 입력으로 지원 세트($S = (I_s, Y_s(l))$)의 레이블링된 이미지-마스크 쌍을 받습니다.
   - 수정된 VGG-16 아키텍처 `g_eta(.)`를 사용하여 매개변수 $\{w, b\}$를 출력합니다.
   - **마스킹:** 입력 이미지를 해당 레이블로 마스킹하여 목표 객체만 포함하도록 합니다. 이는 배경 정보가 출력 매개변수의 분산을 증가시켜 네트워크 수렴을 방해하는 것을 방지합니다.
   - **가중치 해싱 (Weight Hashing):** VGG 마지막 레이어의 1000차원 벡터 출력을 $\{w, b\}$의 4097차원으로 매핑하기 위해 [7]의 가중치 해싱 레이어를 사용합니다. 이는 완전 연결 레이어(fully connected layer)가 도입할 수 있는 대량의 추가 매개변수로 인한 과적합을 방지합니다.

2. **분할 브랜치 (Segmentation Branch):**
   - 쿼리 이미지($I_q$)를 입력으로 받고, `g_eta(.)`에서 생성된 매개변수 $\{w, b\}$를 함께 사용하여 분할 마스크를 생성합니다.
   - FCN-32s (또는 Dilated-FCN) 아키텍처를 사용하여 쿼리 이미지에서 고밀도 피처 볼륨($F_q = \phi_\zeta(I_q)$)을 추출합니다.
   - 생성된 매개변수를 사용하여 픽셀 수준 로지스틱 회귀(pixel-level logistic regression)를 수행하여 최종 마스크를 얻습니다:
     $$\hat{M}_{mn}^q = \sigma(w^T F_{mn}^q + b)$$
     여기서 $w, b$는 학습 후에 고정되지 않고 지원 세트에 따라 계산됩니다.
   - 예측된 마스크는 표준 이중선형 보간법(bilinear interpolation)을 사용하여 원본 이미지 크기로 업샘플링됩니다.

**훈련 절차:**

- 각 반복에서 훈련 세트 $D_{\text{train}}$에서 지원 세트 $S$, 쿼리 이미지 $I_q$, 해당 이진 마스크 $M_q$를 샘플링하여 원-샷 작업을 시뮬레이션합니다.
- 지상 진실 마스크의 로그 우도(log likelihood)를 최대화합니다.
- SGD(Stochastic Gradient Descent)를 사용하며, VGG 네트워크는 FCN보다 빠르게 과적합되므로 학습률 승수를 0.1로 설정합니다.

**k-샷 확장:**

- 지원 세트에 $k$개의 레이블링된 이미지가 있을 때, 각 이미지로부터 $k$개의 매개변수 세트 $\{w_i, b_i\}$를 독립적으로 생성합니다.
- 이 매개변수 세트 각각을 독립적인 분류기로 간주합니다.
- 각 분류기가 생성한 이진 마스크들을 픽셀 수준에서 논리적 OR 연산으로 결합하여 최종 마스크를 만듭니다. 이 방법은 재훈련이 필요 없어 빠르고, 어떤 $k$ 값에도 일반화할 수 있습니다.

## 📊 Results

- **PASCAL-5$_i$ 벤치마크:** PASCAL VOC 2012 및 SDS 확장 어노테이션을 사용하여 새로운 데이터셋 PASCAL-5$_i$를 생성하고, L(L$_{train}$과 L$_{test}$은 겹치지 않음)에 대한 평균 IoU(Intersection over Union)로 성능을 측정합니다.
- **1-샷 성능:** 제안된 방법은 PASCAL-5$_i$ 벤치마크에서 기존 베이스라인(1-NN, Logistic Regression, Fine-tuning, Siamese)을 크게 능가합니다. 특히, 1-NN 및 Fine-tuning 대비 25%의 상대적 평균 IoU 향상을 보입니다 (본 논문: 40.8, 1-NN: 32.6, Fine-tuning: 32.6).
- **5-샷 성능:** 5-샷 설정에서도 제안된 방법(43.9 평균 IoU)은 Co-segmentation(27.1), 1-NN(40.0), Logistic Regression(39.3)을 능가합니다.
- **Dilated-FCN:** 고해상도 Dilated-FCN을 사용하여 1-샷에서 37.0%, 5-샷에서 37.43%의 평균 IoU를 달성했습니다. 이는 저해상도 버전보다 3.4% 향상되었으나, 1-샷과 5-샷 간의 격차는 작았습니다.
- **실행 시간:** 제안된 방법은 1-샷 설정에서 두 번째로 빠른 Logistic Regression보다 약 3배 빠르며, 5-샷 설정에서는 약 10배 빠릅니다. 이는 단일 순방향 전달(forward pass)로 매개변수를 계산하는 방식의 효율성을 보여줍니다.
- **사전 훈련 효과:** ImageNet 사전 훈련에서 PASCAL 카테고리와 겹치는 클래스를 제외하더라도(AlexNet-771), 제안된 방법의 성능은 전체 ImageNet 사전 훈련(AlexNet-1000)과 동등했습니다. 이는 약한 지도 없이도 새로운 범주로 일반화할 수 있음을 시사합니다. 반면, 베이스라인(LogReg-1000 vs. LogReg-771)은 성능 저하를 보여, 메타 학습의 중요성을 강조합니다.

## 🧠 Insights & Discussion

- 제안된 아키텍처는 쿼리 이미지의 픽셀을 분류하기 위한 앙상블 분류기(ensemble classifier)를 학습합니다.
- 기존 방법들이 지원 세트의 단일 이미지에 과적합되는 경향과 달리, 제안된 방법은 새로운 클래스에 대한 더 나은 일반화 성능을 보여줍니다. 이는 특히 1-샷 학습에서 두드러집니다.
- 소수의 클래스만으로도 강력한 어노테이션이 있다면 메타 학습이 효과적으로 수행될 수 있다는 가설을 지지합니다.
- ImageNet 사전 훈련은 모델 성능에 도움이 되지만, 테스트 클래스에 대한 약한 지도 없이도 좋은 일반화가 가능함을 입증했습니다.
- `k-샷` 학습을 위한 논리적 OR 연산 기반의 마스크 결합은 재훈련 없이도 빠르고 효과적이며, 지원 세트의 이미지 수 증가에 따라 정확도가 향상됩니다.
- Dilated-FCN을 사용한 실험에서 1-샷과 5-샷 사이의 성능 격차가 작게 나타난 것은 훈련이 1-샷 문제에 특화되어 있기 때문일 수 있다는 한계점을 언급합니다.

## 📌 TL;DR

**문제:** 단일 레이블 예제로 새로운 클래스의 시맨틱 분할을 수행하는 `원-샷 시맨틱 분할`은 기존 딥러닝 방식에서 데이터 부족으로 인한 과적합 문제와 확장성 한계에 직면합니다.
**방법:** 본 논문은 `두 갈래 메타 학습(two-branched meta-learning)` 네트워크를 제안합니다. 한 브랜치는 지원 이미지-마스크 쌍에서 분할 모델의 매개변수를 동적으로 생성하고, 다른 브랜치는 이 매개변수를 사용하여 쿼리 이미지에서 픽셀 단위 예측을 수행합니다. `k-샷` 확장은 각 지원 이미지에서 생성된 마스크들을 픽셀 단위 논리적 OR 연산으로 결합합니다.
**발견:** 제안된 방법은 베이스라인 대비 1-샷에서 평균 IoU가 25% 상대적으로 향상되었으며, 추론 속도가 훨씬 빠릅니다. 또한, 새로운 클래스에 대한 약한 지도 없이도 우수한 일반화 성능을 보이며, 소수의 강력하게 어노테이션된 클래스만으로도 메타 학습이 효과적임을 입증했습니다.
