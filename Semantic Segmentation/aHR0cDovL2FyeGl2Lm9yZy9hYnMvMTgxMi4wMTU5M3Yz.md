# 비디오 전파 및 레이블 완화를 통한 의미론적 분할 개선

Yi Zhu, Karan Sapra, Fitsum A. Reda, Kevin J. Shih, Shawn Newsam, Andrew Tao, Bryan Catanzaro

## 🧩 Problem to Solve

의미론적 분할(Semantic Segmentation)은 정확한 모델 학습을 위해 대량의 픽셀 단위 주석(annotation)을 요구하지만, 이는 비용이 매우 많이 드는 작업입니다. 비디오 시퀀스의 시간적 일관성(temporal consistency)을 활용하여 주석을 확장하려는 기존의 레이블 전파(label propagation) 방법들(예: 패치 매칭, 옵티컬 플로우)은 패치 크기/임계값에 대한 민감성, 정렬 불량(mis-alignment), 그리고 폐색(occlusion) 처리의 어려움과 같은 단점을 가집니다. 또한, 객체 경계(object boundary) 부근의 픽셀들은 본질적으로 모호하거나 주석 오류가 발생하기 쉬워 분류하기 어렵습니다.

## ✨ Key Contributions

* 의미론적 분할 훈련 데이터셋을 확장하기 위해 비디오 예측(Video Prediction) 모델을 활용하여 인접 프레임으로 레이블을 전파하는 새로운 방법론을 제안했습니다.
* 전파된 이미지와 레이블 간의 정렬 불량(mis-alignment) 문제를 완화하기 위한 공동 이미지-레이블 전파(Joint Image-Label Propagation) 전략을 도입했습니다.
* 객체 경계 영역에서 주석 노이즈 및 전파 아티팩트(propagation artifact)에 강건하도록 경계 레이블 완화(Boundary Label Relaxation) 기법을 제안했습니다. 이는 경계 픽셀에 대해 여러 클래스의 확률 합(union of class probabilities)을 최대화하는 방식으로, 더 긴 범위의 전파 활용을 가능하게 합니다.
* 제안하는 비디오 예측 기반 접근 방식이 기존 옵티컬 플로우(optical flow) 기반 방법보다 우수함을 정성적 및 정량적으로 비교하여 입증했습니다.
* Cityscapes (83.5%), CamVid (82.9%), KITTI (72.8%) 데이터셋에서 최첨단(State-of-the-Art) mIoU를 달성했습니다.

## 📎 Related Works

* **레이블 전파 (Label Propagation):** 패치 매칭 기반 방법 [2, 9]은 패치 크기 및 임계값에 민감하고 특정 상황에서 클래스 통계에 대한 사전 지식을 요구합니다. 옵티컬 플로우 기반 방법 [31, 16, 33]은 매우 정확한 옵티컬 플로우 추정에 의존하지만, 이는 달성하기 어렵고 전파된 레이블과 프레임 간의 정렬 불량을 야기할 수 있습니다. 본 연구는 비디오 예측 모델에서 학습된 모션 벡터를 사용하고 공동 전파를 통해 이 문제를 해결합니다.
* **경계 처리 (Boundary Handling):** 일부 이전 연구 [12, 29]는 경계 픽셀을 처리하기 위해 엣지 정보를 명시적으로 통합했지만, 이는 엣지 추정 오류 전파 및 과적합(over-fitting)의 단점이 있습니다. 어피니티 필드(affinity field) [21], 랜덤 워크(random walk) [5], 완화 레이블링(relaxation labelling) [37] 등과 같은 구조 모델링 방법들도 있으나, 경계 픽셀 자체보다는 세그먼트 간의 상호작용 모델링에 중점을 둡니다. 본 연구의 경계 레이블 완화 기법과 가장 유사한 [22]는 베이지안 프레임워크 내에서 불확실성 추론을 통합하는 반면, 본 논문은 경계 픽셀에서 여러 클래스를 예측할 수 있도록 클래스 레이블 공간 자체를 수정합니다.

## 🛠️ Methodology

* **비디오 예측을 통한 레이블 합성:**
  * 과거 프레임 시퀀스로부터 미래 프레임을 생성하는 비디오 예측 모델 [34]을 활용합니다. 이 모델은 각 픽셀 $(x,y)$를 미래 좌표로 변환하기 위한 모션 벡터 $(u,v)$를 예측합니다.
  * 예측된 미래 프레임 $\tilde{I}_{t+1}$은 다음과 같이 주어집니다:
        $$ \tilde{I}_{t+1} = \mathcal{T}(\mathcal{G}(I_{1:t}, F_{2:t}), I_t) $$
  * 동일한 예측된 모션 벡터를 사용하여 미래 레이블 $\tilde{L}_{t+1}$도 합성합니다:
        $$ \tilde{L}_{t+1} = \mathcal{T}(\mathcal{G}(I_{1:t}, F_{2:t}), L_t) $$
  * 여기서 $\mathcal{G}$는 입력 프레임과 추정된 옵티컬 플로우에 기반하여 모션 벡터를 예측하는 3D CNN이며, $\mathcal{T}$는 예측된 모션 벡터를 사용하여 가장 최근 입력 $I_t$ (또는 $L_t$)에서 이중 선형 샘플링(bilinearly sampling)을 수행하는 연산입니다.
* **공동 이미지-레이블 전파 (Joint Image-Label Propagation, JP):**
  * 기존 레이블 전파가 전파된 레이블 $\tilde{L}_{i+k}$을 원본 미래 프레임 $I_{i+k}$과 쌍으로 묶는 대신, 예측된 프레임 $\tilde{I}_{i+k}$과 예측된 레이블 $\tilde{L}_{i+k}$을 쌍으로 묶어 새로운 학습 샘플 $(\tilde{I}_{i+k}, \tilde{L}_{i+k})$을 생성합니다.
  * 이는 동일한 학습된 변환 파라미터 $(u,v)$를 사용하여 프레임과 레이블 모두를 합성하므로, 더 높은 수준의 정렬을 보장합니다.
  * 학습 데이터셋을 확장하기 위해 순방향 및 역방향 전파($\pm k$)를 모두 수행합니다.
* **비디오 재구성 (Video Reconstruction, VRec):**
  * 더욱 정확한 모션 벡터를 얻기 위해, 과거 프레임뿐만 아니라 실제 미래 프레임까지 모델 학습에 사용하여 "미래" 프레임을 재구성합니다.
  * 재구성된 미래 프레임 $\hat{I}_{t+1}$은 다음과 같이 주어지며:
        $$ \hat{I}_{t+1} = \mathcal{T}(\mathcal{G}(I_{1:t+1}, F_{2:t+1}), I_t) $$
  * 유사하게 레이블도 생성합니다:
        $$ \hat{L}_{t+1} = \mathcal{T}(\mathcal{G}(I_{1:t+1}, F_{2:t+1}), L_t) $$
* **경계 레이블 완화 (Boundary Label Relaxation):**
  * 객체 클래스 간의 경계에 있는 픽셀에 대해, 단일 정답 레이블의 가능성을 최대화하는 대신, 인접 클래스 레이블들의 합집합(union)의 가능성을 최대화하도록 손실 함수를 수정합니다.
  * 경계 픽셀은 다르게 레이블링된 이웃을 가진 픽셀로 정의됩니다.
  * 손실 함수는 다음과 같습니다:
        $$ \mathcal{L}_{\text{boundary}} = -\log \sum_{C \in N} P(C) $$
  * 여기서 $N$은 픽셀의 $3 \times 3$ 윈도우 내에 있는 클래스 집합이며, $|N|=1$인 경우 표준 크로스 엔트로피 손실로 환원됩니다.
* **기타 학습 전략:**
  * **Mapillary 사전 학습:** ImageNet 대신 Cityscapes와 도메인 유사성이 높은 Mapillary Vistas 데이터셋으로 모델을 사전 학습하여 더 나은 초기화를 제공합니다.
  * **클래스 균일 샘플링 (Class Uniform Sampling):** 훈련 중 모든 클래스가 대략적으로 균일하게 선택되도록 데이터 샘플링 전략을 도입하여 클래스 불균형 문제를 해결합니다.

## 📊 Results

* **Cityscapes 데이터셋:**
  * Mapillary 사전 학습과 클래스 균일 샘플링을 적용한 강력한 베이스라인(DeepLabV3+ with ResNeXt50)은 79.46% mIoU를 달성했습니다.
  * 공동 전파(Joint Propagation, JP)는 모든 전파 길이에서 기존 레이블 전파(Label Propagation, LP)보다 우수하며, $\pm 1$ 전파에서 베이스라인 대비 0.8% 향상된 80.26% mIoU를 기록했습니다.
  * 비디오 재구성(Video Reconstruction, VRec)은 비디오 예측(Video Prediction, VPred)보다 모든 전파 길이에서 더 나은 성능을 보였습니다.
  * 경계 레이블 완화(Boundary Label Relaxation)는 전파를 사용하지 않은 경우에도 79.46%에서 80.85%로, VRec와 결합 시 $\pm 3$ 전파에서 80.54%에서 81.35%로 mIoU를 크게 향상시켰으며, 더 긴 범위의 전파 활용을 가능하게 했습니다.
  * 제안하는 비디오 재구성 모델에서 학습된 모션 벡터는 FlowNet2 기반 옵티컬 플로우보다 정량적 및 정성적으로 우수함을 입증했습니다.
  * 최종적으로 Cityscapes 테스트 세트에서 83.5%의 mIoU를 달성하여 최첨단 성능을 경신했으며, 20개 클래스 중 18개에서 가장 높은 IoU를 기록했습니다.
* **CamVid 데이터셋:**
  * 단일 스케일 평가에서 81.7%, 다중 스케일 평가에서 82.9%의 mIoU를 달성하며 최첨단 성능을 크게 능가했습니다.
* **KITTI 데이터셋:**
  * 2018 ROB 챌린지 우승작([10], 앙상블 모델로 69.56% mIoU)을 단일 모델로 3.3%p 초과하는 72.83% mIoU를 달성하여 최첨단 성능을 기록했습니다.

## 🧠 Insights & Discussion

* **데이터 희소성 해결:** 비디오 예측 및 재구성 모델을 활용하여 비용 효율적으로 고품질의 합성 학습 데이터를 생성함으로써, 의미론적 분할의 고질적인 데이터 희소성 문제를 효과적으로 해결했습니다.
* **정렬 개선:** 공동 이미지-레이블 전파는 원본 프레임과 전파된 레이블 간의 정렬 불량 문제를 성공적으로 완화하여, 픽셀 단위 예측 문제인 의미론적 분할에서 정확한 모델 학습의 핵심 요소인 정렬 품질을 크게 향상시켰습니다.
* **경계 처리의 혁신:** 경계 레이블 완화 기법은 모호한 경계 픽셀과 전파 과정에서 발생하는 아티팩트에 대한 모델의 강건성(robustness)을 높이는 데 탁월한 효과를 보였습니다. 이는 전파 길이의 한계를 극복하고 더 많은 정보를 활용할 수 있게 하며, 인간이 직접 주석한 데이터의 경계 모호성을 처리하는 데에도 활용될 수 있는 범용적인 기법입니다.
* **모션 벡터의 우수성:** 비디오 예측 모델에서 학습된 모션 벡터는 기존 옵티컬 플로우(FlowNet2)보다 폐색(occlusion) 처리 능력이 뛰어나고 전파된 샘플의 품질이 높아, 레이블 전파에 훨씬 효과적임이 입증되었습니다.
* **작고 얇은 객체 성능 향상:** 특히 가로등, 표지판, 사람, 자전거 등 작거나 얇은 객체 클래스에서 성능 향상이 두드러져, 합성된 샘플이 이러한 클래스에 대한 모델의 일반화 능력(generalization ability)을 향상시키는 데 기여했음을 시사합니다.
* **향후 연구 방향:** GAN [26]과 같은 다른 데이터 증강 기법과의 결합, 그리고 학습된 커널을 이용한 소프트 레이블 완화 등 불확실성 추론을 개선하는 방향으로의 확장 가능성을 제시합니다.
* **한계점:** 전파 거리가 길어질수록 합성된 데이터의 품질이 저하되는 경향이 있으며, 누적된(accumulated) 합성 샘플을 사용하는 것이 오히려 성능을 저하시킬 수 있다는 점은 향후 개선될 수 있는 부분입니다.

## 📌 TL;DR

* **문제점:** 의미론적 분할을 위한 픽셀 단위 주석의 높은 비용, 기존 레이블 전파의 정렬 불량 문제, 그리고 모호한 객체 경계 처리의 어려움.
* **제안 방법:** 1) 비디오 예측/재구성 모델로 모션 벡터를 학습하여 이미지와 레이블을 함께(jointly) 전파해 학습 데이터셋을 확장합니다. 2) 경계 레이블 완화 기법을 도입하여 경계 픽셀에서 여러 클래스 확률의 합집합을 최대화함으로써 주석 노이즈에 강건한 학습을 가능하게 합니다.
* **주요 결과:** 이 방법론은 Cityscapes, CamVid, KITTI 데이터셋에서 최첨단 성능(SOTA)을 달성하며, 효율적인 데이터 확장과 혁신적인 경계 처리를 통해 기존 옵티컬 플로우 기반 방법보다 우수함을 입증했습니다.
