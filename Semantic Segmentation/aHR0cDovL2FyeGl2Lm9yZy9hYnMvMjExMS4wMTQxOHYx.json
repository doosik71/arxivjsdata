{
  "url": "http://arxiv.org/abs/2111.01418v1",
  "title": "A Pixel-Level Meta-Learner for Weakly Supervised Few-Shot Semantic\n  Segmentation",
  "authors": "Yuan-Hao Lee, Fu-En Yang, Yu-Chiang Frank Wang",
  "year": 2021,
  "abstract": "Few-shot semantic segmentation addresses the learning task in which only few\nimages with ground truth pixel-level labels are available for the novel classes\nof interest. One is typically required to collect a large mount of data (i.e.,\nbase classes) with such ground truth information, followed by meta-learning\nstrategies to address the above learning task. When only image-level semantic\nlabels can be observed during both training and testing, it is considered as an\neven more challenging task of weakly supervised few-shot semantic segmentation.\nTo address this problem, we propose a novel meta-learning framework, which\npredicts pseudo pixel-level segmentation masks from a limited amount of data\nand their semantic labels. More importantly, our learning scheme further\nexploits the produced pixel-level information for query image inputs with\nsegmentation guarantees. Thus, our proposed learning model can be viewed as a\npixel-level meta-learner. Through extensive experiments on benchmark datasets,\nwe show that our model achieves satisfactory performances under fully\nsupervised settings, yet performs favorably against state-of-the-art methods\nunder weakly supervised settings."
}