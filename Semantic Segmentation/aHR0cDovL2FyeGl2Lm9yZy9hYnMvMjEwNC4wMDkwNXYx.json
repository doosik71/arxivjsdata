{
  "url": "http://arxiv.org/abs/2104.00905v1",
  "title": "Background-Aware Pooling and Noise-Aware Loss for Weakly-Supervised\n  Semantic Segmentation",
  "authors": "Youngmin Oh, Beomjun Kim, Bumsub Ham",
  "year": 2021,
  "abstract": "We address the problem of weakly-supervised semantic segmentation (WSSS)\nusing bounding box annotations. Although object bounding boxes are good\nindicators to segment corresponding objects, they do not specify object\nboundaries, making it hard to train convolutional neural networks (CNNs) for\nsemantic segmentation. We find that background regions are perceptually\nconsistent in part within an image, and this can be leveraged to discriminate\nforeground and background regions inside object bounding boxes. To implement\nthis idea, we propose a novel pooling method, dubbed background-aware pooling\n(BAP), that focuses more on aggregating foreground features inside the bounding\nboxes using attention maps. This allows to extract high-quality pseudo\nsegmentation labels to train CNNs for semantic segmentation, but the labels\nstill contain noise especially at object boundaries. To address this problem,\nwe also introduce a noise-aware loss (NAL) that makes the networks less\nsusceptible to incorrect labels. Experimental results demonstrate that learning\nwith our pseudo labels already outperforms state-of-the-art weakly- and\nsemi-supervised methods on the PASCAL VOC 2012 dataset, and the NAL further\nboosts the performance."
}