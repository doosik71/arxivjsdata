# A Strong Baseline for Generalized Few-Shot Semantic Segmentation
Sina Hajimiri, Malik Boudiaf, Ismail Ben Ayed, Jose Dolz

## 🧩 Problem to Solve
최근 딥러닝 기반의 이미지 해석 및 의미론적 이해는 크게 발전했지만, 기존의 시맨틱 세분화(Semantic Segmentation) 모델은 대규모의 레이블링된 데이터에 의존하여 새로운 클래스로의 확장성(scalability)이 제한됩니다. Few-Shot Semantic Segmentation (FSS)은 이 문제를 해결하고자 하지만, 다음과 같은 중요한 한계를 가집니다:
*   **지원 샘플 가정의 비현실성**: 지원(support) 이미지에 쿼리(query) 이미지에 있는 클래스가 포함되어야 한다는 가정이 실제 시나리오에서 수작업으로 인한 높은 비용을 발생시킵니다.
*   **기존 클래스 성능 유지 소홀**: 새로운 클래스에 대한 성능 향상에만 초점을 맞추어, 이미 학습된 기본(base) 클래스에 대한 성능 저하를 방치합니다.
*   **이진 분류에 최적화**: 대부분의 FSS 모델은 이진(배경-전경) 분류에 맞춰져 있어, 여러 개의 새로운 클래스를 동시에 인식하는 데 비효율적입니다.

이를 극복하기 위해 제안된 Generalized Few-Shot Semantic Segmentation (GFSS)도 여전히 실용적인 적용에 있어서 다음과 같은 문제점을 안고 있습니다:
*   **비현실적인 사전 지식**: 기존 GFSS 연구들은 훈련 단계에서 테스트 시에만 노출되어야 할 새로운 클래스에 대한 사전 정보를 암묵적으로 사용합니다 (예: 새로운 클래스를 포함하는 이미지 필터링).
*   **모듈성의 부족**: 훈련과 테스트 단계가 긴밀하게 엮여 있어, 임의의 작업에 대한 모델의 유연성이 떨어집니다.

이 논문은 이러한 한계들을 해결하고, 훈련 단계에 대한 가정을 최소화하며 어떠한 훈련 모델에도 적용 가능한 완전 모듈식 추론(inference) 절차를 개발하여 더욱 실용적인 GFSS 설정을 목표로 합니다.

## ✨ Key Contributions
*   **DIaM (Distilled Information Maximization) 프레임워크 제안**: 정보 최대화(InfoMax) 원리($I(X;P) = H(P) - H(P|X)$)에 기반하여 학습된 특징 표현과 예측 간의 상호 정보(Mutual Information, MI)를 극대화하는 새로운 GFSS 프레임워크를 제시합니다.
*   **지식 증류(Knowledge Distillation) 도입**: 기본 클래스에 대한 성능 저하를 줄이기 위해, 명시적인 감독 없이 이전 모델과 새로운 모델의 기본 클래스 예측 간 일관성을 강제하는 Kullback-Leibler (KL) 발산 항을 도입합니다.
*   **향상된 성능 시연**: 기존 GFSS 벤치마크인 PASCAL-5i 및 COCO-20i에서 DIaM이 기존 SOTA 모델보다 특히 새로운 클래스 세분화에서 뛰어난 성능을 보임을 입증합니다. (PASCAL-5i에서 1-샷 시나리오 시 7%~26%, 5-샷 시나리오 시 3%~12% 개선).
*   **더욱 도전적인 시나리오 제안**: 기본 클래스와 새로운 클래스의 수가 동일한 PASCAL-10i라는 새로운 도전적인 설정을 제안하며, 이 환경에서 DIaM이 기존 GFSS SOTA와의 성능 격차를 더욱 벌려, 기존 방법들의 다수의 새로운 클래스 처리 능력의 한계를 부각시킵니다.

## 📎 Related Works
*   **Few-Shot Segmentation (FSS)**:
    *   **초기 이중 분기 구조**: 지원 샘플에서 클래스 프로토타입을 생성하고 쿼리 이미지를 분할하는 [7, 23, 25]와 같은 방식.
    *   **지원 샘플 활용 개선**: 다수의 프로토타입 생성 ([15, 34]), Graph CNN ([32]), 새로운 클래스 가중치 각인 ([27]), 트랜스포머 활용 ([20, 22, 38]) 등.
    *   **트랜스덕티브 추론**: 에피소드 방식의 메타 학습을 배제한 RePRI [1], [2, 5, 19, 40] 등.
*   **Generalized Few-Shot Segmentation (GFSS)**:
    *   **확장된 설정**: [29]에서 FSS 설정을 확장하여 GFSS 개념을 도입. 지원 세트에 모든 새로운 클래스 이미지가 포함되고, 쿼리 이미지에서 기본 및 새로운 클래스를 모두 예측해야 함.
    *   **CAPL [29]**: 기본 및 새로운 프로토타입을 동적으로 조정하는 프레임워크를 제안했으나, 기본 클래스에 편향되고 지원 샘플에 기본 클래스 레이블이 필요하다는 한계.
    *   **BAM [14]**: 두 단계로 구성 (기본 학습기, 메타 학습기). 메타 학습기는 전경-배경 예측만 가능하여 다중 클래스 GFSS에 직접 적용하기 부적합.
    *   **점진적 학습 (Incremental Learning)**: 기존 모델의 예측을 사용하여 지식을 증류하는 MiB [4]와 같은 접근법과 유사한 지식 증류 항 통합.

## 🛠️ Methodology
본 논문은 훈련보다는 추론(inference)에 중점을 둔 방법론을 제안합니다.

1.  **훈련 (Training)**:
    *   시맨틱 세분화 모델은 특징 추출기($f_{\phi}$)와 선형 분류기($f_{\theta_b}$)로 나뉩니다.
    *   훈련 중에는 기본 클래스($C_b$)를 세분화하기 위해 표준 지도 학습 방식으로 훈련됩니다.
    *   이 단계에서 분류기는 1 + $|C_b|$개의 클래스(배경 및 기본 클래스)만 예측합니다. 새로운 클래스 객체는 배경으로 레이블링됩니다.

2.  **추론 (Inference)**:
    *   테스트 시에는 특징 추출기($f_{\phi}$)를 고정하고, 미리 훈련된 분류기 $\theta_b$에 새로운 클래스 프로토타입 $\theta_n$을 추가하여 최종 분류기 $\theta = [\theta_b; \theta_n]$를 구성합니다.
    *   이 $\theta$는 주어진 태스크에 대해 최적화됩니다. (단, $d$는 특징 공간의 크기입니다.)
    *   **최적화 목표**: InfoMax 원리($\max_{\theta} I(X;P) = H(P) - H(P|X)$)를 기반으로 합니다. 이는 높은 확신도의 예측을 유도하면서 전체적으로 균형 잡힌 클래스 분포를 장려합니다.
    *   최종 목적 함수는 다음과 같습니다:
        $$ \min_{\theta} L_{DIaM} = L_{cond-ent} - L_{marg-ent} + \beta L_{KD} $$
        *   **높은 확신도 강제 ($L_{cond-ent}$)**:
            *   각 픽셀에 대한 높은 확신도 예측을 위해 교차 엔트로피 연산자 $H(p_i; q_i) = -\frac{1}{|\Omega|} \text{Tr}(p_i \log(q_i^{\top}))$를 사용합니다.
            *   **지원 감독 엔트로피 ($L_{xent}$)**: $\alpha \sum_{i=1}^{|S|} H(y_i; \pi_S(p_i))$. 실제 ground-truth 레이블 $y_i$를 사용하여 감독합니다. $\pi_S(p_i)$는 모델의 예측을 레이블 공간에 맞춰 투영(project)합니다 (기본 클래스 객체는 배경으로 간주). $\alpha$는 레이블링된 지원 세트의 의존도를 조절합니다.
            *   **쿼리 비감독 엔트로피**: $H(p_{|S|+1})$.
            *   $L_{cond-ent} = L_{xent} + H(p_{|S|+1})$.
        *   **클래스 불균형 해결 ($L_{marg-ent}$)**:
            *   단순한 높은 확신도 강제는 모든 픽셀을 한 클래스에 할당하는 것과 같은 뻔한 해결책으로 이어질 수 있으므로, 균형 잡힌 클래스 할당을 위해 주변 엔트로피(marginal entropy) 항을 사용합니다.
            *   표준 균일 분포 대신, 추정된 사전 확률 $\Pi$를 사용하여 주변 엔트로피 손실을 정의합니다: $L_{marg-ent} = H(P;\Pi) = \text{Cste} - KL(\bar{p}||\Pi)$. ($\bar{p}$는 쿼리 이미지의 클래스에 대한 모델의 주변 분포입니다.)
            *   $\Pi$는 모델의 초기 주변 분포에서 추정되며, 최적화 중에 한 번 업데이트됩니다.
        *   **기본 지식 보존 ($L_{KD}$)**:
            *   기본 클래스에 대한 모델의 예측이 훈련 직후의 예측과 가깝게 유지되도록 하는 자기 증류(self-distillation) 항을 제안합니다.
            *   $L_{KD} = KL(\pi_{new2old}(p_{|S|+1})||p_{old_{|S|+1}})$.
            *   $\pi_{new2old}(p)$는 현재 예측($p$)을 이전 모델의 레이블 공간(배경 + 기본 클래스)으로 매핑합니다 (새로운 클래스 확률은 배경에 합산). $p_{old_{|S|+1}}$는 이전 분류기($f_{\theta_b^{(0)}}$)의 예측입니다.
            *   $\beta$는 기본 클래스 지식 보존의 중요도를 조절합니다.
*   **구현 세부 사항**:
    *   백본: Resnet-50을 사용한 PSPNet.
    *   훈련: 표준 교차 엔트로피 손실.
    *   추론: 특징 추출기는 고정하고, 분류기를 100회 반복으로 최적화.
    *   하이퍼파라미터: $\alpha=\beta=100$, 특징 공간 크기 $d=512$.

## 📊 Results
*   **데이터셋**: PASCAL-5i, COCO-20i 벤치마크 및 새로 정의된 PASCAL-10i (10개 기본, 10개 새로운 클래스)에서 평가되었습니다.
*   **평가 지표**: 기본 클래스 mIoU (Base), 새로운 클래스 mIoU (Novel), 그리고 이 둘의 평균 (Mean)을 사용합니다. 전체 클래스 mIoU는 기본 클래스에 편향될 수 있음을 지적합니다.
*   **SOTA GFSS와의 비교 (Table 1)**:
    *   DIaM은 PASCAL-5i 및 COCO-20i에서 기존 FSS 및 GFSS 방법(CANet, PANet, PFENet, SCL, RePRI, CAPL, BAM)에 비해 **Novel 클래스에서 상당한 성능 향상**을 보였습니다.
    *   PASCAL-5i에서 CAPL 대비 Novel mIoU가 1-샷에서 약 17%, 5-샷에서 약 31% 향상. BAM 대비 1-샷에서 7%, 5-샷에서 26% 향상.
    *   COCO-20i에서도 CAPL 대비 Novel mIoU가 1-샷에서 약 10%, 5-샷에서 약 17% 향상. BAM 대비 1-샷에서 3%, 5-샷에서 12% 향상.
    *   BAM은 Base mIoU가 높지만, 이는 기본 예측을 유지하여 얻은 것으로, 새로운 클래스 학습 능력을 저해합니다.
*   **새로운 클래스 수 증가의 영향 (PASCAL-10i, Table 2)**:
    *   PASCAL-10i와 같이 새로운 클래스 수가 증가하는 도전적인 시나리오에서, DIaM은 Novel mIoU에서 CAPL 및 BAM 대비 각각 약 15%(1-샷) 및 30%(5-샷)에 가까운 훨씬 더 큰 성능 격차를 보였으며, Base mIoU에서도 우위를 점했습니다.
*   **어블레이션 연구 (Ablation Studies, Fig 1)**:
    *   **손실 함수의 구성 요소**: $L_{DIaM}$의 모든 항들이 시너지 효과를 내어 기본 및 새로운 클래스 모두에서 최상의 성능을 제공합니다.
    *   **사전 확률 $\Pi$**: $\Pi$의 자기 추정 방식이 균일 분포를 사용하는 것보다 새로운 클래스 성능에서 더 우수함을 확인했습니다. 실제 $\Pi$를 아는 DIaM-UB 모델은 상당한 추가 성능 개선 가능성을 보여줍니다.
    *   **기본 분류기 $\theta_b$ 최적화**: $\theta_b$를 고정하지 않고 최적화하는 것이 더 빠른 수렴과 더 나은 최적점을 제공함을 입증했습니다.
*   **정성적 결과 (Qualitative Results, Fig 2, 4)**:
    *   지식 증류 항 ($L_{KD}$)이 없을 경우, 모델이 일부 기본 클래스를 새로운 클래스로 오분류하는 경향을 보였습니다. $L_{KD}$의 도입이 이러한 오분류를 효과적으로 수정함을 시각적으로 확인했습니다.

## 🧠 Insights & Discussion
*   **실용적인 GFSS 기준점 제시**: DIaM은 표준 지도 학습 훈련과 경량의 추론 단계로 구성되어 어떤 학습된 특징 추출기와 분류기에도 적용 가능하며, 이전 방법들의 비현실적인 가정을 제거하여 보다 실용적인 GFSS 솔루션을 제공합니다.
*   **정보 최대화 및 지식 증류의 효과**: InfoMax 원리는 높은 확신도의 예측과 균형 잡힌 클래스 분포를 유도합니다. 특히 지식 증류($L_{KD}$) 항은 지원 이미지에서 기본 클래스에 대한 명시적 감독이 없더라도 기본 클래스 지식을 효과적으로 보존하고 기본 클래스와 새로운 클래스 간의 오분류를 방지하는 데 결정적인 역할을 합니다. 이는 기본 클래스에 대한 명시적 레이블을 요구하는 것보다 훨씬 실용적입니다.
*   **모듈성 및 확장성**: 이 방법은 추론 과정이 모듈식으로 설계되어, 여러 개의 새로운 클래스를 동시에 처리해야 하는 실제 시나리오에 잘 확장될 수 있음을 PASCAL-10i와 같은 도전적인 벤치마크에서 입증했습니다.
*   **한계 및 향후 연구**: DIaM-UB 실험 결과는 주변 엔트로피 항에서 사용되는 사전 확률($\Pi$)에 대한 보다 정확한 추정 메커니즘이 모델 성능을 크게 향상시킬 수 있음을 시사합니다. 미래 연구에서는 관심 객체의 정확한 비율을 제공하는 더 강력한 메커니즘을 탐구하여 성능을 더욱 개선할 수 있을 것입니다.

## 📌 TL;DR
**문제**: 기존 Few-Shot Semantic Segmentation (FSS) 및 Generalized FSS (GFSS) 방법은 훈련 시 새로운 클래스에 대한 사전 지식 요구, 지원 세트의 기본 클래스 레이블링 필요, 이진 분류에 대한 제약 등 비현실적인 가정과 모듈성 부족으로 인해 실제 적용에 어려움을 겪습니다.

**제안 방법**: DIaM (Distilled Information Maximization)은 표준 지도 학습 기반의 기본 모델 훈련과 InfoMax 원리에 기반한 최적화 기반 추론 단계로 구성된 GFSS 프레임워크를 제안합니다. 이 방법은 특징 표현과 예측 간의 상호 정보를 극대화하고, 클래스 균형을 위한 사전 확률 기반의 주변 엔트로피 항을 사용합니다. 특히, 지식 증류(Knowledge Distillation, $L_{KD}$) 항을 통해 지원 이미지에 기본 클래스에 대한 명시적 감독 없이도 기본 클래스 성능을 효과적으로 보존하면서 새로운 클래스에 적응합니다. 이 추론 방식은 기존에 훈련된 모든 세분화 네트워크에 적용 가능한 모듈식입니다.

**주요 결과**: DIaM은 기존 SOTA GFSS 방법들보다 새로운 클래스에 대한 mIoU 성능을 크게 향상시키며 (예: PASCAL-5i에서 7-31% 개선), 기본 클래스에서도 높은 성능을 유지합니다. 기본 및 새로운 클래스의 수가 동일한 더욱 도전적인 시나리오에서도 DIaM의 우수한 확장성과 견고성을 입증했습니다. 어블레이션 연구를 통해 손실 함수의 각 구성 요소의 시너지 효과와 특히 지식 증류가 기본 클래스와 새로운 클래스 간의 오분류를 방지하는 데 중요함을 확인했습니다. 이는 기존의 한정적인 가정을 해결하여 보다 실용적이고 확장 가능한 GFSS 방법론을 제시합니다.