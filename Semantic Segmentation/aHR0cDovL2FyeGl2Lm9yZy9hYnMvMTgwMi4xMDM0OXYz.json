{
  "url": "http://arxiv.org/abs/1802.10349v3",
  "title": "Learning to Adapt Structured Output Space for Semantic Segmentation",
  "authors": "Yi-Hsuan Tsai, Wei-Chih Hung, Samuel Schulter, Kihyuk Sohn, Ming-Hsuan Yang, Manmohan Chandraker",
  "year": 2018,
  "abstract": "Convolutional neural network-based approaches for semantic segmentation rely\non supervision with pixel-level ground truth, but may not generalize well to\nunseen image domains. As the labeling process is tedious and labor intensive,\ndeveloping algorithms that can adapt source ground truth labels to the target\ndomain is of great interest. In this paper, we propose an adversarial learning\nmethod for domain adaptation in the context of semantic segmentation.\nConsidering semantic segmentations as structured outputs that contain spatial\nsimilarities between the source and target domains, we adopt adversarial\nlearning in the output space. To further enhance the adapted model, we\nconstruct a multi-level adversarial network to effectively perform output space\ndomain adaptation at different feature levels. Extensive experiments and\nablation study are conducted under various domain adaptation settings,\nincluding synthetic-to-real and cross-city scenarios. We show that the proposed\nmethod performs favorably against the state-of-the-art methods in terms of\naccuracy and visual quality."
}