# 객체 세그먼트 정제 학습 (Learning to Refine Object Segments)

Pedro O. Pinheiro, Tsung-Yi Lin, Ronan Collobert, Piotr Doll ́ar

## 🧩 Problem to Solve

객체 세그멘테이션은 객체 수준의 정보와 픽셀 수준의 저수준 데이터를 모두 요구합니다. 기존 피드포워드 컨볼루션 신경망(CNN)은 풀링(pooling) 레이어로 인해 고해상도 공간 정보를 잃어버려 픽셀 단위의 정확한 세그멘테이션 마스크를 생성하는 데 어려움이 있습니다. 상위 레이어는 객체 수준의 지식을 인코딩하지만 자세나 외형과 같은 요소에 불변하며, 하위 레이어는 풍부한 공간 정보를 캡처하지만 객체 인스턴스를 구분하기 위한 고수준 정보가 부족합니다. 스킵 연결(skip connection)과 같은 기존 접근 방식은 시맨틱 세그멘테이션에는 효과적이지만, 객체 인스턴스 세그멘테이션에는 객체 수준 정보가 부족하여 적합하지 않습니다. 따라서, 고품질 객체 마스크를 효율적으로 생성하기 위해 저수준 피처의 공간 정보와 고수준 객체 지식을 효과적으로 융합하는 방법이 필요합니다.

## ✨ Key Contributions

- **새로운 상향식/하향식 정제 아키텍처 제안**: 피드포워드 네트워크를 보강하는 새로운 탑-다운(top-down) 정제 접근 방식을 제안하여, 고화질 객체 마스크를 효율적으로 생성하는 SharpMask를 개발했습니다.
- **정제 모듈 도입**: 마스크 인코딩($M_i$)과 하향식 피처($F_i$)를 병합하여 공간 해상도를 점진적으로 두 배씩 증가시키는 '정제 모듈($R_i$)'을 설계했습니다. 이는 스킵 연결과 달리 각 레이어에서 독립적인 예측을 시도하는 대신, 단일의 거친 마스크 인코딩을 정제하는 방식입니다.
- **성능 및 속도 향상**: 기존 DeepMask 네트워크 대비 객체 제안(object proposal) 생성 시 평균 재현율(AR)을 10~20% 향상시켰습니다. 또한, 네트워크 아키텍처 최적화를 통해 DeepMask보다 50% 빨라진 이미지당 평균 0.76초의 처리 속도를 달성했습니다.
- **일반화 가능성**: 제안된 정제 접근 방식은 다른 픽셀 단위 라벨링(pixel-labeling) 작업에도 적용될 수 있는 일반성을 가집니다.
- **객체 탐지 성능 개선**: SharpMask를 Fast R-CNN 탐지기와 결합했을 때 객체 탐지 결과가 크게 향상됨을 입증했습니다.

## 📎 Related Works

- **멀티스케일 아키텍처(Multiscale architectures)**: 이미지의 여러 스케일 버전에 대해 피처를 계산합니다. 본 연구는 이와 유사한 직관을 사용하지만, 각 이미지 스케일에서 피처를 다시 계산할 필요 없이 효율적으로 정제를 수행합니다.
- **디컨볼루션 네트워크(Deconvolutional networks)**: CNN의 풀링 과정을 역전시켜 해상도를 점진적으로 높입니다. 본 연구의 정제 모듈과 유사점이 있지만, 피처 값 대신 '스위치' 변수를 전달하여 정보 전송이 제한됩니다.
- **그래픽 모델 네트워크(Graphical model networks)**: CNN에 그래픽 모델(예: CRFs)을 통합하여 거친 세그멘테이션 마스크를 정교화합니다. 시맨틱 세그멘테이션에서 좋은 결과를 보였지만, 이미지당 여러 제안에 적용하기에는 속도가 너무 느립니다.
- **스킵 연결(Skip connections)**: 시맨틱 세그멘테이션이나 엣지 탐지에 널리 사용됩니다(예: FCNs, HED). 각 네트워크 레이어에서 독립적인 예측을 수행하고 이를 통합하는 방식입니다. 객체 인스턴스 세그멘테이션에는 객체 수준 정보가 부족하여 한계가 있습니다.
- **DeepMask [22]**: 본 연구의 출발점이 되는 객체 제안 생성 모델입니다. 주어진 이미지 패치에서 객체가 중앙에 포함될 가능성과 해당 객체의 세그멘테이션 마스크를 예측합니다. SharpMask는 DeepMask 아키텍처를 기반으로 정제 모듈을 추가하여 마스크 품질을 향상시킵니다.

## 🛠️ Methodology

본 논문은 객체 인스턴스 세그멘테이션을 위해 DeepMask 네트워크를 기반으로 한 하향식/상향식 정제 아키텍처를 제안합니다.

- **기본 아키텍처**: DeepMask 네트워크를 기반으로 합니다. DeepMask는 입력 패치에 대해 클래스 불가지론적 객체 마스크와 객체성 점수를 예측합니다. 이 네트워크의 피드포워드 경로(bottom-up path)는 여러 풀링 단계를 거쳐 저해상도의 특징 맵을 생성합니다.
- **정제 모듈($R_i$)**:
  - **목표**: 풀링의 영향을 역전시키고 입력 마스크 인코딩의 해상도를 두 배로 늘립니다.
  - **입력**: 상향식 경로에서 생성된 마스크 인코딩($M_i$)과 하향식 경로에서 추출된 해당 특징($F_i$)을 입력으로 받습니다. $F_i$는 해당 풀링 레이어 직전의 컨볼루션 레이어에서 가져옵니다.
  - **세부 과정**:
    1. **스킵 피처($S_i$) 생성**: $F_i$의 채널 수를 줄이기 위해 $3 \times 3$ 컨볼루션 모듈(ReLU 포함)을 적용하여 $S_i$를 생성합니다. (일반적으로 두 개의 $3 \times 3$ 컨볼루션 사용)
    2. **피처 병합**: 마스크 인코딩 $M_i$와 스킵 피처 $S_i$를 채널 방향으로 연결(concatenate)합니다.
    3. **마스크 인코딩 변환**: 병합된 피처에 또 다른 $3 \times 3$ 컨볼루션(ReLU 포함)을 적용합니다.
    4. **해상도 상향 샘플링**: 결과를 이선형 업샘플링(bilinear upsampling)으로 2배 확대하여 새로운 마스크 인코딩 $M_{i+1}$을 생성합니다.
  - **반복 적용**: 이 과정은 입력 이미지 패치와 동일한 해상도가 복원될 때까지 풀링 레이어 수($n$)만큼 반복됩니다. 각 정제 모듈 $R_i$는 독립적인 파라미터를 가집니다.
- **네트워크 최적화**:
  - **트렁크 아키텍처(Trunk Architecture)**: DeepMask의 VGG-A 모델을 ResNet-50 모델로 교체하여 정확도는 유지하면서 속도를 향상시켰습니다. 입력 크기 $W$, 풀링 레이어 수 $P$, 스트라이드 밀도 $S$, 깊이 $D$, 최종 피처 채널 수 $F$ 등 다양한 파라미터를 조정하여 최적의 속도-정확도 균형을 찾았습니다.
  - **헤드 아키텍처(Head Architecture)**: 마스크 및 점수 예측 헤드를 단순화하여 추론 속도를 더욱 개선했습니다. 특히, 점수 예측이 마스크 예측과 더 많은 연산을 공유하도록 하여 효율성을 높였습니다.
- **학습 및 추론**:
  - **2단계 학습 절차**:
    1. **1단계**: 피드포워드 경로를 학습시켜 거친 픽셀 마스크와 객체 점수를 공동으로 추론합니다(DeepMask와 동일). ImageNet으로 사전 학습된 네트워크 파라미터를 사용합니다.
    2. **2단계**: 피드포워드 경로를 '고정'하고, 최종 마스크 예측 레이어를 마스크 인코딩($M_1$)을 생성하는 선형 레이어로 교체합니다. 정제 모듈을 추가하고, 이들을 SGD로 학습시키며 오차는 정제 모듈에만 역전파됩니다.
  - **추론**: 컨볼루션 방식으로 밀집된 객체 제안을 생성한 후, 가장 유망한 상위 $N$개 제안에 대해서만 정제 모듈을 배치 모드(batch mode)로 적용합니다.

## 📊 Results

- **마스크 품질**: SharpMask는 DeepMask에 비해 객체 경계 근처에서 더 선명하고 고화질의 마스크를 생성했습니다 (그림 2, 9).
- **객체 제안 성능 (COCO 데이터셋)**:
  - DeepMask 대비 객체 제안 생성의 평균 재현율(AR)이 10-20% 향상되었습니다.
  - 특히, 분할 제안 및 대형 객체에 대해 가장 큰 성능 향상을 보이며, 객체 제안 생성 분야에서 새로운 SOTA(State-of-the-Art)를 달성했습니다.
  - SharpMaskZoom을 통해 작은 객체의 AR을 최대 2배까지 향상시킬 수 있었습니다.
- **속도**:
  - 최적화된 DeepMask 기본 모델인 "DeepMask-ours"는 이미지당 0.46초로, 기존 DeepMask(1.59초)보다 3배 이상 빨라졌습니다.
  - SharpMask는 이미지당 0.76초로, 기존 DeepMask보다 2배 이상 빨랐습니다. 정제 모듈 추가로 인한 파라미터 증가는 3M 미만이었습니다.
- **객체 탐지 성능**:
  - Fast R-CNN 파이프라인에서 SharpMask 제안을 사용했을 때, SelSearch보다 5 AP 높은 28 AP를 달성했습니다 (MPN 분류기 사용).
  - 2015 COCO 탐지 챌린지에서 VGG 분류기 및 앙상블 모델과 결합하여 박스 탐지에서 33.5 AP, 세그먼트 탐지에서 25.1 AP로 2위를 차지했습니다.

## 🧠 Insights & Discussion

- **마스크 인코딩 채널 수의 중요성**: 정제 모듈의 마스크 인코딩($M_i$) 채널 수($k_i{_m}$)를 1보다 크게 사용하는 것이 풍부한 정보를 캡처하고 좋은 정확도를 얻는 데 중요했습니다.
- **스킵 피처 변환의 효율성**: 하위 레이어의 특징($F_i$)을 $3 \times 3$ 컨볼루션을 통해 '스킵 피처'($S_i$)로 변환하여 채널 수를 줄이는 것은 계산 비용을 절감하면서도 정제에 적합한 형태로 특징을 변환하는 데 효과적이었습니다. 특히, 스킵 피처는 겹치는 이미지 패치 간에 공유되어 효율성을 높였습니다.
- **수평 및 수직 연결의 필요성**: 마스크 인코딩의 탑-다운 흐름(수직)과 하위 레이어 피처의 통합(수평) 모두가 의미 있는 성능 향상을 위해 필수적임을 ablation study를 통해 확인했습니다. 단순한 '스킵' 또는 '디컨볼루션' 네트워크로는 충분한 개선을 얻지 못했습니다.
- **정제 네트워크의 채널 설계**: 피드포워드 네트워크와 반대로, 공간 해상도가 증가함에 따라 채널 수를 감소시키는 디자인이 정제에 효과적이었습니다.
- **2단계 학습의 이점**: 피드포워드 경로를 먼저 학습시키고 정제 모듈을 별도로 학습시키는 2단계 절차는 더 빠른 수렴을 이끌었으며, 추론 시 거친 마스크와 정제된 마스크를 모두 유연하게 생성할 수 있게 했습니다.
- **한계점**: 정제 모듈의 계산은 패치 의존적이며, 이로 인해 초기 피처 추출만큼 연산 공유가 이루어지지 않는다는 점이 있습니다.

## 📌 TL;DR

- **문제**: 표준 CNN은 풀링 레이어로 인해 객체 인스턴스 세그멘테이션에서 픽셀 단위의 정확한 마스크를 생성하는 데 한계가 있습니다.
- **해결책**: SharpMask는 하향식/상향식 CNN 아키텍처로, 먼저 피드포워드 경로에서 거친 '마스크 인코딩'을 생성한 다음, '정제 모듈'을 사용하여 이를 정교화합니다. 각 정제 모듈은 현재 마스크 인코딩과 하향식 경로의 하위 레이어에서 추출된 상세한 특징을 효율적으로 병합하여 해상도를 점진적으로 두 배씩 늘립니다.
- **주요 결과**: SharpMask는 기존 DeepMask 대비 객체 제안의 평균 재현율을 10-20% 높이고 더 선명한 마스크를 생성합니다. 또한, 속도도 50% 향상되어 객체 제안 생성 분야의 새로운 SOTA를 달성했으며, 객체 탐지 성능도 크게 개선했습니다.
