{
  "title": "Dynamically pruning segformer for efficient semantic segmentation",
  "authors": "Haoli Bai, Hongda Mao, Dinesh Nair",
  "year": 2021,
  "url": "http://arxiv.org/abs/2111.09499v1",
  "abstract": "As one of the successful Transformer-based models in computer vision tasks,\nSegFormer demonstrates superior performance in semantic segmentation.\nNevertheless, the high computational cost greatly challenges the deployment of\nSegFormer on edge devices. In this paper, we seek to design a lightweight\nSegFormer for efficient semantic segmentation. Based on the observation that\nneurons in SegFormer layers exhibit large variances across different images, we\npropose a dynamic gated linear layer, which prunes the most uninformative set\nof neurons based on the input instance. To improve the dynamically pruned\nSegFormer, we also introduce two-stage knowledge distillation to transfer the\nknowledge within the original teacher to the pruned student network.\nExperimental results show that our method can significantly reduce the\ncomputation overhead of SegFormer without an apparent performance drop. For\ninstance, we can achieve 36.9% mIoU with only 3.3G FLOPs on ADE20K, saving more\nthan 60% computation with the drop of only 0.5% in mIoU"
}