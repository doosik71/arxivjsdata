{
  "url": "http://arxiv.org/abs/2306.08913v2",
  "title": "Advancing Volumetric Medical Image Segmentation via Global-Local Masked\n  Autoencoder",
  "authors": "Jia-Xin Zhuang, Luyang Luo, Hao Chen",
  "year": 2023,
  "abstract": "Masked autoencoder (MAE) is a promising self-supervised pre-training\ntechnique that can improve the representation learning of a neural network\nwithout human intervention. However, applying MAE directly to volumetric\nmedical images poses two challenges: (i) a lack of global information that is\ncrucial for understanding the clinical context of the holistic data, (ii) no\nguarantee of stabilizing the representations learned from randomly masked\ninputs. To address these limitations, we propose the\n\\textbf{G}lobal-\\textbf{L}ocal \\textbf{M}asked \\textbf{A}uto\\textbf{E}ncoder\n(GL-MAE), a simple yet effective self-supervised pre-training strategy. In\naddition to reconstructing masked local views, as in previous methods, GL-MAE\nincorporates global context learning by reconstructing masked global views.\nFurthermore, a complete global view is integrated as an anchor to guide the\nreconstruction and stabilize the learning process through global-to-global\nconsistency learning and global-to-local consistency learning. Finetuning\nresults on multiple datasets demonstrate the superiority of our method over\nother state-of-the-art self-supervised algorithms, highlighting its\neffectiveness on versatile volumetric medical image segmentation tasks, even\nwhen annotations are scarce. Our codes and models will be released upon\nacceptance."
}