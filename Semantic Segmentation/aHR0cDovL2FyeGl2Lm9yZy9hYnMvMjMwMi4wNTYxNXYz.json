{
  "url": "http://arxiv.org/abs/2302.05615v3",
  "title": "Anatomical Invariance Modeling and Semantic Alignment for\n  Self-supervised Learning in 3D Medical Image Analysis",
  "authors": "Yankai Jiang, Mingze Sun, Heng Guo, Xiaoyu Bai, Ke Yan, Le Lu, Minfeng Xu",
  "year": 2023,
  "abstract": "Self-supervised learning (SSL) has recently achieved promising performance\nfor 3D medical image analysis tasks. Most current methods follow existing SSL\nparadigm originally designed for photographic or natural images, which cannot\nexplicitly and thoroughly exploit the intrinsic similar anatomical structures\nacross varying medical images. This may in fact degrade the quality of learned\ndeep representations by maximizing the similarity among features containing\nspatial misalignment information and different anatomical semantics. In this\nwork, we propose a new self-supervised learning framework, namely Alice, that\nexplicitly fulfills Anatomical invariance modeling and semantic alignment via\nelaborately combining discriminative and generative objectives. Alice\nintroduces a new contrastive learning strategy which encourages the similarity\nbetween views that are diversely mined but with consistent high-level\nsemantics, in order to learn invariant anatomical features. Moreover, we design\na conditional anatomical feature alignment module to complement corrupted\nembeddings with globally matched semantics and inter-patch topology\ninformation, conditioned by the distribution of local image content, which\npermits to create better contrastive pairs. Our extensive quantitative\nexperiments on three 3D medical image analysis tasks demonstrate and validate\nthe performance superiority of Alice, surpassing the previous best SSL\ncounterpart methods and showing promising ability for united representation\nlearning. Codes are available at https://github.com/alibaba-damo-academy/alice.",
  "citation": 1
}