# Learning Rich Features from RGB-D Images for Object Detection and Segmentation
Saurabh Gupta, Ross Girshick, Pablo Arbel ́aez, and Jitendra Malik

## 🧩 Problem to Solve
본 논문은 RGB-D(RGB-Depth) 이미지를 활용하여 객체 탐지 및 분할 문제를 해결하는 것을 목표로 합니다. 기존의 객체 탐지 시스템은 일반적으로 바운딩 박스만을 제공하며, 의미론적 분할은 픽셀별 카테고리 라벨링에 초점을 맞추지만 객체 인스턴스에 대한 정보를 제공하지 않습니다. 이러한 한계는 로봇 공학 등 실제 응용 분야에서 정교한 장면 이해를 어렵게 합니다. 특히, 깊이 정보를 CNN(Convolutional Neural Network)이 효과적으로 학습할 수 있는 형태로 인코딩하는 방법에 대한 연구가 필요합니다.

## ✨ Key Contributions
*   **새로운 지리적 깊이 인코딩 (HHA):** 깊이 이미지를 수평 시차(Horizontal Disparity), 지면으로부터의 높이(Height Above Ground), 중력과의 각도(Angle with Gravity)의 3채널로 인코딩하는 HHA 표현을 제안합니다. 이 인코딩이 기존의 원시 깊이 이미지보다 CNN 특징 학습에 훨씬 효과적임을 입증했습니다.
*   **RGB-D 객체 탐지 성능 향상:** R-CNN 프레임워크를 RGB-D에 맞게 확장하여 기존 방법 대비 56%의 상대적 개선을 달성했으며, 평균 정밀도($AP_{b}$) 37.3%를 기록했습니다.
*   **인스턴스 분할 방법 제안:** 탐지된 바운딩 박스 내 픽셀을 전경(foreground) 또는 배경(background)으로 분류하는 결정 포레스트(Decision Forest) 기반의 인스턴스 분할 접근 방식을 제안하여 기존 베이스라인 대비 $AP_{r}$에서 4%p 향상을 보였습니다.
*   **의미론적 분할 개선:** 객체 탐지 결과를 기존의 수퍼픽셀 분류 프레임워크에 통합하여, 연구 대상 카테고리에서 기존 최첨단 기술 대비 24%의 상대적 개선을 이루었습니다.
*   **향상된 2.5D 영역 제안:** RGB-D 윤곽선 감지 및 깊이 기반 특징을 활용하여 영역 제안의 품질을 크게 개선했습니다.

## 📎 Related Works
*   **의미론적 분할:** [3, 18, 24, 31, 34] 등 기존 연구들은 픽셀별 카테고리 라벨링에 중점을 둡니다.
*   **RGB-D 객체 탐지:** [21, 23, 26, 36, 39] 등은 주로 바운딩 박스 탐지에 초점을 맞춥니다.
*   **인스턴스 분할:** [20, 37]은 객체의 픽셀 단위 마스크를 예측하는 문제를 다룹니다.
*   **CNN 적용:** [27]은 CNN의 일반적인 유용성을, [25]는 이미지 분류, [16]은 객체 탐지(R-CNN), [13]은 의미론적 분할, [11]은 세분화된 분류에 CNN을 활용했습니다.
*   **RGB-D에서의 CNN:** [4, 6, 35]는 깊이 이미지에서 특징을 학습하기 위한 신경망을 고려했지만, 주로 제어된 환경의 작은 객체에 초점을 맞췄습니다.
*   **윤곽선 감지 및 영역 제안:** [9, 18]의 윤곽선 감지 기법과 [1]의 Multiscale Combinatorial Grouping (MCG), [29]의 RGB-D 객체 제안이 참조됩니다.
*   **기준선 모델:** DPMs (Deformable Part Models) [14]은 객체 탐지 성능 비교를 위한 기준선으로 사용됩니다.

## 🛠️ Methodology
1.  **2.5D 영역 제안 (2.5D Region Proposals):**
    *   **윤곽선 감지:** [18]에서 제안된 Normal Gradients, Geocentric Pose(지면으로부터의 높이, 중력과의 각도) 및 [9]에서 학습된 Richer Appearance 특징을 [9]의 Structured Random Forests 학습 프레임워크와 결합합니다.
    *   **후보 영역 랭킹:** Multiscale Combinatorial Grouping (MCG) [1]를 확장하여 깊이 이미지 기반의 29가지 새로운 기하학적 특징(예: 시차, HHA, 3D 좌표의 평균 및 표준 편차, 영역 범위, 표면 방향 비율 등)을 추가하고 이를 활용하여 객체 후보 영역의 품질을 평가합니다.

2.  **RGB-D 객체 탐지 (RGB-D Object Detectors):**
    *   **깊이 이미지 인코딩:** 깊이 이미지를 HHA (Horizontal Disparity, Height Above Ground, Angle with Gravity) 3채널로 변환합니다. 각 채널은 0-255 범위로 선형 스케일링됩니다.
    *   **CNN 활용:** Krizhevsky 등 [25]이 제안한 CNN 아키텍처(ImageNet [7]으로 사전 학습됨)를 사용하며, 이를 HHA 이미지에 맞게 미세 조정(finetuning)합니다.
    *   **합성 데이터 증강:** NYUD2 데이터셋의 제한된 데이터 문제를 해결하기 위해 [17]의 3D 장면 주석을 활용하여 다양한 시점에서 합성 장면을 렌더링하고, Kinect 양자화 모델 및 노이즈를 시뮬레이션하여 학습 데이터를 증강합니다.
    *   **특징 결합:** 개별적으로 미세 조정된 RGB CNN과 HHA CNN에서 추출된 특징을 결합(late fusion)하여 최종 분류를 수행합니다.

3.  **인스턴스 분할 (Instance Segmentation):**
    *   **문제 정의:** 객체 탐지 결과 내의 픽셀을 전경 또는 배경으로 분류하는 2클래스 라벨링 문제로 정의합니다.
    *   **모델:** 랜덤 포레스트 분류기 [5]를 사용하여 각 픽셀을 분류합니다. 결정 트리의 분할 노드에서는 픽셀의 상대적 위치 및 채널 값을 임계값으로 사용하는 단항(unary) 및 이항(binary) 질의를 사용합니다.
    *   **후처리:** 픽셀별 예측을 수퍼픽셀 단위로 평균화하여 부드럽게 만듭니다.

4.  **의미론적 분할 (Semantic Segmentation):**
    *   **통합:** 기존의 수퍼픽셀 기반 의미론적 분할 프레임워크 [18]를 확장합니다.
    *   **특징 추가:** 훈련된 객체 탐지기의 탐지 점수와 수퍼픽셀의 중첩 정보를 기반으로 새로운 특징을 설계하여 기존 수퍼픽셀 특징에 추가합니다.

## 📊 Results
*   **윤곽선 감지:** NYUD2 데이터셋에서 제안된 윤곽선 감지기($F_{max}$ 71.03%)는 기존 최신 방법보다 우수한 성능을 보였습니다.
*   **영역 제안:** 제안된 2.5D 영역 제안 방법은 객체 후보 영역의 커버리지 측면에서 기존 방법들을 일관되게 능가했습니다.
*   **객체 탐지 ($AP_{b}$):**
    *   RGB DPM: 9.0%
    *   RGBD-DPM: 23.9%
    *   RGB R-CNN (미세 조정): 22.5%
    *   깊이 HHA CNN (미세 조정): 25.2% (단순 시차 CNN 대비 25% 상대적 개선)
    *   **최종 시스템 (RGB + HHA 특징 결합, 2배 합성 데이터): 37.3% ($AP_{b}$ on test set)**. 이는 RGBD-DPM 기준선 대비 56%의 상대적 성능 향상입니다.
*   **인스턴스 분할 ($AP_{r}$):**
    *   최고 베이스라인: 28.1%
    *   **본 논문의 방법: 32.1%**. 일부 카테고리에서는 $AP_{b}$보다 $AP_{r}$이 더 높게 나타나, 탐지 오류를 인스턴스 분할이 교정했음을 시사합니다.
*   **의미론적 분할 ($fwavacc$):**
    *   [18]: 45.2%
    *   [18]+DPM: 45.6%
    *   **본 논문의 방법: 47.0%**. 특히, 객체 탐지기가 추가된 카테고리($avacc^{*}$)에서는 평균 성능이 28.4%에서 35.1%로 24% 상대적 개선을 달성했습니다.

## 🧠 Insights & Discussion
*   **HHA 인코딩의 중요성:** HHA 인코딩은 깊이 이미지의 기하학적, 지리적 특성을 효과적으로 포착하여, CNN이 깊이 정보로부터 의미 있는 특징을 학습하는 데 결정적인 역할을 합니다. 이는 제한된 학습 데이터 상황에서 CNN이 깊이, 표면 법선, 높이와 같은 구조적 불연속성을 자동으로 학습하기 어렵다는 문제를 해결합니다.
*   **CNN의 일반화 능력:** ImageNet으로 사전 학습된 CNN이 HHA 인코딩 깊이 이미지에 놀라울 정도로 잘 일반화되어 깊이 특징 학습을 위한 좋은 초기화 방법임을 보여줍니다.
*   **합성 데이터의 역할:** 합성 데이터 증강은 데이터 부족 문제를 완화하는 데 도움이 되지만, 합성 데이터의 품질과 통계적 유사성이 중요함을 시사합니다. 실제 장면과 다른 합성 데이터는 오히려 성능 저하를 야기할 수 있습니다.
*   **통합 시스템의 강점:** 객체 탐지, 인스턴스 분할, 의미론적 분할을 통합된 프레임워크 내에서 효과적으로 해결함으로써, 심층적인 장면 이해가 가능함을 입증했습니다.
*   **응용 분야의 중요성:** 본 연구의 성과는 로봇 공학 등 정교한 지각 능력과 장면 이해가 필요한 분야에서 RGB-D 데이터 활용을 촉진할 잠재력을 가지고 있습니다.

## 📌 TL;DR
*   **문제:** RGB-D 영상에서 객체 탐지 및 분할의 한계점을 극복하고, 의미론적으로 풍부한 장면 이해 시스템 구축.
*   **방법:** 깊이 영상을 수평 시차, 지면으로부터의 높이, 중력과의 각도를 인코딩한 'HHA' 3채널 표현으로 변환하여 CNN에 입력. R-CNN 프레임워크를 RGB-D에 맞춰 확장하고, 개선된 2.5D 영역 제안과 함께 CNN을 통한 풍부한 특징 학습을 수행. 탐지된 객체에 대해 결정 포레스트를 이용한 인스턴스 분할을 수행하고, 이를 기존의 의미론적 분할 시스템에 통합하여 성능 향상.
*   **주요 결과:** HHA 인코딩은 CNN이 깊이 특징을 학습하는 데 매우 효과적임을 입증. 객체 탐지에서 기존 대비 56%의 상대적 성능 향상 ($AP_{b}$ 37.3%). 인스턴스 분할 및 의미론적 분할에서도 최신 기술 대비 상당한 개선을 달성. 이는 로봇 공학 등 다양한 분야의 지각 능력 발전에 기여할 잠재력을 보여줌.