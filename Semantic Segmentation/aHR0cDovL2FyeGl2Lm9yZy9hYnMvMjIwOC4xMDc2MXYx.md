# CRCNet: Few-shot Segmentation with Cross-Reference and Region-Global Conditional Networks

Weide Liu, Chi Zhang, Guosheng Lin, Fayao Liu

## 🧩 Problem to Solve

소수 샷 분할(Few-shot Segmentation, FSS)은 적은 수의 학습 이미지만으로 새로운 클래스에 일반화될 수 있는 분할 모델을 학습하는 것을 목표로 합니다. 기존 FSS 연구들은 주로 지원(support) 이미지를 사용하여 쿼리(query) 이미지의 분할을 일방적으로 안내하는 비대칭적인 접근 방식을 취하여, 지원 이미지와 쿼리 이미지 간의 정보를 충분히 활용하지 못했습니다. 또한, 객체의 지역적 유사성을 포착하는 데 한계가 있었고, 예측 마스크를 효과적으로 정제하는 메커니즘이 부족했습니다.

## ✨ Key Contributions

* **대칭적 교차 참조 네트워크(Cross-Reference Network) 제안:** 쿼리 세트와 지원 세트 모두에 대해 동시에 예측을 수행하여, 두 이미지에서 공존하는 특징을 발굴함으로써 분할 성능을 효과적으로 개선했습니다.
* **마스크 정제 모듈(Mask Refinement Module) 개발:** 신뢰도 캐시(confidence cache)를 사용하여 예측 결과를 반복적으로 정제할 수 있는 모듈을 개발했습니다.
* **k-샷 학습을 위한 미세 조정(Finetuning) 방식 제안:** 여러 지원 이미지를 효과적으로 처리하고 일관된 정확도 향상을 가져오는 솔루션을 제시했습니다.
* **전역-지역 조건 모듈(Local-Global Conditional Module) 개발:** 쿼리 이미지와 지원 이미지 간의 지역적 및 전역적 관계를 모두 포착하여 성능을 더욱 향상시켰습니다.
* **확장된 연구 및 분석:** 이전 회의 버전(CRNet)에서 전역-지역 조건 모듈을 추가하고, FSS-1000 및 MS COCO 데이터셋에 대한 새로운 실험, 약지도(weakly-supervised) 분할 작업에 대한 평가, 그리고 각 구성 요소의 효과를 검증하는 포괄적인 어블레이션 연구(ablation studies)를 수행했습니다.

## 📎 Related Works

* **소수 샷 학습(Few-shot Learning):** 주로 임베딩 인코더를 통해 이미지 쌍 유사성을 측정하는 메트릭 기반(metric-based) 접근 방식과 새로운 작업에 맞춰 모델 파라미터를 조정하는 미세 조정(finetuning-based) 방식이 있습니다. 어텐션(attention) 메커니즘도 널리 사용됩니다.
* **의미론적 분할(Semantic Segmentation):** 심층 신경망을 사용하여 각 픽셀을 분류하는 작업으로, 인코더-디코더(encoder-decoder) 구조, 건너뛰기 연결(skip connections), 전역 및 지역 정보 활용이 특징입니다.
* **소수 샷 분할(Few-shot Segmentation):** 지도(guided) 분할 작업으로 정식화되며, 지원 임베딩을 쿼리 브랜치에 융합하거나, 프로토타입 학습(prototype learning), 코사인 유사도(cosine similarity) 기반 안내, 반복적 정제(recurrent refinement) 등의 방법이 연구되었습니다.
* **이미지 공동 분할(Image Co-segmentation):** 여러 이미지에서 공통 객체를 공동으로 분할하는 연구로, 샴 네트워크(Siamese network)나 채널 어텐션(channel attention)을 활용합니다. CRCNet은 이 공동 분할 접근 방식에서 영감을 받았습니다.

## 🛠️ Methodology

CRCNet은 쿼리 이미지와 지원 이미지 모두에서 예측을 수행하는 대칭적인 네트워크 구조를 가지며, 네 가지 주요 모듈로 구성됩니다.

* **샴 인코더(Siamese Encoder):**
  * 파라미터를 공유하는 합성곱 신경망(CNN) 쌍으로, ImageNet 사전 훈련된 ResNet-50을 백본으로 사용하여 쿼리 및 지원 이미지를 특징 맵(feature map)으로 인코딩합니다.
  * 다중 레벨 특징(multi-level features)과 건너뛰기 연결(skip connections)을 활용하여 대표적인 특징 임베딩을 얻습니다.
* **교차 참조 모듈(Cross-Reference Module):**
  * 두 이미지의 공존 특징(co-occurrent features)을 발굴하기 위해 설계되었습니다.
  * 입력 특징 맵 $F_s$ (지원)와 $F_q$ (쿼리)의 전역 평균 풀링(global average pooling)을 통해 전역 통계를 얻습니다.
  * 완전 연결(FC) 레이어와 시그모이드(Sigmoid) 활성화 함수를 사용하여 채널 중요도 벡터를 생성하고, 이를 요소별 곱셈(element-wise multiplication)으로 융합하여 공통 특징을 강조합니다.
  * 융합된 벡터로 입력 특징 맵의 가중치를 재조정하여 강화된 특징 표현 $G_s, G_q$를 생성합니다.
  * 보조 분할 헤드를 포함하여 훈련 시 공존 객체 예측에 대한 추가 손실($L_{QM_{sub}}, L_{SM_{sub}}$)을 제공합니다.
* **조건 모듈(Conditional Module):**
  * **전역 조건 모듈(Global Conditional Module):** 지원 마스크를 활용한 마스크 평균 풀링(masked average pooling)을 통해 범주 관련 벡터를 생성하고, 이를 쿼리 특징 맵과 병합한 후 잔여 합성곱(residual convolution)으로 처리하여 전역 조건을 제공합니다.
  * **지역 조건 모듈(Local Conditional Module):** 쿼리 이미지와 지원 이미지 간의 지역적 유사성을 포착합니다.
    * 쿼리 특징 $F_q$와 지원 특징 $F_s$ 간의 유사성 행렬 $M_{sim} = \theta(F_q)^T \otimes \delta(F_s)$를 계산합니다 (여기서 $\theta, \delta$는 1x1 합성곱 + ReLU).
    * 지원 마스크를 사용하여 배경 특징을 제거하고 전경 유사성 행렬을 생성합니다.
    * Softmax를 통해 각 행을 정규화하여 어텐션 행렬 $M'_{sim}$를 얻습니다.
    * 지원 특징과 어텐션 행렬을 곱하여 쿼리 어텐션 맵 $F'_q = F_s \otimes M'_{sim}$를 생성합니다.
  * 전역 및 지역 조건 모듈의 출력을 융합하여 최종 조건 특징을 만듭니다.
* **마스크 정제 모듈(Mask Refinement Module):**
  * 이전 예측에서 생성된 신뢰도 맵(confidence map)을 캐시에 저장하고, 이를 다음 예측 단계의 입력으로 활용하여 마스크를 반복적으로 정제합니다.
  * 전역 합성곱 블록(global convolution block)과 결합 블록(combined block)을 사용하여 캐시된 신뢰도 맵과 현재 특징 맵을 효과적으로 융합합니다.
  * 이 모듈을 여러 번(예: 10회) 실행하여 최종 정제된 마스크를 생성합니다.
* **k-샷 학습을 위한 미세 조정:**
  * k-샷 시나리오에서는 샴 인코더를 제외한 나머지 모듈의 파라미터를 지원 세트의 레이블된 이미지 쌍을 사용하여 미세 조정합니다. 이 방식은 지원 이미지 수가 증가할수록 성능이 꾸준히 향상되는 장점이 있습니다.
* **훈련 목적 함수:**
  * 쿼리 예측 마스크($L_{QM}, L_{QM_{sub}}$)와 지원 예측 마스크($L_{SM}, L_{SM_{sub}}$)에 대한 4개의 이진 교차 엔트로피 손실(Binary Cross-Entropy Loss, BCEloss)을 결합합니다.
    $$L = (L_{QM} + L_{SM}) + \lambda(L_{QM_{sub}} + L_{SM_{sub}})$$
    여기서 $\lambda$는 하이퍼파라미터로 0.1로 설정됩니다.

## 📊 Results

* **최첨단 성능 달성:** PASCAL VOC 2012, MS COCO, FSS-1000 데이터셋에서 1-샷 및 5-샷 설정 모두에서 mIoU 및 FBIoU 메트릭 기준으로 새로운 최첨단(State-of-the-Art) 성능을 달성했습니다.
* **어블레이션 연구:**
  * **교차 참조 모듈:** 베이스라인(조건 모듈만 사용) 대비 성능을 크게 향상시켰습니다 (예: PASCAL VOC 1-샷에서 3.8% mIoU 향상).
  * **마스크 정제 모듈:** PASCAL VOC 1-샷에서 2.6% mIoU 성능 향상을 가져왔습니다.
  * **전역-지역 조건 모듈:** 전역 조건과 지역 조건을 모두 결합했을 때 4.4% mIoU 향상을 보였습니다.
  * **다중 레벨 특징 및 다중 스케일 입력:** 다중 레벨 특징은 3.4% mIoU, 다중 스케일 입력은 0.8% mIoU 성능 향상에 기여했습니다.
  * **k-샷 미세 조정:** 기존 융합(fusion) 기반 방법보다 일관된 성능 향상을 보였으며, 특히 지원 이미지 수가 증가할수록 그 이점이 더 커졌습니다 (예: PASCAL VOC 5-샷에서 1-샷 베이스라인 대비 8.4% mIoU 향상). PFENet에 적용했을 때도 성능이 개선되었습니다.
  * **활성화 함수:** 교차 참조 모듈에서 시그모이드(Sigmoid) 활성화 함수가 렐루(ReLU), 소프트맥스(Softmax)보다 우수한 성능을 보였습니다.
  * **지역 조건 모듈 내 지원 마스크:** 배경 정보를 억제하는 데 효과적임이 입증되었습니다.
* **약지도 소수 샷 분할(Weakly Supervised Few Shot Segmentation):** 바운딩 박스(bounding box) 주석을 사용한 약지도 설정에서도 픽셀 단위 주석과 비슷한 성능을 보이며, 기존 방법들을 능가하여 CRCNet의 견고성을 입증했습니다.

## 🧠 Insights & Discussion

* **상호 참조의 중요성:** 기존의 일방적인 접근 방식과 달리, 쿼리와 지원 이미지가 서로의 분할을 안내할 수 있다는 대칭적 설계의 중요성을 보여주었습니다. 이는 두 이미지 간의 공존 객체 특징을 효과적으로 발굴합니다.
* **전역 및 지역 관계 활용:** 전역 및 지역 조건 모듈을 결합하여 특징 비교를 강화함으로써, 객체 부분 간의 유사성과 같은 미묘한 관계를 포착하여 객체의 외형 변화나 가려짐에도 불구하고 견고한 분할을 가능하게 했습니다.
* **점진적 정제의 효과:** 마스크 정제 모듈은 높은 신뢰도를 가진 초기 예측 영역(seed region)부터 시작하여 점진적으로 마스크를 개선하는 전략이 복잡한 객체 분할에 매우 효과적임을 입증했습니다.
* **k-샷 학습의 확장성:** 제안된 미세 조정 방식은 더 많은 지원 데이터를 효과적으로 활용하여 융합 기반 방식의 성능 포화 문제를 해결하고, k-샷 시나리오에서 모델의 확장성을 크게 향상시켰습니다.
* **제한 사항:** 모델은 개/고양이, 의자/테이블과 같이 의미론적으로 유사한 객체들을 구별하는 데 어려움을 겪는 경향이 있습니다. 또한, 매우 작은 객체나 지원 이미지에 부분적인 정보만 포함된 객체(예: 새 머리만 있는 지원 이미지로 전체 새 몸체를 분할)에 대해서는 성능이 저하될 수 있습니다.

## 📌 TL;DR

**문제:** 소수 샷 분할은 적은 데이터로 새로운 클래스에 일반화하는 것을 목표로 하지만, 기존 방법은 쿼리-지원 이미지 간의 비대칭적 정보 활용과 지역 유사성 포착의 한계가 있었습니다.
**해결책:** CRCNet은 쿼리 및 지원 이미지 모두에서 예측을 수행하는 대칭적인 교차 참조(cross-reference) 메커니즘을 제안합니다. 이는 전역 및 지역 조건 모듈(local-global conditional module)로 특징 비교를 강화하고, 마스크 정제 모듈(mask refinement module)로 예측을 반복적으로 정제합니다. k-샷 학습에는 미세 조정(finetuning) 방식을 사용하여 여러 지원 이미지를 효율적으로 활용합니다.
**성과:** PASCAL VOC 2012, MS COCO, FSS-1000 데이터셋에서 최첨단 성능을 달성했으며, 제안된 각 모듈이 성능 향상에 기여하고 미세 조정 방식이 다수의 지원 이미지에 대해 일관된 정확도 향상을 가져옴을 입증했습니다.
