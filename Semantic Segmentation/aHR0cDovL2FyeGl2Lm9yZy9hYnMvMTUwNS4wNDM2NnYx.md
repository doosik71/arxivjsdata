# Learning Deconvolution Network for Semantic Segmentation
Hyeonwoo Noh, Seunghoon Hong, Bohyung Han

## 🧩 Problem to Solve
기존의 완전 합성곱 네트워크(FCN) 기반 의미론적 분할(Semantic Segmentation) 방법론들은 다음과 같은 주요 한계점을 가지고 있습니다:
- **고정된 수용 필드(Receptive Field)로 인한 규모(Scale) 문제:** FCN은 고정된 수용 필드로 인해 이미지 내 단일 스케일의 의미만을 처리할 수 있습니다. 이로 인해 객체가 수용 필드보다 너무 크거나 작으면 분할이 부정확하거나(큰 객체의 레이블 불일치) 아예 무시되는(작은 객체 누락) 문제가 발생합니다.
- **상세 구조 손실:** FCN에서 사용되는 레이블 맵은 종종 너무 거칠고 (예: FCN-16s의 16x16 맵) 역합성곱(deconvolution) 절차가 단순한 보간(bilinear interpolation)에 불과하여 객체의 상세한 구조를 재구성하기 어렵습니다. 이는 픽셀 단위 분할의 정확도를 떨어뜨립니다.

## ✨ Key Contributions
- **다층 역합성곱 네트워크 학습:** 역합성곱(deconvolution), 역풀링(unpooling), ReLU(Rectified Linear Unit) 레이어로 구성된 새로운 다층 역합성곱 네트워크를 학습하여 의미론적 분할에 적용했습니다. 이는 이전까지 시도되지 않은 접근 방식입니다.
- **개별 객체 제안(Proposal) 기반 분할:** 학습된 네트워크를 개별 객체 제안에 적용하여 인스턴스별 분할을 수행한 후, 이를 결합하여 최종 의미론적 분할 맵을 생성합니다. 이는 FCN 기반 방법의 스케일 문제를 해결하고 객체의 미세한 세부 사항을 식별하는 데 효과적입니다.
- **최고 성능 달성 및 앙상블 효과 입증:** PASCAL VOC 2012 데이터셋만으로 뛰어난 성능을 달성했으며, FCN 기반 방법론과 상호 보완적인 특성을 활용한 앙상블을 통해 72.5%의 최고 정확도를 기록했습니다.

## 📎 Related Works
- **합성곱 신경망(CNN):** 이미지 분류 [15, 22, 23], 객체 탐지 [7, 9], 의미론적 분할 [6, 18], 행동 인식 [12, 21] 등 다양한 시각 인식 문제에서 성공을 거두었습니다.
- **분류 기반 의미론적 분할:** 다중 스케일 슈퍼픽셀 분류 [18, 6] 및 영역 제안 분류 [3, 9, 10]를 통해 픽셀 단위 레이블링을 수행하는 방법들이 있습니다.
- **완전 합성곱 네트워크(FCN):** [17]은 표준 CNN의 완전 연결 계층을 합성곱으로 변환하여 의미론적 분할을 수행했으며, 단순한 보간 필터로 역합성곱을 구현했습니다.
- **DeepLab-CRF:** [1]은 FCN 프레임워크 내에서 밀도 높은 스코어 맵을 얻고, 완전 연결된 조건부 확률장(CRF) [14]으로 레이블 맵을 정제했습니다.
- **약 지도(Weakly Supervised) 의미론적 분할:** 바운딩 박스 [2, 19] 또는 이미지 수준 주석 [20]만으로 분할을 수행하는 연구들도 있습니다.
- **역합성곱 네트워크:** [25]에서 입력 이미지 재구성을 위해 도입되었으며, [24]에서는 풀링 위치를 저장하는 역풀링(unpooling) 연산을 통해 학습된 CNN의 활성화된 특징을 시각화하는 데 활용되었습니다. 본 논문은 이 역합성곱 네트워크를 의미론적 분할을 위해 학습하여 사용합니다.

## 🛠️ Methodology
본 논문의 핵심은 합성곱 네트워크와 역합성곱 네트워크로 구성된 대칭적인 "디콘브넷(DeconvNet)" 아키텍처와 이를 활용한 인스턴스 기반 분할입니다.

- **네트워크 아키텍처:**
  - **합성곱 네트워크:** VGG 16-레이어 넷 [22]에서 마지막 분류 레이어를 제거한 형태로, 입력 이미지를 특징 표현으로 변환합니다.
  - **역합성곱 네트워크:** 합성곱 네트워크의 미러링 버전으로, 특징 표현으로부터 객체 분할 마스크를 생성합니다. 역풀링($\text{unpooling}$), 역합성곱($\text{deconvolution}$), 그리고 정류($\text{rectification}$) 레이어로 구성됩니다.
    - **역풀링:** 합성곱 네트워크의 풀링($\text{pooling}$) 시 최대 활성화 위치(스위치 변수)를 기록하여 공간 정보를 복원하고, 예시별(example-specific) 구조를 재구성합니다.
    - **역합성곱:** 역풀링으로 얻은 희소(sparse)한 활성화 맵을 학습된 필터로 밀도 있게(dense) 만듭니다. 필터는 계층적으로 객체의 클래스별($\text{class-specific}$) 형상 정보를 학습하며, 노이즈를 억제합니다.
- **인스턴스 기반 분할:**
  - 전체 이미지에 대해 EdgeBox [26]를 통해 객체 제안(proposal)을 생성하고, 각 제안에 대해 네트워크를 적용하여 픽셀 단위 클래스 예측을 수행합니다.
  - 이 예측 결과들을 원본 이미지 공간으로 집계합니다. 이때 픽셀 단위 최대값($\max_{i} G_{i}(x,y,c)$)을 사용하여 노이즈를 억제합니다.
  - 최종적으로 완전 연결된 CRF [14]를 적용하여 픽셀 단위 레이블링을 정제합니다.
- **학습 방법:**
  - **배치 정규화(Batch Normalization) [11]:** 각 합성곱 및 역합성곱 레이어의 출력에 적용하여 내부 공변량 변화(internal-covariate-shift) 문제를 줄이고, 깊은 네트워크의 최적화를 용이하게 합니다. 이는 학습에 필수적입니다.
  - **2단계 학습(Two-stage Training):**
    - **1단계:** 쉬운 예제(정답 주석을 1.2배 확장하여 객체가 중앙에 위치하도록 자른 이미지)로 네트워크를 학습시킵니다.
    - **2단계:** 더 어려운 예제(EdgeBox 제안 중 정답 분할과 충분히 겹치는 것)로 미세 조정하여 제안의 불일치에 강건하게 만듭니다.
  - **데이터 증강:** 250x250으로 리사이즈 후 224x224로 무작위 크롭, 수평 뒤집기 등을 사용합니다.
  - **최적화:** Caffe [13] 프레임워크 기반, SGD(Stochastic Gradient Descent) 사용. 합성곱 네트워크 가중치는 ILSVRC [4] 사전 학습된 VGG 모델로 초기화, 역합성곱 네트워크는 0평균 가우시안으로 초기화합니다.
- **추론 방법:**
  - 테스트 이미지당 EdgeBox를 통해 약 2000개의 객체 제안을 생성하고, 객체성(objectness) 점수에 따라 상위 50개를 선택합니다.
  - 각 제안에 대한 인스턴스별 예측 결과를 픽셀 단위 최댓값으로 집계합니다.
  - **FCN과의 앙상블:** DeconvNet(미세 세부사항, 다중 스케일 처리 우수)과 FCN(전반적인 객체 형태, 문맥 추출 우수)의 상호 보완적 특성을 활용하여, 두 네트워크의 클래스 조건부 확률 맵의 평균을 계산한 후 CRF를 적용하여 최종 분할 맵을 얻습니다.

## 📊 Results
- **PASCAL VOC 2012 평가:** Intersection over Union (IoU) 기준으로 평가.
- **DeconvNet 단독 성능:** 기존 최신 방법론들과 비교하여 경쟁력 있는 성능을 보였습니다 (평균 IoU 69.6%).
- **CRF 적용 효과:** CRF 후처리를 통해 정확도가 약 1%p 향상되었습니다 (DeconvNet+CRF: 70.5%).
- **FCN과의 앙상블(EDeconvNet):** FCN-8s(62.2%)와 DeconvNet+CRF(70.5%) 대비 현저히 높은 성능을 달성했습니다. 특히, EDeconvNet+CRF는 PASCAL VOC 데이터만으로 학습된 방법 중 72.5%의 최고 정확도를 기록했습니다.
- **인스턴스 기반 예측의 장점:** 객체 제안을 크기 감소 순으로 집계하면서 분할이 점진적으로 개선되는 것을 확인, 이는 다중 스케일 객체를 효과적으로 처리하고 미세 구조를 식별하는 능력(그림 6)을 보여줍니다.
- **정성적 결과 (그림 7):** DeconvNet은 FCN보다 미세한 분할을 생성하고 다중 스케일 객체를 효과적으로 처리합니다. FCN이 너무 크거나 작은 객체에서 실패하는 경향을 보이지만, DeconvNet은 제안이 잘못 정렬되거나 배경에 위치할 경우 노이즈가 발생할 수 있습니다. 그러나 FCN과의 앙상블은 두 방법의 단점을 보완하고, 심지어 개별적으로는 부정확했던 예측까지 개선하는 결과를 보여주었습니다.

## 🧠 Insights & Discussion
- 제안된 역합성곱 네트워크는 역풀링 및 역합성곱 연산의 연속을 통해 거친 수준에서 미세 수준으로 객체 구조를 점진적으로 재구성함으로써, 밀도 있고 정밀한 객체 분할 마스크를 생성하는 데 적합합니다.
- 인스턴스 기반 예측 방식은 FCN의 고정된 수용 필드 한계를 극복하여 객체 스케일 변화에 자연스럽게 대처할 수 있도록 합니다.
- DeconvNet(미세한 세부사항 및 인스턴스 처리)과 FCN(전반적인 객체 형태 및 문맥)의 상호 보완적인 특성이 두 알고리즘의 앙상블이 현저히 우수한 성능을 달성하는 데 결정적인 역할을 합니다. 이는 다른 FCN 기반 알고리즘과의 주요 차별점입니다.
- 배치 정규화와 2단계 학습 전략은 한정된 데이터로 매우 깊은 네트워크를 성공적으로 최적화하는 데 필수적인 요소였습니다.
- CRF는 추가적인 정확도 향상을 제공하지만, 그 개선 폭이 크지 않다는 점은 네트워크 자체가 이미 좋은 경계를 학습하고 있음을 시사합니다.

## 📌 TL;DR
- **문제:** 기존 FCN은 고정된 수용 필드와 단순한 역합성곱으로 인해 다중 스케일 객체 처리 및 상세 분할에서 한계를 보였습니다.
- **해결책:** VGG 기반 합성곱 네트워크 위에 역풀링과 학습된 역합성곱 레이어로 구성된 새로운 "역합성곱 네트워크"를 제안했습니다. 이 네트워크는 개별 객체 제안을 처리하여 상세한 픽셀 단위 분할 마스크를 생성하며, 배치 정규화와 2단계 학습을 통해 최적화되었습니다.
- **주요 결과:** PASCAL VOC 2012에서 외부 데이터 없이 최고 성능을 달성했으며, FCN과의 앙상블을 통해 두 방법론의 상호 보완적 장점(디콘브넷은 미세 구조/다중 스케일, FCN은 전반적 문맥)을 활용하여 평균 IoU 72.5%라는 뛰어난 정확도를 기록했습니다.