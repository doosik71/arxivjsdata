{
  "url": "http://arxiv.org/abs/1903.02351v1",
  "title": "CANet: Class-Agnostic Segmentation Networks with Iterative Refinement\n  and Attentive Few-Shot Learning",
  "authors": "Chi Zhang, Guosheng Lin, Fayao Liu, Rui Yao, Chunhua Shen",
  "year": 2019,
  "abstract": "Recent progress in semantic segmentation is driven by deep Convolutional\nNeural Networks and large-scale labeled image datasets. However, data labeling\nfor pixel-wise segmentation is tedious and costly. Moreover, a trained model\ncan only make predictions within a set of pre-defined classes. In this paper,\nwe present CANet, a class-agnostic segmentation network that performs few-shot\nsegmentation on new classes with only a few annotated images available. Our\nnetwork consists of a two-branch dense comparison module which performs\nmulti-level feature comparison between the support image and the query image,\nand an iterative optimization module which iteratively refines the predicted\nresults. Furthermore, we introduce an attention mechanism to effectively fuse\ninformation from multiple support examples under the setting of k-shot\nlearning. Experiments on PASCAL VOC 2012 show that our method achieves a mean\nIntersection-over-Union score of 55.4% for 1-shot segmentation and 57.1% for\n5-shot segmentation, outperforming state-of-the-art methods by a large margin\nof 14.6% and 13.2%, respectively."
}