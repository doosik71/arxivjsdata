# Fully Convolutional Networks for Semantic Segmentation
Jonathan Long, Evan Shelhamer, Trevor Darrell

## 🧩 Problem to Solve
기존의 컨볼루션 네트워크(ConvNets)는 이미지 분류와 같은 전체 이미지 수준의 인식 작업에서 뛰어난 성능을 보였지만, 픽셀 단위로 객체나 영역을 분류하는 시맨틱 분할(semantic segmentation)에는 여러 제약이 있었습니다. 주요 문제는 다음과 같습니다:
- **고정된 입력 크기 및 비공간적 출력:** 일반적인 분류 ConvNet은 고정된 크기의 입력을 받으며 최종적으로는 공간적 정보가 없는 단일 벡터 출력을 생성하여, 임의 크기의 이미지에 대한 픽셀 단위 예측에 적합하지 않았습니다.
- **효율성 부족:** 이미지의 모든 픽셀에 대해 밀집된 예측을 수행하기 위해서는 각 픽셀 또는 패치마다 네트워크를 여러 번 실행해야 하므로 계산 효율성이 매우 낮았습니다.
- **시맨틱과 위치 정보 간의 충돌:** 깊은 계층은 전역적인 '무엇(what)'에 대한 시맨틱 정보를 제공하지만 공간적 해상도가 낮아 세부적인 '어디(where)'에 대한 위치 정보를 잃기 쉬웠습니다. 반대로 얕은 계층은 미세한 위치 정보를 담고 있지만 시맨틱 정보가 부족했습니다.
- **복잡한 후처리:** 기존 시맨틱 분할 접근 방식은 슈퍼픽셀, 제안 영역, 조건부 랜덤 필드(CRF)와 같은 복잡한 전/후처리 기법에 의존하여 종단 간(end-to-end) 학습이 어려웠습니다.

## ✨ Key Contributions
이 논문은 시맨틱 분할을 위한 '완전 컨볼루션 네트워크(Fully Convolutional Networks, FCNs)'를 제안하며 다음과 같은 핵심 기여를 했습니다.
- **FCN의 개념 도입 및 정의:** 임의 크기의 입력을 받아 그에 상응하는 크기의 공간적 출력 맵을 생성하는 FCN의 개념을 정의하고 기존 분류 네트워크를 FCN으로 변환하는 방법을 제시했습니다. 이를 통해 효율적인 추론 및 학습이 가능해졌습니다.
- **종단 간 픽셀-투-픽셀 학습:** FCN을 시맨틱 분할을 위해 픽셀-투-픽셀 방식으로 종단 간 학습시켜, 추가적인 복잡한 전/후처리 없이도 기존 최고 성능을 뛰어넘는 결과를 달성했습니다.
- **분류 네트워크의 전이 학습 활용:** AlexNet, VGG, GoogLeNet과 같은 현대적인 이미지 분류 네트워크를 FCN으로 재구성하고 시맨틱 분할 작업에 대해 미세 조정(fine-tuning)하여 학습된 표현을 효과적으로 전이했습니다.
- **새로운 스킵 아키텍처(Skip Architecture) 제안:** 깊고 거친 계층의 시맨틱 정보와 얕고 미세한 계층의 외형 정보를 결합하는 독창적인 아키텍처를 도입하여 정확하고 세부적인 분할 결과를 생성했습니다 (FCN-16s, FCN-8s).
- **디컨볼루션(Deconvolution)을 통한 인-네트워크 업샘플링:** 픽셀 단위 예측을 위해 서브샘플링된 특징 맵을 네트워크 내에서 효율적으로 업샘플링하기 위해 학습 가능한 디컨볼루션 레이어를 사용했습니다.
- **최첨단 성능 달성 및 효율성 입증:** PASCAL VOC (2012년 데이터셋에서 평균 IU 62.2%로 20% 상대적 개선), NYUDv2, SIFT Flow 데이터셋에서 최고 성능을 달성했으며, 일반적인 이미지에 대한 추론 시간이 0.2초 미만으로 매우 빨랐습니다.

## 📎 Related Works
- **심층 분류 네트워크 및 전이 학습:** 이미지 분류에서의 AlexNet [19], VGG [31], GoogLeNet [32]과 전이 학습 [4, 38]의 성공에 기반을 두었습니다.
- **완전 컨볼루션 네트워크(FCNs)의 선행 연구:**
    - Matan et al. [25]은 LeNet을 확장하여 숫자 문자열을 인식하는 데 FCN의 아이디어를 처음 사용했습니다.
    - Wolf and Platt [37]은 우편 주소 블록의 4개 코너에 대한 2D 감지 점수 맵을 출력하는 컨볼루션 네트워크를 확장했습니다.
    - Ning et al. [27]은 거친 다중 클래스 분할을 위해 FCN 추론을 사용했습니다.
    - Sermanet et al. [29] (OverFeat), Pinheiro and Collobert [28], Eigen et al. [5]은 완전 컨볼루션 추론을 수행했습니다.
    - Tompson et al. [35]은 종단 간 부분 감지기 및 자세 추정을 학습하기 위해 완전 컨볼루션 학습을 효과적으로 사용했습니다.
- **ConvNet을 사용한 밀집 예측 (이전 접근 방식의 한계점):**
    - 작은 모델, 패치별 학습 [27, 2, 8, 28, 11], 슈퍼픽셀 투영, 랜덤 필드 정규화 등 후처리 [8, 16, 2, 11]에 의존했습니다.
    - Hariharan et al. [16] 및 Gupta et al. [14]는 심층 분류 네트워크를 시맨틱 분할에 적용했지만, 종단 간 학습되지 않는 하이브리드 제안-분류기 모델이었습니다.

## 🛠️ Methodology
논문은 다음 단계로 시맨틱 분할을 위한 FCN을 구축하고 학습했습니다.

1.  **분류 네트워크의 FCN 변환 (Convolutionalization):**
    *   AlexNet, VGG16, GoogLeNet과 같은 기존 이미지 분류 네트워크를 사용했습니다.
    *   이 네트워크의 마지막 분류 레이어(fully connected layers)를 제거하고, 모든 완전 연결 레이어를 컨볼루션 레이어로 변환했습니다. 이는 완전 연결 레이어가 전체 입력 영역을 덮는 커널을 가진 컨볼루션으로 간주될 수 있다는 점을 활용한 것입니다.
    *   변환된 마지막 컨볼루션 레이어 뒤에 1x1 컨볼루션 레이어를 추가하여 PASCAL VOC의 21개 클래스(배경 포함)에 대한 스코어를 예측하도록 했습니다. 이로 인해 임의 크기의 입력에 대해 공간적 출력 맵(스코어 맵)을 생성할 수 있게 되었습니다.

2.  **인-네트워크 업샘플링 (In-network Upsampling):**
    *   변환된 FCN의 출력 맵은 특징 추출 과정에서 풀링(pooling) 등으로 인해 원본 이미지보다 해상도가 낮습니다 (예: 32픽셀 스트라이드).
    *   이 거친 스코어 맵을 픽셀 단위 예측을 위해 원본 이미지 크기로 되돌리기 위해 **디컨볼루션(Deconvolution)** 레이어(또는 전치 컨볼루션, transposed convolution)를 사용했습니다.
    *   이 디컨볼루션 필터는 고정된 선형 보간(예: 바이리니어 보간)으로 초기화될 수 있지만, 역전파를 통해 **학습될 수 있도록** 하여 네트워크가 최적의 업샘플링 방법을 학습하도록 했습니다.

3.  **스킵 아키텍처 (Skip Architecture)를 통한 정제:**
    *   단순히 최종 계층에서 업샘플링하는 것(FCN-32s)은 세부 정보를 잃기 쉬웠습니다.
    *   이를 개선하기 위해, 깊은 계층의 거친 시맨틱 정보와 얕은 계층의 미세한 외형 정보를 결합하는 "스킵 연결(skip connection)"을 도입했습니다.
    *   **FCN-16s:** 마지막 계층(stride 32)의 예측을 2배 업샘플링한 것과 `pool4` 계층(stride 16)에서 얻은 예측을 1x1 컨볼루션으로 변환한 것을 합산하여 더 정교한 예측을 생성했습니다.
    *   **FCN-8s:** FCN-16s의 예측을 2배 업샘플링한 것과 `pool3` 계층(stride 8)에서 얻은 예측을 1x1 컨볼루션으로 변환한 것을 합산하여 공간적 정밀도를 더욱 높였습니다.

4.  **학습 전략:**
    *   **전이 학습 및 미세 조정:** ImageNet으로 사전 학습된 분류 네트워크의 가중치를 사용하여 FCN을 초기화하고, 시맨틱 분할 작업에 대해 전체 네트워크를 종단 간 미세 조정했습니다.
    (최종 분류 레이어만 미세 조정하는 것보다 전체 레이어를 미세 조정하는 것이 훨씬 효과적임을 입증했습니다).
    *   **최적화:** 모멘텀을 사용한 확률적 경사 하강법(SGD with momentum)을 사용했습니다.
    *   **전체 이미지 학습:** 패치별 학습보다 효율적이고 효과적임을 발견하여, 전체 이미지를 사용하여 학습했습니다. 패치 샘플링은 수렴 속도를 향상시키지 못했습니다.

## 📊 Results
이 논문에서 제안된 FCN 모델은 다양한 시맨틱 분할 및 장면 파싱 데이터셋에서 최첨단 성능을 달성했으며, 주요 결과는 다음과 같습니다:

-   **PASCAL VOC 2011/2012:**
    *   FCN-8s는 PASCAL VOC 2011 테스트 세트에서 62.7%의 평균 IU (Intersection over Union)를, 2012년 테스트 세트에서 62.2%를 달성했습니다.
    *   이는 이전 최고 성능 시스템인 SDS [16] (52.6% 평균 IU) 대비 약 20%의 상대적 개선을 보여주었습니다.
    *   추론 시간은 일반적인 이미지당 약 175ms로, SDS (약 50초)에 비해 286배 이상 빨라, 효율성 면에서도 압도적인 우위를 보였습니다.

-   **NYUDv2 (RGB-D 데이터셋):**
    *   RGB 이미지만 사용한 FCN-32s는 29.2%의 평균 IU를 기록했습니다.
    *   깊이 정보를 HHA 인코딩 [14]으로 변환하여 RGB 정보와 늦은 퓨전(late fusion) 방식으로 결합한 FCN-16s RGB-HHA 모델은 34.0%의 평균 IU를 달성하여 깊이 정보의 유효성을 입증했습니다.

-   **SIFT Flow (시맨틱 및 기하학적 레이블):**
    *   FCN-16s의 두 개 헤드(two-headed) 버전을 학습하여 시맨틱 카테고리(33개)와 기하학적 카테고리(3개)를 동시에 예측했습니다.
    *   시맨틱 분할에서 39.5%의 평균 IU를, 기하학적 분할에서 94.3%의 픽셀 정확도를 달성하여 두 가지 작업 모두에서 최첨단 성능을 기록했습니다. 이는 두 작업을 독립적으로 학습한 모델과 동일한 성능을 보이면서도 학습 및 추론 속도는 개별 모델과 유사했습니다.

-   **PASCAL-Context:**
    *   FCN-8s는 59개 클래스 태스크에서 35.1%의 평균 IU를 달성하여 이전 최고 성능 (CFM, 31.5%) 대비 11% 상대적 개선을 이루었습니다.

## 🧠 Insights & Discussion
-   **FCN의 일반성:** 이 연구는 최신 이미지 분류 ConvNet이 FCN의 특수한 사례이며, 이를 시맨틱 분할에 맞게 확장하고 다중 해상도 계층 조합(스킵 아키텍처)을 통해 성능을 극적으로 향상시킬 수 있음을 보여주었습니다. 이는 분류 작업에서 학습된 강력한 특징 계층 구조가 픽셀 단위 예측에서도 매우 효과적임을 시사합니다.
-   **종단 간 학습의 효율성:** 복잡한 전처리(예: 슈퍼픽셀)나 후처리(예: CRF) 없이도 네트워크를 픽셀-투-픽셀 방식으로 종단 간 학습함으로써 학습 및 추론 과정을 크게 단순화하고 가속화했습니다. 특히, 완전 컨볼루션 방식의 전체 이미지 학습이 패치별 학습보다 효율적임을 입증했습니다.
-   **깊은 특징 계층의 가치:** 깊은 계층은 전역적인 시맨틱 정보를 포착하는 데 중요하며, 얕은 계층은 지역적인 세부 정보를 유지합니다. 이 두 정보를 효과적으로 융합하는 스킵 아키텍처는 "무엇"과 "어디" 사이의 본질적인 충돌을 해결하며, 분할 결과의 정확도와 세밀함을 모두 향상시켰습니다.
-   **평가 지표의 한계:** 평균 IU와 같은 지표는 대규모 객체의 정확도를 잘 측정하지만, 미세한 스케일의 정확도(예: 얇은 객체 경계)를 완전히 반영하지 못할 수 있음을 언급했습니다. 아주 거친 예측으로도 높은 평균 IU를 달성할 수 있다는 분석(부록 A)은 세부적인 분할 품질 평가에 있어 추가적인 지표의 필요성을 시사합니다.

## 📌 TL;DR
**문제:** 기존 분류 ConvNet은 고정된 입력과 거친 출력으로 인해 픽셀 단위 시맨틱 분할에 비효율적이었고, 이전 방법들은 복잡한 전/후처리에 의존했습니다.
**제안 방법:** 이 논문은 기존 분류 ConvNet의 완전 연결(FC) 레이어를 컨볼루션 레이어로 변환하여 임의 크기 입력에 대응하는 '완전 컨볼루션 네트워크(FCN)'를 제안했습니다. 학습 가능한 '디컨볼루션'을 통해 네트워크 내에서 효율적으로 업샘플링하며, 깊은 계층의 시맨틱 정보와 얕은 계층의 미세한 외형 정보를 결합하는 '스킵 아키텍처'를 도입하여 공간적 세부 사항을 개선했습니다. 이 모든 과정을 전체 이미지를 사용하여 종단 간 학습했습니다.
**핵심 결과:** FCN은 PASCAL VOC (2012년 데이터셋에서 평균 IU 62.2%로 20% 상대적 개선), NYUDv2, SIFT Flow에서 최첨단 성능을 달성했으며, 추론 시간을 획기적으로 단축하여 효율적이고 상세한 시맨틱 분할을 가능하게 했습니다.