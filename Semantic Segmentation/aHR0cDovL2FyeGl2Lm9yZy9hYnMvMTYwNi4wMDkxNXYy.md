# DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs

Liang-Chieh Chen, George Papandreou, Iasonas Kokkinos, Kevin Murphy, and Alan L. Yuille

## 🧩 Problem to Solve

본 논문은 심층 컨볼루션 신경망(DCNN)을 활용한 시맨틱 이미지 분할에서 발생하는 세 가지 주요 문제를 해결하고자 합니다.

1. **감소된 특징 해상도:** DCNN의 반복적인 최대 풀링(max-pooling) 및 다운샘플링(`striding`) 작업으로 인해 특징 맵의 공간 해상도가 크게 감소하여 조밀한 픽셀 예측이 어려워집니다.
2. **다중 스케일 객체의 존재:** 이미지 내 객체들이 다양한 크기로 존재하여, DCNN이 모든 스케일의 객체를 효과적으로 인식하고 분할하는 데 어려움이 있습니다.
3. **감소된 지역화 정확도:** DCNN의 본질적인 공간 변환 불변성(invariance)은 분류 작업에는 유리하지만, 객체 경계의 정확한 위치를 파악하는 데는 한계가 있습니다.

## ✨ Key Contributions

본 논문은 위에 언급된 문제들을 해결하기 위해 다음과 같은 세 가지 주요 기여를 합니다.

- **Atrous Convolution(확장 컨볼루션) 도입:** 업샘플링된 필터를 사용하는 `atrous convolution`을 통해 DCNN 내에서 특징 응답이 계산되는 해상도를 명시적으로 제어하고, 매개변수나 계산량 증가 없이 필터의 시야(Field-of-View, FOV)를 효과적으로 확장하여 더 넓은 컨텍스트를 통합할 수 있도록 합니다.
- **Atrous Spatial Pyramid Pooling (ASPP) 제안:** 다중 스케일 객체를 강력하게 분할하기 위해 다양한 샘플링 레이트와 유효 시야를 가진 필터로 입력 컨볼루션 특징 레이어를 탐색하여 다중 스케일에서 객체와 이미지 컨텍스트를 포착합니다.
- **DCNN과 Fully Connected CRF 결합:** DCNN의 최종 레이어 응답과 완전 연결 조건부 확률장(Conditional Random Field, CRF)을 결합하여 객체 경계의 지역화 정확도를 크게 향상시킵니다.
- **최고 성능 달성:** 제안된 "DeepLab" 시스템은 PASCAL VOC-2012 시맨틱 이미지 분할 태스크에서 79.7%의 mIOU(평균 교차-합집합)를 달성하며 새로운 최고 성능을 기록했고, PASCAL-Context, PASCAL-Person-Part, Cityscapes와 같은 다른 데이터셋에서도 성능을 향상시켰습니다.

## 📎 Related Works

- **전통적인 시맨틱 분할:** 수공예 특징(hand-crafted features)과 Boosting [24], Random Forests [43], SVM [44] 등의 분류기를 결합한 방식이 주를 이루었으며, 구조화된 예측 기법 [22], [26], [27], [46]이 성능을 향상시켰습니다.
- **DCNN 기반 시스템 (초기):**
  - **세분화-분류 캐스케이드:** 이미지 세분화 후 DCNN 기반 영역 분류를 수행하는 방식 [7], [49], [50]. 날카로운 경계를 제공하지만 세분화 오류에 취약했습니다.
  - **조밀한 특징 라벨링:** 컨볼루션으로 계산된 DCNN 특징을 조밀한 이미지 라벨링에 사용하고 독립적으로 얻은 세분화와 결합하는 방식 [39], [21], [51]. DCNN 분류기와 세분화 알고리즘이 분리되어 있었습니다.
  - **직접적인 픽셀 라벨링 (FCNs):** DCNN을 이미지 전체에 직접 완전 컨볼루션 방식으로 적용하여 픽셀 수준의 라벨을 제공 [14], [52]. 공간 지역화 문제를 해결하기 위해 [14]는 중간 특징 맵의 점수를 업샘플링하고 연결했으며, [52]는 예측 결과를 조악한 수준에서 미세한 수준으로 정제했습니다.
- **관련 개념:**
  - **Atrous Convolution:** 본 논문의 "atrous convolution" 개념은 원래 "algorithme à trous" [15]라는 비하향 샘플링 웨이블릿 변환 계산을 위해 개발되었으며, DCNN 맥락에서는 [3], [6], [16]에서 이와 유사한 연산이 사용되었습니다. [76]에서는 이를 "dilated convolution"이라고 명명했습니다.
  - **Spatial Pyramid Pooling (SPP):** R-CNN [20]에서 임의의 스케일 영역을 단일 스케일에서 추출된 컨볼루션 특징으로 분류하는 데 성공적으로 사용되었습니다.
  - **Fully Connected CRF:** [22]에서 제안되었으며, 모든 픽셀 쌍을 연결하는 그래프에서 효율적인 추론이 가능하며 미세한 경계 디테일을 포착할 수 있습니다. [53], [39]에서도 DCNN과 CRF를 결합하려는 시도가 있었으나, 국소적으로 연결된 CRF 모델이거나 수퍼픽셀 오류에 한계가 있었습니다.
- **DeepLab 발표 이후 발전:** DeepLab 시스템의 핵심 요소인 Atrous convolution과 완전 연결 CRF는 이후 많은 연구 [17], [40], [58], [59], [60], [61], [62], [63]에서 채택되었습니다. 특히 DCNN과 CRF를 엔드-투-엔드(end-to-end)로 학습하거나 [40], [59], [62], [64], [65] 더 효율적인 추론 방법을 모색하는 연구 [63]가 진행되었습니다.

## 🛠️ Methodology

본 DeepLab 시스템은 다음 세 가지 핵심 구성 요소를 활용하여 시맨틱 분할을 수행합니다.

1. **Atrous Convolution (확장 컨볼루션)을 이용한 조밀한 특징 추출 및 시야 확장:**

   - **문제 해결:** DCNN에서 풀링 및 스트라이딩으로 인한 특징 맵 해상도 감소 문제를 해결합니다.
   - **원리:** 네트워크의 마지막 몇몇 풀링 레이어에서 다운샘플링 연산자를 제거하고, 대신 후속 컨볼루션 레이어의 필터를 업샘플링합니다. 이는 필터 탭 사이에 0(holes, 'trous')을 삽입하는 것과 같습니다.
   - **1D Atrous Convolution 공식:** 입력 신호 $x[i]$와 길이 $K$의 필터 $w[k]$에 대한 출력 $y[i]$는 다음과 같이 정의됩니다.
     $$ y[i] = \sum\_{k=1}^{K} x[i+r \cdot k]w[k] $$
        여기서 $r$은 입력 신호를 샘플링하는 보폭(stride)을 나타내는 **레이트(rate)** 파라미터입니다. $r=1$은 표준 컨볼루션입니다.
   - **효과:**
     - 더 높은 샘플링 레이트로 특징 맵을 계산하여 공간 밀도를 증가시킵니다 (예: 원본 네트워크에서 32배 다운샘플링 대신 8배 다운샘플링).
     - 매개변수 수 또는 계산량 증가 없이 필터의 유효 시야(effective field-of-view)를 임의로 확장합니다. $k \times k$ 필터의 유효 커널 크기는 $k_{e} = k + (k-1)(r-1)$가 됩니다.
   - **구현:** 필터에 0을 삽입하여 암묵적으로 업샘플링하거나, 입력 특징 맵을 $r$만큼 다운샘플링하여 여러 개의 저해상도 맵을 생성한 후 표준 컨볼루션을 적용하고 다시 인터레이싱합니다.

2. **Atrous Spatial Pyramid Pooling (ASPP)을 이용한 다중 스케일 이미지 표현:**

   - **문제 해결:** 다양한 크기의 객체를 효과적으로 처리합니다.
   - **원리:** 단일 특징 레이어를 여러 병렬 `atrous convolutional layers`로 프로빙하며, 각 레이어는 다른 샘플링 레이트(예: $r=\{6, 12, 18, 24\}$)를 가집니다.
   - **효과:** 다양한 유효 시야를 가진 필터를 통해 다중 스케일에서 객체와 유용한 이미지 컨텍스트를 포착하고, 각 샘플링 레이트에서 추출된 특징을 융합하여 최종 결과를 생성합니다.

3. **Fully-Connected Conditional Random Fields (CRFs)를 이용한 정확한 경계 복원:**
   - **문제 해결:** DCNN의 공간 정확도 한계와 부드러운 예측으로 인한 경계 흐림 문제를 해결합니다.
   - **원리:** DCNN의 인식 능력과 완전 연결 CRF의 미세한 지역화 정확도를 결합합니다.
   - **에너지 함수:** 픽셀에 대한 레이블 할당 $x$에 대한 에너지 함수는 다음과 같습니다.
     $$ E(x) = \sum*{i} \theta*{i}(x*{i}) + \sum*{ij} \theta*{ij}(x*{i},x\_{j}) $$
     - **단항 잠재력(Unary potential) $\theta_{i}(x_{i})$:** DCNN에 의해 계산된 픽셀 $i$에서의 레이블 할당 확률 $P(x_{i})$에서 $-\log P(x_{i})$로 정의됩니다.
     - **쌍항 잠재력(Pairwise potential) $\theta_{ij}(x_{i},x_{j})$:** 모든 픽셀 쌍 $i, j$를 연결하는 완전 연결 그래프를 사용합니다.
       $$ \theta*{ij}(x*{i},x*{j})=\mu(x*{i},x*{j}) \left[ w*{1}\exp\left(-\frac{||p*{i}-p*{j}||^2}{2\sigma*{\alpha}^2} - \frac{||I*{i}-I*{j}||^2}{2\sigma*{\beta}^2}\right) + w*{2}\exp\left(-\frac{||p*{i}-p*{j}||^2}{2\sigma*{\gamma}^2}\right) \right] $$
            여기서 $\mu(x_{i},x_{j}) = 1$ (만약 $x_{i} \neq x_{j}$), 그렇지 않으면 0입니다. 첫 번째 '양방향' 커널은 픽셀 위치($p$)와 RGB 색상($I$)에 모두 의존하며, 유사한 색상과 위치의 픽셀에 유사한 레이블을 부여합니다. 두 번째 커널은 공간적 근접성만 고려하여 부드러움을 강화합니다.
   - **추론:** 평균 필드(mean field) 근사를 통한 효율적인 근사 확률 추론이 가능하며, 고차원 필터링 알고리즘 [84]을 사용하여 빠르게 계산됩니다.

**학습 과정:**

- ImageNet으로 사전 학습된 VGG-16 또는 ResNet-101 네트워크를 시맨틱 분할 태스크에 맞게 미세 조정합니다.
- 손실 함수는 DCNN 출력 맵의 각 공간 위치에 대한 교차 엔트로피(cross-entropy) 항의 합입니다.
- DCNN과 CRF 학습 단계는 분리됩니다 (CRF 매개변수 설정 시 DCNN 단항 항은 고정).
- "poly" 학습률 정책과 데이터 증강(무작위 스케일링), MS-COCO 사전 학습 등을 활용합니다.

## 📊 Results

- **PASCAL VOC 2012:**
  - 최종 모델은 79.7%의 mIOU로 최고 성능을 달성했습니다.
  - CRF는 모든 모델 변형에서 평균 IOU를 3-5% 절대적으로 향상시켰습니다.
  - ASPP-L은 CRF 적용 전후 모두 LargeFOV baseline보다 일관된 개선을 보였습니다.
  - VGG-16 대비 ResNet-101 기반 DeepLab은 더 나은 분할 결과를 제공했으며, 특히 객체 경계에서의 정확도가 향상되었습니다.
- **PASCAL-Context:**
  - 최종 모델은 45.7%의 mIOU를 달성하여 기존 최고 성능을 2.4% 초과했습니다.
  - ResNet-101 적용, 다중 스케일 입력, MS-COCO 사전 학습, ASPP, CRF 후처리가 순차적으로 성능을 향상시켰습니다.
- **PASCAL-Person-Part:**
  - ResNet-101 기반 DeepLab은 VGG-16 기반 모델보다 훨씬 뛰어난 성능을 보였습니다.
  - 다중 스케일 입력 및 MS-COCO 사전 학습이 효과적이었으나, LargeFOV 또는 ASPP는 이 데이터셋에서 큰 개선을 가져오지 않았습니다.
  - 최종 모델은 64.94% mIOU (CRF 전)를 달성했으며, CRF 후처리로 기존 연구보다 4.78% 우수한 성능을 보였습니다.
- **Cityscapes:**
  - 원본 해상도 이미지 처리가 성능 향상에 기여했습니다 (1.8-1.9% 개선).
  - ResNet-101, 데이터 증강, ASPP, CRF 후처리를 통해 70.4%의 mIOU를 달성했습니다.
- **전반적인 결과:** CRF는 VGG-16에서 객체 경계의 정확한 예측에 중요하며, ResNet-101은 CRF 없이도 허용 가능한 경계 성능을 보입니다. CRF를 ResNet-101 결과에 적용하면 분할 결과가 더욱 향상됩니다.

## 🧠 Insights & Discussion

- **DeepLab 시스템의 장점:**
  - **속도 (Speed):** `atrous convolution` 덕분에 조밀한 DCNN은 NVidia Titan X GPU에서 8 FPS로 작동하며, 완전 연결 CRF의 Mean Field 추론은 CPU에서 0.5초가 소요됩니다.
  - **정확도 (Accuracy):** PASCAL VOC 2012, PASCAL-Context, PASCAL-Person-Part, Cityscapes 등 여러 난이도 높은 데이터셋에서 최고 성능을 달성했습니다.
  - **단순성 (Simplicity):** DCNN과 CRF라는 두 가지 잘 확립된 모듈의 조합으로 구성되어 있습니다.
- **핵심 기술의 효과:**
  - `Atrous convolution`은 DCNN의 특징 해상도를 효율적으로 제어하고 필터의 시야를 확장하여 더 넓은 컨텍스트를 통합하는 데 효과적입니다.
  - `ASPP`는 다중 스케일의 객체와 컨텍스트를 포착하는 데 뛰어난 성능을 보입니다.
  - `Fully connected CRFs`는 DCNN이 생성하는 부드러운 예측에도 불구하고, 미세한 경계 세부 사항을 복원하는 데 결정적인 역할을 합니다.
- **ResNet-101의 기여:** ResNet-101의 항등 매핑(identity mapping)은 하이퍼-컬럼(hyper-column) 특징과 유사하게 중간 레이어의 특징을 활용하여 경계 지역화를 개선하는 효과가 있습니다.
- **한계점 및 향후 연구:** 일부 객체(예: 자전거, 의자)의 섬세한 경계는 DCNN의 단항 항이 충분히 확신하지 못하여 CRF 후처리로도 완전히 복원되지 못하는 경우가 있었습니다. 인코더-디코더(encoder-decoder) 구조 [100], [102]를 활용하여 고해상도 특징 맵을 활용하는 방안이 미래 연구로 제시되었습니다.

## 📌 TL;DR

DeepLab은 시맨틱 분할에서 DCNN의 해상도 감소, 다중 스케일 객체 처리, 지역화 정확도 문제를 해결합니다. 제안된 방법은 `atrous convolution`으로 조밀한 특징을 추출하고 시야를 확장하며, `Atrous Spatial Pyramid Pooling (ASPP)`으로 다중 스케일 객체를 효과적으로 처리합니다. 또한, DCNN의 출력에 `Fully Connected CRF`를 결합하여 객체 경계를 정밀하게 다듬습니다. 이 시스템은 PASCAL VOC 2012를 포함한 여러 도전적인 데이터셋에서 최고 성능을 달성하며 시맨틱 분할 분야의 발전에 크게 기여했습니다.
