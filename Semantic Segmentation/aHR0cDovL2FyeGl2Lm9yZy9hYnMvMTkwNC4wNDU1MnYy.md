# BoLTVOS: Box-Level Tracking for Video Object Segmentation

Paul Voigtlaender, Jonathon Luiten, Bastian Leibe

## 🧩 Problem to Solve

반지도 학습 비디오 객체 분할(VOS)은 비디오의 첫 프레임에 주어진 객체의 참값 정보를 기반으로 이후 모든 프레임에 대한 객체 분할 마스크를 생성하는 것을 목표로 합니다. 기존의 반지도 학습 VOS 방법은 세 가지 범주로 나뉩니다: 1) 첫 프레임 마스크를 사용하여 미세 조정하는 방법 (매우 정확하지만 느림), 2) 첫 프레임 마스크를 미세 조정 없이 사용하는 방법 (빠르지만 덜 정확함), 3) 첫 프레임의 바운딩 박스만 사용하는 방법 (성능이 훨씬 떨어짐).

이 논문은 세 번째 범주에 속하며, 첫 프레임 마스크 대신 *첫 프레임 바운딩 박스*만으로도 빠르고 정확한 VOS를 수행하는 방법을 제시하여 기존의 성능 격차를 줄이고자 합니다. 특히, 객체가 사라졌다가 다시 나타나는 장기 추적 상황에서도 강건하게 동작해야 하는 과제를 해결합니다.

## ✨ Key Contributions

- **BoLTVOS 제안**: 비디오 객체 분할(VOS) 작업을 바운딩 박스 수준의 추적(Box-level Tracking)과 바운딩 박스 분할(Bounding Box Segmentation)의 두 가지 하위 작업으로 분리하는 새로운 접근 방식인 BoLTVOS를 제안합니다. 이는 첫 프레임 바운딩 박스 정보만 요구합니다.
- **조건부 R-CNN 개발**: 객체를 추적하기 위한 새로운 조건부 R-CNN 네트워크를 도입했습니다. 이 네트워크는 전체 이미지에 걸쳐 전역적으로 탐색할 수 있어 (기존 방법들의 로컬 탐색 창 한계를 넘어) 객체가 사라진 후에도 다시 감지할 수 있습니다.
- **시간적 일관성 재채점 알고리즘**: 시간적 일관성 단서와 방해 객체(distractor object)를 고려하여 탐지 결과를 재채점하는 알고리즘을 개발하여 추적 성능을 향상시켰습니다.
- **우수한 VOS 성능 달성**: 첫 프레임 마스크 미세 조정을 수행하지 않는 모든 VOS 방법 중에서 DAVIS 2017 및 YouTube-VOS 벤치마크에서 최고의 성능을 달성했으며, 일부 미세 조정 기반 방법보다도 뛰어난 결과를 보였습니다.
- **BoLTVOS-ft 확장 제안**: 첫 프레임 마스크가 주어질 경우, 추적과 병렬로 Box2Seg 네트워크를 미세 조정하여 런타임을 증가시키지 않으면서 분할 정확도를 크게 향상시키는 BoLTVOS-ft를 제시합니다. BoLTVOS-ft는 기존 최고 성능 VOS 방법인 PReMVOS를 능가하며, 최대 45배 더 빠르게 동작합니다.
- **최첨단 바운딩 박스 추적 성능**: 바운딩 박스 수준 추적 데이터셋인 LTB35 (장기 추적) 및 OTB 2015 (단기 추적)에서도 새로운 최첨단(State-of-the-Art) 결과를 달성했습니다.

## 📎 Related Works

- **비디오 객체 분할 (VOS)**
  - **첫 프레임 마스크 미세 조정 (Category 1)**: PReMVOS [28], DyeNet [24], OSVOS-S [31], CINM [1], OnAVOS [48], OSVOS [3]. (높은 정확도, 느린 속도)
  - **첫 프레임 마스크 사용, 미세 조정 없음 (Category 2)**: FEELVOS [46], RGMP [55], VideoMatch [17], FAVOS [7], OSMN [57], PML [6]. (빠르지만 정확도 낮음)
  - **첫 프레임 바운딩 박스만 사용 (Category 3)**: SiamMask [50]. (본 논문의 BoLTVOS가 이 범주에 속하며, SiamMask가 가장 밀접한 관련 연구임. SiamMask는 단일 단계 탐지기를 사용하고 이전 예측의 로컬 검색 창에서만 작동하는 반면, BoLTVOS는 조건부 2단계 R-CNN과 전체 이미지 검색을 사용함.)
- **비주얼 객체 추적 (VOT)**
  - SiamRPN [23], DaSiamRPN [60], C-RPN [12], SiamRPN++ [22]: 템플릿 특징과 검색 영역 특징 간의 상호 상관 관계를 이용하는 샴(Siamese) 네트워크 기반 단일 단계 RPN 방법들. 대부분 로컬 검색 창에 한정됨.
  - PReMVOS [28]: VOS에 바운딩 박스 기반 분할 네트워크(Box2Seg)를 사용하지만, BoLTVOS와는 매우 다른 전체 아키텍처와 느린 속도를 가짐. 본 논문은 PReMVOS의 Box2Seg 네트워크를 채택하여 사용함.
- **VOT 벤치마크**: OTB [53, 54], LTB35 [20], VOT challenges [21, 20], OxUvA [45] 등.

## 🛠️ Methodology

BoLTVOS는 VOS 작업을 바운딩 박스 수준의 추적과 바운딩 박스 분할로 분할하여 접근합니다. 이는 세 가지 주요 구성 요소로 이루어집니다.

1. **조건부 R-CNN (Conditional R-CNN)**:

   - **목적**: 첫 프레임 템플릿 객체와 시각적으로 유사한 바운딩 박스 영역을 탐지합니다.
   - **아키텍처**: Faster R-CNN [40]의 2단계 탐지 아키텍처를 기반으로 합니다. ResNet101 [15] 백본과 Feature Pyramid Network [25]를 사용합니다.
   - **조건부 2단계 (Conditional Second Stage)**:
     - 일반 객체 제안을 생성하는 RPN (Region Proposal Network)은 COCO [26] 데이터셋으로 사전 학습된 가중치를 고정하고, 백본도 고정합니다.
     - Faster R-CNN의 범주별 2단계 대신 "조건부 2단계"를 사용합니다. 이 단계에서는 RPN이 제안한 영역의 RoI 정렬(RoI Align) 특징과 첫 프레임 참값 바운딩 박스의 RoI 정렬 특징을 추출합니다.
     - 추출된 두 특징을 **연결(concatenation)**한 후, $1 \times 1$ 컨볼루션 레이어를 통해 채널 수를 절반으로 줄입니다.
     - 이 결합된 특징을 2단계 네트워크에 입력하여, 제안된 영역이 추적할 "객체"인지 "객체가 아닌지"를 이진 분류합니다.
     - 3단계 캐스케이드(cascade) 구조 [4]를 사용하여 더욱 강력한 판별 능력을 갖춥니다.
   - **학습**: 조건부 2단계만 추적을 위해 ImageNet VID [41], YouTube-VOS [56], GOT-10k [19], YouTube-BoundingBoxes [39] 등의 비디오 데이터셋에서 학습됩니다. 이 방식은 전체 이미지에서 객체를 탐지할 수 있어 객체 재등장 상황에 효과적입니다.

2. **시간적 일관성 재채점 (Temporal Consistency Rescoring)**:

   - **목적**: 조건부 R-CNN의 탐지 결과를 재채점하여 시간적 일관성을 높이고 시각적으로 유사한 방해 객체(distractor)의 영향을 줄입니다.
   - **과정**:
     - 이전 프레임의 모든 탐지 결과를 "트랙릿(tracklet)"으로 그룹화합니다. 각 프레임에서 기존 트랙릿에 IoU (Intersection over Union) 임계값(약 70%) 이상으로 연결되지 않는 탐지는 새로운 트랙릿을 생성합니다.
     - 온라인 동적 프로그래밍을 사용하여 최적의 트랙릿 조합인 "트랙 가설(track hypothesis)"을 찾아 최종 추적 결과를 결정합니다.
     - **트랙릿 점수**: $score(\tau_i) = \sum_{t=t_{start_i}}^{t_{end_i}} s_{i,t} + w_{ff} ff\_score(b_{ff}, b_{i,t})$
       - $ff\_score(b_{ff}, b) = min(\frac{ar(b_{ff})}{ar(b)}, \frac{ar(b)}{ar(b_{ff})}) - \alpha_{ff}$ (현재 탐지의 종횡비 $ar(b)$와 첫 프레임 바운딩 박스의 종횡비 $ar(b_{ff})$ 간의 유사성 측정)
     - **트랙 가설 점수**: $score(T) = \sum_{i=1}^{k} score(\tau_i) + w_{bnd} \sum_{i=2}^{k} bnd\_score(\tau_{i-1}, \tau_i)$ (개별 트랙릿 점수와 연속적인 트랙릿 간의 경계 점수를 결합).
       - $bnd\_score(\tau_{i-1}, \tau_i) = (\sum_{t=t_{start_{i-1}}}^{t_{end_{i-1}}} w_{iou} IoU(b_{i-1,t_{end_{i-1}}}, b_{i,t_{start_i}}) - w_{loc} \left\|center(b_{i-1,t_{end_{i-1}}}) - center(b_{i,t_{start_i}})\right\| - \alpha_{bnd})$ (이전 트랙릿의 마지막 바운딩 박스와 다음 트랙릿의 첫 번째 바운딩 박스 간의 IoU 및 중심 거리 기반 경계 점수).
     - 최고 점수의 트랙 가설을 선택하고, 해당 가설에 속하는 가장 최근 프레임의 탐지를 출력합니다.

3. **Box2Seg 네트워크 (Box2Seg Network)**:

   - **목적**: 추적된 바운딩 박스에 대한 분할 마스크를 생성합니다.
   - **아키텍처**: Luiten et al. [28]의 사전 학습된 DeepLabV3+ [5] 네트워크 (Xception-65 [8] 백본 포함)를 사용합니다.
   - **입력**: 바운딩 박스는 네 번째 입력 채널로 인코딩되어 네트워크에 주어집니다.
   - **효율성**: 매우 빠르며, 초당 40개의 바운딩 박스를 분할 마스크로 변환할 수 있습니다. 겹치는 마스크는 픽셀 수가 가장 적은 마스크가 다른 마스크 위에 오도록 조합됩니다.

4. **BoLTVOS-ft (Fine-tuned Extension)**:
   - **목적**: 첫 프레임 마스크 주석을 활용하여 분할 정확도를 향상시킵니다.
   - **방법**: Box2Seg 네트워크를 첫 프레임 객체 마스크에 대해 미세 조정합니다.
   - **장점**: Box2Seg가 바운딩 박스 추적 완료 후에 후처리 단계로 적용되므로, 미세 조정은 추적 과정과 **병렬로 실행**될 수 있습니다. 이로 인해 런타임 증가 없이 분할 정확도를 높일 수 있습니다 (예: 두 번째 GPU 사용 시).

## 📊 Results

- **비디오 객체 분할 (VOS) 평가**

  - **DAVIS 2017**:
    - **BoLTVOS (바운딩 박스만 사용)**: $J\&F$ 점수 $71.9\%$. 첫 프레임 바운딩 박스만 사용하는 기존 최고 방법인 SiamMask [50] ($55.8\%$)를 $16.1\%$p 크게 능가합니다. 또한 첫 프레임 마스크를 사용하지만 미세 조정하지 않는 FEELVOS [46] 등의 모든 Category 2 방법을 능가했습니다.
    - **재채점(Rescoring)의 중요성**: 재채점 없는 BoLTVOS는 $J\&F=64.9\%$로, 재채점 알고리즘이 $7.0\%$p의 성능 향상을 가져왔음을 보여줍니다.
    - **BoLTVOS-ft (미세 조정 포함)**: $J\&F$ 점수 $76.3\%$. 이는 PReMVOS [28] ($77.8\%$)와 매우 유사한 성능이지만, 25배 더 빠릅니다.
    - $J_{box}$ (바운딩 박스 IoU) 점수에서 BoLTVOS는 $78.5\%$를 달성하여 Box2Seg 네트워크가 병목 현상을 일으키고 있음을 시사합니다.
  - **DAVIS 2016**:
    - **BoLTVOS**: $J\&F$ 점수 $79.6\%$. SiamMask [50] ($69.8\%$)를 $9.8\%$p 능가합니다.
    - **BoLTVOS-ft**: $J\&F$ 점수 $87.7\%$. 기존 최고 성능 PReMVOS [28] ($86.8\%$)를 능가하며, **PReMVOS보다 45배 더 빠르게 동작합니다.**
    - 이 데이터셋에서는 방해 객체가 적어 재채점 알고리즘의 효과가 미미했습니다.
  - **YouTube-VOS**:
    - **BoLTVOS**: $J\&F_{seen+uns.}$ 점수 $65.7\%$. PReMVOS [28] ($66.9\%$)만이 더 높은 점수를 기록했습니다.
    - **BoLTVOS-ft**: $J\&F_{seen+uns.}$ 점수 $71.1\%$. **이 데이터셋에서 새로운 최첨단 성능을 달성했습니다.**

- **바운딩 박스 수준 추적 평가**

  - **LTB35 (장기 추적)**:
    - **BoLTVOS (재채점 포함)**: 최대 F-score $66.2\%$. 이전 최고 성능 SiamRPN++ [22] ($62.9\%$)보다 $3.3\%$p 높습니다.
    - 전역 탐지 능력 덕분에 객체가 사라졌다가 다시 나타나는 장기 추적에 매우 강건함을 입증했습니다.
  - **OTB2015 (단기 추적)**:
    - **BoLTVOS**: AUC $69.7\%$. 이전 최고 성능 SiamRPN++ [22] ($69.6\%$)를 근소하게 앞섰습니다.

- **런타임**: BoLTVOS는 프레임당 약 $0.72 \sim 1.45$초로 매우 빠르며, BoLTVOS-ft는 Box2Seg의 병렬 미세 조정 덕분에 런타임 증가 없이 성능을 향상시켰습니다.

## 🧠 Insights & Discussion

- **VOS 작업 분할의 효율성**: VOS를 바운딩 박스 추적과 마스크 분할로 나누는 접근 방식이 각 하위 작업에서 뛰어난 성능을 발휘하며 전체 VOS 성능을 크게 향상시킬 수 있음을 입증했습니다.
- **강력한 바운딩 박스 추적의 중요성**: BoLTVOS의 $J_{box}$ 점수가 높다는 것은 VOS의 핵심이 정확한 바운딩 박스 수준 추적에 있음을 시사합니다. Box2Seg와 같은 분할 네트워크의 개선이 최종 마스크 품질을 더욱 높일 잠재력이 있습니다.
- **조건부 R-CNN의 장점**: 전역 탐색 능력과 직접적인 특징 연결 방식은 객체의 크기 및 종횡비 변화에 강건하며, 장기 추적에서 객체의 재탐지에 매우 효과적입니다.
- **시간적 일관성 재채점의 기여**: 복잡한 비디오에서 방해 객체가 많을 때 재채점 알고리즘이 중복 탐지를 줄이고 일관된 추적을 유지하는 데 결정적인 역할을 합니다.
- **실용적인 적용 가능성**: 첫 프레임 바운딩 박스만으로도 높은 성능을 달성할 수 있어, 마스크 주석보다 훨씬 저렴하고 빠른 데이터 주석이 가능해 대규모 비디오 데이터 처리 시 매우 실용적입니다.
- **향후 연구 방향**: 현재 Box2Seg가 추적에 피드백을 주지 않으므로, 픽셀 수준 분할 정보를 추적 과정에 더 긴밀하게 통합하면 추가적인 성능 향상을 기대할 수 있습니다.

## 📌 TL;DR

본 논문은 비디오 객체 분할(VOS)을 바운딩 박스 수준 추적과 바운딩 박스 분할의 두 단계로 분해하는 BoLTVOS를 제안합니다. BoLTVOS는 객체 재탐지와 방해 객체 처리에 강건한 새로운 조건부 R-CNN 및 시간적 일관성 재채점 알고리즘을 사용하여 첫 프레임 바운딩 박스만으로도 뛰어난 추적 성능을 달성합니다. 여기에 기존 Box2Seg 네트워크를 결합하여, 첫 프레임 마스크 미세 조정 없이도 최첨단 VOS 성능을 달성하고 기존의 느린 미세 조정 기반 방법보다 훨씬 빠릅니다. 특히, 첫 프레임 마스크를 활용해 Box2Seg를 병렬로 미세 조정하는 BoLTVOS-ft는 기존 최고 성능을 능가하면서도 런타임을 대폭 단축하여, 효율적인 VOS에 있어 강건한 바운딩 박스 수준 추적이 핵심임을 입증했습니다.
