# A Pixel-Level Meta-Learner for Weakly Supervised Few-Shot Semantic Segmentation

Yuan-Hao Lee, Fu-En Yang, Yu-Chiang Frank Wang

## 🧩 Problem to Solve

이 논문은 **약 지도 학습 소수 이미지 의미론적 분할(Weakly Supervised Few-Shot Semantic Segmentation)**이라는 도전적인 문제를 다룹니다. 이는 새로운 클래스에 대해 픽셀 단위 레이블이 지정된 이미지가 거의 없는 상황에서 의미론적 분할을 수행하는 것입니다. 특히, 훈련 및 테스트 시 **이미지 단위 의미론적 레이블(image-level semantic labels)만 사용 가능**한 경우를 다룹니다. 기존 소수 이미지 의미론적 분할 방법들은 대부분 픽셀 단위 레이블에 의존하며, 이를 이미지 단위 레이블로 확장하기 어렵다는 한계가 있습니다.

## ✨ Key Contributions

* 훈련 및 테스트 단계 모두에서 이미지 단위 레이블만 요구하는 **약 지도 학습 소수 이미지 의미론적 분할** 문제를 해결합니다.
* **분류 활성화 맵(CAM)**을 활용하여 이미지 단위 레이블과 픽셀 단위 레이블 간의 간극을 정보 유출 없이 연결하고, 이를 통해 약 지도 학습 환경에서 의사 픽셀 단위 레이블을 예측합니다.
* 소수 이미지 의미론적 분할을 위해 **픽셀 단위 메타 학습기**를 독창적으로 설계하여, 지원(support) 이미지와 질의(query) 이미지 간의 분할 일관성을 강화합니다. 제안된 모델은 완전 지도 및 약 지도 학습 환경 모두에서 구현될 수 있습니다.

## 📎 Related Works

* **의미론적 분할(Semantic Segmentation):** FCN, SegNet, DeepLabs 등 CNN 기반 모델들이 발전하여 뛰어난 성능을 보이지만, 픽셀 단위 주석이 달린 방대한 양의 훈련 데이터가 필요합니다.
* **약 지도 학습 의미론적 분할(Weakly Supervised Semantic Segmentation):** 다중 인스턴스 학습(Multiple-Instance Learning), 그래프 기반, 자기 훈련(Self-Training) 등의 기법을 사용하여 주석 부담을 줄이지만, 소수 데이터 또는 개방형 시나리오로 쉽게 확장하기 어렵습니다.
* **소수 이미지 의미론적 분할(Few-Shot Semantic Segmentation):** 제한된 레이블 데이터만으로 새로운 카테고리에 일반화하는 것을 목표로 합니다. Meta-learning(메타 학습)이 널리 적용되며, ProtoNet, RN, OSLSM, PL, CANet, PFENet, PANet, FWB 등과 같은 방법들이 지원 이미지로부터 프로토타입을 추출하거나 어텐션 메커니즘을 사용하여 성능을 향상시킵니다. 일부 기존 연구($[29, 46, 54]$)는 바운딩 박스나 스크리블과 같은 약한 감독 설정을 사용했지만, 이미지 단위 주석만으로는 만족스러운 성능을 내지 못했습니다. 또한, $[31, 4, 37]$는 이미지 단위 감독을 사용하지만 메타 훈련 시에는 여전히 베이스 클래스에 대한 픽셀 단위 마스크를 요구합니다. 본 연구는 훈련 및 테스트 단계 모두에서 **오직 이미지 단위 주석만을 사용하여 소수 이미지 의미론적 분할을 다루는 최초의 시도**임을 강조합니다.

## 🛠️ Methodology

제안하는 약 지도 학습 프레임워크는 크게 두 단계로 구성됩니다:

1. **픽셀 단위 의사 레이블 생성(Pixel-Level Pseudo Label Generation):**
    * 입력 이미지 $I$와 이미지 단위 레이블 $c$가 주어지면, **CAM(Classification Activation Maps)** 모듈을 사용하여 픽셀 단위 의사 마스크를 생성합니다.
    * CAM 백본(VGG-16)은 분할 작업의 베이스/노블 카테고리에 속하지 않는 ImageNet의 축소된 부분집합으로 사전 훈련되어 정보 유출을 최소화합니다.
    * 각 CAM 카테고리 $c_k$에 대해 클래스별 히트맵 $T_k \in [0,1]^{H \times W}$를 추출합니다.
    * 주어진 이미지 레이블 $c$와 각 CAM 카테고리 $c_k$의 단어 임베딩 $\pi(c), \pi(c_k)$ 간의 코사인 유사도를 사용하여 가중치 $w_k = d(\pi(c),\pi(c_k))^{-1}$를 계산합니다.
    * 이 가중치를 사용하여 모든 히트맵을 평균하여 가중치 히트맵 $T = \sum_{k=1}^{N_{CAM}} w_k T_k$를 얻습니다.
    * 마지막으로, 클래스에 구애받지 않는 **시각적 중요도 맵(saliency map)**을 게이팅 메커니즘으로 적용하여 잘못된 긍정 픽셀(false-positive pixels)을 줄이고 의사 레이블을 정교화합니다. 이 시각적 중요도 맵 또한 범주적 감독 없이 전경/배경 정보로만 사전 훈련됩니다.

2. **픽셀 단위 메타 학습기(Pixel-Level Meta-Learner):**
    * 사전 훈련된 DeepLabv3+ 네트워크를 특징 추출기(feature extractor)로 사용합니다. 이 네트워크는 메타 학습 과정 내내 고정되며, 사용될 클래스와 관련 없는 카테고리로 사전 훈련되어 정보 유출을 방지합니다.
    * DeepLabv3+에서 픽셀 단위 특징 맵 $F_s$ (지원 이미지)와 $F_q$ (질의 이미지)를 얻습니다.
    * 생성된 지원 의사 마스크 $\tilde{M}_s$를 사용하여 각 전경/배경 카테고리에서 고정된 수의 픽셀을 무작위로 샘플링하여 지원 픽셀 특징을 수집합니다.
    * 모든 지원 및 질의 픽셀 특징은 학습 가능한 인코더 $E$를 통해 잠재 공간(latent space)으로 임베딩됩니다.
    * 지원 픽셀 특징과 의사 레이블을 기반으로 각 카테고리 $c \in \{c_s \cup 0_\cdot\}$에 대한 프로토타입 $p_c$를 정의합니다:
        $$p_c = \frac{\sum_l E(F_{s_l})1[\tilde{M}_{s_l}=c]}{\sum_l 1[\tilde{M}_{s_l}=c]}$$
    * 메타 훈련 단계에서는 **프로토타입 손실(prototypical loss)** $L_{meta}$를 최적화 목표로 사용합니다. 이는 각 질의 픽셀(의사 레이블 포함)과 지원 세트의 해당 픽셀 단위 프로토타입 간의 거리를 누적하여 계산됩니다:
        $$L_{meta} = -\frac{\sum_c \sum_l \exp(-d(E(F_{q_l}),p_c))1[\tilde{M}_{q_l}=c]}{\sum_c \sum_l 1[\tilde{M}_{q_l}=c]}$$
    * 추론(meta-testing) 시에는 임베딩된 질의 픽셀 특징의 레이블이 **픽셀 단위 k-NN 분류**를 통해 결정됩니다.

## 📊 Results

* **데이터셋:** PASCAL-5${^i}$ 및 MS COCO 2014.
* **평가 지표:** mean-IoU (평균 픽셀 단위 교차합).
* **약 지도 학습 성능:**
  * PASCAL-5${^i}$에서, 제안 모델은 기존의 완전 지도 학습 방식인 PANet($[46]$) 대비 약 15.3% (42.4% vs. 27.1%)의 큰 폭의 성능 향상을 약 지도 학습 설정에서 보였습니다. PFENet($[42]$)이 더 강력한 백본(ResNet-50)을 사용했음에도 불구하고, 제안 모델은 약 2.5% 더 높은 성능을 달성했습니다.
  * 완전 지도 학습에서 약 지도 학습으로 전환 시 성능 하락폭이 PFENet($[42]$)과 PANet($[46]$)이 20% 이상이었던 반면, 제안 모델은 PASCAL-5${^i}$에서 5.1%, MS COCO에서 2.7%에 불과하여 약한 레이블에 대한 높은 견고성을 입증했습니다.
* **다중 클래스 분할(Multi-way Segmentation):** 대부분의 기존 방법이 1-way 분할(이미지 내 단일 전경 객체)에 초점을 맞추는 반면, 제안 모델은 k-NN 탐색을 통해 다중 카테고리 이미지의 출력 레이블을 직접 생성할 수 있습니다. PASCAL-5${^i}$ 2-way 1-shot 작업에서 11.5% 더 우수한 성능을 보였으며, MS COCO 데이터셋에 대한 2-way 작업 결과를 처음으로 보고했습니다.
* **Ablation Study (요소 연구):**
  * 메타 학습 인코더 $E$를 제거하고 DeepLabv3+ 백본의 픽셀 특징에 직접 k-NN을 적용한 결과, 성능이 최대 18% 크게 저하되어 $E$의 중요성을 확인했습니다.
  * 시각적 중요도 게이팅(saliency gating)을 제거했을 때는 mean-IoU가 5% 미만으로 약간 감소하여, 게이팅이 유용하지만 필수적이지는 않음을 보여주었습니다.
* **정성적 분석(Qualitative Analysis):** 생성된 의사 마스크는 전체 객체를 커버하지 않고 식별에 도움이 되는 특징적인 영역(예: 말의 주둥이, 오토바이의 바퀴)에 집중되지만, 제안 모델은 질의 이미지에 대해 만족스러운 분할 마스크를 예측할 수 있습니다. 병, 의자 등 전경 영역이 작거나 배경과 구분하기 어려운 카테고리에서는 여전히 어려움을 겪는 한계가 있습니다.

## 🧠 Insights & Discussion

이 논문은 기존 소수 이미지 의미론적 분할의 핵심 한계인 "픽셀 단위 주석의 필요성"을 극복하는 데 중점을 둡니다. 특히, **훈련 및 테스트 모두에서 이미지 단위 레이블만 사용하는** 더욱 실용적이고 도전적인 약 지도 학습 설정을 효과적으로 해결했습니다. CAM과 단어 임베딩 기반의 의사 레이블 생성은 정보 유출 없이 이미지-픽셀 간 간극을 메우는 독창적인 접근 방식입니다. 픽셀 단위 메타 학습기는 이러한 약한 레이블 정보로부터도 견고하게 학습하여, 완전 지도 학습 환경과 비교해도 성능 저하가 미미하다는 점에서 모델의 일반화 및 실용성이 높음을 시사합니다. 하지만 병, 의자와 같이 객체 영역이 작거나 배경과 혼동하기 쉬운 경우의 분할은 소수 데이터 학습의 본질적인 한계로 남아있음을 명확히 지적합니다.

## 📌 TL;DR

본 연구는 **약 지도 학습 소수 이미지 의미론적 분할** 문제를 해결하기 위해 **픽셀 단위 메타 학습기**를 제안합니다. 이 모델은 훈련 및 테스트 시 이미지 단위 레이블만 사용하며, CAM과 단어 임베딩을 통해 의사 픽셀 단위 마스크를 생성하고 이를 바탕으로 픽셀 단위 메타 학습을 수행합니다. 실험 결과, 제안 모델은 기존 완전 지도 학습 방법을 능가하는 약 지도 학습 성능을 보였으며, 약한 레이블에 대한 높은 견고성을 입증했습니다.
