{
  "title": "Learning Temporal Distribution and Spatial Correlation Towards Universal\n  Moving Object Segmentation",
  "authors": "Guanfang Dong, Chenqiu Zhao, Xichen Pan, Anup Basu",
  "year": 2023,
  "url": "http://arxiv.org/abs/2304.09949v4",
  "abstract": "The goal of moving object segmentation is separating moving objects from\nstationary backgrounds in videos. One major challenge in this problem is how to\ndevelop a universal model for videos from various natural scenes since previous\nmethods are often effective only in specific scenes. In this paper, we propose\na method called Learning Temporal Distribution and Spatial Correlation (LTS)\nthat has the potential to be a general solution for universal moving object\nsegmentation. In the proposed approach, the distribution from temporal pixels\nis first learned by our Defect Iterative Distribution Learning (DIDL) network\nfor a scene-independent segmentation. Notably, the DIDL network incorporates\nthe use of an improved product distribution layer that we have newly derived.\nThen, the Stochastic Bayesian Refinement (SBR) Network, which learns the\nspatial correlation, is proposed to improve the binary mask generated by the\nDIDL network. Benefiting from the scene independence of the temporal\ndistribution and the accuracy improvement resulting from the spatial\ncorrelation, the proposed approach performs well for almost all videos from\ndiverse and complex natural scenes with fixed parameters. Comprehensive\nexperiments on standard datasets including LASIESTA, CDNet2014, BMC, SBMI2015\nand 128 real world videos demonstrate the superiority of proposed approach\ncompared to state-of-the-art methods with or without the use of deep learning\nnetworks. To the best of our knowledge, this work has high potential to be a\ngeneral solution for moving object segmentation in real world environments. The\ncode and real-world videos can be found on GitHub\nhttps://github.com/guanfangdong/LTS-UniverisalMOS."
}