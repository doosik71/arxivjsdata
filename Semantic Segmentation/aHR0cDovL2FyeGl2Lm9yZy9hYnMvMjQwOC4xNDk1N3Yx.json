{
  "url": "http://arxiv.org/abs/2408.14957v1",
  "title": "Applying ViT in Generalized Few-shot Semantic Segmentation",
  "authors": "Liyuan Geng, Jinhong Xia, Yuanhe Guo",
  "year": 2024,
  "abstract": "This paper explores the capability of ViT-based models under the generalized\nfew-shot semantic segmentation (GFSS) framework. We conduct experiments with\nvarious combinations of backbone models, including ResNets and pretrained\nVision Transformer (ViT)-based models, along with decoders featuring a linear\nclassifier, UPerNet, and Mask Transformer. The structure made of DINOv2 and\nlinear classifier takes the lead on popular few-shot segmentation bench mark\nPASCAL-$5^i$, substantially outperforming the best of ResNet structure by 116%\nin one-shot scenario. We demonstrate the great potential of large pretrained\nViT-based model on GFSS task, and expect further improvement on testing\nbenchmarks. However, a potential caveat is that when applying pure ViT-based\nmodel and large scale ViT decoder, the model is easy to overfit.",
  "citation": 1
}