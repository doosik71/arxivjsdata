# A Closer Look at Self-training for Zero-Label Semantic Segmentation

Giuseppe Pastore, Fabio Cermelli, Yongqin Xian, Massimiliano Mancini, Zeynep Akata, Barbara Caputo

## 🧩 Problem to Solve

해결하고자 하는 주요 문제는 "일반화된 제로 레이블 의미론적 분할(Generalized Zero-Label Semantic Segmentation, GZLSS)"입니다. GZLSS는 훈련 시 관찰되지 않은(unseen) 클래스와 관찰된(seen) 클래스 모두를 테스트 시 분할해야 하는 어려운 작업입니다. 기존의 제로 레이블 의미론적 분할(ZSLSS) 연구들은 주로 시각-의미 임베딩 또는 생성 모델을 학습하는 방식이었으나, 이들은 관찰되지 않은 클래스에 대한 훈련 신호가 없기 때문에 관찰된 클래스에 과적합될 위험이 높았습니다. 특히, 훈련 이미지에 관찰되지 않은 클래스 픽셀이 주석 없이 존재함에도 불구하고 SPNet과 같은 기존 방법들은 이를 무시했습니다. 또한, SPNet은 관찰된 클래스의 예측 점수를 상수 인자 $\gamma$로 줄이는 방식으로 문제를 해결하려 했으나, 이 $\gamma$ 값은 미세 조정하기 어렵고 성능에 민감하게 반응한다는 한계가 있었습니다.

## ✨ Key Contributions

* GZLSS에서 주석이 없는 픽셀로부터 관찰되지 않은 클래스에 대한 강력한 감독 신호를 얻기 위한 자기 훈련(self-training) 파이프라인을 제안합니다. 이 파이프라인의 핵심 구성 요소는 데이터 증강(data augmentations)에 대한 일관성 제약(consistency constraints)을 적용하는 의사 레이블(pseudo-label) 생성기입니다.
* 이러한 과정을 통해 미세 조정된 모델이 관찰되지 않은 클래스를 예측하는 능력을 점진적으로 향상시키고, 이에 따라 의사 레이블의 품질도 개선됨을 입증합니다.
* PascalVOC12 (배경 포함/제외) 및 COCO-stuff 데이터셋에 대한 광범위한 실험을 통해 제안하는 모델이 GZLSS에서 최첨단 성능을 달성함을 보여줍니다.

## 📎 Related Works

* **제로샷 학습(Zero-Shot Learning, ZSL):** ZSL 모델은 지식을 보거나 보지 못한 범주로 전달하는 방식에 따라 네 가지 주요 범주로 나뉩니다. 본 연구는 시각-의미 임베딩 문제(예: SPNet)와 클래스 수준 의미 조건부 생성기(예: ZS3, CaGNet)에 중점을 둡니다.
* **일반화된 제로 레이블 의미론적 분할(GZLSS):** SPNet [44], ZS3 [7], CaGNet [16]이 이 분야를 직접 다룹니다. SPNet은 시각 특징을 의미 공간에 투영하는 반면, ZS3와 CaGNet은 생성 모델을 통해 관찰되지 않은 클래스의 특징을 합성합니다. ZS5 [7]와 CaGNet+ST [16]는 자기 훈련을 통해 GZLSS 시나리오에 접근합니다. 본 연구는 SPNet을 기반으로 삼아 제안하는 간단한 접근 방식이 모델의 예측 능력을 어떻게 향상시킬 수 있는지 보여줍니다.
* **의미론적 분할에서의 자기 훈련:** 의사 레이블링은 반지도 학습(semi-supervised learning)에서 자기 감독 전략으로 널리 사용되었습니다 [22, 3, 35, 39, 18]. PseudoSeg [50]와 같은 많은 연구는 일관성 훈련(consistency training)에 의존하여 여러 증강된 이미지의 예측 일관성을 강제합니다. ZS5 및 CaGNet은 미확인 픽셀에 대해 자체 생성된 의사 레이블 중 신뢰도가 낮은 일정 비율($p\%$)을 걸러냅니다. 본 연구는 민감한 하이퍼파라미터 없이 견고한 제로샷 의사 레이블을 생성하는 것을 목표로 합니다.

## 🛠️ Methodology

본 연구는 GZLSS의 클래스 불균형 문제를 해결하기 위해 주석이 없는 픽셀에 대한 의사 레이블을 생성하여 모델 학습에 활용하는 자기 훈련 프레임워크를 제안합니다.

1. **GZLSS 작업 정의:** 훈련 세트 $T$는 관찰된 클래스 $S$의 레이블이 지정된 픽셀과 주석이 없는 관찰되지 않은 클래스 $U$의 픽셀을 포함합니다. 목표는 테스트 시 $S \cup U$의 모든 클래스에 대해 픽셀별 예측을 수행하는 모델을 학습하는 것입니다.
2. **의미론적 투영 네트워크(SPNet) 개요:**
    * SPNet은 CNN 백본($\phi$)을 기반으로 입력 이미지 $x$를 $D$차원의 픽셀 임베딩 $\phi(x)_{nm}$으로 매핑합니다.
    * 이 임베딩과 클래스 단어 임베딩 $W_s$ (관찰된 클래스) 간의 내적을 계산하여 사후 확률을 출력합니다:
        $$P(\hat{y}_{nm}=c|x;W_s) = \frac{\exp(w_c^T \phi(x)_{nm})}{\sum_{c' \in S} \exp(w_{c'}^T \phi(x)_{nm})}$$
    * 모델은 표준 교차 엔트로피 손실 $L_{CE}$로 훈련됩니다. 여기서 주석이 없는 픽셀($y_{nm}=0$)의 손실은 무시됩니다.
    * 테스트 시에는 $S \cup U$의 모든 클래스에 대해 가장 높은 확률을 보이는 클래스를 예측합니다:
        $$\arg \max_{c \in S \cup U} P(\hat{y}_{nm}=c|x; [W_s, W_u])$$
3. **반복적 자기 훈련 파이프라인 (STRICT):**
    * **의사 레이블 생성:** 초기 SPNet 모델 $P_0$를 훈련 세트 $T$와 관찰된 클래스 단어 임베딩 $W_s$를 사용하여 훈련합니다. 각 반복 $t$에서, 이전 반복에서 학습된 모델 $P_{t-1}$을 사용하여 주석이 없는 픽셀($y_{nm}=0$)에 대한 의사 레이블을 생성합니다. 여기서 의사 레이블은 오직 관찰되지 않은 클래스 $U$에 대해서만 예측됩니다.
    * **일관성 제약(Consistency Constraints):** 단순한 의사 레이블 예측은 노이즈가 많으므로, 이를 줄이기 위해 일관성 제약 기반의 의사 레이블 생성기 $G$를 도입합니다.
        * 주석이 없는 픽셀을 포함하는 이미지 $x$에 대해 $K$가지 다른 데이터 증강($A_1(\cdot), \dots, A_K(\cdot)$)을 적용합니다. (예: 수평 미러링, 다양한 스케일링)
        * 각 증강된 이미지 $A_k(x)$에 대해 모델 $P_t$를 사용하여 관찰되지 않은 클래스에 대한 하드 의사 레이블 $\bar{y}_{nm}^k = \arg \max_{c \in U} P(\hat{y}_{nm}=c|A_k(x);W_u)$를 생성합니다.
        * 최종 의사 레이블 $\bar{y}$는 $K$개의 의사 레이블 마스크를 원본 좌표로 역변환($A_k^{-1}$)한 후, 이들의 교집합을 취하여 얻습니다:
            $$\bar{y} = A_1^{-1}(\bar{y}_1) \cap \dots \cap A_K^{-1}(\bar{y}_K)$$
        * 이 교집합 연산은 여러 증강된 마스크에서 일관되지 않는 의사 레이블을 걸러내어 더 정확한 의사 레이블을 생성합니다.
    * **반복적 미세 조정:** 생성된 의사 레이블 마스크 $\bar{y}$를 기존의 실제 레이블 마스크 $y$와 함께 사용하여 모델 $P_{t-1}$을 미세 조정합니다. 손실 함수는 다음과 같습니다:
        $$L = L_{CE}(x,y) + \lambda L_{CE}(x, \bar{y})$$
        여기서 첫 번째 항은 관찰된 클래스 픽셀에 대한 손실이고, 두 번째 항은 의사 레이블이 감독 신호가 되는 주석이 없는 픽셀에 대한 손실입니다.
    * 미세 조정된 모델 $P_t$는 다음 반복 $t+1$의 의사 레이블 생성에 사용되며, 이 과정은 여러 번 반복됩니다.

## 📊 Results

* **최첨단 성능 비교:**
  * PascalVOC12 및 COCO-stuff 데이터셋 모두에서 STRICT가 기존 GZLSS 방법(SPNet, ZS3, CaGNet 및 이들의 자기 훈련 변형)을 크게 능가했습니다.
  * 특히 PascalVOC12에서 STRICT는 이전 최첨단(CaGNet+ST)보다 조화 평균(HM)에서 6.1%, 관찰되지 않은 mIoU에서 5.3% 우수했습니다.
  * COCO-stuff에서는 관찰되지 않은 mIoU에서 CaGNet보다 16.9%, HM에서 13.1% 더 높은 성능을 보였습니다.
  * 단순한 자기 훈련 전략(SPNet+ST)만으로도 SPNet의 HM 성능이 PascalVOC12에서 17%, COCO-stuff에서 13.5% 향상되었으며, 이는 관찰된/관찰되지 않은 클래스의 공동 발생을 고려하는 것이 매우 유익하다는 것을 확인했습니다.
* **배경 클래스 포함 시 영향 (PascalVOC12):**
  * 배경 클래스를 분류에 포함할 경우 모든 모델의 성능이 크게 저하되었습니다. SPNet은 관찰되지 않은 mIoU가 2.5%로 낮아졌습니다.
  * 하지만 STRICT는 이러한 도전적인 상황에서도 관찰되지 않은 mIoU 14.3%, HM 24.0%로 다른 기존 방법들보다 훨씬 우수한 성능을 달성했습니다. 이는 배경이 무시될 때의 SPNet 성능과 유사한 수준입니다.
* **절삭 연구 (Ablation Study):**
  * **이미지 변환 유형:** 일관성 제약에 대해 다양한 변환(미러링, 멀티 스케일링)을 실험한 결과, 멀티 스케일링이 일반적으로 미러링보다 효과적이었고, 특히 업스케일링(upscaling)이 가장 좋은 결과를 가져왔습니다. 미러링과 업스케일링을 결합했을 때 최적의 성능을 달성했습니다 (관찰되지 않은 mIoU 32.9%, HM 47%).
  * **자기 훈련 반복 횟수:** 성능은 자기 훈련 반복 횟수가 증가함에 따라 향상되는 경향을 보였으며, 약 6회 반복까지는 빠르게 증가하다가 이후에는 포화되거나 약간 감소했습니다. 이는 의사 레이블의 노이즈를 완전히 제거할 수 없기 때문으로 분석됩니다.

## 🧠 Insights & Discussion

* **자기 훈련의 중요성:** 본 연구는 복잡한 생성 모델이나 수동으로 조정해야 하는 교정 항(calibration term) 없이도 자기 훈련이 GZLSS에서 관찰되지 않은 클래스에 대한 네트워크의 편향을 크게 줄일 수 있음을 강력하게 입증했습니다. 이는 관찰된 클래스와 관찰되지 않은 클래스의 공동 발생을 활용하는 자기 훈련의 중요성을 강조합니다.
* **일관성 제약의 효과:** 제안된 일관성 제약은 생성된 의사 레이블의 노이즈를 크게 줄여주며, 모델이 공간적으로 일관된 구조를 포착할 수 있도록 돕습니다. 이는 단일 단계의 의사 레이블링으로는 불가능한 개선입니다.
* **배경 클래스의 도전:** 배경 클래스를 포함하는 시나리오는 여전히 큰 도전 과제임을 확인했습니다. 배경 픽셀에 관찰되지 않은 클래스가 포함될 수 있어 모델의 식별 능력을 방해하며, 이러한 경우를 위한 추가적인 기술적 구성 요소(예: 배경 클래스의 의미론적 변화를 명시적으로 다루는 방법)가 필요합니다.
* **한계점:** 모델의 성능은 co-occurring 픽셀의 수에 의존합니다. 예를 들어, 'plant'와 같이 이미지에서 차지하는 비중이 낮은 클래스의 경우, 일관된 의사 레이블을 생성하기 어려워 최종 모델의 인식 능력이 낮아질 수 있습니다. 향후 연구에서는 각 클래스에 대해 생성된 의사 레이블 수에 기반한 감독 정규화 전략을 탐색할 수 있습니다.
* **단순성과 확장성:** 제안된 STRICT 프레임워크는 간단하고 견고하며 확장성이 뛰어나다는 장점이 있습니다. 이는 모델이 동일 이미지의 다양한 증강 버전 간에 일관된 레이블링을 예측하는 능력에 의존하여 의사 레이블을 필터링하고, 의사 레이블 생성기를 반복적으로 강화하기 때문입니다.

## 📌 TL;DR

이 논문은 **일반화된 제로 레이블 의미론적 분할(GZLSS)**에서 훈련 데이터의 주석 없는 픽셀에 숨겨진 정보를 활용하여 관찰되지 않은 클래스를 효과적으로 분할하는 방법을 제안합니다. 주요 문제는 기존 방법들이 관찰되지 않은 클래스에 대한 훈련 신호 부족으로 과적합되거나, 수동 튜닝이 필요한 민감한 파라미터에 의존한다는 점입니다. 이를 해결하기 위해, 본 연구는 **반복적 자기 훈련 파이프라인(STRICT)**을 도입하며, 핵심은 **데이터 증강 간의 일관성 제약을 통한 노이즈 없는 의사 레이블 생성**입니다. 이 방법을 통해 모델은 점진적으로 관찰되지 않은 클래스에 대한 예측 능력을 향상시키고, PascalVOC12 및 COCO-stuff 데이터셋에서 기존 최첨단 방법들을 크게 능가하는 성능을 달성했습니다. 이는 단순하면서도 효과적인 자기 훈련 전략이 GZLSS의 성능을 혁신적으로 개선할 수 있음을 보여줍니다.
