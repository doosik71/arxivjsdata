# Advancing Volumetric Medical Image Segmentation via Global-Local Masked Autoencoder

Jia-Xin Zhuang, Luyang Luo, Hao Chen

## 🧩 Problem to Solve

기존의 MAE(Masked Autoencoder) 기반 자가 지도 사전 학습 방법이 볼륨 메트릭 의료 영상에 직접 적용될 때 다음과 같은 두 가지 주요 문제가 발생합니다.

1. **전역 정보(Global Information) 부족:** 전체 데이터의 임상적 맥락을 이해하는 데 필수적인 전역 정보가 무시되어, 학습된 표현이 전체적인 환자 상태나 다른 장기와의 관계를 충분히 담아내지 못합니다.
2. **표현 학습의 불안정성:** 무작위로 마스킹된 지역 부분 볼륨(sub-volume)으로부터 학습된 표현이 불안정하여 학습 수렴이 느려지고 효율성이 저하될 수 있습니다. 다양한 지역 뷰들이 원본 입력의 작은 부분만을 대표하기 때문에 발생하는 문제입니다.

## ✨ Key Contributions

* **전역-지역 마스킹된 오토인코더(GL-MAE) 제안:** 볼륨 메트릭 의료 영상 분석을 위한 간단하면서도 효과적인 자가 지도 사전 학습 전략을 제시했습니다.
* **전역 및 지역 재구성 학습 도입:** 기존의 마스킹된 지역 뷰 재구성 외에 마스킹된 전역 뷰 재구성을 통합하여, 모델이 데이터의 전역적 맥락과 지역적 세부 정보를 동시에 학습할 수 있도록 합니다.
* **전역 가이드 일관성 학습(Global-guided Consistency Learning) 제시:** 마스킹되지 않은 완전한 전역 뷰를 '앵커'로 활용하여 마스킹된 전역 및 지역 뷰의 표현 학습을 유도합니다. 이를 통해 마스킹으로 인한 입력 왜곡에 강건한 표현을 학습하고 학습 과정을 안정화합니다.
* **다양한 의료 영상 데이터셋에서 SOTA 성능 달성:** 여러 볼륨 메트릭 의료 영상 분할 작업에서 기존의 자가 지도 학습 알고리즘들(예: MAE3D, Swin-UNETR)을 능가하는 우수한 성능과 일반화 능력을 입증했습니다. 특히, 주석 데이터가 부족한 시나리오에서도 높은 효율성을 보입니다.

## 📎 Related Works

* **자율 학습(Self-Supervised Learning, SSL)과 의료 영상 분석:**
  * **대조 학습 기반(Contrastive-based):** MoCo-V2, DeSD 등이 있으며, 양성 쌍은 특징 공간에서 가깝게, 음성 쌍은 멀게 배치합니다. 분류 작업에는 효과적이나, 분할과 같은 밀집 예측(dense prediction)에서는 의미론적 불일치로 인해 개선이 미미합니다.
  * **프리텍스트 태스크 기반(Pretext task-based):** Model Genesis (왜곡된 영상 복원), Rubik’s Cube+ (구조적 특징 학습), Swin-UNETR (인페인팅, 대조 학습, 회전 예측 조합) 등이 있으며, 영상의 내부 공간 구조 정보를 탐색하여 밀집 예측 작업에서 유망함을 보입니다.
* **마스크드 이미지 모델링(Masked Image Modeling, MIM):**
  * DAE, Context Encoder와 같이 마스킹된 부분의 픽셀을 예측하는 초기 연구들이 있습니다.
  * ViT는 마스킹된 패치 예측을 통해 시각적 표현을 학습합니다.
  * MAE는 높은 마스킹 비율을 통해 원본 픽셀을 복원하는 의미 있는 자가 지도 작업을 수행합니다.
  * SimMIM은 디코더를 단순화하여 유사한 결과를 얻었습니다.
  * MAE3D는 3D CT 의료 영상 분석을 위한 최근 MIM 발전으로, 트랜스포머 백본을 사용하여 가시 패치로부터 보이지 않는 패치를 복구합니다.
  * **기존 3D 의료 영상 MIM의 한계:** 지역적 크롭핑 전략에 기반하여 전역 정보(global information)를 훈련 과정에서 고려하지 않는다는 한계가 있습니다.

## 🛠️ Methodology

GL-MAE는 크게 두 가지 핵심 구성 요소로 이루어집니다.

1. **전역 및 지역 재구성(Global and Local Reconstruction)을 통한 MAE:**
    * 입력 볼륨 $x \in R^{CHWD}$으로부터 이미지 변환 $\tau_1$을 통해 상세한 고해상도 **지역 뷰 $v_l$**을, 변환 $\tau_2$를 통해 거시적인 저해상도 **전역 뷰 $v_g$**를 추출합니다. 지역 뷰는 세부 정보를, 전역 뷰는 전반적인 임상적 맥락을 제공합니다.
    * 추출된 각 뷰($v_l, v_g$)는 개별적으로 패치로 토큰화된 후, 사전 정의된 마스킹 비율로 **볼륨 마스킹 변환 $\tau_m$**이 적용됩니다.
    * 마스킹되지 않은 (가시적인) 패치들($\hat{v}_l, \hat{v}_g$)은 학습 가능한 인코더 $s(\cdot)$에 입력되어 볼륨 표현 $\hat{Z}_l, \hat{Z}_g$를 생성합니다.
    * 디코더 $D(\cdot)$는 인코딩된 가시 패치 표현과 학습 가능한 마스크 토큰을 입력받아 마스킹된 패치를 재구성합니다. 모든 토큰에는 위치 정보가 포함되도록 위치 임베딩이 추가됩니다.
    * 재구성된 볼륨 $y_l, y_g$를 원본 마스킹된 볼륨과 비교하여 **평균 제곱 오차(MSE)**를 기반으로 지역 재구성 손실 $L_l^R$과 전역 재구성 손실 $L_g^R$을 계산합니다. 전역 뷰가 지역 뷰보다 큰 입력 크기를 가지므로, 위치 임베딩은 보간됩니다.

2. **전역 가이드 일관성 학습(Global-guided Consistency Learning):**
    * 이 접근 방식은 두 가지 구성 요소로 나뉩니다: **전역-대-전역 일관성(Global-to-global consistency)**과 **전역-대-지역 일관성(Global-to-local consistency)**.
    * 마스킹되지 않은 완전한 전역 뷰 $v_g$의 표현을 '앵커'로 사용하여 마스킹된 전역 뷰 $\hat{v}_g$와 마스킹된 지역 뷰 $\hat{v}_l$의 표현 학습을 유도합니다. 이는 마스킹으로 인한 왜곡에 강건한 특징을 학습하고 학습 수렴을 가속화합니다.
    * 이를 위해, 학습 가능한 인코더 $s(\cdot)$와 모멘텀 인코더 $m(\cdot)$로 구성된 투-인코더 아키텍처가 사용됩니다. 모멘텀 인코더 $m(\cdot)$는 마스킹되지 않은 전역 뷰 $v_g$로부터 평균 표현 $Z_c = m(v_g)$를 생성하며, 그 파라미터는 $s(\cdot)$의 파라미터를 기반으로 지수 이동 평균(EMA) 방식으로 업데이트됩니다.
    * $s(\cdot)$와 $m(\cdot)$의 출력을 각각 투영 계층 $P_s(\cdot)$와 $P_m(\cdot)$을 통해 공유 특징 공간으로 투영합니다: $E_c = P_m(Z_{cls}^c)$, $\hat{E}_g = P_s(\hat{Z}_{cls}^g)$, $\hat{E}_l = P_s(\hat{Z}_{cls}^l)$.
    * 이들 임베딩은 정규화된 후, **크로스-엔트로피 손실** $H(\Gamma(E_c), \Gamma(\hat{E}_g)) + H(\Gamma(E_c), \Gamma(\hat{E}_l))$을 통해 전역-대-전역 일관성 손실 $L_{gg}^C$과 전역-대-지역 일관성 손실 $L_{gl}^C$을 계산합니다.

* **최종 목적 함수:** 위 모든 손실 항의 가중 합으로 정의됩니다: $L = L_l^R + \beta_1 L_g^R + \beta_2 L_{gg}^C + \beta_3 L_{gl}^C$. (실험에서 모든 $\beta$ 값은 1.0으로 설정되었습니다.)

## 📊 Results

* **하류 작업(Downstream Tasks) 성능:**
  * **완전 전이 학습(End-to-end) 및 선형 평가:** BTCV, MSD Spleen, MM-WHS 데이터셋에서 GL-MAE는 supervised baseline 및 MAE3D를 포함한 기존 SOTA 자가 지도 학습 방법론들을 일관되게 능가했습니다. 특히, 25%나 50%와 같이 주석 데이터가 적은 환경에서도 현저히 우수한 성능을 보였습니다.
  * **경량 백본(ViT-Tiny)에서의 성능:** GL-MAE는 ViT-Tiny와 같은 경량 트랜스포머 백본에서도 평균 Dice 점수, Normalized Surface Dice, Hausdorff Distance-95와 같은 지표에서 다른 방법론들보다 뛰어난 성능을 유지하여, 다양한 계산 환경에서의 유용성을 입증했습니다.
* **미학습 데이터셋 및 교차 모달리티 일반화:**
  * **MM-WHS (기관 데이터셋):** MAE3D 대비 평균 Dice 점수를 86.03%에서 88.88%로 크게 향상시키며 강력한 일반화 능력을 보였습니다.
  * **BraTS (MRI 뇌종양 데이터셋):** CT 데이터로 사전 학습했음에도 불구하고 MRI 데이터셋에서 모델 성능을 향상시켜, 다른 영상 모달리티 간에도 유사한 조직적 지식이 공유될 수 있음을 시사했습니다.
* **COVID-19 병변 분할:** COVID-19-20 Lung CT Lesion Segmentation Challenge 데이터셋에서 baseline 대비 47.92%에서 49.88%로 성능을 향상시켜, 비주석 CT 데이터로부터 질병 진단에 유용한 지식을 포착할 수 있음을 보여주었습니다.
* **프레임워크 분석:**
  * **어블레이션 연구:** 전역 및 지역 재구성, 전역-대-전역 일관성, 전역-대-지역 일관성 등 GL-MAE의 모든 구성 요소가 모델 성능 향상에 기여함을 확인했습니다. 특히 전역 정보의 통합이 볼륨 데이터에 중요함을 강조합니다.
  * **레이블 효율성:** 제한된 주석 데이터(25%, 50%)만으로도 Dice 점수를 4.4%에서 8.0%까지 향상시켜, 레이블링 노력의 필요성을 줄이는 효과를 입증했습니다.
  * **수렴 속도:** GL-MAE는 MAE3D보다 더 빠른 수렴 속도와 더 우수한 최종 성능을 보였으며, 이는 전역 완전 뷰를 '앵커'로 사용하는 것이 학습 과정을 안정화함을 시사합니다.
  * **마스크 비율 분석:** 0.6의 마스크 비율이 가장 좋은 재구성 성능을 보였으며, 너무 높은 마스크 비율(0.7)은 적합하지 않음을 확인했습니다.

## 🧠 Insights & Discussion

* GL-MAE는 볼륨 메트릭 의료 영상 분석을 위한 기존 ViT(Vision Transformer) 기반 자가 지도 사전 학습 방법의 주요 한계점인 **전역 정보의 부족**과 **학습된 표현의 불안정성**을 효과적으로 해결합니다.
* 모델이 **전역적 맥락과 지역적 세부 정보를 동시에 학습**하고, 마스킹되지 않은 전역 뷰를 통한 **일관성 학습으로 '앵커' 역할**을 부여함으로써, 입력 왜곡에 강건하며 풍부한 의미론적 표현을 학습하도록 유도하는 것이 핵심입니다.
* 이러한 접근 방식은 특히 **레이블링된 데이터가 부족한 의료 영상 분야**에서 큰 잠재력을 가지며, 모델의 **일반화 능력과 효율성**을 크게 향상시킵니다. CT 데이터로 사전 학습된 모델이 MRI와 같은 **다른 모달리티에서도 전이 학습이 가능**하다는 점은 GL-MAE가 다양한 임상 시나리오에 적용될 수 있는 다재다능함을 시사합니다.
* GL-MAE는 기존 방법들 대비 우수한 성능을 보이며, 의료 영상 분석에서 밀집 예측을 위한 유망한 사전 학습 백본임을 입증했습니다. 향후 연구에서는 GL-MAE의 대규모 데이터셋 및 모델 용량으로의 확장 가능성을 탐구할 계획입니다.

## 📌 TL;DR

볼륨 메트릭 의료 영상 분할을 위해, 기존 MAE 기반 자가 지도 학습의 전역 정보 부족 및 불안정한 표현 학습 문제를 해결하고자 GL-MAE를 제안합니다. GL-MAE는 마스킹된 지역/전역 뷰 재구성과 마스킹되지 않은 전역 뷰를 '앵커'로 활용한 전역 가이드 일관성 학습을 통해 전역적 맥락과 지역적 세부 정보를 동시에 학습하고 표현 학습을 안정화합니다. 다양한 데이터셋에서 SOTA 성능을 달성하며, 특히 레이블이 적은 환경에서도 뛰어난 일반화 능력과 효율성을 입증하여, 의료 영상 밀집 예측을 위한 유망한 사전 학습 백본임을 보여줍니다.
