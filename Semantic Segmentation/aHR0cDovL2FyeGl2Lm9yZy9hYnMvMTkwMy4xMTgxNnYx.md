# FastFCN: Rethinking Dilated Convolution in the Backbone for Semantic Segmentation
Huikai Wu, Junge Zhang, Kaiqi Huang, Kongming Liang, Yizhou Yu

## 🧩 Problem to Solve
시맨틱 분할(semantic segmentation)을 위한 현대 신경망은 일반적으로 고해상도 특징 맵(feature map)을 추출하기 위해 백본(backbone)에 팽창 컨볼루션(dilated convolutions, 또는 atrous convolutions)을 사용합니다. 하지만 이러한 팽창 컨볼루션은 막대한 계산 복잡도와 메모리 사용량을 야기하여 실시간 애플리케이션에서의 활용을 제한합니다. 이 논문은 시간과 메모리를 많이 소모하는 팽창 컨볼루션을 대체하여 성능 손실 없이 연산량을 대폭 줄이는 것을 목표로 합니다.

## ✨ Key Contributions
*   **JPU(Joint Pyramid Upsampling) 모듈 제안**: 시간과 메모리를 많이 소모하는 백본의 팽창 컨볼루션을 대체하는 새로운 조인트 업샘플링(joint upsampling) 모듈인 JPU를 제안했습니다.
*   **연산 효율성 및 성능 향상**: 제안된 JPU를 통해 전체 시맨틱 분할 프레임워크의 계산 복잡도를 3배 이상 줄이면서도 성능 손실 없이 더 나은 성능을 달성했습니다.
*   **최첨단 성능 달성**: Pascal Context 데이터셋(53.13% mIoU)과 ADE20K 데이터셋(최종 점수 0.5584)에서 새로운 최첨단(state-of-the-art) 성능을 달성했으며, 동시에 3배 이상 빠르게 동작합니다.
*   **모듈의 범용성**: JPU는 기존의 많은 시맨틱 분할 접근 방식에 쉽게 적용되어 계산 복잡도를 줄이고 성능을 향상시킬 수 있는 플러그 앤 플레이(plug-and-play) 모듈임을 입증했습니다.

## 📎 Related Works
*   **시맨틱 분할 (Semantic Segmentation)**:
    *   **FCN (Fully Convolutional Networks)** [22]: 시맨틱 분할의 기본 모델입니다.
    *   **DilatedFCN 계열**: DeepLab [5], PSPNet [38], EncNet [36] 등은 팽창 컨볼루션을 사용하여 높은 해상도의 특징 맵을 유지하고 멀티 스케일 문맥(multi-scale context) 정보를 활용합니다 (예: ASPP, PSP, Context Encoding Module).
    *   **Encoder-Decoder 계열**: U-Net [28], RefineNet [18], DeepLabV3+ [8] 등은 인코더에서 추출한 다단계(multi-level) 특징 맵을 디코더에서 결합하여 공간 정보를 복구합니다.
*   **업샘플링 (Upsampling)**:
    *   **조인트 업샘플링 (Joint Upsampling)** [17, 31]: 가이드 이미지(guidance image)를 활용하여 저해상도 이미지의 구조적 세부 정보를 고해상도 목표 이미지로 전달하는 것을 목표로 합니다. 이 연구의 JPU는 채널 수가 많은 특징 맵 처리에 특화되어 기존 조인트 필터와 차별화됩니다.
    *   **데이터 의존적 업샘플링 (Data-Dependent Upsampling)** [29]: DUpsampling과 같이 레이블 공간의 중복성을 활용하여 저해상도 CNN 출력에서 픽셀 단위 예측을 복구합니다. JPU는 레이블 공간 의존성이 적어 더 복잡한 레이블 공간에 대한 일반화 능력이 우수합니다.

## 🛠️ Methodology
FastFCN은 기존 팽창 컨볼루션 기반 DilatedFCN의 계산 복잡성과 메모리 오버헤드를 해결하기 위해, 고해상도 특징 맵을 추출하는 작업을 **조인트 업샘플링 문제**로 재구성하고 이를 해결하기 위한 JPU(Joint Pyramid Upsampling) 모듈을 제안합니다.

1.  **백본 재구성**:
    *   DilatedFCN이 제거했던 모든 스트라이드 컨볼루션(stride convolutions)을 다시 도입하고, 팽창 컨볼루션을 일반 컨볼루션 레이어로 대체합니다.
    *   이는 본래의 FCN과 동일한 백본 구조를 사용하며, 최종 특징 맵의 공간 해상도는 32배 축소(OS=32)됩니다.

2.  **JPU (Joint Pyramid Upsampling) 모듈**:
    *   **입력**: 백본에서 생성된 마지막 세 가지 특징 맵($\text{Conv}_3$, $\text{Conv}_4$, $\text{Conv}_5$)을 입력으로 받습니다. 이들은 각각 8배, 16배, 32배 다운샘플링된 특징 맵입니다.
    *   **초기 처리**: 각 입력 특징 맵은 우선 일반 컨볼루션 블록을 통해 처리됩니다.
        *   이는 $y_m$과 같은 중간 특징 맵을 생성합니다.
        *   모든 특징을 동일한 임베딩 공간으로 매핑하여 차원을 줄이고 퓨전을 용이하게 하며 계산 복잡도를 감소시킵니다.
    *   **업샘플링 및 연결**: 처리된 특징 맵들은 모두 고해상도(예: OS=8)로 업샘플링된 후 하나로 **연결(concatenate)**됩니다($y_c$).
    *   **멀티 스케일 컨텍스트 추출**: 연결된 특징 맵 $y_c$에 대해 서로 다른 팽창률(1, 2, 4, 8)을 가진 네 개의 분리 가능 컨볼루션(separable convolutions)을 병렬로 적용합니다.
        *   **팽창률 1**: $y_0^m$(다운샘플링된 $y_m$ 부분)과 $y_m$의 나머지 부분 사이의 관계를 포착합니다.
        *   **팽창률 2, 4, 8**: $y_0^m$을 $y_s$(스트라이드 컨볼루션 분기의 출력)로 변환하는 매핑 $\hat{h}$를 학습하는 데 사용됩니다. 이를 통해 다단계 특징 맵에서 멀티 스케일 문맥 정보를 효과적으로 추출합니다. 이는 단일 특징 맵에만 의존하는 ASPP와는 다른 점입니다.
    *   **최종 예측**: 추출된 특징들은 또 다른 일반 컨볼루션 블록을 통해 최종 예측 특징 맵으로 변환됩니다.
    *   **조인트 업샘플링 문제 해결**: JPU는 $\text{Conv}_3$를 기반으로 $\text{Conv}_4$를 업샘플링하고, 확장된 $\text{Conv}_4$의 가이드를 받아 $\text{Conv}_5$를 업스케일링하는 두 가지 밀접하게 관련된 조인트 업샘플링 문제를 동시에 해결합니다.

3.  **후처리**: JPU에서 생성된 고해상도 특징 맵(OS=8)은 이후 PSP [38], ASPP [6] 또는 Context Encoding [36]과 같은 멀티 스케일/글로벌 문맥 모듈에 입력되어 최종 시맨틱 레이블 맵을 생성합니다.

이러한 접근 방식을 통해 DilatedFCN과 비교하여 ResNet-101 백본 사용 시 23개 잔여 블록(69개 컨볼루션 레이어)에서 4배, 3개 블록(9개 컨볼루션 레이어)에서 16배 적은 계산 및 메모리 자원을 사용하게 됩니다.

## 📊 Results
*   **계산 복잡도 (FPS)**:
    *   ResNet-50 백본에서 Encoding-JPU 방식은 기존 EncNet보다 약 2배 빠릅니다 (18.77 FPS $\rightarrow$ 37.56 FPS).
    *   ResNet-101 백본에서 Encoding-JPU 방식은 기존 EncNet보다 3배 이상 빠릅니다 (10.51 FPS $\rightarrow$ 32.02 FPS).
    *   JPU는 DeepLabV3 (ASPP) 및 PSPNet에도 적용 가능하며, 성능 향상과 동시에 상당한 속도 향상을 보여줍니다.
*   **성능 (mIoU)**:
    *   **Pascal Context 데이터셋**:
        *   ResNet-50 백본 사용 시 51.2% mIoU를 달성하여 Bilinear, FPN, 기존 EncNet(OS=8) 대비 우수합니다.
        *   ResNet-101 백본 사용 시 53.13% mIoU를 달성하여 기존 EncNet(ResNet-101) 및 DUpsampling(Xception-71)보다 높은 최첨단 성능을 기록했습니다.
    *   **ADE20K 데이터셋**:
        *   ResNet-50 백본 사용 시 검증(val) 세트에서 42.75% mIoU를 달성하며 EncNet(ResNet-50)과 RefineNet(ResNet-152)보다 뛰어납니다.
        *   ResNet-101 백본 사용 시 테스트(test) 세트에서 0.5584의 최종 점수를 기록하여 2017 COCO-Place 챌린지의 우승팀 및 PSPNet, EncNet을 능가하는 최첨단 성능을 보여주었습니다.
*   **시각적 결과**: JPU는 객체 경계와 세부 정보를 더 정확하게 예측하며, 특히 작은 객체나 복잡한 구조(예: 나뭇가지의 작은 가지)에서도 뛰어난 분할 능력을 보여줍니다.

## 🧠 Insights & Discussion
*   **근본적인 원리**: 이 연구는 팽창 컨볼루션과 스트라이드 컨볼루션의 연관성을 분석하고, 고해상도 특징 맵 추출 문제를 조인트 업샘플링 문제로 재구성하는 혁신적인 통찰력을 제시합니다. 이 재구성을 통해 계산 비용이 높은 팽창 컨볼루션을 더 효율적인 JPU 모듈로 대체할 수 있었습니다.
*   **JPU의 효과**: JPU는 단순히 저해상도 특징 맵을 업샘플링하는 것을 넘어, 다단계(multi-level) 특징 맵에서 멀티 스케일 문맥 정보(예: 팽창률 1, 2, 4, 8을 가진 분리 가능 컨볼루션)를 효과적으로 추출합니다. 이는 단일 마지막 특징 맵에만 의존하는 기존 방식(예: ASPP)과 차별화되며, 더 정확하고 섬세한 분할 결과를 가능하게 합니다. 특히, JPU는 $y_0^m$와 $y_m$의 나머지 부분 사이의 관계를 포착하고, $y_0^m$을 $y_s$로 변환하는 매핑 $\hat{h}$를 학습함으로써, 세부 정보를 효과적으로 복구합니다.
*   **실용적 의의**: JPU의 도입으로 시맨틱 분할 네트워크의 추론 속도를 크게 향상시키면서도, 기존의 복잡한 팽창 컨볼루션 기반 모델들의 성능을 능가하거나 대등한 수준을 달성했습니다. 이는 자원 제약이 있는 환경(예: 임베디드 시스템, 모바일 장치)에서 시맨틱 분할 모델을 배포하는 데 큰 이점을 제공합니다.
*   **한계 및 논의**: ADE20K 검증 세트에서의 ResNet-101 성능이 EncNet보다 약간 낮았던 것은 훈련 이미지 크기(본 연구: $480 \times 480$, EncNet: $576 \times 576$)의 차이 때문으로 분석됩니다. 더 큰 이미지 크기로 훈련할 경우 성능 향상의 여지가 있음을 시사합니다. 하지만 테스트 세트에서는 여전히 최첨단 성능을 달성하여 JPU의 강점을 입증했습니다.

## 📌 TL;DR
시맨틱 분할에서 고해상도 특징 맵을 얻기 위한 팽창 컨볼루션은 연산량이 많고 메모리를 많이 소비합니다. FastFCN은 이 문제를 해결하기 위해 고해상도 특징 맵 추출을 '조인트 업샘플링' 문제로 재정의하고, 이를 해결하는 **JPU(Joint Pyramid Upsampling) 모듈**을 제안합니다. JPU는 표준 FCN 백본의 다단계 특징 맵을 활용하여 멀티 스케일 문맥 정보를 효과적으로 융합합니다. 결과적으로 FastFCN은 Pascal Context 및 ADE20K 데이터셋에서 최첨단 성능을 달성하면서도, 기존 팽창 컨볼루션 방식보다 3배 이상 빠르며 연산량과 메모리 사용량을 대폭 줄였습니다.