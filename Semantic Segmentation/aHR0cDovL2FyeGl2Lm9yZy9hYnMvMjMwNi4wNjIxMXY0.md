# A Survey on Segment Anything Model (SAM): Vision Foundation Model Meets Prompt Engineering

Chaoning Zhang, Joseph Cho, Fachrina Dewi Puspitasari, Sheng Zheng, Chenghao Li, Yu Qiao, Taegoo Kang, Xinru Shan, Chenshuang Zhang, Caiyan Qin, Francois Rameau, Lik-Hang Lee, Sung-Ho Bae, Choong Seon Hong

## 🧩 Problem to Solve

이 논문은 Meta AI Research에서 개발한 Segment Anything Model (SAM)과 그 후속작인 SAM 2의 혁신적인 이미지 및 비디오 분할(segmentation) 프레임워크를 심층적으로 탐구합니다. 주된 문제는 SAM 제품군이 컴퓨터 비전 분야에서 다양한 시나리오에 걸쳐 객체를 정확하고 유연하게 분할할 수 있도록 하는 강력한 비전 파운데이션 모델(Vision Foundation Model)로서의 역할을 검토하고, 동시에 이 모델들의 다용성(versatility)을 입증하며 개선이 필요한 영역을 식별하는 것입니다. 특히 높은 정밀도(granularity)가 요구되는 시나리오나 명시적인 프롬프트가 없는 상황에서의 한계점을 해결하고자 합니다.

## ✨ Key Contributions

- **SAM 제품군의 포괄적 탐색**: SAM과 SAM 2를 모두 포함하여, 분할 세분화(granularity) 및 맥락적 이해(contextual understanding)의 발전을 중점적으로 다룹니다.
- **광범위한 애플리케이션 다용성 입증**: 이미지, 비디오, 3D, 멀티모달, 인간-로봇 상호작용 및 특수 도메인(원격 감지, 이상 감지, 농업 등)에 걸쳐 SAM의 활용 사례를 광범위하게 제시합니다.
- **강점 및 한계 식별**: SAM 모델의 강점과 함께, 높은 정밀도가 요구되는 시나리오나 명시적인 프롬프트가 없는 상황(예: 의료 영상, 위장 객체, 투명 객체)에서 개선이 필요한 영역을 명확히 합니다.
- **미래 연구 방향 제시**: 도메인별 맞춤화, 향상된 메모리 및 전파 메커니즘, 다른 AI 기술(LLM 등)과의 통합 등 SAM 기술의 지속적인 발전을 위한 구체적인 연구 방향을 제안합니다.
- **체계적인 검토 방법론**: PRISMA 프레임워크를 사용하여 192편의 관련 논문을 엄격하게 선별하고 분석하여 신뢰성 있는 조사를 수행합니다.

## 📎 Related Works

- **SAM 이전의 정밀 분할 기술**:
  - **Human Parsing (JPPNet [16])**: 포즈 추정(pose estimation)에 의존하며, 주로 관절형(articulated) 객체에 제한됩니다.
  - **다중 스케일 특징 추출 (DeepLab [17])**: 객체 독립적인 정밀 분할이 가능하지만, 구조적 관계 정보를 무시합니다.
  - **그래프 기반 모델 (GMNet [18])**: 객체-부분(part-object) 구조 정보를 인코딩하여 분할에 활용합니다.
  - **트랜스포머 기반 모델 (Panoptic-PartFormer [19])**: SAM의 전체(whole), 부분(part), 하위 부분(sub-part) 쿼리 방식과 유사하게 세분화된 쿼리를 사용합니다.
- **기존 SAM 관련 설문 조사**:
  - [6]: SAM의 아키텍처 및 비전 작업 전반의 응용을 다룹니다.
  - [7]: SAM의 비디오 응용을 중점적으로 다룹니다.
  - [8]: SAM을 포함한 파운데이션 모델의 프롬프트 기반 분할 역할을 다룹니다.
  - [9]: 의료 영상 분할에서의 SAM 응용을 다룹니다.
  - [10]: 생체 의료 영상 및 비디오 분할에서의 SAM 2 응용을 다룹니다.
- **주요 개념**: 프롬프트 가능한 분할(promptable segmentation), 제로샷 분할(zero-shot segmentation), 비전 파운데이션 모델(vision foundation model).

## 🛠️ Methodology

이 설문 조사는 Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) [11] 프레임워크를 활용하여 SAM 및 SAM 2 관련 문헌을 체계적으로 수집하고 분석했습니다.

- **문헌 수집**: IEEE Xplore, ACM Library, Scopus, arXiv (빠른 연구 발전을 반영하기 위해)와 같은 주요 데이터베이스에서 AAAI, CVPR, ECCV, ICCV, ICLR, NeurIPS 등 저명한 학회 및 저널의 논문을 수집했습니다.
- **기간 및 키워드**: 2023년 4월부터 2024년 9월까지 "segment anything model" 및 "SAM" 키워드를 사용하여 총 428개의 논문을 초기 선별했습니다.
- **선별 기준**:
  - SAM을 단순한 분할 도구로만 활용하는 논문 제외.
  - 다른 설문 및 리뷰 논문 제외.
  - 발표 6개월 후에도 첫 인용이 없는 arXiv 논문 제외 (품질 및 유용성 대리 지표).
- **최종 분석 대상**: 이 기준을 적용하여 최종적으로 192개의 논문을 선정하여 설문 조사의 주요 자료로 활용했습니다.
- **SAM/SAM 2 아키텍처 (개요)**:
  - **SAM**: ViT 백본 기반의 이미지 인코더, 프롬프트 인코더(점, 상자, 마스크 등 다양한 프롬프트 지원), 마스크 디코더로 구성된 프롬프트 기반 아키텍처. 객체의 다양한 세분화 수준을 동시에 처리하는 모호성 인식 디코딩(ambiguity-aware decoding)과 대규모의 의미적으로 비제약적인 마스크 주석(semantically unconstrained mask annotation)이 핵심입니다.
  - **SAM 2**: SAM의 기능을 확장하여 비디오 분할을 지원합니다. PVS(Promptable Visual Segmentation) 접근 방식을 통해 이미지와 비디오 데이터를 통합 처리하는 통일된 분할 프레임워크를 제공합니다. 또한, 스트리밍 메모리 아키텍처(streaming memory architecture)를 도입하여 이전 프레임의 정보를 활용해 비디오 시퀀스 전반에 걸쳐 분할 일관성을 유지하고, 메모리 뱅크에 키프레임 정보를 저장하여 동적 환경에서의 정확성을 높입니다.

## 📊 Results

이 설문 조사는 SAM과 SAM 2의 광범위한 적용 가능성과 다양한 도메인에서의 성능을 강조합니다.

- **이미지 기반 애플리케이션**:
  - **생성**: Concept Weaver, TheaterGen 등에서 정확한 객체 분할 마스크를 제공하여 이미지 생성의 정밀도와 맥락적 일관성을 향상시킵니다.
  - **인페인팅, 스타일링, 복원**: Inpaint Anything에서 이미지 수정 및 재구성을 용이하게 하고, Matte Anything에서 알파-매트(alpha-matte) 생성을 지원하며, 이미지 복원(Image Restoration)에서는 노이즈 샘플링을 안내하고 아티팩트를 줄입니다.
  - **주석**: weakly supervised semantic segmentation에서 CAM(Class Activation Maps)과 결합하여 의사 레이블(pseudo-labels)을 개선하고, 의료 영상 및 멀티스펙트럴 이미징에서 주석 프로세스를 가속화합니다.
  - **매칭**: MESA 프레임워크에서 영역 매칭 정확도를 개선하고, 이미지 간 매칭에서 마스크 제안(mask proposals)을 통해 영역 분류 성능을 높입니다.
- **비디오 기반 애플리케이션**:
  - **생성**: Magic-Me, CustomVideo 등에서 비디오 내 객체 분할 마스크를 생성하여 정체성 유지, 맥락 일관성 및 동적 움직임 제어를 지원합니다.
  - **주석**: EVA-VOS 및 SAMText 파이프라인에서 비디오 레이블링 속도와 정확도를 향상시킵니다.
  - **추적**: SAM 2는 Track Anything Model (TAM) 및 XMem과 같은 이전 방법을 뛰어넘어, 메모리 기반 어텐션 메커니즘을 통해 객체 추적의 시간적 일관성과 견고성을 크게 향상시킵니다.
- **3D 애플리케이션**:
  - **3D 감지**: SAM과 Depth Anything Model (DAM)의 결합으로 pseudo-LiDAR 데이터를 생성하여 3D 객체 감지 정확도를 높이고, Grounded-SAM 및 PointSAM을 통해 3D 공간에서의 객체 감지 및 주석을 자동화합니다.
  - **3D (분해) 구성**: 2D 분할 마스크를 3D 가우시안(3D Gaussians) 그룹화 및 NeRF(Neural Radiance Fields) 분해에 활용하여 3D 장면의 조작 및 이해를 용이하게 합니다.
- **멀티모달 애플리케이션**:
  - **오디오-비주얼**: 오디오 프롬프트를 활용하여 시각적 분할 작업을 정교화하고, 오디오-비주얼 특징 융합을 통해 음원 위치 파악 및 분할 성능을 향상시킵니다.
  - **비전-언어 모델 (VLMs)**: 정확한 3D 포인트 추출, 개방형 객체 질의 생성, 세부적인 이미지 설명 및 지역 캡셔닝을 가능하게 하여 VLMs의 능력을 강화합니다.
  - **픽셀 레벨 지시 및 미세 입자 시각 이해**: 픽셀 단위 시각 지시 튜닝 및 특정 지역 텍스트 설명을 가능하게 하여 객체 감지, 이미지 캡셔닝, 시각적 접지(visual grounding) 등에서 성능을 향상시킵니다.
- **인간-로봇 상호작용 애플리케이션**:
  - 로봇의 변형 가능한 선형 객체 인식 및 조작, 자율 로봇의 조작, 모바일 플랫폼에서의 동적 객체 조작 및 추적 능력을 향상시킵니다.
  - 로봇의 계획 및 조작 작업에서 키포인트 식별 및 모션 계획을 지원하며, 자율 주행 시나리오에서 데이터셋 생성 및 센서 캘리브레이션에 기여합니다.
- **특수 도메인 애플리케이션**:
  - **원격 감지**: 미세 객체, 해빙(sea ice) 분할, 대규모 원격 감지 분할 데이터셋 생성에 기여하며, MeSAM, RSAM-Seg, Text2Seg와 같은 모델을 통해 정확도를 향상시키고 변화 감지(change detection)에 적용됩니다.
  - **이상 감지 (Anomaly Detection)**: CLIP과의 협업을 통해 이상 영역의 위치 파악 및 분할을 정교화하고, 결함 감지, 경량 모델 학습 지도 등 다양한 이상 감지 시나리오에서 효과적입니다.
  - **농업**: 정밀 축산(닭 추적) 및 잎 분류 등 농업 관련 작업에 적용될 가능성을 보여줍니다.
  - **기타**: 우주 탐사(행성 지질 매핑, 크레이터 감지), 시맨틱 통신, 토목 건축물 결함 평가(균열 감지) 등 다양한 분야에서 활용됩니다.

## 🧠 Insights & Discussion

- **한계점 및 도전 과제**:
  - **의료 영상**: 일반 시나리오에서는 우수한 성능을 보이나, 의료 도메인에서는 U-Net과 같은 완전 지도 학습 모델에 비해 낮은 정확도(Dice score)를 보입니다. 특히 췌장, 간과 같이 경계가 불분명한 장기나 악성 종양 분할에서 어려움을 겪습니다. SAM 2는 3D 설정에서 개선되었지만, 낮은 대조도 영상(CT, 초음파)에서는 여전히 취약하며, 과분할(over-segmentation) 문제가 존재합니다.
  - **까다로운 객체 및 장면**: 미세하거나 가는 객체, 모호한 경계, 가려진 객체, 위장된 객체, 투명 객체, 그림자 감지 등 복잡한 실제 환경에서 분할 정확도가 떨어집니다. 이러한 경우 SAM의 원시(raw) 출력 마스크는 객체 개수 세기와 같은 작업에 직접 사용하기 어렵습니다.
  - **프롬프트 의존성**: SAM의 성능은 제공되는 프롬프트의 유형과 품질에 크게 의존합니다. 자동 프롬프트는 만족스럽지 못한 결과를 내는 경우가 많고, 박스 프롬프트가 포인트 프롬프트보다 더 정확하며, 여러 포인트를 적용하거나 박스 프롬프트와 포인트 프롬프트를 순차적으로 결합할 때 정확도가 높아집니다.
  - **견고성 (Robustness)**: SAM은 적대적 공격(adversarial attacks)에 취약하여, 특히 화이트박스 PGD(Projected Gradient Descent) 공격 시 마스크가 쉽게 제거되거나 새로운 마스크가 생성될 수 있습니다. 이미지 손상(image corruptions)에 대해서는 어느 정도 견고성을 보이나, 의료 X선과 같은 까다로운 객체에서는 성능 저하가 더 큽니다.
- **미래 연구 방향**:
  - **미세 조정 (Fine-Tuning)**: 의료 영상 등 분포 외(out-of-distribution) 도메인에서 모델 성능을 향상시키는 가장 빠른 방법입니다. MedSAM, Polyp-SAM 등은 이 전략을 통해 유망한 결과를 보여주었습니다.
  - **어댑터 삽입 (Adapter Fixing)**: SAM 프레임워크를 약간 수정하여 도메인 특화 어댑터(domain-specific adapters)를 삽입하는 방식입니다. 이미지 임베딩과 프롬프트 토큰 간의 결합 효과를 해결하여 분할 출력이 프롬프트 품질에 과도하게 의존하는 문제를 완화할 수 있습니다.
  - **다른 AI 기술과의 통합**: LLM(Large Language Models)과의 통합을 통해 더 정교한 장면 해석 및 프롬프트 생성을 가능하게 합니다. 멀티모달 AI 시스템(오디오, 공간 데이터, LiDAR, 레이더)과의 결합은 자율 주행 및 AR/VR과 같은 분야에서 SAM의 능력을 확장할 수 있습니다.
  - **새로운 도메인 및 데이터셋으로의 확장**: 위장되거나 투명한 객체 감지, 그래프 기반 데이터와 같은 비유클리드 도메인, 위성 영상 분석, 더 다양한 의료 영상 모달리티 등으로 SAM의 적용 범위를 넓히는 것이 중요합니다.
  - **메모리 및 전파 메커니즘 개선**: SAM 2의 스트리밍 메모리 아키텍처를 더욱 최적화하여 대규모 분할 작업의 계산 비용을 줄이고, 3D 의료 영상 및 비디오 분할을 위한 적응형 전파 방법을 개발해야 합니다. 비지도 학습 및 강화 학습을 통합하여 레이블링된 데이터에 대한 의존도를 줄이고 동적으로 분할 전략을 개선하는 것도 중요합니다.

## 📌 TL;DR

Segment Anything Model (SAM)과 SAM 2는 프롬프트 기반의 강력한 비전 파운데이션 모델로서 이미지 및 비디오 분할 분야에 혁신을 가져왔다. 이 모델들은 이미지 생성, 의료 영상 주석, 3D 객체 감지, 로봇 조작 등 다양한 애플리케이션에서 탁월한 다용성과 정밀한 분할 능력을 입증했다. 그러나 의료 영상의 모호한 경계, 위장/투명 객체와 같은 까다로운 시나리오, 프롬프트 품질에 대한 의존성, 적대적 공격에 대한 취약성 등의 한계도 존재한다. 미래에는 도메인별 미세 조정, 아키텍처 어댑터, 다른 AI 기술(LLM 등)과의 통합, 새로운 도메인으로의 확장, 그리고 메모리 및 전파 메커니즘의 최적화를 통해 SAM 제품군의 견고성과 일반화 능력을 더욱 향상시킬 수 있을 것이다.
