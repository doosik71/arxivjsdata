# U-Net: 생체 의학 영상 분할을 위한 컨볼루션 네트워크

Olaf Ronneberger, Philipp Fischer, and Thomas Brox

## 🧩 Problem to Solve

생체 의학 영상 분할(biomedical image segmentation)은 각 픽셀에 클래스 레이블을 할당하는 정밀한 지역화(localization)를 요구하지만, 일반적으로 주석이 달린 학습 샘플이 매우 부족하다는 문제를 가지고 있습니다. 기존의 슬라이딩 윈도우(sliding-window) 방식은 픽셀별 예측이 가능하지만, 각 패치(patch)마다 네트워크를 개별적으로 실행해야 하므로 속도가 느리고, 지역화 정확도와 컨텍스트(context) 활용 사이의 절충이 필요하다는 단점이 있었습니다.

## ✨ Key Contributions

- **새로운 U-Net 아키텍처 제안**: 컨텍스트를 포착하는 '수축 경로(contracting path)'와 정밀한 지역화를 가능하게 하는 '확장 경로(expansive path)'로 구성된 대칭적인 U-자형 완전 컨볼루션 네트워크를 제안했습니다.
- **강력한 데이터 증강 전략**: 학습 데이터가 적은 생체 의학 영상의 특성을 고려하여, 탄성 변형(elastic deformation)을 포함한 과도한 데이터 증강을 사용하여 네트워크가 이러한 변형에 불변성(invariance)을 학습하도록 했습니다.
- **가중치 손실 함수 도입**: 동일 클래스 내 접촉하는 객체들을 효과적으로 분리하기 위해, 접촉하는 세포 사이의 배경 픽셀에 더 큰 가중치를 부여하는 픽셀별 가중치 손실 함수를 사용했습니다.
- **최첨단 성능 달성**: ISBI EM 분할 챌린지에서 이전 최고 방법(슬라이딩 윈도우 컨볼루션 네트워크)을 능가하는 성능을 달성했으며, ISBI 세포 추적 챌린지 2015에서 광학 현미경 이미지 부문에서 큰 차이로 우승했습니다.
- **빠른 추론 속도**: 512x512 크기의 이미지 분할에 최신 GPU에서 1초 미만이 소요되는 빠른 속도를 보여주었습니다.
- **임의 크기 이미지의 끊김 없는 분할**: 오버랩-타일(overlap-tile) 전략을 통해 GPU 메모리 한계 없이 임의로 큰 이미지를 끊김 없이 분할할 수 있도록 했습니다.

## 📎 Related Works

- **Ciresan et al. [1]:** 슬라이딩 윈도우 방식의 컨볼루션 네트워크를 사용하여 ISBI 2012 EM 분할 챌린지에서 우승하며 픽셀 단위 예측 가능성을 보여주었지만, 속도 및 컨텍스트/지역화 절충 문제점을 가졌습니다.
- **Long et al. [9]:** '완전 컨볼루션 네트워크(Fully Convolutional Networks, FCN)' 개념을 제안하여, U-Net 아키텍처의 기반이 되는 업샘플링(upsampling) 연산을 통한 해상도 증가 및 고해상도 피처 결합 방식을 확립했습니다.
- **Krizhevsky et al. [7]:** ImageNet 데이터셋을 사용한 대규모 딥 컨볼루션 네트워크 학습의 성공을 보여주며 딥러닝 분야의 돌파구를 마련했습니다.
- **Dosovitskiy et al. [2]:** 비지도 특징 학습(unsupervised feature learning) 분야에서 데이터 증강의 가치를 입증했습니다.
- **He et al. [5]:** ReLU 활성화 함수를 사용하는 딥 네트워크의 효율적인 가중치 초기화 방법($\sqrt{2/N}$ 표준 편차)에 대한 지침을 제공했습니다.

## 🛠️ Methodology

U-Net은 컨텍스트 포착을 위한 수축 경로(인코더)와 정밀한 지역화를 위한 확장 경로(디코더)로 구성된 U자형 아키텍처를 가집니다.

- **네트워크 아키텍처:**

  - **수축 경로 (좌측):** 일반적인 컨볼루션 네트워크 아키텍처를 따릅니다. 두 번의 3x3 컨볼루션(패딩 없음)과 ReLU(Rectified Linear Unit) 활성화 함수를 반복 적용한 후, 2x2 최대 풀링(stride 2)을 통해 다운샘플링합니다. 각 다운샘플링 단계마다 피처 채널 수를 두 배로 늘립니다.
  - **확장 경로 (우측):** 피처 맵을 업샘플링한 다음, 피처 채널 수를 절반으로 줄이는 2x2 컨볼루션("up-convolution")을 적용합니다. 이 결과를 수축 경로에서 잘라낸(cropped) 해당 피처 맵과 연결(concatenation)하고, 이어서 두 번의 3x3 컨볼루션과 ReLU를 적용합니다. 패딩 없는 컨볼루션으로 인한 테두리 픽셀 손실 때문에 크롭핑이 필요합니다.
  - **최종 레이어:** 1x1 컨볼루션을 사용하여 각 64-컴포넌트 피처 벡터를 원하는 클래스 수로 매핑합니다.
  - 총 23개의 컨볼루션 레이어로 구성되며, 완전 연결(fully connected) 레이어는 없습니다.
  - 출력 분할 맵의 끊김 없는 타일링을 위해, 모든 2x2 최대 풀링 연산이 짝수 x-y 크기의 레이어에 적용되도록 입력 타일 크기를 선택합니다.

- **학습:**

  - Caffe 프레임워크의 확률적 경사 하강법(SGD)을 사용하여 네트워크를 학습시킵니다.
  - GPU 메모리를 효율적으로 사용하고 오버헤드를 최소화하기 위해, 큰 입력 타일을 선호하여 배치 크기는 단일 이미지(1)로 설정하고, 높은 모멘텀(0.99)을 사용합니다.
  - **에너지 함수:** 픽셀별 소프트맥스(soft-max)를 최종 피처 맵에 적용하고, 이를 교차 엔트로피(cross-entropy) 손실 함수와 결합하여 계산합니다.
    - 소프트맥스: $p_k(x) = \frac{\exp(a_k(x))}{\sum_{k'=1}^{K} \exp(a_{k'}(x))}$ (여기서 $a_k(x)$는 픽셀 위치 $x \in \Omega$에서 $k$번째 피처 채널의 활성화 값, $K$는 클래스 수입니다.)
    - 교차 엔트로피 손실: $E = \sum_{x \in \Omega} w(x) \log(p_{\ell(x)}(x))$ (여기서 $\ell(x): \Omega \to \{1,...,K\}$는 각 픽셀의 실제 레이블이고, $w(x): \Omega \to R$는 가중치 맵입니다.)
  - **가중치 맵 $w(x)$:** 학습 데이터셋에서 특정 클래스 픽셀의 빈도 불균형을 보정하고, 접촉하는 세포들 사이의 작은 분리 경계에 더 큰 중요도를 부여하기 위해 미리 계산됩니다.
    - $w(x) = w_c(x) + w_0 \cdot \exp\left(-\frac{(d_1(x) + d_2(x))^2}{2\sigma^2}\right)$
    - $w_c(x)$는 클래스 빈도 균형을 위한 가중치, $d_1(x)$는 가장 가까운 세포 경계까지의 거리, $d_2(x)$는 두 번째로 가까운 세포 경계까지의 거리입니다. 실험에서는 $w_0 = 10$, $\sigma \approx 5$ 픽셀로 설정했습니다.
  - **가중치 초기화:** 각 피처 맵이 약 단위 분산(unit variance)을 갖도록, 초기 가중치는 $\sqrt{2/N}$ 표준 편차를 갖는 가우시안 분포에서 추출됩니다 (N은 한 뉴런의 수신 노드 수).

- **데이터 증강:**
  - 적은 수의 학습 샘플만 있을 때 네트워크에 원하는 불변성과 견고성을 가르치기 위해 필수적입니다.
  - 특히 무작위 탄성 변형(random elastic deformations)은 생체 의학 영상 분할에서 핵심적인 개념으로, 3x3 격자에서 가우시안 분포(표준 편차 10픽셀)로부터 샘플링된 무작위 변위 벡터를 사용하여 부드러운 변형을 생성하고, 이후 쌍삼차 보간법(bicubic interpolation)으로 픽셀별 변위를 계산합니다.
  - 수축 경로의 끝 부분에 있는 드롭아웃(dropout) 레이어도 암시적인 데이터 증강 역할을 합니다.

## 📊 Results

U-Net은 다양한 생체 의학 분할 작업에서 뛰어난 성능을 입증했습니다.

- **ISBI EM 분할 챌린지 (전자 현미경 내 신경 구조 분할):**

  - U-Net은 전처리 또는 후처리 없이 워핑 에러(warping error) 0.0003529 (새로운 최고 기록)와 랜드 에러(Rand error) 0.0382를 달성했습니다.
  - 이는 기존 최고 성능이었던 Ciresan et al. [1]의 슬라이딩 윈도우 컨볼루션 네트워크(워핑 에러 0.000420, 랜드 에러 0.0504)보다 현저히 우수한 결과입니다.

- **ISBI 세포 추적 챌린지 2015 (광학 현미경 이미지 내 세포 분할):**
  - **"PhC-U373" 데이터셋 (위상차 현미경 글리오블라스토마 세포):** 평균 IOU(Intersection Over Union) 92%를 달성하여 2위 알고리즘(83%)을 크게 앞섰습니다.
  - **"DIC-HeLa" 데이터셋 (DIC 현미경 HeLa 세포):** 평균 IOU 77.5%를 달성하여 2위 알고리즘(46%)보다 훨씬 우수한 성능을 보였습니다.

## 🧠 Insights & Discussion

U-Net 아키텍처는 매우 적은 수의 주석 달린 이미지만으로도 다양한 생체 의학 분할 애플리케이션에서 매우 우수한 성능을 보여줍니다. 이는 탄성 변형을 통한 강력한 데이터 증강 전략 덕분이며, 네트워크가 이러한 변형에 대한 불변성을 학습할 수 있도록 합니다. 또한, U-Net은 NVidia Titan GPU에서 10시간 정도의 합리적인 학습 시간을 가지며, 512x512 이미지 분할에 1초 미만이 소요되는 빠른 추론 속도를 제공합니다. 이러한 효율성과 성능은 생체 의학 분야에서 딥러닝 기반 이미지 분할의 실용성을 크게 높였습니다. 접촉하는 객체 분리를 위한 가중치 손실 함수는 이러한 까다로운 문제에 대한 효과적인 해결책을 제시하며, U-Net 아키텍처의 범용성은 향후 더 많은 작업에 쉽게 적용될 수 있음을 시사합니다.

## 📌 TL;DR

생체 의학 영상 분할은 주석 데이터 부족과 정밀한 픽셀 단위 지역화라는 문제를 안고 있습니다. 본 논문은 컨텍스트 포착 경로와 정밀 지역화 경로를 갖춘 U자형 완전 컨볼루션 네트워크인 **U-Net**을 제안하고, 탄성 변형을 통한 강력한 데이터 증강 및 픽셀별 가중치 손실 함수를 도입하여 이 문제를 해결합니다. 그 결과, U-Net은 적은 학습 데이터로도 ISBI EM 영상 및 세포 분할 챌린지에서 **최첨단 성능**을 달성했으며, **빠른 추론 속도**와 **광범위한 적용 가능성**을 보였습니다.
