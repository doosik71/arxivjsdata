# BiSeg: Simultaneous Instance Segmentation and Semantic Segmentation with Fully Convolutional Networks

Viet-Quoc Pham, Satoshi Ito, Tatsuo Kozakaya

## 🧩 Problem to Solve

본 논문은 이미지 내의 객체를 픽셀 수준에서 정확하게 감지하고 분할하는 인스턴스 분할(Instance Segmentation) 문제를 해결하고자 합니다. 인스턴스 분할은 각 픽셀을 특정 카테고리로 분류하지만 객체 개별 인스턴스를 구분하지 않는 의미론적 분할(Semantic Segmentation)과 달리, 동일한 카테고리 내의 개별 객체 인스턴스를 구분해야 합니다. 기존 방식들은 종종 외부 모듈에서 마스크 제안을 필요로 하거나(예: DeepMask, SharpMask), 느리고 정확도가 떨어지는 경향이 있었습니다. 이 논문은 의미론적 분할과 인스턴스 분할을 동시에 수행하는 효과적인 통합 프레임워크를 제안하여 이 문제를 해결합니다.

## ✨ Key Contributions

- **동시 인스턴스/의미론적 분할 프레임워크 제안:** 완전 컨볼루션 네트워크(FCN)를 활용하여 의미론적 분할과 인스턴스 분할을 동시에 수행하는 BiSeg 프레임워크를 제안합니다.
- **베이즈 추론 기반 인스턴스 분할:** 의미론적 분할 결과를 사전 확률(prior)로 활용하고, 인스턴스 분할을 베이즈 추론의 사후 확률(posterior)로 예측하는 새로운 방식을 도입합니다.
- **위치 민감 스코어 맵 융합:** FCIS(Fully Convolutional Instance-aware Semantic Segmentation)에서 사용된 위치 민감 스코어 맵(position-sensitive score maps) 개념을 확장하여, 다양한 스케일과 파티션 모드에서 생성된 여러 스코어 맵을 융합함으로써 견고한 우도(likelihood)를 구성합니다.
- **완전 컨볼루션 엔드-투-엔드 솔루션:** BiSeg는 완전 컨볼루션 기반의 엔드-투-엔드(end-to-end) 솔루션으로, FCN의 모든 장점을 계승하며 픽셀 단위로 베이즈 추론 및 맵 융합을 수행합니다.
- **최첨단 성능 달성:** PASCAL VOC 데이터셋에서 인스턴스 분할 정확도에서 최첨단 성능을 달성했으며, 특히 mAP{$_r$}@0.5에서 67.3%, mAP{$_r$}@0.7에서 54.4%를 기록하여 FCIS 대비 약 2% 가까이 높은 성능을 보였습니다.
- **의미론적 분할의 인스턴스 분할 개선 효과 입증:** 의미론적 분할 정보가 인스턴스 분할 성능을 크게 향상시킬 수 있음을 입증했습니다.

## 📎 Related Works

- **초기 인스턴스 분할 연구:** DeepMask [27], SharpMask [28], Instance FCN [8]과 같은 초기 방법들은 마스크 제안을 위해 외부 모듈 [1, 33]을 사용하거나 클래스 인식 없이 마스크를 생성한 후 별도의 네트워크에서 분류를 수행해야 했습니다.
- **엔드-투-엔드 솔루션:** Multi-task Network Cascade (MNC) [9]는 박스 제안, 마스크 회귀, 인스턴스 분류의 3단계로 구성된 엔드-투-엔드 솔루션을 제안했습니다.
- **FCIS (Fully Convolutional Instance-aware Semantic Segmentation):** [8]의 위치 민감 스코어 맵 아이디어를 확장한 완전 컨볼루션 방식의 엔드-투-엔드 솔루션 [20]입니다. 마스크 예측과 분류를 위한 컨볼루션 표현 및 스코어 맵을 공유합니다.
- **의미론적 분할과의 결합:** Faster R-CNN [29]에 보조 작업으로 분할을 추가하여 영역 제안 생성을 유도한 연구 [31]가 있습니다.
- **기반 기술:**
  - **FCN [24]:** 픽셀별 확률을 나타내는 스코어 맵을 예측하는 의미론적 분할에 사용됩니다.
  - **위치 민감 스코어 맵:** Instance FCN [8]에서 도입되어 객체의 상대적 공간 위치 정보를 인코딩하는 데 사용됩니다.
  - **ResNet [18]:** 특징 추출을 위한 컨볼루션 백본 아키텍처로 활용됩니다.
  - **Region Proposal Networks (RPN) [29]:** 관심 영역(ROI)을 생성하는 데 사용됩니다.
  - **Fast R-CNN [13]:** 다중 작업 손실(multi-task loss) 정의 및 ROI 처리에 참고됩니다.
  - **"Hole algorithm" (Atrous Convolution) [4]:** 특징 맵의 스트라이드(stride)를 줄이는 데 사용됩니다.

## 🛠️ Methodology

BiSeg는 여러 서브 네트워크가 컨볼루션 특징을 공유하는 완전 컨볼루션 엔드-투-엔드 프레임워크입니다.

1. **네트워크 아키텍처:**

   - **백본:** ResNet-101 [18]을 사용하여 특징을 추출하고, 1x1 컨볼루션 레이어를 추가하여 특징 맵의 차원을 2048에서 1024로 줄입니다.
   - **스트라이드 감소:** `conv5` 레이어의 특징 스트라이드를 "hole algorithm" [4]을 사용하여 32에서 16으로 줄입니다.
   - **서브 네트워크:**
     - **RPN 서브 네트워크 [29]:** `conv4` 레이어 위에 추가되어 ROI를 생성합니다.
     - **바운딩 박스 회귀 서브 네트워크 [13]:** 초기 ROI를 정제하여 더 정확한 탐지 결과를 얻습니다.
     - **의미론적 분할 서브 네트워크:** `conv5` 특징 맵 위에 FCN [24] 기반으로 구축되며, $C+1$개의 클래스에 대한 픽셀별 분할 확률을 나타내는 스코어 맵 $S$를 생성합니다. (단순화를 위해 CRF 등은 사용하지 않음)
     - **인스턴스 분할 서브 네트워크:** 각 ROI에 대한 인스턴스 분할 우도 $L$을 추론합니다.

2. **위치 민감 스코어 맵 융합:**

   - 인스턴스 분할 서브 네트워크에서 다양한 스케일과 파티션 모드를 가진 여러 스코어 맵을 융합합니다.
   - 두 세트의 위치 민감 스코어 맵을 생성합니다:
     - 첫 번째 세트: `conv5` 레이어에서 $2k_1^2 \times (C+1)$ 스코어 맵 ($k_1=7$ 기본).
     - 두 번째 세트: `conv3` 레이어에서 $2k_2^2 \times (C+1)$ 스코어 맵 (`conv5` 맵보다 2배 큼, $k_2=9$ 기본).
   - 각 ROI에 대해, 이 두 세트의 스코어 맵에서 어셈블리(assembling) 작업을 수행하여 두 세트의 $2(C+1)$ ROI 우도 맵을 생성합니다 (내부/외부).
   - 첫 번째 ROI 우도 맵 세트를 x2 업샘플링한 후 두 번째 세트와 합산하여 최종 우도 맵을 얻습니다.

3. **베이즈 추론:**

   - 각 ROI에 대한 인스턴스 분할 확률 $I$를 계산합니다.
   - **사전 확률(Prior):** $C+1$개의 의미론적 분할 스코어 맵 $S$에서 ROI 사각형을 잘라내어 ROI 의미론적 분할 확률 맵(사전 확률 $P(c|X)$)을 만듭니다.
   - **우도(Likelihood):** 융합된 위치 민감 스코어 맵에서 얻은 ROI 내부(inside) 우도 맵($P(I_{ck}|c,X)$)을 사용합니다.
   - **사후 확률(Posterior):** ROI 의미론적 분할 확률 맵과 ROI 내부 우도 맵을 원소별(element-wise) 곱셈하여 ROI 내부 확률 맵($P(I_{ck}|X) = P(I_{ck}|c,X)P(c|X)$)을 예측합니다.
   - ROI 외부(outside) 확률 맵은 ROI 외부 우도 맵과 동일합니다 (외부 확률 예측에 대한 사전 확률 없음).
   - 최종적으로 내부/외부 확률 맵에 소프트맥스(softmax) 연산을 적용하여 전경(foreground) 확률을 생성하고, 최대(max) 연산을 통해 픽셀별 객체 카테고리 우도를 얻은 후 평균 풀링(average pooling)으로 분류 점수를 추론합니다.

4. **학습 (Training):**

   - 다중 작업 손실 $L = L_{rpn} + L_{ss} + L_{cls} + L_{mask} + L_{bbox}$를 사용합니다.
     - $L_{rpn}$: Faster R-CNN [29]과 동일.
     - $L_{ss}$: 픽셀별 다항 교차 엔트로피 손실.
     - $L_{cls}$: $C+1$개 카테고리에 대한 소프트맥스 분류 손실.
     - $L_{mask}$: 전경 마스크에 대한 이진 교차 엔트로피 손실 (긍정 ROI에만 적용).
     - $L_{bbox}$: 바운딩 박스 회귀 손실 (긍정 ROI에만 적용).
   - ImageNet으로 사전 학습된 ResNet-101 모델을 사용합니다.
   - 이미지 중심 학습(image-centric training) 방식을 사용하며, 공유 컨볼루션 레이어와 $L_{ss}$는 전체 이미지에 대해 계산되고, 다른 손실은 샘플링된 ROI에 대해 계산됩니다.
   - SGD 최적화를 사용합니다.

5. **추론 (Inference):**
   - RPN에서 300개의 ROI를 생성하고, 바운딩 박스 회귀 및 비최대 억제(NMS)를 적용합니다.
   - 남은 ROI는 가장 높은 분류 점수를 가진 카테고리로 분류됩니다.
   - 마스크 투표(mask voting) 방식 [9]을 사용하여, 각 ROI에 대해 IoU $\ge 0.5$로 겹치는 주변 인스턴스의 전경 마스크를 분류 점수에 따라 가중 평균하여 최종 마스크를 형성합니다.

## 📊 Results

- **데이터셋:** PASCAL VOC 2012 데이터셋 (훈련: train set, 평가: validation set)
- **평가 지표:** mean Average Precision over regions (mAP{$_r$}) [16] (IoU 임계값 0.5 및 0.7)
- **주요 결과:**
  - **BiSeg (fused PS score map):** mAP{$_r$}@0.5에서 67.3%, mAP{$_r$}@0.7에서 54.4%를 달성하여 최첨단 성능을 기록했습니다. 이는 기존 FCIS [20] 대비 약 2% 높은 수치입니다.
- **기존 방법 및 베이스라인 비교:**
  - FCIS\* (본 논문 구현): mAP{$_r$}@0.5 64.2%, mAP{$_r$}@0.7 48.6%.
  - Naive Multi-task (베이즈 결합 없는 다중 작업): mAP{$_r$}@0.5 65.2%, mAP{$_r$}@0.7 49.6%.
  - BiSeg (single PS score map, 융합 없음): mAP{$_r$}@0.5 66.4%, mAP{$_r$}@0.7 50.5%. 이는 naive Multi-task보다 약 1% 높으며, 의미론적 분할 강화를 통한 인스턴스 분할 개선의 효과를 입증합니다.
- **위치 민감 스코어 맵 융합 효과:**
  - BiSeg (single PS score map) 대비 BiSeg (fused PS score map)는 mAP{$_r$}@0.7에서 4%p 향상을 보이며 제안된 맵 융합 방식의 중요성을 입증했습니다.
  - 다양한 파티션 모드 $(k_1, k_2)$ 조합 실험 결과, $(7,9)$ 조합이 $(7,7)$이나 $(7,11)$보다 더 효과적이었습니다.
- **의미론적 분할 성능:**
  - BiSeg는 평균 정확도 70.2%, mean IU 60.8%를 기록하며 naive Multi-task(평균 정확도 69.0%, mean IU 59.5%)를 능가하여 두 분할 작업의 결합 중요성을 다시 한번 확인했습니다.
- **정성적 결과:** CRF를 사용하지 않고도 경계선에서 높은 분할 품질을 보여주며, 심하게 가려진(occluded) 객체에 대해서도 좋은 인스턴스 분할 결과를 확인했습니다.

## 🧠 Insights & Discussion

- **시너지 효과:** 의미론적 분할을 베이즈 추론의 사전 확률로 사용하는 것이 인스턴스 분할을 크게 향상시킬 수 있다는 것이 핵심 통찰입니다. 두 작업 간의 강한 상관관계가 이러한 시너지 효과를 가져옵니다.
- **견고성 및 정확도 향상:** 다양한 스케일과 파티션 모드에서 위치 민감 스코어 맵을 융합하는 방식은 인스턴스 분할의 견고성과 정확도를 크게 높이는 데 기여합니다. 특히 미세한 디테일과 전역적 맥락을 동시에 활용할 수 있게 합니다.
- **FCN의 장점 활용:** BiSeg는 완전 컨볼루션 엔드-투-엔드 솔루션으로서 FCN의 모든 장점을 계승합니다. 이는 효율적인 학습과 추론, 그리고 유연한 입력 크기 처리 능력을 포함합니다.
- **"Stuff" 카테고리 처리:** 의미론적 분할은 '하늘', '잔디', '물'과 같이 인스턴스로 구분하기 어려운 "stuff" 카테고리를 처리할 수 있다는 장점이 있습니다. 인스턴스 분할이 객체에 집중하는 반면, 의미론적 분할은 배경 맥락을 제공하여 더욱 견고한 이미지 인식 시스템 구축에 기여합니다.
- **한계점 및 향후 연구:**
  - 의미론적 분할 품질 향상(예: CRF 사용)이 인스턴스 분할 성능에 미치는 영향은 향후 연구 주제로 남겨져 있습니다.
  - 깊이 맵(depth maps)과 같은 다른 맥락 사전 확률이나 인간 자세(human pose)와 같은 인스턴스 인식 우도를 탐색할 계획입니다.
  - 이 접근 방식은 혼잡한 장면에서 객체 수를 세는 문제와 같은 다른 컴퓨터 비전 응용 분야에도 적용될 수 있습니다.

## 📌 TL;DR

**문제:** 픽셀 단위로 객체를 감지하고 개별 인스턴스를 구분하는 인스턴스 분할은 정확한 객체 탐지와 정밀한 분할을 동시에 요구하는 어려운 문제입니다. 기존 엔드-투-엔드 방식들은 성능 개선의 여지가 있었습니다.

**제안 방법:** BiSeg는 의미론적 분할과 인스턴스 분할을 동시에 수행하는 완전 컨볼루션 엔드-투-엔드 프레임워크입니다. 이 방법은 의미론적 분할 결과를 베이즈 추론의 사전 확률(prior)로 사용하여 인스턴스 분할을 예측하고, 다양한 스케일과 파티션 모드에서 생성된 위치 민감 스코어 맵을 융합하여 견고한 우도(likelihood)를 구성합니다.

**주요 발견:** PASCAL VOC 데이터셋에서 mAP{$_r$}@0.5 67.3%라는 최첨단 인스턴스 분할 성능을 달성하여 기존 FCIS보다 약 2%p 높은 결과를 보였습니다. 이는 베이즈 추론을 통한 의미론적 분할의 통합과 스코어 맵 융합 방식의 효과를 명확히 입증합니다.
