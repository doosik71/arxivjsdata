{
  "url": "http://arxiv.org/abs/1909.12996v1",
  "title": "Distributed Iterative Gating Networks for Semantic Segmentation",
  "authors": "Rezaul Karim, Md Amirul Islam, Neil D. B. Bruce",
  "year": 2019,
  "abstract": "In this paper, we present a canonical structure for controlling information\nflow in neural networks with an efficient feedback routing mechanism based on a\nstrategy of Distributed Iterative Gating (DIGNet). The structure of this\nmechanism derives from a strong conceptual foundation and presents a\nlight-weight mechanism for adaptive control of computation similar to recurrent\nconvolutional neural networks by integrating feedback signals with a\nfeed-forward architecture. In contrast to other RNN formulations, DIGNet\ngenerates feedback signals in a cascaded manner that implicitly carries\ninformation from all the layers above. This cascaded feedback propagation by\nmeans of the propagator gates is found to be more effective compared to other\nfeedback mechanisms that use feedback from the output of either the\ncorresponding stage or from the previous stage. Experiments reveal the high\ndegree of capability that this recurrent approach with cascaded feedback\npresents over feed-forward baselines and other recurrent models for pixel-wise\nlabeling problems on three challenging datasets, PASCAL VOC 2012, COCO-Stuff,\nand ADE20K."
}