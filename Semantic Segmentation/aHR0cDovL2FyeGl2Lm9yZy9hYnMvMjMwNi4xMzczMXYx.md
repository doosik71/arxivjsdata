# 의료 영상에 대규모 분할 모델(SAM)을 효율적으로 적용하는 방법

Xinrong Hu, Xiaowei Xu, Yiyu Shi

## 🧩 해결하려는 문제

대규모 분할 모델인 SAM(Segment Anything Model)은 자연 이미지에 대해 인상적인 제로-샷 분할 능력을 보여주지만, 의료 영상에 적용할 경우 성능 저하가 뚜렷하게 나타납니다. 이러한 성능 저하는 주로 다음과 같은 요인에 기인합니다:

1. **도메인 차이**: 자연 영상과 의료 영상(CT, MRI, 초음파 등)은 색상, 밝기, 대비 측면에서 큰 차이를 보이며, 의료 영상은 종종 경계가 모호합니다.
2. **프롬프트 기반의 한계**: SAM은 프롬프트(점, 박스 등)를 필요로 하는데, 여러 클래스에 대한 정밀한 프롬프트는 시간 소모적이며, 프롬프트의 품질에 따라 분할 성능이 크게 좌우되어 실제 의료 애플리케이션에 적용하기 어렵습니다.

따라서 이 연구는 SAM을 의료 영상 데이터셋에 효율적으로 맞춤화하고, 프롬프트 없이도 다중 클래스 분할을 수행할 수 있는 방법을 찾는 것을 목표로 합니다.

## ✨ 주요 기여

- **효율적인 미세 조정 전략 제안**: SAM 인코더의 가중치를 고정하고 경량의 작업별 예측 헤드(prediction head)만 미세 조정하는 방법을 제안합니다. 이는 SAM 모델 가중치의 대부분이 인코더에 집중되어 있기 때문에 효율적입니다.
- **세 가지 프롬프트-없는 예측 헤드 탐구**: ViT, CNN, 선형(Linear) 레이어 기반의 세 가지 유형의 프롬프트-없는(prompt-free) 예측 헤드를 탐색합니다.
- **AutoSAM 제안**: 기존 SAM 마스크 디코더에서 프롬프트 토큰을 제거하고, 보조 임베딩 및 이미지 임베딩을 복제하여 단일 추론으로 여러 클래스에 대한 마스크를 생성할 수 있도록 수정된 ViT 기반의 예측 헤드인 AutoSAM을 개발합니다.
- **레이블 효율성 입증**: 제한된 레이블 데이터(1개 또는 5개의 레이블된 볼륨)만으로도 미세 조정된 SAM이 기존의 제로-샷 SAM, 스크래치 학습, 자가 지도 학습 방식보다 훨씬 뛰어난 성능을 보임을 입증합니다.

## 📎 관련 연구

- **대규모 비전 모델**: CLIP [21], ALIGN [14], DALL-E [22], DINOv2 [19], SAM [16]과 같이 대규모 데이터셋으로 사전 학습되어 다양한 비전 태스크에 일반화 능력을 보이는 모델들이 언급됩니다. 특히 SAM은 대규모 프롬프트 기반 분할 모델로 소개됩니다.
- **의료 영상에 대규모 모델 맞춤화**:
  - **MedSAM [18]**: 30개 이상의 의료 영상 데이터셋에 SAM 디코더를 미세 조정하여 제로-샷 예측 대비 성능 향상을 보였습니다.
  - **Kaidong Zhang et al. [28]**: 저랭크 기반 미세 조정 전략을 SAN 인코더에 적용하고 SAM 디코더와 함께 학습하여 복부 분할 태스크에 맞춤화했습니다.
  - **Junde Wu et al. [25]**: SAM 모델의 가중치를 고정하고 학습 가능한 적응 모듈을 추가하여 재학습 비용을 줄였습니다.

## 🛠️ 방법론

이 연구는 SAM의 이미지 인코더 가중치를 고정하고, 그 위에 새로운 프롬프트-없는 예측 헤드를 추가하여 의료 영상 데이터셋에 미세 조정하는 방법을 제안합니다.

1. **SAM 구조 배경**:

   - **이미지 인코더**: Vision Transformer (ViT) [8] 아키텍처를 가지며, MAE [10]로 SAM-1B 데이터셋에 사전 학습되었습니다. ViT-h, ViT-l, ViT-b 세 가지 크기 옵션이 있습니다. 입력 이미지를 1024x1024로 재구성한 후, 16x16 패치 임베딩으로 변환하여 (64x64, 256) 차원의 출력을 생성합니다.
   - **프롬프트 인코더**: 점, 박스, 텍스트와 같은 희소 프롬프트(sparse prompts)와 마스크와 같은 밀집 프롬프트(dense prompts)를 처리합니다.
   - **마스크 디코더**: 투-웨이 어텐션(two-way attention) 모듈을 사용하여 이미지 임베딩과 프롬프트/출력 토큰을 처리하고, 전치 합성곱 레이어(transposed convolutional layers)로 이미지 임베딩을 업샘플링하여 최종 마스크를 생성합니다.

2. **예측 헤드 설계**: SAM 인코더의 출력인 이미지 임베딩만 입력으로 받는 프롬프트-없는 예측 헤드를 설계합니다.

   - **Vision Transformer (AutoSAM)**:
     - SAM 마스크 디코더를 경량으로 수정합니다.
     - **프롬프트 토큰 제거**: 보조 임베딩(auxiliary embeddings)에서 프롬프트 토큰을 제거하여 프롬프트가 필요 없습니다.
     - **다중 클래스 분할**: 보조 임베딩과 이미지 임베딩 쌍을 클래스 수만큼 복제하여 여러 클래스에 대한 마스크를 동시에 생성합니다. 각 쌍은 병렬로 계산되어 오버헤드가 적습니다.
   - **Convolutional Neural Network (CNN)**:
     - 이미지 임베딩을 (256, 64, 64) 크기의 특징 맵으로 재구성합니다.
     - U-Net [23] 구조를 따르며, $k$개($k \ge 2$)의 스테이지로 구성됩니다. 각 스테이지는 스트라이드가 1인 합성곱 레이어와 스트라이드가 2인 전치 합성곱 레이어를 포함하여 특징 맵을 업스케일합니다.
     - 마지막에 1x1 커널의 합성곱 레이어를 적용하여 각 클래스에 대한 예측 마스크를 생성합니다.
   - **Linear Layer**:
     - 이미지 임베딩을 2D 특징 맵으로 재구성합니다.
     - 두 개의 전치 합성곱 레이어와 두 개의 1x1 커널 합성곱 레이어를 사용하여 픽셀별 분류를 수행합니다.

3. **데이터셋**:

   - **ACDC (Automated Cardiac Diagnosis Challenge) [2]**: 100명의 환자로부터 얻은 심장 MRI 스캔 데이터셋으로, 좌심실(LV), 우심실(RV), 심근(Myo)의 전문가 분할 마스크를 포함합니다.
   - 데이터 분할: 환자 기반으로 학습, 검증, 테스트 세트를 70:15:15 비율로 나눕니다.
   - 전처리: 각 볼륨을 평균 0, 단위 분산으로 정규화하고, 픽셀 값을 RGB 형식으로 변환하여 각 슬라이스를 PNG 파일로 저장합니다. 분할은 2D 이미지 단위로 수행됩니다.
   - 평가 지표: Dice Score와 평균 대칭 표면 거리(ASSD)를 사용합니다.

4. **학습 설정**:

   - 프레임워크: PyTorch
   - GPU: NVIDIA Tesla V100 (16GB)
   - 데이터 증강: 가우시안 노이즈, 밝기 수정, 탄성 변형, 회전 등을 무작위로 적용합니다.
   - 손실 함수: Cross-Entropy 손실과 Dice 손실의 조합.
   - 최적화: Adam [15] 옵티마이저. 학습률은 0.0005. 배치 크기는 GPU당 4.
   - 학습 에폭: 120 에폭.

5. **비교 대상 (Baselines)**:
   - 스크래치부터 학습된 UNet.
   - 자가 지도 학습 (Self-supervised learning) 방법인 UNet + SimCLR [7].
   - 어떠한 미세 조정도 거치지 않은 원본 SAM (제로-샷, 박스 프롬프트 사용).

## 📊 결과

- **레이블 효율적 적응 (Table 1)**:
  - **AutoSAM과 CNN 헤드의 우수성**: 1개의 레이블된 볼륨만으로도 AutoSAM과 CNN 헤드는 모든 다른 방법들(UNet, SimCLR, 원본 SAM)보다 훨씬 뛰어난 분할 정확도를 보였습니다. 특히 AutoSAM의 평균 Dice 점수는 39.32로 UNet의 약 두 배였습니다. 이는 SAM 인코더가 학습한 특징이 의료 영상에도 잘 전이됨을 시사합니다.
  - **SAM(제로-샷)의 한계**: 미세 조정된 AutoSAM 및 CNN 인코더보다 성능이 저조했습니다. 다만, 박스 프롬프트가 제공하는 지역화 정보 덕분에 ASSD는 낮았습니다. LV 분할에서 Dice 점수가 0으로 나타나는 등 특정 클래스에서 오분할 경향을 보였습니다.
  - **선형 예측 헤드의 저조한 성능**: 매우 경량의 아키텍처로 인해 의료 영상에 대한 풍부한 의미론적 정보가 부족하여 언더피팅(underfitting)을 겪었습니다.
- **Ablation Study (Table 2, Table 3)**:
  - **CNN 예측 헤드의 깊이**: CNN 헤드의 깊이가 4일 때 가장 좋은 Dice 점수를 보였습니다. 너무 얕은 모델은 언더피팅, 너무 깊은 모델은 성능 향상에 한계가 있었습니다.
  - **인코더 크기**: 일반적으로 인코더 크기가 클수록 미세 조정 결과가 좋았습니다 (vit-b < vit-l < vit-h). AutoSAM은 인코더 크기에 덜 민감한 반면, CNN 헤드는 더 큰 인코더에서 더 큰 성능 향상을 보였습니다.
- **레이블된 데이터 양에 따른 변화 (Fig. 5)**:
  - AutoSAM은 레이블된 볼륨 수가 10개 미만일 때 UNet 또는 SimCLR보다 우위를 가졌습니다.
  - 레이블된 데이터가 10개를 초과할 경우, AutoSAM의 이점은 줄어들었습니다. 이는 SAM이 자연 영상에 사전 학습되었기 때문에, 충분한 의료 데이터가 주어질 경우 오히려 편향된 정보가 될 수 있음을 시사합니다.

## 🧠 통찰 & 논의

이 연구는 SAM을 의료 영상에 적용하는 효율적인 방법을 제시했습니다. SAM 인코더를 고정하고 경량의 예측 헤드를 미세 조정하는 전략은 매우 레이블 효율적이며, 제한된 데이터 상황에서 기존 방법들을 크게 능가했습니다. 특히, 프롬프트-없는 AutoSAM은 단일 추론으로 다중 클래스 분할을 가능하게 하여 실제 임상 적용 가능성을 높였습니다.

SAM의 사전 학습된 인코더는 의료 영상에 전이될 수 있는 일반적인 특징을 추출하지만, 의료 영상 도메인에 특화된 풍부한 의미론적 정보는 부족할 수 있습니다. 이것이 레이블 데이터가 풍부할수록 SAM 기반 접근법의 상대적 이점이 줄어드는 이유입니다. 이는 진정한 "파운데이션 모델"이 되기 위해서는 미래에 대규모 의료 영상 데이터셋을 이용한 SAM의 사전 학습이 필요함을 시사합니다.

제한점으로는, 단일 데이터셋(ACDC)에 대한 평가이며, 예측 헤드의 아키텍처 복잡성에 대한 추가 탐색이 필요합니다.

## 📌 TL;DR

이 연구는 SAM(Segment Anything Model)이 의료 영상에서 성능이 저하되고 프롬프트 의존적이라는 문제를 해결하고자 합니다. 이를 위해 SAM 인코더를 고정하고 경량의 **프롬프트-없는 예측 헤드**를 미세 조정하는 방법을 제안합니다. 특히, 기존 SAM 마스크 디코더를 수정하여 프롬프트 없이 다중 클래스 분할이 가능한 **AutoSAM**을 개발했습니다. ACDC 데이터셋을 이용한 실험에서, **1개**의 레이블된 볼륨만으로도 AutoSAM과 CNN 기반 예측 헤드가 스크래치 학습된 UNet이나 자가 지도 학습보다 **두 배 가까이 높은 Dice 점수**를 달성하며 뛰어난 레이블 효율성을 입증했습니다. 그러나 레이블된 데이터가 충분할 경우, SAM의 자연 영상 기반 사전 학습 지식이 의료 영상 도메인에 편향된 영향을 미 미칠 수 있음을 보여주며, 향후 대규모 의료 영상 데이터셋으로의 사전 학습 필요성을 제기합니다.
