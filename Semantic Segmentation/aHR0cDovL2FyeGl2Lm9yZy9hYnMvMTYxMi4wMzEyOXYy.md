# Boundary-aware Instance Segmentation

Zeeshan Hayder, Xuming He, Mathieu Salzmann

## 🧩 Problem to Solve

기존 인스턴스 수준 시맨틱 분할(instance-level semantic segmentation) 방법들은 일반적으로 바운딩 박스(bounding box) 형태의 객체 후보를 제안한 후, 이 후보 박스 *내부*에서 이진 마스크를 예측합니다. 이러한 접근 방식은 객체 후보 생성 과정(예: 박스가 너무 작거나 위치가 벗어나는 경우)의 오류에 매우 민감하며, 일단 생성된 박스의 범위를 넘어선 마스크를 예측할 수 없어 부정확한 박스로 인한 오류를 복구하기 어렵다는 한계가 있습니다.

## ✨ Key Contributions

* **경계 인식 객체 마스크 표현**: 객체 마스크의 거리 변환(distance transform)에 기반한 새로운 객체 세그먼트 표현을 도입하여, 바운딩 박스의 공간적 범위를 넘어설 수 있는 마스크 예측을 가능하게 했습니다.
* **OMN (Object Mask Network) 설계**: 제안된 거리 변환 표현을 추론하고 최종 이진 객체 마스크로 디코딩하는 새로운 잔차-역합성곱(residual-deconvolution) 아키텍처를 가진 OMN을 개발했습니다. 이는 완전히 미분 가능(fully differentiable)합니다.
* **BAIS (Boundary-aware Instance Segmentation) 프레임워크**: OMN을 Multitask Network Cascade (MNC) 프레임워크에 통합하여, 부정확한 객체 제안에 강건한 경계 인식 인스턴스 분할 네트워크를 종단 간(end-to-end) 방식으로 학습할 수 있도록 했습니다.
* **최고 성능 달성**: PASCAL VOC 2012 및 Cityscapes 데이터셋에서 기존 최첨단 인스턴스 분할 및 객체 제안 생성 방법들보다 우수한 성능을 입증했으며, 특히 높은 IoU 임계값에서 상당한 개선을 보였습니다.

## 📎 Related Works

* **카테고리 수준 시맨틱 분할**: Deep CNN 이후 FCN [10, 24, 4] 등 많은 발전이 있었습니다.
* **인스턴스 수준 시맨틱 분할**:
  * **객체 제안 기반**: 대부분의 기존 방법(Fast-RCNN [11] 기반 [14], Hypercolumn [15], InstanceFCN [21], MNC [8])은 바운딩 박스 내에서 마스크를 예측하며 박스 품질에 민감합니다.
  * **객체 제안 우회**: Proposal-free Network (PFN) [22], 깊이 순서 기반 [36, 35], FCN 기반 깊이/의미/방향 인코딩 [33] 등의 방법들이 제안되었으나, 최적화 문제나 특정 가정에 의존하는 경향이 있습니다. Recurrent Neural Network [29]는 단일 클래스 인스턴스를 가정합니다.
* **클래스 불가지론적 영역 제안**: Selective Search [34], MCG [1], DeepMask [25], SharpMask [26], InstanceFCN [6] 등이 있으며, 본 연구의 OMN 또한 이러한 객체 제안 품질을 평가하는 데 사용될 수 있습니다.

## 🛠️ Methodology

본 논문은 초기 바운딩 박스 제안의 부정확성에 강건한 인스턴스 수준 시맨틱 분할을 위해 새로운 객체 마스크 표현과 이를 활용하는 OMN을 제안합니다.

1. **경계 인식 마스크 표현 (Boundary-aware Mask Representation)**
    * **거리 변환 기반**: 각 픽셀 $p$에 대해 객체 경계 $Q$까지의 (잘린) 최소 거리 $D(p)$를 인코딩하는 조밀한 다중 값 맵을 구성합니다.
        $$D(p) = \min \left( \min_{\forall q \in Q} \lceil d(p, q) \rceil, R \right)$$
        여기서 $d(p, q)$는 픽셀 $p$와 $q$ 사이의 유클리드 거리이며, $R$은 절단 임계값입니다.
    * **양자화 및 이진 벡터 인코딩**: 거리 값을 $K$개의 균일한 bin으로 양자화하고, 각 픽셀 $p$의 잘린 거리를 $K$차원 이진 벡터 $b(p)$로 원-핫 인코딩(one-hot encoding)합니다. 이는 다중 값 맵 예측을 $K$개의 픽셀별 이진 분류 문제로 변환합니다.
        $$D(p) = \sum_{n=1}^{K} r_n \cdot b_n(p), \quad \sum_{n=1}^{K} b_n(p) = 1$$
    * **역 거리 변환을 통한 마스크 복구**: 각 픽셀에 반경 $D(p)$의 이진 디스크 $T(p, D(p))$를 연관시키고, 모든 디스크의 합집합으로 최종 객체 마스크 $M$을 생성합니다. 이 과정은 일련의 합성곱(convolution) 연산으로 표현될 수 있습니다.
        $$M = \bigcup_{p} T(p, D(p)) = \bigcup_{n=1}^{K} T(\cdot, r_n) * B_n$$
        여기서 $B_n$은 $n$-번째 bin에 대한 이진 픽셀 맵입니다.

2. **객체 마스크 네트워크 (Object Mask Network, OMN)**
    * **모듈 1: $K$개의 이진 맵 예측**: RPN [28]에서 생성된 바운딩 박스 제안에 대한 RoI 워핑된 특징을 입력으로 받아, 시그모이드 활성화 함수를 가진 완전 연결(fully connected) 레이어를 통해 $K$개의 픽셀별 확률 맵을 예측합니다.
    * **모듈 2: 잔차 역합성곱 네트워크를 통한 디코딩**: 예측된 $K$개의 확률 맵을 입력으로 받아 이진 객체 마스크로 디코딩합니다. 수식 (3)의 형태학적(morphology) 연산이 고정된 가중치를 가진 역합성곱(deconvolution)의 시리즈로 구현될 수 있다는 관찰에 기반하며, 합집합 연산은 가중치 합산(weighted summation) 레이어와 시그모이드 활성화 함수로 근사합니다. 이 네트워크는 완전히 미분 가능하여 종단 간 학습이 가능합니다.

3. **BAIS (Boundary-Aware Instance Segmentation) 네트워크 학습**
    * **MNC (Multistage Network Cascade) 프레임워크 통합**: OMN을 MNC [8] 프레임워크에 통합하여 BAIS 네트워크를 구성합니다.
    * **네트워크 구조**: VGG16 [31] 기반의 특징 추출, RPN [28]을 통한 바운딩 박스 제안, OMN을 통한 마스크 예측, 그리고 분류 모듈로 구성됩니다. 초기 3단계 캐스케이드를 5단계로 확장하여, 3단계의 바운딩 박스 회귀 오프셋을 사용하여 바운딩 박스를 정제한 후 이를 4단계 OMN의 입력으로 사용하고, 5단계에서 다시 분류에 활용합니다. 두 OMN과 분류 모듈의 가중치는 공유됩니다.
    * **종단 간 학습**: 바운딩 박스, 객체 마스크, 분류 오류를 고려하는 다중 작업 손실 함수를 사용하여 SGD(Stochastic Gradient Descent)로 종단 간 학습합니다. (RPN 및 분류에 소프트맥스 손실, OMN에 이진 교차 엔트로피 손실, 바운딩 박스 회귀에 smooth L$_1$ 손실).

## 📊 Results

* **PASCAL VOC 2012 데이터셋**:
  * 인스턴스 분할에서 기존 최첨단 방법들을 능가하는 성능을 달성했으며, 특히 높은 IoU 임계값($0.7$)에서 상당한 성능 향상을 보였습니다 (예: MNC의 $41.5$ mAP 대비 BAIS의 $48.30$ mAP).
  * 마스크가 바운딩 박스 범위를 넘어설 수 있도록 허용하는 것의 중요성을 `BAIS - insideBBox`($44.58$ mAP@$0.7$)와의 비교를 통해 명확히 입증했습니다.
  * OMN은 객체 제안 생성(segment proposal generation) 태스크에서도 AR@100에서 DeepMask [25], SharpMask [26]와 같은 최첨단 방법들과 동등하거나 더 우수한 성능을 보여주었습니다.
* **Cityscapes 데이터셋**:
  * 모든 메트릭에서 기존 최첨단 방법(DWT [2])보다 훨씬 우수한 성능을 달성했습니다 (예: DWT의 $15.6$ AP 대비 BAIS의 $17.4$ AP, DWT의 $30.0$ AP(50%) 대비 BAIS의 $36.7$ AP(50%)).
  * 정성적 결과는 복잡한 도시 환경 이미지에서 다수의 인스턴스가 존재함에도 불구하고 상세하고 정확한 분할을 보여주었습니다.

## 🧠 Insights & Discussion

* **문제 해결의 핵심**: 본 논문의 핵심 통찰은 바운딩 박스 제안의 부정확성이라는 기존 인스턴스 분할 방법의 주요 한계를 극복하는 것입니다. 거리 변환 기반의 객체 마스크 표현은 객체의 전체 형태를 경계 정보를 통해 모델링하며, 부분적인 가려짐이나 부정확한 초기 박스에도 불구하고 완전한 마스크를 추론할 수 있게 합니다.
* **OMN의 효과**: 제안된 OMN은 이러한 거리 변환 표현을 효과적으로 학습하고, 특별히 설계된 잔차-역합성곱 아키텍처를 통해 이진 마스크로 디코딩함으로써 바운딩 박스 제안의 한계를 넘어선 마스크 예측을 가능하게 합니다.
* **종단 간 학습의 이점**: OMN이 완전히 미분 가능한 덕분에 전체 BAIS 네트워크를 종단 간 학습할 수 있었으며, 이는 각 구성 요소의 상호 작용을 최적화하여 전체 성능 향상에 크게 기여했습니다.
* **향후 개선 방향**: 현재 VGG16 백본 네트워크를 사용하고 있으나, Residual Network와 같은 더 깊은 아키텍처로 대체함으로써 프레임워크의 정확도를 더욱 향상시킬 수 있는 잠재력을 가지고 있습니다. 일부 실패 사례(하나의 인스턴스가 여러 개로 분할되는 경우)에 대한 개선도 향후 연구 과제로 남아있습니다.

## 📌 TL;DR

기존 인스턴스 분할 방법은 부정확한 바운딩 박스 제안에 취약하고 마스크가 박스 내부에 국한되는 한계가 있었다. 본 논문은 객체 마스크를 경계까지의 거리 변환(distance transform)으로 표현하고, 이를 학습 및 디코딩하기 위해 잔차-역합성곱(residual-deconvolution) 구조의 OMN(Object Mask Network)을 제안한다. OMN을 Multitask Network Cascade에 통합한 BAIS(Boundary-aware Instance Segmentation) 네트워크는 종단 간 학습을 통해 바운딩 박스 범위를 넘어서는 정확한 마스크 예측이 가능하며, PASCAL VOC 2012 및 Cityscapes 데이터셋에서 기존 최첨단 방법들을 크게 능가하는 성능을 달성하여 부정확한 객체 제안에 대한 강력한 강건성을 입증했다.
