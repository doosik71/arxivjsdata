# Learning to Segment Moving Objects in Videos

Katerina Fragkiadaki, Pablo Arbeláez, Panna Felsen, Jitendra Malik

## 🧩 Problem to Solve

이 논문은 비디오에서 움직이는 객체를 효과적으로 분할하는 문제를 다룹니다. 기존 방법들은 다음과 같은 한계를 가집니다:

* **정적 객체 탐지 방법의 한계:** 비디오의 동적 움직임 정보를 충분히 활용하지 못합니다.
* **광학 흐름의 'Bleeding' 문제:** 광학 흐름(optical flow)은 객체 경계와 잘 맞지 않는 'bleeding' 현상으로 인해 직접 분할에 사용하기 어려웠습니다.
* **객체의 다양한 움직임:** 움직이는 객체가 일시적으로 멈추거나, 관절 움직임(articulation), 가려짐(occlusion) 등이 있을 때 분할 성능이 저하됩니다.
* **후보 영역의 효율적 순위 매기기:** 매 프레임마다 수많은 후보 영역(segment proposals)이 생성되는데, 이들 중 실제 움직이는 객체를 포함할 가능성이 높은 후보를 효율적으로 선별하고 순위를 매기는 것이 중요합니다.
* **범용적인 움직이는 객체 개념의 부재:** 기존 비디오 분할 방법은 객체 카테고리에 무관하지만 '움직이는 객체'라는 일반적인 개념을 학습하지 않거나, 특정 객체 클래스에 한정된 추적(tracking) 방법을 사용합니다.

## ✨ Key Contributions

* **움직이는 객체 후보(Moving Object Proposals, MOPs) 생성:** 광학 흐름 경계(optical flow boundaries)에 기반한 다중 분할을 통해 프레임별 MOP를 생성했습니다.
* **Moving Objectness Detector (MOD) 개발:** 프레임별 분할 및 시공간 튜브 후보의 순위를 매기기 위한 '움직이는 객체성' 감지기를 제안했습니다. 이는 이미지와 광학 흐름 필드에 모두 작동하는 듀얼-패스웨이 CNN 기반입니다.
* **시공간 튜브 확장:** 밀집된 점 궤적(dense point trajectories)의 움직임 유사도(motion affinities)에 대한 Random Walker를 사용하여 프레임별 분할을 시공간 궤적 클러스터(spatio-temporal trajectory clusters)로 확장했습니다.
* **최첨단 성능 달성:** 기존 비디오 분할 벤치마크(Moseg, VSB100)에서 어떤 수의 후보에 대해서도 기존 최첨단 방법들을 일관되게 능가하는 성능을 입증했습니다.
* **객체 탐지율 향상:** 제안된 프레임별 MOP가 기존 정적 후보 방법 대비 객체 탐지율을 최대 7% 향상시킴을 보여주었습니다.

## 📎 Related Works

관련 연구는 객체에 대한 정보 가정에 따라 크게 두 가지로 분류됩니다.

* **상향식(Top-down) 추적 방법:** 특정 객체 카테고리 감지기(예: 보행자 또는 자동차 감지기)를 활용하여 관심 영역에 집중하는 방식입니다 (예: [4, 13]).
* **하향식(Bottom-up) 비디오 분할 방법:** 객체 카테고리에 구애받지 않고 픽셀의 색상 및/또는 광학 흐름 유사성을 기반으로 그룹화하는 방식입니다.
  * **슈퍼복셀(Supervoxel) 기반:** 다중 스케일 시공간 분할 맵을 생성합니다 (예: [18, 39]). [12]는 광학 흐름을 사용하여 정적 경계 맵에서 슈퍼픽셀을 시간적으로 스무딩하여 VSB100 데이터셋에서 최신 성능을 달성했습니다.
  * **궤적 클러스터링(Trajectory Clustering) 기반:** 밀집된 점 궤적을 장거리 궤적 움직임 유사성을 사용하여 클러스터링합니다 (예: [6, 28, 32]). 주로 강체(rigid objects) 객체에 우수한 성능을 보이며, [28]은 궤적 클러스터를 픽셀로 매핑하기 위해 다중 스케일 마르코프 랜덤 필드(MRF)를 사용했습니다.
  * **다중 분할 후보(Multiple Segment Proposals) 기반:** 프레임당 여러 분할 후보를 계산하고 외형 유사성을 사용하여 프레임 간 연결하는 방법입니다 (예: [3, 26]). [29]는 높은 흐름 강도를 보이지 않는 이미지 경계를 제거하여 다중 비디오 세그먼트를 생성합니다.

## 🛠️ Methodology

1. **광학 흐름 계산 및 경계 탐지:**
    * 각 비디오 프레임에서 Brox와 Malik [5]의 대변위 광학 흐름(large displacement optical flow)을 계산합니다.
    * 광학 흐름 크기에 Dollár와 Zitnick [8]의 구조화된 숲 경계 탐지기(structured forest boundary detector)를 적용하여 **광학 흐름 경계(optical flow boundaries)**를 추출합니다. 이는 흐름 'bleeding' 문제로 인한 정적 경계와의 불일치를 우회하기 위함입니다.
2. **프레임별 움직이는 객체 후보(MOPs) 생성:**
    * 추출된 광학 흐름 경계를 이용하여 Krähnbühl와 Koltun [22]의 지오데식 객체 후보 방법(geodesic object proposal method)을 통해 다중 전경-배경 분할(figure-ground segmentations)을 수행합니다. 이 과정으로 각 프레임에 대한 MOP 풀을 생성합니다.
3. **Moving Objectness Detector (MOD) 학습:**
    * RGB 이미지와 광학 흐름 필드(스케일링된 $x$, $y$ 변위 및 흐름 크기)에 모두 작동하는 **듀얼-패스웨이 CNN** 아키텍처(그림 3)를 사용하여 MOD를 학습시킵니다.
    * ImageNet 탐지 작업에 대해 사전 학습된 [15]의 가중치로 네트워크를 초기화한 후, VSB100 및 Moseg 벤치마크의 훈련 세트에서 수집된 움직이는 객체 상자와 배경 상자 데이터로 미세 조정합니다.
4. **시공간 튜브 후보 생성:**
    * **밀집된 점 궤적(Dense Point Trajectories) 계산:** 광학 흐름 필드를 연결하여 dense point trajectories를 계산합니다 [36].
    * **궤적 유사도(Trajectory Affinities) 계산:** 궤적 쌍 간의 움직임 유사도를 최대 속도 차이의 함수로 계산하여 $n \times n$ 유사도 행렬 $A$를 생성합니다 [6].
    * **Random Walker 기반 궤적 레이블 전파:** MOP가 탐지된 프레임 $t_i$에서 궤적을 전경 또는 배경으로 초기 레이블링합니다 (그림 4d). 궤적 비정규화 라플라시안 행렬 $L$을 사용하여 Random Walker 비용 함수 $\frac{1}{2}x^T L x$를 최소화하며, 이는 정규화된 유사도 행렬을 이용한 레이블 확산 $x' = \text{Diag}(A1_n)^{-1} Ax$으로 근사화됩니다 (50회 확산).
    * **픽셀 튜브로의 매핑:** 레이블링된 궤적 클러스터를 슈퍼복셀(supervoxels)에 대한 가중 평균을 사용하여 픽셀로 매핑합니다 [12]. 각 슈퍼복셀의 가중치는 궤적 클러스터와의 IoU 점수이며, 임계값 처리를 통해 이진 시공간 분할(픽셀 튜브)을 얻습니다.
5. **최종 튜브 순위 매기기:** MOD를 사용하여 생성된 시공간 튜브를 순위 매깁니다. 튜브의 점수는 해당 튜브의 수명 주기 동안 바운딩 박스 점수의 합으로 정의되며, 이는 더 긴 튜브를 선호하도록 편향시킵니다.

## 📊 Results

* **움직이는 객체 분할 성능:**
  * VSB100 및 Moseg 벤치마크에서 제안된 방법은 모든 수의 튜브 후보에 대해 기존 슈퍼복셀 기반 [12, 39] 및 궤적 클러스터링 기반 [28] 방법보다 높은 Ground-Truth 커버리지를 달성했습니다 (그림 5, 1-2열).
  * 특히, VSB100은 Moseg보다 비강체 객체, 미묘하거나 관절 움직임 등 더 도전적인 장면을 포함하며, 모든 방법에서 성능 차이가 크게 나타났습니다.
* **정적 분할(MOPs의 기여):**
  * MOPs를 정적 지오데식 객체 후보(Geodesic Object Proposals, GOPs) [22]와 결합했을 때, VSB100 벤치마크에서 50% IoU 탐지율 6%, 70% IoU 탐지율 5% 증가를 보였습니다. Moseg에서는 70% IoU 탐지율이 5% 증가했습니다 (표 1).
  * 이는 MOPs와 GOPs가 상호 보완적이며, 기존 GOPs의 포화점 이후에도 성능 향상을 제공함을 입증합니다.
* **후보 순위 매기기(MOD의 성능):**
  * 제안된 듀얼-패스웨이 CNN 회귀기(piCNN-regress)는 프레임별 MOP 및 시공간 튜브 순위 매기기에서 다른 CNN 아키텍처(분류, 이미지 전용, 흐름 전용), 수동 설계된 Center-Surround Saliency [14], 그리고 LSDA [20] 기반 객체성 감지기보다 우수한 성능을 보였습니다 (그림 5, 3-4열).

## 🧠 Insights & Discussion

* **의미:** 제안된 방법은 '움직이는 객체' 개념을 학습하기 위해 훈련 세트를 활용하면서도, 특정 객체 클래스에 구애받지 않고 픽셀 튜브로 객체를 표현함으로써 비디오 분할 및 추적 연구 간의 간극을 메웁니다. 특히 혼잡하고 도전적인 장면에서 MOPs가 정적 후보를 보완하여 움직이는 객체 포착 성능을 크게 향상시킵니다. MOD는 과분할/과소분할 또는 배경 부분을 걸러내어 적은 수의 튜브 후보만으로도 Ground-Truth 객체를 포착할 수 있는 효율적인 순위를 제공합니다.
* **한계:** VSB100 데이터셋에서는 큰 움직임이나 객체의 완전한 가려짐으로 인한 시간적 단편화(temporal fragmentations)가 발생합니다. 유사한 튜브를 연결하는 추가적인 사후 처리 단계가 도움이 될 수 있으나, 현재 방법에서는 고려되지 않았습니다. Moseg 데이터셋에서는 궤적 클러스터를 픽셀 튜브로 부정확하게 매핑하는 경우가 발생하며, 특히 얇은 사지를 가진 동물(예: 낙타)의 경우 배경으로 약간 누출되는 현상이 관찰되었습니다.
* **계산 시간:** 단일 CPU 기준, 광학 흐름 계산은 이미지당 평균 16초, MOP 계산은 700x1000 이미지에서 4초가 소요됩니다. MOP를 궤적 임베딩으로 투영하는 데는 70000개 궤적에 대해 2초가 걸리며, 이는 행렬 확산 연산을 통해 동시에 처리 가능합니다. 슈퍼복셀 계산은 각 프레임에서 7초, 궤적 움직임 유사도 계산은 각 비디오에서 15초가 소요됩니다. 슈퍼복셀, 광학 흐름, MOP 계산 및 투영은 완전히 병렬화 가능합니다.

## 📌 TL;DR

이 논문은 비디오에서 움직이는 객체를 효과적으로 분할하기 위해 '움직이는 객체성(moving objectness)' 개념을 도입합니다. 광학 흐름 경계에서 생성된 프레임별 움직이는 객체 후보(MOPs)는 이미지 및 광학 흐름 정보를 모두 활용하는 듀얼-패스웨이 CNN 기반의 Moving Objectness Detector (MOD)로 순위가 매겨집니다. MOP는 밀집된 점 궤적의 움직임 유사도에 대한 Random Walker를 통해 시공간 튜브로 확장되며, 최종 튜브도 MOD로 다시 순위가 매겨져 최적의 결과를 도출합니다. 제안된 방법은 VSB100 및 Moseg 벤치마크에서 기존 최첨단 비디오 분할 방법을 뛰어넘는 성능을 달성했으며, MOP는 정적 객체 후보와 결합 시 탐지율을 최대 7% 향상시키는 것으로 나타났습니다.
