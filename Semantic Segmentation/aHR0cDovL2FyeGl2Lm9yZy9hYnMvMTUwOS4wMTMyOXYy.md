# Semantic Amodal Segmentation

Yan Zhu, Yuandong Tian, Dimitris Mexatas, and Piotr Dollár

## 🧩 Problem to Solve

기존의 이미지 분류, 객체 탐지, 시맨틱 분할과 같은 시각 인식 작업들이 성숙 단계에 도달하면서, 본 연구는 다음 시각 인식의 개척지가 무엇인지 묻습니다. 특히, 인간이 부분적으로 가려진 객체를 쉽게 인식하고 전체적인 형태를 추론하는 능력(비양상 지각, amodal perception)에 영감을 받아, 눈에 보이는 픽셀을 넘어 장면의 완전한 구조를 파악하고 복잡한 추론을 요구하는 새로운 상세 이미지 주석(annotation) 방식인 '시맨틱 비양상 분할(semantic amodal segmentation)'을 제안하고 이를 위한 데이터셋 구축 및 평가 방법을 모색합니다. 기존의 데이터셋은 주로 가시 영역(modal)만 주석 처리되어 있습니다.

## ✨ Key Contributions

- **새로운 주석 방식 제안:** 눈에 보이는 픽셀뿐만 아니라 객체의 가려진 부분까지 포함하여 전체 영역을 표시하는 '시맨틱 비양상 분할' 주석 방식을 제안합니다. 이는 객체의 의미론적 레이블, 깊이 순서, 형상-배경(figure-ground) 경계 정보 등을 포함합니다.
- **대규모 데이터셋 구축:**
  - **BSDS 데이터셋:** 인간 주석의 통계적 특성을 연구하기 위해 BSDS 이미지 500개에 대해 다수의 주석자를 통해 비양상 분할을 수행했습니다. 이 주석들이 놀라울 정도로 일관성이 있음을 보여주었습니다.
  - **COCO 데이터셋:** 비양상 분할 및 깊이 순서 알고리즘 개발을 위해 COCO 이미지 5,000개에 대한 대규모 비양상 주석을 구축했습니다.
- **새로운 평가 지표 및 강력한 베이스라인:** 비양상 분할 품질과 쌍별(pairwise) 깊이 순서를 측정하기 위한 새로운 평가 지표를 도입하고, 강력한 베이스라인 알고리즘(DeepMask, SharpMask 확장 모델 및 OrderNet)을 제시하여 커뮤니티에 새로운 도전을 제시합니다.

## 📎 Related Works

- **비양상 지각 (Amodal Perception):** 심리물리학 문헌에서 광범위하게 연구되었으나, 대규모 비양상 분할 자연 이미지 데이터셋은 없었습니다.
- **양상 분할 (Modal Segmentation):**
  - **BSDS 데이터셋 [2]:** 엣지 검출 및 분할 알고리즘에 널리 사용되었으며, 나중에 형상-배경 엣지 레이블이 추가되었습니다. 하지만 주석 지침이 불분명하여 일관성이 부족하다는 단점이 있었습니다.
  - **시맨틱 분할 [36, 25, 37]:** 각 픽셀에 고정된 카테고리 레이블을 할당하여 BSDS보다 일관성이 높으나, 개별 객체가 구분되지 않고 주석이 양상(visible portion only) 방식입니다.
  - **StreetScenes [4], PASCAL Context [28]:** 일부 카테고리가 비양상으로 레이블링되거나 큰 카테고리 세트를 사용하는 예외적인 데이터셋입니다.
  - **Hierarchical Scenes [27]:** 폐색(occlusion), 형상-배경 순서, 객체-부분 관계를 포착하는 상세한 주석을 제공하지만, 100개 이미지로 규모가 작습니다.
  - **Visual Genome [21]:** 깊이 순서 등 풍부한 주석을 제공하지만 분할 정보는 포함하지 않습니다.
- **객체 탐지 (Object Detection) [9, 5, 24]:** 본 연구의 주석은 밀집(dense)하고 비양상이며 객체와 영역을 모두 커버합니다. 보행자 탐지 [7]의 경우에만 비양상 경계 상자(bounding box)가 주석으로 사용되는 경우가 있습니다.
- **비양상 완성 (Amodal Completion) 알고리즘 연구 [14, 15, 38, 19]:** 특히 Ke et al. [23]의 비양상 인스턴스 분할 접근 방식이 본 연구의 베이스라인 모델 중 하나에 영감을 주었습니다. 기존 인식 시스템들은 제한된 수용 필드나 패치/윈도우 기반으로 작동하여 객체 상호작용 추론이 필요한 비양상 분할에는 한계가 있습니다.

## 🛠️ Methodology

1. **데이터셋 주석 도구 확장:**
   - 기존 Open Surfaces [3] 주석 도구를 확장하여 비양상 분할을 지원합니다.
   - **깊이 순서 지정:** 객체 목록에서 드래그하여 순서를 재배치하고 시각적 피드백을 제공합니다.
   - **시맨틱 주석:** 각 분할 영역에 자유 형식 텍스트로 이름을 지정해야 합니다.
   - **엣지 공유:** 새로운 다각형 정점을 기존 다각형 엣지에 '스냅(snapping)'하여 공유 엣지 주석을 용이하게 합니다.
   - **다각형 편집:** 기존 다각형의 정점 추가/제거 기능을 개선합니다.
2. **주석 가이드라인:** 고품질 및 일관성 있는 주석을 위해 네 가지 핵심 가이드라인을 따릅니다.
   - **의미론적 영역만 주석:** 명명 가능하고 의미론적으로 중요한 영역만 주석 처리합니다.
   - **밀집 주석:** 최소 크기(600픽셀) 이상의 모든 전경 객체를 포함하여 이미지를 밀집하게 주석 처리하며, 가려진 객체는 가리는 객체도 함께 주석 처리합니다.
   - **깊이 순서 지정:** 모든 영역의 상대적 깊이 순서, 특히 겹치는 영역의 앞뒤 관계를 명시합니다.
   - **엣지 공유 표시:** 인접한 두 영역이 경계를 공유하는 경우(형상-배경 관계가 불분명한 경우) 공유 엣지를 명시적으로 표시합니다.
3. **알고리즘 베이스라인:**
   - **비양상 분할:**
     - **SharpMask [32]:** 양상(modal) 객체 분할의 최신 베이스라인으로 사용.
     - **ExpandMask:** SharpMask에서 생성된 양상 마스크를 입력으로 받아 비양상 마스크로 확장하는 딥 네트워크.
     - **AmodalMask:** 이미지 패치에서 직접 비양상 마스크를 예측하는 딥 네트워크.
     - 두 비양상 모델은 SharpMask와 동일한 네트워크 아키텍처를 공유하며, COCO 원본 양상 데이터로 사전 학습된 SharpMask 모델을 사용하여 미세 조정(finetune)됩니다.
   - **쌍별 깊이 순서:**
     - **기본 휴리스틱:** 영역 크기(작은 마스크가 앞) 또는 Y축 위치(상단에 가까울수록 뒤)를 기준으로 정렬.
     - **OrderNet:**
       - $\text{OrderNet}_\text{B}$: 두 개의 경계 상자를 입력으로 받는 3계층 MLP.
       - $\text{OrderNet}_\text{M}$: 두 개의 마스크를 입력으로 받는 ResNet50 모델.
       - $\text{OrderNet}_{\text{M+I}}$: 두 개의 마스크와 이미지 패치를 입력으로 받는 ResNet50 모델.

## 📊 Results

- **데이터셋 통계 (BSDS 500개, COCO 5000개):**
  - BSDS 이미지 당 평균 7.3개 영역, 각 영역은 64개 점으로 구성. 이미지 픽셀의 84%가 커버됩니다.
  - 영역의 62%가 부분적으로 가려져 있으며, 평균 가려짐 정도는 21%입니다.
  - 'Things' (사람, 물고기)와 'Stuff' (잔디, 구름) 모두 의미론적 레이블로 포함됩니다.
  - **영역 복잡도:** 비양상 분할 영역은 양상 분할 영역보다 '단순성(simplicity)' 및 '볼록성(convexity)' 지표에서 더 간단한 형태를 가집니다 (표 1).
- **데이터셋 일관성:**
  - **영역 일관성:** 제안된 비양상 영역의 일관성(F-score 중앙값 0.723)은 원본 BSDS 양상 영역(0.425)보다 훨씬 높았습니다 (그림 8a). 이는 주석 지침의 명확성 덕분입니다.
  - **엣지 일관성:** 비양상 데이터셋의 엣지 일관성(F-score 중앙값 0.795)도 원본 BSDS 엣지(0.728)보다 높았습니다 (그림 8b).
  - **엣지 검출 성능:** 제안된 데이터셋으로 훈련된 최첨단 엣지 검출기(SE, HED)는 원본 BSDS 엣지에서도 성능 향상을 보이거나, 최소한 동등한 성능을 보였습니다 (표 2). 이는 새로운 데이터셋이 엣지 검출에 유효함을 시사합니다.
  - **인간 vs. 기계 성능 격차:** BSDS 원본 주석에서 HED (ODS 0.79)와 인간(F-score 0.81) 간의 성능 격차는 0.02였으나, 본 연구의 주석에서는 HED(0.69)와 인간(0.90) 간의 격차가 0.21로 크게 벌어져, 최첨단 기술의 개선 여지가 많음을 보여줍니다.
- **비양상 분할 품질 (COCO 검증 세트):**
  - 가려지지 않은 영역에서는 SharpMask가 강한 베이스라인이지만, 가려짐이 심한 경우(heavy occlusion)에는 ExpandMask 및 AmodalMask와 같은 비양상 베이스라인이 우수한 성능을 보였습니다 (표 3a).
  - $\text{AmodalMask}$는 모든 영역에서 $\text{AR}=0.434$를 달성했으며, 특히 가려짐이 심한 영역에서 $\text{AR}_\text{H}=0.364$로 가장 좋은 성능을 보였습니다.
- **쌍별 깊이 순서:**
  - 단순한 휴리스틱(면적, Y축)은 약 70%의 정확도를 보였습니다.
  - $\text{OrderNet}_{\text{M+I}}$ 모델은 생성된 마스크에 대해 약 80%의 정확도를, Ground Truth 마스크에 대해서는 약 90%의 정확도를 달성하여 매우 강력한 성능을 보였습니다 (표 3b). 모델의 성능은 입력 마스크의 품질이 좋을수록 향상됩니다.

## 🧠 Insights & Discussion

- **비양상 분할의 타당성:** 광범위한 분석을 통해 시맨틱 비양상 분할이 주석 작업으로서 잘 정의되어 있으며, 독립적인 주석자들 간의 일관성이 매우 높음을 입증했습니다. 이는 복잡한 장면 이해를 위한 인간 수준의 능력을 학습하는 데 중요한 기반이 됩니다.
- **새로운 도전 과제 제시:** 기존의 양상 기반 시각 인식 과제들이 인간 수준에 근접하고 있는 상황에서, 비양상 분할은 객체 상호작용 및 장면 구조에 대한 복잡한 추론을 요구하는 '다음 개척지'로서 커뮤니티에 새로운 연구 방향과 도전 과제를 제시합니다.
- **데이터셋의 활용성:** 본 데이터셋은 비양상 분할뿐만 아니라 기존의 양상 분할, 엣지 검출, 형상-배경 엣지 레이블링과 같은 고전적인 그룹화 작업 연구에도 활용될 수 있으며, BSDS보다 10배 큰 규모로 데이터 기반 접근 방식에 큰 이점을 제공합니다.
- **인간 vs. 기계 성능 격차:** 비양상 분할 작업에서 현재 기계의 성능은 인간의 성능에 비해 여전히 상당한 격차를 보여주어, 이 분야에서 최첨단 기술의 큰 개선 여지가 있음을 시사합니다.

## 📌 TL;DR

본 논문은 객체의 가려진 부분을 포함하여 완전한 영역을 주석 처리하는 새로운 시각 인식 과제인 **시맨틱 비양상 분할**을 제안합니다. 이 복잡한 장면 이해를 위한 과제를 위해, 연구팀은 인간 주석 일관성을 검증한 BSDS (500 이미지)와 대규모 알고리즘 개발을 위한 COCO (5000 이미지) **두 가지 비양상 데이터셋을 구축**했습니다. 또한, 비양상 마스크 품질 및 깊이 순서 예측을 위한 **새로운 평가 지표와 강력한 딥러닝 베이스라인(ExpandMask, AmodalMask, OrderNet)을 제시**했습니다. 결과적으로 인간 주석이 높은 일관성을 보였으며, 제시된 베이스라인 모델들이 특히 가려진 영역에서 기존 양상 모델보다 우수한 성능을 나타냈으나, 여전히 인간 성능과의 상당한 격차를 보여주어 미래 연구를 위한 새로운 도전 과제를 제시합니다.
