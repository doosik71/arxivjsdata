# Image Amodal Completion: A Survey

Jiayang Ao, Qiuhong Ke, Krista A. Ehinger

## 🧩 Problem to Solve

이 논문은 부분적으로 가려진 객체의 보이지 않는 부분을 인간처럼 이해하는 컴퓨터 비전 시스템, 즉 **비가시적 객체 완전화(Amodal Completion)** 능력의 부족 문제를 다룹니다. 기존 컴퓨터 비전 시스템은 객체의 가시적인 부분은 잘 이해하지만, 부분적으로 가려진 객체의 숨겨진 부분을 추론하는 데는 인간 능력에 크게 미치지 못합니다. 이는 자율 주행, 로봇 공학 등 실세계 응용에서 안전과 신뢰성을 저해하는 주요 과제입니다. 이 연구는 비가시적 객체 완전화 분야의 연구 동향, 핵심 기술 및 미래 방향에 대한 직관적인 이해를 제공하는 것을 목표로 합니다.

## ✨ Key Contributions

* **체계적인 단일 이미지 기반 비가시적 객체 완전화 리뷰:** 입력-출력 및 기술적 관점에서 다양한 시스템을 분류하는 새로운 분류 체계를 제시하여 포괄적인 통찰력을 제공합니다.
* **최신 연구 및 공개 데이터셋 조사:** 2022년까지의 비가시적 객체 완전화 연구 및 데이터셋을 조사하고, 미래 연구자들이 기술을 적용할 수 있도록 실제 응용 분야를 식별합니다.
* **도전 과제 및 미래 연구 방향 제시:** 비가시적 객체 완전화의 현재 도전 과제를 논의하고, 더 많은 관심이 필요한 미해결 문제들을 강조하며, 미래 연구를 위한 가능한 방향을 제안합니다.

## 📎 Related Works

기존 컴퓨터 비전 연구는 대부분 이미지의 가시적 영역에 집중해왔습니다. 객체 인식 및 추적 방법론은 종종 가려진 부분을 무시하거나 평가에서 제외했습니다. 최근 비가시적 객체 완전화에 대한 관심이 증가하고 있지만, 이 분야는 아직 초기 단계에 있습니다. 이전 연구들은 특정 도메인(예: 자동차 환경, 얼굴)에 초점을 맞추거나, 객체 감지에서의 가려짐 처리 문제만을 다루었습니다. 3D 시각 작업을 위한 3D 볼륨 완전화에 대한 초기 연구도 있었지만, 이 논문은 단일 2D 이미지에서 비가시적 객체 완전화를 포괄적으로 다룹니다.

## 🛠️ Methodology

이 논문은 비가시적 객체 완전화 프로세스를 세 가지 핵심 하위 문제로 분류하고, 각 문제에 대한 대표적인 방법론을 검토합니다.

1. **비가시적 형상 완전화 (Amodal Shape Completion)**
    * **목표:** 부분적으로 가려진 객체의 전체 형상(비가시적 마스크 포함)을 추론합니다. 이는 주로 비가시적 인스턴스 분할을 통해 이루어집니다.
    * **객체 감지 기법과 결합된 인스턴스 분할 방법:**
        * **CNN 기반 방법:** Mask R-CNN과 같은 2단계 접근 방식을 확장하여 비가시적 경계 상자(Amodal Bounding Box) 감지 후 픽셀 단위 분할을 수행합니다 (예: IBBE, ASN, BCNet).
        * **CompositionalNet 변형:** 부분 가려짐에 대한 견고성을 위해 CompositionalNet을 활용하며, 객체 표현과 컨텍스트를 분리하거나 (예: Context-aware CompositionalNet) ORM(Occlusion Reasoning Module)을 추가합니다 (예: Yuan et al. (2021)).
        * **약지도 학습 (Weakly Supervised Learning):** 수동 주석의 높은 비용 문제를 해결하기 위해 타임랩스 이미지에서 자동으로 생성된 데이터를 활용하거나 (예: WALT), 부분 완전화 개념을 기반으로 자기지도 학습을 사용합니다 (예: PCNet, ASBU, Amodal-VAE).
    * **객체 감지 없이 직접 인스턴스 분할 방법:**
        * **전통적인 방법:** 게슈탈트 원리(Gestalt principles)를 따르거나, 특정 형상 또는 곡선(예: Euler Spiral)을 가정하여 비가시적 영역을 완성합니다.
        * **CNN 기반 방법:** AmodalMask, ORCNN 등 딥러닝 모델을 사용하여 가려진 부분 뒤의 비가시적 마스크를 예측하며, 일부는 컴퓨터 생성 이미지와 정밀 주석을 활용합니다.
    * **기타 비가시적 형상 표현:**
        * **의미 인식 거리 맵 (Semantics-aware Distance Maps):** 객체의 가시성을 나타내는 맵을 사용합니다.
        * **비가시적 의미론적 분할 맵 (Amodal Semantic Segmentation Maps):** 객체 외에 배경 정보까지 포함하며, APSNet과 같은 비가시적 파놉틱 분할(Amodal Panoptic Segmentation)도 포함됩니다.
        * **비가시적 장면 레이아웃 (Amodal Scene Layouts):** 로드 또는 실내 레이아웃을 이미지에서 추론하여 자율 주행 등에 활용합니다 (예: MonoLayout).

2. **비가시적 외형 완전화 (Amodal Appearance Completion)**
    * **목표:** 객체 인스턴스 또는 배경의 보이지 않는 영역 외형(RGB 값)을 재구성합니다.
    * **접근 방식:** 대부분 비가시적 형상 완전화에서 추론된 비가시적 마스크에 의존하여 파이프라인 형태로 작동합니다.
    * **응용 시나리오별 분류:**
        * **객체 중심 표현 (Object-centric Representations) (주로 장난감 데이터셋):** 이미지를 잠재적 구성 요소(객체, 영역)로 분해하여 재구성합니다 (예: MONet, IODINE, GENESIS, Slot Attention). 대부분 비지도 학습입니다.
        * **카테고리별 연구:** 특정 종류의 가려진 객체(예: 차량, 사람, 음식) 외형을 완성하는 데 초점을 맞춥니다 (예: Yan et al. (2019)의 차량, Zhou et al. (2021)의 사람, PizzaGAN의 음식).
        * **복잡한 장면을 위한 방법:** 합성 데이터를 기반으로 하거나 (예: SeGAN, Dhamo et al. (2019a)), 실제 이미지를 대상으로 자기지도 학습을 통해 외형을 완성합니다 (예: PCNet, CSDNet).

3. **순서 인지 (Order Perception)**
    * **목표:** 겹치는 객체 간의 올바른 순서(가려짐 관계 또는 깊이 관계)를 식별합니다. 이는 다른 비가시적 완전화 작업에 도움이 될 수 있습니다.
    * **가려짐 순서 (Occlusion Order):**
        * 객체 간의 가려짐 관계를 직접 추론합니다 (예: BCNet, ORM). 어떤 객체가 다른 객체를 가리는지 (occluder-occludee)를 판단합니다.
        * 인접한 인스턴스 쌍 사이의 가려짐 순서를 추론한 다음 전체 장면의 순서를 유추하기도 합니다 (예: PCNet, ASBU).
    * **레이어 순서 (Layer Order):**
        * 객체와 카메라 간의 거리에 기반한 깊이 관계를 고려하여 이미지를 계층화된 구조로 표현합니다.
        * 간단한 2-레이어 구조(전경/배경)부터 (예: Dhamo et al. (2019b)), 장면에 따라 가변적인 레이어 수를 사용하는 방법 (예: Dhamo et al. (2019a), CSDNet)이 있습니다.
        * 카메라로부터의 거리, 전역 계층 맵(global layering map), 시각적으로 유사한 객체를 동일 레이어로 취급하는 등의 방법도 있습니다.

## 📊 Results

이 논문은 각 하위 태스크에 대한 데이터셋 및 평가 지표를 상세히 설명하고 최신 벤치마크 결과를 제시합니다.

* **데이터셋:**
  * **데이터 수집 방법:** 수동 주석, 클립아트 기반 이미지 합성, 3D 합성 장면에서 2D 이미지 생성의 세 가지 주요 접근 방식이 있습니다.
  * **주요 데이터셋:** COCOA, KINS, InstaOrder (일반 객체), OVD, WALT, Amodal Cityscapes, KITTI-360-APS, BDD100K-APS (차량), AHP (사람), DYCE, OLMD, CSD (실내) 등이 있습니다. 이 데이터셋들은 비가시적 마스크, 외형, 순서 정보를 다양하게 제공합니다.

* **평가 지표 및 벤치마크:**
  * **비가시적 형상 완전화:**
    * **비가시적 인스턴스 분할:** $IoU$, $mIoU$, Precision, Recall, $F1$-score, $mAP$ 등이 사용됩니다. $mAP$가 가장 보편적입니다. COCOA 및 KINS 데이터셋의 결과가 Table 3에 제시됩니다.
    * **비가시적 의미론적 분할:** $MIoU_{vis}$, $MIoU_{inv}$, $MIoU_{total}$ 등을 사용하여 가시적/비가시적 영역의 $MIoU$를 측정합니다. Amodal Cityscapes 데이터셋의 결과가 Table 4에 제시됩니다.
    * **비가시적 파놉틱 분할:** $APQ$ (Amodal Panoptic Quality) 및 $APC$ (Amodal Parsing Coverage)가 사용됩니다. KITTI-360-APS 및 BDD100K-APS 데이터셋의 결과가 Table 5에 제시됩니다.
  * **비가시적 외형 완전화:**
    * **픽셀 차이 기반:** $MSE$, $RMSE$, $PSNR$, $L1$ 및 $L2$ 거리 등이 사용됩니다.
    * **인지적 차이 기반:** $SSIM$ (Structural Similarity Index)이 사용됩니다.
    * **GAN 생성 결과 유사성:** $FID$ (Fréchet Inception Distance)가 사용됩니다.
    * 정성적 평가(인간 관찰자 만족도)도 활용됩니다. CSD 및 AHP 데이터셋의 결과가 Table 6에 제시됩니다.
  * **순서 인지:**
    * **가려짐 순서:** 쌍별 깊이 순서의 평균 정확도, Precision, Recall, $F1$-score가 사용됩니다. COCOA, KINS, InstaOrder 데이터셋의 결과가 Table 7에 제시됩니다.
    * **레이어 순서:** 깊이 오차(예: $RMSE$, $REL$, 특정 임계값 내 정확도 %인 $max(\frac{d_i}{d_i^*}, \frac{d_i^*}{d_i}) = \delta < thr$) 및 Damerow-Levenstein 거리 등이 사용됩니다.

* **분포 외 일반화 (Out-of-Distribution Generalization):** 모델의 견고성 평가를 위해 보지 못한 데이터셋으로 테스트하거나, 가려지지 않은 이미지로 훈련 후 부분적으로 가려진 이미지에서 평가하는 방식이 중요합니다. 실제 이미지에 대한 정확한 외형 그라운드 트루스의 희소성으로 인해 3D CAD 모델 활용, 수동 주석, 또는 시각적으로 합리적인 이미지 편집 등의 방법을 사용합니다.

## 🧠 Insights & Discussion

* **응용 분야:** 비가시적 객체 완전화는 자동 주석 생성, 장면 편집 및 재구성, Diminished Reality (DR), 로봇 그리핑 시스템, 자율 주행, 새로운 시점 합성 등 다양한 실제 응용 분야에서 중요하게 활용됩니다. 특히 DR과 같이 불필요한 객체를 제거하고 자연스럽게 배경을 채우는 기술이나, 자율 주행에서 가려진 객체의 전체 형상을 추론하여 안전한 판단을 내리는 데 핵심적입니다.

* **한계 및 미래 방향:**
  * **데이터셋 도전 과제:** 실제 이미지 데이터셋의 수동 주석은 주관적이며, 보이지 않는 부분의 외형에 대한 실제 그라운드 트루스가 부족합니다. 합성 데이터셋은 다양성과 사실성이 제한적이며, 복합 이미지 데이터셋은 시각적 이질성이 있을 수 있습니다. 미래에는 X-ray 같은 새로운 이미징 시스템 도입, 실제 외형 그라운드 트루스 확보, 더 다양한 시나리오와 시각적으로 유사한 객체 간의 가려짐을 다루는 데이터셋이 필요합니다.
  * **출력의 다양성:** 부분적으로만 보이는 객체에 대해 여러 가지 합리적인 숨겨진 부분 구성이 가능하므로, 모델이 단일 해답이 아닌 다양한 가능성을 제공하는 연구가 필요합니다. 다중 해답 데이터셋과 FID와 같은 평가 지표가 중요해질 것입니다.
  * **더 나은 시각적 표현:** 현재 2D 표현을 넘어 2.5D 또는 3D 표현을 구축하여 추론된 정보를 더 직관적으로 시각화하고 공간 레이아웃과 같은 추가 정보를 활용하는 연구가 필요합니다.
  * **하위 문제의 공동 해결:** 비가시적 형상, 외형, 순서 인지 하위 문제들을 공동으로 해결하는 것의 중요성에 대한 연구(예: Ablation Study)가 필요합니다.
  * **일관된 성능 지표:** 현재 각 하위 태스크별로 평가 지표가 일관되지 않아 비교가 어렵습니다. 미래에는 통일된 평가 지표의 개발이 필수적입니다.
  * **실시간 모델:** 자율 주행 등 실시간 추론이 필요한 응용 분야를 위해 모델 복잡도 및 추론 속도를 고려한 실시간 비가시적 완전화 모델 개발이 필요합니다.
  * **다른 작업 또는 컨텍스트와의 통합:** 다중 모달 완전화, 고해상도 완전화, 객체 감지, 의미론적 분할, 깊이 추정 등 다른 컴퓨터 비전 작업 및 3D 정보, 시간 정보, 장면 컨텍스트 등 추가 정보와의 통합을 통해 성능 향상과 더 포괄적인 장면 이해를 도모할 수 있습니다.

## 📌 TL;DR

이 설문조사 논문은 가려진 객체의 **보이지 않는 부분을 인지(Amodal Completion)**하는 컴퓨터 비전 시스템의 현재 상태를 다룹니다. 핵심 문제는 컴퓨터가 인간처럼 객체의 전체 형상, 외형, 그리고 객체 간의 순서 관계를 추론하지 못한다는 것입니다. 이 논문은 비가시적 형상 완전화, 외형 완전화, 순서 인지라는 세 가지 주요 하위 작업을 체계적으로 분류하고 각 분야의 최신 딥러닝 기반 방법론(CNN, CompositionalNet, VAE/GAN)과 그들의 강점 및 한계를 분석합니다. 또한, COCOA, KINS, CSD와 같은 관련 데이터셋과 mAP, PSNR, 정확도 등 다양한 평가 지표를 상세히 검토합니다. 비가시적 완전화는 자율 주행, 로봇 공학, 장면 편집 등 다양한 실세계 응용에 필수적이지만, 아직 데이터셋 부족, 출력의 다양성 처리, 일관된 평가 지표, 실시간 성능 및 다른 컨텍스트와의 통합 등 해결해야 할 많은 과제가 남아있음을 강조하며 미래 연구 방향을 제시합니다.
