# 컨볼루션 레이어와 순환 레이어의 장점 결합: 시맨틱 분할을 위한 하이브리드 네트워크

Zhicheng Yan, Hao Zhang, Yangqing Jia, Thomas Breuel, Yizhou Yu

## 🧩 Problem to Solve

현재 시맨틱 분할(Semantic Segmentation) 분야에서 최첨단 성능을 달성한 완전 컨볼루션 네트워크(FCN)는 계층적인 컨볼루션 및 풀링 레이어를 통해 수용 필드(receptive field)를 점진적으로 확장하여 원거리 컨텍스트 의존성(distant contextual dependence)을 간접적으로 모델링합니다. 그러나 이러한 방식은 다음과 같은 한계를 가집니다:

- **제한된 수용 필드:** FCN의 뉴런 수용 필드는 입력 이미지의 지역 영역에만 해당되어, 이미지의 원거리 영역에서 오는 컨텍스트 정보(예: 바다와 언덕 패턴을 통해 "해변"을 예측하는 경우)를 효과적으로 포착하기 어렵습니다.
- **비효율적인 장거리 의존성 모델링:** 수용 필드를 인위적으로 전체 이미지에 걸쳐 늘릴 수 있지만, 이러한 간접적인 모델링 방식은 장거리 컨텍스트 인코딩에 비효율적이며, 정보가 필터 간에 어떻게 전파되고 추론에 기여하는지 불분명합니다.

이러한 문제점은 전역 컨텍스트와 장거리 의존성을 보다 명시적으로 모델링하는 새로운 접근 방식의 필요성을 제기합니다.

## ✨ Key Contributions

- **공간적으로 순환하는 레이어(ReNet 레이어) 도입:** 시맨틱 분할을 위해 이미지 전체를 수직 및 수평으로 스캔하는 ReNet 레이어를 제안하여, 전역 컨텍스트를 직접적으로 포착하고 향상된 특징 표현을 생성합니다.
- **Naive Deep ReNet (N-ReNet) 개발:** ReNet 레이어를 단순히 쌓아 올린 N-ReNet이 Stanford Background 데이터셋에서 경쟁력 있는 성능을 달성함을 입증하여, ReNet 레이어의 단독적인 유효성을 보여줍니다.
- **하이브리드 Deep ReNet (H-ReNet) 구축:** 기존 FCN에 ReNet 레이어를 통합하여, 컨볼루션 레이어가 지역 특징을 추출하고 순환 레이어가 공간적 장거리 정보 전파를 수행하는 새로운 하이브리드 네트워크를 개발합니다.
- **H-ReNet의 탁월한 특성 입증:**
  - **전체 이미지 수용 필드:** 순환 레이어를 통해 전체 이미지에 대한 수용 필드를 직접 지원합니다.
  - **향상된 특징 표현:** 전역 컨텍스트 포착을 통해 지역 인식 및 경계 지역화 성능을 향상시킵니다.
  - **엔드-투-엔드 학습 및 효율적인 실행:** 모든 레이어가 미분 가능하여 엔드-투-엔드 학습이 가능하며, 순환 레이어 계산의 병렬화를 통해 GPU를 효율적으로 활용합니다.
- **최첨단 성능 달성:** PASCAL VOC 2012 벤치마크에서 기존 최첨단 방법(Piecewise, CRFasRNN, DeepParsing 등) 대비 3.6%, 2.3%, 0.2%의 성능 향상을 보이며, 20개 객체 클래스 중 13개에서 가장 높은 IoU(Intersection over Union)를 기록합니다.

## 📎 Related Works

- **비모수적 방법 (Nonparametric Methods):** 유사 패치 검색, 레이블 전이, 확률적 그래픽 모델(MRF, CRF)을 통한 공간적 일관성 모델링(예: [10,11,12,13,14]). 여러 단계로 나뉘어 개별적으로 설계되며 공동 최적화가 어려움.
- **모수적 방법 (Parametric Methods) - FCN 기반 모델:**
  - 바운딩 박스 입력 및 개별 마스크 병합 방식(예: [20,21,22,23,24,25]).
  - 전체 이미지 직접 입력 및 분할 마스크 생성 방식: CNN의 풀링 레이어 때문에 결과 마스크가 불명확할 수 있어, 픽셀 상호작용 및 경계 유지를 위해 추가 그래픽 모델(MRF, CRF) 레이어(사후 처리 [27] 또는 공동 최적화 [2,28])를 도입함.
  - 줌아웃(Zoom-out) 특징을 사용하여 슈퍼픽셀을 레이블링하는 방식(예: [29]).
- **시각 인식 분야의 RNN:**
  - 2D LSTM 및 컨볼루션 레이어로 구성된 계층적 구조(예: [11]).
  - 객체 감지를 위한 IRNN 레이어(예: [30]).
  - CNN의 대안으로 이미지 인식을 위한 ReNet 아키텍처(예: [31]). 본 논문은 이 ReNet 아키텍처를 기반으로 하지만, IRNN의 단순한 ReLU RNN 대신 복잡한 게이팅 유닛을 가진 LSTM을 사용하여 소실 그래디언트 문제(vanishing gradient issue)를 극복하고 성능을 향상시킵니다.

## 🛠️ Methodology

- **공간적으로 순환하는 레이어(Spatially Recurrent Layer, ReNet Layer):**
  - **입력:** $H \times W$ 크기의 이미지 또는 특징 맵 $I$를 입력받습니다.
  - **패치 분할:** $h \times w$ 그리드의 패치(패치 크기 $s \times t$, 여기서 $h = \lceil H/s \rceil$, $w = \lceil W/t \rceil$)로 나눕니다.
  - **1D RNN 사용:** 두 개의 1D RNN(여기서는 LSTM 유닛 [32] 사용)이 독립적인 가중치를 가지며, 수직(또는 수평) 방향으로 반대 방향으로 스캔합니다.
  - **LSTM 유닛:** 망각 게이트($f_t$), 입력 게이트($i_t$), 셀 입력($\tilde{C}_t$), 셀 메모리($C_t$), 출력 게이트($o_t$), 은닉 상태($h_t$)를 포함하여 각 단계 $t$에서 메모리($C_t$) 내용을 적응적으로 망각, 기억, 노출할 수 있도록 합니다.
  - **수식:**
    $$ (h^F*{y,x}, C^F*{y,x}) = \text{LSTM}_F(I_{y,x}, h^F*{y-1,x}, C^F*{y-1,x}) \text{ for } y=1,..,H $$
        $$ (h^B*{y,x}, C^B*{y,x}) = \text{LSTM}_B(I_{y,x}, h^B*{y+1,x}, C^B*{y+1,x}) \text{ for } y=H,...,1 $$
        여기서 위첨자 $F$와 $B$는 각각 전방(forward) 및 후방(backward) 스캔 방향을 나타냅니다.
  - **특징 맵 생성:** 두 LSTM의 은닉 상태를 연결하여 합성 특징 맵을 생성하며, 이는 동일한 열(column) 내 모든 패치를 포함하는 수용 필드를 가집니다.
  - **순환 레이어 그룹:** 직교하는 스캔 방향을 가진 두 개의 ReNet 레이어(예: 수평 및 수직)를 쌓아 입력 이미지를 완전히 커버하는 출력 특징 맵을 얻습니다.
- **Naive Deep ReNet (N-ReNet):**
  - 여러 순환 레이어 그룹을 쌓아 구성합니다.
  - 첫 번째 그룹은 원본 픽셀을 입력으로 받습니다.
  - 마지막 그룹의 출력은 소프트맥스(softmax) 레이어를 통해 조밀한 예측을 생성합니다.
  - 특징 맵 채널 수를 시맨틱 레이블 수와 일치시키기 위해 마지막 ReNet 레이어 위에 보조 $1 \times 1$ 컨볼루션 레이어를 추가합니다.
- **하이브리드 Deep ReNet (H-ReNet):**
  - 사전 학습된 FCN(예: ImageNet으로 사전 학습된 VGG-16 기반 네트워크)의 끝에 순환 레이어 그룹을 추가하여 구성합니다.
  - **베이스라인 FCN 아키텍처:** VGG-16 네트워크를 FCN으로 변환하되, `pool4` 및 `pool5` 레이어의 stride를 2에서 1로 줄여(`hole algorithm` 또는 `dilated convolution` 기법) 특징 맵 해상도를 유지합니다. 여기에 `conv6`, `conv7`, `conv8` 컨볼루션 레이어를 추가합니다.
  - **H-ReNet의 통합:** 베이스라인 FCN의 `conv7`과 `conv8` 레이어 사이에 하나의 순환 레이어 그룹(`renet1`)을 삽입합니다.
  - **다층 특징 조합 (Multi-layer Feature Combination):** `pool4`, `pool5`, `conv7` 레이어의 특징 맵을 연결하여 `renet1`에 입력하기 전에 사용합니다. 상이한 레이어의 특징 값 스케일 문제를 해결하기 위해 배치 정규화(Batch Normalization) [47]를 적용합니다.
- **학습:** 픽셀 단위 다항 교차 엔트로피(pixelwise multinomial cross entropy) 손실 함수를 사용한 확률적 경사 하강법(stochastic gradient descent)으로 엔드-투-엔드 학습됩니다. 무작위 크롭 및 수평 뒤집기(random horizontal flipping)를 적용한 미니 배치로 훈련합니다.
- **테스트:** 컨볼루션 및 ReNet LSTM 레이어 모두 가변 크기 입력을 처리할 수 있으므로, 원본 이미지 해상도로 조밀한 예측을 생성합니다.
- **CRF 통합 (선택적 사후 처리):** 경계 정제를 위해 `DenseCRF` [27]를 사후 처리 단계로 사용하여, 네트워크 예측을 일변량(unary) 포텐셜로, 공간 및 양방향 커널을 이변량(pairwise) 포텐셜로 구성합니다. 이는 GPU에서 효율적으로 구현됩니다.

## 📊 Results

- **N-ReNet 평가 (Stanford Background 데이터셋):**
  - **성능:** 픽셀 정확도 80.4%, 클래스 정확도 71.8%를 달성하여 비모수적 방법 및 대부분의 CNN 기반 방법보다 우수합니다.
  - **효율성:** GPU에서 이미지당 0.07초의 빠른 처리 속도를 보여, 비교 대상 방법들보다 훨씬 빠릅니다.
  - **특징 학습:** N-ReNet이 CNN과 유사하게 계층적 특징 표현을 학습함을 시각화를 통해 확인했습니다.
- **H-ReNet 평가 (PASCAL VOC 2012 데이터셋):**
  - **베이스라인 FCN 대비 개선:** 순환 레이어 그룹 하나를 삽입함으로써 베이스라인 FCN (평균 IoU 63.4%) 대비 평균 IoU를 70.0%로 크게 향상($\Delta$6.6%)시켰습니다.
  - **추가 개선:** 배치 정규화(Batch Normalization) 적용 시 70.4%로 ($\Delta$0.4%), 다층 특징 조합(multi-layer feature combination) 적용 시 71.1%로 ($\Delta$0.7%) 추가적인 개선을 달성했습니다.
  - **DenseCRF 통합:** 사후 처리로 `DenseCRF`를 적용하면 평균 IoU가 72.6%로 향상되며(테스트 세트에서는 74.3% 달성), 경계 지역화(boundary localization) 능력이 더욱 강화됩니다.
  - **최첨단 성능 비교 (VOC12 테스트 세트, COCO 데이터 제외):**
    - H-ReNet (+DenseCRF)는 74.3% IoU를 달성하여 FCN-8s($\Delta$12.1%), Zoomed-out($\Delta$5.6%), DeepLab-CRF-LargeFOV($\Delta$4.0%), CRFasRNN($\Delta$2.3%), Piecewise($\Delta$3.6%) 등의 기존 방법들을 능가하며, DeepParsing($\Delta$0.2%)보다 약간 우수한 결과를 보였습니다.
    - 20개 객체 클래스 중 13개에서 가장 높은 IoU를 기록했습니다.
  - **MS COCO 추가 학습 데이터 사용 시:** H-ReNet (+DenseCRF)는 76.8% IoU를 달성했으며, DeepParsing(77.5%)보다는 약간 낮았습니다.
  - **효율성:** H-ReNet 추가는 FCN 베이스라인 대비 예측 시간에 미미한 증가(0.03초)만을 가져왔으며, `DenseCRF` 사후 처리는 정확도 향상과 함께 계산 비용을 소폭 증가시켰습니다.
  - **어블레이션 스터디 (Ablation Studies):**
    - LSTM 유닛이 IRNN 유닛보다 3.2% 더 높은 성능(70.4% vs. 67.2%)을 보였습니다.
    - 다층 특징 조합은 심층 레이어의 특징이 더 유익하며, 여러 레이어의 특징을 결합할 때 보완적인 관계가 있음을 확인했습니다.
    - H-ReNet은 FCN과 달리 학습 이미지 크기가 커질수록 성능이 향상됨을 보여, ReNet 레이어가 더 긴 거리의 컨텍스트 정보를 활용할 수 있음을 시사합니다.

## 🧠 Insights & Discussion

- **명시적 전역 컨텍스트 모델링의 우수성:** FCN이 컨볼루션 및 풀링 레이어를 계층적으로 쌓아 간접적으로 장거리 의존성을 모델링하는 것과 달리, ReNet 레이어는 이미지 전체에 걸쳐 정보를 직접 전파하여 전역 컨텍스트를 명시적으로 모델링합니다. 이는 특히 모호한 영역에서 보다 일관된 예측과 정확한 객체 인식을 가능하게 합니다.
- **경계 지역화 개선:** 특징 맵 해상도가 감소하더라도, H-ReNet은 전역 컨텍스트를 통한 향상된 특징 표현 덕분에 베이스라인 FCN 대비 경계를 더 잘 지역화하고 복원할 수 있습니다.
- **CRF와의 상보성:** ReNet 레이어가 고수준 특징으로부터 컨텍스트 의존성을 모델링하는 반면, `DenseCRF`는 저수준 픽셀 간 상호작용을 모델링합니다. 이 두 가지 접근 방식은 특히 경계 정밀도 향상에 있어 상호 보완적임을 입증했습니다.
- **효율적인 설계:** ReNet 레이어는 GPU에서 병렬화가 가능하여 계산 효율성이 높으며, FCN에 추가될 때 성능 향상에 비해 계산 오버헤드가 미미합니다.
- **한계점 및 향후 연구:**
  - H-ReNet은 '자전거'와 같이 바퀴 내부 영역이 배경으로 정확히 예측되어야 하는 복잡한 객체에서 DeepParsing이 모델링하는 고차 레이블 관계(high-order label relations)에는 미치지 못하는 경우가 있었습니다. 이는 H-ReNet에 더 정교한 학습 가능한 그래픽 모델을 통합하여 공동 최적화할 여지가 있음을 시사합니다.
  - 매우 대규모 데이터셋(예: MS COCO)을 사용할 경우 DeepParsing이 H-ReNet을 약간 능가하는 경향이 있었는데, 이는 충분한 데이터가 제공될 때 그래픽 모델이 컨텍스트와 고차 관계를 더 잘 포착할 수 있음을 의미할 수 있습니다.

## 📌 TL;DR

- **문제:** 시맨틱 분할을 위한 FCN은 수용 필드 제한으로 인해 장거리 컨텍스트 의존성을 모델링하는 데 어려움을 겪습니다.
- **방법:** 본 논문은 1D LSTM 기반의 공간적 순환 레이어(ReNet 레이어)를 제안합니다. 이는 이미지를 수직 및 수평으로 스캔하여 전역 컨텍스트를 명시적으로 포착합니다. ReNet 레이어를 쌓은 N-ReNet과 FCN에 ReNet 레이어를 추가한 하이브리드 네트워크 H-ReNet을 구축합니다. H-ReNet은 CNN의 지역 특징 추출 능력과 RNN의 전역 컨텍스트 모델링 능력을 결합하며, 다층 특징 조합 및 배치 정규화 기법을 활용합니다.
- **발견:** N-ReNet은 단독으로도 효과적이며, H-ReNet은 PASCAL VOC 2012에서 FCN의 성능을 크게 향상(CRF 없이 IoU +6.6%)시켰습니다. 이는 H-ReNet이 전체 이미지 수용 필드를 가능하게 하고 더 나은 특징 표현을 생성하기 때문입니다. `DenseCRF` 사후 처리를 통해 74.3%의 최첨단 IoU를 달성하며, 장거리 컨텍스트 모델링 한계를 효과적으로 해결하면서도 계산 오버헤드는 미미합니다.
