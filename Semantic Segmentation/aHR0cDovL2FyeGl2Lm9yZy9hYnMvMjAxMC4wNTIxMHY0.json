{
  "url": "http://arxiv.org/abs/2010.05210v4",
  "title": "Generalized Few-shot Semantic Segmentation",
  "authors": "Zhuotao Tian, Xin Lai, Li Jiang, Shu Liu, Michelle Shu, Hengshuang Zhao, Jiaya Jia",
  "year": 2020,
  "abstract": "Training semantic segmentation models requires a large amount of finely\nannotated data, making it hard to quickly adapt to novel classes not satisfying\nthis condition. Few-Shot Segmentation (FS-Seg) tackles this problem with many\nconstraints. In this paper, we introduce a new benchmark, called Generalized\nFew-Shot Semantic Segmentation (GFS-Seg), to analyze the generalization ability\nof simultaneously segmenting the novel categories with very few examples and\nthe base categories with sufficient examples. It is the first study showing\nthat previous representative state-of-the-art FS-Seg methods fall short in\nGFS-Seg and the performance discrepancy mainly comes from the constrained\nsetting of FS-Seg. To make GFS-Seg tractable, we set up a GFS-Seg baseline that\nachieves decent performance without structural change on the original model.\nThen, since context is essential for semantic segmentation, we propose the\nContext-Aware Prototype Learning (CAPL) that significantly improves performance\nby 1) leveraging the co-occurrence prior knowledge from support samples, and 2)\ndynamically enriching contextual information to the classifier, conditioned on\nthe content of each query image. Both two contributions are experimentally\nshown to have substantial practical merit. Extensive experiments on Pascal-VOC\nand COCO manifest the effectiveness of CAPL, and CAPL generalizes well to\nFS-Seg by achieving competitive performance. Code is available at\nhttps://github.com/dvlab-research/GFS-Seg."
}