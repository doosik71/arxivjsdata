# Coarse-to-Fine Domain Adaptive Semantic Segmentation with Photometric Alignment and Category-Center Regularization

Haoyu Ma, Xiangru Lin, Zifeng Wu, Yizhou Yu

## 🧩 Problem to Solve

시맨틱 세그멘테이션에서 레이블링 작업의 노력을 줄이기 위해 비지도 도메인 적응(Unsupervised Domain Adaptation, UDA)은 중요한 연구 분야입니다. 하지만 소스 도메인(합성 이미지)과 타겟 도메인(실제 이미지) 사이의 "도메인 시프트(Domain Shifts)" 문제로 인해 세그멘테이션 성능이 저하됩니다. 본 논문은 이러한 도메인 시프트의 주요 원인을 두 가지로 관찰합니다:

1. **이미지 레벨 도메인 시프트**: 촬영 조건(노출, 대비, 조명 등)의 차이.
2. **카테고리 레벨 도메인 시프트**: 객체 카테고리 구성(모양, 자세, 질감 등)의 차이로 인해 특정 카테고리가 서로 구별하기 어려운 문제.

기존 방법들은 이미지 스타일 변환을 위해 계산 비용이 많이 드는 심층 모델 학습(예: GAN)을 요구하거나, 만족스럽지 못한 스타일 변환 이미지 품질을 보여주거나, 카테고리 중심을 '하드 제약(hard constraint)'으로 사용하여 카테고리 간 거리 조절에 한계가 있었습니다.

## ✨ Key Contributions

* **새로운 Coarse-to-Fine UDA 파이프라인 제안**: 이미지 레벨 정렬(Coarse)과 카테고리 레벨 특징 분포 정규화(Fine)를 매끄럽게 통합합니다.
* **전역 광학 정렬(Global Photometric Alignment, GPA) 모듈 도입**: 이미지 레벨 도메인 시프트를 효율적으로 해결하기 위한 새로운 모듈로, 추가 학습 과정이 필요 없고 GAN 기반 모델에 필적하거나 능가하는 이미지 품질과 성능을 제공합니다.
* **두 가지 카테고리 레벨 정규화 방법 제안**:
  * **카테고리 중심 트립렛 손실(Category-oriented Triplet Loss, CTL)**: 소스 도메인에서 카테고리 중심 간의 거리를 능동적으로 확장하여 카테고리 구별력을 높입니다.
  * **타겟 도메인 일관성 정규화(Target Domain Consistency Regularization, TCR)**: 타겟 도메인에서 증강된 이미지에 대한 예측이 원본 이미지의 의사 레이블(pseudo-label)과 일관되도록 강제하는 자기 지도(self-supervised) 방법입니다.
* **최첨단 성능 달성**: GTA5→Cityscapes 및 SYNTHIA→Cityscapes 벤치마크에서 기존의 모든 방법들을 능가하는 새로운 최첨단(State-of-the-Art, SOTA) 성능을 달성했습니다.

## 📎 Related Works

* **광학 정렬 기반 방법 (Photometric Alignment)**:
  * GAN 기반 모델 (예: BDL [14], Cycada [8]): 도메인 간 이미지 스타일을 전이하여 광학적 차이를 줄입니다. 하지만 학습이 어렵고, 실제 특징 매핑을 얻지 못할 수 있으며, 결정론적 방식으로 제한된 스타일만 생성할 수 있습니다.
  * 주파수 기반 방법 (FDA [33]): 푸리에 변환을 통해 저주파수 컴포넌트를 교체하여 도메인을 정렬하지만, 시각적 아티팩트를 유발하고 성능이 앙상블에 크게 의존합니다.
  * **본 논문의 차별점**: GPA는 경량화된 전략으로, 추가 학습 없이 유사하거나 더 나은 성능과 이미지 품질을 제공합니다.
* **카테고리 기반 방법 (Category-Based Methods)**:
  * [9, 16, 26, 29]는 예측 레이블 분포에 전역적인 의미론적 제약을 부과합니다.
  * CAG [34] 및 DTST [30]는 소스 도메인의 카테고리 특징 중심 또는 인스턴스 특징을 '앵커(anchor)'로 사용하여 도메인 간 정렬을 유도합니다.
  * **본 논문의 차별점**: 기존 방법들은 카테고리 중심 간의 여백(margin)을 명시적으로 확대하지 않았습니다. 본 논문의 CTL은 소스 도메인에서 카테고리 중심 간 거리를 능동적으로 확장하는 '소프트 제약(soft constraint)'을 가합니다. 또한, TCR은 타겟 도메인에서 자기 지도 기반 일관성 정규화를 통해 카테고리 레벨 특징 분포를 더욱 제약합니다.

## 🛠️ Methodology

본 논문의 핵심 아이디어는 **Coarse-to-Fine 파이프라인**으로, 이미지 레벨 정렬(Coarse)과 카테고리 레벨 특징 분포 정규화(Fine)를 단계적으로 적용하며, 전체 과정은 반복적인 자기 지도 학습 방식으로 진행됩니다.

**Step 0: Coarse Alignment (전역 광학 정렬, GPA)**

1. **색 공간 변환**: 소스 도메인 이미지 $m_k$와 무작위로 선택된 타겟 도메인 참조 이미지 $n_k$를 Lab 색 공간으로 변환합니다 (각각 $(L_m, a_m, b_m)$과 $(L_n, a_n, b_n)$).
2. **색상 채널 정렬**: $a_m$과 $b_m$에 $f_{match}$ (히스토그램 매칭) 함수를 적용하여 $a_n$과 $b_n$에 매칭합니다.
3. **명도 채널 정렬**: $L_m$에 $f_{gamma}$ (감마 보정) 함수를 적용하여 $L_n$에 매칭합니다. 이는 다음 목적 함수를 최소화하여 $\gamma$를 수치적으로 해결합니다:
    $$
    \gamma^* = \arg \min_{\gamma} \left( \sum_L L p_{m}^{s}(L^{\gamma}) - \sum_L L p_{n}^{t}(L) \right)^2 + \beta(\gamma-1)^2
    $$
    여기서 $p_{m}^{s}$는 소스 이미지의 명도 히스토그램, $p_{n}^{t}$는 타겟 참조 이미지의 명도 히스토그램입니다. $\beta$는 정규화 항입니다.
4. **RGB 변환 및 증강**: 정렬된 Lab 이미지를 RGB로 변환하여 정렬된 소스 이미지 $m'$를 생성하고, 여기에 확률적 함수 $\tau$ (색상 지터링)를 적용하여 증강된 버전 $\tau(M')$을 만듭니다.
5. **초기 모델 학습**: $\tau(M')$를 사용하여 초기 세그멘테이션 모델 $T_0$를 세그멘테이션 손실 $L_{seg}$로 학습합니다.

**Step 1: Category-level Feature Distribution Regularization**

1. **의사 레이블 생성**: $T_0$를 사용하여 타겟 도메인 이미지 $N$에 대한 픽셀별 의사 레이블 $\hat{y}_{k}^{j}$와 신뢰도 임계값 $t_c = \min(P_h, P_{s,c})$를 생성합니다. $P_h$는 전역 확률 임계값, $P_{s,c}$는 카테고리별 임계값입니다.
2. **카테고리 중심 트립렛 손실 (CTL) (소스 도메인)**:
    * 소스 도메인의 픽셀 특징을 사용하여 각 카테고리 $c$의 L2 정규화된 카테고리 중심 $f_c$를 계산합니다:
        $$
        f_c = G\left(\frac{1}{N_c}\sum_s\sum_i\sum_j 1(y_{i,j}=c)x_{i,j}\right)
        $$
        여기서 $G$는 L2 정규화 함수입니다.
    * 다음과 같은 트립렛 손실 $L_{triplet}$를 적용하여 픽셀 특징 $x_{i,j}$가 자신의 카테고리 중심에는 더 가깝고, 다른 카테고리 중심과는 $\alpha$만큼 더 멀어지도록 강제합니다:
        $$
        L_{triplet} = \frac{1}{N_s} \sum_s \sum_C \sum_i \sum_j \max(\|G(x_{i,j})-f_{c=C}\| - \|G(x_{i,j})-f_{c \neq C}\| + \alpha,0)
        $$
    * 이는 소스 도메인의 신뢰할 수 있는 레이블에만 적용됩니다.
3. **타겟 도메인 일관성 정규화 (TCR) (타겟 도메인)**:
    * 타겟 도메인 이미지 $n_k$에 대해 $T_{i-1}$로 생성된 의사 레이블 $\hat{y}_{k}^{j}$를 얻습니다.
    * $n_k$의 증강된 버전 $n'_k = \tau(n_k)$를 생성하고, $T_i$를 통해 예측 $p'_{k,j}$를 얻습니다.
    * 의사 레이블의 신뢰도가 $t_c$ 이상인 픽셀에 대해 $p'_{k,j}$가 $\hat{y}_{k}^{j}$와 일관되도록 다음 손실 $L_{cst}$를 적용합니다:
        $$
        L_{cst} = \sum_j 1(\max(T_{i-1}(n_k)|_j) \geq t_c) CELoss(1_{[c=\hat{y}_{k}^{j}]}, p_{k}^{'j}) \\
        \text{여기서 } \hat{y}_{k}^{j} = \arg \max(T_{i-1}(n_k)|_j) \\
        \text{그리고 } p_{k}^{'j} = T_i(n_k')|_j
        $$
    * **참고**: 의사 레이블 생성에는 불안정한 $T_i$ 대신 이전 단계의 안정적인 $T_{i-1}$ 모델을 사용합니다.
4. **모델 미세 조정**: $T_0$를 $U$ 반복 동안 $L_{seg} + L_{triplet} + L_{cst}$를 최소화하여 $T_1$을 생성합니다.

**Step 2 to K: Iterative Self-Supervised Training**

* Step 1의 과정을 $K-1$번 반복하여 모델 $T_i$를 훈련하고, 의사 레이블 및 카테고리 중심 $f_c$를 업데이트합니다.

## 📊 Results

* **GTA5→Cityscapes 태스크**:
  * 제안된 방법은 56.1%의 mIoU를 달성하여 이전 최첨단(CAG [34])보다 5.9%p 높은 성능을 보였습니다.
  * 'road', 'sidewalk', 'building', 'light', 'sky', 'car', 'person', 'train', 'motor', 'bike' 등 여러 중요한 카테고리에서 최고의 성능을 기록했습니다. 특히 'road', 'sidewalk', 'motor', 'bike' 등 시각적으로 유사한 카테고리에서도 우수한 성능을 보였는데, 이는 CTL의 효과를 시사합니다.
* **SYNTHIA→Cityscapes 태스크**:
  * GTA5에 비해 도메인 시프트가 더 큰 SYNTHIA 데이터셋에서도 제안된 모델은 다른 최첨단 방법들을 능가하는 55.5%의 mIoU를 달성하며 기술의 효과성을 입증했습니다. (CAG [34] 대비 3.7%p 향상)
* **Ablation Studies (구성 요소 분석)**:
  * **소스 온리(Source-only) 모델 (37.6% mIoU) 대비 18.5%p 성능 향상**을 보였습니다.
  * **GPA 제거 시 가장 큰 성능 저하 (47.3% mIoU)**: Coarse 정렬 단계의 필수성을 입증합니다.
  * **TCR 제거 시 53.1% mIoU**: 간단하지만 타겟 도메인 학습 샘플 수를 늘려 매우 효과적임을 보여줍니다.
  * **CTL 제거 시 53.2% mIoU**: 소스 도메인의 '어려운 샘플(hard samples)'을 활용하여 성능을 2.9%p 향상시켰습니다.
  * **다른 광학 정렬 방법과의 비교**: GPA (56.1%)는 BDL-GAN [14] (54.5%)이나 Fourier Adaptation [33] (52.0%)보다 우수했습니다. GPA는 무작위성과 다양성을 통해 더 넓은 타겟 도메인을 커버합니다.
  * **의사 레이블을 사용한 트립렛 손실**: 타겟 도메인의 의사 레이블을 CTL에 포함했을 때 성능이 53.3%로 감소했습니다. 이는 '어려운 샘플'의 의사 레이블은 신뢰할 수 없다는 것을 시사하며, CTL을 소스 도메인에만 적용하는 것의 타당성을 뒷받침합니다.

## 🧠 Insights & Discussion

본 논문은 이미지 레벨 및 카테고리 레벨의 도메인 시프트를 동시에 해결하는 것이 UDA 시맨틱 세그멘테이션 성능 향상에 결정적임을 명확히 보여줍니다.

* **GPA의 효율성 및 효과성**: 기존의 GAN 기반 방법들이나 주파수 기반 방법들과 달리, GPA는 별도의 학습 없이도 도메인 간의 광학적 차이를 효과적으로 줄여줍니다. 특히 무작위적인 참조 이미지를 통해 정렬된 소스 이미지를 생성함으로써, 학습 모델이 타겟 도메인의 다양한 이미지 조건에 대해 더욱 강건하게 일반화될 수 있도록 돕습니다. 이는 결정론적인 스타일 전이 방법보다 우수한 이유를 설명합니다.
* **CTL의 구별 능력 향상**: 소스 도메인의 신뢰할 수 있는 레이블을 활용하여 카테고리 중심 간의 거리를 명시적으로 벌리는 트립렛 손실은 특히 형태나 질감이 유사하여 혼동하기 쉬운 카테고리들의 구별 능력을 크게 향상시킵니다. '어려운 샘플'에 집중함으로써 모델의 일반화 능력을 높이는 데 기여합니다.
* **TCR의 강건성 강화**: 타겟 도메인에는 레이블이 없기 때문에, 의사 레이블의 신뢰성을 높이는 것이 중요합니다. TCR은 증강된 이미지에 대한 예측이 원본 이미지의 의사 레이블과 일관되도록 강제하여, 의사 레이블의 신뢰도를 높이고 타겟 도메인에서 학습할 수 있는 샘플 수를 실질적으로 증가시킵니다. 이는 특히 'building'이나 'sky'처럼 내부 변동성이 큰 카테고리에 유용합니다.
* **한계 및 시사점**: 카테고리 중심 트립렛 손실을 타겟 도메인의 의사 레이블에 적용하지 않은 결정은 의사 레이블, 특히 '어려운 샘플'에 대한 의사 레이블의 신뢰도 문제를 고려한 현명한 선택으로 판명되었습니다. 이는 실제 비지도 도메인 적응 시 의사 레이블의 품질 관리가 매우 중요함을 시사합니다.

## 📌 TL;DR

* **문제**: 비지도 도메인 적응 시맨틱 세그멘테이션에서 이미지 레벨(광학 조건)과 카테고리 레벨(객체 구성)의 도메인 시프트로 인한 성능 저하를 해결해야 합니다.
* **해결책**: "Coarse-to-Fine" 파이프라인을 제안합니다. Coarse 단계에서는 전역 광학 정렬(GPA)로 이미지 레벨 도메인 정렬을 수행하며, Fine 단계에서는 소스 도메인에 카테고리 중심 트립렛 손실(CTL)을 적용하여 카테고리 간 구별력을 높이고, 타겟 도메인에 자기 지도 일관성 정규화(TCR)를 적용하여 의사 레이블의 안정성과 활용도를 높입니다.
* **결과**: 제안된 방법은 GTA5→Cityscapes 및 SYNTHIA→Cityscapes 벤치마크에서 기존 최첨단 방법들을 크게 능가하는 성능을 달성하며, 이미지 및 카테고리 레벨 도메인 시프트를 동시에 해결하는 것의 중요성을 입증했습니다.
