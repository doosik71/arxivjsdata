{
  "url": "http://arxiv.org/abs/2408.04212v2",
  "title": "Is SAM 2 Better than SAM in Medical Image Segmentation?",
  "authors": "Sourya Sengupta, Satrajit Chakrabarty, Ravi Soni",
  "year": 2024,
  "abstract": "The Segment Anything Model (SAM) has demonstrated impressive performance in\nzero-shot promptable segmentation on natural images. The recently released\nSegment Anything Model 2 (SAM 2) claims to outperform SAM on images and extends\nthe model's capabilities to video segmentation. Evaluating the performance of\nthis new model in medical image segmentation, specifically in a zero-shot\npromptable manner, is crucial. In this work, we conducted extensive studies\nusing multiple datasets from various imaging modalities to compare the\nperformance of SAM and SAM 2. We employed two point-prompt strategies: (i)\nmultiple positive prompts where one prompt is placed near the centroid of the\ntarget structure, while the remaining prompts are randomly placed within the\nstructure, and (ii) combined positive and negative prompts where one positive\nprompt is placed near the centroid of the target structure, and two negative\nprompts are positioned outside the structure, maximizing the distance from the\npositive prompt and from each other. The evaluation encompassed 24 unique\norgan-modality combinations, including abdominal structures, cardiac\nstructures, fetal head images, skin lesions and polyp images across 11 publicly\navailable MRI, CT, ultrasound, dermoscopy, and endoscopy datasets. Preliminary\nresults based on 2D images indicate that while SAM 2 may perform slightly\nbetter in a few cases, it does not generally surpass SAM for medical image\nsegmentation. Notably, SAM 2 performs worse than SAM in lower contrast imaging\nmodalities, such as CT and ultrasound. However, for MRI images, SAM 2 performs\non par with or better than SAM. Like SAM, SAM 2 also suffers from\nover-segmentation issues, particularly when the boundaries of the target organ\nare fuzzy."
}