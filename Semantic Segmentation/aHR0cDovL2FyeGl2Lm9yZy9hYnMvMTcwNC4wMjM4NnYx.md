# Pixelwise Instance Segmentation with a Dynamically Instantiated Network

Anurag Arnab and Philip H.S Torr

## 🧩 Problem to Solve

기존의 컴퓨터 비전 태스크인 **시맨틱 분할(Semantic Segmentation)**은 이미지 내 모든 픽셀에 객체 클래스 레이블을 할당하지만, 동일한 객체의 여러 **인스턴스를 구분하지 못합니다.** 반면 **객체 감지(Object Detection)**는 여러 인스턴스를 바운딩 박스 수준에서 구분하지만, 픽셀 단위의 정밀한 위치 파악은 제공하지 않습니다.

이러한 한계를 극복하기 위해 **인스턴스 분할(Instance Segmentation)**이 등장했지만, 대부분의 기존 인스턴스 분할 방법은 다음과 같은 문제점을 가집니다:

- 객체 감지 파이프라인을 기반으로 하여, **독립적인 영역 제안(region proposals)을 처리**하므로 이미지 전체를 고려하지 못하고 객체 간의 **가려짐(occlusions)을 제대로 처리하지 못합니다.**
- 수많은 제안들이 중첩될 수 있으며, **추가적인 후처리(post-processing) 단계가 필요**하여 비효율적입니다.
- 초기 감지 단계의 품질에 크게 의존하여 **오탐지(false detections)나 부정확한 바운딩 박스(poorly localized bounding boxes) 오류로부터 회복하기 어렵습니다.**

## ✨ Key Contributions

이 논문은 위에서 언급된 문제점들을 해결하기 위한 **동적으로 인스턴스화되는 네트워크 기반의 픽셀 단위 인스턴스 분할 시스템**을 제안하며, 다음과 같은 핵심 기여를 합니다:

- **완전한 종단간(End-to-end) 인스턴스 분할 시스템**: 초기 시맨틱 분할 모듈과 인스턴스 서브네트워크를 포함하며, 전체 파이프라인이 미분 가능하여 종단간 학습이 가능합니다.
- **동적 인스턴스화된 네트워크**: 이미지당 가변적인 수의 인스턴스를 출력하며, 이를 위해 CRFs(Conditional Random Fields)를 동적으로 인스턴스화합니다.
- **후처리 불필요**: 이미지 전체를 고려하여 예측하므로, 제안 기반 방법과 달리 마스크 통합 등의 복잡한 후처리 없이 분할 맵을 직접 생성합니다.
- **오탐지 및 불량 바운딩 박스에 대한 강건성**: 객체 감지기의 출력을 "단서(cue)"로 사용하되, 초기 시맨틱 분할과 CRFs의 에너지 항을 통해 감지 오류나 부정확한 위치 파악에 강건하게 대응합니다.
- **정밀한 분할 성능**: $AP_{r}$ (Average Precision over regions)의 높은 IoU 임계값에서 기존 최신 방법론 대비 상당한 성능 향상을 달성하여, 더 정밀하고 정확한 분할을 제공합니다.
- **시맨틱 분할 성능 향상**: 인스턴스 분할을 위해 네트워크를 미세 조정(finetuning)하는 과정에서 관련된 시맨틱 분할 태스크의 성능 또한 함께 향상됨을 입증합니다.

## 📎 Related Works

- **초기 인스턴스 분할**: Winn과 Shotton [51]은 CRFs의 비대칭 쌍체 포텐셜(asymmetric pairwise potentials)을 사용하여 객체 부분의 공간적 순서를 유지했으며, 양 [54]은 DPM [15]의 감지 출력에 깊이 순서(depth ordering)를 할당하여 가려짐을 해결했습니다.
- **객체 감지 기반 방법**: Hariharan 등 [19]의 SDS(Simultaneous Detection and Segmentation) 이후 R-CNN [16] 파이프라인을 기반으로 많은 연구 [20, 8, 30]가 진행되었습니다. 이들은 바운딩 박스 감지를 세그멘테이션으로 정제하는 방식입니다. 하지만 초기 제안의 품질에 의존하며, 여러 모듈이 다른 목적 함수로 훈련되고 복잡한 후처리가 필요하다는 한계가 있습니다. Dai 등 [12]는 이를 개선하여 종단간 훈련 가능한 네트워크를 제안했고, Liu 등 [37]은 SDS의 종단간 버전을, [32]는 객체 제안을 반복적으로 정제했습니다.
- **객체 감지기 불필요 방법**: Zhang 등 [57, 58]은 MRF 기반으로 이미지 내 모든 인스턴스를 동시에 추론하며 깊이 순서를 예측하여 자동차 인스턴스를 분할했지만, 종단간 학습이 아니었고 최대 인스턴스 개수를 가정했습니다. Romera-Paredes와 Torr [45]는 RNN을 제안했지만 단일 객체 범주에 한정되었습니다. Liang 등 [33]은 시맨틱 분할 네트워크 [6] 기반의 제안 없는 방법을 개발하여 인스턴스 수준 바운딩 박스를 예측하고 스펙트럴 클러스터링을 사용했습니다.
- **CRF를 이용한 시맨틱-감지 결합**: Arnab 등 [3]은 초기 시맨틱 분할 네트워크 [2]와 객체 감지기 출력을 CRF로 결합하여 인스턴스를 추론했지만, 종단간 훈련이 아니었으며 바운딩 박스 위치 오류나 가려짐에 대한 회복력이 부족했습니다.

본 연구는 Arnab 등 [3]의 아이디어를 확장하여, 초기 시맨틱 분할 서브네트워크와 객체 감지기 출력을 종단간 CRF 내의 에너지 항으로 통합하여, 시맨틱 및 인스턴스 분할 성능을 동시에 개선하고 오류 처리 능력을 향상시켰습니다.

## 🛠️ Methodology

제안하는 네트워크는 **시맨틱 분할 서브네트워크**와 **인스턴스 분할 서브네트워크**로 구성되며, 객체 감지기가 주어졌을 때 전체 파이프라인은 완전하게 미분 가능하고 종단간 훈련됩니다.

1. **시맨틱 분할 서브네트워크**:

   - **아키텍처**: FCN8s [38] (VGG [47] ImageNet 모델 기반)를 사용합니다.
   - **CRF 통합**: 이 모듈의 마지막 레이어에는 [26]에서 설명된 稠密 연결(densely-connected) 쌍체 포텐셜을 포함하는 CRF의 평균 필드 추론(mean field inference)이 포함됩니다. 이 CRF는 [60]에서처럼 순환 신경망(RNN)으로 구성됩니다.
   - **고차 감지 포텐셜(Higher Order detection potential)**: [2]에서 설명된 감지 포텐셜을 추가하여, 객체 감지와 분할 간의 일관성을 높이고 감지 점수를 재조정합니다.
   - **출력**: 각 픽셀 $i$가 레이블 $l \in \mathcal{L}$을 가질 확률 $Q_i(l)$을 텐서 $Q$로 출력합니다.

2. **인스턴스 분할 서브네트워크**:

   - **입력**: 시맨틱 분할 예측 $Q$와 $D$개의 객체 감지(각 감지는 $(l_k, s_k, B_k)$ 형태, $D$는 이미지마다 가변적)를 입력으로 받습니다.
   - **CRF 정식화**: 이미지 내 각 픽셀에 대해 다항 확률 변수 $V_i$를 정의하고, $V = [V_1 \ V_2 \ ... \ V_N]^T$를 인스턴스 변수로 사용합니다. 이 변수들은 $\{0, 1, ..., D\}$ 중 하나의 레이블(0은 배경, 1부터 $D$는 감지된 인스턴스)을 가집니다.
   - **에너지 함수**: 할당 $v$에 대한 에너지 $E(V=v)$는 단항 에너지 $U(v_i)$와 쌍체 에너지 $P(v_i, v_j)$의 합으로 구성됩니다:
     $$E(V=v) = \sum_{i} U(v_i) + \sum_{i<j} P(v_i, v_j)$$
   - **단항 에너지 (Unary Potentials)**: 세 가지 항의 합으로 구성됩니다:
     $$U(v_i) = -\ln[w_1\psi_{\text{Box}}(v_i) + w_2\psi_{\text{Global}}(v_i) + w_3\psi_{\text{Shape}}(v_i)]$$
     - **Box 항($\psi_{\text{Box}}$)**: 픽셀 $i$가 감지된 $k$번째 바운딩 박스 $B_k$ 내에 있을 때, 해당 감지의 클래스 확률 $Q_i(l_k)$와 감지 점수 $s_k$에 비례하는 포텐셜을 할당합니다. 박스 외부 픽셀에는 0을 할당합니다.
       $$\psi_{\text{Box}}(V_i=k) = \begin{cases} Q_i(l_k)s_k & \text{if } i \in B_k \\ 0 & \text{otherwise} \end{cases}$$
     - **Global 항($\psi_{\text{Global}}$)**: 바운딩 박스에 의존하지 않고, 픽셀 $i$의 감지된 객체 클래스에 대한 시맨틱 분할 신뢰도 $Q_i(l_k)$에 비례합니다. 바운딩 박스가 객체의 전체 범위를 커버하지 못하는 경우에도 유용합니다.
       $$\psi_{\text{Global}}(V_i=k) = Q_i(l_k)$$
     - **Shape 항($\psi_{\text{Shape}}$)**: 모양 템플릿 $T$를 사용하여 객체의 예상 모양에 대한 사전 정보를 통합합니다. $k$번째 바운딩 박스 $B_k$의 차원에 맞게 템플릿 $\tilde{T}$를 변형하고, 정규화된 교차 상관(normalized cross correlation)을 통해 $Q_{B_k}(l_k)$에 가장 잘 맞는 $t^*$를 선택합니다. 단항 확률과 매칭된 모양 사전 정보의 요소별 곱(Hadamard product $\odot$)을 사용합니다.
       $$t^* = \arg \max_{t \in \tilde{T}} \frac{\sum Q_{B_k}(l_k) \odot t}{\|Q_{B_k}(l_k)\| \|t\|}$$
       $$\psi(V_{B_k}=k) = Q_{B_k}(l_k) \odot t^*$$
   - **쌍체 에너지 (Pairwise Term)**: 稠密 연결 가우시안 포텐셜 [26]로 구성되어 외관 및 공간적 일관성을 촉진합니다. 인접한 픽셀들이 유사한 외관을 가질 때 동일한 객체 인스턴스에 속할 가능성이 높다는 가정을 활용합니다.
   - **추론 (Inference)**: 평균 필드 추론(mean field inference)을 사용하여 Gibbs Energy를 근사적으로 최소화하며, 이 반복 알고리즘은 RNN [60]으로 언롤링(unrolled)되어 네트워크 레이어로 통합됩니다. 이를 통해 인스턴스 분할 네트워크 전체를 종단간 훈련할 수 있습니다.

3. **손실 함수 (Loss Function)**:

   - **레이블 순열 불변성 처리**: 인스턴스 레이블링의 순열에 불변해야 하므로, 예측 $P$와 실제 값 $G$ 간의 IoU(Intersection over Union) 기반으로 "일치된(matched)" 실제 값 $G^*$를 찾습니다. 이는 최대 가중치 이분 매칭(maximum-weight bipartite matching) 문제로 정식화되어 효율적으로 계산됩니다.
   - **크로스-엔트로피 손실**: 일치된 실제 값 $G^*$와 예측 $P$ 사이의 일반적인 크로스-엔트로피 손실 함수를 사용합니다.

4. **네트워크 훈련 (Network Training)**:
   - **사전 훈련(Pretraining)**: 먼저 시맨틱 분할 네트워크를 표준 크로스-엔트로피 손실로 사전 훈련합니다.
   - **미세 조정(Finetuning)**: 사전 훈련된 네트워크에 인스턴스 분할 서브네트워크를 추가하고, 3.4절에서 설명된 인스턴스 분할 손실 함수만을 사용하여 전체 네트워크를 미세 조정합니다. 학습률(learning rate) 감소 및 배치 크기(batch size) 조절, 기울기 클리핑(gradient clipping) 등의 기법을 적용하여 안정적인 훈련을 유도합니다.

## 📊 Results

- **평가 지표**: $AP_{r}$ (Average Precision over regions)와 그 변형인 $AP_{r}^{vol}$ (다양한 IoU 임계값에서 $AP_{r}$의 평균), 그리고 이미지 전체의 일관성을 측정하는 "Matching IoU"를 사용합니다.
- **단항 포텐셜 및 종단간 훈련 효과 (VOC 2012)**:
  - 모든 단항 포텐셜(Box, Global, Shape)은 $AP_{r}^{vol}$ 및 Matching IoU 모두에서 전반적인 인스턴스 분할 성능을 향상시킵니다.
  - 특히 "Global" 항은 높은 $AP_{r}$ 임계값(0.9)에서 "Box" 항보다 뛰어난 개선을 보이며, 이는 바운딩 박스 위치 오류 극복 및 시맨틱 분할의 정확한 예측 활용 덕분입니다.
  - "Shape" 항은 낮은 $AP_{r}$ 임계값에서 성능을 개선하여 가려진 인스턴스를 복구하는 데 도움을 줍니다.
  - 종단간 훈련은 모든 $AP_{r}$ 임계값에서 성능을 향상시키며, "Global" 및 "Shape" 항과 함께 훈련할 때 더 큰 개선을 보입니다.
- **VOC Validation Set 결과**:
  - 제안하는 방법은 기존 최신 방법(MPA [37]) 대비 높은 $AP_{r}$ 임계값(0.7 이상)에서 더 정밀하고 정확한 분할을 달성합니다 (IoU 0.9에서 MPA 대비 6.6%p, 상대적 36% 향상).
  - 최고 $AP_{r}^{vol}$인 57.5%를 달성합니다.
  - MPA (8.7초) 대비 훨씬 빠른 처리 시간(Titan X GPU에서 약 1.5초)을 보여줍니다.
- **SBD Dataset 결과**:
  - 높은 $AP_{r}$ 임계값(0.7)에서 기존 최신 방법(IIS [30]) 대비 1.5%p 향상을 보입니다.
  - $AP_{r}^{vol}$ 측면에서도 3.4%p 상당한 개선을 이룹니다.
  - "Matching IoU" 지표에서 MNC [12] 대비 8.3%p 성능 향상을 달성합니다.
- **시맨틱 분할 성능 향상**:
  - 인스턴스 분할을 위한 미세 조정을 통해 시맨틱 분할 성능이 VOC에서 0.9%p, SBD에서 1%p 향상됨을 확인했습니다. 이는 두 태스크의 밀접한 관련성을 시사합니다.
- **Cityscapes 결과**:
  - Cityscapes 테스트 세트에서 새로운 최신 성능(AP 20.0)을 달성하여 이전 연구들을 크게 앞질렀습니다.

## 🧠 Insights & Discussion

- **전체론적 이미지 처리 및 후처리 불필요**: 제안된 시스템은 전체 이미지를 동시에 추론하고, 별도의 후처리(예: 마스크 통합, 슈퍼픽셀 투영 등) 없이 인스턴스 분할 맵을 자연스럽게 생성합니다. 이는 기존 제안 기반 방법들이 겪는 비효율성과 한계를 극복합니다.
- **객체 감지 오류에 대한 강건성**: 초기 시맨틱 분할 모듈 덕분에 객체 감지기의 오탐지(false positives)나 불량한 바운딩 박스 위치 파악에 대해 강건하게 작동합니다. 시맨틱 분할과 객체 감지 네트워크의 실패 모드가 다르기 때문에 상호 보완적인 이점을 제공합니다.
- **가변적인 출력 인스턴스 수**: 이미지 내 인스턴스 수에 따라 네트워크 출력이 동적으로 변하여, 최대 인스턴스 수를 가정하는 방식의 한계를 해결합니다.
- **시맨틱 및 인스턴스 분할의 상호 개선**: 인스턴스 분할을 위해 네트워크를 미세 조정하는 것이 시맨틱 분할 성능까지 향상시킨다는 점은, 두 태스크가 밀접하게 관련되어 있음을 시사하며 통합 모델의 잠재력을 보여줍니다.
- **한계점**: 객체 감지기는 네트워크와 **공동으로 훈련되지 않습니다.** 또한, 현재 시맨틱 분할 시스템(본 논문의 시스템 포함)이 어려워하는 "자전거", "의자", "식탁", "화분"과 같은 일부 클래스에서는 인스턴스 분할 성능도 낮게 나타납니다. 이는 초기 시맨틱 분할 단계의 한계가 인스턴스 분할에 영향을 미치는 것으로 보입니다.

## 📌 TL;DR

이 논문은 픽셀 단위 인스턴스 분할의 문제(시맨틱 분할의 인스턴스 미인식, 객체 감지의 낮은 정밀도, 기존 인스턴스 분할의 제안 의존성 및 후처리 필요성)를 해결합니다. 핵심 제안은 **초기 시맨틱 분할 모듈과 동적으로 인스턴스화되는 CRF 기반의 인스턴스 서브네트워크로 구성된 종단간 훈련 가능한 시스템**입니다. 이 시스템은 객체 감지 결과를 단서로 활용하되, 잘못된 감지나 부정확한 바운딩 박스에 강건하며, 복잡한 후처리 없이 가변적인 수의 인스턴스를 가진 정확하고 정밀한 분할 맵을 생성합니다. 결과적으로 VOC, SBD, Cityscapes 데이터셋에서 높은 $AP_{r}$ 임계값에서 최신 성능을 달성했으며, 인스턴스 분할 훈련이 시맨틱 분할 성능까지 향상시킴을 입증했습니다.
