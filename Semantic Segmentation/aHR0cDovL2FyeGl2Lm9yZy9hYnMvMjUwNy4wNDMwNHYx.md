# Surg-SegFormer: A Dual Transformer-Based Model for Holistic Surgical Scene Segmentation

Fatimaelzahraa Ahmed, Muraam Abdel-Ghani, Muhammad Arsalan, Mahmoud Ali, Abdulaziz Al-Ali, and Shidin Balakrishnan

## 🧩 Problem to Solve

로봇 보조 수술(RAS)에서 수술 장면의 통합적인 분할은 해부학적 조직, 관절형 도구 및 혈관과 같은 중요 구조를 식별하는 데 필수적입니다. 그러나 다음과 같은 어려움이 존재합니다:

- 수술 중 시간 제약으로 인해 외과 의사가 연수생에게 수술 현장을 실시간으로 상세히 설명하기 어렵습니다.
- 최신 고급 분할 모델(예: AdaptiveSAM)은 수동 프롬프트에 의존하지만, 몇 시간 이상 지속되는 긴 수술 비디오에는 비현실적입니다.
- ISINet, SegNet, Ternaus와 같은 기존의 프롬프트 없는(prompt-free) 모델은 자율적이지만, 작거나 변동성이 큰 객체에 대한 정확도에서 수동 프롬프트 기반 모델에 비해 뒤처지는 경향이 있습니다.
- 따라서 수술 후 분석을 위한 고성능의 자율적인(프롬프트 없는) 수술 장면 분할 모델이 필요합니다.

## ✨ Key Contributions

- **이중 모델 분할 프레임워크:** 로봇 보조 수술(RAS) 장면에서 해부학적 구조와 수술 도구를 전문적으로 분할하는 두 개의 독립적인 모델을 활용하는 프레임워크를 제안합니다.
- **우선순위 가중 조건부 융합 전략:** 두 모델의 출력을 결합하여 전체적인 정확도와 견고성을 향상시키기 위해 중요한 분할 단서에 우선순위를 부여하는 고급 융합 전략을 개발했습니다.
- **벤치마크 데이터셋 종합 평가:** EndoVis2017 및 EndoVis2018 벤치마크 데이터셋에서 제안된 프레임워크의 성능을 검증하여 기존 최첨단(SOTA) 방법보다 우수한 분할 성능을 입증했습니다.

## 📎 Related Works

- **CNN 기반 접근 방식:** U-Net [10]은 의료 영상 분할의 중추가 되었으며, Mask R-CNN [11], DeepLabV3+ [12], SegNet [7], TernausNet [8] 등 다양한 CNN 아키텍처가 계층적 특징 추출 및 멀티스케일 컨텍스트 집계에 중점을 두어 성능을 향상시켰습니다. 그러나 CNN은 수술 장면의 복잡한 특성상 장거리 종속성 및 전역 컨텍스트를 포착하는 데 어려움이 있습니다.
- **트랜스포머 기반 및 하이브리드 모델:** 최근 연구는 전역 관계 모델링에 자기 어텐션을 사용하는 트랜스포머 기반 설계로 전환되고 있습니다. 특히 SegFormer [9]는 경량 계층적 트랜스포머 인코더와 효율적인 MLP 디코더를 결합하여 SOTA 성능을 달성했습니다.
- **프롬프트 기반 vs. 프롬프트 없는 패러다임:**
  - **프롬프트 기반 모델:** Segment Anything Model (SAM) [13]과 같이 마스크 생성을 위해 사용자 입력(점, 바운딩 박스, 텍스트)을 필요로 합니다. 인상적인 제로샷 기능을 제공하지만, 장시간의 수술 비디오에서는 수동 프롬프트가 비실용적입니다.
  - **프롬프트 없는 모델:** ISINet [6], SegNet, TernausNet과 같이 훈련 후 자율적으로 작동하며 외부 신호 없이 마스크를 생성합니다. 확장성이 더 좋지만, 정확도 면에서는 프롬프트 기반 모델에 비해 뒤처지는 경향이 있었습니다.

## 🛠️ Methodology

저자들은 두 개의 SegFormer 인스턴스를 활용하고 그 출력을 융합하는 이중 모델 프레임워크인 Surg-SegFormer를 제안합니다.

1. **모델 개요:**

   - **SegAnatomy:** 해부학적 구조 분할에 특화되도록 SegFormer B2 아키텍처를 미세 조정합니다. (SegFormer B2는 해부학적 구조 분할에서 가장 높은 mIoU 및 Dice 점수를 달성했습니다.)
   - **SegTool:** 수술 도구 분할을 위해 SegFormer B5 인코더를 사용하고, 정보 손실을 줄이고 작은 객체의 공간 정보를 보존하기 위해 스킵 연결을 통합한 맞춤형 경량 디코더를 채택합니다.
     - **맞춤형 디코더 구성 요소:**
       - **균일 채널 투영 및 업샘플링:** 각 인코더 특징 맵 $X^{(i)}$는 선형 투영 $x_i = \text{Proj}_i(X^{(i)})$을 통해 균일한 채널 차원으로 투영된 후 가장 높은 해상도로 업샘플링됩니다.
       - **멀티스케일 특징 융합:** 업샘플링된 특징들($x^{\text{up}}_1, x^{\text{up}}_2, x^{\text{up}}_3$)과 가장 높은 해상도 특징($x_4$)을 단일 텐서로 연결하여 다양한 크기의 객체 분할을 위한 정보를 보존합니다.
       - **밀집 스킵 연결:** 디코딩 과정 전반에 걸쳐 초기 단계의 미세한 디테일을 재방문하여 작고 복잡한 구조에 초점을 맞추는 모델의 능력을 향상시킵니다.
   - **우선순위 기반 조건부 융합 전략:** 두 SegFormer 모델 인스턴스의 출력을 OR 연산을 통해 융합합니다. 이는 특정 영역이 두 모델 중 하나에 의해 식별되면 최종 분할에 포함되도록 보장합니다. 특히 도구가 해부학적 구조를 가릴 수 있는 경우, 신뢰도 점수를 기반으로 분할에 우선순위를 부여하며 다음과 같은 조건을 따릅니다:
     $$C(x,y) = \begin{cases} M_{\text{inst}}(x,y) & \text{if } P_{\text{inst}} > P_{\text{anat}} \text{ or } M_{\text{anat}}(x,y) = 0 \\ M_{\text{anat}}(x,y) & \text{otherwise} \end{cases}$$
     여기서 $C(x,y)$는 최종 분할 마스크의 픽셀 $(x,y)$를 나타내며, $M_{\text{inst}}$와 $M_{\text{anat}}$는 각각 도구 및 해부학 모델의 예측입니다. $P_{\text{inst}}$와 $P_{\text{anat}}$는 각 모델의 신뢰도 점수입니다. 추가적으로, 중복 영역의 경계를 다듬고 모호성을 해결하기 위해 형태학적 연산을 적용하는 후처리 단계를 거칩니다.

2. **실험 설정:**
   - **하드웨어:** 로컬 NVIDIA RTX4090 및 클라우드 기반 NVIDIA V100-32G GPU.
   - **프레임워크:** PyTorch.
   - **최적화:** Adam 옵티마이저, 가중치 감쇠 $10^{-4}$, 학습률 $5 \times 10^{-6}$.
   - **학습 스케줄러:** 순환 학습률 스케줄러.
   - **배치 크기:** 4.
   - **에포크:** 100.
   - **손실 함수:** 배경 영역과 작고 복잡한 도구 영역 사이의 클래스 불균형을 해결하기 위해 Tversky Loss [14]와 Cross-Entropy Loss [15]를 통합한 결합 손실 함수를 사용합니다.
     $$ \text{Combined Loss} = \alpha \cdot \text{TverskyLoss} + (1-\alpha) \cdot \text{CELoss} $$
        여기서 $\alpha=0.7, \beta=0.3$으로 설정하여 오탐(false negatives)에 더 높은 벌칙을 부여함으로써 봉합 바늘이나 도구 끝과 같은 섬세한 구조의 분할을 향상시켰습니다.
   - **데이터 증강:** 색상 분포를 보존하고 분할 정밀도를 유지하는 뒤집기, 자르기, 회전과 같은 기하학적 증강을 적용했습니다.

## 📊 Results

Surg-SegFormer는 EndoVis2017 [17] 및 EndoVis2018 [18] 데이터셋에서 평가되었으며, 다음과 같은 주요 결과를 보였습니다.

- **전반적인 성능 (Table II):**

  - **EndoVis2017 (도구 유형):** mIoU 0.54, Dice 0.56을 달성하여 U-Net (0.49/0.51) 및 재학습된 SegFormer (0.41/0.42)를 능가했습니다. 프롬프트 기반 AdaptiveSAM (0.72)보다는 낮았습니다.
  - **EndoVis2018 (전체 장면 분할, Task 1):** mIoU 0.80, Dice 0.89를 달성하며 **최첨단(SOTA) 성능**을 경신했습니다. MedT (0.64/0.68) 및 AdaptiveSAM (0.65/0.69)를 크게 앞질렀습니다.
  - **EndoVis2018 (도구 유형 분할, Task 2):** mIoU 0.64, Dice 0.66으로 경쟁력 있는 성능을 보였으며, 재학습된 SegFormer (0.46/0.47) 및 U-Net (0.57/0.60)을 능가했지만 Surgical-SAM (0.80) 및 MATIS (0.77)에는 약간 못 미쳤습니다.

- **클래스별 성능:**

  - **EndoVis2017 (Table III):** Ultrasound Probe (0.87)와 Monopolar Curved Scissors (0.69)와 같은 미세 도구에서 가장 높은 IoU를 기록했습니다. Bipolar Forceps (0.24) 및 Prograsp Forceps (0.16)에서는 낮은 점수를 보였는데, 이는 시각적 다양성 부족과 클래스 간 모호성에 기인합니다.
  - **EndoVis2018 Task 1 (Table IV):** 10개 라벨 중 8개에서 가장 높은 mIoU를 달성했습니다. 특히 Robotic Instrument Part (0.70), Covered Kidney (0.64), 그리고 매우 얇은 Suturing Needle (0.98 - 거의 완벽)에서 상당한 차이를 보였습니다. Kidney Parenchyma (0.45)에서도 모든 기준선을 능가했습니다. Small Intestine (0.72)에서는 MedT (0.78)에 비해 상대적 우위가 낮았습니다.
  - **EndoVis2018 Task 2 (Table V):** 7개 도구 중 5개에서 상위 3위 안에 들었으며, Suction Instrument (0.83)에서 선두를 차지하고 Clip Applier (0.93)와 거의 동등한 성능을 보였습니다. EndoVis2017과 유사하게 Prograsp Forceps (0.13) 및 Large Needle Driver (0.09)에서는 낮은 IoU를 보였습니다.

- **성능 일관성:** Surg-SegFormer는 단일 벤치마크에서는 뛰어나지만 다른 벤치마크에서는 저조한 기존 기준선들과 달리 두 데이터셋 전반에서 더 균형 잡힌 성능 프로필을 보였습니다. 이는 해부학적으로 복잡하거나 시각적으로 어려운 장면에서 Surg-SegFormer가 강점을 나타냄을 의미합니다.

## 🧠 Insights & Discussion

Surg-SegFormer는 로봇 보조 수술에서 해부학적 구조와 수술 도구 모두에 대한 정확하고 자동화된 이해를 제공함으로써 전문가 외과 의사의 교육 부담을 크게 줄이고, 수련의들이 복잡한 수술 환경을 독립적으로 효과적으로 이해할 수 있도록 지원합니다.

- **모델의 강점:**

  - **프롬프트 없는 자율성:** 수동 프롬프트, 대규모 모델 또는 과도한 후처리 없이 높은 분할 정확도를 달성하여 긴 수술 비디오에 대한 실용성과 확장성을 강조합니다.
  - **이중 분기 인코더:** 조직과 금속성 특징에 각각 특화되어 혼잡한 프레임에서 오탐을 줄이고 중첩된 세그먼트를 효과적으로 처리함으로써 높은 정확도를 이끌어냅니다.
  - **우선순위 가중 융합 규칙:** 두 모델의 예측을 효과적으로 결합하여 최종 분할의 견고성을 보장합니다.
  - **하이브리드 손실 함수:** Tversky Loss와 Cross-Entropy Loss의 결합은 배경 우세 및 클래스 불균형 문제를 효과적으로 해결하며, 특히 봉합 바늘과 같은 작고 복잡한 객체에 대한 분할 정확도를 향상시킵니다.
  - **맞춤형 디코더:** SegTool의 맞춤형 디코더는 다운샘플링으로 인한 정보 손실을 완화하여 작은 수술 도구의 미세한 디테일을 효과적으로 보존합니다.
  - **광범위한 일반화 능력:** EndoVis2017 및 EndoVis2018 데이터셋 모두에서 강력하고 일관된 성능을 보여, 다양한 수술 환경에 대한 모델의 견고한 일반화 능력을 입증합니다.

- **한계 및 향후 연구:**
  - 일부 클래스(예: Bipolar Forceps, Prograsp Forceps, Large Needle Driver)에서는 시각적 유사성, 클래스 간 모호성 또는 훈련 데이터 부족으로 인해 성능이 상대적으로 낮았습니다.
  - Small Intestine 분할 시 정반사 및 빠른 연동 운동과 같은 문제는 여전히 모델에 도전 과제로 남아 있습니다.
  - 향후 연구에서는 동적 손실 가중치 스키마나 Focal Tversky Loss를 탐색하여 고도로 불균형한 데이터셋에서 분할 견고성을 더욱 향상시킬 수 있습니다.

## 📌 TL;DR

로봇 보조 수술 장면 분할에서 기존 모델의 수동 프롬프트 의존성 및 정확도 한계를 해결하기 위해, 본 논문은 프롬프트 없는 **Surg-SegFormer**를 제안합니다. 이 모델은 해부학적 구조를 위한 SegAnatomy와 수술 도구를 위한 SegTool이라는 두 가지 SegFormer 기반 모델을 사용하여 이중으로 분할합니다. SegTool은 작은 객체의 공간 정보를 보존하기 위해 스킵 연결을 갖춘 맞춤형 경량 디코더를 포함합니다. 두 모델의 출력은 우선순위 가중 조건부 융합 전략과 클래스 불균형에 강한 Tversky-Cross-Entropy 혼합 손실 함수를 통해 결합됩니다. 결과적으로 Surg-SegFormer는 EndoVis2018 데이터셋에서 mIoU 0.80을 달성하며 최첨단 성능을 기록했고, 특히 미묘한 구조(예: 봉합 바늘) 분할에서 뛰어난 능력을 보였습니다. 이는 수동 프롬프트 없이도 복잡한 수술 장면을 이해하는 데 강력하고 효율적인 솔루션을 제공하며, 외과 교육 부담을 경감시키는 데 기여합니다.
