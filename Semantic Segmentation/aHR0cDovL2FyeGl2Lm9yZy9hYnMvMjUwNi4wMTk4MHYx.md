# Surgical Foundation Model Leveraging Compression and Entropy Maximization for Image-Guided Surgical Assistance

Lianhao Yin, Ozanan Meireles, Guy Rosman, Daniela Rus

## 🧩 Problem to Solve

의료 분야, 특히 최소 침습 수술(MIS)에서 실시간 비디오 이해는 환자 안전과 수술 효율성 향상에 매우 중요합니다. 하지만 기존 지도 학습(supervised learning) 방식은 대규모의 고품질 주석(annotation) 데이터셋을 필요로 하는데, 의료 분야에서는 데이터 희소성, 프라이버시 문제, 그리고 주석 작업의 높은 비용과 전문성 요구로 인해 이러한 데이터셋을 확보하기가 매우 어렵습니다. 기존의 자기 지도 학습(self-supervised learning) 방법론은 이러한 데이터 부족 문제를 일부 해결할 수 있지만, 수술 비디오에 내재된 구조적, 물리적 정보를 효과적으로 포착하고 다양한 작업에 걸쳐 일반화하는 데는 한계가 있었습니다. 또한, 대부분의 수술 컴퓨터 비전(CV) 모델이 일반 이미지 데이터로 사전 학습된 백본(backbone)을 사용하기 때문에 수술 이미지 특유의 미세하고 중요한 정보에 대한 편향이 발생한다는 문제도 존재합니다.

## ✨ Key Contributions

- **압축 및 엔트로피 최대화 기반 자기 지도 학습 프레임워크 C2E 제안:** 콜모고로프 복잡도(Kolmogorov complexity)와 엔트로피 최대화(entropy maximization) 원리를 활용하여 수술 비디오로부터 압축되고 정보가 풍부한 시각적 표현(representation)을 학습하는 새로운 자기 지도 학습 프레임워크인 Compress-to-Explore (C2E)를 개발했습니다.
- **효율적인 인코더-디코더 아키텍처:** 잠재 압축 트랜스포머 아키텍처를 설계하고, 자동 인코더 내에서 효율적으로 잠재 압축 표현을 얻기 위한 학습 방법을 제시했습니다. 특히 엔트로피를 최대화하는 디코더는 임상적으로 중요한 세부 정보를 보존하면서 이미지를 압축하여 레이블링된 데이터 없이도 인코더 성능을 향상시킵니다.
- **광범위한 일반화 및 Few-shot 학습 능력 입증:** 대규모의 비레이블링 수술 비디오 데이터셋(2122건의 수술, 0.78M 이미지)으로 사전 학습된 C2E는 수술 워크플로우 분류, 도구-조직 상호작용 분류, 분할(segmentation), 진단 등 다양한 수술 ML 작업에서 최신(SOTA) 모델 대비 우수한 성능을 보였습니다. 특히, 소수의 데이터(few-shot)만으로도 강력한 일반화 능력을 입증하여 새로운 수술 절차에 대한 적용 가능성을 보여주었습니다.
- **내부 표현의 우수성:** 모델의 내부 압축 표현이 수술 유형, 단계, 도구 등 의료 관련 개념의 특징을 더 잘 분리(disentangle)한다는 것을 정량적 및 정성적 분석(t-SNE, Saliency maps)을 통해 입증했습니다. 이는 C2E가 수술 비전 파운데이션 모델로서의 잠재력을 높이는 핵심 요소입니다.

## 📎 Related Works

본 논문은 다양한 관련 연구 분야의 최신 동향을 참고했습니다.

- **자기 지도 파운데이션 모델 (Self-supervised foundation models):**
  - **불변성 기반(Invariance-based) 방법:** SimSiam, JEPA(Joint Embedding Predictive Architecture)와 같은 대조 학습(contrastive learning) 방식을 포함하며, 이미지의 로컬(local) 및 글로벌(global) 특징 학습 균형의 중요성을 강조합니다.
  - **생성 모델(Generative models):** VAE(Variational AutoEncoder), MAE(Masked AutoEncoder), Diffusion 모델 등이 있으며, 본 논문은 MAE의 사전 학습 방식을 차용하여 발전시켰습니다.
- **정보 기반(Information-based) 접근 방식:** 콜모고로프 복잡도, 총 코딩률 최대화(Total Coding Rate Maximization) 등 정보 이론적 개념을 컴퓨터 비전 및 딥러닝 모델 설계에 적용한 연구들을 언급합니다.
- **에너지 기반(Energy-based) 접근 방식:** 신경망의 합성성(compositionality)과 일반화 능력 향상을 위해 에너지 기반 모델을 생성 모델 프레임워크에 통합하려는 시도들을 다룹니다.
- **수술 컴퓨터 비전 (Surgical Computer Vision):** 수술 영상 분석에서 분할(segmentation), 탐지(detection), 추적(tracking), 워크플로우 추정(workflow estimation), 예측(prediction) 등 다양한 작업에 대한 기존 연구들을 검토하며, 자기 지도 학습 기반의 비전 파운데이션 모델이 이 분야를 혁신하고 있음을 강조합니다.

## 🛠️ Methodology

C2E는 MAE(Masked AutoEncoder)의 기본 구조를 채택하여, 마스킹되지 않은 이미지 패치를 사용하여 마스킹된 부분을 예측하는 자동 인코더 방식으로 작동합니다. 핵심은 인코더와 디코더의 구조를 혁신하여 "압축 인코더"와 "탐색 디코더"로 재설계한 것입니다.

1. **압축 인코더 (Compression Encoder):**
    - **목표:** 입력 이미지 $I$를 압축되고 정보가 풍부하며 분리된(disentangled) 잠재 공간 $Z_0 \in \mathbb{R}^{N,C}$로 변환합니다. 여기서 $N$은 패치 수, $C$는 요소 수입니다.
    - **콜모고로프 복잡도 최대화:** 각 압축 단계에서 입력과 은닉 상태 간의 콜모고로프 복잡도 차이 $(K(Z) - K(I))$를 최대화하도록 정식화합니다. 이는 정보 이론적으로 엔트로피 차이 $\text{max}_{\theta} (-H(Z) + H(I))$를 최대화하는 것과 유사하며, 최종적으로 $-\frac{1}{2} \text{ln}|\Sigma_Z|$ 항을 최소화하는 문제로 귀결됩니다 (Theorem 1, 2).
    - **차원 축소 강제:** 각 인코더 블록 프로젝션 전에 일정한 차원을 제거하여 잠재 공간의 차원 축소를 명시적으로 강제합니다 (Theorem 4).
    - **반복 최적화:** 최적화 문제를 해결하기 위해 반복 수축-임계값 알고리즘(iterative shrinkage-thresholding algorithms)을 사용하며, 각 단계에서 다음 업데이트 식을 적용합니다:
        $$ Z_{i+\frac{1}{2}} = Z_{i+1} - \beta Z_{i+1} (Z_{i+1}^T Z_{i+1})^{-1} $$
        이는 콜모고로프 복잡도를 최소화합니다 (Theorem 3).
    - **선형 투영 및 바이패스 항:** $Z_{i+\frac{1}{2}}$를 부분 공간 $Z_i$로 투영하기 위해 선형 피드포워드 레이어를 적용하며, 잔차 연결(residual connection)과 유사한 바이패스 항을 추가하여 정보 및 기울기 전파를 용이하게 합니다:
        $$ Z_i = Z_{i+\frac{1}{2}} + P Z_{i+\frac{1}{2}} $$
        여기서 $P^T P = \Pi$ (대각 행렬)는 압축을 최대화합니다 (Theorem 5).

2. **탐색 디코더 (Exploration Decoder):**
    - **목표:** 인코더의 역 과정으로, 엔트로피를 최대화하여 원본 이미지를 재구성합니다.
    - **에너지 기반 모델:** 엔트로피 최대화의 해는 에너지 함수 $E(z)$ 형태로 표현되는 폐쇄형 해를 가지며, 디코더는 이 에너지 함수 기반 신경망을 사용하여 일반화 능력을 향상시킵니다.
    - **랑제뱅 동역학(Langevin dynamics) 기반 샘플링:** 숨겨진 상태를 샘플링하기 위해 다음과 같은 랑제뱅 동역학을 사용합니다:
        $$ \hat{Z}_i = \hat{Z}_{i-1} + \epsilon \nabla \log p(\hat{Z}_i) + \sqrt{2\epsilon}\omega_i, \quad \omega_i \sim N(0,I) $$
        확률 분포 $p(z)$는 $p(z) \propto e^{-\frac{1}{E[E(z)]}E(z)}$ 형태로 에너지 함수에 비례하며, $E[E(z)]$는 온도 $kT(h)$에 비례합니다.
    - **재구성 및 조건부 온도:** 인코더의 역 투영 과정을 결합하여 재구성을 수행하며, 온도는 잠재 상태 $Z_0$의 부분 요소 $h=E_c(Z_0, \beta)$에 의해 조건화됩니다 (Theorem 6).

3. **사전 학습 (Pre-training):**
    - **데이터셋:** Cholec80, hsdb-instrument, HeiCo 등 다양한 공개 수술 비디오 데이터셋과 Massachusetts General Hospital (MGH)의 사설 일반 수술 비디오 데이터셋을 통합하여 구성되었습니다. 총 2122건의 수술에서 추출된 0.78M(78만)개의 이미지 프레임을 사용했습니다.
    - **데이터 전처리:** 원본 비디오에서 초당 1프레임(1 fps)을 추출하고, deduplication([68]) 및 CLIP 기반 이미지 품질 평가([69])를 통해 중복을 제거하고 고품질 이미지만을 선별하여 데이터셋의 다양성을 최대화했습니다. 다운스트림 작업에 사용될 이미지는 데이터 유출(data leakage) 방지를 위해 사전 학습에서 제외했습니다.
    - **손실 함수:** 예측된 이미지($\hat{I}$)와 원본 이미지($I$) 간의 평균 절대 오차(MAE)를 최소화하는 방식으로 학습을 진행하여, 전반적인 학습 파이프라인은 표준 MAE와 동일하게 작동합니다.

## 📊 Results

C2E는 85.22M개의 매개변수를 가진 인코더를 사용하여 다양한 수술 ML 작업에서 강력한 성능과 일반화 능력을 입증했습니다.

- **수술 워크플로우 예측:** Cholec80 데이터셋(7단계)에서 92.5%의 정확도를 달성하여 SurgFormer(92.4%) 및 LoViT(91.5%)와 같은 기존 최신 방법들을 능가했습니다.
- **외과 의사 행동 예측:** CholecT45 데이터셋을 사용하여 도구, 조직, 도구-조직 상호작용 등 다중 삼중항(triplet) 분류에서 우수한 평균 정밀도(mAP)를 보여주었습니다. 특히, mAP$_{ivt}$에서 41.8을 달성하여 MT4MTL(37.1) 및 LAM(35.9)보다 뛰어난 성능을 보였습니다.
- **수술 이미지 분할:** CholecSeg8k 데이터셋에서 0.74 IoU(Intersection over Union)를 기록하여 S-SAM(0.71) 및 LoRA of SAM(0.65) 등 최신 분할 모델을 능가했습니다. 시각적 비교에서도 C2E의 분할 결과가 실제(ground truth)와 더 작은 차이를 보였습니다.
- **수술 중 용종 진단:** PolypDiag 데이터셋에서 94.0%의 정확도를 달성하여 EndoSSL(91.3%) 및 EndoFM(90.7%)을 포함한 여러 관련 연구 대비 가장 높은 성능을 보여주었습니다.
- **Few-shot 학습 능력:** VIT 모델과의 비교를 통해, C2E는 적은 수의 데이터(예: 2개 또는 8개 비디오)만으로도 다양한 수술 절차(담낭절제술, 직장결장절제술 등)에서 일관되게 VIT보다 우수한 성능을 보여주며, 새로운, 레이블링이 부족한 수술 절차에 대한 강력한 일반화 가능성을 입증했습니다.
- **표현 통찰 (Representation Insights):**
  - t-SNE 시각화 결과(그림 4, 5, 6)는 C2E가 수술 유형, 단계, 도구 등 의료 관련 개념의 특징을 MAE/VIT보다 훨씬 더 명확하게 분리하고 응집된 클러스터를 형성함을 보여주었습니다.
  - 살리언시 맵(Saliency maps) 분석(그림 7)에서는 C2E가 더 압축된 활성화 맵을 가지며, 각 헤드의 주의 영역이 상호 보완적이고 겹치지 않아 지역적 세부 정보와 전역적 정보를 균형 있게 학습하고 있음을 시사했습니다.

## 🧠 Insights & Discussion

본 연구에서 제안된 C2E 모델은 정보 압축과 엔트로피 최대화 원리를 활용하여 신경망의 표현력을 크게 향상시켰습니다. 이러한 사전 학습된 백본(backbone)은 수술 워크플로우 예측, 로봇 행동 분석, 분할, 진단 등 다양한 수술 인공지능(AI) 분야의 다운스트림 작업에서 매우 유망한 성능을 보였습니다.

가장 중요한 통찰력은 C2E가 학습된 표현의 본질에 있습니다. 모델의 내부 압축 표현은 수술 이미지 내의 다양한 구조적 부분(예: 특정 도구, 수술 단계, 조직 유형)으로부터 특징들을 더 잘 분리(disentangle)합니다. 이러한 분리 능력은 모델이 적은 양의 레이블링된 데이터(few-shot learning)만으로도 새로운 작업이나 미지의 수술 절차에 대해 효과적으로 일반화할 수 있음을 의미합니다.

이는 수술 비디오의 고품질 주석이 프라이버시 문제와 높은 작업량으로 인해 제한적이라는 현실을 고려할 때 매우 중요합니다. C2E와 같은 자기 지도 학습 파운데이션 모델은 향후 다양한 다운스트림 작업에 필요한 레이블링 양을 현저히 줄여줄 수 있습니다. 궁극적으로, 이는 수술 중 모니터링 작업의 품질을 향상시키고, 수술 합병증을 줄이며, 환자 치료의 질을 높이는 데 기여할 것으로 기대됩니다.

## 📌 TL;DR

- **문제:** 수술 비디오 분석은 필수적이지만, 의료 데이터의 희소성과 주석의 어려움으로 인해 기존 지도 학습 및 자기 지도 학습 모델의 일반화 능력이 제한적입니다.
- **제안 방법:** 본 연구는 콜모고로프 복잡도 기반의 압축 인코더와 엔트로피 최대화 기반의 탐색 디코더를 결합한 새로운 자기 지도 학습 프레임워크인 **Compress-to-Explore (C2E)**를 제안합니다. C2E는 수술 비디오에서 압축되고 정보가 풍부하며 분리된 시각적 표현을 학습합니다.
- **주요 결과:** 대규모의 비레이블링 수술 비디오 데이터셋으로 사전 학습된 C2E는 워크플로우 분류, 도구-조직 상호작용, 분할, 진단 등 **다양한 수술 AI 다운스트림 작업에서 기존 최신 모델보다 우수한 성능**을 달성했습니다. 특히, 소수의 데이터(few-shot)만으로도 뛰어난 학습 및 **새로운 수술 절차에 대한 강력한 일반화 능력**을 입증하여, 의료 데이터의 희소성 문제를 해결하고 수술 AI의 임상적 적용 가능성을 크게 높였습니다.
