# Distributed Iterative Gating Networks for Semantic Segmentation
Rezaul Karim, Md Amirul Islam, Neil D. B. Bruce

## 🧩 Problem to Solve
최신 딥러닝 기반 의미론적 분할(semantic segmentation) 모델(주로 Fully Convolutional Networks)은 높은 수준의 성능을 달성했지만, 다음과 같은 몇 가지 한계를 가지고 있습니다.
*   **공간 해상도 손실:** 네트워크가 깊어질수록 공간 해상도가 감소하여 세부적인 공간 정보를 유지하기 어렵습니다. 이는 픽셀 단위 레이블링에서 공간적인 세밀함의 손실을 초래합니다.
*   **제한된 공간적 범위:** 컨볼루션의 특성상 각 레이어에서 고려할 수 있는 픽셀 또는 피처의 공간적 범위가 제한됩니다. 깊은 레이어의 피처는 더 넓은 공간을 커버하지만, 국부적인 일관성을 해칠 수 있습니다.
*   **범주적 모호성:** 중간 레이어의 피처는 특정 범주 경계에서는 식별 능력이 있을 수 있지만, 다른 범주에서는 모호성을 가질 수 있습니다. 이러한 모호성은 초기 순방향 패스에서 발생하며, 더 식별력이 있는 깊은 레이어의 정보를 역방향으로 전달하여 해소할 필요가 있습니다.
이러한 문제들을 해결하기 위해 신경망 내에서 정보 흐름을 효율적으로 제어하고, 가벼운 적응형 계산 제어 메커니즘을 제공하는 방법이 필요합니다.

## ✨ Key Contributions
이 논문은 의미론적 분할을 위한 효율적인 피드백 라우팅 메커니즘을 기반으로 하는 분산 반복 게이팅(Distributed Iterative Gating, DIGNet)이라는 정형화된 구조를 제안하며 다음과 같은 핵심 기여를 합니다.
*   **캐스케이드 피드백 생성:** DIGNet은 상위 레이어의 모든 정보를 암묵적으로 전달하는 캐스케이드(cascaded) 방식으로 피드백 신호를 생성하는 전파 게이트(propagator gates)를 도입합니다. 이는 기존의 피드백 메커니즘(해당 단계의 출력 또는 이전 단계의 피드백만 사용하는 방식)보다 효과적입니다.
*   **적응형 피처 변조:** 변조 게이트(modulator gates)를 통해 피드백 신호를 바탕으로 선택된 중간 단계의 문맥적 피처를 재가중(re-weighting)하여 순방향 활성화를 제어합니다.
*   **순환적 반복 개선:** 이 메커니즘의 반복적인(순환적인) 특성은 출력과 내부 표현을 점진적으로 개선하고, 공간적으로 모호하지 않고 전역적으로 일관된 예측을 생성합니다.
*   **우수한 성능 및 빠른 수렴:** 제안된 접근 방식은 순방향(feed-forward) 베이스라인 및 다른 순환 피드백 기반 접근 방식에 비해 PASCAL VOC 2012, COCO-Stuff, ADE20K와 같은 도전적인 데이터셋에서 픽셀 단위 레이블링 문제에서 뛰어난 성능을 보이며, 반복 추론이 매우 빠르게 수렴함을 입증합니다.
*   **경량 메커니즘:** 피드백 신호를 순방향 아키텍처에 통합하여 순환 컨볼루션 신경망과 유사하게 적응형 계산을 제어하는 경량 메커니즘을 제공합니다.

## 📎 Related Works
*   **Fully Convolutional Network (FCN) 기반의 의미론적 분할:** [35, 6, 37, 1, 12, 20, 32, 7]과 같은 최신 SOTA 모델들은 FCN 구조를 따르지만, 높은 레이어에서 생성되는 피처 맵은 의미론적 표현은 강하지만 공간 해상도 저하로 인해 정확한 공간 세부 정보 유지에 한계가 있습니다.
*   **반복적 개선(Iterative Improvement) 및 피드백 메커니즘:**
    *   출력 정제를 위한 순환 모듈 사용: [51, 36, 39, 22, 23, 29, 27, 46]은 순방향 네트워크의 출력을 반복적으로 개선하는 방법을 제안했습니다.
    *   순환 처리 또는 피드백 기반 어텐션: [39, 31, 48, 24, 21]은 순환 처리, [29]는 피드백 기반 어텐션 메커니즘을 CNN과 결합합니다.
    *   상향식(bottom-up) 순방향 네트워크와 하향식(top-down) 변조 네트워크를 통합하여 객체 탐지를 수행한 TDM [42]과 같은 정제(refinement) 기반 인코더-디코더 구조 [32, 37, 20, 40]도 있습니다.
*   **하이퍼컬럼 표현 (Hypercolumn Representation):** [15]는 다양한 깊이의 피처를 결합하여 풍부한 공간적 및 의미론적 정보를 얻는 하이퍼컬럼 아이디어를 제안했습니다. DIGNet은 피드백 신호를 압축하여 '압축된 하이퍼컬럼(compact hypercolumn)' 표현을 생성하는 것으로 설명됩니다.

## 🛠️ Methodology
DIGNet은 기존 순방향 신경망 백본(예: ResNet101-FCN)을 확장하여 `전파 게이트(propagator gate)`와 `변조 게이트(modulator gate)`라는 두 가지 유형의 게이팅 모듈을 추가하여 효율적인 피드백 메커니즘을 구현합니다. 이 네트워크는 순환적 반복 방식으로 작동하며, `T`번의 반복 추론을 수행합니다.

1.  **DIGNet 아키텍처:**
    *   **순방향 백본 ($f^{\theta}_{i}$):** 입력 이미지를 처리하여 피처 표현을 생성하는 일반적인 컨볼루션 네트워크입니다.
    *   **전파 게이트 ($G^{p}_{k}$):**
        *   고수준 정보를 캐스케이드 방식으로 상위 레이어에서 하위 레이어로 피드백으로 전파합니다.
        *   수식: $F_i = \hat{y}(W_c * ((W_a * f_i) \oplus (W_b * F_{i+1})))$
            *   $F_{i+1}$: 이전 전파 게이트로부터의 피드백 신호 (상위 레이어의 정보).
            *   $f_i$: 현재 중간 단계의 하향식(bottom-up) 피처.
            *   $W_a, W_b$: $3 \times 3$ 컨볼루션 및 ReLU를 적용하여 $f_i$와 $F_{i+1}$을 각각 $f'_i$와 $F'_{i+1}$로 변환합니다.
            *   $\oplus$: 변환된 피처 맵을 채널 방향으로 연결(concatenation)합니다.
            *   $W_c$: $1 \times 1$ 컨볼루션을 적용하여 결합된 피처 맵을 융합하고 채널 차원을 축소하여 새로운 피드백 신호 $F_i$를 생성합니다.
            *   $\hat{y}$: 다음 하향식 피처 맵 $f_{i-1}$의 공간 해상도가 $F_i$보다 높을 경우, $F_i$를 bilinear interpolation으로 업샘플링하여 해상도를 맞춥니다.
    *   **변조 게이트 ($G^{m}_{i}$):**
        *   전파 게이트로부터 받은 피드백 신호 $F_i$를 바탕으로 하향식(bottom-up) 활성화의 흐름을 변조합니다.
        *   $F_i$를 먼저 $f_{(i-1)}$와 동일한 채널 차원으로 처리합니다.
        *   $F_i$에 대해 공간 피라미드 풀링(Spatial Pyramid Pooling, {1, 3, 5, 7} 풀링 비율)을 적용하여 전역 문맥 정보를 포함한 $F'_i$를 얻습니다.
        *   $F'_i$에 $1 \times 1$ 컨볼루션과 시그모이드를 순차적으로 적용하여 변조 신호 $F_s$를 생성합니다.
        *   최종적으로 $F_s$를 이전 순방향 단계 $f_{(i-1)}$와 원소별 곱셈(element-wise multiplication)으로 결합하여 변조된 하향식 피처 맵 $f'_{(i-1)}$을 다음 순방향 단계로 전달합니다.

2.  **반복 추론 과정 (Algorithm 1 참고):**
    *   `T=1` (첫 번째 반복): 변조 게이트가 순방향 정보의 바이패스를 허용하여 네트워크가 일반적인 순방향 네트워크처럼 작동합니다.
    *   `T>1` (후속 반복):
        *   **피드백 전파 (하향식):** 모든 전파 게이트($G^{p}_{k}$)가 활성화되어 마지막 레이어의 초기 예측부터 시작하여 캐스케이드 방식으로 피드백 신호를 생성합니다. $F_k = G_k^p(F_{k+1}, f_k)$ (여기서 $F_n = f_n$는 마지막 단계의 피처).
        *   **피드백 변조를 통한 순방향 처리 (상향식):** 변조 게이트($G^{m}_{i}$)가 활성화되어 전파 게이트로부터 받은 피드백 신호 $F_i$를 사용하여 이전 순방향 단계로부터 받은 피처 표현 $f_{(i-1)}$를 변조하여 다음 단계로 전달합니다. $f'_{(i-1)} = G_i^m(F_i, f_{i-1})$.
    *   손실 함수는 오직 $T$번째 단계의 최종 예측에만 적용됩니다. (중간 예측에 대한 의미론적 감독은 사용하지 않음)
    *   실험에서는 성능과 계산 비용의 균형을 위해 주로 $T=2$로 설정했습니다.

## 📊 Results
DIGNet은 PASCAL VOC 2012, ADE20K, COCO-Stuff 세 가지 도전적인 의미론적 분할 데이터셋에서 기존 베이스라인 및 다른 순환 모델 대비 우수한 성능을 입증했습니다.

*   **PASCAL VOC 2012:**
    *   **검증 세트 (Table 4):** ResNet101-DIGNet (OS=8)이 77.5% mIoU를 달성하여 DeepLabv2-ResNet101 베이스라인(74.9%)을 크게 상회합니다.
    *   **테스트 세트 (Table 5):** DIGNet은 80.7% mIoU를 달성하여 복잡한 최적화(배치 정규화 파라미터 훈련, 대규모 데이터셋 사전 훈련, 다중 손실 함수 결합 등) 없이도 경쟁력 있는 성능을 보여줍니다.
*   **ADE20K (Table 6):** ResNet101-DIGNet (8s)은 36.9% mIoU를 달성하여 ResNet101-FCN (33.6%)보다 약 3.3%, DeepLab-Res101 (35.3%)보다 약 1.6% 높은 성능을 보였습니다.
*   **COCO-Stuff10k (Table 7):** ResNet101-DIGNet은 베이스라인 대비 2.7%(32s) 및 2.9%(8s) mIoU 향상을 보이며, DeepLabv2-DIGNet도 베이스라인 대비 1.8% mIoU 향상을 달성했습니다.

*   **설계 선택의 영향 (Table 2, 3):**
    *   **캐스케이드 피드백의 효과 (Table 2):** 단계별 피드백이나 마지막 레이어 피드백에 비해 캐스케이드 방식으로 피드백을 생성했을 때 분할 성능이 크게 향상되었습니다.
    *   **반복 횟수 (Table 2):** 성능은 반복 횟수(T)가 증가함에 따라 점진적으로 향상되다가 (T=2에서 최고점), 이후 포화되는 경향을 보이며 빠른 수렴과 안정성을 나타냅니다.
    *   **게이팅 범위 (Table 3):** 더 많은 피드백 전파(특히 초기 레이어 포함)를 통합할수록 분할 품질이 점진적으로 개선됩니다.

*   **오류 수정 능력 (정성적 결과):**
    *   **범주적 모호성 해결 (Fig. 4):** 초기 클래스 할당이 잘못된 경우 (예: 말을 소로 분할), DIGNet은 첫 반복에서부터 잘못된 예측을 수정합니다.
    *   **부분 분할 개선 (Fig. 5):** 초기 예측이 거친 또는 공간적으로 제한된 마스크를 가질 때, DIGNet은 피드백 메커니즘의 분산 게이팅을 통해 부분 분할을 개선하고 세부적인 마스크를 생성하며, 때로는 객체의 누락된 부분을 완성합니다.
    *   **누락된 작은 객체 복구 (Fig. 6):** 큰 객체 앞에 있는 작은 객체를 초기 예측이 놓치는 경우, DIGNet은 중간 피처 맵을 포함한 캐스케이드 피드백을 통해 누락된 작은 객체를 복구할 수 있습니다.
    *   **점진적 정제 (Coarse-to-Fine Refinement) (Fig. 7):** 계층적으로 전파 및 변조 게이트를 추가하면서 예측 품질이 점진적으로 향상되고, 공간 세부 정보를 복구하며 범주적 모호성을 해결합니다.

## 🧠 Insights & Discussion
*   **정보 흐름의 효율성:** DIGNet은 깊은 레이어와 초기 레이어 사이에 존재하는 의미론적 특이성 및 해상도 격차를 효과적으로 연결합니다. 이는 하이퍼컬럼 표현과 유사하게, 이전 단계의 피드백 신호가 모든 후속 처리 단계로부터 필요한 가이드를 받아 초기 오류를 수정할 수 있도록 합니다.
*   **적응형 피처 학습:** 반복적인 특성을 통해 피처 표현이 점진적으로 정제되고, 특히 공간적으로 분리된 식별 피처로 인해 발생하는 범주적 모호성을 해소하는 데 도움을 줍니다.
*   **계산 효율성:** 피드백 신호가 블록 단위 압축을 통해 차원 축소를 거쳐 "압축된 하이퍼컬럼(compact hypercolumn)" 표현을 생성하는 전략은 계산 비용과 성능 면에서 모두 효율적입니다.
*   **빠른 수렴:** 몇 번의 반복(주로 $T=2$)만으로도 성능이 빠르게 수렴한다는 점은 피드백 메커니즘이 오류 수정 신호를 효율적으로 전달하고 네트워크 전체에 걸쳐 정보를 넓게 전달하는 데 매우 효과적임을 시사합니다.
*   **한계점:** 대부분의 경우 일관된 성능 향상을 보이지만, 초기 예측에서 전경 객체가 주변 배경과 시각적으로 유사한 특징을 공유하는 드문 경우에는 잘못된 레이블링으로 이어질 수 있습니다 (예: 비행기 그림자의 일부가 배경으로 흡수되는 경우). 이는 두 클래스에 대한 확신도가 매우 유사할 때 발생할 수 있으며, 이 경우 피드백이 잘못된 방향으로 작용하여 객체를 억제할 수 있음을 보여줍니다.

## 📌 TL;DR
**문제:** 기존 의미론적 분할 네트워크는 순방향 처리로 인해 공간적 세부 정보 손실과 중간 레이어의 범주적 모호성 문제를 겪습니다.
**방법:** 본 논문은 순환적 피드백 구조인 DIGNet(Distributed Iterative Gating Network)을 제안합니다. DIGNet은 '전파 게이트'를 통해 깊은 레이어에서 얕은 레이어로 캐스케이드 방식의 압축된 피드백 신호를 생성하고, '변조 게이트'를 통해 이 피드백을 바탕으로 중간 피처를 적응적으로 재가중하여 순방향 활성화를 제어합니다.
**결과:** 이 반복적인 상향식 피드백 메커니즘은 범주적 모호성을 해결하고, 공간적 세부 정보를 정제하며, 누락된 작은 객체를 복구하여 의미론적 분할 성능을 크게 향상시킵니다. 여러 데이터셋에서 베이스라인 대비 우수한 성능을 달성했으며, 빠른 수렴을 보여줍니다.