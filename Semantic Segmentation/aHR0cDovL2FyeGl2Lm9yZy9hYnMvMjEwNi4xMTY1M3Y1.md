# A Curriculum-style Self-training Approach for Source-Free Semantic Segmentation

Yuxi Wang, Jian Liang, and Zhaoxiang Zhang

## 🧩 Problem to Solve

의미론적 분할(Semantic Segmentation)은 컴퓨터 비전의 핵심 과제이지만, 픽셀 단위 주석이 달린 대규모 훈련 데이터셋을 구축하는 것은 비용과 시간이 많이 소요됩니다. 이 문제를 해결하기 위해 도메인 적응(Domain Adaptation, DA)이 제안되었으나, 대부분의 기존 DA 방법은 레이블된 원본(source) 데이터를 훈련 과정에 필요로 합니다.

그러나 자율 주행이나 얼굴 인식과 같은 민감한 시나리오에서는 데이터 보호 및 지적 재산권 문제로 인해 원본 데이터에 접근할 수 없습니다. 이 논문은 원본 데이터 없이 미리 훈련된 원본 모델만 사용하여 대상(target) 도메인에 적응하는 **원본 데이터 없는 도메인 적응(Source-Free Domain Adaptation, SFDA)**이라는 훨씬 더 도전적인 문제 설정을 다룹니다.

이 설정에서 기존의 특징 정렬(feature alignment) 기법은 불가능하며, 원본 전용 모델에서 생성된 의사 레이블(pseudo-labels)은 신뢰할 수 없어 자기 학습(self-training) 방식이 노이즈에 취약해지는 문제가 있습니다.

## ✨ Key Contributions

* **커리큘럼 스타일 자기 학습(Curriculum-style Self-training, ATP)** 프레임워크를 제안하여 원본 데이터 없는 도메인 적응 의미론적 분할을 해결합니다. 이는 다음을 포함합니다:
  * **커리큘럼 스타일 특징 정렬(Curriculum-style Feature Alignment)**: 쉬운 샘플부터 어려운 샘플까지 자신감 있는 예측을 유도하여 암묵적인 지식 전이(implicit knowledge transfer)를 수행합니다.
  * **상보적 커리큘럼 스타일 자기 학습(Complementary Curriculum-style Self-training)**: 예측 불확실성이 높은 픽셀에 대한 **음성 의사 레이블(Negative Pseudo-Labeling)**과 신뢰도 높은 픽셀에 대한 **양성 의사 레이블(Positive Pseudo-Labeling)**을 모두 활용하여 모델을 훈련합니다.
* 대상 도메인 내의 도메인 내 불일치(intra-domain discrepancy)를 추가로 줄이기 위한 **정보 전파(Information Propagation) 체계**를 제안하며, 이는 도메인 적응 분야의 표준 후처리 방법으로 활용될 수 있습니다.
* 원본 모델의 예측값만 사용 가능한 더 도전적인 **블랙박스 원본 모델(Black-box Source Model)** 시나리오로 제안된 방법을 확장하여 성공적인 성능을 보였습니다.
* 합성-실제(synthetic-to-real) 및 악천후(adverse conditions) 데이터셋에서 최첨단(state-of-the-art, SOTA) 교차 도메인 결과를 달성했으며, 원본 데이터에 접근 가능한 도메인 적응 방법과 비견되는 성능을 보였습니다.

## 📎 Related Works

* **비지도 도메인 적응(UDA)**: 레이블된 원본 도메인의 지식을 레이블되지 않은 대상 도메인으로 전이하는 것을 목표로 합니다. 불일치 기반(discrepancy-based), 적대적 기반(adversarial-based), 재구성 기반(reconstruction-based) 방법론으로 나뉩니다.
* **도메인 적응 의미론적 분할(DASS)**: 픽셀 단위 예측을 위한 UDA의 응용 분야입니다. 이미지, 특징, 출력 레벨에서 도메인 불일치를 줄이는 적대적 학습 기반 방법과 신뢰할 수 있는 의사 레이블을 생성하는 자기 지도 학습 기반 방법이 있습니다.
* **원본 데이터 없는 도메인 적응(SFDA)**: 원본 데이터셋에 접근하지 않고 도메인 적응 문제를 해결합니다. 기존 연구는 생성 모델을 통한 샘플 합성, 불확실성 감소, 데이터 증강, 과거 모델 예측 활용, 양성/음성 레이블링(LD) 등을 사용했습니다. 특히 블랙박스 SFDA는 원본 모델의 예측만 사용하는 더 어려운 설정입니다.
* **준지도 의미론적 분할(SSL)**: 소량의 레이블 데이터와 대량의 레이블 없는 데이터를 함께 사용하여 훈련합니다. 적대적 기반 및 일관성 기반(consistency-based) 방법이 주류입니다.
* **커리큘럼 학습(CL)**: 인간이 쉬운 샘플부터 배우고 점차 어려운 샘플로 나아가는 과정을 모방합니다. C-SFDA, CurricuDA, PyCDA 등 DASS에 적용된 사례가 있습니다.

## 🛠️ Methodology

제안하는 ATP(A Curriculum-style Self-training Approach for Source-Free Semantic Segmentation) 프레임워크는 그림 1에 나타나 있으며, 크게 세 단계로 구성됩니다.

1. **커리큘럼 특징 정렬 (Curriculum Feature Alignment)**
    * 원본 데이터 없이 명시적인 특징 정렬이 불가능하므로, **가설 전이(hypothesis transfer)** 아이디어를 통해 분류기($g_t$)를 원본 모델의 분류기($g_s$)로 고정($g_t = g_s$)하고 특징 추출기($f_t$)만 훈련하여 암묵적으로 대상 특징을 원본 특징 분포에 맞춥니다.
    * **커리큘럼 스타일 엔트로피 최소화 손실($L_{cel}$)**을 도입하여 쉬운 샘플(낮은 엔트로피)에 먼저 초점을 맞추고 점진적으로 어려운 샘플(높은 엔트로피)을 처리합니다.
        $$L_{cel} = \alpha * (1 - h(x_t))^\gamma * h(x_t)$$
        여기서 $h(x_t)$는 엔트로피 맵을 나타내며, $\alpha$와 $\gamma$는 각각 예측의 확실성/불확실성의 중요성과 확실한 샘플의 가중치를 조절하는 하이퍼파라미터입니다.
    * **가중치 다양성 증진 손실($L_{div}$)**을 사용하여 모델이 쉬운 클래스에만 집중하여 발생하는 퇴행적인 솔루션을 방지하고 모든 카테고리를 포함하는 전역적 다양성을 확보합니다.
        $$L_{div} = - \sum_{c=1}^C \hat{p}_{(h,w,c)}^{x_t} \log \hat{p}_{(h,w,c)}^{x_t}$$
        여기서 $\hat{p}_{(h,w,c)}^{x_t}$는 엔트로피에 기반하여 가중치가 부여된 대상 이미지의 평균 출력 임베딩입니다.

2. **상보적 커리큘럼 자기 학습 (Complementary Curriculum Self-training)**
    * **음성 의사 레이블링($L_{npl}$)**: 이전 자기 지도 학습 방법에서 무시되었던 낮은 신뢰도의 예측(높은 불확실성 영역)을 활용합니다. 특정 픽셀이 *어떤 클래스에 속하지 않는지*를 명확하게 지시하는 정보를 제공합니다.
        $$\delta(p_{(h,w,c)}^{x_t}) = \begin{cases} 1 & \text{if } p_{(h,w,c)}^{x_t} < \lambda_{neg} \\ 0 & \text{otherwise} \end{cases}$$
        $$L_{npl} = - \frac{1}{n_t} \sum_{i=1}^{n_t} \sum_{j=1}^{H \times W} \sum_{c=1}^C \delta(p_{(i,j,c)}^{x_t}) \log(1 - p_{(i,j,c)}^{x_t})$$
    * **양성 의사 레이블링($L_{ppl}$)**: 높은 신뢰도의 예측을 바탕으로 의사 레이블을 생성합니다. 쉬운 클래스에 대한 편향을 줄이기 위해 카테고리별 동적 임계값($\lambda_c$)을 사용하여 의사 레이블을 할당합니다.
        $$L_{ppl} = - \frac{1}{n_t} \sum_{i=1}^{n_t} \sum_{j=1}^{H \times W} \sum_{c=1}^C \hat{y}_{(i,j,c)}^t \log p_{(i,j,c)}^{x_t}$$
    * 최종 상보적 자기 학습 목적 함수: $L_{cst} = L_{ppl} + L_{npl}$.

3. **정보 전파 (Information Propagation)**
    * 도메인 내 불일치를 줄이기 위한 후처리 단계입니다. 대상 데이터를 엔트로피 순위($r(x_t)$)에 따라 쉬운 분할($X_{te}$)과 어려운 분할($X_{th}$)로 나눕니다.
    * 쉬운 분할을 레이블된 데이터로, 어려운 분할을 레이블 없는 데이터로 간주하는 준지도 학습 방식으로 접근합니다.
    * ClassMix [88]와 같은 증강 전략을 어려운 분할에 적용하고, 쉬운 분할과 어려운 분할 간의 **의미론적 대조 손실($L_{scl}$)**을 사용하여 모델을 정규화합니다.
        $$L_{scl} = - \sum_{c \in C} \sum_{r_{c}^{th} \sim R_{c}^{th}} \log \frac{\exp(r_{c}^{th} * r_{c}^{te} / \tau)}{\sum_{r_{c}^{te} \sim R_{c}^{te}} \exp(r_{c}^{th} * r_{c}^{te} / \tau)}$$
        여기서 $r_{c}^{th}$와 $r_{c}^{te}$는 각각 어려운/쉬운 분할 이미지의 클래스 $c$에 대한 정규화된 표현을 나타냅니다.
    * 최종 정보 전파 목적 함수: $L_{ssl} = L_{ce}(M_t(x_{te}), \hat{y}_{te}) + L_{scl}$.

4. **블랙박스 원본 모델 확장 (Extension for Black-box Source Model)**
    * 원본 모델의 파라미터에 접근할 수 없는 경우, **지식 증류(Knowledge Distillation, KD)**를 사용하여 원본 모델의 소프트 예측을 대상 모델로 전이합니다.
        $$L_{kd} = E_{x_t \in X_t} D_{kl}(f_s \circ g_s(x_t); f_t \circ g_t(x_t))$$
        여기서 $D_{kl}$은 Kullback-Leibler 발산 손실입니다.
    * 이후 제안된 상보적 자기 학습 전략과 정보 전파를 적용합니다.

## 📊 Results

* **GTA5→Cityscapes 및 SYNTHIA→Cityscapes**: ResNet-101 백본에서 각각 52.6% 및 57.9% mIoU를 달성하여 비적응 기준선(non-adaptation baseline) 대비 큰 성능 향상을 보였습니다. 기존 원본 데이터 없는 방법론(SFDA, URMA, SFUDA, HCL)을 큰 폭으로 능가했습니다. 심지어 원본 데이터에 접근하는 전통적인 도메인 적응 방법과도 견줄만한 또는 더 우수한 성능을 보여 ATP의 효과를 입증했습니다. Transformer 기반 백본(MiT-B5, P2T-Base)에서도 SOTA 성능을 달성했습니다.
* **Cityscapes→ACDC (악천후)**: ResNet-101 및 MiT-B5 백본에서 안정적인 성능 향상을 보이며 SOTA를 달성했습니다.
* **Cityscapes→Cross-City**: 사소한 도메인 변화가 있는 경우에도 (Rome, Rio, Tokyo, Taipei) 최상의 성능을 보여 방법의 효과를 입증했습니다.
* **이미지 인식 태스크(VisDA-C, OfficeHome)**: ResNet-101 및 ResNet-50 백본에서 기존 SOTA 방법론(C-SFDA, PLUE, NRC++)과 견줄만한 결과를 달성하여 방법의 일반화 가능성을 입증했습니다.
* **블랙박스 원본 모델 시나리오**: 원본 모델의 예측만으로도 45.3% mIoU 성능을 달성하여, 기존 원본 데이터 의존 또는 원본 데이터 없는 도메인 적응 방법과 비견될 만한 결과를 보였습니다. 데이터 증강(Color Jitter, Gaussian Blur)을 적용하면 성능이 더욱 향상됩니다.
* **기여 요소 분석(Ablation Study)**: 각 구성 요소($L_{cel}$, $L_{div}$, $L_{ppl}$, $L_{npl}$, $L_{ssl}$)가 단계적으로 성능을 향상시키는 것을 확인하여 제안된 각 모듈의 효과를 검증했습니다.
* **파라미터 민감도 분석**: 커리큘럼 스타일 엔트로피 손실의 하이퍼파라미터($\alpha, \gamma$) 및 음성 의사 레이블 임계값($\lambda_{neg}$)에 대해 비교적 강건함을 보였습니다. 분류기를 고정하는 가설 전이 전략이 중요함을 확인했습니다.
* **시각화**: 제안된 방법이 원본 데이터 없이도 더 적은 스퓨리어스(spurious) 영역으로 신뢰할 수 있는 분할 마스크를 생성하며, 각 단계가 픽셀 수준 정확도에 기여함을 시각적으로 보여주었습니다.

## 🧠 Insights & Discussion

* ATP는 원본 데이터에 대한 의존성 없이도 효과적인 지식 전이가 가능함을 입증했습니다. 이는 데이터 프라이버시 및 지적 재산권 보호가 중요한 현실 시나리오에서 매우 실용적인 해결책을 제시합니다.
* 커리큘럼 학습 접근 방식은 기존 자기 학습의 한계인 의사 레이블의 불신뢰성 문제를 효과적으로 완화합니다. 특히, 음성 의사 레이블링은 기존에 무시되었던 낮은 신뢰도 예측으로부터 **보완적인 정보**를 추출하여 결정 경계 학습에 기여한다는 점에서 중요한 통찰을 제공합니다.
* 정보 전파 단계는 대상 도메인 내의 잔존하는 불일치를 효과적으로 줄여주며, 이는 도메인 적응 모델의 성능을 추가로 향상시키는 일반적인 후처리 모듈로 활용될 수 있음을 시사합니다.
* 블랙박스 원본 모델 설정에서의 성공적인 적응은 ATP의 유연성과 다양한 실제 환경에서의 적용 가능성을 높입니다.
* 다양한 백본 네트워크(CNN 및 Transformer 기반)와 여러 도메인 적응 시나리오(합성-실제, 악천후, 사소한 도메인 변화)에서 일관적으로 우수한 성능을 보임으로써, 제안 방법의 **강건성과 일반화 능력**을 강력히 입증합니다.

## 📌 TL;DR

원본 데이터 없는 의미론적 분할 도메인 적응 문제(SFDA)를 해결하기 위해, 논문은 **ATP**라는 커리큘럼 스타일 자기 학습 프레임워크를 제안한다. ATP는 **커리큘럼 특징 정렬**을 통해 쉬운 샘플부터 자신감 있는 예측을 유도하고, **상보적 자기 학습**을 통해 음성 및 양성 의사 레이블을 모두 활용한다. 또한, **정보 전파**를 통해 대상 도메인 내 불일치를 줄이는 후처리 단계를 포함한다. 이 방법은 원본 데이터에 접근하지 않고도 SOTA 성능을 달성했으며, 블랙박스 원본 모델 시나리오에도 효과적임을 입증하여 데이터 접근이 제한적인 환경에서 중요한 진전을 이뤘다.
