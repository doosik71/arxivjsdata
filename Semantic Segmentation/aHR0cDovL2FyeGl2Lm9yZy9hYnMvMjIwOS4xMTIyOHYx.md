# NamedMask: Distilling Segmenters from Complementary Foundation Models

Gyungin Shin, Weidi Xie, Samuel Albanie

## 🧩 Problem to Solve

이 연구의 목표는 훈련 중 픽셀 수준의 레이블 접근 없이 이미지 영역을 분할하고 이름을 부여하는 것입니다. 기존의 기반 모델(Foundation Models)인 CLIP과 DINO는 이 작업에 있어 상호 보완적인 강점과 함께 한계점을 가집니다:

* **CLIP**은 이미지 콘텐츠에 이름을 부여하는 능력은 탁월하지만, 객체의 구조에 대한 접근 가능한 표현이 부족합니다.
* **DINO**는 객체의 공간적 범위를 포착하는 능력은 뛰어나지만, 객체 이름에 대한 지식이 없습니다.
의미론적 분할(Semantic Segmentation)은 픽셀 수준의 주석이 필수적이지만, 이는 매우 비용이 많이 드는 작업입니다 (예: 품질 관리 포함 이미지당 1.5시간). 기존의 MaskCLIP이나 ReCo와 같은 접근 방식은 주석 없이 또는 카테고리 이름만으로 작업할 때 분할 품질이나 정밀한 객체 분할에 어려움을 겪는 한계가 있습니다.

## ✨ Key Contributions

* **NamedMask 프레임워크 제안:** 픽셀 수준 주석 없이 CLIP과 DINO의 상호 보완적인 강점을 활용하여 객체를 분할하고 명명하는 새로운 프레임워크인 NamedMask를 제안합니다.
* **광범위한 실험:** 언어-이미지 사전 훈련을 활용하는 기존 의미론적 분할 방법들에 비해 NamedMask가 가져온 성능 향상을 광범위한 실험을 통해 입증합니다.
* **마스크 품질 및 다중 객체 분할 개선:** 카테고리별 전문가(expert) 분할기 및 copy-paste 증강 기법이 마스크 품질 및 다중 객체 이미지 분할 성능을 크게 향상시킴을 보여줍니다.

## 📎 Related Works

* **비지도 의미론적 분할 (Unsupervised Semantic Segmentation):** 레이블 없이 독창적인 학습 목표(예: 기대-최대화, 상호 정보 최대화, 제안 대조, 특징 대응 증류 등)를 통해 의미론적 분할을 수행하는 연구들입니다. 이 방법들은 언어-이미지 사전 훈련이나 훈련 중 대상 카테고리 목록을 사용하지 않으며, 종종 이름 부여를 위해 적은 수의 레이블된 이미지 세트를 필요로 합니다.
* **언어-이미지 모델을 이용한 주석 없는 의미론적 분할 (Annotation-free Semantic Segmentation):**
  * **MaskCLIP (Zhou et al., 2022):** CLIP의 제로샷 전이(zero-shot transfer) 능력을 활용하여 페어링된 데이터 없이 의미론적 분할을 수행합니다.
  * **ReCo (Shin et al., 2022):** CLIP을 사용하여 레이블 없는 이미지를 개념 예제로 큐레이션한 다음, 공동 분할(co-segmentation) 알고리즘을 적용하여 의미론적 분할 훈련 데이터를 파생합니다. NamedMask는 ReCo 프레임워크를 기반으로 하지만, ReCo의 불안정한 공동 분할 메커니즘을 대체합니다.
* **비지도 돌출 객체 검출 (Unsupervised Salient Object Detection):** 사람의 주석 없이 전경 객체를 분할하는 것을 목표로 하는 연구들입니다.
  * **SelfMask (Shin et al., 2022):** DINO 특징에 대한 스펙트럼 클러스터링을 기반으로 하는 비지도 돌출 객체 검출 방법입니다. NamedMask는 SelfMask를 견고한 카테고리-불가지론적(category-agnostic) 분할기로 활용합니다.

## 🛠️ Methodology

NamedMask는 네 단계의 시퀀스로 훈련됩니다:

1. **동적 아카이브 구축 (Dynamic Archive Construction):**
    * 주어진 목표 카테고리 목록에 대해, CLIP의 이미지 인코더($\phi_I$)와 텍스트 인코더($\phi_T$)를 사용하여 레이블 없는 이미지 컬렉션 $U$에서 각 카테고리 $c$에 대한 이미지 아카이브를 큐레이션합니다.
    * $\phi_I(x_i)$와 $\phi_T(c)$의 유사도가 가장 높은 상위 $k$개 이미지를 선택하여 $A_c$를 구성합니다.
2. **마스크 생성 (Mask Generation - Category-agnostic):**
    * 각 아카이브 내 이미지 $x_i$에 대해 SelfMask (DINO에서 부트스트랩된 비지도 돌출 객체 검출기) $\psi_s$를 사용하여 카테고리-불가지론적 돌출 맵 $y_i = \psi_s(x_i)$를 예측합니다.
    * 각 돌출 맵에 해당 아카이브의 카테고리 레이블 $c$를 할당합니다.
3. **카테고리 전문가를 통한 마스크 정제 (Mask Refinement through Category Experts):**
    * 이전 단계에서 생성된 마스크는 카테고리 불가지론적이므로, 각 카테고리 $c$에 특화된 "전문가(expert)" 분할기 $\psi_c$를 훈련하여 마스크를 정제합니다.
    * $\psi_c$는 각 아카이브 $A_c$ 내의 이미지에 대해 픽셀 수준의 "one-vs-all" 이진 분류 작업(카테고리 $c$ vs. 배경)으로 훈련됩니다.
    * $\psi_c$의 예측은 카테고리 $c$에 대한 정제된 의사(pseudo) 마스크로 사용됩니다.
    * 카테고리 수가 많을 경우(예: ImageNet-S), CLIP 텍스트 임베딩에 k-means 클러스터링을 적용하여 카테고리 그룹을 만들고, 각 그룹에 대한 전문가를 훈련하여 계산 비용을 줄입니다.
4. **NamedMask 훈련 (Training NamedMask):**
    * 정제된 이미지 아카이브와 의사 레이블을 사용하여 표준 의미론적 분할 아키텍처(예: DeepLabv3+ with ResNet50 백본, DINO 사전 훈련으로 초기화)를 교차 엔트로피 손실(cross-entropy loss)로 훈련합니다.
    * Copy-paste 데이터 증강 기법을 적용하여 다중 객체 이미지에 대한 일반화 성능을 향상시킵니다.

## 📊 Results

* **어블레이션 연구 (Ablation Study):**
  * **아카이브 크기:** 카테고리당 더 많은 이미지를 사용할수록(최대 500개) 분할기 성능이 단조롭게 향상됩니다.
  * **카테고리 전문가:** VOC2012 벤치마크에서 카테고리 전문가가 SelfMask(카테고리-불가지론적)보다 모든 카테고리에서 일관되게 우수한 분할 마스크를 생성합니다.
  * **카테고리 전문가 수:** ImageNet-S$_{300}$에서 전문가를 사용하는 것이 SelfMask보다 높은 점수를 보이며, 전문가 수가 30개 이상일 때 성능이 포화되는 경향을 보입니다. 이는 이미지 다양성과 카테고리 그룹 내 의미론적 관련성 간의 균형을 나타냅니다.
  * **Copy-Paste 증강:** copy-paste 증강을 사용하면 다중 객체 분할 성능이 VOC2012에서 4.1 mIoU 향상됩니다.
* **최신 기술과의 비교:**
  * **COCO, CoCA, Cityscapes$_{obj}$:** NamedMask는 "name-only transfer" 설정에서 MaskCLIP과 ReCo를 크게 능가합니다.
  * **PASCAL VOC2012:** NamedMask(mIoU 59.2)는 기존 SLOWP(ReCo: 34.2) 및 USS(MaskDistill: 45.8) 방법들을 상당히 뛰어넘습니다.
  * **대규모 ImageNet-S 벤치마크 (ImageNet-S$_{50}$, ImageNet-S$_{300}$, ImageNet-S$_{919}$):** NamedMask는 "name-and-image transfer" 설정에서 기존 USS 및 SLOWP 방법들보다 각각 15.5, 14.7, 11.9 mIoU 더 높은 mIoU를 달성하며 일관되게 우수한 성능을 보입니다.

## 🧠 Insights & Discussion

* **의미:** NamedMask는 CLIP의 명명 능력과 DINO의 구조적 이해를 효과적으로 결합하여 픽셀 수준 주석 없이도 고품질의 의미론적 분할을 달성합니다. 이는 주석 비용이라는 주요 병목 현상을 해결하는 데 기여합니다. 카테고리별 전문가와 copy-paste 증강의 사용은 성능에 결정적인 역할을 합니다.
* **한계점:**
    1. 이전에 고려되지 않은 새로운 카테고리를 포함하려면 분할기를 재훈련해야 합니다. 향후 연구에서는 CLIP의 공유 임베딩 공간에서 직접 임베딩을 예측하여 훈련 중 보지 못한 카테고리에 대한 제로샷 명명 기능을 개발할 수 있습니다.
    2. 주로 객체 의미론적 분할에 초점을 맞추고 있으며, 물, 하늘 등 "stuff" 카테고리를 분할하기 위한 단서가 부족합니다.
    3. 기반 모델(CLIP, DINO)의 편향을 상속받을 가능성이 있어, 실세계 배포 시 추가적인 고려와 완화 메커니즘이 필요합니다.
* **중요성:** NamedMask는 주석 없는 의미론적 분할의 경계를 확장하며, 다양한 응용 분야에 대한 확장 가능한 방법론을 제공합니다. 동시에 강력한 컴퓨터 비전 기술의 이중 사용(dual-use) 가능성도 인지하고 있습니다.

## 📌 TL;DR

NamedMask는 픽셀 수준 주석 없이 이미지 영역을 분할하고 명명하기 위한 프레임워크입니다. CLIP의 명명 능력과 DINO의 객체 구조 포착 능력을 상호 보완적으로 활용하여 객체 분할기를 증류합니다. 이 방법은 CLIP으로 카테고리별 이미지 아카이브를 구축하고, DINO 기반의 비지도 객체 검출기로 마스크를 생성하며, 카테고리별 전문가 분할기로 마스크를 정제한 후, 최종적으로 정제된 마스크와 copy-paste 증강을 사용하여 표준 분할 모델을 훈련합니다. 결과적으로 NamedMask는 VOC2012, COCO, ImageNet-S를 포함한 여러 벤치마크에서 기존의 비지도 및 약한 사전 학습 기반 방법들보다 훨씬 뛰어난 성능을 보였습니다.
