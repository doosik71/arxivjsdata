# Segmenter: Transformer for Semantic Segmentation

Robin Strudel, Ricardo Garcia, Ivan Laptev, Cordelia Schmid

## 🧩 Problem to Solve

시맨틱 분할(Semantic Segmentation)은 이미지 내의 각 픽셀을 해당 객체 범주 레이블로 분류하는 컴퓨터 비전 문제로, 자율 주행, 로봇 공학 등 다양한 응용 분야에 중요합니다. 기존의 합성곱 신경망(CNN) 기반 방법(예: FCN, DeepLab)은 필터의 **지역적 특성**으로 인해 **전역적(global) 문맥 정보**를 효과적으로 포착하기 어렵다는 한계가 있습니다. 이로 인해 클래스 내 다양성, 문맥 변화, 가려짐 등으로 인한 모호성 때문에 정확한 픽셀 단위 레이블링에 어려움이 있습니다. 특정 레이어에서 확장된 수용 필드(receptive field)나 어텐션 메커니즘을 추가하는 방식은 CNN의 본질적인 한계를 보완하기 위한 복잡한 해결책이었습니다.

## ✨ Key Contributions

* **순수 트랜스포머 기반 시맨틱 분할 모델 제안:** 합성곱(convolution)을 사용하지 않는 Vision Transformer (ViT) 기반의 Segmenter 모델을 제안하여, 설계상 초기 계층부터 전역 문맥 정보를 효과적으로 포착하고 기존 FCN 기반 접근 방식을 능가합니다.
* **다양한 해상도 모델 제공:** 정확도와 런타임 간의 절충을 가능하게 하는 다양한 해상도(패치 크기)를 가진 모델 제품군을 제시합니다.
* **마스크 트랜스포머 디코더 개발:** 학습 가능한 클래스 임베딩을 통해 클래스 마스크를 생성하는 트랜스포머 기반 디코더를 제안하며, 이는 간단한 선형 디코더보다 성능이 우수하고 인스턴스/파노프틱 분할 등 더 일반적인 이미지 분할 작업으로 확장 가능합니다.
* **최첨단 성능 달성:** ADE20K 및 Pascal Context 데이터셋에서 최첨단(state-of-the-art) 결과를 달성하고, Cityscapes 데이터셋에서도 경쟁력 있는 성능을 보여줍니다.

## 📎 Related Works

* **시맨틱 분할 (Semantic Segmentation):**
  * FCN(Fully Convolutional Networks) 및 인코더-디코더 아키텍처 [21, 36, 39, 40, 1, 4, 34, 41, 43].
  * Dilated/atrous convolutions [8, 33, 59]를 통한 수용 필드 확장.
  * 공간 피라미드 풀링(Spatial Pyramid Pooling, SPP) [9, 10, 65]을 활용한 다중 스케일 문맥 정보 캡처 (예: DeepLabv3+ [10]).
  * 어텐션 메커니즘 [22, 23, 61, 66]을 통한 장거리 의존성 포착.
* **비전용 트랜스포머 (Transformers for Vision):**
  * NLP 분야의 트랜스포머 [50]에서 영감을 받아 컴퓨터 비전 분야에 적용.
  * CNN과 셀프 어텐션의 결합 [7, 53, 51, 54, 18].
  * Vision Transformer (ViT) [19]: 이미지를 패치 시퀀스로 처리하는 합성곱 없는 이미지 분류 아키텍처.
  * DeiT [49]: 이미지넷(ImageNet) 데이터셋에서 경쟁력 있는 ViT를 학습시키기 위한 토큰 기반 증류(distillation) 전략 제안.
  * 최근 연구: SETR [67]은 ViT 백본과 CNN 디코더 사용, Swin Transformer [35]는 ViT 변형과 FCN 디코더 사용.
* 본 논문의 Segmenter는 ViT 백본을 기반으로 하며, DETR [7]에서 영감을 받은 마스크 디코더를 도입하여 순수 트랜스포머 기반 인코더-디코더 아키텍처를 구성합니다.

## 🛠️ Methodology

Segmenter는 패치 임베딩 시퀀스를 픽셀 단위 클래스 어노테이션으로 매핑하는 완전한 트랜스포머 기반 인코더-디코더 아키텍처입니다.

1. **인코더 (Encoder):**
    * **이미지 패치 분할:** 입력 이미지 $x \in R^{H \times W \times C}$를 $N$개의 패치 $x = [x_1, ..., x_N] \in R^{N \times P^2 \times C}$로 분할합니다. 여기서 $(P, P)$는 패치 크기입니다.
    * **패치 임베딩:** 각 패치를 1D 벡터로 평탄화하고 선형 투영하여 패치 임베딩 $Ex_i$를 생성합니다.
    * **위치 임베딩 추가:** 학습 가능한 위치 임베딩 $pos_i$를 패치 임베딩에 추가하여 입력 토큰 시퀀스 $z_0 = x_0 + pos$를 만듭니다.
    * **트랜스포머 인코딩:** $L$개의 계층으로 구성된 표준 트랜스포머 인코더가 $z_0$를 처리하여 문맥화된 인코딩 시퀀스 $z_L \in R^{N \times D}$를 생성합니다. 각 계층은 멀티헤드 셀프 어텐션(Multi-Headed Self-Attention, MSA) 블록과 MLP 블록으로 구성되며, 계층 정규화(Layer Norm, LN)와 잔차 연결(residual connection)이 적용됩니다.
2. **디코더 (Decoder):**
    * **선형 디코더 (Linear Decoder, 베이스라인):**
        * 인코더 출력 $z_L$에 점별(point-wise) 선형 계층을 적용하여 패치 수준 클래스 로짓 $z_{lin} \in R^{N \times K}$를 생성합니다.
        * 이 시퀀스를 $H/P \times W/P \times K$ 크기의 2D 특징 맵 $s_{lin}$으로 재구성하고, 이중 선형 보간법(bilinear interpolation)으로 원본 이미지 크기 $s \in R^{H \times W \times K}$로 업샘플링합니다.
        * 클래스 차원에 소프트맥스(softmax)를 적용하여 최종 분할 맵을 얻습니다.
    * **마스크 트랜스포머 (Mask Transformer, 제안):**
        * $K$개의 학습 가능한 클래스 임베딩 $cls = [cls_1, ..., cls_K] \in R^{K \times D}$를 도입합니다.
        * 디코더(M개의 계층을 가진 트랜스포머 인코더)는 패치 인코딩 $z_L$과 클래스 임베딩 $cls$를 함께 처리합니다.
        * 디코더 출력인 L2 정규화된 패치 임베딩 $z'_M \in R^{N \times D}$와 클래스 임베딩 $c \in R^{K \times D}$ 간의 스칼라 곱을 계산하여 $K$개의 클래스 마스크를 생성합니다: $Masks(z'_M, c) = z'_M c^T$.
        * 각 마스크 시퀀스를 $H/P \times W/P \times K$ 크기의 2D 마스크 $s_{mask}$로 재구성하고, 이중 선형 보간법으로 원본 이미지 크기 $s \in R^{H \times W \times K}$로 업샘플링합니다.
        * 클래스 차원에 소프트맥스 후 계층 정규화를 적용하여 최종 분할 맵을 구성하는 픽셀별 클래스 점수를 얻습니다.
3. **학습 및 추론:**
    * 픽셀별 교차 엔트로피 손실(cross-entropy loss)을 사용하여 end-to-end로 학습합니다.
    * ViT/DeiT 백본은 ImageNet-21k 또는 ImageNet-1k에서 사전 학습됩니다.
    * 세그멘테이션 데이터셋(ADE20K, Pascal Context, Cityscapes)에서 미세 조정(fine-tuning)됩니다.
    * 최적화는 SGD를 사용하고, 학습률 스케줄러는 "poly" 방식을 따릅니다.
    * 정규화 기법으로 드롭아웃(dropout) 대신 스토캐스틱 뎁스(stochastic depth)를 사용하며, 이는 성능 향상에 기여합니다.
    * 추론 시에는 슬라이딩 윈도우(sliding-window) 및 멀티 스케일 추론(multi-scale inference)을 사용하여 강건한 결과를 얻습니다.

## 📊 Results

* **ADE20K 데이터셋:**
  * 가장 큰 모델인 Seg-L-Mask/16은 53.63%의 mIoU(mean Intersection over Union)를 달성하여 DeepLabv3+ ResNeSt-200을 5.27%p 차이로 능가하고 기존 트랜스포머 기반 모델(SETR, Swin-L UperNet)보다 뛰어납니다.
  * 패치 크기가 작을수록(예: $32 \times 32 \to 16 \times 16 \to 8 \times 8$) mIoU가 크게 향상되며, 특히 작은 객체 및 중간 객체 분할에 유리합니다.
  * 마스크 트랜스포머 디코더는 선형 디코더 대비 일관되게 1.1%에서 2.1%까지 mIoU를 향상시킵니다.
  * 스토캐스틱 뎁스(0.1)는 드롭아웃 없이 학습했을 때 mIoU를 향상시키지만, 드롭아웃은 성능을 저하시킵니다.
* **Pascal Context 데이터셋:**
  * Seg-L-Mask/16은 59.04%의 mIoU로 OCR HRNetV2-W48보다 2.8%p, SETR-L MLA보다 3.2%p 높은 최첨단 성능을 달성했습니다.
* **Cityscapes 데이터셋:**
  * Seg-L-Mask/16은 81.3%의 mIoU로 다른 최첨단 방법들과 경쟁력 있는 성능을 보여줍니다.
* **성능/속도 트레이드오프:** Seg/16 모델은 정확도와 연산 시간 측면에서 좋은 균형을 제공하며, Seg-B-Mask/16은 비슷한 추론 속도의 FCN 기반 모델보다 성능이 우수합니다. Seg/32 모델은 더 빠른 추론 속도를 제공합니다.
* **사전 학습의 중요성:** ImageNet-21k 사전 학습은 무작위 초기화 모델 대비 32.9%p의 mIoU 향상을 가져오며, 미세 조정 시에도 충분한 양의 데이터가 트랜스포머 성능에 필수적임을 보여줍니다.
* **정성적 결과:** Segmenter는 DeepLabv3+ 대비 더 일관성 있는 분할 맵과 부분적인 가려짐(occlusion) 처리에 강점을 보이며, DeepLabv3+는 더 선명한 객체 경계를 생성하는 경향이 있습니다.

## 🧠 Insights & Discussion

* **전역 문맥 포착의 우월성:** 트랜스포머는 CNN과 달리 모델의 첫 계층부터 전역 문맥 정보를 설계상 효과적으로 포착할 수 있습니다. 이는 특히 대형 객체 및 복잡한 장면 이해가 중요한 시맨틱 분할에서 CNN 기반 접근 방식 대비 성능을 크게 향상시키는 주요 요인입니다.
* **모델 확장성 및 패치 크기의 영향:** 모델 크기(계층 수, 토큰 크기)와 패치 크기가 성능에 큰 영향을 미칩니다. 작은 패치 크기는 더 높은 해상도의 표현과 선명한 경계를 제공하지만, 더 긴 시퀀스에 대한 어텐션 계산으로 인해 연산 비용과 메모리 사용량이 증가합니다. 이는 고해상도 처리를 위한 트랜스포머의 효율성 개선이 향후 연구 방향임을 시사합니다.
* **마스크 트랜스포머의 효과:** 제안된 마스크 트랜스포머 디코더는 선형 디코더를 능가하며, 패치 임베딩과 클래스 임베딩을 공동으로 처리하여 입력에 따라 동적으로 필터를 생성하는 이점을 가집니다. 학습된 클래스 임베딩은 의미론적으로 유사한 클래스들을 함께 묶는 경향을 보입니다.
* **사전 학습 데이터의 중요성:** ViT가 이미지 분류에서 대규모 데이터셋의 중요성을 강조했듯이, Segmenter 또한 시맨틱 분할 미세 조정 시에도 ImageNet과 같은 대규모 데이터셋에서의 사전 학습이 필수적이며, 충분한 학습 데이터가 성능을 크게 좌우합니다.
* **향후 확장 가능성:** 본 연구에서 제시된 end-to-end 인코더-디코더 트랜스포머 아키텍처는 시맨틱 분할뿐만 아니라 인스턴스 분할, 파노프틱 분할 등 다른 이미지 분할 작업으로의 통합된 접근 방식을 위한 유망한 첫걸음입니다.

## 📌 TL;DR

**문제:** 기존 CNN 기반 시맨틱 분할 방법은 지역적 특성으로 인해 전역 문맥 정보를 효과적으로 포착하기 어려워 복잡한 장면에서 한계를 보입니다.
**방법:** 본 논문은 'Segmenter'라는 **순수 트랜스포머 기반의 인코더-디코더 아키텍처**를 제안합니다. 이는 Vision Transformer (ViT) 인코더를 사용하여 이미지 패치를 처리하고 처음부터 전역 문맥을 포착합니다. 디코더로는 학습 가능한 클래스 임베딩과 패치 임베딩을 함께 처리하여 동적으로 클래스 마스크를 생성하는 **마스크 트랜스포머**를 도입합니다.
**결과:** Segmenter는 ADE20K 및 Pascal Context 데이터셋에서 **최첨단 성능을 달성**하고, Cityscapes에서도 경쟁력을 입증하며, 기존 FCN 기반 방법들을 크게 능가합니다. 특히 작은 패치 크기와 대형 모델 사용 시 정확도가 향상되며, 마스크 트랜스포머 디코더는 선형 디코더 대비 일관된 성능 향상을 보여줍니다. 대규모 데이터셋에서의 사전 학습이 성능에 결정적인 역할을 합니다.
