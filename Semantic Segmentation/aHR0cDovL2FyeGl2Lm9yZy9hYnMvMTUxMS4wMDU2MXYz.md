# SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation
Vijay Badrinarayanan, Alex Kendall, Roberto Cipolla

## 🧩 Problem to Solve
의미론적 픽셀 단위 분할(semantic pixel-wise segmentation)의 문제점을 해결한다.
- 기존 이미지 분류용 딥러닝 모델(예: VGG16)은 맥스 풀링(max-pooling) 및 서브 샘플링(sub-sampling)을 사용하여 특징 맵(feature map)의 해상도를 감소시킨다. 이로 인해 **분할 결과가 거칠고** 특히 경계선 위치 파악(boundary localization)이 부정확하다.
- **정확한 경계선 분할**은 픽셀 단위 분류에서 매우 중요하다.
- 기존의 진보된 아키텍처(예: FCN, DeconvNet)는 **학습 가능한 파라미터 수가 많아** 종단 간(end-to-end) 학습이 어렵고 추론 시 메모리 소모가 많으며 계산 비용이 높다.
- 특히 **장면 이해(scene understanding) 애플리케이션** (도로 장면, 실내 장면)에서는 고품질의 부드러운 분할 결과를 생성하면서도 경계선 정보를 유지하는 동시에 **추론 시 메모리와 계산 시간 측면에서 효율적인** 아키텍처가 필요하다.

## ✨ Key Contributions
- **새로운 디코더 아키텍처:** 의미론적 분할을 위한 새로운 딥 완전 컨볼루션 인코더-디코더 아키텍처인 SegNet을 제안한다.
- **풀링 인덱스를 활용한 효율적인 업샘플링:** 핵심적인 참신성은 디코더가 해당 인코더에서 계산된 **맥스 풀링 인덱스(max-pooling indices)**를 사용하여 비선형 업샘플링을 수행한다는 점이다. 이를 통해 업샘플링을 학습할 필요가 없으며, 희소(sparse) 특징 맵을 생성한 후 컨볼루션을 통해 밀집(dense) 맵을 생성한다.
- **메모리 및 계산 효율성:** VGG16의 완전 연결 계층(fully connected layers)을 제거하고 풀링 인덱스를 재사용함으로써, SegNet은 학습 가능한 파라미터 수와 추론 시 메모리/시간을 크게 줄여 실시간 애플리케이션에 적합하다.
- **종단 간 학습 가능성:** 이 아키텍처는 확률적 경사 하강법(stochastic gradient descent)을 사용하여 종단 간 학습이 가능하도록 설계되었다.
- **제어된 벤치마킹:** 도로 장면(CamVid) 및 실내 장면(SUN RGB-D) 분할 작업에서 널리 사용되는 FCN, DeepLab-LargeFOV, DeconvNet과의 포괄적인 비교를 통해 메모리-정확도 간의 절충점(trade-off)을 보여준다.
- **경쟁력 있는 성능:** 다른 아키텍처에 비해 경쟁력 있는 추론 시간과 가장 효율적인 추론 메모리로 우수한 분할 성능을 달성한다.

## 📎 Related Works
- **초기 분할 방법:** 수작업으로 설계된 특징(hand-engineered features)과 분류기(Random Forest, Boosting)에 의존했으며, 종종 CRF(Conditional Random Field)와 결합하여 노이즈가 많은 픽셀 단위 예측을 평활화했다.
- **분할을 위한 딥러닝:**
    - **직접 적용:** 초기 시도는 딥 분류 아키텍처(예: 가장 깊은 계층 특징 복제)를 직접 적용했지만 거칠고 "블록형" 예측을 초래했다.
    - **완전 컨볼루션 네트워크 (FCN) [2]:** 선구적인 연구. 다양한 인코더 계층의 특징 맵을 업샘플링하고 결합하는 방법을 학습한다. 파라미터 수가 많아 종단 간 학습이 어렵고 단계별 학습을 사용한다. 인코더 특징 맵을 저장해야 하므로 메모리 집약적이다.
    - **DeepLab-LargeFOV [3]:** 확장 컨볼루션(dilated convolutions)을 사용하여 더 넓은 수용 필드(receptive field)를 얻고 완전 연결 CRF(fully connected CRFs)와 결합하여 정교화한다.
    - **DeconvNet [4]:** SegNet의 핵심 아이디어와 유사하게 맥스 풀링 인덱스를 업샘플링에 사용하지만, VGG16의 완전 연결 계층을 포함하여 훨씬 더 많은 파라미터 수와 복잡한 학습/추론을 초래한다.
    - **U-Net [16]:** 유사한 인코더-디코더 구조를 가지지만, 풀링 인덱스뿐만 아니라 전체 특징 맵을 디코더로 전송하고 연결하여 더 많은 메모리를 사용한다.
    - **다중 스케일 아키텍처 [13, 44]:** 다양한 스케일/계층의 특징을 결합하여 지역적 및 전역적 컨텍스트를 제공하며, 종종 학습이 복잡하다.
    - **CRF-RNN [10]:** FCN에 RNN 계층을 추가하여 CRF 기능을 모방하고 경계선 분할을 개선한다.
- **비지도 특징 학습 [19]:** SegNet의 맥스 풀링 인덱스 재사용 아이디어는 입력 이미지를 재구성하는 비지도 특징 학습 아키텍처에서 영감을 받았다.

## 🛠️ Methodology
SegNet은 픽셀 단위 분류 계층을 포함하는 인코더-디코더 아키텍처이다.
1.  **인코더 네트워크:**
    *   VGG16 [1]의 13개 컨볼루션 계층과 위상적으로 동일하다.
    *   VGG16의 완전 연결 계층을 제거하여 파라미터 수를 줄인다 (1억 3,400만 개에서 1,470만 개로).
    *   각 인코더 계층은 다음을 수행한다: 컨볼루션 $\rightarrow$ 배치 정규화(Batch Normalization) $\rightarrow$ ReLU $\rightarrow$ $2 \times 2$ 윈도우와 스트라이드 2의 맥스 풀링.
    *   핵심적으로, 맥스 풀링 시 각 풀링 윈도우에서 **최대 특징 값의 인덱스(위치)**를 저장하고 해당 디코더 계층으로 전송한다. 이는 매우 적은 메모리를 필요로 한다 (예: $2 \times 2$ 윈도우당 2비트).
2.  **디코더 네트워크:**
    *   각 인코더에 해당하는 디코더 계층들의 계층 구조로 구성된다.
    *   각 디코더는 해당 인코더에서 기억된 **맥스 풀링 인덱스**를 사용하여 **비선형 업샘플링**을 수행한다. 이는 희소 특징 맵을 생성한다.
    *   희소 특징 맵은 그 다음 **학습 가능한 디코더 필터 뱅크**와 컨볼루션되어 밀집 특징 맵을 생성한다.
    *   컨볼루션 후에 배치 정규화 단계가 적용된다.
    *   최종 디코더 출력은 **다중 클래스 소프트맥스 분류기**에 입력되어 픽셀 단위 분류를 수행한다.
3.  **학습:**
    *   고정된 학습률과 모멘텀(momentum)을 가진 확률적 경사 하강법(SGD)을 사용하여 종단 간 학습된다.
    *   목표 함수로 **교차 엔트로피 손실(cross-entropy loss)**을 사용한다.
    *   클래스 불균형(예: CamVid 데이터셋에서 도로/하늘/건물 픽셀이 지배적인 경우)을 처리하기 위해 손실 함수에 **중앙값 빈도 균형(median frequency balancing)**을 적용한다. 이는 작은 클래스에 더 높은 가중치를 부여한다.
    *   가중치는 He et al. [55]에서 설명된 기법을 사용하여 초기화된다.
    *   인코더와 디코더 모두 각 컨볼루션 계층 뒤에 배치 정규화가 추가된다.

## 📊 Results
- **디코더 변형 분석 (CamVid):**
    - SegNet-Basic (풀링 인덱스 사용)은 FCN-Basic (업샘플링 학습)과 동등한 성능을 보이지만, 추론 시 메모리를 크게 적게 사용한다 (예: 첫 번째 계층 특징 맵의 경우 11배 적음).
    - 바이리니어 보간(bilinear interpolation, 고정 업샘플링)은 가장 나쁜 성능을 보이며, 디코더 학습 또는 풀링 인덱스 기반 업샘플링의 필요성을 강조한다.
    - 전체 인코더 특징 맵을 저장하는 방식 (예: FCN-Basic-NoDimReduction, SegNet-Basic-EncoderAddition)은 전반적으로 가장 좋은 성능(더 높은 mIoU, BF 점수)을 제공하지만, 더 많은 메모리와 느린 추론 속도를 야기한다.
    - 중앙값 빈도 균형(median frequency balancing)은 특히 작은 클래스의 경우 자연 빈도 균형(natural frequency balancing)에 비해 클래스 평균 정확도와 mIoU를 크게 향상시킨다.
- **도로 장면 분할 (CamVid - 대규모 데이터셋):**
    - SegNet은 전통적인(비 딥러닝) 방법과 다른 딥 아키텍처에 비해 경쟁력 있는 결과를 달성한다.
    - 더 큰 통합 데이터셋(3.5K 이미지)으로 학습했을 때, SegNet은 클래스 평균 정확도에서 약 $10\%$ 향상을 보였으며, 특히 작거나 얇은 클래스에서 두드러졌다.
    - 정성적으로, SegNet은 부드러운 분할과 우수한 경계선 분할 능력을 제공한다.
    - DeepLab-LargeFOV는 효율적이지만 작은 클래스를 놓치는 경향이 있다. DeconvNet은 가장 크고 학습 비효율적이며, 역시 작은 클래스를 놓친다.
- **실내 장면 분할 (SUN RGB-D - RGB 모달리티만 사용):**
    - 이 작업은 높은 다양성, 다양한 객체 스케일, 잦은 폐색(occlusions)으로 인해 더 어려운 과제이다 (37개 클래스).
    - SegNet을 포함한 모든 딥 아키텍처는 도로 장면에 비해 낮은 mIoU와 경계 측정값을 보인다.
    - SegNet은 G, C, BF 측정에서 다른 방법들을 능가하며, DeepLab-LargeFOV보다 약간 낮은 mIoU를 기록했다.
    - 성능은 클래스 크기와 관련이 있으며; 큰 클래스는 비교적 잘 분할되지만, 작고 빈번하지 않은 클래스는 성능이 좋지 않다.
    - 중앙값 빈도 클래스 균형(median frequency class balancing)을 사용하는 것이 이 어려운 데이터셋에서도 SegNet의 성능을 여전히 향상시킨다.
- **효율성 비교:** SegNet은 추론 시 메모리 효율적이며 (예: 모델 크기 117MB, 추론 메모리 52MB) FCN, DeepLab, DeconvNet에 비해 경쟁력 있는 전방/역방향 통과 시간을 가진다 (논문의 표 6 참조).

## 🧠 Insights & Discussion
- **메모리 대 정확도 절충점:** 분석은 명확한 절충점을 보여준다: 전체 인코더 특징 맵을 저장하는 것이 (특히 경계선 분할에 대해) 최고의 정확도를 제공하지만, 더 높은 메모리 소모와 느린 추론 속도를 초래한다. SegNet은 풀링 인덱스를 사용하여 좋은 타협점을 제공한다.
- **디코더의 중요성:** 학습된 디코더 (또는 SegNet의 풀링 인덱스와 같은 지능적인 업샘플링)는 의미론적 분할에 필수적이다; 바이리니어 보간과 같은 간단한 방법은 성능이 좋지 않다.
- **종단 간 학습:** 배치 정규화(Batch Normalization)는 대부분의 모델에서 종단 간 학습을 가능하게 했으며, 이는 모든 가중치를 함께 최적화하는 데 유용하다.
- **실내 장면의 어려움:** 실내 장면 분할은 다양한 객체 스케일, 복잡한 배치, 잦은 폐색으로 인해 여전히 매우 어려운 과제이며, 모든 아키텍처에서 전반적으로 낮은 성능을 보인다. 현재 VGG 기반 아키텍처는 이러한 다양성에 최적화되지 않을 수 있다.
- **실용적인 응용:** SegNet의 효율성은 자율 주행 및 증강 현실과 같이 메모리 및 계산 제약이 중요한 실시간 애플리케이션에 매우 적합하다.
- **향후 연구:** 더 효율적인 아키텍처를 설계하고 분할 예측의 모델 불확실성을 추정하는 데 추가 연구가 필요하다.

## 📌 TL;DR
SegNet은 픽셀 단위 의미론적 분할에서 풀링으로 인한 해상도 손실과 경계선 부정확성 문제를 해결하고자 한다. 이 논문은 인코더의 맥스 풀링 인덱스를 디코더의 비선형 업샘플링에 재사용하여 학습 없이 효율적인 업샘플링을 수행하는 새로운 완전 컨볼루션 인코더-디코더 아키텍처를 제안한다. 이를 통해 SegNet은 적은 파라미터와 낮은 추론 메모리로 경쟁력 있는 성능을 달성하며, 실시간 장면 이해 애플리케이션에 적합하다는 것을 보여준다.