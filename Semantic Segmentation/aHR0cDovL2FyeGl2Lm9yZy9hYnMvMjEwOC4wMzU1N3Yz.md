# Context-Aware Mixup for Domain Adaptive Semantic Segmentation

Qianyu Zhou, Zhengyang Feng, Qiqi Gu, Jiangmiao Pang, Guangliang Cheng, Xuequan Lu, Jianping Shi, Lizhuang Ma

## 🧩 Problem to Solve

레이블이 지정된 소스 도메인에서 레이블이 없는 타겟 도메인으로 모델을 적응시키는 비지도 도메인 적응(UDA)은 시맨틱 분할에서 중요한 과제입니다. 기존의 UDA 기반 시맨틱 분할 접근 방식들은 픽셀, 특징, 출력 레벨에서 도메인 차이를 줄이는 데 중점을 두었지만, 대부분 다른 도메인 간에 일반적으로 공유되는 **문맥적 의존성(contextual dependency)**을 크게 간과하여 만족스럽지 못한 성능과 심각한 음성 전이(negative transfer)를 초래했습니다. 특히, 도메인 믹스업(domain mixup) 과정에서 문맥적 의존성을 무시하면 혼합된 이미지에서 부적절한 객체 배치로 인한 **범주 혼란(category confusion)** 및 **레이블 오염(label contamination)**이 발생할 수 있습니다. 또한, 기존 방법들은 복잡하고 수렴하기 어려우며 오프라인 단계가 많아 엔드투엔드로 학습하기 어렵다는 단점이 있습니다.

## ✨ Key Contributions

* **새로운 관점 제시**: 도메인 간 문맥적 의존성을 명시적인 사전 지식으로 활용하여 타겟 도메인에 대한 적응성을 향상시키는 새로운 Context-Aware Mixup (CAMix) 프레임워크를 제안했습니다.
* **문맥적 마스크 생성 (CMG) 전략**: 소스 도메인의 공간 분포와 타겟 도메인의 문맥적 관계를 활용하여 문맥적 마스크를 생성하는 전략을 제시했으며, 이 마스크는 세 가지 다른 레벨(입력, 출력, 유의성 마스크)에서 문맥 인식 도메인 믹스업을 안내합니다.
* **유의성 가중 일관성 손실 (SRC) 도입**: 문맥의 안내에 따라 믹스업된 학생(student) 예측과 교사(teacher) 예측 간의 불일치에 벌칙을 가하여 적응 과정 중 발생하는 초기 성능 저하와 같은 부정적인 영향을 완화합니다.
* **강력한 성능 입증**: 두 가지 주요 UDA 벤치마크(GTAV $\rightarrow$ Cityscapes, SYNTHIA $\rightarrow$ Cityscapes)에서 기존 최첨단 방법들보다 우수한 성능을 달성했으며, CAMix는 기존 UDA 프레임워크(DACS, DAFormer)에 쉽게 통합되어 일관된 성능 향상을 가져옵니다.

## 📎 Related Works

* **비지도 도메인 적응 시맨틱 분할**: 대부분의 기존 UDA 방법들은 픽셀 레벨([15]–[22]), 특징 레벨([23]–[29]), 출력 레벨([30]–[35])의 도메인 차이 감소에 중점을 두었지만, 도메인 간 공유되는 문맥적 의존성을 간과했습니다. 또한, 이들은 적대적 학습, 이미지-투-이미지 변환, 자기 학습 등 복잡한 서브 컴포넌트를 포함하여 엔드투엔드 학습이 어렵습니다.
* **도메인 믹스업**: Mixup은 준지도 학습([44], [45]) 등 다른 분야에서 모델 견고성을 향상하는 데 연구되었습니다. UDA에서는 [61]–[63]이 교차 도메인 믹스업을 연구했지만, 시맨틱 분할과 같은 도전적인 작업에는 적용하기 어렵습니다. DACS [41]와 BAPA-Net [29]는 분할을 위해 믹스업을 사용했지만, 문맥적 의존성을 명시적으로 활용하는 데는 거의 초점을 맞추지 않았습니다.
* **일관성 정규화 (Consistency Regularization)**: Mean Teacher [67]와 같이 학생 모델과 교사 모델 간의 예측 일관성을 유지하는 개념으로, 준지도 학습 및 UDA ([39]–[41], [66], [68]–[70])에 적용되었습니다.
* **불확실성 추정**: 베이지안 분류기 [71] 및 베이지안 판별자 [72]와 같이 예측 불확실성을 활용하는 아이디어가 도메인 적응 분류에 사용되었으나, 시맨틱 분할과 같은 픽셀 단위 예측에는 잘 적용되지 않았고, 불안정한 적대적 학습에 의존하는 경향이 있습니다.

## 🛠️ Methodology

CAMix (Context-Aware Mixup) 프레임워크는 문맥적 의존성을 명시적 사전 지식으로 활용하며, 두 가지 핵심 구성 요소로 이루어져 있습니다:

1. **문맥적 마스크 생성 (Contextual Mask Generation, CMG)**:
    * **공간 사전 지식 (Spatial Prior)**: 소스 도메인에서 클래스 빈도를 계산하여 $C \times H \times W$ 형태의 공간 사전 텐서 $Q$를 생성합니다. 이는 타겟 예측을 정규화하는 사전 지식으로 사용됩니다: $\hat{F}_{\theta'} \leftarrow Q \circ F_{\theta'}(X_T)$.
    * **문맥적 관계 (Contextual Relationship)**: Cityscapes [11] 데이터셋의 계층적 문맥 관계(예: "pole", "traffic sign", "traffic light"가 "object" 그룹에 속함)를 기반으로 메타 클래스 그룹($m$)을 정의합니다.
    * **마스크 생성**:
        * 먼저 공간적으로 조절된 유사 레이블 $\tilde{Y}_T \leftarrow \arg \max_{c'} \hat{F}_{\theta'}(h,w,c')$을 얻습니다.
        * $\tilde{Y}_T$에 존재하는 클래스 중 절반($c$)을 무작위로 선택합니다.
        * 선택된 클래스 $k \in c$가 메타 클래스 목록 $m$에 속하는 경우, 해당 클래스와 의미론적으로 관련된 클래스($\tilde{k}$)를 현재 목록 $c$에 추가합니다.
        * 최종 클래스 목록 $c$의 픽셀은 1, 나머지는 0으로 설정하여 이진 문맥적 마스크 $M(h,w)$를 생성합니다.
        * $M(h,w) = \begin{cases} 1, & \text{if } \tilde{Y}_T(h,w) \in c \\ 0, & \text{otherwise} \end{cases}$

2. **문맥 인식 도메인 믹스업 (Context-Aware Domain Mixup)**:
    CMG에서 생성된 마스크 $M$의 안내에 따라 세 가지 레벨에서 믹스업을 수행합니다.
    * **입력 레벨 믹스업**: 소스 이미지 $X_S$와 타겟 이미지 $X_T$를 혼합하여 $X_M$을 생성합니다: $X_M = M \circ X_T + (1-M) \circ X_S$.
    * **출력 레벨 믹스업**: 소스 레이블 $Y_S$와 타겟 유사 레이블 $\hat{Y}_T$를 혼합하여 $Y_M$을 생성합니다: $Y_M = M \circ \hat{Y}_T + (1-M) \circ Y_S$. (타겟-투-소스 방향으로 믹스업)
    * **유의성 마스크 레벨 믹스업 및 유의성 가중 일관성 손실 (Significance-reweighted Consistency Loss, SRC)**:
        * **확률적 순방향 패스(Stochastic forward passes)**: 각 타겟 이미지 $X_T$에 대해 $L$개의 복사본을 만들고 각 복사본에 무작위 가우시안 노이즈를 주입합니다. 교사 모델 $F_{\theta'}$을 사용하여 $L$번의 순방향 패스에서 예측 확률의 평균 $\hat{P}^{(h,w,c)}$를 계산합니다.
        * **예측 엔트로피**: $\hat{P}^{(h,w,c)}$를 기반으로 픽셀 단위 예측 엔트로피 $\zeta^{(h,w)} = - \sum_{c=1}^C \hat{P}^{(h,w,c)} \cdot \log(\hat{P}^{(h,w,c)})$를 계산합니다.
        * **동적 임계값 (Dynamic Threshold)**: $t$를 현재 훈련 스텝, $t_{max}$를 최대 훈련 스텝, $K_{sup}$을 엔트로피 상한으로 하여 동적 임계값 $R$을 계산합니다: $R = \beta + (1-\beta) \cdot e^{\gamma(1-t/t_{max})^2} \cdot K_{sup}$.
        * **유의성 마스크 생성**: 예측 엔트로피 $\zeta$가 동적 임계값 $R$보다 낮은 픽셀(고신뢰도 픽셀)만 남겨 타겟 유의성 마스크 $U_T = I(\zeta < R)$를 생성합니다. 소스 유의성 마스크 $U_S$는 모두 1인 텐서입니다.
        * **유의성 마스크 믹스업**: $U_T$와 $U_S$를 혼합하여 $U_M = M \circ U_T + (1-M) \circ U_S$를 생성합니다.
        * **SRC 손실**: 혼합된 유의성 마스크 $U_M$을 사용하여 믹스업된 학생 예측과 교사 예측 간의 불일치를 페널티하는 교차 엔트로피 기반의 SRC 손실 $L_{con}(f_{\theta'}, f_{\theta}) = \frac{\sum_j (U_M \cdot \text{CE}(F_{\theta}(X_M), Y_M))}{\sum_j U_M}$를 정의합니다.

3. **엔드투엔드 학습 및 추론**:
    * 총 손실 $L_{total} = L_{seg} + \lambda_{con} L_{con}$를 사용하여 전체 프레임워크를 엔드투엔드로 최적화합니다. $L_{seg}$는 소스 이미지에 대한 교차 엔트로피 손실입니다.
    * 추론 단계에서는 EMA(Exponential Moving Average)로 업데이트된 교사 모델만 사용합니다.

## 📊 Results

* **GTAV $\rightarrow$ Cityscapes**:
  * DACS [41] 기반으로 3.1% mIoU 향상 (52.1% $\rightarrow$ 55.2%).
  * DAFormer [46] 기반으로 1.7% mIoU 향상 (68.3% $\rightarrow$ 70.0%).
* **SYNTHIA $\rightarrow$ Cityscapes**:
  * DACS [41] 기반으로 4.9% mIoU 향상 (54.8% $\rightarrow$ 59.7%).
  * DAFormer [46] 기반으로 1.8% mIoU 향상 (67.4% $\rightarrow$ 69.2%).
* **기존 도메인 믹스업 방법들과의 비교**: DeepLabV2 [1] 및 SegFormer [89]를 기본 아키텍처로 사용했을 때, Mean Teacher [67], CowMix [45], CutMix [44], DACS [41], DAFormer [46] 등 모든 기존 믹스업 방법보다 우수한 성능을 보였습니다. 특히, 기존 DACS (52.1%) 대비 55.2%, DAFormer (68.3%) 대비 70.0% mIoU를 달성했습니다.
* **클래스별 성능**: CAMix는 오토바이, 자전거, 교통 표지판 등 대부분의 희소 클래스(infrequent categories)에서 가장 높은 IoU를 달성하여 다양한 클래스에 대한 효과를 입증했습니다.
* **시각화 결과**: 기존 DACS [41]는 레이블 오염과 범주 혼란을 보이는 반면, CAMix는 장면의 문맥적 구조를 명시적으로 고려하여 더 적은 아티팩트를 생성하고 시맨틱 분할 결과에서 높은 신뢰도를 보여주었습니다.

## 🧠 Insights & Discussion

* **문맥적 의존성의 중요성**: 기존 UDA 방법들이 간과했던 도메인 간 공유 문맥적 의존성을 명시적으로 활용하는 것이 성능 향상에 결정적인 역할을 함을 입증했습니다. 이는 단순히 픽셀, 특징, 출력 레벨의 도메인 차이 감소를 넘어섭니다.
* **CMG의 효과**: 공간 사전 지식과 문맥적 관계를 결합한 CMG는 믹스업 과정에서 레이블 오염 및 범주 혼란 문제를 완화하고, 부적절한 문맥에 시맨틱 카테고리가 배치되는 것을 방지합니다.
* **SRC의 안정화 효과**: SRC 손실은 교사 모델의 불확실성을 추가적으로 줄이고, 교사 모델이 학생 모델에게 더 신뢰할 수 있는 지식을 전달하도록 유도하여 적응 과정 중 훈련 불안정성 및 초기 성능 저하와 같은 부정적인 영향을 효과적으로 완화합니다. 성능 곡선 시각화를 통해 SRC의 훈련 안정화 효과가 명확히 드러났습니다.
* **다단계 믹스업의 상호 보완성**: 입력, 출력, 유의성 마스크 레벨에서의 CAMix는 서로 보완적이며, 함께 통합될 때 최적의 성능을 달성합니다.
* **메타 클래스 목록의 중요성**: 메타 클래스 그룹의 조합은 성능에 영향을 미치며, 너무 적거나 너무 많은 문맥 지식은 오히려 성능을 저하시킬 수 있습니다. 적절한 수준의 사전 지식이 최적의 적응을 유도합니다.
* **유연성과 실용성**: CAMix 프레임워크는 기존 UDA 프레임워크(DACS, DAFormer)에 쉽게 통합될 수 있으며, 복잡한 추가 모델이나 오프라인 단계를 요구하지 않아 실제 응용 프로그램에서 더 실용적입니다.

## 📌 TL;DR

이 논문은 비지도 도메인 적응 시맨틱 분할에서 **도메인 간 공유되는 문맥적 의존성**이 간과되었던 문제에 주목합니다. 저자들은 이를 명시적인 사전 지식으로 활용하기 위해 **Context-Aware Mixup (CAMix)** 프레임워크를 제안합니다. CAMix는 소스 도메인의 공간 분포와 타겟 도메인의 문맥적 관계를 통합한 **문맥적 마스크 생성 (CMG)** 전략을 통해 이미지, 레이블, 그리고 **유의성 마스크**라는 세 가지 레벨에서 문맥 인식 믹스업을 수행합니다. 또한, 예측 불확실성을 줄이기 위해 **유의성 가중 일관성 손실 (SRC)**을 도입하여 학습 안정성을 높였습니다. 광범위한 실험을 통해 CAMix가 기존 최첨단 방법들보다 **우수한 성능**을 달성하며, **훈련 불안정성과 음성 전이 문제를 효과적으로 완화**함을 입증했습니다.
