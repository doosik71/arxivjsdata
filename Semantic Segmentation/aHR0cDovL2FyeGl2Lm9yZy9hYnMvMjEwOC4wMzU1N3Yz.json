{
  "url": "http://arxiv.org/abs/2108.03557v3",
  "title": "Context-Aware Mixup for Domain Adaptive Semantic Segmentation",
  "authors": "Qianyu Zhou, Zhengyang Feng, Qiqi Gu, Jiangmiao Pang, Guangliang Cheng, Xuequan Lu, Jianping Shi, Lizhuang Ma",
  "year": 2021,
  "abstract": "Unsupervised domain adaptation (UDA) aims to adapt a model of the labeled\nsource domain to an unlabeled target domain. Existing UDA-based semantic\nsegmentation approaches always reduce the domain shifts in pixel level, feature\nlevel, and output level. However, almost all of them largely neglect the\ncontextual dependency, which is generally shared across different domains,\nleading to less-desired performance. In this paper, we propose a novel\nContext-Aware Mixup (CAMix) framework for domain adaptive semantic\nsegmentation, which exploits this important clue of context-dependency as\nexplicit prior knowledge in a fully end-to-end trainable manner for enhancing\nthe adaptability toward the target domain. Firstly, we present a contextual\nmask generation strategy by leveraging the accumulated spatial distributions\nand prior contextual relationships. The generated contextual mask is critical\nin this work and will guide the context-aware domain mixup on three different\nlevels. Besides, provided the context knowledge, we introduce a\nsignificance-reweighted consistency loss to penalize the inconsistency between\nthe mixed student prediction and the mixed teacher prediction, which alleviates\nthe negative transfer of the adaptation, e.g., early performance degradation.\nExtensive experiments and analysis demonstrate the effectiveness of our method\nagainst the state-of-the-art approaches on widely-used UDA benchmarks."
}