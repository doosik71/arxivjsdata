{
  "title": "Spatiotemporal Graph Neural Network based Mask Reconstruction for Video\n  Object Segmentation",
  "authors": "Daizong Liu, Shuangjie Xu, Xiao-Yang Liu, Zichuan Xu, Wei Wei, Pan Zhou",
  "year": 2020,
  "url": "http://arxiv.org/abs/2012.05499v1",
  "abstract": "This paper addresses the task of segmenting class-agnostic objects in\nsemi-supervised setting. Although previous detection based methods achieve\nrelatively good performance, these approaches extract the best proposal by a\ngreedy strategy, which may lose the local patch details outside the chosen\ncandidate. In this paper, we propose a novel spatiotemporal graph neural\nnetwork (STG-Net) to reconstruct more accurate masks for video object\nsegmentation, which captures the local contexts by utilizing all proposals. In\nthe spatial graph, we treat object proposals of a frame as nodes and represent\ntheir correlations with an edge weight strategy for mask context aggregation.\nTo capture temporal information from previous frames, we use a memory network\nto refine the mask of current frame by retrieving historic masks in a temporal\ngraph. The joint use of both local patch details and temporal relationships\nallow us to better address the challenges such as object occlusion and missing.\nWithout online learning and fine-tuning, our STG-Net achieves state-of-the-art\nperformance on four large benchmarks (DAVIS, YouTube-VOS, SegTrack-v2, and\nYouTube-Objects), demonstrating the effectiveness of the proposed approach."
}