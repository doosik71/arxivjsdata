{
  "url": "http://arxiv.org/abs/2107.06278v2",
  "title": "Per-Pixel Classification is Not All You Need for Semantic Segmentation",
  "authors": "Bowen Cheng, Alexander G. Schwing, Alexander Kirillov",
  "year": 2021,
  "abstract": "Modern approaches typically formulate semantic segmentation as a per-pixel\nclassification task, while instance-level segmentation is handled with an\nalternative mask classification. Our key insight: mask classification is\nsufficiently general to solve both semantic- and instance-level segmentation\ntasks in a unified manner using the exact same model, loss, and training\nprocedure. Following this observation, we propose MaskFormer, a simple mask\nclassification model which predicts a set of binary masks, each associated with\na single global class label prediction. Overall, the proposed mask\nclassification-based method simplifies the landscape of effective approaches to\nsemantic and panoptic segmentation tasks and shows excellent empirical results.\nIn particular, we observe that MaskFormer outperforms per-pixel classification\nbaselines when the number of classes is large. Our mask classification-based\nmethod outperforms both current state-of-the-art semantic (55.6 mIoU on ADE20K)\nand panoptic segmentation (52.7 PQ on COCO) models.",
  "citation": 2154
}