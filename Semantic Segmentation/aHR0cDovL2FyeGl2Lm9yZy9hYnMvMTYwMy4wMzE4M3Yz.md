# Exploring Context with Deep Structured models for Semantic Segmentation

Guosheng Lin, Chunhua Shen, Anton van den Hengel, Ian Reid

## 🧩 Problem to Solve

의미론적 이미지 분할(Semantic Image Segmentation)은 모든 이미지 픽셀에 카테고리 레이블을 할당하는 중요한 작업입니다. 최근 딥 컨볼루션 신경망(CNN) 기반 방법론들이 뛰어난 성능을 보였지만, 컨텍스트 정보의 활용 측면에서는 여전히 개선의 여지가 있었습니다. 특히, 이미지 패치 간의(patch-patch) 의미론적 관계와 특정 패치와 넓은 배경 영역 간의(patch-background) 컨텍스트를 효과적으로 모델링하는 것이 중요합니다. 기존의 심층 신경망과 조건부 랜덤 필드(CRF)를 결합한 방법들은 주로 경계선 정제에 초점을 맞추었으며, 패치 간의 "의미론적 호환성"을 학습하는 데는 한계가 있었습니다. 또한, 일반화된 쌍별(pairwise) 잠재 함수를 사용하는 CRF 학습은 계산 비용이 많이 든다는 문제가 있었습니다.

## ✨ Key Contributions

- CNN 기반의 일반화된 쌍별 잠재 함수를 CRF에 통합하여 패치 간의 의미론적 관계를 명시적으로 모델링하는 새로운 방법을 제안했습니다.
- 심층 CNN 기반의 일반화된 쌍별 잠재 함수를 효율적으로 학습하기 위해 CRF의 조각별 훈련(piecewise training) 방식을 적용하여 역전파 과정에서 반복적인 비용이 많이 드는 추론(inference)을 피함으로써 효율적인 학습을 가능하게 했습니다.
- 전통적인 다중 스케일(multi-scale) 이미지 입력과 슬라이딩 피라미드 풀링(sliding pyramid pooling)을 활용하는 네트워크 아키텍처를 탐색하여 패치-배경 컨텍스트를 효과적으로 캡처하고, 이 네트워크 아키텍처의 성능 향상 효과를 경험적으로 입증했습니다.
- NYUDv2, PASCAL VOC 2012, PASCAL-Context, Cityscapes 등 여러 도전적인 의미론적 분할 데이터셋에서 새로운 최첨단 성능을 달성했습니다. 특히 PASCAL VOC 2012 데이터셋에서 77.8%의 IoU(Intersection-over-Union) 점수를 기록했습니다.

## 📎 Related Works

- **컨텍스트 정보 활용:** 초기 연구 "TAS" [26]는 Things와 Stuff 간의 다양한 공간 컨텍스트를 생성적 그래픽 모델로 모델링했습니다.
- **CNN 기반 의미론적 분할:**
  - **FCNNs (Fully Convolutional Neural Networks)** [5], [8], [39]: 밀집 예측(dense prediction) 및 엔드투엔드(end-to-end) 학습의 효율성으로 인해 널리 사용됩니다.
  - **저해상도 예측 문제 해결:** DeepLab-CRF [5]와 CRF-RNN [60]은 atrous convolution과 밀집 CRF(Dense CRF)를 사용하여 저해상도 예측을 고해상도로 정제하고 객체/영역 경계선을 선명하게 했습니다. DeconvNet [42]은 역컨볼루션 레이어를 학습하여 업샘플링을 수행했으며, FCN [39]과 Hyper-column [23]은 중간 레이어 특징(skip connections)을 활용했습니다.
- **CRF와 CNN의 공동 학습:** 심도 추정 [36], [37] 및 인간 자세 추정 [55]과 같은 다른 응용 분야에서도 탐구되었습니다. [6]에서는 Markov Random Fields와 딥 신경망의 공동 학습을 탐색했으나, 이는 각 그래디언트 계산마다 주변 추론을 필요로 하여 계산 비용이 높았습니다.
- **CRF 학습 방법:** 유사 가능도 학습(pseudo-likelihood learning) [2]과 조각별 학습(piecewise learning) [53]은 CRF 목적 함수를 근사화하여 효율적인 학습을 가능하게 하는 방법들입니다.

## 🛠️ Methodology

1. **FeatMap-Net을 통한 특징 맵 생성:**
   - **다중 스케일 CNN:** 입력 이미지를 1.2, 0.8, 0.4의 3가지 스케일로 크기를 조절하여 처리합니다. 상위 5개 컨볼루션 블록은 모든 스케일에서 공유하며, 각 스케일은 고유한 6번째 컨볼루션 블록을 가집니다. 이를 통해 스케일 종속적인 정보를 캡처하고 추상화 수준을 높입니다.
   - **슬라이딩 피라미드 풀링:** 각 스케일의 특징 맵에 2단계(5x5, 9x9) 슬라이딩 피라미드 풀링(max-pooling)을 적용합니다. 이는 다양한 크기의 배경 영역 정보를 캡처하고 특징 맵의 수용 필드(field-of-view)를 확장합니다. 풀링된 특징 맵은 원본 특징 맵과 결합되어 최종 특징 맵을 구성합니다.
   - **네트워크 구성:** FeatMap-Net은 VGG-16 모델 [51]을 기반으로 하며, 마지막 max pooling 레이어의 스트라이드를 1로 줄여 특징 맵 해상도를 입력 이미지의 1/16로 유지하고, 추가적인 3x3 컨볼루션 레이어를 통해 수용 필드 변화를 보상합니다.
2. **CRF 그래프 구성:** 생성된 저해상도 특징 맵의 각 공간 위치를 CRF 그래프의 노드로 사용합니다. 쌍별 연결은 미리 정의된 공간 범위 상자(range box) 내에 있는 모든 노드와 연결하여 구성하며, "주변(surrounding)" 및 "상하(above/below)"와 같은 다른 공간 관계를 모델링합니다.
3. **심층 CRF 모델:**
   - **에너지 함수:** CRF의 에너지 함수는 단항(unary) 및 쌍별(pairwise) 잠재 함수로 구성됩니다:
     $$E(y,x) = \sum_{U \in \mathcal{U}} \sum_{p \in N_U} U(y_p,x_p) + \sum_{V \in \mathcal{V}} \sum_{(p,q) \in S_V} V(y_p,y_q,x_{pq})$$
   - **단항 잠재 함수 (Unary-Net):** FeatMap-Net으로 생성된 각 노드의 특징 벡터를 입력으로 받아 shallow fully connected network(Unary-Net)를 통해 해당 노드의 $K$개 클래스에 대한 예측($z_{p,y_p}$)을 출력합니다.
     $$U(y_p,x_p;{\theta_U}) = -z_{p,y_p}(x;{\theta_U})$$
   - **쌍별 잠재 함수 (Pairwise-Net):** 두 연결된 노드의 특징 벡터를 순서대로 연결한 것을 입력으로 받아 shallow fully connected network(Pairwise-Net)를 통해 $K^2$개 쌍별 레이블 조합에 대한 호환성 값($z_{p,q,y_p,y_q}$)을 출력합니다. 이는 비대칭 관계 모델링을 가능하게 합니다.
     $$V(y_p,y_q,x_{pq};{\theta_V}) = -z_{p,q,y_p,y_q}(x;{\theta_V})$$
4. **효율적인 학습 (조각별 훈련):**
   - 전역 분할 함수(partition function) $Z(x)$ 계산의 어려움을 피하기 위해, 조건부 가능도(conditional likelihood)를 단항 및 쌍별 잠재 함수에 대한 독립적인 가능도의 곱으로 근사화합니다:
     $$\log P(y|x) = \sum_{U \in \mathcal{U}} \sum_{p \in N_U} \log P_U(y_p|x) + \sum_{V \in \mathcal{V}} \sum_{(p,q) \in S_V} \log P_V(y_p,y_q|x)$$
   - 이는 각 잠재 함수에 대한 소프트맥스 정규화만을 포함하여 그래디언트 계산을 효율적으로 만듭니다.
   - **쌍별 연결 샘플링:** 계산 비용 절감을 위해 각 노드에 대해 정의된 범위 내에서 24개의 이웃 노드를 샘플링하여 쌍별 연결 수를 줄입니다.
   - **비동기 그래디언트 업데이트:** Pairwise-Net과 FeatMap-Net의 그래디언트 업데이트를 비동기적으로 수행하여 GPU 메모리 소비를 줄이고 대규모 배치 사이즈로 인한 수렴 저하 문제를 해결합니다.
5. **예측 단계:**
   - **거친 수준 예측:** CRF 모델에 대해 평균 필드 근사(mean field approximation) 기반의 효율적인 메시지 전달 알고리즘을 사용하여 각 노드의 주변 분포(marginal distribution)를 계산하여 저해상도(입력 이미지의 1/16) 점수 맵을 생성합니다.
   - **예측 정제 단계:** 거친 예측의 점수 맵을 입력 이미지 크기로 이중 선형 업샘플링(bilinearly up-sample)한 후, 밀집 CRF(dense CRF) [30]를 적용하여 객체 경계를 선명하게 하여 최종 고해상도 예측을 생성합니다. PASCAL VOC 2012의 경우, 중간 레이어 특징 맵을 활용하는 추가적인 정제 네트워크를 사용하여 예측 해상도를 높입니다.

## 📊 Results

본 논문은 8개의 주요 의미론적 분할 데이터셋에서 포괄적인 실험을 수행하여 제안된 방법이 새로운 최첨단 성능을 달성함을 입증했습니다.

- **NYUDv2 (40 클래스):** RGB 이미지만 사용하여 40.6% IoU를 달성, 기존 FCN-HHA [39] (RGB-D 사용)의 34.0%를 크게 뛰어넘었습니다. 각 구성 요소(슬라이딩 피라미드 풀링, 다중 스케일, 경계 정제, CNN 쌍별 잠재 함수)가 순차적으로 성능 향상에 기여했음을 보였습니다.
- **PASCAL VOC 2012 (20 + 1 배경 클래스):** VOC 훈련 데이터만 사용 시 75.3% IoU, VOC + COCO 훈련 데이터 사용 및 개선된 정제 네트워크 적용 시 77.8% IoU를 달성하여 해당 데이터셋에서 최고 보고 성능을 기록했습니다.
- **Cityscapes (19 클래스):** 71.6% IoU로 기존 방법들을 능가하며 최고 성능을 달성했습니다.
- **PASCAL-Context (60 클래스):** 43.3% IoU로 기존 방법들을 크게 능가하며 최고 성능을 기록했습니다.
- **SUN-RGBD (37 클래스):** RGB 정보만으로 42.3% IoU를 달성하여 기존 방법들을 크게 앞섰습니다.
- **COCO (80 클래스):** 46.8% IoU를 달성하여 베이스라인 FullyConvNet (37.2% IoU)을 크게 상회했습니다.
- **SIFT-flow (33 클래스):** 44.9% IoU로 최고 성능을 달성했습니다.
- **KITTI (10 클래스):** 68.5% IoU를 달성하여 최고 성능을 기록했으며, COCO 사전 훈련 시 70.3% IoU를 달성했습니다.

## 🧠 Insights & Discussion

- **컨텍스트 모델링의 강력함:** 패치-패치 및 패치-배경 컨텍스트를 CNN 기반의 학습된 잠재 함수로 명시적으로 모델링하는 것이 의미론적 분할 성능 향상에 매우 효과적임을 입증했습니다. 특히, CNN 쌍별 잠재 함수는 단순한 지역 평활화를 넘어 의미론적 호환성을 모델링하여 거친 수준의 예측을 크게 개선했습니다.
- **효율적인 학습의 중요성:** 조각별 훈련(piecewise training)과 비동기 그래디언트 업데이트(asynchronous gradient update) 전략은 대규모 데이터셋에서 계산 비용이 높은 심층 구조 모델을 효율적으로 학습할 수 있는 실용적인 방법을 제공했습니다. 이는 반복적인 CRF 추론으로 인한 병목 현상을 해결했습니다.
- **다중 스케일 및 피라미드 풀링의 역할:** 다중 스케일 입력과 슬라이딩 피라미드 풀링은 특징 맵의 수용 필드를 확장하고 풍부한 배경 정보를 인코딩하여 전체 시스템의 성능 향상에 크게 기여했습니다.
- **결과의 시사점:** 제안된 접근 방식은 다양한 데이터셋에서 일관되게 최첨단 성능을 달성하며, 컨텍스트 정보의 중요성과 이를 딥 러닝 모델에 통합하는 효과적인 방법을 보여주었습니다.
- **한계 및 미래 방향:** 본 논문의 정제 단계는 비교적 간단한 방법(양선형 업샘플링 + Dense CRF)을 사용했는데, 역컨볼루션 네트워크 [42]나 다중 해상도 학습 네트워크 [13]와 같은 더 정교한 정제 방법을 적용하면 추가적인 성능 향상이 가능할 것으로 예상됩니다. 이 방법론은 의미론적 분할 외의 다른 컴퓨터 비전 작업에도 광범위하게 적용될 수 있는 잠재력을 가집니다.

## 📌 TL;DR

의미론적 분할에서 컨텍스트 정보 활용의 중요성을 강조하며, CNN과 CRF를 결합한 심층 구조 모델을 제안합니다. 이 모델은 CNN 기반의 쌍별 잠재 함수로 패치 간의 의미론적 관계를, 다중 스케일 입력과 슬라이딩 피라미드 풀링으로 패치-배경 컨텍스트를 모델링합니다. 계산 효율성을 위해 조각별 훈련과 비동기 그래디언트 업데이트 방식을 도입했습니다. 8개 주요 벤치마크 데이터셋에서 새로운 최첨단 성능을 달성하며, 복합적인 컨텍스트 정보를 효과적으로 활용하는 심층 구조 모델의 우수성을 입증했습니다.
