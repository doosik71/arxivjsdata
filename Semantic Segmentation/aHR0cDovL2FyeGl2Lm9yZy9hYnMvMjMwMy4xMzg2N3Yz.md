# Few Shot Medical Image Segmentation with Cross Attention Transformer

Yi Lin, Yufan Chen, Kwang-Ting Cheng, and Hao Chen

## 🧩 Problem to Solve

의료 영상 분할은 질병 진단 및 치료 계획 수립에 필수적이지만, 딥러닝 기반의 기존 방법들은 대량의 수동 주석(annotation) 데이터에 크게 의존합니다. 의료 분야에서 이러한 수동 주석은 전문 지식이 필요하며 시간과 비용이 많이 소요되어 심각한 병목 현상을 초래합니다. 특히 3D 볼륨 영상의 경우 이러한 문제는 더욱 심각합니다. 제한된 수의 주석된 예시만으로 새로운 클래스를 학습할 수 있는 Few-Shot Learning(FSL) 패러다임은 이 문제를 해결할 잠재력을 가지고 있지만, 기존 FSL 분할 방법들은 서포트(support) 이미지와 쿼리(query) 이미지 간의 상호작용을 충분히 활용하지 못하거나 단방향 지식 전달에만 초점을 맞추는 한계가 있었습니다.

## ✨ Key Contributions

* 교차 마스크드 어텐션 트랜스포머(Cross Masked Attention Transformer, CMAT) 기반의 새로운 Few-Shot 의료 영상 분할 프레임워크인 CAT-Net을 제안합니다.
* 서포트 이미지와 쿼리 이미지 간의 상관관계를 탐색하여 유용한 전경(foreground) 정보에만 초점을 맞추도록 제한하며, 서포트 프로토타입 및 쿼리 특징의 표현 능력을 상호 강화합니다.
* 쿼리 이미지 분할을 반복적으로 개선하고 서포트 특징을 순차적으로 강화하는 반복 정제(iterative refinement) 프레임워크를 설계했습니다.
* 세 가지 공개 의료 데이터셋(Abd-CT, Abd-MRI, Card-MRI)에서 최신(SOTA) 방법들보다 뛰어난 성능을 달성하여 제안 방법의 효과성과 각 구성 요소의 유효성을 입증했습니다.

## 📎 Related Works

* **완전 지도 학습(Fully-supervised learning)**: 대량의 주석 데이터가 필요한 딥러닝 기반 의료 영상 분할 방법들 [4, 12, 32, 3, 10].
* **레이블 효율적인 기술(Label-efficient techniques)**: 수동 주석의 어려움을 해결하기 위한 방법들 (자체 지도 학습 [15], 준지도 학습 [30, 31], 약지도 학습 [11]).
* **Few-Shot Learning(FSL)**: 제한된 수의 레이블 데이터로 새로운 클래스를 학습하는 패러다임 [22, 24, 6, 28]. 특히 프로토타입 기반 방법 [22] 및 메타 학습 [17, 26, 14]이 포함됩니다.
* **기존 Few-Shot 분할 방법**: 지식 전달 방식에 초점을 맞춘 방법들 [23, 27, 18, 13, 5, 25].
* **의료 FSS의 대표적인 SOTA 방법**: SE-Net [19], PANet [29], ALP-Net [15], AD-Net [7], Q-Net [20].

## 🛠️ Methodology

CAT-Net은 크게 세 가지 구성 요소로 이루어져 있습니다: 마스크 통합 특징 추출(Mask Incorporated Feature Extraction, MIFE), 교차 마스크드 어텐션 트랜스포머(CMAT) 모듈, 반복 정제 프레임워크.

1. **문제 정의**: FSS는 $N$-way $K$-shot 학습을 목표로 하며, 본 논문에서는 의료 FSS의 기존 관례에 따라 1-way 1-shot 작업을 다룹니다.
2. **마스크 통합 특징 추출(MIFE)**:
    * 쿼리 이미지($I_q$)와 서포트 이미지($I_s$)를 ResNet-50 기반 특징 추출 네트워크에 입력하여 다단계 특징 맵 $F_q$와 $F_s$를 생성합니다.
    * 서포트 마스크를 $F_s$와 통합한 후, $F_q$ 및 $F_s$와 연결합니다.
    * MIFE에서 얻은 쿼리 마스크를 쿼리 특징과 추가로 연결하여 쿼리-서포트 특징 간의 픽셀 단위 유사성 관계를 강화합니다.
    * 쿼리 특징은 간단한 분류기를 통해 초기 쿼리 분할 마스크를 생성합니다.
3. **교차 마스크드 어텐션 트랜스포머(CMAT)**: CMAT 모듈은 서포트 및 쿼리 특징이 서로를 강화하도록 합니다.
    * **셀프 어텐션 모듈**: 입력 특징 $F_q^0$와 $F_s^0$를 1D 시퀀스로 평탄화한 후, 멀티-헤드 어텐션(MHA) 및 MLP 레이어로 구성된 모듈에 입력하여 전역 컨텍스트 정보를 포착합니다. 어텐션 행렬은 다음과 같이 계산됩니다:
        $$A(Q,K) = \frac{QK^T}{\sqrt{d}}$$
    * **교차 마스크드 어텐션 모듈**: 쿼리 마스크($M_q$) 및 서포트 마스크($M_s$)를 활용하여 어텐션 영역을 전경 정보로 제한합니다. 이를 통해 쿼리 특징과 서포트 특징 간에 전경 정보를 교환하여 불필요한 배경 정보를 제거합니다. 마스크드 교차 어텐션(MCA) 맵은 다음과 같이 계산됩니다:
        $$MCA(K_q,Q_s,V_q,M_s) = M_s \cdot V_q (\text{softmax}(A(K_q,Q_s)))$$
        유사하게 쿼리 특징도 강화됩니다.
    * **프로토타입 분할 모듈**: 강화된 쿼리($F_q^1$) 및 서포트($F_s^1$) 특징을 사용하여 최종 분할을 예측합니다.
        * 클래스 $c$의 프로토타입 $p_c$는 마스크드 평균 풀링(Masked Average Pooling)을 통해 서포트 특징 $F_s^1$로부터 생성됩니다:
            $$p_c = \frac{1}{K} \sum_{k=1}^K \frac{\sum_{x,y} F_{s_{1,(k,x,y)}} m_s(k,x,y,c)}{\sum_{x,y} m_s(k,x,y,c)}$$
        * 비모수적 메트릭 학습을 사용하여 쿼리 특징과 프로토타입 간의 코사인 거리를 계산하고 Softmax를 적용하여 쿼리 분할 마스크 $\hat{M}_q$를 생성합니다:
            $$\hat{M}_{q_{i,(x,y)}} = \text{softmax} \left( \alpha \cos(F_{q_{i,(x,y)}},p_c) \cdot \text{softmax}(\alpha \cos(F_{q_{i,(x,y)}},p_c)) \right)$$
        * 이중 임계값 전략을 사용하여 쿼리 분할 마스크 $M_q$ (Dice 손실 계산용, $\tau=0.5$)와 확장된 쿼리 마스크 $\hat{M}_q$ (다음 반복에 사용될 특징 강화용, $\hat{\tau}=0.4$)를 얻습니다:
            $$M_{q_i} = \begin{cases} 1, & M_{q_{i,(x,y)}} > \tau \\ 0, & M_{q_{i,(x,y)}} < \tau \end{cases}$$
            $$\hat{M}_{q_i} = \begin{cases} 1, & M_{q_{i,(x,y)}} > \hat{\tau} \\ 0, & M_{q_{i,(x,y)}} < \hat{\tau} \end{cases}$$
4. **반복 정제 프레임워크**: CMAT 모듈은 반복적으로 적용되어 쿼리 및 서포트 특징을 지속적으로 개선하고 분할 성능을 향상시킵니다. $i$번째 반복 후 결과는 다음과 같이 표현됩니다:
    $$(F_{s_i},F_{q_i},M_{q_i},\hat{M}_{q_i}) = CMAT(F_{s_{i-1}},F_{q_{i-1}},\hat{M}_{q_{i-1}},M_s)$$
    세부 단계:
    $$(F_{s_i},F_{q_i}) = CMA(F_{s_{i-1}},F_{q_{i-1}},\hat{M}_{q_{i-1}},M_s)$$
    $$(M_{q_i},\hat{M}_{q_i}) = \text{Proto}(F_{s_i},F_{q_i},M_s,\tau,\hat{\tau})$$

## 📊 Results

* **데이터셋 및 평가**: Abd-CT, Abd-MRI, Card-MRI 세 가지 공개 데이터셋에 대해 Dice Score를 평가 지표로 사용했습니다. 1-way 1-shot 시나리오에서 5-겹 교차 검증을 수행했으며, 두 가지 설정(Setting I: 마지막 환자를 서포트로, Setting II: 모든 이미지를 번갈아 서포트로)에서 평가했습니다.
* **SOTA 비교**:
  * 두 가지 설정 모두에서 제안된 CAT-Net은 SE-Net, PANet, ALP-Net, AD-Net, Q-Net과 같은 최신 방법들보다 일관되게 우수한 성능을 보였습니다.
  * Setting I에서 Abd-CT는 66.59% (1.76%p 향상), Abd-MRI는 75.18% (0.75%p 향상), Card-MRI는 79.03% (0.45%p 향상)의 Dice 점수를 달성했습니다.
  * Setting II에서 Abd-CT는 70.88% (2.56%p 향상), Abd-MRI는 75.22% (2.02%p 향상), Card-MRI는 79.36% (1.32%p 향상)의 Dice 점수를 달성했습니다.
* **정성적 결과**: 시각적 비교에서도 CAT-Net이 SOTA보다 더 정확하고 상세한 분할 결과를 생성함을 보여주었습니다.
* **Ablation Study**:
  * **CMAT 블록의 효과**: 서포트 특징만 사용하거나(Q→S), 쿼리 특징만 사용하거나(S→Q), 또는 양방향 상호작용(S↔Q)을 사용하는 경우를 비교했습니다. S↔Q 방식이 가장 우수하여 상호 강화의 중요성을 입증했습니다. S↔Q는 단방향 학습보다 Dice 점수를 1.90%p 향상시켰습니다.
  * **반복 마스크 정제 블록의 영향**: CMAT 블록의 반복 횟수를 늘릴수록 성능이 향상되었으며, 5회 반복 시 최대 2.26%p의 Dice 점수 향상을 보였습니다. 효율성과 성능의 균형을 위해 최종 모델에서는 4개의 CMAT 블록을 사용했습니다.

## 🧠 Insights & Discussion

CAT-Net은 서포트-쿼리 특징 간의 상호작용을 강조하고 마스크 제약을 통해 관련성 높은 전경 정보에 집중함으로써 Few-Shot 의료 영상 분할의 핵심 과제를 효과적으로 해결합니다. 반복 정제 프레임워크는 분할 품질을 지속적으로 향상시키는 데 기여하며, 이는 의료 이미지와 같이 복잡하고 미묘한 구조를 가진 데이터에 특히 중요합니다. 본 모델의 일관된 우수성과 일반화 능력은 의료 분야에서 데이터 부족 문제를 해결하는 데 큰 잠재력을 시사합니다. 한계점으로는 현재 2D 기반으로 작동한다는 점이 있으며, 향후 3D 네트워크로 확장하여 3D 볼륨 영상에서의 성능을 탐색할 필요가 있습니다. 또한 희귀 질환이나 기형 장기 등 데이터 및 주석이 부족한 다른 임상 응용 분야에도 모델을 적용할 계획입니다.

## 📌 TL;DR

**문제**: 의료 영상 분할은 방대한 수동 주석 데이터가 필요하지만, 이는 비용과 시간이 많이 듭니다. Few-shot learning(FSL)이 대안이지만, 기존 FSL 모델들은 서포트/쿼리 이미지 간의 상호작용을 충분히 활용하지 못했습니다.
**방법**: CAT-Net은 교차 마스크드 어텐션 트랜스포머(CMAT)와 반복 정제 프레임워크를 사용하여 이 문제를 해결합니다. CMAT은 서포트 및 쿼리 특징 간의 상호작용을 강화하여 전경 정보에 집중하고, 반복 정제는 분할 성능을 점진적으로 향상시킵니다.
**결과**: 제안된 CAT-Net은 세 가지 공개 의료 데이터셋에서 기존 SOTA 방법들을 능가하는 성능을 달성하며, 데이터가 부족한 의료 환경에서 효과적이고 일반화 가능한 분할을 위한 강력한 솔루션을 제시합니다.
