{
  "url": "http://arxiv.org/abs/1903.05434v1",
  "title": "Visual Semantic Information Pursuit: A Survey",
  "authors": "Daqi Liu, Miroslaw Bober, Josef Kittler",
  "year": 2019,
  "abstract": "Visual semantic information comprises two important parts: the meaning of\neach visual semantic unit and the coherent visual semantic relation conveyed by\nthese visual semantic units. Essentially, the former one is a visual perception\ntask while the latter one corresponds to visual context reasoning. Remarkable\nadvances in visual perception have been achieved due to the success of deep\nlearning. In contrast, visual semantic information pursuit, a visual scene\nsemantic interpretation task combining visual perception and visual context\nreasoning, is still in its early stage. It is the core task of many different\ncomputer vision applications, such as object detection, visual semantic\nsegmentation, visual relationship detection or scene graph generation. Since it\nhelps to enhance the accuracy and the consistency of the resulting\ninterpretation, visual context reasoning is often incorporated with visual\nperception in current deep end-to-end visual semantic information pursuit\nmethods. However, a comprehensive review for this exciting area is still\nlacking. In this survey, we present a unified theoretical paradigm for all\nthese methods, followed by an overview of the major developments and the future\ntrends in each potential direction. The common benchmark datasets, the\nevaluation metrics and the comparisons of the corresponding methods are also\nintroduced."
}