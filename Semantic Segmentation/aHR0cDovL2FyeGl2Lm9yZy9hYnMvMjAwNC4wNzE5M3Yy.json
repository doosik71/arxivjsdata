{
  "url": "http://arxiv.org/abs/2004.07193v2",
  "title": "A Transductive Approach for Video Object Segmentation",
  "authors": "Yizhuo Zhang, Zhirong Wu, Houwen Peng, Stephen Lin",
  "year": 2020,
  "abstract": "Semi-supervised video object segmentation aims to separate a target object\nfrom a video sequence, given the mask in the first frame. Most of current\nprevailing methods utilize information from additional modules trained in other\ndomains like optical flow and instance segmentation, and as a result they do\nnot compete with other methods on common ground. To address this issue, we\npropose a simple yet strong transductive method, in which additional modules,\ndatasets, and dedicated architectural designs are not needed. Our method takes\na label propagation approach where pixel labels are passed forward based on\nfeature similarity in an embedding space. Different from other propagation\nmethods, ours diffuses temporal information in a holistic manner which take\naccounts of long-term object appearance. In addition, our method requires few\nadditional computational overhead, and runs at a fast $\\sim$37 fps speed. Our\nsingle model with a vanilla ResNet50 backbone achieves an overall score of 72.3\non the DAVIS 2017 validation set and 63.1 on the test set. This simple yet high\nperforming and efficient method can serve as a solid baseline that facilitates\nfuture research. Code and models are available at\n\\url{https://github.com/microsoft/transductive-vos.pytorch}."
}