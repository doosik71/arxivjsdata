{
  "url": "http://arxiv.org/abs/1807.06132v1",
  "title": "Effective Use of Synthetic Data for Urban Scene Semantic Segmentation",
  "authors": "Fatemeh Sadat Saleh, Mohammad Sadegh Aliakbarian, Mathieu Salzmann, Lars Petersson, Jose M. Alvarez",
  "year": 2018,
  "abstract": "Training a deep network to perform semantic segmentation requires large\namounts of labeled data. To alleviate the manual effort of annotating real\nimages, researchers have investigated the use of synthetic data, which can be\nlabeled automatically. Unfortunately, a network trained on synthetic data\nperforms relatively poorly on real images. While this can be addressed by\ndomain adaptation, existing methods all require having access to real images\nduring training. In this paper, we introduce a drastically different way to\nhandle synthetic images that does not require seeing any real images at\ntraining time. Our approach builds on the observation that foreground and\nbackground classes are not affected in the same manner by the domain shift, and\nthus should be treated differently. In particular, the former should be handled\nin a detection-based manner to better account for the fact that, while their\ntexture in synthetic images is not photo-realistic, their shape looks natural.\nOur experiments evidence the effectiveness of our approach on Cityscapes and\nCamVid with models trained on synthetic data only."
}