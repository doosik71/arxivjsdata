# SEGMENT ANY OBJECT MODEL (SAOM): REAL-TO-SIMULATION FINE-TUNING STRATEGY FOR MULTI-CLASS MULTI-INSTANCE SEGMENTATION

Mariia Khan, Jumana Abu-Khalaf, David Suter, Yue Qiu, Yuren Cong, Bodo Rosenhahn

## 🧩 Problem to Solve

* 기존 Segment Anything Model (SAM)의 "everything" 모드는 종종 객체의 부분 또는 하위 부분 마스크를 출력하여, 로봇 공학 및 실내 장면 이해와 같이 전체 객체 분할 마스크가 필수적인 실제 애플리케이션에 사용하기 어렵습니다.
* 실제 환경에서 훈련 데이터를 수집하는 데 드는 높은 비용과 시간 문제를 해결하고, 시뮬레이션 데이터를 활용하는 효율적인 방안이 필요합니다.
* SAM을 실내 환경에서 다중 클래스 다중 인스턴스 분할을 위해 효과적으로 미세 조정할 수 있는 도메인 불변(domain-invariant) 전략이 부재합니다.

## ✨ Key Contributions

* **새로운 Real-to-Simulation (Real-Sim) 미세 조정 전략 제안:** "everything" 모드에서 다중 클래스 다중 인스턴스 의미론적 분할에 적합한 도메인 불변 SAM 미세 조정 전략을 제안합니다. 이 전략의 Real-to-Sim 훈련 단계에서 "nearest neighbour assignment"라는 새로운 방법을 도입하여, 원본 객체 포인트 프롬프트를 이미지의 미리 정의된 포인트 그리드에서 가장 가까운 이웃으로 대체함으로써 모델이 "everything" 모드에서 전체 객체를 인식하도록 합니다.
* **SAOM (Segment Any Object Model) 개발:** 실내 환경에서 전체 객체 의미론적 분할에 특화된 SAM의 미세 조정 버전인 SAOM을 개발했습니다. 이 모델은 훈련 중 실제 데이터를 사용하지 않고도 실제 장면에서 수용 가능한 일반화 성능을 보여주며, 낮은 훈련 비용으로 효과적인 결과를 달성합니다.
* **새로운 데이터셋 공개:** Ai2Thor 시뮬레이터 내에서 SAOM 평가를 위한 새로운 데이터셋을 구축했으며, 이는 의미론적 또는 인스턴스 분할과 같은 다른 분할 작업에도 활용될 수 있습니다. 또한 Sim-to-Real 추론 단계에서 실제 실내 환경의 다양한 컨텍스트에서 수집된 소규모 이미지 세트를 사용했습니다.

## 📎 Related Works

* **SAM 응용 분야:** SAM의 일반화 능력은 의료 영상 분석, 이미지 편집, 위장 객체 탐지, 거울/투명 객체 탐지, 이미지 캡셔닝, 오디오-시각적 현지화, 3D 재구성 등 다양한 분야에서 탐구되어 왔습니다. 그러나 로봇 작업 및 복잡한 시뮬레이션 실내 환경에서의 SAM 성능 분석은 제한적이었습니다.
* **SAM 미세 조정 전략:**
  * **도메인 특정 모델:** SAM-Path [26], Ladder [27] (의료 분야), Segment Salient Object Model [28] (돌출 객체 탐지) 등이 있습니다.
  * **특정 프롬프트 기반 모델:** AquaSAM [29] (바운딩 박스), PerSAM [30] (단일 객체), Open-Vocabulary SAM [32] (레이블 제공 가능하나 "everything" 모드 미지원) 등이 있습니다. 이러한 모델들은 특정 입력 프롬프트를 필요로 하므로, 환경에 대한 사전 지식이 없는 작업에는 적합하지 않습니다.
  * **세분성 제어 모델:** Semantic-SAM [31]은 "everything" 모드에서 의미론적, 인스턴스, 부분 수준 등 다양한 세분성으로 마스크를 생성할 수 있습니다.
  * 기존의 미세 조정 모델들은 레이블을 제공하지 않거나, 특정 데이터 형식에 의존하거나, "everything" 모드에서 다중 클래스 다중 인스턴스 분할에 완전히 적합하지 않다는 한계가 있습니다. 본 연구의 Real-Sim 방법은 이러한 한계를 극복하고, 수동 프롬프트 없이도 모든 관심 객체를 자동으로 마스킹하고 레이블링할 수 있는 최초의 도메인 불변 SAM 미세 조정 전략입니다.

## 🛠️ Methodology

* **목표:** 로봇 에이전트 경로에서 수집된 주어진 이미지 프레임 내의 모든 관심 객체에 대해 정확한 전체 객체 분할 마스크와 해당 클래스(레이블)를 예측합니다.
* **Real-to-Sim 미세 조정:**
  * 모델은 입력 이미지 $x_i \in R^{H \times W \times C}$와 해당 이미지 내 모든 관심 객체에 대한 전체 객체 이진 마스크 $m_1, ..., m_n \in M^{H \times W \times 1}$ 및 레이블 $l_1, ..., l_n \in L$를 입력으로 받습니다.
  * 시뮬레이터 이미지는 일반적으로 해상도가 낮기 때문에(예: 224x224), 바닐라 SAM의 입력 해상도인 1024x1024로 보간합니다.
  * PerSAM [30]을 확장하여 각 ground truth 마스크-레이블 쌍을 순차적으로 처리합니다.
  * **Nearest Neighbour Assignment (가장 가까운 이웃 할당) 방법:**
    * SAM을 사용하여 이미지 $x_i$ 내 목표 객체 $n$의 위치 우선순위(location prior)를 얻습니다.
    * "everything" 모드에서 이 원본 위치 우선순위를 이미지의 미리 정의된 포인트 그리드에서 가장 가까운 이웃으로 대체합니다.
    * 각 ground truth 이진 마스크 $m_i$에 대해, SAM의 이미지 인코더 $Enc$를 사용하여 객체 마스크 특징 $F_m$을 추출합니다. 이미지 특징 $F_x$와 $F_m$ 간의 코사인 유사도 $S$를 계산하여 위치 신뢰도 맵을 구축합니다.
    * 이 맵에서 가장 높은 유사도 값을 가진 픽셀 좌표 $c_i$를 선택하고, 이 $c_i$에서 미리 정의된 2D 이미지 포인트 그리드 $P = [p_1, p_2, ..., p_K]$ 상의 모든 포인트까지의 유클리드 거리 $D$를 계산하여 가장 가까운 이웃 $p_i = \text{arg min}_{p \in P} D(c_i, p)$를 고유한 프롬프트 포인트로 할당합니다.
  * SAM 위에 추가 분류기 레이어를 통합하여 목표 객체의 레이블을 예측합니다.
  * SAM이 출력하는 여러 마스크 중 가장 높은 IoU 점수를 가진 마스크를 선택합니다.
  * 미세 조정 손실은 교차 엔트로피, Focal loss 및 Dice loss의 조합으로 구성됩니다.
* **구현 세부 사항:**
  * Ai2Thor 시뮬레이터를 사용했으며, 224x224 해상도의 RGB 이미지와 이진 객체 마스크를 수집했습니다.
  * ViT-B [34] 이미지 인코더를 사용하는 사전 훈련된 SAM을 채택하여 훈련 속도를 높였습니다.
  * SAOM은 32x32 포인트 그리드를 사용하여 200 에포크 동안 훈련되었으며, 초기 학습률은 $10^{-3}$, AdamW [35] 옵티마이저와 코사인 스케줄러를 사용했습니다.
  * SAM의 자동 마스크 생성기 파라미터를 튜닝하여 중복 마스크를 필터링하고 끊어진 영역을 제거했습니다.

## 📊 Results

* **Real-to-Sim 평가:**
  * 54개 객체 클래스에 대해 SAOM은 기존 SAM 대비 mIoU (평균 교차 결합) 28% (10.82%에서 39.17%), mAcc (평균 정확도) 25% (40.63%에서 65.62%) 향상이라는 유의미한 성능 개선을 달성했습니다.
  * SAOM의 평균 분류 정확도는 0.36을 기록했습니다.
  * 자주 등장하는 객체 클래스에서 IoU 점수가 크게 증가했지만, 일부 객체(예: CounterTop, Dresser)의 경우 데이터셋 내 객체 외관의 난이도(가려짐, 작은 크기)로 인해 정확도가 소폭 감소하기도 했습니다.
  * SAOM은 바닐라 SAM 및 Semantic-SAM과 비교했을 때, 대형 및 중형 객체에 대해 "everything" 모드에서 전체 객체 분할 마스크를 더 정확하게 예측하는 경향을 보였습니다 (Fig. 4).
  * SAOM은 불필요한 세부 마스크를 제거하여 출력 마스크 수를 크게 줄였습니다. Semantic-SAM보다 39%, 원본 SAM보다 81.6% 더 적은 마스크를 생성하여, SAOM이 더 객체 중심적임을 입증했습니다 (Table 5).
* **단일 객체 분할:**
  * 단일 객체 테스트 세트에서 SAOM은 기존 SAM 및 Semantic-SAM보다 우수한 성능을 보여주며, 거의 완벽한 전체 객체 마스크를 생성했습니다 (Fig. 6 왼쪽).
* **객체 포인트 프롬프트 선택의 중요성:**
  * 'nearest neighbour assignment' 방법의 중요성이 실험을 통해 확인되었습니다. 이 방법을 사용하지 않은 SAOM은 더 많은 에포크를 훈련했음에도 불구하고, 목표한 전체 객체 분할 결과를 달성하지 못했습니다 (Fig. 5).
* **Sim-to-Real 추론 단계:**
  * SAOM은 실제 환경 데이터로 훈련하지 않고도 실제 데이터에 대해 우수한 일반화 성능을 보여주었으며, 전체 객체 분할 마스크를 예측할 수 있음을 입증했습니다.
  * 가려지지 않거나 약간 가려진 객체에 대해서는 고품질 마스크를 예측했습니다. 그러나 대부분 가려진 객체(예: 안락의자)의 경우, SAOM은 주로 그 위에 있는 작은 집을 수 있는 객체에 집중하는 경향을 보였습니다 (Fig. 6 오른쪽).
  * 배경이 복잡한 경우, SAOM은 전경 객체 대신 배경에 집중하는 경향도 나타냈습니다.

## 🧠 Insights & Discussion

* **의미:**
  * 본 연구는 시뮬레이션 환경에서 미세 조정된 SAM이 실제 세계에서도 효과적인 전체 객체 분할을 가능하게 함을 보여주었습니다. 이는 실제 데이터 수집의 높은 비용과 시간을 절감하는 중요한 이점을 제공하며, 로봇 공학 등 실제 응용 분야에서 SAM의 활용도를 높입니다.
  * 제안된 'nearest neighbour assignment' 방법은 SAM의 "everything" 모드에서 객체의 부분 마스크 대신 전체 객체 마스크를 예측하는 능력을 크게 향상시키는 데 핵심적인 역할을 했습니다.
  * 출력 마스크 수의 상당한 감소는 SAOM이 불필요한 세부 사항에 집중하지 않고, 사용자가 관심 있는 전체 객체에 초점을 맞추도록 성공적으로 유도되었음을 의미합니다.
* **한계:**
  * SAOM은 배경 객체보다 전경 객체에 대한 마스크 예측 성능이 더 우수한 경향이 있습니다. 이는 배경 객체의 상대적으로 작은 크기 때문일 수 있습니다. 이를 극복하기 위해 더 많은 포인트가 있는 그리드(예: 64x64)를 사용하거나, ViT-B보다 더 강력한 백본 모델을 사용하는 방안을 제안합니다.
  * 분류 정확도 점수가 아직 낮아, 데이터 증강 기술 등을 통해 추가적인 개선이 필요합니다.
* **향후 연구:**
  * 향후 연구에서는 Real-Sim 전략을 도메인 적응(domain adaptation) 또는 도메인 무작위화(domain randomization) 방법과 결합하여 실제 장면에서의 SAOM 일반화 능력을 더욱 향상시킬 계획입니다.

## 📌 TL;DR

* **문제:** SAM은 "everything" 모드에서 객체의 부분 마스크를 생성하여 로봇 공학 및 실내 장면 이해에 필요한 전체 객체 분할에 비효율적이며, 실제 데이터 수집은 비용이 많이 듭니다.
* **제안 방법:** Real-to-Simulation (Real-Sim) 미세 조정 전략을 제안하여 SAM을 SAOM으로 변환합니다. 이 전략은 시뮬레이터에서 수집한 객체 이미지와 GT 데이터를 사용하여 훈련하며, "nearest neighbour assignment" 방법을 통해 포인트 프롬프트를 조정하여 "everything" 모드에서 전체 객체 마스크를 출력하도록 합니다. 또한 분류기 레이어를 추가하여 객체 레이블을 예측합니다.
* **주요 결과:** SAOM은 기존 SAM에 비해 mIoU 28%, mAcc 25% 향상되었으며, 출력 마스크 수를 80% 이상 줄였습니다. 실제 데이터를 사용하지 않고 훈련했음에도 불구하고 실제 환경에 대한 우수한 Sim-to-Real 일반화 성능을 보여주었습니다.
