{
  "url": "http://arxiv.org/abs/1812.09953v3",
  "title": "A Curriculum Domain Adaptation Approach to the Semantic Segmentation of\n  Urban Scenes",
  "authors": "Yang Zhang, Philip David, Hassan Foroosh, Boqing Gong",
  "year": 2018,
  "abstract": "During the last half decade, convolutional neural networks (CNNs) have\ntriumphed over semantic segmentation, which is one of the core tasks in many\napplications such as autonomous driving and augmented reality. However, to\ntrain CNNs requires a considerable amount of data, which is difficult to\ncollect and laborious to annotate. Recent advances in computer graphics make it\npossible to train CNNs on photo-realistic synthetic imagery with\ncomputer-generated annotations. Despite this, the domain mismatch between the\nreal images and the synthetic data hinders the models' performance. Hence, we\npropose a curriculum-style learning approach to minimizing the domain gap in\nurban scene semantic segmentation. The curriculum domain adaptation solves easy\ntasks first to infer necessary properties about the target domain; in\nparticular, the first task is to learn global label distributions over images\nand local distributions over landmark superpixels. These are easy to estimate\nbecause images of urban scenes have strong idiosyncrasies (e.g., the size and\nspatial relations of buildings, streets, cars, etc.). We then train a\nsegmentation network, while regularizing its predictions in the target domain\nto follow those inferred properties. In experiments, our method outperforms the\nbaselines on two datasets and two backbone networks. We also report extensive\nablation studies about our approach.",
  "citation": 175
}