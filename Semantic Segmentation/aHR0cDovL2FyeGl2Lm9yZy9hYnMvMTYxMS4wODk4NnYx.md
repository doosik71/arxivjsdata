# Improving Fully Convolution Network for Semantic Segmentation

Bing Shuai, Ting Liu, Gang Wang

## 🧩 Problem to Solve

기존의 완전 컨볼루션 네트워크(FCN)는 시맨틱 분할에서 큰 성공을 거두었지만, 몇 가지 한계점이 존재합니다.

- **도메인 격차(Domain Gap)**: FCN은 저해상도 이미지(예: $224 \times 224$ 픽셀) 분류를 위해 사전 훈련된 CNN(예: VGG-16) 아키텍처를 고해상도 시맨틱 분할 이미지(예: $512 \times 512$ 픽셀)에 단순히 적용합니다. 이로 인해 효과적으로 해소되지 않는 도메인 격차가 발생하며, 특징 맵의 컨텍스트 필드(contextual fields)가 제한되어 지역적으로 모호한 영역에 대한 예측이 일관적이지 못하게 됩니다.
- **제한된 스케일 융합**: FCN-8s는 `pool3`, `pool4`, `fc7`의 세 가지 스케일 예측만을 통합합니다. 이는 이미지 내 객체의 다양한 스케일 변화를 효과적으로 처리하기에 충분하지 않습니다.

## ✨ Key Contributions

본 논문은 FCN의 이러한 아키텍처적 한계를 개선한 IFCN(Improved Fully Convolution Network)을 제안합니다.

- **컨텍스트 네트워크 도입**: 사전 훈련된 CNN과 업샘플 레이어 사이에 컨텍스트 네트워크를 삽입하여 특징 맵의 수용 필드를 점진적으로 확장합니다. 이는 새로운 파라미터를 도입하여 고해상도 분할 이미지에 대한 미세 조정 시 도메인 격차를 메우는 데 중요합니다.
- **조밀한 스킵 연결(Dense Skip Connections)**: 컨텍스트 네트워크 내부와 사전 훈련된 CNN의 초기 특징 맵에서 더 많은 스킵 연결을 추가합니다.
  - 컨텍스트 네트워크 내 스킵 연결은 경사 소실(gradient vanishing) 문제를 완화하여 네트워크의 효과적인 최적화를 돕습니다.
  - 사전 훈련된 CNN의 초기 레이어로부터의 스킵 연결은 IFCN이 풍부한 스케일의 컨텍스트를 융합하여 더 신뢰할 수 있는 예측을 수행할 수 있도록 합니다.
- **FC 레이어 제거**: 사전 훈련된 CNN의 마지막 두 FC 레이어(`fc6`, `fc7`)를 제거하여 특징 맵을 더 압축하고 네트워크 크기를 줄입니다.
- **SOTA 성능 달성**: 컨텍스트 후처리 없이도 ADE20K, Pascal Context, Pascal VOC 2012, SUN-RGBD 등 여러 표준 시맨틱 분할 데이터셋에서 기존 최신 기술(State-of-the-Art, SOTA)을 크게 능가하는 성능을 달성했습니다.

## 📎 Related Works

- **FCN [18]**: 시맨틱 분할을 위한 사실상의(de facto) 네트워크 아키텍처로, 사전 훈련된 분류 네트워크를 미세 조정하여 사용합니다.
- **컨텍스트 모델링 기법**:
  - **CRF 기반 방법**: [4] DeepLab + FC-CRF, [34] CRF-RNN 등은 FCN의 단일 예측(unary predictions)을 후처리 단계에서 개선하는 데 주로 사용됩니다. 본 연구는 이와 직교적이며, IFCN의 성능을 더욱 향상시킬 수 있습니다.
  - **새로운 연산 레이어 도입**: [17] 지역 컨볼루션, [14] 컨볼루션 레이어를 통한 시맨틱 호환성 모델링, [28, 24] RNN을 통한 컨텍스트 전파, [33] Dilated Convolution (확장 컨볼루션)을 통한 수용 필드 확장 등이 있습니다. IFCN의 컨텍스트 네트워크는 이러한 접근법과 유사하지만, 조밀한 스킵 연결을 통해 더 깊은 구조를 효과적으로 훈련하고 더 넓은 수용 필드 및 풍부한 스케일 융합을 달성합니다.
- **멀티-스케일 예측 융합**: [6, 14] 이미지 피라미드(image pyramid) 또는 [2] Hypercolumn features와 같은 방법을 사용합니다. 이들은 높은 계산 비용이나 메모리 요구 사항을 가지지만, IFCN은 조밀한 스킵 연결을 통해 매우 효율적이고 효과적으로 풍부한 컨텍스트 예측을 융합합니다.

## 🛠️ Methodology

IFCN은 FCN의 기본 구조에 두 가지 핵심적인 아키텍처 변경을 적용합니다.

1. **컨텍스트 네트워크(Context Network)**

   - **위치**: 사전 훈련된 CNN(예: VGG-16의 `pool5` 이후 또는 ResNet의 마지막 레이어)과 업샘플링 레이어 사이에 삽입됩니다.
   - **구조**: `Conv + BN + ReLU`로 구성된 `convblock`을 여러 개(`M`개) 쌓아 올린 조밀하게 분기된(densely branched) 컨볼루션 네트워크입니다.
   - **목표**: 특징 맵의 수용 필드를 효과적으로 확장하여 더 넓은 컨텍스트 정보를 포착합니다.
   - **단축 브랜치(Shortcut Branches)**: 각 `convblock`의 중간 특징 맵($f_{i}$)에서 단축 브랜치가 추가되어 지역 예측을 수행하며, 이 예측들은 최종 융합된 예측 맵 $F$를 생성하기 위해 합산됩니다.
     - 수식: $F = \sum_{i=1}^{M} S(\Theta_{i}, f_{i})$
     - 이러한 구조는 오류 신호의 전파를 위한 단축 경로를 제공하여 경사 소실 문제를 크게 완화하고 컨텍스트 네트워크의 효과적인 훈련을 가능하게 합니다. 또한, 각 $f_i$가 다른 스케일 컨텍스트를 보존하므로, 융합된 $F$는 더 견고한 예측을 제공합니다.

2. **조밀한 스킵 연결(Dense Skip Connections)**
   - FCN-8s가 `pool3`, `pool4`, `fc7`의 세 가지 스케일만 융합하는 것과 달리, IFCN-xs는 사전 훈련된 CNN의 초기 특징 맵(`pool3`부터 시작하는 모든 후속 특징 맵)에서 예측 맵으로 더 많은 스킵 연결을 추가합니다.
   - 이는 각 특징 맵이 고유한 스케일 정보를 가지고 있어 객체 스케일의 큰 변화를 처리하는 데 상호 보완적이라는 점을 활용합니다.
   - 이러한 조밀한 스킵 연결은 FCN-xs에 비해 미미한 추가 계산 오버헤드만을 발생시킵니다.
   - **훈련**: 픽셀 단위 손실(pixel-wise loss)을 사용하며, [24]와 유사하게 드문 클래스(infrequent classes)에 더 많은 주의를 기울이기 위해 희귀도(rareness)에 따라 손실을 조정합니다.

## 📊 Results

IFCN은 ADE20K, Pascal Context, Pascal VOC 2012, SUN-RGBD 등 다양한 시맨틱 분할 데이터셋에서 포괄적인 평가를 통해 그 성능을 입증했습니다.

- **FCN 대비 월등한 성능**:
  - IFCN-8s (VGG-16)는 모든 데이터셋에서 FCN-8s 대비 Mean IoU 기준으로 7.5% 이상 크게 향상된 성능을 보였습니다. 예를 들어, ADE20K에서 FCN-8s의 Mean IoU는 29.32%였으나, IFCN-8s는 36.98%를 달성했습니다.
  - 이는 객체 분할, 실외 장면 파싱, 실내 장면 레이블링 등 광범위한 시나리오에 걸쳐 IFCN이 FCN보다 훨씬 우수한 분할 네트워크 아키텍처임을 보여줍니다.
- **아키텍처 디자인의 중요성**:
  - **수용 필드 확장**: 컨텍스트 네트워크를 통한 수용 필드 확장이 분할 성능 향상에 매우 중요함이 입증되었습니다. IFCN-8s-A가 FCN-8s보다 현저히 큰 수용 필드를 가짐으로써 상당한 성능 우위를 보였습니다.
  - **깊이와 성능**: 동일한 수용 필드 크기에서 더 깊은 컨텍스트 네트워크(더 많은 convblock 및 단축 브랜치)가 얕은 네트워크보다 더 나은 성능을 보였습니다. 이는 더 많은 스킵 연결을 통해 정보 융합이 풍부해지기 때문입니다.
  - **파라미터 수보다 아키텍처**: 성능 향상이 단순히 파라미터 수의 증가 때문이 아니라, 컨텍스트 네트워크의 아키텍처(수용 필드 확장, 스킵 연결) 덕분임을 실험으로 검증했습니다.
  - **조밀한 스킵 연결의 필수성**: 단축 브랜치를 제거한 IFCN-8s-B가 IFCN-8s-A보다 성능이 크게 저하되는 것을 통해, 단축 브랜치가 컨텍스트 네트워크 훈련을 개선하고 멀티 스케일 컨텍스트 예측 융합에 중요함을 입증했습니다.
- **더 깊은 사전 훈련 네트워크(ResNet)에도 적용 가능**: ResNet-50 및 ResNet-101 기반에서도 IFCN-8s는 FCN-8s를 일관되게 능가하며, 제안된 아키텍처 설계의 일반성과 효과를 증명했습니다. 특히 ResNet-101 기반 IFCN-8s는 ADE20K에서 39.73%의 Mean IoU를 달성하며 SOTA를 갱신했습니다.
- **경쟁력 있는 추론 시간**: FCN-8s 대비 추론 시간이 다소 길어졌으나(FCN-8s: 25.0ms, IFCN-8s (VGG-16): 47.9ms), DeepLab, DilatedNet 등 다른 최신 분할 네트워크 아키텍처와 비교했을 때 경쟁력 있는 수준입니다.
- **정성적 결과**: IFCN-8s는 FCN-8s가 어려움을 겪는 확대된 객체에 대해 더 견고한 예측을 수행하고, FCN-8s보다 더 날카로운 경계를 가진 매우 상세한 분할 맵을 생성할 수 있습니다.

## 🧠 Insights & Discussion

- **FCN 한계의 성공적 극복**: IFCN은 FCN의 주요 한계점인 제한된 수용 필드와 불충분한 스케일 융합 문제를 효과적으로 해결했습니다. 컨텍스트 네트워크를 통한 수용 필드 확장은 지역적 모호성을 줄이고 더 넓은 컨텍스트를 활용하게 하며, 조밀한 스킵 연결은 다양한 스케일의 객체를 처리하는 데 필수적인 풍부한 스케일 컨텍스트를 통합합니다.
- **아키텍처적 우위**: 성능 향상이 단순히 파라미터 수의 증가 때문이 아니라, 컨텍스트 네트워크의 구조적 설계와 조밀한 스킵 연결에서 비롯된 것임을 명확히 보여줍니다. 이는 효율적이면서도 강력한 네트워크 설계를 가능하게 합니다.
- **다용도성 및 확장성**: VGG-16뿐만 아니라 ResNet과 같은 더 깊은 사전 훈련 네트워크에도 일관되게 성능 향상을 가져다주어 IFCN 아키텍처의 다용도성과 다양한 기반 모델에 대한 확장성을 입증했습니다.
- **성능 향상의 원인**: 조밀한 스킵 연결이 컨텍스트 네트워크의 훈련 난이도(경사 소실 문제)를 완화하고, 다양한 스케일의 특징 맵을 통합하여 예측의 견고성을 높이는 데 핵심적인 역할을 합니다. 특히, 초기 레이어의 스킵 연결은 분할 맵의 세부적인 경계를 더 날카롭게 만드는 데 기여합니다.
- **향후 개선 가능성**: 본 연구는 별도의 컨텍스트 후처리(예: FC-CRF)나 보조 데이터(예: Microsoft COCO)를 사용하지 않았음에도 SOTA 성능을 달성했지만, 이러한 기법들을 IFCN과 결합하면 추가적인 성능 향상을 기대할 수 있습니다.

## 📌 TL;DR

FCN의 제한된 수용 필드와 불충분한 스케일 융합 문제를 해결하기 위해, 본 논문은 **IFCN**을 제안합니다. IFCN은 **컨텍스트 네트워크**를 통해 특징 맵의 수용 필드를 확장하고, **조밀한 스킵 연결**을 통해 풍부한 스케일 컨텍스트를 융합하여 예측의 견고성을 높입니다. 결과적으로, IFCN은 컨텍스트 후처리 없이도 다양한 시맨틱 분할 데이터셋에서 **FCN을 일관되게 크게 능가하며 새로운 SOTA 성능을 달성**했습니다.
