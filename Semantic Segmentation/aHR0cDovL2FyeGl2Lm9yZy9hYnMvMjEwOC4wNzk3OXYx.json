{
  "url": "http://arxiv.org/abs/2108.07979v1",
  "title": "A New Bidirectional Unsupervised Domain Adaptation Segmentation Framework",
  "authors": "Munan Ning, Cheng Bian, Dong Wei, Chenglang Yuan, Yaohua Wang, Yang Guo, Kai Ma, Yefeng Zheng",
  "year": 2021,
  "abstract": "Domain shift happens in cross-domain scenarios commonly because of the wide\ngaps between different domains: when applying a deep learning model\nwell-trained in one domain to another target domain, the model usually performs\npoorly. To tackle this problem, unsupervised domain adaptation (UDA) techniques\nare proposed to bridge the gap between different domains, for the purpose of\nimproving model performance without annotation in the target domain.\nParticularly, UDA has a great value for multimodal medical image analysis,\nwhere annotation difficulty is a practical concern. However, most existing UDA\nmethods can only achieve satisfactory improvements in one adaptation direction\n(e.g., MRI to CT), but often perform poorly in the other (CT to MRI), limiting\ntheir practical usage. In this paper, we propose a bidirectional UDA (BiUDA)\nframework based on disentangled representation learning for equally competent\ntwo-way UDA performances. This framework employs a unified domain-aware pattern\nencoder which not only can adaptively encode images in different domains\nthrough a domain controller, but also improve model efficiency by eliminating\nredundant parameters. Furthermore, to avoid distortion of contents and patterns\nof input images during the adaptation process, a content-pattern consistency\nloss is introduced. Additionally, for better UDA segmentation performance, a\nlabel consistency strategy is proposed to provide extra supervision by\nrecomposing target-domain-styled images and corresponding source-domain\nannotations. Comparison experiments and ablation studies conducted on two\npublic datasets demonstrate the superiority of our BiUDA framework to current\nstate-of-the-art UDA methods and the effectiveness of its novel designs. By\nsuccessfully addressing two-way adaptations, our BiUDA framework offers a\nflexible solution of UDA techniques to the real-world scenario.",
  "citation": 20
}