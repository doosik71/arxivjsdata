# YouTube-VOS: A Large-Scale Video Object Segmentation Benchmark

Ning Xu, Linjie Yang, Yuchen Fan, Dingcheng Yue, Yuchen Liang, Jianchao Yang, and Thomas Huang

## 🧩 Problem to Solve

기존 비디오 객체 분할(VOS) 방법론은 주로 정적 이미지 분할 기술에 의존하거나 사전에 훈련된 옵티컬 플로우 모델에 의존하여 최적의 성능을 내지 못했습니다. 이는 시공간적 특징을 활용한 종단 간(end-to-end) 학습이 가능하도록 충분한 규모의 비디오 분할 데이터셋이 부족했기 때문입니다. 당시 가장 큰 비디오 분할 데이터셋조차도 90개의 짧은 비디오 클립만을 포함하여, 비디오 분석 작업에 필수적인 장기 시공간 특징 학습에 한계가 있었습니다.

## ✨ Key Contributions

- **YouTube-VOS 데이터셋 구축 및 공개**: 장기 시공간 특징 학습을 위한 최초의 대규모 비디오 객체 분할 데이터셋인 YouTube-VOS를 구축하고 공개했습니다. 이 데이터셋은 4,453개의 유튜브 비디오 클립과 94개의 객체 카테고리를 포함하여 기존 데이터셋보다 훨씬 크고 다양합니다.
- **최신 VOS 알고리즘 벤치마킹**: YouTube-VOS 데이터셋을 활용하여 여러 최신 비디오 객체 분할 알고리즘의 성능을 평가하고 벤치마크를 수립하여, 향후 새로운 알고리즘 개발을 위한 기준점을 제시했습니다.

## 📎 Related Works

- **기존 VOS 데이터셋**: DAVIS [15,20], YouTubeObjects [16], JC [21], ST [22], FBMS [24] 등 기존 VOS 데이터셋은 규모가 작고 내용이 비교적 단순하며 해상도가 낮습니다. DAVIS 2017은 90개의 비디오로 다중 객체, 카메라 움직임, 가림 등 복잡한 상황을 포함하지만 여전히 규모가 작습니다.
- **초기 VOS 방법론**: 외형, 경계, 움직임, 옵티컬 플로우와 같은 특징을 기반으로 공간-시간 그래프 구조를 해결하는 방식 [16,28,29,30,31]이 주로 사용되었습니다.
- **딥러닝 기반 VOS 방법론**: 이미지 분할 네트워크 [32,33]를 기반으로 하며, 대부분 순차적 모델링 없이 온라인 학습 [7]을 통해 성능을 개선합니다 [7,8,9,10,11]. 일부는 이전 프레임의 마스크를 가이드로 사용하며 [8,9,14], 시공간 정보를 활용하려는 시도 [12,13]도 있었으나, 훈련 데이터 부족으로 인해 사전에 훈련된 옵티컬 플로우 [17,18]나 모션 분할 모델 [19]에 의존하여 최적의 종단 간 학습이 어려웠습니다.
- **최근 시퀀스-투-시퀀스 학습**: Xu et al. [34]은 YouTube-VOS의 초기 버전을 사용하여 옵티컬 플로우 모델에 의존하지 않는 시퀀스-투-시퀀스 학습 알고리즘을 제안했습니다.

## 🛠️ Methodology

YouTube-VOS 데이터셋은 다음과 같은 방식으로 구축되었습니다.

1. **카테고리 선정**: 사람, 동물, 차량, 액세서리 등 78개의 다양한 객체 카테고리를 선정했습니다. 특히, 사람 관련 비디오는 다양한 움직임과 행동을 포함하도록 활동 태그를 사용하여 수집했습니다.
2. **비디오 수집**: 대규모 비디오 분류 데이터셋인 YouTube-8M [26]에서 선정된 카테고리에 해당하는 고해상도 비디오를 검색했습니다. 유튜브 비디오는 다양한 객체 외형 및 움직임, 가림, 빠른 움직임, 카메라 흔들림 등 도전적인 상황을 포함합니다.
3. **비디오 클립 추출**: 긴 비디오를 오프라인 샷 감지 알고리즘을 사용하여 여러 클립으로 분할했습니다. 소개 및 크레딧이 포함된 클립은 제외하고, 적절한 길이(3~6초)의 클립을 최대 5개 샘플링하여 수동으로 검증했습니다.
4. **수동 주석(Annotation)**:
   - 각 비디오 클립당 적절한 크기와 카테고리를 가진 최대 5개의 객체를 선택했습니다.
   - 30fps 프레임 속도에서 5프레임마다 (즉, 6fps 샘플링 속도) 객체 경계를 수동으로 추적하여 정밀하게 주석을 달았습니다.
   - 비디오 레벨 카테고리 외에 추가적인 객체 카테고리(예: 테니스 라켓, 스케이트보드 등)를 포함하여 총 94개의 인스턴스-레벨 객체 카테고리를 라벨링했습니다.
   - 연속된 프레임 간의 높은 시간적 상관관계를 고려하여 중간 프레임의 주석을 생략하는 스킵-프레임(skip-frame) 주석 전략을 사용하여 주석 작업 비용을 줄였습니다.
5. **데이터셋 분할**: 전체 4,453개 비디오를 학습(3,471), 검증(474), 테스트(508) 세트로 분할했습니다. 검증 세트에는 학습 세트에 없는 26개의 '미등록(unseen)' 카테고리가 포함되어 알고리즘의 일반화 능력을 평가할 수 있도록 했습니다.

## 📊 Results

- **성능 비교**: OSVOS [7], MaskTrack [8], OSMN [9], OnAVOS [35], S2S [34] 등 최신 VOS 알고리즘들을 YouTube-VOS 데이터셋에서 재훈련하고 평가했습니다.
- **핵심 지표**: 영역 유사도($\mathcal{J}$)와 윤곽 정확도($\mathcal{F}$)를 사용했으며, 등록(seen) 카테고리와 미등록(unseen) 카테고리에 대한 평균 성능을 종합하여 "Overall" 점수를 산출했습니다.
- **S2S의 우수성**: 장기 시공간 일관성을 활용하는 S2S (with OL) [34] 모델이 전체 정확도에서 OSVOS를 비롯한 다른 온라인 학습(Online Learning, OL) 방법들보다 약 6%p 높은 성능을 달성하여 $\mathbf{64.4\%}$의 Overall 점수로 가장 우수했습니다. 이는 비디오 객체 분할에서 장기 시공간 정보의 중요성을 입증합니다.
- **온라인 학습의 한계**: DAVIS에서 최고 성능을 보였던 OnAVOS는 YouTube-VOS에서 상대적으로 낮은 성능을 보였는데, 이는 YouTube-VOS의 급격한 외형 변화와 복잡한 움직임 패턴이 온라인 적응을 어렵게 만들기 때문으로 분석됩니다.
- **미등록 카테고리 일반화**: 모든 방법론은 등록 카테고리에서 미등록 카테고리보다 훨씬 좋은 결과를 보였습니다. OSVOS가 미등록 카테고리에서 가장 작은 성능 차이를 보였는데, 이는 대규모 이미지 분할 데이터셋에서의 사전 훈련 덕분일 수 있습니다. 온라인 학습이 미등록 카테고리의 정확도를 향상시키지만, 일반적인 객체 특징 표현을 학습하기 위한 대규모 데이터셋 사전 훈련의 중요성도 시사됩니다.
- **추론 속도**: OSMN과 S2S (w/o OL)는 온라인 학습을 사용하지 않아 실시간 적용이 가능한 매우 빠른 추론 속도를 보였습니다(각각 0.14s/frame, 0.16s/frame).

## 🧠 Insights & Discussion

YouTube-VOS 데이터셋은 기존 데이터셋에 비해 비디오 수, 주석 수, 객체 카테고리 면에서 월등히 크고 복잡하여, 비디오 객체 분할 연구에 새로운 지평을 열었습니다. 기존 SOTA 알고리즘들은 이 새로운 데이터셋에서 더 큰 성능 격차를 보였으며, 특히 미등록 카테고리에 대한 일반화 능력이 크게 부족했습니다. 이는 데이터셋의 복잡성과 다양성이 기존 방법론의 한계를 드러냈음을 의미합니다.

S2S 모델의 뛰어난 성능은 장기 시공간 특징을 직접 학습하는 것이 비디오 객체 분할에 매우 중요함을 시사합니다. 또한, 온라인 학습 없이도 실시간에 가까운 속도를 내는 모델의 등장은 모바일 애플리케이션 등 실제 적용 가능성을 높입니다. 이 데이터셋은 향후 비디오 기반 컴퓨터 비전, 특히 복잡한 실제 시나리오에서 객체를 정확하게 분할하고 추적하는 알고리즘 개발을 촉진할 것으로 기대됩니다.

## 📌 TL;DR

이 논문은 기존 비디오 객체 분할(VOS) 연구의 주요 한계점인 대규모 시공간 특징 학습 데이터셋의 부족 문제를 해결하기 위해, 방대한 규모의 **YouTube-VOS** 데이터셋을 구축하고 공개했습니다. YouTube-VOS는 4,453개의 유튜브 비디오와 94개의 객체 카테고리를 포함하여 기존 데이터셋보다 훨씬 다양하고 복잡한 실제 시나리오를 반영합니다. 또한, 이 데이터셋을 사용하여 최신 VOS 알고리즘들을 벤치마킹한 결과, 장기 시공간 정보를 활용하는 S2S 모델이 가장 우수한 성능을 보였으며, 미등록 카테고리에 대한 기존 방법들의 일반화 능력 부족을 확인했습니다. 이는 향후 VOS 연구가 복잡한 시공간적 상호작용과 새로운 객체에 대한 일반화 능력에 초점을 맞춰야 함을 시사합니다.
