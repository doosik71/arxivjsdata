# 시각-언어 모델 시대의 의미론적 분할을 위한 비지도 도메인 적응 연구

Manuel Schwonberg, Claus Werner, Hanno Gottschalk, Carsten Meyer

## 🧩 Problem to Solve

최근 딥러닝 기반 컴퓨터 비전의 발전에도 불구하고, 학습 데이터와 추론 데이터의 분포가 달라지는 도메인 시프트(domain shift)는 여전히 주요 과제로 남아있습니다. 특히 자율 주행을 위한 의미론적 분할(semantic segmentation)은 날씨 변화, 지리적 위치 변화, 합성 데이터 사용 등으로 인한 다양한 도메인 시프트에 직면합니다. 기존의 비지도 도메인 적응(Unsupervised Domain Adaptation, UDA) 방법들은 타겟 도메인의 레이블 없는 데이터만을 사용하여 모델을 적응시키지만, 모두 ImageNet으로 사전 훈련된 모델을 사용합니다. 최근 시각-언어 모델(Vision-Language Models, VLMs)이 강력한 일반화 능력을 보여주었지만, UDA 분야에서는 그 잠재력이 거의 탐구되지 않았습니다.

이 연구는 기존 UDA 방법들의 인코더를 VLM 사전 훈련 인코더로 간단히 교체하는 것만으로도 성능 향상을 가져올 수 있는지, 그리고 이러한 UDA 방법들이 이전에 본 적 없는 도메인(unseen domains)에 대해 얼마나 잘 일반화되는지를 탐구합니다. 또한, 혼합된 도메인 시프트가 아닌 순수한 단일 도메인 시프트(예: 특정 악천후 조건)에서의 성능도 평가하고자 합니다.

## ✨ Key Contributions

* **VLM 사전 훈련 백본의 효과 입증**: DACS와 같은 기존 UDA 방법을 최신 시각-언어 사전 훈련 백본(EVA02-CLIP)과 함께 광범위하게 평가하여, GTA5→Cityscapes 도메인 이동에서 최대 10.0% mIoU, 세 가지 미확인 데이터셋에 걸쳐 최대 13.7% mIoU의 유의미한 성능 향상을 입증했습니다.
* **VLM 인코더와의 호환성 분석**: 모든 UDA 방법이 VLM 기반 인코더와 유사하게 호환되는 것은 아니며, 이는 시각-언어 모델에 특화된 새로운 UDA 방법의 필요성을 시사한다는 것을 밝혔습니다. (예: DAFormer의 FD-loss가 VLM과 잘 맞지 않음)
* **일반화 성능에 대한 심층 분석**: UDA 성능과 일반화 성능이 반드시 상관관계가 있는 것은 아니며, 최근 도메인 일반화(Domain Generalization, DG) 방법이 UDA 방법보다 더 나은 일반화 성능을 제공할 수 있음을 보여주는 광범위한 미확인 데이터셋 평가를 수행했습니다.
* **순수 도메인 시프트 평가**: 순수한 실제-실제(real-to-real) 악천후 조건 도메인 시프트(ACDC 데이터셋)에서 적응 및 일반화 성능을 추가로 검증하여 연구 결과를 뒷받침했습니다.

## 📎 Related Works

* **비지도 도메인 적응 (UDA) 방법**: 입력, 특징, 출력 공간 적응 및 하이브리드 방법으로 분류됩니다. 적대적 적응(AdaptSegNet, ADVENT), 대조 학습(SePiCo), 자기 훈련(DACS, DAFormer), 지식 증류(knowledge distillation) 등의 기법들이 활용됩니다.
* **UDA 아키텍처**: 과거에는 ImageNet으로 사전 훈련된 VGG-16 및 ResNet-101 네트워크가 주로 사용되었고, 최근에는 DAFormer의 MiT-B5와 같은 비전 트랜스포머 백본이 인기를 얻었습니다. 그러나 이 모든 백본은 ImageNet 사전 훈련에 기반합니다.
* **시각-언어 모델 (VLMs)**: CLIP이 선구적인 연구이며, 대규모 다중 모달 데이터셋(예: Laion-5B)을 통해 훈련됩니다. 주로 다운스트림 작업(예: 의미론적 분할)을 위한 전이 학습(transfer learning)에 사용됩니다. Englert et al. [12]의 최근 연구만이 UDA를 위해 파운데이션 모델을 탐구했습니다.
* **도메인 일반화 (DG)**: 타겟 데이터 없이 여러 미확인 도메인에 걸쳐 잘 일반화되는 모델을 목표로 합니다. Rein, CLOUDS, VLTSeg와 같은 최근 DG 연구들은 VLM을 활용하여 성능을 크게 향상시켰습니다. 본 연구는 Piva et al. [43]의 연구와 평가 방법론에서 유사점을 공유하지만, VLM은 그들의 연구에 포함되지 않았습니다.

## 🛠️ Methodology

* **선정된 UDA 방법**: AdaptSegNet [60], ADVENT [64], DACS [59], SePiCo [67], DAFormer [21], MIC [24]를 포함하여, 영향력 있는 초기 방법과 최신 SOTA(state-of-the-art) 방법을 모두 다루었습니다.
* **인코더 및 초기화**:
  * **주요 인코더**: 강력한 일반화 능력을 보인 EVA02-CLIP-L-14 시각 인코더 [57] (EVA02-L로 지칭)를 사용했습니다. 이는 CLIP 및 마스크 이미지 모델링 사전 훈련을 기반으로 합니다.
  * **기준 인코더**: ImageNet 사전 훈련된 ResNet-101 백본을 사용하는 DeepLabv2 및 MiT-B5 백본을 사용하는 DAFormer 아키텍처 [21]를 포함했습니다.
  * DINOv2 [42]는 Cityscapes 데이터가 사전 훈련에 사용되어 평가의 의미를 감소시킬 수 있으므로 사용하지 않았습니다.
* **디코더**: DAFormer 아키텍처 [21]의 ASPP 기반 디코더를 사용했습니다. 계층적 인코더에서는 다중 레벨 특징을 수신하며, 비계층적 EVA02-L에서는 업샘플링 효과가 없습니다.
* **도메인 시프트 데이터셋**:
  * **합성-실제 시프트**: GTA5 [46], SYNTHIA [47] (소스) → Cityscapes [9] (타겟).
  * **순수 악천후 시프트**: ACDC [50] 데이터셋 (정상 날씨(D$_{ACDC\_normal}$) → 안개, 비, 눈, 밤(D$_{ACDC\_fog}$, D$_{ACDC\_rain}$, D$_{ACDC\_snow}$, D$_{ACDC\_night}$)). 단일, 잘 정의된 도메인 시프트를 평가하기 위해 사용되었습니다.
  * **도메인 일반화 평가**: Mapillary Vistas [40], BDD100K [69]를 포함한 다양한 실제 데이터셋에서 평가했습니다.
* **실험 설정**:
  * **프레임워크**: MMSegmentation [8].
  * **GPU**: A100 (80GB) 단일 GPU.
  * **해상도**: 512x512 (MIC 제외 1024x1024).
  * **훈련 반복**: 40,000회, 배치 크기: 4.
  * **최적화**: SGD (ResNet-101), AdamW [35] (MiT-B5, EVA02-L).
  * **학습률**: MiT-B5 (6e-05), EVA02-L (1e-05).
  * UDA 방법별 하이퍼파라미터는 원본 논문 설정을 따랐습니다.
* **평가 지표**: 평균 IoU (Mean Intersection over Union, mIoU), 19개 클래스(SYNTHIA는 13개)에 대해 평균을 냈습니다.

## 📊 Results

* **VLM 사전 훈련을 통한 UDA 성능**:
  * GTA5→Cityscapes 시프트에서 EVA02-L 백본을 탑재한 DACS [59]는 70.3% mIoU를 달성하여 MiT-B5 인코더보다 10.0%p mIoU 성능 향상을 보였습니다. 이는 SOTA UDA 방법과 유사한 수준입니다.
  * DAFormer [21]는 EVA02-L 백본에서 성능 향상이 거의 없었는데, 이는 ImageNet 사전 훈련 지식 보존을 위한 FD-loss (Feature Distance Loss)가 VLM과 호환되지 않아 FD-loss가 5-10배 높게 나타났기 때문입니다.
  * AdaptSegNet [60] 및 ADVENT [64]는 EVA02-L 백본에서 소스 온리(source-only) 성능에 비해 큰 이점을 얻지 못했습니다. 이는 새로운 백본으로 인한 이득이 UDA 방법에 따라 다름을 시사합니다.
* **순수 악천후 도메인 시프트(ACDC)에서의 UDA 성능**:
  * GTA5→Cityscapes 벤치마크와 비교하여 UDA 방법들의 순위가 달라졌습니다. AdaptSegNet 및 ADVENT(EVA02-L)는 DAFormer보다 좋은 성능을 보였습니다.
  * MIC [24](MiT-B5 백본)는 ACDC 시프트에서 여전히 최고의 성능을 보였으며, DACS(EVA02-L)보다 평균 5.0%p mIoU 높았습니다.
  * 일부 UDA 방법은 특정 도메인(예: 비, 안개)에서 소스-온리 모델보다 성능이 저하되기도 했습니다. EVA02-L 백본을 사용해도 DACS를 제외한 대부분의 UDA 방법에서 평균 성능 저하가 관찰되었습니다.
* **UDA 방법의 도메인 일반화 성능**:
  * DACS [59]를 EVA02-L과 결합했을 때, Mapillary, BDD, ACDC에 걸쳐 평균 64.6% mIoU의 강력한 DG 성능을 달성했으며, 순수 DG 방법인 VLTSeg [26]보다 2.1%p mIoU 높았습니다. 이는 UDA 방법이 DG 방법보다 더 나은 일반화 능력을 제공할 수 있음을 뒷받침합니다.
  * UDA 목표 도메인(예: Cityscapes)에서의 성능이 반드시 일반화 성능과 비례하지 않는다는 것을 발견했습니다. 목표 도메인에서 큰 성능 차이가 DG 평균에서는 훨씬 줄어들었습니다 (예: MiT-B5 DAFormer와 DACS 간 Cityscapes에서 7%p 차이가 DG 평균에서 1.2%p로 감소). 이는 UDA 방법이 목표 도메인에 과적합될 수 있음을 시사합니다.
  * ACDC 순수 악천후 시프트 DG 평가에서 EVA02-L 기반의 네 가지 UDA 방법(AdaptSegNet, ADVENT, DACS, DAFormer)은 MIC [24](MiT-B5)를 능가하는 일반화 및 목표 도메인 성능을 보였습니다. 이는 작은 타겟 데이터셋에서 EVA02-L 사전 훈련 표현의 영향력이 커진 결과일 수 있습니다.

## 🧠 Insights & Discussion

* 기존 UDA 방법의 인코더를 VLM 사전 훈련 인코더로 교체하는 것은 비지도 도메인 적응의 성능을 크게 향상시킬 수 있는 잠재력을 가지고 있습니다. 특히 DACS와 같은 비교적 간단한 방법에서 그 효과가 두드러졌습니다.
* 그러나 모든 UDA 방법이 VLM 기반 인코더와 원활하게 통합되는 것은 아닙니다. 특히 DAFormer와 같은 최신 SOTA UDA 방법은 기존 ImageNet 사전 훈련에 맞춰진 손실 함수(FD-loss) 때문에 VLM 사전 훈련 인코더와 사용할 때 성능이 저해될 수 있습니다. 이는 VLM의 잠재력을 최대한 활용하기 위해 VLM에 특화된 새로운 UDA 방법론 개발이 필요함을 시사합니다.
* UDA의 목표 도메인 성능이 미확인 도메인에 대한 일반화 능력을 반드시 예측하지는 않는다는 중요한 발견을 했습니다. UDA 방법이 특정 목표 도메인에 과적합되어 다른 도메인으로의 일반화가 저해될 수 있음을 의미합니다.
* 간단한 UDA 방법이라도 VLM 백본과 결합되면 최신 도메인 일반화 방법과 경쟁하거나 심지어 능가하는 일반화 능력을 보여줄 수 있습니다. 이는 UDA가 특정 타겟 도메인으로 적응함으로써 얻는 실제 이미지에 대한 학습이 다른 미확인 실제 도메인에 대한 일반화에도 도움이 될 수 있음을 시사합니다.

## 📌 TL;DR

* **문제**: 기존 UDA(비지도 도메인 적응)는 ImageNet 사전 훈련 모델에 의존하며, 도메인 시프트에 취약하고 강력한 VLM(시각-언어 모델)의 잠재력을 충분히 활용하지 못했습니다.
* **제안 방법**: 본 연구는 기존 UDA 방법(DACS, DAFormer 등)의 인코더를 최신 VLM 사전 훈련 인코더(EVA02-CLIP)로 교체하고, 이를 다양한 합성-실제 및 실제-실제 도메인 시프트 시나리오에서 평가하여 성능과 일반화 능력을 분석했습니다.
* **주요 결과**: 간단한 DACS 방법이 EVA02-CLIP 인코더와 결합되었을 때 GTA5→Cityscapes에서 10.0%p mIoU 향상을 보였고, 미확인 도메인에 대한 일반화 능력 또한 최대 13.7%p mIoU 향상되어 최신 도메인 일반화 방법보다 우수했습니다. 하지만 DAFormer와 같은 일부 UDA 방법은 VLM 인코더와의 호환성 문제(ImageNet 기반의 FD-loss 때문)를 보였으며, UDA의 목표 도메인 성능이 일반화 성능과 반드시 상관관계가 있는 것은 아니라는 점을 발견했습니다. 이는 VLM의 잠재력을 완전히 활용하기 위한 새로운 UDA 방법의 필요성을 강조합니다.
