# Anatomical Invariance Modeling and Semantic Alignment for Self-supervised Learning in 3D Medical Image Analysis

Yankai Jiang, Mingze Sun, Heng Guo, Xiaoyu Bai, Ke Yan, Le Lu, Minfeng Xu

## 🧩 Problem to Solve

현재 3D 의료 영상 분석을 위한 자가 지도 학습(Self-supervised Learning, SSL) 방법론은 대부분 사진이나 자연 영상에서 파생된 패러다임을 따르고 있습니다. 이러한 접근 방식은 다양한 의료 영상 간에 존재하는 본질적인 유사 해부학적 구조를 명시적으로 또는 충분히 활용하지 못합니다. 이는 다음과 같은 문제점을 야기하여 학습된 심층 표현의 품질을 저하시킬 수 있습니다:

1. **내재된 해부학적 구조 무시**: 기존 샴(siamese) SSL 프레임워크(예: MoCo, DINO, IBOT)는 서로 다른 볼륨에서 얻은 샘플을 '음성 쌍'으로 간주하거나, 동일한 CT 볼륨 내에서 완전히 다른 해부학적 정보를 담고 있는 이미지 패치 샘플을 '양성 쌍'으로 간주하여 잘못된 인스턴스 불변성 제약을 부여합니다. 이는 의미적으로 일관된 해부학적 특징을 무시하는 결과를 초래합니다. (그림 1a 참조)
2. **해부학적 의미 정렬 부족**: 마스킹된 뷰(masked view)와 온전한 뷰(intact view) 간의 큰 의미적 차이를 무시합니다. 무작위 크롭이나 높은 마스킹 비율로 인해 마스킹된 뷰는 원래 뷰와 크게 달라질 수 있으며, 이들 간의 유사성을 최대화하는 것은 학습된 표현에 해로울 수 있습니다. (그림 1b 참조)

이러한 문제들은 학습된 표현이 장기 변형, 병리학적 변화, 피험자 간 변이 등으로 인한 신체 부위의 크기, 모양, 강도, 질감 변화에 대해 충분히 강건하지 못하게 만듭니다.

## ✨ Key Contributions

본 논문은 `Alice`라는 새로운 자가 지도 학습 프레임워크를 제안하며, 이는 3D 의료 영상 분석의 고유한 특성을 활용하여 기존 SSL 방법의 한계를 극복합니다. 주요 기여는 다음과 같습니다:

* **기존 SSL 프레임워크의 비합리성 분석**: 의료 영상에 적용되는 기존 샴(siamese) SSL 프레임워크의 비합리성을 조사하고, 이를 해결하기 위해 `Alice`를 제안했습니다. `Alice`는 볼륨 의료 영상 간의 해부학적 유사성을 활용하여 클래스별 불변성(class-specific invariance)을 모델링하도록 설계되었습니다.
* **조건부 해부학적 의미 정렬(CASA) 모듈 제안**: `Alice` 내에서 조건부 해부학적 의미 정렬(Conditional Anatomical Semantic Alignment, CASA) 모듈을 제안하여, 생성된 대조적 뷰(contrastive views) 간에 가장 관련성 높은 고수준 의미(high-level semantics)를 일치시킵니다.
* **성능 우수성 및 일반화 능력 입증**: `Alice`는 세 가지 공개 하류 작업(downstream tasks) 벤치마크(FLARE 2022, BTCV, COVID-19 분류)에서 대중적인 SSL 방법들을 일관되게 능가하며, 그 효과성과 일반화 능력을 입증했습니다.

## 📎 Related Works

* **자가 지도 학습(Self-supervised Learning)**: 대조 학습(Contrastive Learning, CL)은 뷰 불변 표현 학습에 중점을 두며(SimCLR, MoCo, DINO, BYOL), 마스크 영상 모델링(Masked Image Modeling, MIM)은 마스크된 콘텐츠 재구성을 통해 표현을 학습합니다(MAE, BEiT). 최근에는 CL과 MIM을 결합한 하이브리드 SSL 프레임워크(IBOT, SIM, CMAE)가 등장했습니다. 하지만 이러한 방법들은 종종 이미지 내의 의미 정보나 이미지 간의 잠재적 양성 쌍을 간과하는 경향이 있습니다.
* **의료 영상 분야의 자가 지도 학습**: 많은 연구들이 의료 영상에 특화된 CL 방법(예: DiRA, Swin UNETR)을 적용하거나, 이미지 복원(inpainting, Rubik's cube, context reconstruction)을 선행 작업(pre-text task)으로 사용하여 공간적 맥락을 학습합니다.
* **`Alice`의 차별점**: `Alice`는 기존 방법들과 달리 (1) 다른 이미지 볼륨 간에 내재된 해부학적 일관성(anatomical consistency)을 명시적으로 활용하여 클래스별 불변성을 인코딩하고, (2) 해부학적 의미 정렬을 수행하여 더 나은 대조 쌍을 생성합니다.

## 🛠️ Methodology

`Alice`는 마스크 영상 모델링(MIM)과 대조 학습(CL)을 정교하게 결합하여 해부학적 불변성을 모델링하고 의미 정렬을 수행하는 새로운 자가 지도 학습 프레임워크입니다. 전체 파이프라인은 그림 2와 같습니다.

1. **다양하면서도 의미적으로 일관된 크롭 마이닝**:
    * 임의의 쿼리 볼륨(Q)과 키 볼륨(K)을 선택합니다.
    * 사전 훈련된 SAM(Self-supervised Anatomical Embeddings) 모델을 사용하여 서로 다른 볼륨 내에서 동일한 신체 부위(예: 복부)를 찾고 정렬하여, 두 개의 서브 볼륨 크롭(Q와 K)을 생성합니다. 이는 기존 방법의 무작위 크롭으로 인한 의미적 불일치를 방지합니다.
    * 두 가지 데이터 증강 ($u, w$)을 사용하여 $Q$에서 두 뷰($X_Q^u$, $X_Q^w$)를 생성하고, 두 가지 데이터 증강 ($r, v$)을 사용하여 $K$에서 두 뷰($X_K^r$, $X_K^v$)를 생성합니다. 여기서 $u, r$은 랜덤 마스킹(MAE와 유사)이고, $w, v$는 다른 데이터 증강 연산입니다.

2. **네트워크 아키텍처 구성 요소**:
    * **온라인 인코더($E_s$)**: 마스킹된 뷰($X_Q^u$, $X_K^r$)를 입력으로 받습니다. MAE [21]와 유사하게 가시 영역 패치만을 처리합니다. Transformer 블록을 통해 특징($V_Q^u$, $V_K^r$)을 생성합니다. 사전 훈련 후 하류 작업에 사용됩니다.
    * **온라인 디코더($D_s$)**: 온라인 인코더의 특징과 마스크 토큰을 입력으로 받아 마스크된 패치의 픽셀 값을 재구성합니다. 재구성 손실 $L_r$은 마스크된 패치에 대한 MSE(평균 제곱 오차)입니다:
        $$L_r = \frac{1}{n_{Q_m}} \sum [\Theta(\bar{Q} - Q)]^2 + \frac{1}{n_{K_m}} \sum [\Theta(\bar{K} - K)]^2$$
        여기서 $\Theta$는 마스크된 토큰에 해당하는 예측을 선택하는 지시자이며, $n_{Q_m}, n_{K_m}$은 각각 $Q, K$의 마스크된 패치 수입니다. 이 MIM 목표는 지역적 맥락 및 환자별 정보를 인코딩하는 데 기여합니다.
    * **타겟 인코더($E_t$)**: 온라인 인코더와 동일한 아키텍처를 가지며, 매개변수는 온라인 인코더 가중치의 EMA(지수 이동 평균)로 업데이트됩니다. 마스킹되지 않은 증강 뷰($X_Q^w$, $X_K^v$)를 입력으로 받아 의미적 무결성을 보존하는 고차원 특징 표현을 생성합니다.

3. **해부학적 불변성 모델링(Anatomical Invariance Modeling) (볼륨 간)**:
    * 서로 다른 볼륨(Q와 K)에서 얻은 뷰들의 임베딩 간 유사성을 최대화하여 보편적인 해부학적 특징을 학습합니다.
    * 온라인 디코더에는 프로젝션 헤드 $\phi$, 타겟 인코더에는 프로젝션 헤드 $\psi$를 추가하여 특징 쌍 $(H_Q^u, Y_K^v)$ 및 $(H_K^r, Y_Q^w)$을 생성합니다.
    * 이 특징들에 대해 전역 평균 풀링(global average pooling)을 수행하여 전역 시각 의미([cls] 토큰)를 얻고, 이들 간의 고수준 클래스별 표현이 특징 공간에서 가까워지도록 유도합니다.
    * 손실 $L_{dv}$는 코사인 유사도 손실 [10, 17]을 사용합니다:
        $$L_{dv} = L_s([cls]_Q^u, [cls]_K^v) + L_s([cls]_K^r, [cls]_Q^w)$$
    * 이 과정을 통해 `Alice`는 해부학적 불변성을 명시적으로 강화합니다.

4. **해부학적 의미 정렬(Anatomical Semantic Alignment, CASA) (볼륨 내)**:
    * 동일 볼륨 내에서 마스킹된 뷰와 온전한 뷰 간의 의미적 간극을 해소합니다.
    * 기존 방법처럼 온전한 뷰의 임베딩으로 마스킹된 뷰의 표현을 직접 감독하는 대신, CASA는 마스킹된 뷰의 특징을 기준으로 원본 볼륨에서 가장 의미적으로 유사한 해부학적 특징을 추출하여 정렬된 교사($T$) 임베딩과 학생($S$) 임베딩을 생성합니다.
    * $X_Q^u$ (마스킹된 뷰)와 $X_Q^w$ (증강된 온전한 뷰)의 특징 정렬 과정을 예시로 설명합니다 (그림 3 참조):
        * 온라인 인코더 출력 $V_Q^u$를 쿼리 $q_Q^u$로 투영합니다.
        * 재구성된 특징 $H_Q^u$를 키 $k_Q^u$와 값 $\nu_Q^u$로 투영합니다.
        * $q_Q^u$와 $k_Q^u$ 간의 스케일드 닷 프로덕트 어텐션(scaled dot-product attention) $ATT_u$를 계산하여 지역적 패치 정보에서 고수준 전역 해부학적 의미에 대한 관련성 가중치를 얻습니다:
            $$ATT_u(V_Q^u, H_Q^u) = \text{softmax} \left( \frac{q_Q^u \cdot (k_Q^u)^T}{\sqrt{C}} \right)$$
        * $ATT_u$를 사용하여 $\nu_Q^u$를 집계하고 프로젝션 레이어 $\zeta$를 통과시켜 학생 임베딩 $S_Q^u = \zeta(ATT_u \cdot \nu_Q^u)$를 얻습니다.
        * 교사 임베딩 $T_Q^w$는 유사한 과정으로 타겟 인코더 출력 $Y_Q^w$를 사용하여 생성됩니다.
    * $S_Q^u$와 $T_Q^w$는 동일한 쿼리 $q_Q^u$에 의해 유도되므로, 마스킹된 뷰의 지역 영상 콘텐츠 분포에 따라 조건화된 전역적으로 일치하는 해부학적 의미와 패치 간 토폴로지 정보를 인코딩하게 됩니다.
    * 손실 $L_{st}$는 이러한 의미적으로 정렬된 교사 임베딩과 학생 임베딩 간의 유사성을 최대화합니다:
        $$L_{st} = L_s(S_Q^u, T_Q^w) + L_s(S_K^r, T_K^v)$$
    * 이러한 볼륨 간(inter-volume) 및 볼륨 내(intra-volume) 대조를 통해, `Alice`의 온라인 인코더는 고수준 판별 해부학적 특징과 미세한 위치-민감 맥락 세부 정보를 모두 학습할 수 있습니다.

5. **총 손실**: 전체 훈련 손실은 $L = L_r + L_{dv} + L_{st}$입니다.

## 📊 Results

`Alice`는 세 가지 공개 벤치마크에서 기존 SSL 방법론 대비 뛰어난 성능을 보였습니다.

* **FLARE 2022 복부 장기 분할**:
  * `Alice`는 UNETR, Swin UNETR, nnFormer와 같은 ViT 기반 분할 프레임워크에 적용되었을 때 평균 DSC(Dice Similarity Coefficient)에서 86.87%, NSD(Normalized Surface Dice)에서 91.28%를 달성하며, 기존 최상위 SSL 방법(MoCo v3, DINO, IBOT, SIM, MAE, CMAE 등)보다 최소 2.22% (DSC) 높은 성능을 보였습니다.
  * 특히 의료 영상에 특화된 medical MAE [64] 및 Tang et al. [45]의 프레임워크보다 우수했습니다.
  * CNN 기반 SOTA 방법들과 비교했을 때도 `Alice`는 훨씬 우수한 성능을 기록했습니다. (표 2)
  * 정성적 결과(그림 4)에서도 `Alice`는 더 날카로운 경계와 지상 진실(ground truth)에 일관된 분할 결과를 보여주었습니다.

* **BTCV 다중 장기 분할**:
  * `Alice`는 앙상블 전략 없이도 BTCV 오프라인 및 온라인 테스트 세트에서 각각 86.76% 및 88.58%의 경쟁력 있는 DSC를 달성했습니다. (표 3)
  * 5,000개 이상의 3D CT 스캔으로 사전 훈련된 UniMiSS 및 Swin UNETR (Tang et al.)과 같은 의료 영상 특화 SOTA 방법보다 적은 데이터(40%만 사용)로도 우수한 성능을 보였습니다.

* **COVID-19 분류**:
  * `Alice`는 COVID-19 분류 벤치마크에서 90.88%의 AUC(Area Under the ROC Curve)를 달성하며, CNN 기반 및 ViT 기반 SOTA SSL 방법들보다 최소 2.52% (AUC) 이상 우수한 성능을 보였습니다. (표 4)
  * 이는 `Alice`가 다른 시나리오로도 일반화할 수 있는 능력이 있음을 입증합니다.

* **Ablation Study**:
  * **볼륨 간 해부학적 불변성 모델링의 중요성**: `Alice`에 $L_{dv}$ 손실을 추가하고 서로 다른 볼륨에서 일관된 뷰를 입력했을 때, DSC가 1.24%p 향상되었습니다. 이는 볼륨 간 해부학적 불변성 모델링이 하류 작업의 표현 학습에 유익함을 보여줍니다. (표 5)
  * **CASA의 효과**: CASA 모듈을 적용했을 때, 다양한 샴 구조 기반 SSL 방법들(IBOT, SIM 포함)에서 1.21%p 이상의 절대 DSC 개선을 달성했습니다. 이는 CASA가 마스킹된 뷰와 마스킹되지 않은 뷰로부터 더 나은 대조 쌍을 생성하는 데 효과적임을 나타냅니다. (표 6)
  * **음성 샘플 사용 여부**: BYOL 스타일 코사인 손실(음성 쌍 미사용)이 InfoNCE 손실(음성 쌍 사용)보다 FLARE 2022 테스트 세트에서 약간 더 높은 성능을 보였습니다. 따라서 `Alice`의 대조 학습 브랜치에서는 코사인 손실을 기본으로 사용합니다. (표 7)

## 🧠 Insights & Discussion

`Alice`의 뛰어난 성능은 다음과 같은 핵심 통찰력에서 비롯됩니다.

* **본질적인 해부학적 일관성 활용**: 3D 의료 영상은 본질적으로 유사한 해부학적 구조를 공유합니다. `Alice`는 SAM을 활용하여 이러한 유사한 해부학적 영역을 정확하게 정렬하고, 이를 기반으로 볼륨 간 불변성 모델링(inter-volume invariance modeling)을 통해 공통적인 고수준 의미를 학습함으로써, 장기 변형이나 병변 등으로 인한 변화에도 강건한 표현을 획득합니다.
* **의미적 정렬을 통한 대조 쌍 개선**: 기존의 마스킹된 이미지 모델링 기반 SSL은 마스킹된 뷰와 온전한 뷰 간의 큰 의미적 차이를 간과할 수 있습니다. `Alice`의 CASA 모듈은 마스킹된 뷰의 지역적 정보에 기반하여 온전한 뷰로부터 가장 관련성 높은 해부학적 의미를 조건부로 추출하고 정렬하여, 의미적으로 일관된 고수준 정보를 가진 대조 쌍을 생성합니다. 이는 학습된 표현이 공간적 민감성(spatial sensitivity)과 의미적 판별성(semantic discriminability)을 모두 갖추도록 돕습니다.
* **효율성 및 일반화**: `Alice`는 상대적으로 적은 사전 훈련 데이터로도 SOTA 성능을 달성하여 데이터 효율성을 입증했습니다. 또한 복부 장기 분할(FLARE 2022, BTCV)부터 폐 CT 기반 COVID-19 분류에 이르기까지 다양한 하류 작업과 시나리오에서 일관된 성능 향상을 보여, 뛰어난 일반화 능력을 입증했습니다. 이는 `Alice`가 실제 복잡한 의료 영상 문제(예: CT 스캔 범위 변화, 시간적 변화)를 처리하는 데 더 적합함을 시사합니다.
* **제한 사항**: 본 논문에서는 명시적인 한계점을 언급하지 않았지만, 사전 훈련된 SAM 모델의 성능에 의존하는 점, 그리고 방사선 영상의 다양성(CT, MR, X-ray 등) 전체에 대한 일반화 가능성은 추가 연구가 필요할 수 있습니다.

## 📌 TL;DR

**문제**: 기존 3D 의료 영상용 자가 지도 학습(SSL) 방법들은 의료 영상의 고유한 해부학적 일관성을 충분히 활용하지 못하며, 뷰 간의 의미 정렬이 부족하여 학습된 표현의 품질이 저하됩니다.

**제안 방법**: `Alice`는 해부학적 불변성 모델링과 의미 정렬을 통해 이러한 문제를 해결하는 새로운 SSL 프레임워크입니다. 사전 훈련된 SAM 모델을 사용하여 서로 다른 볼륨에서 동일한 신체 부위를 정렬하여 해부학적 일관성을 확보하고, 볼륨 간 대조 손실($L_{dv}$)을 통해 클래스별 불변성을 명시적으로 학습합니다. 또한 조건부 해부학적 의미 정렬(CASA) 모듈과 볼륨 내 대조 손실($L_{st}$)을 도입하여 마스킹된 뷰와 온전한 뷰 간의 고수준 의미를 정렬, 더 나은 대조 쌍을 생성합니다. 여기에 마스크 영상 모델링 손실($L_r$)이 더해집니다.

**주요 결과**: `Alice`는 3D 의료 영상 분할(FLARE 2022, BTCV) 및 분류(COVID-19) 벤치마크에서 SOTA 성능을 크게 능가하며, 학습된 표현이 장기 변형 및 병리학적 변화에 강건하고 다양한 시나리오에 일반화할 수 있음을 입증했습니다.
