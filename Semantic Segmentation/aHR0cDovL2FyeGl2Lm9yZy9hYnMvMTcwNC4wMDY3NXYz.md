# 2017 DAVIS Challenge on Video Object Segmentation

Jordi Pont-Tuset, Federico Perazzi, Sergi Caelles, Pablo Arbeláez, Alexander Sorkine-Hornung, and Luc Van Gool

## 🧩 Problem to Solve

기존 DAVIS 2016 데이터셋에서 비디오 객체 분할(VOS) 기술이 높은 성능을 달성하여 포화 상태에 이르렀습니다. 이에 연구자들은 더 복잡하고 실제와 같은 시나리오에서 VOS 알고리즘의 성능을 더욱 향상시킬 필요성을 느꼈습니다. 특히, 단일 객체 분할에서 다중 객체 분할로의 확장은 새로운 도전 과제를 제시합니다.

## ✨ Key Contributions

- **DAVIS 2017 데이터셋 출시**: 이전 DAVIS 2016을 확장하여 더 많은 비디오(150개), 프레임(10459개), 객체(376개)를 포함하며, 특히 단일 시퀀스 내에 여러 객체가 존재하는 시나리오를 도입하여 난이도를 높였습니다. 이는 방해물, 작은 객체, 폐색, 빠른 움직임 등 더 복잡한 요소를 포함합니다.
- **다중 객체 VOS 평가 지표 정의**: Jaccard index (IoU)와 F-measure를 기반으로 하는 새로운 평가 지표를 제시하여 다중 객체 환경에서 알고리즘 성능을 객체 인스턴스별로 정확하게 측정하도록 정의했습니다.
- **공개 챌린지 및 워크샵 개최**: CVPR 2017과 함께 공개 챌린지를 개최하여 22개 팀의 참여를 유도했으며, 이를 통해 VOS 분야의 최신 기술 수준을 20% 향상시켰습니다.
- **참가 팀 결과 심층 분석**: 최고 성능을 보인 팀들의 결과를 상세히 분석하여 현재 방법론의 한계점(예: 오탐/미탐 유형, 작은 객체 처리, 객체 ID 전환)에 대한 통찰을 제공했습니다.

## 📎 Related Works

- **DAVIS (Densely-Annotated VIdeo Segmentation) 2016 [3]**: 본 챌린지의 기반이 되는 비디오 객체 분할 벤치마크 데이터셋 및 평가 방법론.
- **ImageNet [1], PASCAL VOC [2], MS-COCO [4]**: 컴퓨터 비전 분야의 다른 성공적인 공개 벤치마크 및 챌린지.
- **OSVOS [5], MaskTrack [6]**: DAVIS 2016에서 개발된 최신 비디오 객체 분할 알고리즘.
- **참가 팀의 주요 기술**: MaskTrack과 재식별 모듈 결합 [9], MaskTrack 훈련 확장 (lucid dreaming) [10], OSVOS 개선 [13, 15, 16], 인스턴스 재식별 모듈 [11], 객체 제안(object proposals) [12, 17], 공간 전파 네트워크(spatial propagation networks) [14].

## 🛠️ Methodology

- **과제 정의**: '반지도 학습(semi-supervised)' 비디오 객체 분할 작업에 중점을 둡니다. 이는 첫 프레임의 객체 마스크가 주어지면, 해당 객체들의 나머지 프레임에서의 마스크를 예측하는 것입니다. 각 객체는 고유한 식별자(ID)를 가집니다.
- **데이터셋 구성**:
  - DAVIS 2016의 `train` 및 `val` 세트를 확장하여 다중 객체 주석을 추가했습니다.
  - `test-dev` 및 `test-challenge` 두 가지 테스트 세트를 정의했으며, 이들에는 첫 프레임의 마스크만 공개됩니다.
  - 총 150개의 시퀀스(10459 프레임, 376개 객체)로 구성되어 있으며, 대부분 4K 해상도이나 챌린지는 480p로 다운샘플링된 이미지에서 진행됩니다.
- **평가 지표**:
  - **영역 유사도 ($J$)**: 예측 마스크와 Ground Truth 마스크 간의 Intersection over Union (IoU) 또는 Jaccard index를 계산합니다.
  - **경계 정확도 ($F$)**: 두 마스크의 경계 픽셀 간의 이분 매칭을 통해 정밀도(precision)와 재현율(recall)의 F-measure를 평가합니다.
  - **전체 성능 ($M(S)$)**: 각 객체 인스턴스에 대한 $J$ 및 $F$ 점수의 평균을 계산한 후, 이들의 평균을 최종 랭킹 지표로 사용합니다.
    $$ M(S) = \frac{1}{2} [m(J,S) + m(F,S)] $$
        여기서 $m(M,S) = \frac{1}{|O_S|} \sum_{o \in O_S} \frac{1}{|F_{s(o)}|} \sum_{f \in F_{s(o)}} M(m^o_f, g^o_f)$ 입니다.
  - DAVIS 2016에서 사용된 시간적 불안정성 ($T$) 지표는 DAVIS 2017의 잦은 폐색(occlusion)으로 인해 주요 평가에서는 제외되었으나, 안정성 분석을 위해 연구 논문에서 보고하는 것을 권장합니다.

## 📊 Results

- **전반적인 성능 향상**: 챌린지 결과, 최고 성능은 OSVOS(49.0%) 대비 J&F MeanM$\uparrow$ 69.9%를 달성하여 20%의 상당한 개선을 보였습니다. 1위 팀 [9]은 2위 팀 [10]보다 2.1% 높은 성능을 기록했습니다.
- **오류 분석**:
  - **전경-배경 분할 vs. 다중 객체 분리**: 모든 객체 마스크를 단일 전경-배경 분할로 변환하여 평가했을 때, 결과(예: 1위 팀 82.4%)가 크게 향상되어 현재 방법론이 전경 객체들을 서로 분리하는 데 어려움을 겪고 있음을 시사합니다.
  - **주요 오류 유형**: 오분류된 픽셀 분석 결과, '미탐(False Negatives, FN)'이 '오탐(False Positives, FP)'이나 '객체 ID 전환(Identity Switches)'보다 지배적인 오류 유형으로 나타났습니다.
  - **객체 크기 영향**: 작은 객체들이 큰 객체들보다 분할하기 더 어려운 경향을 보였습니다. 이미지 영역의 5% 미만인 작은 객체들을 제거했을 때, 최고 성능 방법의 품질이 15% (85%까지) 상승했습니다.
- **앙상블 잠재력**: 여러 기술의 최고 결과를 조합하는 오라클(oracle) 테스트에서 1위와 2위 기술을 조합했을 때 +5.4%의 성능 향상이 가능하여, 다양한 방법론을 결합할 경우 추가적인 개선 여지가 있음을 보여주었습니다.

## 🧠 Insights & Discussion

- 다중 객체 비디오 객체 분할은 객체 ID 유지라는 새로운 도전 과제를 추가합니다. 그럼에도 불구하고, 단일 객체 사례와 유사하게 '미탐(False Negatives)'이 여전히 가장 지배적인 오류 유형으로 나타납니다.
- 작은 객체의 존재는 DAVIS 2016에서는 관찰되지 않았던 새로운 도전 과제를 제기합니다.
- 현재 방법들은 전경-배경 분할에는 능숙하지만, 여러 전경 객체들 사이를 구별하는 데 어려움을 겪습니다.
- 다양한 기술을 조합(앙상블)함으로써 상당한 성능 향상이 가능함을 오라클 결과가 입증하여, 향후 연구를 위한 명확한 방향을 제시합니다.

## 📌 TL;DR

DAVIS 2016의 한계를 넘어 더 도전적인 다중 객체 비디오 객체 분할을 위해 DAVIS 2017 데이터셋과 챌린지를 도입했습니다. 이 챌린지는 새로운 평가 지표를 제시하고 VOS 분야의 SOTA 성능을 20% 향상시켰습니다. 분석 결과, '미탐'과 '작은 객체 처리'가 주요 난제로 나타났으며, 다양한 기술의 조합을 통해 추가적인 성능 향상 가능성이 있음을 확인했습니다.
