# Class-Aware Adversarial Transformers for Medical Image Segmentation

Chenyu You, Ruihan Zhao, Fenglin Liu, Siyuan Dong, Sandeep Chinchali, Ufuk Topcu, Lawrence Staib, James S. Duncan

## 🧩 Problem to Solve

의료 영상 분석에서 트랜스포머 모델이 장거리 의존성 모델링에 상당한 발전을 이루었음에도 불구하고, 기존 방법들은 몇 가지 한계를 가지고 있습니다. 주요 문제점은 다음과 같습니다:

1. **단순한 토큰화 방식:** 기존 트랜스포머 기반 모델은 이미지를 단순하게 토큰화하여 이미지의 중요한 특징을 효과적으로 포착하지 못합니다.
2. **단일 스케일 특징 표현:** 단일 스케일 특징 표현만을 고려하여 정보 손실이 발생하고, 다양한 크기와 형태의 해부학적 특징을 캡처하는 데 어려움을 겪습니다.
3. **불충분한 정확도:** 풍부한 의미론적 문맥과 해부학적 질감을 고려하지 않아 생성되는 분할(segmentation) 라벨 맵의 정확도가 충분히 높지 않습니다.
4. **CNN의 한계 극복:** CNN은 수용장의 본질적인 지역성(locality)으로 인해 장거리 의존성을 명시적으로 모델링하는 데 실패합니다.
이러한 문제들은 특히 다양한 형태와 크기의 종양과 같은 해부학적 특징을 정확히 분할하는 데 있어 최적이 아닌 결과를 초래합니다.

## ✨ Key Contributions

이 연구는 2D 의료 영상 분할을 위한 새로운 적대적 트랜스포머인 **CASTformer**를 제안하며 다음과 같은 핵심 기여를 합니다:

* **새로운 네트워크 아키텍처:** 2D 의료 영상 분할 작업에 트랜스포머 기반 GAN(Generative Adversarial Network) 아키텍처를 구축하려는 최초의 시도입니다. 이는 풍부한 전역 및 지역 다중 스케일 공간 표현을 학습하기 위한 피라미드 구조를 생성기에 통합하고, 이미지의 의미론적 구조와 관련된 흥미로운 영역을 점진적으로 학습하는 새로운 클래스 인식 트랜스포머 모듈을 고안했습니다.
* **모델 내부 작동에 대한 이해 증진:** 샘플링 전략의 작동 방식과 다양한 학습 요인이 최종 성능에 미치는 영향을 포함하여 모델의 내부 작동에 대한 상세한 분석을 수행했습니다. 이를 통해 클래스 인식 트랜스포머 모듈로 구별되는 문맥적 표현을 점진적으로 학습하는 것이 더욱 효과적임을 보여주었습니다.
* **현저한 성능 향상:** 세 가지 벤치마크 데이터셋에서 이전 최첨단 트랜스포머 기반 접근 방식을 크게 능가하며, Dice 점수에서 2.54% ~ 5.88%의 절대적인 개선을 달성했습니다. 특히 Synapse 다중 장기 데이터셋에서 이전 모델 대비 5.88%의 Dice 점수 향상을 이루었습니다. 컴퓨터 비전 도메인에서 사전 학습된 모델을 활용하는 이점을 입증하고, 제한된 의료 영상 데이터셋으로도 높은 성능을 달성할 수 있음을 보여주었습니다.

## 📎 Related Works

* **CNN 기반 분할 네트워크:** UNet [27], 2.5D FCN (간 분할) [62], 3D CNN + CRF (뇌 병변 분할) [63] 등 의료 영상 분할에서 표준으로 사용되어 온 CNN 기반 방법들을 참조합니다.
* **의료 영상 분할의 트랜스포머:** UNet과 트랜스포머의 장점을 결합한 TransUNet [7], 순수 트랜스포머를 의료 영상 분석에 적용하려 시도한 Cao et al. [10], CNN과 트랜스포머를 효율적으로 결합한 CoTr [13] 등이 언급됩니다.
* **적대적 생성 네트워크의 트랜스포머:** 고해상도 이미지 합성을 위해 순수 트랜스포머 기반 GAN 파이프라인을 구축한 Jiang et al. [71], 컨볼루션 GAN과 트랜스포머 아키텍처를 결합한 Esser et al. [31], StyleGAN에 이분 그래프 자체 주의(bipartite self-attention)를 적용한 Hudson et al. [3] 등이 참조됩니다.

## 🛠️ Methodology

제안하는 CASTformer는 트랜스포머 기반의 생성기(CATformer)와 판별기로 구성됩니다 (그림 1 참조).

### 생성기 (CATformer)

CATformer는 인코더, 클래스 인식 트랜스포머 모듈, 트랜스포머 인코더 모듈, 디코더 모듈의 네 가지 핵심 구성 요소로 이루어진 CNN-트랜스포머 하이브리드 모델입니다.

1. **인코더 모듈:** ResNet과 유사한 40개 컨볼루션 레이어를 사용하여 다중 스케일 특징 맵을 생성합니다. 이는 트랜스포머의 성능을 향상시키고 고해상도 및 저해상도 특징 맵을 제공하여 특징 피라미드를 구성하고 의료 분할 작업을 위한 다중 스케일 특징 맵을 활용합니다.
    * **계층적 특징 표현:** TransUNet과 달리 단일 해상도 특징 맵 대신 $F_i$ ($i \in \{1,2,3,4\}$)와 같은 CNN 유사 다중 레벨 특징을 추출하여 고해상도 및 저해상도 특징을 모두 활용합니다.

2. **클래스 인식 트랜스포머 모듈 (Class-Aware Transformer Module, CAT):** 객체의 유용한 영역(예: 해부학적 특징, 구조 정보)에 적응적으로 초점을 맞추도록 설계되었습니다.
    * **반복적 샘플링:** 초기 샘플링 위치 $s_t$에서 마지막 단계의 추정된 오프셋 벡터 $o_t$를 더하여 샘플링 위치를 반복적으로 업데이트합니다 ($s_{t+1} = s_t + o_t$).
    * **미분 가능성:** 샘플링 함수로 양선형 보간법(bilinear interpolation)을 사용하여 샘플링 위치와 입력 특징 맵 모두에 대해 미분 가능하도록 합니다.
    * **토큰 생성:** 현재 위치 임베딩 $S_t$, 초기 샘플링된 토큰 $I'_t$, 및 마지막 단계의 추정된 토큰 $I_{t-1}$의 요소별 합을 통해 출력 토큰 $I_t$를 얻습니다.
    $$
    S_t = W_t s_t \\
    V_t = I'_t \oplus S_t \oplus I_{t-1} \\
    I_t = \text{Transformer}(V_t), \quad t \in \{1,...,M\}
    $$

3. **트랜스포머 인코더 모듈 (Transformer Encoder Module, TEM):** 입력 이미지 패치 임베딩의 전체 시퀀스로부터 전역 문맥 정보를 집계하여 장거리 문맥 정보를 모델링하도록 설계되었습니다. ViT [4]의 아키텍처를 따르며 Multi-head Self-Attention (MSA) 및 MLP 블록으로 구성됩니다.
    $$
    E'_i = \text{MSA}(\text{LN}(E_{i-1})) + E_{i-1} \\
    E_i = \text{MLP}(\text{LN}(E'_i)) + E'_i
    $$

4. **디코더 모듈:** 네 가지 해상도의 출력 특징 맵을 기반으로 분할 마스크를 생성합니다. 경량 All-MLP 디코더 [86]를 사용하여 효율적으로 강력한 표현을 산출합니다.

### 판별기 (Discriminator Network)

ImageNet에서 사전 학습된 R50+ViT-B/16 하이브리드 모델을 기반으로 설계되었습니다. 판별기는 실제 샘플과 가짜 샘플을 분류하는 것을 목표로 합니다. 입력 이미지 $x$와 예측된 분할 마스크 $y'$의 픽셀 단위 곱셈을 통해 클래스 인식 이미지 $\tilde{x}$를 생성하여 입력으로 사용합니다 ($\tilde{x} = x \times y'$).

### 학습 목표 (Training Objective)

생성기 $G$를 학습하기 위해 Wasserstein GAN (WGAN) [88]의 WGAN-GP 손실 [89]과 분할 손실(Dice loss + Cross-Entropy loss)을 함께 사용합니다. 전체 손실 함수는 다음과 같습니다:
$$
L_G = \lambda_1 L_{CE} + \lambda_2 L_{DICE} + \lambda_3 L_{WGAN-GP}
$$
여기서 $\lambda_1, \lambda_2, \lambda_3$는 각 손실 항의 중요도를 결정하는 하이퍼파라미터입니다.

## 📊 Results

CASTformer는 세 가지 벤치마크 의료 영상 데이터셋에서 기존 최첨단 모델을 크게 능가하는 성능을 보였습니다.

* **Synapse 다중 장기 데이터셋:**
  * CASTformer는 평균 Dice 점수 **82.55%**와 Jaccard 점수 **74.69%**를 달성하여 이전 최고 모델인 TransUNet보다 Dice에서 **+5.07%**, Jaccard에서 **+9.91%** 절대적 개선을 이루었습니다.
  * 큰 장기(왼쪽/오른쪽 신장, 간, 위)에서 각각 +2.77%, +2.51%, +1.35%, +4.95%의 Dice 점수 향상을 보였습니다.
  * 작은 장기(대동맥, 담낭, 췌장)에서도 각각 +1.82%, +0.95%, +10.91%의 Dice 점수 향상을 달성했습니다.

* **LiTS 데이터셋:**
  * CASTformer는 Dice 점수 **73.82%**와 Jaccard 점수 **64.91%**를 달성하여 TransUNet보다 Dice에서 **+5.88%**, Jaccard에서 **+4.66%** 향상된 새로운 최첨단 성능을 기록했습니다.
  * 특히 간 영역에서 95.88% Dice 점수를 달성하며 2.48% 향상되었고, 종양 영역에서는 42.49%에서 51.76%로 크게 개선되었습니다.

* **MP-MRI 데이터셋:**
  * CASTformer는 CATformer보다 더 나은 성능을 보여, 판별기 사용이 의료 영상 충실도 평가에 효과적임을 시사했습니다.

* **전이 학습의 효과:** 컴퓨터 비전 도메인에서 사전 학습된 모델을 활용하는 것이 CASTformer의 성능을 크게 향상시킴을 입증했습니다. 사전 학습된 가중치를 사용함으로써 Dice 및 Jaccard 점수에서 각각 최대 +8.91% 및 +12.01%의 상당한 개선을 보였습니다. 이는 사전 학습된 모델이 제한된 의료 데이터셋에서도 좋은 초기 매개변수를 제공하고 해부학적 정보를 더 잘 수집할 수 있음을 나타냅니다.

* **모델 구성 요소의 효과:** 클래스 인식 트랜스포머 모듈(CAT)과 트랜스포머 인코더 모듈(TEM) 모두 분할 성능 향상에 기여하며, 두 모듈을 함께 사용하는 것이 단일 모듈만 사용하는 것보다 더 효과적임을 확인했습니다.

* **하이퍼파라미터 및 손실 함수:** WGAN-GP 손실이 다른 GAN 손실 함수들에 비해 동등하거나 더 나은 성능을 보였으며, 최적의 하이퍼파라미터 설정($\lambda_1=0.5, \lambda_2=0.5, \lambda_3=0.1$)을 확인했습니다.

## 🧠 Insights & Discussion

* **모델의 견고성 및 적응성:** CASTformer는 다중 스케일 피라미드 구조와 클래스 인식 트랜스포머 모듈을 통해 다양한 해부학적 특징과 구조를 효과적으로 학습하고, 전역 및 지역 문맥 정보를 모두 활용하여 분할 성능을 크게 향상시켰습니다.
* **전이 학습의 중요성:** 컴퓨터 비전 도메인에서 사전 학습된 모델을 의료 영상 분할에 활용하는 새로운 관점을 제시했습니다. 이는 방대한 해부학적 표현을 처음부터 재구축할 필요 없이 모델이 새로운 의료 분할 작업에 빠르게 적응할 수 있도록 돕고, 제한된 크기의 의료 데이터셋에 대한 학습 품질을 높일 수 있음을 시사합니다.
* **생성-판별기 설계의 효과:** 적대적 학습 전략이 분할 성능을 향상시키고 트랜스포머 기반 판별기가 저수준 해부학적 특징과 고수준 의미론적 내용을 모두 포착할 수 있도록 함을 입증했습니다.
* **모델의 투명성 및 데이터 효율성:** 샘플링 위치 시각화를 통해 모델이 해부학적 유사성과 근접성 측면에서 일관된 분할 영역에 집중하고, 특히 간, 신장, 비장 등 고도로 의미론적으로 관련된 영역에 적응적으로 초점을 맞추는 것을 보여주었습니다. 이는 모델의 투명성을 높이고 데이터 효율성을 개선하는 데 기여합니다.
* **향후 연구 방향:** 2D 의료 영상 분할을 위한 견고한 기준선 역할을 하며, 더 안전하고 신뢰할 수 있는 임상 AI 시스템 구축이라는 목표에 기여할 것으로 기대됩니다. 또한, 모델의 내재적 작동에 대한 더 깊은 기계적 설명과 데이터 및 모델 매개변수 측면에서 트랜스포머 기반 아키텍처를 최적화하는 추가 연구의 필요성을 제안합니다.

## 📌 TL;DR

**문제:** 기존 트랜스포머 기반 의료 영상 분할 모델은 단순한 토큰화, 단일 스케일 특징 사용, 그리고 의미론적 문맥 부족으로 인해 정확도와 해부학적 특징 캡처 능력에 한계가 있었습니다.
**해결책:** 본 연구는 **CASTformer**라는 새로운 클래스 인식 적대적 트랜스포머를 제안합니다. 이 모델은 다중 스케일 특징을 포착하는 **피라미드 구조**와 객체의 식별적 영역에 적응적으로 집중하는 **클래스 인식 트랜스포머 모듈**을 포함하는 생성기(CATformer)를 사용합니다. 또한, 판별기와 함께 **적대적 학습**을 사용하여 저수준 해부학적 특징과 고수준 의미론을 학습함으로써 분할 정확도를 높입니다.
**핵심 발견:** CASTformer는 Synapse, LiTS, MP-MRI 세 가지 의료 데이터셋에서 기존 최첨단 모델보다 **Dice 점수에서 2.54% ~ 5.88% 향상**된 뛰어난 성능을 달성했습니다. 특히, 컴퓨터 비전 도메인에서 **사전 학습된 모델을 활용**하는 것이 제한된 의료 데이터셋에서도 성능을 크게 향상시킬 수 있음을 입증했습니다.
