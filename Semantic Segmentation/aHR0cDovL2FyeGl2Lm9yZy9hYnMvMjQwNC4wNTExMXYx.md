# Class Similarity Transition: Decoupling Class Similarities and Imbalance from Generalized Few-shot Segmentation

Shihong Wang, Ruixun Liu, Kaiyu Li, Jiawei Jiang, Xiangyong Cao

## 🧩 Problem to Solve

일반화된 소수점 학습 분할(Generalized Few-shot Segmentation, GFSS)은 제한된 소수 샘플로 새로운 클래스를 학습하는 동시에 기존 클래스에 대한 지식을 보존하는 것을 목표로 합니다. 본 논문은 GFSS가 간과했던 두 가지 주요 문제를 다룹니다:

1. **클래스 유사성 활용 부족**: 새로운 클래스가 기존 클래스와 관련이 있음에도 불구하고, 기존 방법들은 이러한 유사성(예: 도로 유형 1과 도로 유형 2, 바다와 강)을 효과적으로 활용하지 못하고, 프로토타입이나 선형 분류기를 학습하는 데 초점을 맞췄습니다.
2. **클래스 불균형 문제**: 실제 데이터셋과 GFSS의 훈련 세트 및 지원 세트 구성은 심각한 클래스 불균형(기존 클래스 과다, 새로운 클래스 희소)을 야기합니다. 이는 모델이 기존 클래스에 편향되게 학습되어 새로운 클래스에 대한 성능이 저하되는 원인이 됩니다.
또한, 소수점 학습 과정에서 기존 클래스 지식의 **치명적인 망각**과 작은 지원 세트에 대한 **과적합** 문제도 해결해야 할 과제입니다.

## ✨ Key Contributions

* GFSS 태스크에 존재하는 두 가지 핵심 문제(클래스 유사성 및 클래스 불균형)를 규명하고, 이를 해결하기 위한 확률 전이 행렬(probability transfer matrix)과 로짓 조정 손실(logit adjustment loss)을 제안합니다.
* 제안된 방법이 기존 최첨단 GFSS 방법들을 능가함을 입증하고, 일련의 절삭 및 시각화 분석을 통해 제안된 구성 요소의 효과를 검증합니다. OpenEarthMap 챌린지 개발 단계에서 별다른 추가 장치 없이 2위를 차지했습니다.
* 지원 세트에 대한 과적합 방지 및 기존 클래스 지식 보존의 중요성을 추가 실험을 통해 보여줍니다. 강조된 문제점들은 향후 GFSS 연구 발전에 필요한 수단을 제시합니다.

## 📎 Related Works

* **일반화된 소수점 학습 분할 (GFSS)**
  * **프로토타입 네트워크**: CAPL [23] (두 모듈을 통한 프로토타입 동적 적응), [14] (프로토타입 직교화), [15] (그래프 신경망과 클래스-대조 손실을 통한 유사성 처리).
  * **전이 추론(Transductive Inference)을 이용한 통합 분류기**: [2] (KL Divergence 항 도입으로 과적합 방지), DIaM [8] (전이 학습 개념을 GFSS로 확장).
* **클래스 유사성 (전이 학습)**
  * **매개변수 제어**: 기존 클래스의 매개변수 공유 [34] 또는 유사성 강제 [35].
  * **적대적 학습**: 판별기가 구별할 수 없는 모델 학습 [5, 6].
  * 본 논문은 클래스 간 유사성을 활용하여 지식을 전이하는 새로운 방법을 제안합니다.
* **클래스 불균형 (Long-tailed Learning)**
  * **전문가 네트워크**: 공유 특징 추출기와 클래스별 분류기 학습 [28, 26].
  * **재가중치**: 희소 클래스의 분류기 성능 향상 [10, 30].
  * **로짓 조정**: 클래스 사전 분포를 통해 분류기의 로짓을 조정하여 희소 클래스에 대한 오분류에 더 큰 불이익 부여 [3, 17, 21, 31]. 본 논문은 최적화 오버헤드가 적고 견고하여 이 방식을 채택합니다.

## 🛠️ Methodology

본 논문은 GFSS 태스크의 소수점 학습 단계에서 세 가지 관점으로 기존 방법을 개선합니다.

1. **유사성 전이 (Similarity Transition)**
    * 기존 클래스로 훈련된 모델이 새로운 클래스의 픽셀을 유사한 기존 클래스로 잘못 분류한다는 아이디어에서 시작합니다.
    * `유사성 전이 행렬` $S(x)$를 제안하여 기존 클래스 $y_b$에서 새로운 클래스 $y_n$으로의 전이 확률 $s_{hq} := p(y_n=h|y_b=q, x(j))$를 정의합니다.
    * 네트워크는 두 개의 브랜치로 구성됩니다:
        * **분류 브랜치 (Classification Branch)**: 표준 선형 분류기를 사용하여 $\text{Logits}_{\text{cl}} = \text{cat}([W_b^f, W_n^f]) \circ \phi(x)$를 출력합니다.
        * **전이 브랜치 (Transition Branch)**: MLP $g(x)$로 추정된 $S(x)$와 훈련 단계에서 얻은 기존 분류기 $W_b^t$의 출력을 활용하여 $\text{Logits}_{\text{tr}} = S(x) \circ \text{Softmax}(W_b^t \circ \phi(x))$를 계산합니다.
    * MLP 최적화의 어려움을 줄이기 위해 $g(x)$를 두 개의 작은 MLP $g_r(x)$, $g_c(x)$의 외적(outer product)으로 분해하여 매개변수 수를 감소시킵니다: $S(x) = g_c^{\theta_c}(x) \otimes g_r^{\theta_r}(x) + \beta$.
2. **클래스 불균형 심화 탐구 및 완화**
    * 훈련 세트 및 지원 세트의 클래스 불균형 문제를 해결하기 위해 **레이블 분포 인지 마진 (Label-Distribution-Aware Margin, LDAM) 손실** [3]을 도입합니다.
    * $L_{\text{LDAM}}(x,y) = -\log \frac{e^{z_y - \delta_y}}{e^{z_y - \delta_y} + \sum_{k \neq y} e^{z_k}}$ 형태로 로짓을 조정하여, 희소한 새로운 클래스에 대한 손실을 증폭시킵니다. 여기서 $\delta_k = C/n_k^{1/4}$이며, $n_k$는 클래스 $k$의 분포를 나타냅니다.
3. **기존 지식 보존 (Preserving Base Knowledge)**
    * 기존 지식 증류(Knowledge Distillation) 대신, 전이 행렬을 확장하여 기존 클래스 간의 전이 확률을 포함시킵니다:
    $$ \hat{S}(x) = \begin{pmatrix} S_{\text{base2base}}(x) \\ S_{\text{base2novel}}(x) \end{pmatrix} $$
    * $S_{\text{base2base}}(x)$의 대각 요소가 1에 가까워지도록 학습하여, 기존 클래스의 지식을 외적 계산 후에도 보존합니다.
4. **지원 세트 과적합 방지 (Preventing from Overfitting the Support Set)**
    * [2]에서 제안된 **전이적 정규화 항 (Transductive Normalization Term)** $L_{\pi}$를 적용합니다: $L_{\pi} = \hat{P}_Q \log(\frac{\hat{P}_Q}{\pi})$.
    * 이는 쿼리 이미지의 예측 클래스 비율($\hat{P}_Q$)이 추정된 실제 클래스 비율($\pi$)과 일치하지 않을 때 모델에 불이익을 주어 과적합을 방지합니다. $\pi$는 모델의 예측을 통해 점진적으로 추정됩니다.
5. **최종 목적 함수**: 학습 가능한 모든 매개변수 $W_b^f, W_n^f, \theta_r, \theta_c$에 대해 다음을 최소화합니다: $L = L_{\text{LDAM}} + \lambda \cdot L_{\pi}$.

## 📊 Results

* **데이터셋**: OpenEarthMap [27]의 개조된 버전 (15개 클래스 중 8개 기존, 4개 새로운 클래스). 각 새로운 클래스당 5개의 이미지-레이블 쌍으로 구성된 20개의 지원 세트 예제를 사용합니다.
* **평가 지표**: 클래스별 평균 IoU (mIoU). Base, Novel, Average mIoU를 보고하며, 기존 클래스 mIoU와 새로운 클래스 mIoU에 0.6:0.4의 가중치를 부여한 **Weighted mIoU**를 사용합니다.
* **주요 결과**:
  * ResNet-101 백본을 사용한 Ours-RN은 기존 SOTA (CAPL, BAM, DIaM) 대비 Weighted mIoU에서 3%~7% 향상된 성능을 보였으며, 특히 새로운 클래스 (River, Agric land type 2)에서 큰 개선을 이루었습니다. 이는 유사한 기존 클래스 (Sea)의 도움이 작용한 결과입니다.
  * ConvNext-L 백본을 사용한 Ours-CN은 35.21의 Weighted mIoU로 OpenEarthMap 챌린지에서 2위를 차지했습니다.
  * 본 방법은 ResNet-101, ViT-B/16, ConvNext-L 등 다양한 백본에서 일관된 성능 향상을 보여 일반화 가능성을 입증했습니다 (DIaM 대비 2.39~3.62 Weighted mIoU 향상).
* **전이 행렬 시각화**: 학습 후 전이 행렬의 히트맵은 $S_{\text{base2base}}(x)$의 대각 요소가 지배적으로 높음을 보여 기존 지식이 효과적으로 보존됨을 확인했습니다. 또한, 배경 클래스에서 새로운 클래스로의 전이 확률이 높은 것은 훈련 중 배경으로 처리되었던 잠재적인 새로운 클래스들을 모델이 더 잘 구별할 수 있게 돕는다는 것을 시사합니다.
* **과적합 정량적 연구**: $L_{\pi}$가 없을 경우 지원 세트 mIoU는 계속 증가하지만 쿼리 이미지 mIoU는 특정 시점(약 450 에폭) 이후 감소하는 과적합 현상이 발생했습니다. $L_{\pi}$를 도입하자 과적합 시점이 지연되고 쿼리 이미지에서 더 높은 성능을 달성했습니다.
* **구성 요소 절삭 연구**:
  * $L_{\pi}$ 제거 시: 기존 클래스 성능은 향상되나 새로운 클래스 성능은 저하됩니다 (과적합).
  * $\text{Logits}_{\text{tr}}$ 제거 시: 새로운 클래스 성능 저하 (유사성 전이의 효과 증명).
  * $L_{\text{LDAM}}$ 제거 시: 새로운 클래스 성능이 크게 저하됩니다 (클래스 불균형 해소의 중요성 강조).
  * 모든 구성 요소를 포함할 때: 기존 클래스에 대한 약간의 성능 감소와 함께 새로운 클래스 성능이 현저하게 향상됩니다.

## 🧠 Insights & Discussion

본 논문은 GFSS 태스크에서 클래스 유사성 활용 및 클래스 불균형 처리가 간과되어 왔던 중요한 문제임을 실험을 통해 명확히 보여줍니다. 제안된 클래스 유사성 전이 행렬 및 LDAM 손실은 이러한 문제들을 효과적으로 해결하며, 새로운 클래스에 대한 성능을 크게 향상시키고 기존 클래스 지식 보존 및 지원 세트 과적합 방지에도 기여함을 입증했습니다.

한계점으로는, 현재는 클래스 유사성을 암묵적으로 학습하고 있으며, 향후 더 나은 성능을 위해 잘 설계된 아키텍처를 통해 명시적인 유사성 지도 학습을 탐구할 필요가 있습니다. 또한, 지원 세트 과적합을 방지하기 위한 다른 유효한 방법론들도 추가 연구가 필요합니다. 본 연구는 GFSS의 발전을 위한 핵심 방향을 제시합니다.

## 📌 TL;DR

**문제**: GFSS는 기존-새로운 클래스 유사성 활용 및 클래스 불균형(긴 꼬리 분포, 작은 지원 세트)으로 인해 새로운 클래스 성능이 저조하고 기존 클래스 망각 문제가 있었습니다.
**방법**: **클래스 유사성 전이(Class Similarity Transition)** 접근 방식을 제안합니다. 이는 **유사성 전이 행렬($S(x)$)**을 통해 기존 클래스 지식으로 새로운 클래스 학습을 유도하고, **LDAM 손실($L_{\text{LDAM}}$)**로 클래스 불균형을 완화하며, 확장된 전이 행렬로 기존 지식을 보존하고, **전이적 추론($L_{\pi}$)**으로 지원 세트 과적합을 방지합니다.
**발견**: OpenEarthMap 데이터셋에서 SOTA 성능을 달성하여, 새로운 클래스 mIoU를 크게 향상시키면서 기존 클래스 성능을 유지합니다. 제안된 각 구성 요소가 문제 해결에 효과적임을 입증했습니다.
