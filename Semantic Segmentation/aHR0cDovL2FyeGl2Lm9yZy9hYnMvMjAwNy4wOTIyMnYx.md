# Classes Matter: A Fine-grained Adversarial Approach to Cross-domain Semantic Segmentation

Haoran Wang, Tong Shen, Wei Zhang, Ling-Yu Duan, and Tao Mei

## 🧩 Problem to Solve

지도 학습 기반의 의미론적 분할(semantic segmentation) 모델은 실제 환경에 배포될 때 도메인 불일치(domain shift)로 인해 성능이 크게 저하되는 문제가 발생합니다. 기존의 도메인 적응(domain adaptation) 방법들은 대부분 전체적인 특징 분포 정렬에 중점을 두어, 타겟 도메인의 미묘한 클래스 수준 데이터 구조를 간과합니다. 이로 인해 마진 분포(marginal distribution)는 정렬되더라도 클래스 조건부 분포(class conditional distribution)가 일치하지 않아 혼합된 의미론적 특징(semantic features)이 생성될 수 있습니다. 본 연구는 이러한 클래스 수준 불일치 문제를 해결하고자 합니다.

## ✨ Key Contributions

* **세분화된 적대적 학습 프레임워크 제안**: 클래스 수준 정보를 명시적으로 통합하는 세분화된(fine-grained) 적대적 학습 프레임워크를 제안하여 교차 도메인 의미론적 분할 성능을 향상시켰습니다.
* **클래스 수준 특징 정렬 검증**: 제안된 세분화된 학습 프레임워크가 클래스 수준 특징 정렬을 가능하게 함을 Class Center Distance (CCD) 분석을 통해 정량적으로 검증했습니다.
* **최신 성능 달성**: GTA5→Cityscapes, SYNTHIA→Cityscapes, Cityscapes→Cross-City를 포함한 주요 도메인 적응 분할 태스크에서 포괄적인 실험을 통해 기존의 최신(state-of-the-art) 방법들보다 뛰어난 성능 향상을 달성했습니다.

## 📎 Related Works

* **의미론적 분할**: FCN {$[26]$}, DeepLab 계열 {$[4-6]$} 등 딥러닝 기반 방법들이 큰 발전을 이루었습니다.
* **도메인 적응**: 훈련 데이터와 테스트 데이터의 분포 차이로 인한 성능 저하를 해결합니다. GAN {$[13]$}에서 영감을 받은 적대적 학습 {$[8, 15, 16, 20, 25, 30, 34, 35, 38]$}이 전역적인 특징 정렬에 주로 사용됩니다.
* **도메인 적응 의미론적 분할**:
  * **전역적 분포 정렬**: AdaptSegNet {$[30]$}은 출력 공간에서 분포를 정렬하며, CyCADA {$[15]$}는 픽셀 및 특징 수준에서 표현을 적응시킵니다.
  * **속성 정렬**: 엔트로피 {$[32]$} 및 정보 {$[19]$}와 같은 다른 속성들을 정렬하려는 시도도 있었습니다.
  * **기존 방법의 한계**: 대부분의 기존 방법은 전역적 특징 정렬에 치중하여 다른 의미론적 클래스를 가진 샘플들을 혼합하여 클래스 불일치를 야기할 수 있습니다. CLAN {$[20]$}은 카테고리 수준 정렬을 시도했지만, 클래스 정보를 직접적이고 명시적으로 통합하지는 않았습니다.

## 🛠️ Methodology

본 논문은 클래스 정보를 판별자(discriminator)에 직접 통합하여 세분화된 특징 정렬을 유도하는 새로운 적대적 학습 프레임워크인 FADA (Fine-grained Adversarial Domain Adaptation)를 제안합니다.

1. **전통적인 특징 정렬 재고($\text{Revisit Traditional Feature Alignment}$)**:
    * 의미론적 분할 네트워크 $G$는 특징 추출기 $F$와 다중 클래스 분류기 $C$로 구성됩니다 ($G = C \circ F$).
    * 이진 도메인 판별자 $D$는 소스 도메인 ($0$)과 타겟 도메인 ($1$)의 특징을 구별하도록 훈련됩니다.
    * $D$를 최소화($\min_D L_D$)하고 $G$를 최소화($\min_{F,C} L_{seg} + \lambda_{adv} L_{adv}$)하는 방식으로 교대로 최적화됩니다.
    * $L_{seg}$는 소스 도메인의 교차 엔트로피 손실이며, $L_{adv}$는 $D$를 혼동시켜 도메인 불변 특징을 생성하도록 $F$를 유도합니다.

2. **세분화된 적대적 학습($\text{Fine-grained Adversarial Learning}$)**:
    * **새로운 판별자 설계**: 이진 판별자의 두 출력 채널을 각 $K$개의 클래스에 해당하는 $K$개의 채널로 분할합니다. 이 판별자는 $P(d, c|f)$ (도메인 $d$, 클래스 $c$, 특징 $f$)를 모델링하여 더욱 복잡한 클래스별 구조를 학습하고 클래스 수준 정렬을 촉진합니다.
    * **도메인 인코딩 도입**: 기존의 이진 도메인 레이블($[1,0]$ 및 $[0,1]$)을 클래스 정보를 포함하는 일반화된 형태인 "도메인 인코딩"으로 변환합니다. 소스 도메인의 경우 $[a;0]$, 타겟 도메인의 경우 $[0;a]$로 표현되며, 여기서 $a$는 $K$차원 클래스 지식 벡터이고 $0$은 $K$차원 제로 벡터입니다.
    * **손실 함수 수정**: 수정된 $L_D$ 및 $L_{adv}$는 도메인 인코딩과 클래스별 합계를 사용하여 최적화됩니다. $L_{adv}$는 타겟 도메인의 특징이 클래스 관계를 손상시키지 않으면서 소스 특징으로 간주될 확률을 최대화하도록 설계됩니다.
    * 타겟 도메인에 대한 실제 레이블이 없더라도, 분류기 $C$의 예측값(prediction)이 클래스 정보로 사용되어 세분화된 판별자를 지도하는 데 활용됩니다.

3. **도메인 인코딩을 위한 클래스 지식 추출($\text{Extracting class knowledge for domain encodings}$)**:
    * **하드 레이블(One-hot hard labels)**: 가장 신뢰도가 높은 클래스만 $1$로, 나머지는 $0$으로 설정합니다. 노이즈를 줄이기 위해 특정 신뢰도 임계값 이상인 샘플만 선택할 수 있습니다.
    * **소프트 레이블(Multi-channel soft labels)**: 소프트맥스 확률 대신 로짓($z_k$)에 온도($T$)를 적용하여 클래스 전반에 걸쳐 부드러운 확률 분포를 생성합니다 ($a_k = \frac{\exp(z_k/T)}{\sum_{j=1}^K \exp(z_j/T)}$). 과적합을 방지하기 위해 "신뢰도 클리핑(confidence clipping)"을 적용하여 특정 클래스에 과도하게 피팅되는 것을 막습니다.

4. **구현 상세**:
    * PyTorch 기반. DeeplabV2와 VGG-16 또는 ResNet-101 백본 사용.
    * 세분화된 판별자는 3개의 합성곱(convolution) 레이어로 구성됩니다.
    * 훈련은 소스 데이터에서 20k, FADA 프레임워크에서 40k 반복으로 진행됩니다.
    * 성능 향상을 위해 자가 증류(self-distillation) 및 멀티 스케일 테스트(multi-scale testing)를 적용합니다.

## 📊 Results

* **평가 지표**: 픽셀별 IoU(Intersection-over-Union) 및 mIoU(mean IoU) 사용.
* **Cityscapes→Cross-City**: 기존 최신 방법 대비 평균 2.25% mIoU 향상 (소스 전용 기준 8.5% 향상).
* **SYNTHIA→Cityscapes**: VGG16 백본에서 소스 전용 대비 16.4%, ResNet101 백본에서 13.9% mIoU 향상. 기존 최신 방법들을 크게 능가하며 새로운 SOTA 달성.
* **GTA5→Cityscapes**: VGG16 백본에서 소스 전용 대비 15.5%, ResNet101 백본에서 12.4% mIoU 향상. 기존 특징 수준 방법 대비 4% 이상 개선. 시각적 결과에서도 현저한 개선을 보임.
* **특징 분포 분석 (Class Center Distance, CCD)**:
  * CCD는 클래스 내 응집도(intra-class compactness)와 클래스 간 거리(inter-class distance)의 비율을 측정합니다 ($CCD(i) = \frac{1}{K-1} \sum_{j=1,j \neq i}^K \frac{1}{|S_i|} \sum_{x \in S_i} \frac{\left\|x-\mu_i\right\|^2}{\left\|\mu_i-\mu_j\right\|^2}$). 낮은 CCD는 동일 클래스 특징의 밀집된 클러스터링을 의미합니다.
  * FADA는 AdaptSegNet (1.9) 및 CLAN (1.3)과 비교하여 대부분의 클래스에서 훨씬 낮은 CCD 값을 달성했으며, 평균 CCD 값 1.1로 가장 우수한 클래스 수준 정렬을 입증했습니다.
* **Ablation Study**:
  * 세분화된 적대적 훈련(F-Adv) 단독으로 mIoU 10.1% 향상 (ResNet-101 on GTA5→Cityscapes 기준).
  * 자가 증류(Self Distillation, SD) 적용 시 2.3% 추가 향상.
  * 멀티 스케일 테스트(Multi-Scale Testing, MST) 적용 시 0.7% 추가 향상.
  * 클래스 지식 추출 전략 비교: 소프트 레이블(46.9 mIoU)이 하드 레이블(45.7 mIoU)보다 우수한 성능을 보였습니다.
  * 신뢰도 클리핑(Confidence Clipping) 임계값의 영향: 0.9일 때 46.9 mIoU로 가장 좋은 성능을 보였으며, 이는 과적합 방지에 효과적임을 시사합니다.

## 🧠 Insights & Discussion

* **클래스 중요성 강조**: 기존 도메인 적응 방식이 전역적 특징 정렬에만 초점을 맞춘 한계를 넘어, 의미론적 분할에서는 클래스 정보를 명시적으로 고려하는 세분화된 정렬이 필수적임을 보여줍니다.
* **효과적인 클래스 수준 정렬**: 제안된 FADA 프레임워크는 Class Center Distance (CCD)를 통해 정량적으로 입증된 바와 같이, 도메인 간에 일관된 클래스 구조를 유지하면서 동일 클래스 특징을 더 조밀하게 군집화합니다. 이는 모델의 도메인 일반화 능력을 크게 향상시킵니다.
* **도메인 인코딩의 유연성**: 분류기의 예측값을 통해 타겟 도메인의 레이블 없이도 클래스 지식을 활용할 수 있음을 보여주며, 하드/소프트 레이블 및 신뢰도 클리핑과 같은 다양한 지식 추출 전략을 통해 성능을 최적화할 수 있는 유연성을 제공합니다. 특히 소프트 레이블과 신뢰도 클리핑의 조합이 가장 효과적이었습니다.
* **광범위한 적용 가능성**: 작은 도메인 변화(Cityscapes→Cross-City)부터 큰 도메인 변화(합성 데이터→실제 데이터)에 이르기까지 다양한 시나리오에서 뛰어난 성능 향상을 입증하여 FADA의 일반화된 유효성을 확인했습니다.

## 📌 TL;DR

* **문제**: 교차 도메인 의미론적 분할은 도메인 변화로 인해 성능이 저하되며, 기존 방법들은 전역적인 특징 정렬에만 집중하여 중요한 클래스 수준의 불일치를 간과합니다.
* **해결책**: 본 논문은 세분화된 적대적 학습 프레임워크 FADA를 제안합니다. FADA는 도메인과 클래스를 동시에 구별하는 (즉, $P(d,c|f)$를 모델링하는) 새로운 세분화된 판별자를 사용하고, 이진 도메인 레이블을 분류기 예측값(예: 신뢰도 클리핑이 적용된 소프트 레이블)에서 파생된 '도메인 인코딩'으로 일반화하여 클래스 수준 특징 정렬을 유도합니다.
* **주요 결과**: FADA는 더 낮은 Class Center Distance (CCD)로 더 나은 클래스 수준 정렬을 달성함을 입증했습니다. 또한, GTA5→Cityscapes, SYNTHIA→Cityscapes, Cityscapes→Cross-City 벤치마크에서 기존 최신 방법들을 크게 능가하여 새로운 SOTA 성능을 달성했습니다. 세분화된 적대적 훈련, 자가 증류, 멀티 스케일 테스트가 결합되어 강력한 성능을 보여주었습니다.
