{
  "url": "http://arxiv.org/abs/2303.11797v2",
  "title": "CAT-Seg: Cost Aggregation for Open-Vocabulary Semantic Segmentation",
  "authors": "Seokju Cho, Heeseong Shin, Sunghwan Hong, Anurag Arnab, Paul Hongsuck Seo, Seungryong Kim",
  "year": 2023,
  "abstract": "Open-vocabulary semantic segmentation presents the challenge of labeling each\npixel within an image based on a wide range of text descriptions. In this work,\nwe introduce a novel cost-based approach to adapt vision-language foundation\nmodels, notably CLIP, for the intricate task of semantic segmentation. Through\naggregating the cosine similarity score, i.e., the cost volume between image\nand text embeddings, our method potently adapts CLIP for segmenting seen and\nunseen classes by fine-tuning its encoders, addressing the challenges faced by\nexisting methods in handling unseen classes. Building upon this, we explore\nmethods to effectively aggregate the cost volume considering its multi-modal\nnature of being established between image and text embeddings. Furthermore, we\nexamine various methods for efficiently fine-tuning CLIP."
}