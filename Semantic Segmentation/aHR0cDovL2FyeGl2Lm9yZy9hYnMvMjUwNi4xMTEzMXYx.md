# Segment This Thing: Foveated Tokenization for Efficient Point-Prompted Segmentation

Tanner Schmidt, Richard Newcombe

## 🧩 Problem to Solve

기존 이미지 분할 모델, 특히 Segment Anything Model (SAM)은 뛰어난 성능을 보이지만, 무거운 이미지 인코더(예: ViT-H)로 인해 높은 계산 비용을 요구합니다. 이는 로봇 공학이나 증강/가상 현실(AR/VR) 애플리케이션과 같이 실시간 스트리밍 비디오 환경에서 낮은 지연 시간(latency)과 제한된 대역폭이 필수적인 경우에 큰 제약이 됩니다. 기존 효율화 연구들이 주로 모델 크기를 줄이는 방식에 집중했지만, 본 연구는 다른 접근 방식을 통해 효율성을 확보하고자 합니다.

## ✨ Key Contributions

* **Foveated Tokenization 도입:** 인간 시각 시스템의 중심와(fovea) 개념에서 영감을 받아, 점(point) 프롬프트에 집중된 가변 해상도 패치 토큰화 방식을 제안합니다. 이는 균일한 패치 토큰화보다 훨씬 적은 수의 이미지 토큰을 생성하여 효율성을 극대화합니다.
* **모델 크기 유지하면서 효율성 대폭 향상:** 모델 크기를 줄이지 않고도 토큰 수를 획기적으로 줄여 계산 비용을 대폭 절감하고 추론 지연 시간을 낮춥니다. SAM-H 대비 약 42배, EfficientSAM 대비 5.6배 빠른 추론 속도를 달성합니다.
* **대역폭 요구 사항 감소:** 토큰화 과정에서 이미지 압축 효과가 발생하여 센서와 장치 간 이미지 데이터 전송에 필요한 대역폭을 줄입니다. 약 $210 \times 210$ 이미지에 해당하는 44K 픽셀만 입력으로 요구합니다.
* **작은 객체 분할 정밀도 향상:** 마스크 디코더에서 더 많은 역합성(deconvolution) 레이어를 사용하여 중심부의 해상도를 SAM보다 높게 유지, 매우 작은 객체도 더 정밀하게 분할할 수 있습니다.
* **경쟁력 있는 성능 유지:** 효율성 향상에도 불구하고 여러 공개 데이터셋에서 평균 IoU (mIoU) 측면에서 경쟁력 있는 분할 정확도를 유지합니다.

## 📎 Related Works

* **효율적인 프롬프트 기반 분할 (Efficient Prompted Segmentation):**
  * **FastSAM [49]:** CNN 기반 객체 감지 및 분할 백본을 사용하여 후보를 생성하고 프롬프트로 선택/병합.
  * **SqueezeSAM [39]:** UNet 아키텍처에 트랜스포머를 적용하고 프롬프트 조기 융합(early prompt fusion)을 통해 관련 정보에 집중.
  * **EfficientViT-SAM [48], EfficientSAM [40], EdgeSAM [51], MobileSAM [46]:** SAM의 ViT 인코더를 대체하거나 지식 증류(knowledge distillation)를 통해 경량화된 인코더를 학습.
* **프롬프트 기반 비디오 분할 (Prompted Video Segmentation):**
  * **SAM-2 [33]:** SAM을 비디오 객체 분할로 확장하지만, 하나의 프롬프트가 비디오 전체에서 하나의 객체만 분할. STT는 프레임마다 다른 객체 분할 가능.
* **해상도 감소 (Resolution Reduction):** AlexNet [23], ResNet [15] 등 초기 네트워크 레이어에서 해상도를 빠르게 줄이는 기존 관행과 달리, STT는 프롬프트로부터의 거리에 따라 해상도 감소율이 달라짐.
* **압축 (Compression):** Park and Johnson [31]의 JPEG DCT 계수 직접 학습, Horton et al. [17]의 압축된 바이트 인코딩 직접 학습 등. STT의 foveated tokenization은 이러한 방법과 직교하는 저비용 압축 기법.
* **효율적인 토큰화 (Efficient Tokenization):** TiTok [45], 토큰 가지치기(pruning) 또는 병합(merging) 접근법 [2, 5, 13, 21, 27, 28, 32, 34, 35, 41, 42] 등. STT는 입력 크기 자체를 줄이는 방식에서 이점.
* **Foveated Vision:**
  * **FoveaTer [18]:** 컨볼루션 네트워크 출력에 가변 크기 풀링 윈도우를 적용하여 foveated feature map 생성. STT는 네트워크 이전에 foveation을 적용하여 대역폭 제약 완화.
  * **Peripheral Vision Transformer [29]:** 위치 인코딩을 수정하여 foveation의 귀납적 편향(inductive bias)에 중점. 효율성 향상 없음.
  * **PeLK [4]:** CNN에 foveation 개념을 적용, 가중치 할당을 중앙에 집중. STT는 파라미터 수보다 입력 크기 감소에 중점.
  * **GazeGPT [22]:** 시선 기반 프롬프트와 foveated 이미지를 사용하지만, 균일 해상도 이미지로 사전 학습된 모델.

## 🛠️ Methodology

Segment This Thing (STT) 모델은 SAM의 3단계 구조를 기반으로 하지만, 프롬프트 인코더를 생략합니다.

1. **Foveated Tokenization (중심와 토큰화):**
    * **크롭 및 패치화:** 이미지와 단일 점 프롬프트가 주어지면, 프롬프트를 중심으로 고정된 크기(패턴에 의해 결정됨)의 영역을 잘라냅니다. 이미지 경계를 벗어나면 패딩(padding)을 추가합니다.
    * **가변 해상도 패치 생성:** 이 크롭된 영역은 미리 정의된 중심와 패턴에 따라 일련의 패치로 나뉩니다. 중앙에는 조밀한 패치 그리드가 있고, 이를 둘러싼 동심원 형태로 점점 더 큰 패치가 배치됩니다 (Figure 1, 2 참조). 각 링의 패치 크기는 이전 링보다 크며, 중앙 패치 크기의 정수 배수입니다.
    * **다운샘플링:** 각 패치는 중앙 패치와 동일한 크기로 다운샘플링됩니다. 이는 하드웨어 친화적인 적분 이미지(integral image)와 박스 필터(box filter)를 통해 효율적으로 구현됩니다.
    * **토큰 생성:** 다운샘플링 후 모든 패치는 동일한 크기가 되므로, 각 패치를 벡터로 평탄화하고 스택하여 토큰 행렬을 형성합니다. 이 토큰 세트가 STT 모델로 전달됩니다 (Figure 3 참조).

2. **Image Encoder:**
    * **표준 트랜스포머:** foveated tokenization으로 인해 패치들이 2D 그리드에 배열되지 않으므로, SAM의 ViT 모델에서 사용된 윈도우드 어텐션(windowed attention)은 적용되지 않습니다. 대신 토큰 수가 대폭 줄어들어 표준 트랜스포머 모델을 사용할 수 있습니다.
    * **입력 처리:** 다운샘플링된 패치들을 단일 선형 레이어로 투영하고, 학습된 위치 인코딩(position encoding)을 추가한 후, 트랜스포머에 통과시켜 (foveated) 특징 맵을 얻습니다.
    * **추가 토큰:** 모델이 정보를 수집하고 전파할 수 있도록 레지스터 토큰(register token)을 포함합니다.
    * **마스킹:** 이미지 경계를 벗어나는 토큰의 셀프 어텐션(self-attention) 참여를 방지하기 위해 토큰 마스크를 적용합니다.

3. **Mask Decoder:**
    * **SAM 기반 구조:** SAM의 디코더와 유사하게 동작하지만 단순화되었습니다. 반복적인 분할은 지원하지 않으며, 단일 점 프롬프트에 대해 항상 $N$개의 마스크를 출력합니다.
    * **쿼리 토큰:** IoU 예측을 위한 1개와 각 예측 마스크를 위한 1개씩, 총 $N+1$개의 쿼리 토큰을 사용합니다.
    * **크로스 어텐션:** 인코더의 출력(컨텍스트 토큰 세트)과 쿼리 토큰 세트 간에 양방향 크로스 어텐션 트랜스포머를 적용합니다.
    * **고해상도 출력:** SAM이 입력 이미지 해상도의 1/4로 분할 맵을 추정하는 것과 달리, STT는 4개의 역합성 레이어를 스태킹하여 패치당 $16 \times 16$ 분할 맵을 생성할 수 있습니다. 이는 중앙 패치의 경우 전체 해상도로 레이블이 추정되어 SAM보다 높은 해상도 출력을 제공합니다 (Figure 4 참조).

4. **Training:**
    * **MAE 사전 학습:** 새로운 토큰화 방식 때문에 기존 사전 학습된 인코더를 사용할 수 없으므로, 이미지 인코더를 위한 마스크드 오토인코더(MAE) 사전 학습을 수행합니다. SA-1B 데이터셋에서 무작위로 선택된 프롬프트 중심을 기반으로 foveation을 생성합니다. 재구성 손실은 경계 내의 다운샘플링된 토큰에만 적용됩니다.
    * **세그멘테이션 파인튜닝:** 사전 학습 후 디코더를 폐기하고 인코더 가중치를 STT 인코더 초기화에 사용합니다. SA-1B 데이터셋을 사용하여 마스크 디코더를 학습하고 인코더 가중치를 미세 조정합니다. Focal, Dice, IoU 예측 손실을 SAM과 동일하게 사용하지만, STT의 가변 해상도 출력 마스크를 처리하기 위해 두 가지 변경 사항을 적용합니다.
        * **가변 해상도 손실:** ground truth 마스크를 STT의 foveated 출력 공간으로 매핑하여(입력 픽셀과 동일한 다운샘플링 방식 적용) 실숫값 foveated 분할 맵을 생성합니다. 이를 통해 Dice 및 Focal 손실을 적용합니다.
        * **예상 IoU:** IoU 예측을 위해 이진화된 마스크의 IoU 대신 실숫값 분할 맵의 예상 IoU (expected IoU)를 사용합니다.
    * **Foveation Center Selection:** 데이터 증강의 역할로 무작위 foveation 중심 선택을 사용합니다. 학습 시 대상 세그먼트 내에서 선택된 점과 모델 프롬프트에 사용되는 중심점 사이에 작은 가우시안 분포 오프셋(noise)을 추가하여 프롬프트의 불확실성을 모델이 처리하도록 학습시킬 수 있습니다.

## 📊 Results

* **효율성:** Table 2에서 STT는 SAM 및 다른 효율적인 변형들과 비교하여 현저히 낮은 FLOPs와 짧은 지연 시간(latency)을 보여줍니다. STT-B는 MobileSAM보다 약 3배 낮은 FLOPs와 약 2.8배 빠른 latency를 보입니다.
* **분할 정확도 (mIoU):** Figure 7과 Table 5에서 볼 수 있듯이, STT 모델은 MobileSAM을 크게 능가하며, EfficientSAM-Ti와는 정확도 면에서 경쟁력을 유지하지만 훨씬 빠릅니다. STT-L 모델이 STT-B보다 성능이 우수하여 모델 용량 유지가 중요함을 시사합니다.
* **객체 크기별 성능:** STT는 넓은 범위의 크기와 모양을 가진 객체를 분할할 수 있습니다 (Figure 5 참조). 특히 중심 영역에서는 SAM보다 높은 해상도 출력으로 인해 매우 작은 객체에 대한 정밀도 이점을 가집니다 (Figure 4 참조). 큰 객체의 경우 외곽에서 해상도가 낮아져 경계가 다소 거칠어질 수 있습니다 (Figure 8 참조).
* **시선 기반 프롬프트 (Gaze-based Prompting):** 정성적 실험에서 STT는 시선 추적 데이터로 프롬프트되어 사용자가 바라보는 객체를 효과적으로 분할할 수 있음을 보여줍니다. 프롬프트 노이즈를 포함하여 학습된 모델은 시선 추정의 불확실성에도 불구하고 올바른 객체를 분할할 수 있습니다 (Figure 9 참조).

## 🧠 Insights & Discussion

* **혁신적인 효율성 달성:** 기존 모델 경량화와 다른 방식으로 효율성을 극대화했다는 점에서 큰 의미가 있습니다. 토큰 수 감소는 트랜스포머 기반 이미지 인코더의 계산 비용에 결정적인 영향을 미치기 때문입니다.
* **실용적인 애플리케이션 가능성:** 스트리밍 비디오, AR/VR, 로봇 공학과 같이 낮은 지연 시간과 제한된 자원이 요구되는 엣지 디바이스 환경에서 STT는 매우 유망한 솔루션입니다. 특히, 대역폭 요구 사항 감소는 센서와 컴퓨팅 장치 간의 데이터 전송 효율성을 높여줍니다.
* **유용한 귀납적 편향(Inductive Bias):** foveation은 모델이 프롬프트 주변의 관심 영역에 계산 자원을 집중하도록 유도하는 유용한 귀납적 편향을 제공합니다.
* **단점 및 개선 방향:**
  * **거친 분할 경계:** 큰 객체의 경우 foveation으로 인한 정보 손실 때문에 분할 경계가 다소 거칠어질 수 있습니다. 하지만 이는 정밀한 경계가 필요한 경우 근사 윤곽을 안 후 다시 프롬프트하여 보완할 수 있습니다.
  * **프롬프트당 인코더 실행:** SAM과 달리 STT는 각 프롬프트에 대해 이미지 인코더와 마스크 디코더를 모두 실행해야 합니다. 하지만 STT의 속도가 워낙 빨라 동일 이미지에 여러 프롬프트가 필요한 경우에도 여전히 효율적이며, 스트리밍 비디오 사용 사례에서는 단일 객체 분할이 더 흔합니다.
* **확장 가능성:** foveated tokenization은 이미지 분할뿐만 아니라 다양한 이미지 및 비디오 처리 작업에도 적용될 수 있는 일반적인 접근 방식임을 시사합니다.

## 📌 TL;DR

본 논문은 SAM의 높은 계산 비용 문제를 해결하기 위해 생체에서 영감을 받은 **Foveated Tokenization**을 제안하는 **Segment This Thing (STT)** 모델을 소개합니다. STT는 점 프롬프트에 초점을 맞춰 가변 해상도 패치 토큰화를 적용하여 기존 모델들이 모델 크기를 줄인 것과 달리, **모델 크기를 유지하면서 토큰 수를 획기적으로 줄여 계산 효율성(최대 42배 빠름)과 대역폭 효율성을 극대화**합니다. 낮은 지연 시간과 엣지 장치에서의 실행 가능성으로 AR/VR 및 로봇 공학과 같은 **스트리밍 비디오 애플리케이션에 적합**하며, 특히 작은 객체에 대한 높은 분할 정밀도를 유지하며 **시선 기반 프롬프트에서도 우수한 성능**을 보입니다.
