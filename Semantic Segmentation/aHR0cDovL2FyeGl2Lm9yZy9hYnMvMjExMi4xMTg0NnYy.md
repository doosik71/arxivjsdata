# A Discriminative Single-Shot Segmentation Network for Visual Object Tracking

Alan Lukeˇziˇc, Jiˇr ́ı Matas, Matej Kristan

## 🧩 Problem to Solve

기존의 템플릿 기반 판별 추적기(discriminative trackers)는 견고하지만, 바운딩 박스 추적과 제한된 변환 모델에 국한되어 위치 정확도가 낮습니다. 특히, 변형 가능하거나 길거나 회전하는 객체와 같이 바운딩 박스로는 대상 객체를 정확히 나타내기 어려운 경우 문제가 됩니다. 한편, 비디오 객체 분할(Video Object Segmentation, VOS) 방법은 픽셀 단위의 마스크를 제공하지만, 짧은 영상, 작은 객체, 빠른 움직임, 복잡한 배경과 같은 일반적인 단기 추적 시나리오에서는 성능이 저조합니다. SiamMask와 같은 기존의 분할 추적기는 로컬라이제이션과 분할 프로세스를 분리하여 엔드-투-엔드 학습 기회를 놓치고 고정된 템플릿을 사용한다는 한계가 있습니다. 따라서, 시각 객체 추적(Visual Object Tracking, VOT)과 비디오 객체 분할 사이의 간극을 좁히는 견고하고 정확한 분할 추적 네트워크가 필요합니다.

## ✨ Key Contributions

* **D3S$^2$ (Discriminative Single-Shot Segmentation Tracker) 제안:** 시각 객체 추적과 비디오 객체 분할 사이의 간극을 좁히는 새로운 단일 샷(single-shot) 판별 분할 추적기입니다.
* **두 가지 상보적인 타겟 모델 도입:**
  * **GIM (Geometrically Invariant Model):** 비강체 변형을 포함한 광범위한 변환에 불변하며, 변형에 대한 견고성을 제공합니다.
  * **GEM (Geometrically Constrained Euclidean Model):** 유클리드 변환에 제약되며, 판별적 적응을 통해 강력한 로컬라이제이션 능력을 제공하고, GIM이 추론한 여러 타겟 분할 중 올바른 것을 선택하는 역할을 합니다.
* **단일 샷, 엔드-투-엔드 학습 아키텍처:** 네트워크는 오직 분할을 주 출력으로 하여 엔드-투-엔드로 학습되며, 단일 패스(pass)로 분할 맵을 계산합니다.
* **객체 스케일(내재적 크기)과 피처 스케일(가시적 크기) 추정 분리:** 타겟의 고유 크기(모델 업데이트 및 피처 추출에 사용)와 이미지 내에서 보고되는 가시적 크기를 분리하여 추적 신뢰성을 향상시킵니다.
* **최첨단 성능 달성:**
  * VOT2020 벤치마크(분할 기반)에서 모든 공개된 추적기 중 최고 성능을 기록합니다.
  * GOT-10k, TrackingNet, OTB100, LaSoT(바운딩 박스 기반)에서 최신 추적기들과 견줄 만한 성능을 보입니다.
  * VOS 벤치마크에서 선도적인 분할 추적기 SiamMask를 능가하며, 최고 VOS 알고리즘과 대등한 성능을 보이면서도 훨씬 빠릅니다.
* **뛰어난 일반화 능력:** 단일 사전 학습 버전으로 다양한 벤치마크에서 재학습 없이 뛰어난 성능을 보여줍니다.

## 📎 Related Works

* **판별적 상관 필터(DCF) 기반 추적기:** 대상과 배경의 구별 능력에 중점을 둡니다 (예: ECO [3], ATOM [9], DIMP [19]). 초기 DCF는 바운딩 박스 추적에 중점을 두었으나, 최근에는 딥 피처를 활용하여 성능을 개선하고 있습니다. 일부 연구에서는 분할을 DCF 추적의 보조적인 역할로 사용했습니다 (예: [5], [11]).
* **샴(Siamese) 기반 추적기:** 제너레이티브 템플릿에 기반하며, 오프라인으로 사전 학습된 백본을 사용하여 실시간 성능을 달성합니다 (예: SiamFC [6], SiamRPN [8]). SiamMask [18]는 SiamRPN을 확장하여 로컬라이제이션과 분할을 동시에 수행하지만, 두 단계를 분리하여 처리하고 고정된 템플릿을 사용합니다. 최근에는 템플릿 적응 (예: GradNet [39]) 및 앵커 프리(anchor-free) 객체 감지 네트워크 (예: SiamCAR [41])를 통합하는 연구가 진행되었습니다.
* **비디오 객체 분할(VOS):** DAVIS [12] 및 YoutubeVOS [14]와 같은 챌린지를 통해 대중화되었습니다. 대부분의 VOS 방법은 대규모 딥 네트워크를 사용하며, 미세 조정과 긴 처리 시간을 요구합니다 (예: OSVOS [44], OnAVOS [45]). 특징 매칭 기반의 빠른 방법도 제안되었습니다 (예: VideoMatch [48], PML [49]). 최근에는 온라인 적응에 초점을 맞춘 연구 (예: A-GAME [50])가 있었지만, VOS는 주로 짧은 비디오의 큰 객체 분할에 초점을 맞춰 추적 작업에는 부적합한 경우가 많습니다.

## 🛠️ Methodology

D3S$^2$는 대상의 외관 변화와 배경 구별에 견고하게 대처하기 위해 두 가지 모델(GIM 및 GEM)을 사용하며, 이들은 리파인먼트 경로(Refinement Pathway)에서 융합되어 상세한 분할 마스크를 생성합니다. 마지막으로 스케일 추정 모듈(SEM)이 마스크를 기반으로 대상 스케일을 추정합니다.

1. **Geometrically Invariant Model (GIM) 경로:**
    * **목적:** 변형 가능한 대상의 정확한 분할을 위해 공간적 제약이 적은 판별 모델을 제공합니다.
    * **구조:** 대상(X$_F$) 및 배경(X$_B$)에 해당하는 두 가지 딥 피처 벡터 세트로 구성됩니다. 사전 학습된 백본 피처는 1x1 및 3x3 컨볼루션 레이어를 통해 처리됩니다.
    * **작동:** 추적 중 검색 영역에서 추출된 픽셀 레벨 피처는 GIM 모델(X$_{GIM}$)과 비교되어 전경(F) 및 배경(B) 유사도 채널을 계산합니다. 각 픽셀 $i$의 피처 $y_i$는 모든 전경 피처 $x_{F_j} \in X_F$와 정규화된 내적 $s_{F_{ij}}(y_i, x_{F_j}) = \langle \tilde{y_i}, \tilde{x_{F_j}} \rangle$을 통해 유사도를 계산합니다. 이 유사도 점수들은 정렬된 후 MLP(Multi-Layer Perceptron)에 입력되어 단일 유사도 점수 $F_i$로 디코딩됩니다. 배경 유사도 채널 $B$도 동일하게 계산됩니다. 최종적으로 소프트맥스 레이어를 적용하여 대상 후방 확률(posterior) 채널 $P$를 생성합니다.

2. **Geometrically Constrained Euclidean Model (GEM) 경로:**
    * **목적:** 판별적 상관 필터의 강점을 활용하여 견고한 로컬라이제이션을 제공합니다.
    * **구조:** 백본 피처는 1x1 컨볼루션 레이어를 통해 256 채널로 차원 축소된 후, 256 채널 DCF 및 PeLU 비선형성으로 상관됩니다.
    * **작동:** 상관 응답의 최대값은 가장 가능성 있는 대상 위치로 간주됩니다. 픽셀 단위 대상 존재 신뢰도를 나타내는 대상 위치 채널 $L$은 상관 맵에서 최대값 위치로부터 나머지 픽셀까지의 (유클리드) 거리 변환을 계산하여 구성됩니다.

3. **Refinement Pathway (리파인먼트 경로):**
    * **목적:** GIM 및 GEM 경로에서 제공되는 상보적인 정보를 결합하고, 해상도를 높여 정확하고 상세한 분할 맵을 생성합니다.
    * **구조:** GEM의 $L$ 채널과 GIM의 $F$ 및 $P$ 채널을 입력으로 받습니다. 이 채널들을 연결하고 3x3 컨볼루션 레이어를 거쳐 64 채널 텐서로 만듭니다. 이후 백본에서 계산된 여러 레이어의 조정된 피처를 사용하여 세 단계의 업스케일링이 적용됩니다. 각 업스케일링 단계는 해상도를 두 배로 늘리고, 두 개의 3x3 컨볼루션 레이어를 포함합니다. 채널 어텐션 메커니즘이 적용되어 조정된 백본 피처 텐서와 이전 리파인된 레이어의 업스케일된 텐서를 합칩니다. 마지막 업스케일링 단계 후 소프트맥스를 통해 최종 분할 확률 맵을 생성합니다.

4. **Scale Estimation Module (SEM) 스케일 추정 모듈:**
    * **목적:** 대상의 고유 크기(피처 추출을 위한 공간 스케일 결정)와 가시적 크기(이미지 내에서 보고되는 대상 위치)를 분리하여 견고한 스케일 추정을 수행합니다.
    * **구조:** 리파인먼트 경로에서 예측된 분할 마스크, 백본 템플릿 피처, 검색 영역 피처를 입력으로 받습니다. 마스크 조정 모듈이 마스크 해상도를 백본 피처와 일치시키고 스케일 예측에 적합한 형태로 인코딩합니다. 템플릿 및 검색 영역 피처는 1x1 컨볼루션으로 256 채널로 축소됩니다.
    * **작동:** 분류 헤드(classification head)는 픽셀별 대상 및 배경 존재 점수 두 채널을 예측합니다. 가장 가능성 있는 대상 위치 $\tilde{p}$는 이 두 채널의 픽셀별 소프트맥스 최대값 위치입니다. 대상 영역 헤드(target region head)는 대상 바운딩 박스의 상단, 하단, 오른쪽, 왼쪽 가장자리까지의 픽셀별 거리 $d_T, d_B, d_R, d_L$ 네 채널을 예측합니다. 대상의 고유 스케일을 결정하는 폭 $\tilde{w}$와 높이 $\tilde{h}$는 $\tilde{w} = d_R(\tilde{p}) - d_L(\tilde{p})$, $\tilde{h} = d_T(\tilde{p}) - d_B(\tilde{p})$로 정의됩니다.

5. **D3S$^2$를 이용한 추적 과정:**
    * **초기화:** 첫 프레임의 ground truth 대상 위치를 사용하여 D3S$^2$를 초기화합니다. ground truth 바운딩 박스만 제공될 경우, 초기 D3S$^2$ 실행을 통해 근사적인 분할 마스크를 구성하여 GIM을 초기화합니다.
    * **추적:** 새 프레임이 도착하면 이전 대상 위치에서 대상 크기의 4배 영역을 추출합니다. 이 영역은 D3S$^2$ 네트워크에 의해 처리되어 출력 분할 마스크를 생성합니다. SEM을 통해 대상 크기를 추정하고, 이 추정된 크기는 GEM의 DCF 업데이트에 사용되며 다음 프레임의 검색 영역 크기를 결정합니다. 평가 프로토콜에 따라 마스크에 바운딩 박스를 맞춥니다.

## 📊 Results

* **VOT2020 벤치마크 (분할 기반):**
  * 챌린지 참가 추적기 중 EAO(Expected Average Overlap)에서 2위(0.513)를 차지하며 최고 성능 RPT에 불과 3% 낮은 점수를 기록했습니다.
  * 모든 공개된 최신 추적기 (Ocean, SiamMask, DIMP, ATOM, STM 등)를 EAO 기준으로 큰 폭으로 능가했습니다 (예: Ocean보다 19% 우수). 이는 정확도와 견고성 모두에서 높은 성능 향상을 보여줍니다.
* **GOT-10k 테스트 세트 (바운딩 박스 기반):**
  * 대부분의 최첨단 추적기를 능가했으며, 특히 SiamMask와 DIMP보다 각각 24% 및 4.6% 이상 높은 평균 오버랩을 달성했습니다. GOT-10k 훈련 세트에 미세 조정되지 않았음에도 뛰어난 일반화 능력을 보여주었습니다.
* **TrackingNet 테스트 세트 (바운딩 박스 기반):**
  * 최신 최첨단 추적기들을 포함하여 대부분의 추적기를 AUC 기준으로 크게 능가했습니다. D3S$^2$는 Youtube-VOS의 3471개 시퀀스에서 분할을 위해 학습된 반면, 비교 대상 추적기들은 훨씬 큰 데이터셋에 미세 조정되었음에도 불구하고 이룬 성과입니다.
* **OTB100 및 LaSoT 데이터셋:**
  * **OTB100:** 최상위 추적기들과 견줄 만한 성능을 보였으나, 데이터셋의 바운딩 박스 주석 모호성을 지적하며, OTB100s(수동으로 분할 마스크 재주석된 10개 시퀀스)에서 D3S$^2$가 가장 높은 AUC를 달성하여 예측된 바운딩 박스의 높은 정확도를 입증했습니다.
  * **LaSoT (장기 추적):** D3S$^2$는 단기 추적기임에도 불구하고 4위를 기록하는 인상적인 결과를 보여주었습니다. 이는 큰 검색 영역과 대상이 사라진 지점 근처에서 재출현하는 경향 때문입니다.
* **DAVIS16 및 DAVIS17 분할 벤치마크:**
  * 최상위 VOS 방법들과 대등한 성능을 보였으며, 동시에 대부분의 VOS 방법보다 100배 이상 빨랐습니다.
  * SiamMask를 모든 지표에서 능가하여, 추적과 분할의 결합 능력을 입증했습니다.
* **어블레이션 연구:**
  * SEM(스케일 추정 모듈) 제거 시 추적 실패가 증가하며 4%의 성능 저하를 보였고, 이는 모델 업데이트에 영향을 미치는 견고한 스케일 추정이 중요함을 시사합니다.
  * GIM 및 GEM 모듈 각각의 기여도 분석 결과, GIM 제거 시 정확도와 견고성에서 각각 3%와 9% 감소하여 전체 성능이 14% 하락했고, GEM 제거 시 약 10%의 성능 하락이 있었습니다. 이는 두 모델이 상보적으로 중요함을 보여줍니다.
  * 채널 어텐션, 마스크 조정 모듈, GIM의 MLP 등 각 구성 요소가 전체 성능 향상에 기여함을 확인했습니다.

## 🧠 Insights & Discussion

* **추적 및 분할의 융합 성공:** D3S$^2$는 기존의 시각 객체 추적(견고성)과 비디오 객체 분할(정확성) 분야의 한계를 극복하고 이들을 효과적으로 결합했습니다. 특히, GIM과 GEM이라는 두 가지 상보적인 모델의 조합은 변형 가능한 대상의 높은 분할 정확도와 방해 요소로부터의 견고한 구별 능력을 동시에 달성하는 핵심 요인입니다.
* **스케일 추정의 중요성:** 내재적 대상 크기(모델 업데이트 및 피처 추출에 사용)와 가시적 대상 크기(결과 보고에 사용)를 분리하여 추정하는 SEM의 도입은 부분 가려짐이나 외관 변화 시에도 추적 신뢰성을 크게 향상시키는 중요한 기여입니다. 어블레이션 연구에서도 SEM의 제거가 추적 실패율을 현저히 높임이 확인되었습니다.
* **뛰어난 일반화 능력:** 단일 사전 학습된 D3S$^2$ 모델이 다양한 벤치마크(VOT2020, GOT-10k, TrackingNet, OTB100, LaSoT, DAVIS)에서 재학습 없이 최첨단 성능을 달성하는 것은 이 모델의 강력한 일반화 능력을 보여줍니다. 이는 특히 실용적인 응용 분야에서 큰 장점입니다.
* **기존 데이터셋의 한계 지적:** OTB100과 같은 오래된 바운딩 박스 기반 데이터셋의 주석 모호성을 지적하며, 현대 추적기의 성능을 정확히 평가하기 위해서는 분할 기반 주석이 더 신뢰성 있음을 시사합니다.
* **성능-속도 트레이드오프:** D3S$^2$는 정확도와 속도 사이의 균형을 제공하는 두 가지 버전을 통해 다양한 응용 분야의 요구를 충족시킬 수 있습니다.
* **향후 연구 방향:** GEM의 회전 불변성을 더욱 개선하기 위한 공분산 백본 피처 도입을 제안합니다.

## 📌 TL;DR

시각 객체 추적은 바운딩 박스 제약과 비강체 변형 처리 미흡, 비디오 객체 분할은 일반적인 추적 시나리오(작고 빠른 객체)에서 약점이라는 문제를 해결하기 위해, D3S$^2$는 **GIM (변형 불변성)**과 **GEM (견고한 로컬라이제이션)** 두 상보적 모델을 결합한 **단일 샷 판별 분할 추적 네트워크**를 제안합니다. 이 네트워크는 **객체의 내재적 스케일 추정**을 분리하여 추적 신뢰성을 높이며, **분할을 주 출력**으로 하여 엔드-투-엔드로 학습됩니다. 결과적으로, D3S$^2$는 VOT2020에서 최첨단 성능을 달성하고, 다른 주요 추적 벤치마크에서 경쟁 우위를 보이며, VOS 벤치마크에서도 SiamMask를 능가하며 훨씬 빠른 속도를 자랑합니다. 이는 추적과 분할 사이의 간극을 효과적으로 좁혔음을 입증합니다.
