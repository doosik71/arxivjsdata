# Deep Extreme Cut: From Extreme Points to Object Segmentation

K.-K. Maninis, S. Caelles, J. Pont-Tuset, L. Van Gool

## 🧩 Problem to Solve

- 기존 객체 분할(Object Segmentation) 방법론의 한계 극복:
  - **높은 주석 비용:** 픽셀 단위의 수동 주석은 시간과 비용이 많이 들고 번거로운 과정입니다.
  - **성능 부족:** 약한 감독(Weakly Supervised) 방식은 최신 기술에 비해 성능이 뒤처지며, 바운딩 박스나 스크리블과 같은 반자동 방식은 사용자 상호작용이 필요하고 때로는 정확도가 낮거나 비효율적일 수 있습니다.
  - **사용자 상호작용의 비효율성:** 특히 바운딩 박스 그리는 과정은 인지적으로 부담이 큽니다.
- 본 연구는 **객체의 극점(Extreme Points)**(가장 왼쪽, 오른쪽, 위쪽, 아래쪽 픽셀)을 입력으로 활용하여 이러한 문제들을 해결하고, 적은 사용자 입력으로도 정밀한 객체 분할을 달성하는 통일된 접근 방식을 제안합니다.

## ✨ Key Contributions

- **DEXTR (Deep Extreme Cut) 제안:** 객체의 네 극점을 입력으로 사용하여 정밀한 객체 분할 마스크를 생성하는 CNN 기반 방법론인 DEXTR을 개발했습니다.
- **최첨단 성능 달성:** 안내 분할(Guided Segmentation), 상호작용 분할(Interactive Segmentation), 비디오 객체 분할(Video Object Segmentation), 고밀도 주석(Dense Annotation) 생성 등 다양한 벤치마크 및 데이터셋에서 기존 방법론 대비 가장 정밀한 결과를 달성했습니다.
- **사용자 입력 감소 및 효율성:** 기존 바운딩 박스 방식보다 적은 사용자 입력(4개의 극점 클릭)으로 더 정확한 분할을 제공하며, 이는 주석 비용을 획기적으로 줄였습니다(최대 10배).
- **주석 도구로서의 활용 가능성:** DEXTR이 생성한 마스크로 학습된 모델은 실제 그라운드 트루스 마스크로 학습된 모델과 동등한 성능을 보이며, 비용 효율적인 대규모 데이터셋 구축이 가능함을 입증했습니다.
- **광범위한 적용성 및 일반화:** 다양한 데이터셋 및 보이지 않는(Unseen) 카테고리에도 잘 일반화됨을 입증했습니다.
- **코드 및 모델 공개:** 모든 모델 및 코드를 공개하여 연구의 재현성 및 활용성을 높였습니다.

## 📎 Related Works

- **약한 감독 분할 (Weakly Supervised Segmentation):**
  - 이미지 레벨 레이블 [27], 노이즈 있는 웹 레이블 [1, 16], 스크리블 레벨 레이블 [20] 등 픽셀 단위 주석의 대안으로 연구되었습니다.
  - 단일 클릭 지점 [3] 또는 가상 바운딩 박스의 중앙 지점 [26]을 활용한 지점 레벨 감독이 있습니다.
  - 바운딩 박스 감독 [7, 17]을 통한 의미론적 분할 훈련도 있습니다.
  - **Papadopoulos et al. [25]:** 극점 클릭이 바운딩 박스보다 추가 정보를 제공하여 GrabCut과 유사한 객체 분할을 향상시킴을 보여주었습니다 (본 연구와 가장 직접적인 연관).
- **인스턴스 분할 (Instance Segmentation):**
  - 자동으로 분할된 객체 제안(Object Proposal) [14, 31] 형태의 그룹화 방법이 있습니다.
  - 바운딩 박스와 같은 약한 안내 신호 [33]를 통한 인스턴스 레벨 분할도 있습니다.
  - 딥 아키텍처를 사용하여 클래스 불가지론적(Class-agnostic) 마스크를 학습하는 방법 [29, 30, 41]이 있으며, 본 연구는 극점 클릭 정보를 활용하여 더 높은 정확도를 달성합니다.
- **지점 기반 상호작용 분할 (Interactive Segmentation from points):**
  - 주석 시간 단축을 위한 방법론으로, 사용자가 데이터를 점진적으로 개선합니다.
  - **GrabCut [33]:** 바운딩 박스를 통해 점진적으로 외관 모델을 업데이트하며 분할하는 초기 연구입니다.
  - **Click Carving [15]:** 사용자 정의 클릭으로 비디오 객체 분할 결과를 상호작용적으로 업데이트합니다.
  - **iFCN [42] 및 RIS-Net [10]:** 긍정적/부정적 지점으로 CNN을 안내하거나 지역적 맥락을 추가합니다. 본 연구는 4개의 극점을 사용하여 이들보다 크게 개선된 결과를 달성합니다.

## 🛠️ Methodology

- **극점 기반 입력 채널 생성:**
  - 입력 이미지의 RGB 채널에 추가 채널을 더하여 CNN에 입력합니다.
  - 이 추가 채널은 각 극점을 중심으로 하는 2D 가우시안(Gaussian)을 포함하는 히트맵(heatmap) 형태입니다.
- **입력 이미지 전처리:**
  - 극점 주석으로 형성된 바운딩 박스를 기준으로 이미지를 자름(crop)으로써 관심 객체에 초점을 맞춥니다.
  - 맥락(context) 정보를 포함하기 위해 바운딩 박스에 몇 픽셀의 여백(margin)을 두어 스케일 변화를 제거하고 성능을 향상시킵니다.
- **CNN 아키텍처:**
  - **백본(Backbone):** ResNet-101 [13]을 사용합니다. 밀집 예측(Dense Prediction)을 위해 마지막 완전 연결 계층(Fully Connected Layers)과 마지막 두 개의 맥스 풀링 계층(Max Pooling Layers)을 제거합니다.
  - **Atrous Convolutions:** 마지막 두 단계에 Atrous Convolutions를 도입하여 동일한 수용 필드(Receptive Field)를 유지하면서 출력 해상도를 보존합니다.
  - **전역 맥락 모듈 (Global Context Module):** ResNet-101 마지막 단계 후 Pyramid Scene Parsing (PSP) 모듈 [43]을 도입하여 최종 특징 맵에 전역 맥락을 통합합니다.
  - **사전 학습 (Pre-training):** ImageNet에서 사전 학습된 Deeplab-v2 [6] 모델의 가중치를 사용하여 초기화합니다.
- **손실 함수 (Loss Function):**
  - 표준 교차 엔트로피 손실(Cross Entropy Loss) $L = \sum_{j \in Y} w_{y_j} C(y_j, \hat{y}_j)$를 최소화하도록 훈련합니다.
  - $w_{y_j}$는 픽셀 $j$의 레이블 $y_j \in \{0,1\}$에 따라 미니배치 내 레이블의 역정규화 빈도(inverse normalized frequency)로 정의됩니다.
  - 클래스 불균형 문제를 해결하기 위해 클래스 균형 손실(Class-balanced Loss)을 사용하며, 이는 배경 클래스에 비해 샘플 수가 적은 전경(foreground)에 더 중요성을 부여하여 경계 감지(Boundary Detection) 성능을 향상시킵니다.
- **훈련 및 테스트:**
  - PASCAL 2012 Segmentation 또는 COCO 2014 훈련 세트에서 훈련합니다.
  - 테스트는 빠르며, 약 80ms 소요됩니다.
- **시뮬레이션된 극점 (Simulated Extreme Points):** 사람 주석이 어려운 데이터셋(COCO)의 경우, 그라운드 트루스 마스크의 극점에 최대 10픽셀까지 무작위로 지터링(Jittering)하여 시뮬레이션된 극점을 생성하여 사용합니다.

## 📊 Results

- **클래스 불가지론적 인스턴스 분할 (Class-agnostic Instance Segmentation):**
  - **PASCAL 데이터셋:** DEXTR은 80.1% IoU를 달성하여 극점 기반 [25] (73.6%) 및 SharpMask [30]의 최상위 제안보다 우수한 성능을 보였습니다.
  - **Grabcut 데이터셋:** DEXTR은 2.3%의 오류율로 이전 최첨단(DeepGC [41] 3.4%) 대비 획기적인 개선(32% 상대적 향상)을 이루었습니다.
- **일반화 능력 (Generalization Capabilities):**
  - **미등록 카테고리:** PASCAL에서 훈련된 모델이 COCO mini-val의 미등록 카테고리에서 기존 카테고리와 유사한 성능(IoU 약 80%)을 보이며, 클래스 불가지론적 특성을 입증했습니다.
  - **데이터셋 간 일반화:** 훈련 데이터셋과 다른 데이터셋에서 테스트 시 성능 저하가 약 2%에 불과하여 우수한 일반화 능력을 입증했습니다.
  - **배경 (Stuff) 카테고리:** PASCAL Context의 배경 클래스(도로, 하늘, 건물 등)에 대해서도 81.75% mIoU를 달성하며 잘 일반화됨을 보여주었습니다.
- **주석 (Annotation):**
  - 마스크 생성에 필요한 주석 비용을 최대 10배 절감했습니다 (기존 79초/인스턴스 → DEXTR 7.2초/인스턴스).
  - DEXTR이 생성한 마스크로 훈련된 의미론적 분할 알고리즘은 동일 예산에서 그라운드 트루스 마스크로 훈련된 경우보다 훨씬 우수한 성능을 보이며, 동일한 이미지 수에서 그라운드 트루스와 거의 동등한 품질을 달성했습니다 (예: 7분 주석 시간으로 70% IoU 달성, GT는 동일 시간에서 46%).
- **비디오 객체 분할 (Video Object Segmentation):**
  - DAVIS 2016에서 OSVOS [5]를 DEXTR 마스크로 훈련 시, 그라운드 트루스 마스크 하나로 얻는 성능을 5배 적은 주석 예산으로 달성했습니다.
  - DAVIS 2017에서는 성능 격차가 더욱 줄어들어, 비디오 객체 분할 주석 시간 단축에도 매우 효율적임을 입증했습니다.
- **상호작용 객체 분할 (Interactive Object Segmentation):**
  - 사용자 추가 클릭(5번째 점)을 통해 부정확하게 분할된 어려운 경우(IoU < 0.8)의 성능을 +4.2% 향상시킬 수 있음을 보였습니다.
  - 4개의 클릭만으로 기존 최첨단 상호작용 분할 방법론 대비 10% 이상 높은 성능을 달성했습니다 (PASCAL 91.5%, Grabcut 94.4%).

## 🧠 Insights & Discussion

- **극점 정보의 가치:** 극점은 객체 분할에 매우 귀중한 안내 정보를 제공하며, 바운딩 박스 입력에 비해 +3.1%의 상당한 성능 향상을 가져왔습니다. 또한, 사용자가 바운딩 박스보다 극점을 제공하는 것이 인지적으로 효율적임이 확인되었습니다.
- **체계적인 설계의 효과:** Ablation Study를 통해 CNN 아키텍처, 손실 함수, 입력 전처리 등 각 구성 요소의 설계 선택이 효과적임이 검증되었습니다. 특히 객체 중심의 이미지 자르기(cropping)는 스케일 변화를 제거하여 +7.9%의 큰 성능 향상을 가져왔으며, PSP 모듈은 전역 맥락 통합을 통해 +2.3%의 이점을 제공했습니다.
- **주석 프로세스 혁신:** DEXTR은 정확하면서도 매우 효율적인 마스크 주석 도구로 활용될 수 있음을 입증했으며, 이는 대규모 주석 데이터셋 구축의 비용 장벽을 낮출 수 있습니다.
- **강력한 일반화 능력:** 이 방법은 학습되지 않은 카테고리나 다른 데이터셋에도 잘 작동하며, 심지어 "배경" 클래스(예: 도로, 하늘)까지도 성공적으로 분할하는 등 강력한 일반화 능력을 보여주었습니다.
- **상호작용적 개선 가능성:** 초기 극점 클릭으로 만족스럽지 않은 경우, 추가적인 사용자 클릭을 통해 분할 정확도를 높일 수 있어, 실제 상호작용 분할 도구로서의 잠재력을 높입니다. 특히, Online Hard Example Mining (OHEM)과 결합하여 어려운 예제에 집중함으로써 성능을 효과적으로 개선했습니다.
- **제한 사항:** DAVIS 2016 데이터셋의 일부 마스크가 여러 인스턴스를 포함할 때 DEXTR이 전역 극점 세트로 혼란을 겪을 수 있다는 한계점이 언급되었으나, DAVIS 2017과 같이 단일 인스턴스 중심의 데이터셋에서는 이 문제가 적게 발생했습니다.

## 📌 TL;DR

- **문제:** 기존 객체 분할 방법은 높은 주석 비용과 사용자 입력의 비효율성(바운딩 박스 등)으로 인해 한계가 있었습니다.
- **제안 방법:** **DEXTR (Deep Extreme Cut)**은 CNN(ResNet-101 백본 + PSP 모듈)을 사용하여, 사용자가 지정한 객체의 네 극점(가장 왼쪽, 오른쪽, 위쪽, 아래쪽) 정보를 가우시안 히트맵 형태로 RGB 이미지에 추가 채널로 입력받아 정확한 분할 마스크를 생성합니다.
- **주요 성과:** DEXTR은 단 4번의 극점 클릭만으로도 클래스 불가지론적 인스턴스 분할, 상호작용 분할, 비디오 객체 분할에서 최첨단 정확도를 달성했습니다. 또한, 마스크 주석 비용을 최대 10배 절감하여 고품질 훈련 데이터를 효율적으로 생성할 수 있음을 입증했으며, 이는 객체 분할 작업을 위한 사용자 상호작용의 효율성과 주석 프로세스를 혁신적으로 개선했습니다.
