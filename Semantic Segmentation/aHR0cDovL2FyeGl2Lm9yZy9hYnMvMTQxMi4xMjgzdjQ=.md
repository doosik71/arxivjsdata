# Convolutional Feature Masking for Joint Object and Stuff Segmentation
Jifeng Dai, Kaiming He, Jian Sun

## 🧩 해결하고자 하는 문제
기존 R-CNN 기반의 의미론적 분할(semantic segmentation) 방법론(예: SDS)은 마스킹된 이미지 영역에서 CNN 특징을 추출합니다. 이 방식은 두 가지 주요 문제를 가지고 있습니다.
1.  **인위적인 경계 생성**: 원본 이미지에 마스크를 적용하면 네트워크 사전 학습(예: ImageNet) 시 존재하지 않던 인위적인 경계가 생성되어 추출된 특징의 품질을 저하시킬 수 있습니다.
2.  **비효율적인 계산**: 단일 이미지에 대해 수천 개의 네트워크를 적용해야 하므로 계산 시간이 매우 오래 걸립니다.

본 논문은 객체 감지(object detection)에서 SPP-Net이 전체 이미지에 대한 특징 맵을 한 번만 계산하여 효율성을 높인 것처럼, 의미론적 분할에서도 특징 맵만을 활용하여 이 문제들을 해결할 수 있는지 질문하고 답하고자 합니다.

## ✨ 주요 기여
*   **합성곱 특징 마스킹(Convolutional Feature Masking, CFM) 제안**: 원본 이미지 대신 합성곱 특징 맵(convolutional feature maps)에서 직접 세그먼트 특징을 마스킹하여 추출하는 새로운 방법을 제안합니다. 이를 통해 인위적인 경계 문제와 비효율적인 계산 문제를 동시에 해결합니다.
*   **객체(Object) 및 스터프(Stuff) 동시 분할 프레임워크**: 객체(예: 개, 의자)와 스터프(예: 하늘, 잔디, 물)를 동일한 프레임워크 내에서 처리할 수 있는 통합된 방법을 제시합니다. 스터프를 여러 세그먼트 제안의 조합으로 표현하고, "세그먼트 추적(segment pursuit)" 절차를 통해 이를 최적화합니다.
*   **최고 수준 성능 달성**: PASCAL VOC 2012 객체 분할 벤치마크 및 새롭게 레이블링된 PASCAL-CONTEXT 객체 및 스터프 분할 벤치마크에서 이전의 최고 수준 결과(state-of-the-art)를 능가하는 성능을 달성했습니다.
*   **획기적인 계산 속도 향상**: 기존 SDS 방법보다 약 $150 \times$ 더 빠른 계산 속도를 보여주며, 실시간 적용 가능성을 높였습니다.

## 📎 관련 연구
*   **R-CNN [8, 10]**: 의미론적 분할을 위해 바운딩 박스 또는 마스킹된 원본 이미지 영역에서 CNN 특징을 추출하는 방법론. 본 연구의 개선 대상이 됩니다.
*   **SPP-Net [11]**: 전체 이미지에서 합성곱 특징 맵을 한 번만 계산하고 공간 피라미드 풀링(spatial pyramid pooling)을 통해 잘린 특징(cropped features)을 형성하는 객체 감지 방법. 본 연구의 CFM 아이디어에 영감을 주었습니다.
*   **SDS (Simultaneous Detection and Segmentation) [10]**: 의미론적 분할 분야의 이전 최고 수준 방법론으로, 본 연구의 성능 및 속도 비교 대상이 됩니다.
*   **FCN (Fully Convolutional Networks) [16]**: 본 연구와 동시에 제안된 의미론적 분할 방법으로, 빠른 속도와 유사한 픽셀 단위 분할 정확도를 보이지만 인스턴스별 결과는 생성할 수 없습니다.
*   **SuperParsing [21], O$_2$P [4]**: CNN 기반이 아닌 의미론적 분할의 주요 방법론들.

## 🛠️ 방법론
본 논문은 합성곱 특징 마스킹(CFM)을 핵심으로 하여 의미론적 분할을 수행하며, 객체와 스터프를 통합 처리하는 방법을 제안합니다.

1.  **합성곱 특징 마스킹(CFM) 계층**:
    *   **세그먼트 제안 생성**: Selective Search [22] 또는 MCG [1]와 같은 영역 제안(region proposal) 방법으로 원본 이미지에서 슈퍼픽셀 기반의 후보 세그먼트들을 얻습니다.
    *   **마스크 투영**: 이러한 이진(binary) 마스크를 원본 이미지 도메인에서 최종 합성곱 특징 맵 도메인으로 투영합니다. 각 특징 맵 활성화(activation)는 이미지 도메인의 수용장(receptive field)에 해당하므로, 수용장의 중심을 이미지에 투영하고, 이진 마스크의 각 픽셀을 가장 가까운 수용장 중심에 할당합니다. 이후 이 픽셀들을 다시 특징 맵 도메인의 활성화 위치로 투영합니다.
    *   **특징 맵 마스크 생성**: 특징 맵의 각 위치에 투영된 여러 픽셀의 이진 값을 평균하고 $0.5$를 기준으로 이진화하여 특징 맵에 적용할 마스크를 생성합니다.
    *   **세그먼트 특징 추출**: 이 이진 마스크를 합성곱 특징 맵의 각 채널에 곱하여 "세그먼트 특징"을 얻습니다. 이 과정은 특징 맵이 원본 이미지를 마스킹하지 않고 계산되므로 특징의 품질이 저하되지 않습니다.

2.  **네트워크 설계**:
    *   **Design A (최종 합성곱 계층에서)**: `conv5` 이후에 SPP 계층을 통해 영역 특징(regional feature)을 생성하고, CFM 계층을 통해 세그먼트 특징을 생성합니다. 두 특징 모두 별도의 FC 계층을 거친 후 연결되어 분류기에 입력됩니다.
    *   **Design B (공간 피라미드 풀링 계층에서)**: SPP 계층을 먼저 적용하여 특징을 풀링합니다. SPP 계층의 가장 미세한 특징 맵(`6 \times 6` 레벨)에 CFM 계층을 적용하여 세그먼트 특징을 생성합니다. 이 세그먼트 특징은 다른 SPP 레벨(`3 \times 3, 2 \times 2, 1 \times 1`)과 연결되어 단일 FC 계층 경로에 입력됩니다. 계산 비용 및 과적합(overfitting) 위험을 줄이기 위해 Design B가 선호됩니다.

3.  **학습 및 추론**:
    *   **학습**: 먼저 SPP-Net [11] 방식을 사용하여 객체 감지를 위해 네트워크를 미세 조정(finetune)합니다. 그 다음 Design A 또는 B 구조로 전환하여 분할을 위해 추가 미세 조정을 수행합니다.
        *   긍정 샘플: 접합부 대 교차(IoU) 점수 기준 $0.5$에서 $1$ 사이의 지상 진실(ground-truth) 전경 세그먼트와 겹치는 세그먼트 제안.
        *   부정 샘플: IoU 점수 기준 $0.1$에서 $0.3$ 사이의 세그먼트 제안.
        *   네트워크 출력에 대해 각 범주별로 선형 SVM 분류기를 학습합니다.
    *   **추론**: 각 영역 제안의 특징을 추출하고, SVM 분류기를 사용하여 점수를 매긴 후, SDS [10]의 붙여넣기(pasting) 방식을 사용하여 픽셀 수준의 범주 레이블을 얻습니다.

4.  **객체 및 스터프 동시 분할**:
    *   **스터프 표현**: 스터프는 여러 세그먼트 제안의 "압축된 조합(compact combination)"으로 처리됩니다.
    *   **순도 점수(Purity Score)**: 세그먼트 제안과 해당 바운딩 박스 내 스터프 부분 간의 IoU 비율로 정의됩니다.
    *   **세그먼트 추적(Segment Pursuit)**:
        *   **후보 세트 생성**: 순도 점수가 $0.6$을 초과하는 세그먼트 제안들로 구성됩니다.
        *   **결정론적 추적(Deterministic Segment Pursuit)**: 후보 세트에서 가장 큰 세그먼트 제안을 순차적으로 선택하고, IoU $0.2$ 이상의 겹치는 제안을 억제합니다. SVM 학습에 사용됩니다.
        *   **확률적 추적(Stochastic Segment Pursuit)**: 미세 조정을 위해 매 단계에서 세그먼트 면적에 비례하는 확률로 후보 세트에서 무작위로 세그먼트를 샘플링하고 겹침을 억제합니다. 이를 통해 다양한 "압축된 조합"의 긍정 샘플을 생성합니다.
    *   **학습 균형**: 미니 배치(mini-batch)에서 객체($30\%$), 스터프($30\%$), 배경($40\%$) 샘플 비율을 맞춰 다양한 범주의 학습을 균형 있게 조절합니다.

## 📊 결과
*   **객체 분할 (PASCAL VOC 2012 테스트 세트, 평균 IoU)**:
    *   SDS (AlexNet + MCG): $51.6\%$
    *   CFM (ZF + MCG): $55.4\%$ (SDS 대비 $3.8\%$p 향상)
    *   CFM (VGG + MCG): $61.8\%$ (새로운 최고 수준 결과)
*   **속도 (GPU 이미지당 특징 추출 시간)**:
    *   SDS (AlexNet): $17.9$초
    *   CFM (ZF, 5 scale): $0.38$초 (SDS 대비 약 $47 \times$ 빠름)
    *   CFM (ZF, 1 scale): $0.12$초 (SDS 대비 약 $150 \times$ 빠름)
*   **동시 감지 및 분할 (PASCAL VOC 2012 검증 세트, 평균 AP$_r$)**:
    *   SDS (AlexNet + MCG): $49.7$
    *   CFM (ZF + MCG): $53.2$
    *   CFM (VGG + MCG): $60.7$ (새로운 최고 수준 결과, FCN은 이 측정 기준에 적용 불가)
*   **객체 및 스터프 동시 분할 (PASCAL-CONTEXT 검증 세트, 60개 범주 평균 IoU)**:
    *   O$_2$P (비-CNN 기반): $18.1$
    *   CFM w/o Segment Pursuit (ZF + SS): $24.0$ (CFM 계층의 효과)
    *   CFM (ZF + SS, Segment Pursuit 포함): $26.6$ (세그먼트 추적의 효과)
    *   CFM (VGG + MCG): $34.4$ (더 깊은 모델 및 정확한 제안의 이점)

## 🧠 통찰 및 논의
*   **CFM의 효율성**: 합성곱 특징 맵에 직접 마스킹을 적용함으로써, 원본 이미지 마스킹으로 인한 인위적 경계 문제를 해결하고, 특징 맵을 한 번만 계산하여 기존 R-CNN 기반 방식의 주요 병목 현상이었던 계산 속도를 획기적으로 개선했습니다.
*   **깊은 모델의 영향**: VGG-16과 같은 더 깊은 사전 학습된 모델을 사용했을 때 성능이 크게 향상되는 것을 확인하여, CFM 방법이 더 풍부한 특징 표현력을 가진 모델로부터 이점을 얻음을 입증했습니다.
*   **세그먼트 제안의 중요성**: MCG와 같은 더 정확한 세그먼트 제안 알고리즘을 사용할 때 정확도가 높아져, 제안 품질이 최종 결과에 큰 영향을 미침을 보여줍니다.
*   **객체-스터프 통합 처리**: "세그먼트 추적"을 통해 스터프 영역을 효율적으로 포괄하는 샘플을 생성하고, 객체와 스터프를 단일 프레임워크 내에서 효과적으로 처리할 수 있음을 증명했습니다.
*   **제한 및 비교**: FCN과 비교 시, FCN은 픽셀 단위 의미론적 분할에서는 유사한 성능과 빠른 속도를 보이나, 인스턴스별 객체 분할은 지원하지 않습니다. 반면 CFM은 인스턴스 분할도 가능하여 더 폭넓은 적용 가능성을 가집니다.
*   **향후 연구**: CFM을 객체 감지 성능 향상에 적용하고, 객체 및 스터프 동시 분할을 통해 얻은 문맥 정보(context information)를 활용하는 방안을 모색할 계획입니다.

## 📌 TL;DR
**문제**: 기존 R-CNN 기반 의미론적 분할은 원본 이미지 마스킹으로 인해 특징 품질 저하 및 비효율적인 계산 문제가 있었습니다.
**방법**: 본 논문은 **합성곱 특징 마스킹(CFM)**을 제안하여, 원본 이미지 대신 합성곱 특징 맵에서 직접 세그먼트 특징을 추출합니다. 또한, "세그먼트 추적" 절차를 통해 **객체와 스터프를 통합적으로 분할**하는 방법을 제시합니다.
**결과**: CFM은 PASCAL VOC 및 PASCAL-CONTEXT 벤치마크에서 **최고 수준의 분할 정확도**를 달성했으며, 기존 방법(SDS) 대비 **최대 $150 \times$ 빠른 속도**를 보여주었습니다.