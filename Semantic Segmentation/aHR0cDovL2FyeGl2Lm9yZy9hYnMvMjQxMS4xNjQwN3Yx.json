{
  "url": "http://arxiv.org/abs/2411.16407v1",
  "title": "A Study on Unsupervised Domain Adaptation for Semantic Segmentation in\n  the Era of Vision-Language Models",
  "authors": "Manuel Schwonberg, Claus Werner, Hanno Gottschalk, Carsten Meyer",
  "year": 2024,
  "abstract": "Despite the recent progress in deep learning based computer vision, domain\nshifts are still one of the major challenges. Semantic segmentation for\nautonomous driving faces a wide range of domain shifts, e.g. caused by changing\nweather conditions, new geolocations and the frequent use of synthetic data in\nmodel training. Unsupervised domain adaptation (UDA) methods have emerged which\nadapt a model to a new target domain by only using unlabeled data of that\ndomain. The variety of UDA methods is large but all of them use ImageNet\npre-trained models. Recently, vision-language models have demonstrated strong\ngeneralization capabilities which may facilitate domain adaptation. We show\nthat simply replacing the encoder of existing UDA methods like DACS by a\nvision-language pre-trained encoder can result in significant performance\nimprovements of up to 10.0% mIoU on the GTA5-to-Cityscapes domain shift. For\nthe generalization performance to unseen domains, the newly employed\nvision-language pre-trained encoder provides a gain of up to 13.7% mIoU across\nthree unseen datasets. However, we find that not all UDA methods can be easily\npaired with the new encoder and that the UDA performance does not always\nlikewise transfer into generalization performance. Finally, we perform our\nexperiments on an adverse weather condition domain shift to further verify our\nfindings on a pure real-to-real domain shift."
}