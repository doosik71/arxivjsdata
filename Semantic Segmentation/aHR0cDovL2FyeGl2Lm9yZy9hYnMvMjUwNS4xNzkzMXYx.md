# AutoMiSeg: Automatic Medical Image Segmentation via Test-Time Adaptation of Foundation Models

Xingjian Li, Qifeng Wu, Colleen Que, Yiran Ding, Adithya S. Ubaradka, Jianhua Xing, Tianyang Wang, Min Xu

## 🧩 Problem to Solve

의료 영상 분할은 진단 및 치료 계획에 필수적이지만, 기존 딥러닝 방식은 대규모 훈련 데이터에 대한 전문가의 광범위한 주석 작업이나 추론 시 각 사례에 대한 프롬프트 제공을 요구합니다. 이는 시간과 비용이 많이 들고 확장성이 떨어집니다. Segment Anything Model (SAM)과 같은 파운데이션 모델이 등장했지만, 여전히 추론 시 전문가의 상호 작용(예: 포인트 또는 바운딩 박스 프롬프트)이 필요하며, 의료 영상의 다양한 양상, 낮은 대비, 미묘한 해부학적 경계로 인해 성능이 일관되지 않을 수 있습니다. 본 논문은 제로샷(zero-shot) 및 주석이 필요 없는(annotation-free) 자동 의료 영상 분할 패러다임을 실현하기 위해, 단일 모델로 복잡한 의료 영상 분할을 효과적으로 달성하기 어렵다는 점과 일반 목적 파운데이션 모델이 의료 영상의 도메인 특성과 차이를 보인다는 문제를 해결하고자 합니다.

## ✨ Key Contributions

* **완전 자동 제로샷 파이프라인 제안:** 수동 주석이나 추론 시 상호 작용이 필요 없는 `AutoMiSeg`라는 완전 자동 제로샷 의료 영상 분할 파이프라인을 제안합니다.
* **모듈식 작업 분해:** 복잡한 분할 작업을 접지(grounding), 프롬프트 부스팅(prompt boosting), 프롬프트 기반 분할(promptable segmentation)의 모듈식 단계로 분해하여 견고하고 적응 가능한 파이프라인을 구축합니다.
* **테스트-타임 적응(TTA) 프레임워크 도입:** 의료 영상 입력을 파운데이션 모델의 표현과 정렬시키기 위한 학습 가능한 테스트-타임 어댑터(Learnable Test-time Adaptors, LTA) 세트를 포함하는 새로운 테스트-타임 적응 프레임워크를 제시합니다.
* **프록시 유효성 검사기 기반 베이지안 최적화:** 접지 진리(ground-truth) 레이블 없이 대리 유효성 검사 모델(proxy validation model)의 피드백을 활용하여 LTA 하이퍼파라미터를 베이지안 최적화(Bayesian Optimization)를 통해 최적화합니다.
* **다양한 데이터셋에서의 성능 입증:** 7가지 다양한 의료 영상 데이터셋에 대한 평가를 통해, 본 파이프라인이 약한 프롬프트(weak-prompt)를 사용하는 상호 작용 파운데이션 모델과 경쟁력 있는 성능을 보여줌으로써 새로운 자동 분할 패러다임의 잠재력을 입증합니다.

## 📎 Related Works

* **딥러닝 기반 의료 영상 분할:** U-Net과 같은 아키텍처가 지배적이지만, 수작업 주석 데이터셋에 대한 의존성이 병목 현상으로 작용합니다. 본 연구는 훈련 없이 텍스트 프롬프트와 사전 훈련된 파운데이션 모델을 활용합니다.
* **주석 의존성 감소 노력:** 적은 수의 레이블된 예제로 일반화하는 소수샷 학습(few-shot learning), 이미지 수준 레이블을 사용하는 약지도 학습(weakly-supervised learning), 훈련 중 보지 못한 클래스를 분할하는 제로샷 학습(zero-shot learning) 등이 있습니다. 본 연구는 파운데이션 모델의 인상적인 일반화 능력을 활용하는 '훈련 없는(training-free)' 접근 방식에 속합니다.
* **분할을 위한 프롬프트 기반 파운데이션 모델:** SAM [15]은 상호 작용 및 제로샷 분할에서 중요한 진전을 이루었습니다. MedSAM [22] 및 SAM-Med2D [6]는 의료 데이터에 SAM을 미세 조정하여 개선했습니다. 자동 프롬프트 생성에 대한 연구도 있지만, 대부분 시각 전용 메커니즘에 의존하거나 프롬프트 생성기 자체에 감독 구성 요소를 포함합니다. 본 연구는 주석이 필요 없는 다중 모달 프롬프트 생성을 목표로 합니다.
* **구성적 AI 및 모델 오케스트레이션:** 제안된 파이프라인은 텍스트-투-박스(text-to-box), 프롬프트 증강(prompt augmentation), 프롬프트-투-마스크(prompt-to-mask)와 같은 특수화된 사전 훈련 모듈을 조립하는 구성적 접근 방식을 사용합니다. 이는 파운데이션 모델을 구성 요소로 활용하는 광범위한 개념과 일치합니다.
* **테스트-타임 적응 (TTA):** TTA는 재훈련이나 소스 데이터 접근 없이 배포 중 도메인 이동에 대한 모델 견고성을 강화합니다. TENT [44]와 같이 예측 엔트로피를 최소화하거나 TTT [39]와 같이 자기 지도 학습 목표를 활용합니다. 본 연구는 파운데이션 모델을 기반으로 하는 복잡한 다단계 훈련 없는 파이프라인 내의 TTA 전략을 탐색합니다.

## 🛠️ Methodology

`AutoMiSeg` 파이프라인은 텍스트 기반 의료 영상 분할을 위한 훈련 또는 미세 조정이 필요 없는 완전 자동 접근 방식을 제안합니다.

1. **파이프라인 개요:**
    * 입력: 의료 영상 $I \in \mathbb{R}^{H \times W \times C}$ 및 구조화된 작업 설명 $T = \{T_{\text{target}}, T_{\text{whole}}\}$ (예: "optic disc" 및 "eye fundus image").
    * 출력: 작업 설명과 일치하는 이진 분할 마스크 $M \in \mathbb{R}^{H \times W}$.
    * 모듈: 접지 모듈 (grounding module) $\rightarrow$ 시각 프롬프트 부스팅 모듈 (visual prompt boosting module) $\rightarrow$ 프롬프트 기반 분할 모듈 (promptable segmentation module).
    * 추가 구성 요소: 출력 품질을 평가하는 프록시 유효성 검사기 (proxy validator)와 일반 사전 훈련 모델을 의료 영상 도메인에 적응시키는 학습 가능한 테스트-타임 어댑터 (Learnable Test-time Adaptors, LTA).

2. **타겟 영역 접지 (Target Area Grounding):**
    * 사전 훈련된 시각-언어 모델 (VLM, 예: CogVLM [47])을 사용하여 텍스트 질의 $T$에 지정된 영역을 초기화합니다.
    * LLM (예: ChatGPT-4o [25])을 통해 작업 정의 $T_{\text{target}}, T_{\text{whole}}$에서 대상의 시각적 특징을 설명하는 프롬프트 문장 $S_G$를 생성합니다.
    * 변환된 이미지 $I_G$와 $S_G$를 접지 모델 $M_{\text{grd}}(I_G, S_G)$에 입력하여 대략적인 타겟 영역을 나타내는 바운딩 박스 $B=(x_{\min}, y_{\min}, x_{\max}, y_{\max})$를 예측합니다.

3. **시각 프롬프트 부스팅 (Visual Prompt Boosting):**
    * 초기 바운딩 박스 $B$를 개선하기 위해, DINOv2 [26]와 같은 사전 훈련된 비전 파운데이션 모델의 강력한 의미론적 특징 표현을 활용합니다.
    * $B$의 기하학적 중심을 앵커 포인트 $p_a$로 설정하고, 해당 DINOv2 특징 벡터 $f_a$를 추출합니다.
    * $B$ 내에서 $f_a$와 가장 높은 코사인 유사도를 보이는 상위 $k$개의 포인트 $P_k$ (예: $k=10$)를 식별합니다.
    * $P_k$의 공간 좌표를 K-평균 알고리즘을 사용하여 $n$개의 그룹 (예: $n=3$)으로 클러스터링합니다. 이 $n$개 클러스터의 중심이 최종 긍정 포인트 프롬프트 세트 $P_c$를 구성합니다.
    * $P_c$는 원래 바운딩 박스 $B$와 함께 프롬프트 기반 분할 모델에 사용됩니다.

4. **프롬프트 기반 분할 (Promptable Segmentation):**
    * 접지 모듈에서 얻은 $B$와 시각 프롬프트 부스팅 모듈에서 생성된 증강된 포인트 세트 $P_c$를 사용하여 사전 훈련된 프롬프트 기반 분할 모델 $M_{\text{seg}}$ (예: SAM [15])을 사용합니다.
    * $M = M_{\text{seg}}(I, B, P_c)$를 통해 훈련이나 미세 조정 없이 프롬프트된 객체에 해당하는 분할 마스크 $M$을 생성합니다.

5. **학습 가능한 테스트-타임 어댑터 (Learnable Test-time Adaptors, LTAs):**
    * 의료 영상과 일반적인 사전 훈련 비전 모델 간의 도메인 격차를 줄이기 위해 사용됩니다.
    * 조정 가능한 변수 유형:
        * **도메인 적응 이미지 변환 (Domain-adapted Image Transformation):** HSV shift, Channel-wise RGB shift, CLAHE [58], unsharp masking. 각 변환은 접지 및 분할 모델의 입력에 대해 별도의 하이퍼파라미터로 적용됩니다.
        * **자동 프롬프트 강화 (Automatic Prompt Enhancement):** LLM이 생성한 후보 프롬프트 문장 중 가장 효과적인 프롬프트 선택, 프롬프트 부스팅 모듈에서 유사한 특징을 가진 포인트 수($k$)의 최적 값 결정.

6. **프록시 유효성 검사기 (Proxy Validator):**
    * $M_{\text{seg}}$가 생성한 분할 마스크 $M$의 품질을 추정합니다 (접지 진리 레이블 필요 없음).
    * **제로샷 분류를 통한 의사 평가:** 이미지 $I$와 후보 분할 마스크 $M$이 주어지면, 타겟 영역만 남긴 테스트 이미지 $I_{\text{test}} = I \odot (1-M)$를 생성합니다. LLM을 사용하여 작업 정보 $T_{\text{target}}, T_{\text{whole}}$를 포함하는 템플릿을 통해 대조 범주(contrastive categories) 목록 $\{T_{c_i}\}_{i=1}^m$을 생성합니다. 시각-언어 모델 $M_{\text{val}}$ (예: BioMedCLIP [56])을 사용하여 $I_{\text{test}}$에 대한 $T_{\text{target}}$의 확률 점수 $S_{\text{zc}}$를 계산합니다.
    * **이미지-텍스트 매칭을 통한 의사 평가:** LLM을 사용하여 기술적 프롬프트를 생성하고, $M_{\text{val}}$을 사용하여 $I_{\text{test}}$와 각 기술자 간의 유사성을 계산합니다. 평균 이미지-텍스트 매칭 점수 $S_{\text{mt}}$를 계산합니다.
    * 최종 유효성 검사 점수: $S_{\text{val}} = S_{\text{zc}} + S_{\text{mt}}$.

7. **테스트-타임 적응 최적화:**
    * 베이지안 최적화 (Tree-structured Parzen Estimator, TPE [3])를 사용하여 LTA 모듈에 사용된 하이퍼파라미터를 조정하여 프록시 유효성 검사기의 평가 점수를 최대화합니다.
    * 효율성과 효과의 균형을 위해, 테스트 세트의 하위 집합 ($N_s$ 예제, $N_t$ 시도)에서 최적 구성을 식별한 다음 전체 테스트 세트에 적용합니다.

## 📊 Results

* **데이터셋:** REFUGE [27], Kvasir [31], Busi [2], ISIC2016 [9], UWSkinCancer [43], Promise12 [21], Usforkidney [38] 등 7가지 다양한 의료 영상 데이터셋(안저 사진, 내시경, 초음파, 피부경, MRI 등)에서 평가되었습니다.
* **성능 비교:** `AutoMiSeg`는 사전 정의된 클래스에 대해 훈련된 지도 모델 및 다양한 유형의 프롬프트로 안내되는 상호 작용 파운데이션 모델(강한 프롬프트: 접지 진리 바운딩 박스; 약한 프롬프트: 단일 전경 픽셀)과 비교되었습니다.
* **주요 결과:**
  * 지도 모델과 강한 프롬프트 상호 작용 파운데이션 모델은 일관되게 높은 성능을 보였습니다 (예: MedSAM의 Dice 점수 93.24).
  * 약한 프롬프트 모델(SAM, SAM-Med2D)은 성능이 크게 저하되어, 대상 지역화의 중요성을 강조했습니다.
  * `AutoMiSeg`는 약한 프롬프트 상호 작용 파운데이션 모델과 경쟁력 있는 성능을 달성했습니다 (예: 평균 Dice 점수 71.53).
  * `AutoMiSeg`는 지도 모델이나 강한 프롬프트 파운데이션 모델의 성능 수준에는 미치지 못하지만, 수동 프롬프트나 주석 없이 자동 제로샷 분할 패러다임의 잠재력을 입증합니다.

## 🧠 Insights & Discussion

* **접지 모델의 역할:** 파이프라인에서 가장 중요한 구성 요소입니다. 접지 정확도를 위한 테스트-타임 이미지 변환은 전체 파이프라인의 신뢰성에 필수적입니다. 접지 모델에 최적의 변환을 적용하지 않으면 성능이 크게 저하됩니다 (예: Kvasir 데이터셋에서 Dice 점수가 74.80에서 25.94로 하락).
* **프록시 유효성 검사기의 성능:** 정규화된 유효성 검사 점수와 실제 Dice 점수 간에 강한 선형 관계가 관찰되었으며, 높은 피어슨 상관 계수를 통해 유효성 검사기가 모델 성능의 신뢰할 수 있는 대리 역할을 함이 확인되었습니다.
* **베이지안 최적화의 역학:** 최적화 과정에서 유효성 검사 및 실제 점수가 점진적으로 높은 성능 구성을 향해 이동하는 경향이 분명하게 나타났습니다 (그림 5 참조). 이는 최적화 프로세스의 효과를 검증합니다.
* **배치(Batch) vs. 샘플당(Per-sample) BO:** 테스트 샘플 배치에 대한 BO가 샘플당 BO보다 더 나은 성능을 보여주었습니다. 샘플당 BO는 각 개별 테스트 예제에 과적합되어 견고한 구성을 찾을 기회를 놓칠 수 있습니다.
* **한계점:**
  * 파이프라인이 접지 모델의 성능에 크게 의존합니다. 향후에는 보다 강력하고 견고한 (특히 의료 도메인에 특화된) 접지 모델을 활용하여 전체 성능을 향상시킬 계획입니다.
  * 현재 프레임워크는 이진 분할 작업에 특화되어 있습니다. 다중 클래스 또는 다중 인스턴스 분할은 각 대상을 순차적으로 프롬프트하는 방식으로 접근할 수 있지만, 프롬프트 중복 및 마스크 융합 시 잠재적 충돌과 같은 새로운 과제를 야기합니다.
* **함의:** 본 연구는 확장 가능한 의료 영상 분석을 위한 모듈식, 훈련 없는 파이프라인의 잠재력을 강조하며, 더 강력한 사전 훈련 모델을 통해 성능을 개선하고 더 복잡한 시나리오로 파이프라인을 확장하는 유망한 방향을 제시합니다.

## 📌 TL;DR

* **문제:** 기존 의료 영상 분할은 수동 주석이나 전문가 상호 작용이 필수적이어서 확장성이 떨어집니다.
* **제안 방법:** `AutoMiSeg`는 완전 자동, 제로샷 의료 영상 분할 파이프라인입니다. 이 방법은 상용 시각-언어 파운데이션 모델(영역 접지)과 분할 파운데이션 모델(마스크 생성)을 결합하고, 프롬프트 품질을 향상시키기 위한 시각 프롬프트 부스팅 모듈을 포함합니다. 핵심적으로, 접지 진리 레이블 없이 프록시 유효성 검사기에 의해 안내되는 베이지안 최적화를 통해 학습 가능한 테스트-타임 어댑터(LTA)를 사용하여 일반 모델과 의료 영상 간의 도메인 격차를 해소합니다.
* **주요 발견:** 7가지 다양한 의료 데이터셋에서 약한 프롬프트 기반의 상호 작용 파운데이션 모델과 경쟁력 있는 성능을 달성하여, 수동 개입 없이 확장 가능한 자동 의료 영상 분할 솔루션의 가능성을 입증합니다.
