{
  "url": "http://arxiv.org/abs/2210.09782v3",
  "title": "Decoupling Features in Hierarchical Propagation for Video Object\n  Segmentation",
  "authors": "Zongxin Yang, Yi Yang",
  "year": 2022,
  "abstract": "This paper focuses on developing a more effective method of hierarchical\npropagation for semi-supervised Video Object Segmentation (VOS). Based on\nvision transformers, the recently-developed Associating Objects with\nTransformers (AOT) approach introduces hierarchical propagation into VOS and\nhas shown promising results. The hierarchical propagation can gradually\npropagate information from past frames to the current frame and transfer the\ncurrent frame feature from object-agnostic to object-specific. However, the\nincrease of object-specific information will inevitably lead to the loss of\nobject-agnostic visual information in deep propagation layers. To solve such a\nproblem and further facilitate the learning of visual embeddings, this paper\nproposes a Decoupling Features in Hierarchical Propagation (DeAOT) approach.\nFirstly, DeAOT decouples the hierarchical propagation of object-agnostic and\nobject-specific embeddings by handling them in two independent branches.\nSecondly, to compensate for the additional computation from dual-branch\npropagation, we propose an efficient module for constructing hierarchical\npropagation, i.e., Gated Propagation Module, which is carefully designed with\nsingle-head attention. Extensive experiments show that DeAOT significantly\noutperforms AOT in both accuracy and efficiency. On YouTube-VOS, DeAOT can\nachieve 86.0% at 22.4fps and 82.0% at 53.4fps. Without test-time augmentations,\nwe achieve new state-of-the-art performance on four benchmarks, i.e.,\nYouTube-VOS (86.2%), DAVIS 2017 (86.2%), DAVIS 2016 (92.9%), and VOT 2020\n(0.622). Project page: https://github.com/z-x-yang/AOT.",
  "citation": 196
}