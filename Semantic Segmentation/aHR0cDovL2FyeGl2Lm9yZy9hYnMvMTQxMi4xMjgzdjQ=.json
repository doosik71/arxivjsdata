{
  "url": "http://arxiv.org/abs/1412.1283v4",
  "title": "Convolutional Feature Masking for Joint Object and Stuff Segmentation",
  "authors": "Jifeng Dai, Kaiming He, Jian Sun",
  "year": 2014,
  "abstract": "The topic of semantic segmentation has witnessed considerable progress due to\nthe powerful features learned by convolutional neural networks (CNNs). The\ncurrent leading approaches for semantic segmentation exploit shape information\nby extracting CNN features from masked image regions. This strategy introduces\nartificial boundaries on the images and may impact the quality of the extracted\nfeatures. Besides, the operations on the raw image domain require to compute\nthousands of networks on a single image, which is time-consuming. In this\npaper, we propose to exploit shape information via masking convolutional\nfeatures. The proposal segments (e.g., super-pixels) are treated as masks on\nthe convolutional feature maps. The CNN features of segments are directly\nmasked out from these maps and used to train classifiers for recognition. We\nfurther propose a joint method to handle objects and \"stuff\" (e.g., grass, sky,\nwater) in the same framework. State-of-the-art results are demonstrated on\nbenchmarks of PASCAL VOC and new PASCAL-CONTEXT, with a compelling\ncomputational speed."
}