{
  "url": "http://arxiv.org/abs/1910.05886v2",
  "title": "A New Local Transformation Module for Few-shot Segmentation",
  "authors": "Yuwei Yang, Fanman Meng, Hongliang Li, Qingbo Wu, Xiaolong Xu, Shuai Chen",
  "year": 2019,
  "abstract": "Few-shot segmentation segments object regions of new classes with a few of\nmanual annotations. Its key step is to establish the transformation module\nbetween support images (annotated images) and query images (unlabeled images),\nso that the segmentation cues of support images can guide the segmentation of\nquery images. The existing methods form transformation model based on global\ncues, which however ignores the local cues that are verified in this paper to\nbe very important for the transformation. This paper proposes a new\ntransformation module based on local cues, where the relationship of the local\nfeatures is used for transformation. To enhance the generalization performance\nof the network, the relationship matrix is calculated in a high-dimensional\nmetric embedding space based on cosine distance. In addition, to handle the\nchallenging mapping problem from the low-level local relationships to\nhigh-level semantic cues, we propose to apply generalized inverse matrix of the\nannotation matrix of support images to transform the relationship matrix\nlinearly, which is non-parametric and class-agnostic. The result by the matrix\ntransformation can be regarded as an attention map with high-level semantic\ncues, based on which a transformation module can be built simply.The proposed\ntransformation module is a general module that can be used to replace the\ntransformation module in the existing few-shot segmentation frameworks. We\nverify the effectiveness of the proposed method on Pascal VOC 2012 dataset. The\nvalue of mIoU achieves at 57.0% in 1-shot and 60.6% in 5-shot, which\noutperforms the state-of-the-art method by 1.6% and 3.5%, respectively."
}