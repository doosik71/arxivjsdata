{
  "url": "http://arxiv.org/abs/1711.09081v2",
  "title": "Deep Extreme Cut: From Extreme Points to Object Segmentation",
  "authors": "Kevis-Kokitsi Maninis, Sergi Caelles, Jordi Pont-Tuset, Luc Van Gool",
  "year": 2017,
  "abstract": "This paper explores the use of extreme points in an object (left-most,\nright-most, top, bottom pixels) as input to obtain precise object segmentation\nfor images and videos. We do so by adding an extra channel to the image in the\ninput of a convolutional neural network (CNN), which contains a Gaussian\ncentered in each of the extreme points. The CNN learns to transform this\ninformation into a segmentation of an object that matches those extreme points.\nWe demonstrate the usefulness of this approach for guided segmentation\n(grabcut-style), interactive segmentation, video object segmentation, and dense\nsegmentation annotation. We show that we obtain the most precise results to\ndate, also with less user input, in an extensive and varied selection of\nbenchmarks and datasets. All our models and code are publicly available on\nhttp://www.vision.ee.ethz.ch/~cvlsegmentation/dextr/."
}