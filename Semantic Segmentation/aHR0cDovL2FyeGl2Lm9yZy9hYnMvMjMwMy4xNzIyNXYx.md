# FreeSeg: Unified, Universal and Open-Vocabulary Image Segmentation

Jie Qin, Jie Wu, Pengxiang Yan, Ming Li, Ren Yuxi, Xuefeng Xiao, Yitong Wang, Rui Wang, Shilei Wen, Xin Pan, Xingang Wang

## 🧩 Problem to Solve

최근 개방형 어휘(open-vocabulary) 학습은 텍스트 설명을 기반으로 임의의 카테고리에 대한 이미지 분할을 가능하게 하여 시스템의 일반 목적 응용 시나리오를 확장하고 있습니다. 그러나 기존의 이미지 분할 방법들은 특정 분할 태스크에 특화된 아키텍처나 매개변수를 설계하는 데 집중하여, 이는 다양한 분할 태스크 간의 파편화를 초래하고 모델의 통일성을 저해합니다. 이러한 기존 방법들은 i) 태스크에 둔감하여(task-insensitive) 다양한 분할 태스크에 효과적으로 일반화되지 못하고, ii) 리소스 비친화적(resource-unfriendly)이어서 태스크를 전환할 때마다 모델을 처음부터 다시 훈련하고 여러 맞춤형 모델을 배포해야 하는 단점이 있습니다. 비록 MaskFormer와 같은 통합 시스템이 존재하지만, 이는 여전히 각 태스크에 맞는 맞춤형 모델을 훈련해야 하며 개방형 어휘 태스크를 위해 설계되지 않았습니다. 이 연구는 통합된 개방형 어휘 프레임워크를 통해 보편적인 분할 태스크를 수행하는 방법을 모색합니다.

## ✨ Key Contributions

* 컴퓨터 비전 분야에서 통합된(Unified), 보편적인(Universal), 개방형 어휘(Open-Vocabulary) 이미지 분할이라는 새로운 태스크에 도전하는 첫 시도입니다. 동일한 아키텍처와 추론 매개변수를 가진 단일(all-in-one) 모델인 FreeSeg를 제안하여 개방형 어휘 시맨틱, 인스턴스, 파놉틱 분할을 모두 수행합니다.
* 적응형 프롬프트 학습(Adaptive Prompt Learning)을 도입하여 다중 세분성 개념(태스크, 카테고리)을 압축된 텍스트 추상화로 명시적으로 인코딩하고, 이를 통해 통합 모델이 임의의 텍스트 설명에 일반화될 수 있도록 돕습니다.
* 크로스-모달 정렬(cross-modal alignment) 및 미학습(unseen) 클래스에 대한 일반화 능력을 향상시키기 위해 시맨틱 컨텍스트 상호작용(Semantic Context Interaction) 및 테스트 시 프롬프트 튜닝(Test Time Prompt Tuning) 메커니즘을 추가로 설계했습니다.
* COCO, ADE20K, VOC 2012 데이터셋에서 시맨틱, 인스턴스, 파놉틱 분할의 세 가지 이미지 분할 태스크에 대한 광범위한 실험을 통해 FreeSeg가 성능 및 일반화 측면에서 새로운 SOTA(State-of-the-Art) 결과를 달성했음을 입증했습니다. 이는 최상의 태스크-특정 아키텍처보다 미학습 COCO 클래스에 대해 시맨틱 분할에서 5.5% mIoU, 인스턴스 분할에서 17.6% mAP, 파놉틱 분할에서 20.1% PQ의 큰 폭으로 능가합니다.

## 📎 Related Works

* **개방형 어휘 분할 (Open Vocabulary Segmentation)**: 훈련 시 접근할 수 없는 타겟 카테고리를 분할하는 것을 목표로 합니다. 시각적 특징을 시맨틱 공간으로 매핑하는 방식(SPNet, ZS3Net, STRICT)과 CLIP과 같은 사전 학습된 모델과의 교차-모달 정렬을 활용하는 방식(LSeg, ZegFormer, ZSSeg, XPM, MaskCLIP)으로 나뉩니다.
* **보편적 분할 아키텍처 (Universal Segmentation Architecture)**: 동일한 아키텍처로 여러 분할 태스크(시맨틱, 인스턴스, 파놉틱)를 수행하는 것을 목표로 합니다(MaskFormer, K-Net, Mask2Former). 그러나 이들은 여전히 각 태스크에 대해 별도의 모델을 훈련해야 최상의 성능을 달성합니다.
* **프롬프트 학습 (Prompt Learning)**: NLP 분야에서 시작되어(LoRA, Prompt Tuning) 비전 또는 비전-언어 모델(CoOp, DenseCLIP)로 확장되었으며, 개방형 어휘 분할 태스크에서도 활용됩니다(ZegFormer, ZSSeg).

## 🛠️ Methodology

FreeSeg는 임의의 카테고리에 대해 시맨틱, 인스턴스, 파놉틱 분할 결과를 얻기 위해 단일 모델을 최적화하는 것을 목표로 하는 두 단계 프레임워크입니다.

1. **마스크 제안 추출기 (Mask Proposal Extractor)**:
    * 입력 이미지에서 보편적인(universe) 마스크 제안(class-agnostic masks $M \in R^{N \times H \times W}$)과 시각적 개념($F_v \in R^{N \times D}$)을 추출합니다. 이 단계는 Mask2Former를 기반으로 합니다.
    * 훈련 시에는 학습된 태스크들을 단일 모델에 캡슐화하기 위해 세 가지 태스크별 레이블(시맨틱 $M_{gt}^{sem}$, 인스턴스 $M_{gt}^{ins}$, 파놉틱 $M_{gt}^{pan}$)을 활용하여 마스크 손실 $L_{mask} = L_F(M, M_{gt}) + L_D(M, M_{gt})$ (Focal loss와 Dice loss)로 마스크 제안 추출기를 선택적으로 감독합니다. 훈련 중 그래디언트 충돌을 피하기 위해 각 반복마다 한 태스크의 레이블만 무작위로 선택하여 감독합니다.

2. **제로샷 분류 (Zero-shot Classification)**:
    * 첫 번째 단계에서 생성된 마스크에 대해 사전 학습된 CLIP을 활용하여 제로샷 분류를 수행합니다.
    * 시각적 개념 $F_v$를 사용하여 텍스트 임베딩 $F_t$와의 유사도 매칭 맵 $S \in R^{N \times C}$를 계산합니다: $S(i,j) = \frac{F_i^v \cdot F_j^t}{\left\|F_i^v\right\| \left\|F_j^t\right\|}$. 이 유사도 맵은 생성된 마스크에 대한 예측된 카테고리의 확률을 나타내며, 크로스-엔트로피 손실 $L_{cla}$로 감독됩니다.
    * 총 훈련 손실은 $L = L_{cla} + L_{mask}$입니다.

FreeSeg는 태스크 및 카테고리 특성을 처리할 수 있도록 다음 모듈을 설계했습니다.

* **적응형 프롬프트 학습 (Adaptive Prompt Learning)**:
  * 임의의 태스크와 카테고리를 텍스트 추상화로 인코딩합니다.
  * **적응형 태스크 프롬프트 ($P_t$)**: `{◦◦...t...◦◦}` 템플릿(◦는 학습 가능한 벡터, t는 태스크 이름)으로 생성되며, 사전 학습된 CLIP 텍스트 인코더 $\Psi$에 의해 임베딩되어 태스크 임베딩 $E_t$를 얻습니다.
  * **적응형 클래스 프롬프트 ($P_c$)**: `{◦◦...c...◦◦}` 템플릿(c는 클래스 이름)으로 생성되며, $\Psi$에 의해 임베딩되어 클래스 텍스트 임베딩 $E_c$를 얻습니다.
  * **다중 세분성 임베딩**: $E_c$와 $E_t$를 Cat($E_c, E_t$)을 통해 결합하여 다중 세분성 텍스트 임베딩 $F_t$를 생성합니다. 이는 미학습 카테고리에 원활하게 적응할 수 있도록 합니다.
* **시맨틱 컨텍스트 상호작용 (Semantic Context Interaction)**:
  * 적응형 텍스트 임베딩을 시각적 개념에 효과적으로 통합하여 크로스-모달 특징 매칭 및 정렬을 개선합니다. 크로스-어텐션 모듈을 사용하여 텍스트 임베딩과 디코더의 다중 스케일 시각적 특징 $F_z^v$ 간의 상관관계를 모델링합니다.
* **테스트 시 프롬프트 튜닝 (Test Time Prompt Tuning, TTPT)**:
  * 테스트 단계에서 적응형 클래스 프롬프트를 정제하여 미학습 카테고리의 크로스-모달 정렬을 개선합니다. 미학습 클래스의 유사도 점수 $S_u$에 대한 엔트로피를 계산하고, 낮은 엔트로피(높은 신뢰도)를 가진 쿼리를 선택한 후, 엔트로피 손실 $L_{ent}$를 통해 적응형 클래스 프롬프트의 매개변수를 최적화합니다.

## 📊 Results

* **개방형 어휘 시맨틱 분할**: FreeSeg는 COCO에서 미학습 클래스에 대해 49.1% mIoU, ADE20K에서 28.6% mIoU를 달성하여 기존 최고 성능인 ZSSeg를 각각 +5.5% 및 +8.3% 상회했습니다. VOC2012에서도 91.8%(seen)/82.6%(unseen) mIoU로 ZSSeg를 12.6%/4.5% 능가하며 뛰어난 성능을 보였습니다.
* **개방형 어휘 인스턴스 분할**: COCO에서 미학습 클래스에 대해 20.6% mAP를 달성하여 ZSI보다 +7.0% mAP 높았습니다. ADE20K에서는 16.3%(seen)/15.4%(unseen) mAP를 달성했습니다.
* **개방형 어휘 파놉틱 분할**: COCO 미학습 클래스에 대해 29.8% PQ, 79.2% SQ, 37.6% RQ를 달성하여 ZSSeg를 PQ에서 20.1% 크게 능가했습니다. ADE20K에서도 유사하게 뛰어난 결과를 보였습니다.
* **일반화 분석 (데이터셋 간)**: COCO에서 훈련된 모델을 ADE20K에, ADE20K에서 훈련된 모델을 COCO에 직접 테스트한 결과, FreeSeg는 기존 SOTA 방법들보다 모든 세 가지 태스크에서 일관되게 우수한 일반화 성능을 보였습니다.
* **구성 요소 분석 (Ablation Study)**: 적응형 클래스 프롬프트, 적응형 태스크 프롬프트, 시맨틱 컨텍스트 상호작용, 테스트 시 프롬프트 튜닝 등 제안된 모든 모듈이 특히 미학습 클래스의 성능 향상에 기여함을 확인했습니다.
* **멀티-태스크 분석**: 단일 태스크 훈련과 비교했을 때, FreeSeg의 멀티-태스크 훈련은 단일 통합 모델을 통해 모든 태스크의 미학습 클래스 성능을 향상시키며, 훈련 비용을 약 2/3 절감했습니다.
* **적응형 프롬프트 분석**: 고정된 템플릿 프롬프트보다 적응형 프롬프트가 모든 태스크에서 훨씬 뛰어난 성능을 보여, 학습 가능한 매개변수를 통해 태스크 인지 및 카테고리 민감 개념을 포착하는 능력의 중요성을 입증했습니다.

## 🧠 Insights & Discussion

FreeSeg는 단일 통합 모델이 시맨틱, 인스턴스, 파놉틱 분할과 같은 다양한 분할 태스크에서 SOTA 성능을 달성하고 미학습 카테고리에도 효과적으로 일반화될 수 있음을 보여줍니다. 이러한 '단일 모델, 단일 훈련' 접근 방식은 각 태스크별로 개별 모델을 훈련하는 기존 방식에 비해 훈련 비용을 약 2/3 절감합니다. 또한, 실제 배포 시에는 하나의 통합 모델만 필요하므로 계산 용량, 메모리 비용, 대역폭을 줄일 수 있어 효율성이 크게 향상됩니다. 적응형 프롬프트 학습, 시맨틱 컨텍스트 상호작용, 테스트 시 프롬프트 튜닝 등의 메커니즘은 모델이 태스크별 및 카테고리별 특성을 효과적으로 학습하고 미학습 클래스와 데이터셋 간에 뛰어난 일반화 능력을 발휘하도록 하는 데 핵심적인 역할을 합니다. 본 연구는 개방형 어휘 분할 분야에 새로운 방향을 제시하며, 보다 범용적이고 효율적인 분할 시스템 개발에 영감을 줄 것으로 기대됩니다.

## 📌 TL;DR

* **문제**: 기존 이미지 분할 모델은 특정 태스크에 특화되어 파편화되고, 새로운 카테고리에 대한 일반화 및 다양한 태스크 처리 능력이 부족하며, 리소스 비효율적입니다.
* **제안 방법**: FreeSeg는 통합된(unified), 보편적인(universal), 개방형 어휘(open-vocabulary) 이미지 분할을 위한 단일 모델 프레임워크를 제안합니다. 이는 '마스크 제안 추출기'와 'CLIP 기반 제로샷 분류'의 2단계로 구성되며, 적응형 프롬프트 학습, 시맨틱 컨텍스트 상호작용, 테스트 시 프롬프트 튜닝 메커니즘을 통해 태스크 및 카테고리별 특성을 통합 학습합니다.
* **핵심 결과**: FreeSeg는 단일 모델 학습으로 시맨틱, 인스턴스, 파놉틱 분할의 세 가지 태스크 모두에서 미학습(unseen) 클래스에 대해 기존 SOTA 모델보다 월등히 뛰어난 성능을 달성했으며 (예: COCO 미학습 클래스에서 시맨틱 mIoU +5.5%, 인스턴스 mAP +17.6%, 파놉틱 PQ +20.1%), 데이터셋 간 일반화 능력도 입증했습니다. 이는 훈련 비용을 크게 절감하면서도 강력한 성능을 제공합니다.
