# Context-aware Feature Generation for Zero-shot Semantic Segmentation

Zhangxuan Gu, Siyuan Zhou, Li Niu, Zihan Zhao, Liqing Zhang

## 🧩 Problem to Solve

기존의 의미론적 분할(semantic segmentation) 모델들은 픽셀 단위의 조밀한 주석에 크게 의존합니다. 이러한 주석 작업의 부담을 줄이기 위해, 본 논문은 학습 과정에서 주석이 전혀 없는 새로운(unseen) 객체를 분할하는 도전적인 과제인 **제로샷 의미론적 분할(Zero-shot Semantic Segmentation, ZSS)**에 초점을 맞춥니다. 이 과제의 핵심은 의미론적 단어 임베딩(semantic word embeddings)을 통해 알려진(seen) 범주에서 알려지지 않은(unseen) 범주로 지식을 전이시키는 것입니다. 기존의 특징 생성 기반 ZSS 방법들은 (1) 생성되는 특징의 다양성이 부족하여 모드 붕괴(mode collapse) 문제가 발생하거나, (2) 객체 수준의 제한적인 문맥 정보만을 활용하며, 알려지지 않은 범주의 문맥 정보를 획득하기 어렵다는 한계가 있었습니다.

## ✨ Key Contributions

* **문맥 인지 특징 생성기 설계**: 픽셀 단위 문맥 정보(pixel-wise contextual information)의 안내를 받아 다양하고 문맥 인지적인 특징을 생성하는 특징 생성기(feature generator)를 제안합니다. 이는 ZSS를 위해 더 정확하고 다양한 특징을 제공합니다.
* **네트워크 통합**: 의미론적 분할 네트워크와 특징 생성 네트워크를 효과적으로 통합하는 방법을 제시합니다. 문맥 모듈(Contextual Module, CM)과 분류기(Classifier)를 통해 두 네트워크가 연결됩니다.
* **새로운 문맥 모듈 및 문맥 선택기**: 다양한 스케일의 문맥 정보를 캡처하고, 각 픽셀에 적합한 스케일의 문맥 정보를 적응적으로 선택하는 문맥 선택기(context selector)를 포함한 문맥 모듈을 설계합니다.
* **성능 검증**: Pascal-Context, COCO-stuff, Pascal-VOC 등 세 가지 주요 벤치마크 데이터셋에서 제안하는 방법의 효과성을 광범위한 실험을 통해 입증하여 최첨단 결과를 달성합니다.

## 📎 Related Works

* **의미론적 분할**: FCN [26], Deeplab [5], PSPNet [50], U-Net [38] 등 최첨단 모델들은 수용 영역 확대를 통해 문맥 정보를 활용합니다. 그러나 이들은 학습 시 모든 범주에 대한 주석을 필요로 합니다.
* **제로샷 학습 (ZSL)**: 시각 특징과 의미 임베딩 간의 매핑을 학습하거나, 알려지지 않은 범주를 위한 시각 특징을 합성하는 방식으로 지식을 전이합니다 [21, 44]. 본 연구와 달리 기존 ZSL은 이미지 수준에서 작동하며 픽셀 단위 문맥 정보를 고려하지 않습니다.
* **제로샷 의미론적 분할**: SPNet [43]은 의미 투영을, ZS3Net [3]은 픽셀 단위 특징 생성을 통해 ZSS를 수행했습니다. 본 논문의 CaGNet은 ZS3Net에서 영감을 받았지만, 네트워크를 통합하고 픽셀 단위 문맥 정보를 활용한다는 점에서 차별화됩니다.

## 🛠️ Methodology

CaGNet은 DeepLabv2 [5]와 같은 일반적인 분할 네트워크(백본 $E$ 및 분류기 $C$)에 문맥 모듈($CM$), 생성기($G$), 판별기($D$)를 추가하여 확장합니다.

1. **문맥 모듈 (CM) 설계**:
    * **다중 스케일 문맥 맵**: 백본 $E$의 출력 특징 맵 $F_n$을 입력으로 받아, 여러 개의 **확장 컨볼루션 레이어(dilated convolutional layers)**를 통해 다양한 스케일의 문맥 정보를 캡처한 $\hat{F}^0_n, \hat{F}^1_n, \hat{F}^2_n$를 생성합니다. 확장 컨볼루션은 공간 해상도 손실 없이 수용 영역을 확장합니다.
    * **문맥 선택기(Context Selector)**: 각 픽셀에 적합한 문맥 스케일을 동적으로 선택하기 위해, 세 개의 문맥 맵을 연결한 후 $3 \times 3$ 컨볼루션을 적용하여 3채널의 스케일 가중치 맵 $A_n$을 생성합니다. 이 가중치 맵은 픽셀 단위로 각 스케일의 문맥 정보에 대한 가중치를 조절합니다.
    * **문맥 잠재 코드(Contextual Latent Code) 생성**: 가중치가 적용된 문맥 맵에 $1 \times 1$ 컨볼루션을 적용하여 평균 $\mu_{Z_n}$와 표준편차 $\sigma_{Z_n}$를 얻습니다. 각 픽셀의 문맥 잠재 코드 $z_{n,i}$는 가우시안 분포 $N(\mu_{z_{n,i}}, \sigma_{z_{n,i}})$에서 샘플링됩니다. $KL$ 발산 손실 $L_{KL} = D_{KL}[N(\mu_{z_{n,i}}, \sigma_{z_{n,i}})||N(0,1)]$을 통해 잠재 코드가 단위 가우시안 분포를 따르도록 강제하여 확률적 샘플링을 가능하게 합니다.
    * **출력**: $CM$은 $F_n$에 $Z_n$을 기반으로 하는 잔차 어텐션(residual attention)을 적용하여 새로운 특징 맵 $X_n = F_n + F_n \odot \varphi(Z_n)$를 출력합니다. $X_n$은 특징 생성의 목표이자 분류기의 입력으로 사용됩니다.

2. **문맥 인지 특징 생성기**:
    * 생성기 $G$는 픽셀 단위 의미론적 단어 임베딩 $w_{s_{n,i}}$와 $CM$에서 얻은 문맥 잠재 코드 $z_{n,i}$를 입력으로 받아 가짜 특징 $\tilde{x}_{s_{n,i}} = G(z_{n,i}, w_{s_{n,i}})$를 생성합니다.
    * **손실 함수**:
        * **재구성 손실**: $L_{REC} = \sum_{n,i} ||x_{s_{n,i}} - \tilde{x}_{s_{n,i}}||^2_2$: 생성된 특징이 실제 특징과 유사하도록 강제합니다.
        * **분류 손실**: $L_{CLS} = -\sum_{n,i} y_{s_{n,i}} \log(C(x_{s_{n,i}}))$: 실제 특징이 올바르게 분류되도록 합니다.
        * **적대적 손실**: $L_{ADV} = \sum_{n,i} (D(x_{s_{n,i}}))^2 + (1-D(G(z_{n,i}, w_{s_{n,i}})))^2$: 생성된 특징이 실제 특징과 구별할 수 없도록 합니다.

3. **최적화 과정**:
    * **1) 학습 (Training)**: 학습 데이터셋의 알려진 범주 주석을 사용하여 $E, CM, G, D, C$ 모든 모듈을 공동으로 학습합니다. 목표 함수는 $L_{CLS} + L_{ADV} + \lambda_1 L_{REC} + \lambda_2 L_{KL}$입니다. 먼저 $D$를 최대화한 다음 나머지 네트워크를 최소화합니다.
    * **2) 미세 조정 (Finetuning)**: 알려진 범주와 알려지지 않은 범주 모두를 고려합니다. 임의로 샘플링된 잠재 코드 $\tilde{z}_{m,i}$와 알려진/알려지지 않은 범주의 의미론적 단어 임베딩 $\tilde{w}_{s \cup u_{m,i}}$를 사용하여 가짜 특징 $\tilde{x}_{s \cup u_{m,i}} = G(\tilde{z}_{m,i}, \tilde{w}_{s \cup u_{m,i}})$를 생성합니다. 백본 $E$와 $CM$은 고정하고, $G, D, C$만 업데이트합니다. 목표 함수는 $\tilde{L}_{CLS} + \tilde{L}_{ADV}$입니다.
    * 학습 초기에는 학습 단계를 수행하고, 이후 100회 반복마다 학습과 미세 조정 단계를 번갈아 수행하여 실제 특징과 가짜 특징에 기반한 네트워크 최적화의 균형을 맞춥니다.

## 📊 Results

* **정량적 결과**: Pascal-Context, COCO-stuff, Pascal-VOC 세 가지 데이터셋에서 SOTA(State-of-the-art) 모델인 SPNet 및 ZS3Net과 비교하여 CaGNet은 특히 **알려지지 않은 범주(unseen categories)의 mIoU(mean Intersection over Union)**와 **전체 범주의 hIoU(harmonic IoU)**에서 상당한 성능 향상을 달성했습니다. 예를 들어, Pascal-VOC에서 CaGNet은 ZS3Net 대비 hIoU 0.3972 vs 0.2874로 크게 개선되었습니다. 이는 CaGNet이 알려지지 않은 객체를 더 잘 분할함을 의미합니다.
* **정성적 결과 (시각화)**:
  * **의미론적 분할 결과**: CaGNet은 "기차", "TV 모니터", "화분 식물", "양", "소파"와 같은 알려지지 않은 객체를 SPNet이나 ZS3Net보다 훨씬 정확하게 분할하는 것을 시각적으로 보여줍니다.
  * **특징 생성 품질**: $CM$을 사용한 CaGNet이 "CM 없음(w/o CM)" 모델(랜덤 잠재 코드 사용)에 비해 재구성 손실 맵에서 더 어두운 영역(낮은 손실)을 보여주며, 이는 알려진 범주("사람")와 알려지지 않은 범주("화분 식물", "양", "소파", "TV 모니터") 모두에서 더 나은 특징 생성 품질을 의미합니다.
  * **문맥 선택기 효과**: 스케일 선택 맵(scale selection map) 시각화는 식별 가능한 지역적 특징(예: 동물 얼굴, 테이블 위의 작은 물체)의 픽셀이 작은 스케일 문맥을 선호하는 반면, 다른 픽셀이나 큰 객체는 중간 또는 큰 스케일 문맥을 선호함을 보여줍니다. 이는 문맥 선택기가 각 픽셀에 가장 적합한 스케일의 문맥을 적응적으로 선택한다는 것을 검증합니다.

## 🧠 Insights & Discussion

* **픽셀 단위 문맥 정보의 중요성**: 본 연구는 픽셀 단위 특징이 주변 문맥 정보에 크게 의존한다는 통찰을 기반으로 합니다. 이를 문맥 잠재 코드 형태로 특징 생성 과정에 주입함으로써, 생성된 특징의 다양성과 실제성(realism)을 크게 향상시킬 수 있음을 입증했습니다. 이는 ZSS에서 기존의 객체 수준 문맥 정보보다 훨씬 상세하고 유용한 정보를 활용할 수 있음을 시사합니다.
* **모드 붕괴 완화**: 문맥 잠재 코드를 사용하여 생성기 입력과 출력 사이에 일대일 대응(bijection)을 설정함으로써, 기존 생성 모델의 고질적인 문제인 모드 붕괴를 효과적으로 완화하고 더 다양한 특징 생성을 가능하게 했습니다.
* **네트워크 통합의 이점**: 분할 네트워크와 특징 생성 네트워크를 효과적으로 통합함으로써, 두 태스크가 서로를 보완하며 전체 성능을 향상시키는 시너지를 얻었습니다. 특히, $CM$이 분할 네트워크의 잔차 어텐션 모듈 역할도 수행하여 특징 맵을 미세하게 개선하는 효과도 있습니다.
* **제한 사항 및 향후 연구**: 논문에서 직접적인 한계를 언급하지는 않지만, 제로샷 학습의 본질적인 어려움은 알려지지 않은 범주에 대한 추가 정보 없이 오직 의미론적 임베딩에만 의존해야 한다는 점입니다. 향후 연구는 더 정교한 의미 임베딩 학습이나 약한 주석(weak supervision)의 활용을 탐색할 수 있을 것입니다.

## 📌 TL;DR

제로샷 의미론적 분할의 픽셀 단위 주석 부담을 해결하기 위해, 본 논문은 **CaGNet**을 제안합니다. CaGNet은 **문맥 모듈($CM$)**을 통해 **픽셀 단위 문맥 정보**를 추출하고, 이를 **의미론적 단어 임베딩**과 함께 생성기에 입력하여 **다양하고 문맥 인지적인 특징**을 생성합니다. 이 특징들은 알려지지 않은 범주에 대한 효과적인 분할을 가능하게 하며, 분할 네트워크와 특징 생성 네트워크의 통합 및 혁신적인 **문맥 선택기**를 특징으로 합니다. 실험 결과는 CaGNet이 세 가지 주요 벤치마크에서 알려지지 않은 범주에 대한 **최첨단 성능**을 달성하며, 모드 붕괴 문제를 완화하고 문맥 정보의 중요성을 입증했음을 보여줍니다.
