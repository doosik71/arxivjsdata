{
  "title": "ShapeMask: Learning to Segment Novel Objects by Refining Shape Priors",
  "authors": "Weicheng Kuo, Anelia Angelova, Jitendra Malik, Tsung-Yi Lin",
  "year": 2019,
  "url": "http://arxiv.org/abs/1904.03239v1",
  "abstract": "Instance segmentation aims to detect and segment individual objects in a\nscene. Most existing methods rely on precise mask annotations of every\ncategory. However, it is difficult and costly to segment objects in novel\ncategories because a large number of mask annotations is required. We introduce\nShapeMask, which learns the intermediate concept of object shape to address the\nproblem of generalization in instance segmentation to novel categories.\nShapeMask starts with a bounding box detection and gradually refines it by\nfirst estimating the shape of the detected object through a collection of shape\npriors. Next, ShapeMask refines the coarse shape into an instance level mask by\nlearning instance embeddings. The shape priors provide a strong cue for\nobject-like prediction, and the instance embeddings model the instance specific\nappearance information. ShapeMask significantly outperforms the\nstate-of-the-art by 6.4 and 3.8 AP when learning across categories, and obtains\ncompetitive performance in the fully supervised setting. It is also robust to\ninaccurate detections, decreased model capacity, and small training data.\nMoreover, it runs efficiently with 150ms inference time and trains within 11\nhours on TPUs. With a larger backbone model, ShapeMask increases the gap with\nstate-of-the-art to 9.4 and 6.2 AP across categories. Code will be released.",
  "citation": 163
}