{
  "url": "http://arxiv.org/abs/1603.04871v1",
  "title": "Combining the Best of Convolutional Layers and Recurrent Layers: A\n  Hybrid Network for Semantic Segmentation",
  "authors": "Zhicheng Yan, Hao Zhang, Yangqing Jia, Thomas Breuel, Yizhou Yu",
  "year": 2016,
  "abstract": "State-of-the-art results of semantic segmentation are established by Fully\nConvolutional neural Networks (FCNs). FCNs rely on cascaded convolutional and\npooling layers to gradually enlarge the receptive fields of neurons, resulting\nin an indirect way of modeling the distant contextual dependence. In this work,\nwe advocate the use of spatially recurrent layers (i.e. ReNet layers) which\ndirectly capture global contexts and lead to improved feature representations.\nWe demonstrate the effectiveness of ReNet layers by building a Naive deep ReNet\n(N-ReNet), which achieves competitive performance on Stanford Background\ndataset. Furthermore, we integrate ReNet layers with FCNs, and develop a novel\nHybrid deep ReNet (H-ReNet). It enjoys a few remarkable properties, including\nfull-image receptive fields, end-to-end training, and efficient network\nexecution. On the PASCAL VOC 2012 benchmark, the H-ReNet improves the results\nof state-of-the-art approaches Piecewise, CRFasRNN and DeepParsing by 3.6%,\n2.3% and 0.2%, respectively, and achieves the highest IoUs for 13 out of the 20\nobject classes."
}