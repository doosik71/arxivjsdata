# On Efficient Variants of Segment Anything Model: A Survey

Xiaorui Sun, Jun Liu, Hengtao Shen, Xiaofeng Zhu, Ping Hu

## 🧩 해결할 문제

Segment Anything Model (SAM)은 이미지 분할 분야에서 강력한 성능과 뛰어난 일반화 능력을 보여주는 기초 모델입니다. 하지만 SAM의 인상적인 성능은 상당한 계산 및 자원 요구량을 수반하며, 이는 엣지 디바이스와 같이 자원이 제한된 환경에 배포하기 어렵게 만듭니다. 이 논문은 이러한 비효율성 문제를 해결하면서도 높은 정확도를 유지하는 다양한 효율적인 SAM 변형 모델들을 종합적으로 조사하고 평가하는 것을 목표로 합니다.

## ✨ 주요 기여

- 효율적인 SAM 변형 모델들을 가속화 전략에 따라 분류한 체계적인 분류법을 제시합니다. 이는 이 분야에 특화된 첫 번째 설문조사입니다.
- 다양한 하드웨어 환경에서 이 변형 모델들의 효율성과 정확도에 대한 포괄적인 평가 및 비교를 제공하여, 연구자들이 성능 및 응용 요구 사항에 가장 적합한 모델을 선택하는 데 도움을 줍니다.
- 향후 연구를 위한 여러 잠재적인 방향을 제시하여 이 분야의 지속적인 발전에 영감을 줍니다.

## 📎 관련 연구

- **기초 모델(Foundation Models):** 자연어 처리 분야의 대규모 언어 모델(LLM, 예: OpenAI의 GPT, Google의 PaLM, Meta의 LLaMA 시리즈)과 컴퓨터 비전 분야의 비전 트랜스포머(ViT)의 성공에 기반을 둡니다.
- **비전 재단 모델(Vision Foundation Models, VFMs):** CLIP, LLaVA, Video-ChatGPT와 같이 시각 및 언어 모달리티를 정렬하여 다양한 시각 작업을 수행하는 모델들이 등장했습니다.
- **Segment Anything Model (SAM):** Meta가 제안한 일반 이미지 분할을 위한 새로운 기초 모델로, SA-1B 데이터셋으로 학습되었으며 다양한 프롬프트에 대한 강력한 일반화 능력을 가집니다. 후속 모델인 SAM 2는 비디오 분할 능력을 추가했습니다.
- **기존 SAM 설문조사:** 대부분 SAM의 다운스트림 애플리케이션에 초점을 맞추었으며, 효율성 개선, 체계적인 분류법, 비교 평가 측면에서 한계가 있었습니다.
- **모델 가속화 기술:** SAM 효율성 개선에 적용될 수 있는 효율적인 백본(CNN, ViT, Transformer-alternative 모델) 및 모델 압축(지식 증류, 양자화, 가지치기, 저차원 분해) 기술들을 다룹니다.

## 🛠️ 방법론

이 설문조사는 효율적인 SAM 변형 모델들을 다음 두 가지 주요 작업 가속화에 따라 분류하고 평가합니다: Segment Anything (SegAny) 및 Segment Everything (SegEvery).

- **SegAny 가속화 전략:**
  - **스크래치부터 훈련:** SAM과 다른 아키텍처(FastSAM, SqueezeSAM) 또는 SAM과 유사한 아키텍처(EfficientSAM, RMP-SAM, SAM 2)를 사용하여 경량 모델을 완전히 새로 훈련합니다.
  - **지식 증류:** 원본 SAM의 지식을 경량 모델에 전달하며, 경량 ViT 인코더, 순수 CNN 인코더, 어텐션 수정 인코더 등을 백본으로 활용합니다(예: MobileSAM, TinySAM, NanoSAM, EdgeSAM, EfficientViT-SAM).
  - **모델 압축:** 양자화(PTQ4SAM, PQ-SAM), 가지치기(SlimSAM, SuperSAM)와 같은 기술을 사용하여 원본 SAM을 직접 압축합니다.
  - **코드 리팩토링:** PyTorch의 최적화 기법을 활용하여 구현 수준에서 효율성을 높입니다(예: SAMfast).
- **SegEvery 가속화 전략:**

  - **파노틱 분할 전략:** SegEvery 작업을 다른 잘 확립된 작업(예: FastSAM의 인스턴스 분할)으로 전환합니다.
  - **효율적인 샘플링 전략:** 프롬프트 생성을 위한 효율적인 샘플링 전략을 설계하여 중복 마스크 생성을 줄입니다(예: MobileSAMv2, TinySAM의 계층적 샘플링, Lite-SAM, AoP-SAM의 자동 프롬프트 생성).

- **평가 지표 및 데이터셋:**
  - **효율성:** 파라미터 수(#Params), FLOPs, 효율성 오류율(EER, Efficient Error Rate), 추론 지연 시간(CPU, GPU, 엣지 디바이스), 처리량(throughput)을 측정합니다.
  - **정확도:** SegAny 작업에는 평균 IoU(mIoU)를, 인스턴스 분할에는 평균 정밀도(AP)를 사용합니다.
  - **데이터셋:** COCO 2017, LVIS v1, SGinW (Segmentation in the Wild), UVO v1.0 (Unidentified Video Objects) 벤치마크를 활용합니다.
  - 모든 모델은 동일한 환경에서 평가되며, 이미지는 원본 해상도를 유지합니다.

## 📊 결과

- **효율성 비교:**
  - 대부분의 SAM 변형 모델들은 SAM-H에 비해 파라미터 수, FLOPs, EER에서 상당한 감소를 보였습니다. 특히 EdgeSAM이 가장 낮은 #Params, FLOPs, EER을 기록했습니다.
  - SegAny 작업의 추론 시간에서는 EfficientViT-SAM-L0이 GPU에서 SAM-H 대비 약 30배, CPU에서 약 50배 빠른 성능을 보였습니다.
  - 엣지 디바이스(Jetson Nano)에서는 NanoSAM이 가장 낮은 실행 시간을 달성했습니다.
  - 처리량 측면에서는 NanoSAM이 초당 27.9개의 이미지 처리로 가장 높았습니다.
  - SegEvery 작업에서는 SAMfast-H가 32x32 그리드에서 가장 효율적이었고, FastSAM(106ms) 및 MobileSAMv2(173ms)와 같이 효율적인 샘플링 전략을 채택한 모델들이 큰 성능 향상을 보였습니다.
- **정확도 비교:**
  - SegAny 작업(포인트/박스 프롬프트)에서 EfficientViT-SAM-XL1은 COCO 및 LVIS 데이터셋에서 SAM-H를 능가하거나 유사한 최고 수준의 mIoU를 달성했습니다.
  - 인스턴스 분할 작업에서도 EfficientViT-SAM-XL1이 대부분의 경우 가장 높은 AP를 보였습니다.
  - 처리량-mIoU 산점도에서는 NanoSAM이 가장 높은 처리량과 가장 낮은 mIoU를 보였고, EfficientViT-SAM-L0은 높은 mIoU와 상대적으로 높은 처리량으로 최적의 효율성-정확도 균형을 보여주었습니다.
  - SGinW 및 UVO와 같은 도전적인 데이터셋에서는 일부 모델이 희귀하거나 새로운 객체 분할에 어려움을 겪는 한계도 확인되었습니다.

## 🧠 통찰 및 논의

- **아키텍처 및 방법론의 균형:** 백본 선택(CNN, ViT, 어텐션 수정, 하이브리드)은 모델 크기, 계산 복잡성, 분할 성능에 큰 영향을 미칩니다. CNN은 효율적이지만 전역적 컨텍스트 포착에 한계가 있고, ViT는 정확하지만 계산 비용이 높습니다. 효율적인 어텐션 메커니즘과 하이브리드 아키텍처는 효율성과 정확성 사이의 좋은 균형점을 찾을 수 있습니다.
- **압축 기술의 한계:** 양자화 및 가지치기는 모델 크기를 줄일 수 있지만, 예상된 실행 시간 향상을 제공하지 않거나 정확도 및 일반화 성능을 저하시킬 수 있습니다.
- **훈련 절차의 중요성:** 스크래치부터의 훈련은 고품질 모델을 만들지만 자원이 많이 필요하며, 지식 증류는 효율적이지만 교사 모델의 능력을 완전히 상속받지 못할 수 있습니다. 압축 기술과 증류/미세 조정을 결합하여 균형 잡힌 모델을 얻을 수 있습니다.
- **하드웨어별 최적화 권장 사항:**
  - **GPU 환경:** EfficientViT-SAM-L0은 속도와 정확성 사이의 균형이 뛰어나며, EfficientViT-SAM-XL1은 높은 정확도를 제공합니다.
  - **CPU 환경:** EfficientViT-SAM-L0이 가장 효과적입니다.
  - **엣지 디바이스:** NanoSAM이 메모리 사용량과 지연 시간 최소화에 유리하며, EdgeSAM도 좋은 대안이 될 수 있습니다.
- **향후 연구 방향:**
  - **고급 아키텍처 탐색:** Mamba, RetNet, KAN, TTT와 같은 새로운 트랜스포머 대체 모델을 탐색하고, 선형 어텐션, 저차원 분해, CNN-어텐션 하이브리드 등 어텐션 모듈의 효율성을 개선합니다.
  - **희소성 및 가속화 기술 활용:** SAM 아키텍처 내의 미세한 희소성을 발견하고 가지치기, 양자화, 동적 가지치기, 저정밀도 훈련 등을 통해 계산 요구량을 더욱 줄입니다.
  - **하드웨어 특정 최적화:** GPU, TPU, 엣지 디바이스 등 특정 하드웨어 플랫폼에 맞춰 연산자 융합, 양자화 인식 훈련, 커스텀 CUDA 커널 등을 활용하여 성능을 극대화합니다.
  - **계산 비용 공격 및 방어:** SAM 변형 모델들이 계산 비용 공격에 취약한지 연구하고, 안정적인 효율성을 위한 방어 전략을 개발합니다.
  - **다중 도메인 범용 분할:** 의료 영상이나 항공 영상과 같은 특정 도메인에서의 성능 평가를 포함하여 효율적인 SAM 변형 모델의 범용 일반화 능력을 강화합니다.
  - **SAM 2의 효율적인 변형:** SAM 2의 계층적 이미지 인코더 및 새로운 메모리 메커니즘의 병목 현상을 해결하기 위한 효율적인 변형 모델 연구를 심화합니다.

## 📌 TL;DR

SAM은 강력하지만 높은 연산 비용으로 제한된 환경에서의 배포가 어렵습니다. 이 설문조사는 효율적인 SAM 변형 모델들을 체계적으로 분류하고, 다양한 하드웨어에서 이들의 효율성-정확도 균형을 평가했습니다. 결과적으로 EfficientViT-SAM-L0과 NanoSAM 같은 모델들이 원본 SAM 대비 상당한 효율성 향상을 달성하며, 일부는 정확도 면에서도 경쟁력 있거나 우수한 성능을 보였습니다. 향후 연구는 새로운 아키텍처, 희소성 활용, 하드웨어 최적화, 그리고 SAM 2의 효율성 개선에 초점을 맞출 것입니다.
