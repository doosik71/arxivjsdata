# SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers

Enze Xie, Wenhai Wang, Zhiding Yu, Anima Anandkumar, Jose M. Alvarez, Ping Luo

## 🧩 Problem to Solve

시맨틱 분할(Semantic Segmentation)은 컴퓨터 비전의 핵심 과제이지만, 기존의 트랜스포머 기반 방법론(예: SETR과 ViT)은 여러 한계를 가지고 있었습니다.

- 기존 ViT 기반 모델은 단일 스케일의 저해상도 특징만을 출력하여, 조밀한(dense) 예측에 유리한 멀티스케일 특징을 제공하지 못했습니다.
- 대규모 이미지 처리 시 계산 비용이 매우 높았습니다.
- 고정된 위치 인코딩(positional encoding, PE)을 사용하기 때문에, 훈련 시와 다른 해상도의 이미지로 추론할 때 성능 저하가 발생했습니다.
- 대부분의 연구가 트랜스포머 인코더 설계에만 집중하고 디코더의 기여를 간과하는 경향이 있었습니다.
- 결과적으로, 기존 트랜스포머 기반 모델은 계산적으로 부담이 커 실시간 애플리케이션에 배포하기 어려웠습니다.

## ✨ Key Contributions

- 트랜스포머와 경량 MLP 디코더를 통합한 간단하고 효율적이며 강력한 시맨틱 분할 프레임워크인 **SegFormer**를 제안했습니다.
- **새로운 계층적 구조의 트랜스포머 인코더(MiT)**를 도입하여 멀티스케일 특징을 출력하고, 위치 인코딩을 사용하지 않아 테스트 해상도 변화에 따른 성능 저하를 방지했습니다.
- 복잡한 모듈 없이 다양한 레이어의 정보를 통합하여 강력한 표현을 생성하는 **경량 All-MLP 디코더**를 개발했습니다. 이 디코더는 로컬 및 글로벌 어텐션을 효과적으로 결합합니다.
- SegFormer-B0부터 SegFormer-B5까지 다양한 모델 시리즈를 통해 기존 SOTA 모델보다 훨씬 우수한 성능과 효율성을 달성했습니다.
  - 예를 들어, SegFormer-B4는 ADE20K에서 64M 파라미터로 50.3% mIoU를 달성하여, 이전 최고 성능 모델보다 파라미터가 5배 작고 mIoU는 2.2% 높습니다.
  - SegFormer-B5는 Cityscapes 검증 세트에서 84.0% mIoU를 달성했으며, Cityscapes-C에서 뛰어난 제로샷 강건성(zero-shot robustness)을 보여주었습니다.
- 일반적인 손상 및 교란에 대한 모델의 강건성을 크게 향상시켰습니다.

## 📎 Related Works

- **시맨틱 분할:** FCNs [1]이 시초이며, 이후 수용 영역 확장 (예: dilated convolution [4, 5]), 맥락 정보 정제 [21–29], 경계 정보 도입 [30–37], 다양한 어텐션 모듈 설계 [38–46], AutoML 기술 [47–51] 등을 통해 발전했지만, 이는 종종 계산적으로 부담이 크고 복잡한 프레임워크로 이어졌습니다.
- **트랜스포머 백본:**
  - **ViT (Vision Transformer) [6]:** 순수 트랜스포머로 이미지 분류에서 SOTA를 달성했지만, 단일 스케일 저해상도 특징 출력 및 높은 계산 비용의 한계가 있었습니다.
  - **SETR [7]:** ViT를 시맨틱 분할 백본으로 적용했지만, 효율성 문제와 단일 스케일 출력 문제가 있었습니다.
  - **PVT (Pyramid Vision Transformer) [8]:** ViT에 피라미드 구조를 도입하여 조밀한 예측을 위한 멀티스케일 특징 문제를 해결하려는 시도였습니다.
  - Swin Transformer [9] 및 Twins [10]와 같은 후속 연구들은 특징의 로컬 연속성을 강화하고 고정 크기 위치 임베딩을 제거하는 데 중점을 두었습니다.
- **특정 작업용 트랜스포머:** DETR [52]은 객체 탐지, 기타 연구들은 추적, 초해상도, ReID, 컬러라이제이션, 검색, 멀티모달 학습 등에 트랜스포머를 적용했습니다.

## 🛠️ Methodology

SegFormer는 두 가지 주요 모듈로 구성됩니다:

1. **계층적 트랜스포머 인코더 (MiT: Mix Transformer):**
    - **계층적 특징 표현 (Hierarchical Feature Representation):** 입력 이미지에서 CNN과 유사한 멀티레벨 특징을 {1/4, 1/8, 1/16, 1/32} 해상도로 생성하여 고해상도 미세 특징과 저해상도 거친 특징을 모두 제공합니다.
    - **오버랩 패치 병합 (Overlapped Patch Merging):** ViT의 비겹침 패치 병합과 달리, 오버랩되는 패치 (예: $K=7, S=4, P=3$)를 사용하여 로컬 연속성을 보존하고 계층적 특징 맵을 생성합니다.
    - **효율적인 셀프-어텐션 (Efficient Self-Attention):** 표준 셀프-어텐션의 $O(N^2)$ 계산 복잡성을 줄이기 위해 PVT [8]에서 도입된 시퀀스 감소 프로세스를 사용합니다. 키(Key) 시퀀스의 길이를 감소 비율 $R$ (예: [64, 16, 4, 1] for stages 1-4)로 줄여 $O(N^2/R)$ 복잡도로 만듭니다.
    - **Mix-FFN (Mixed Feed-Forward Network):** 기존 위치 인코딩 대신 피드포워드 네트워크(FFN) 내에 3x3 깊이별 합성곱(depth-wise convolution)을 도입합니다. 이는 데이터 기반으로 위치 정보를 제공하며, 훈련/추론 해상도 불일치로 인한 성능 저하를 방지합니다.
        $$x_{out} = \text{MLP}(\text{GELU}(\text{Conv}_{3 \times 3}(\text{MLP}(x_{in})))) + x_{in}$$
2. **경량 All-MLP 디코더 (Lightweight All-MLP Decoder):**
    - **간단한 설계:** 다른 디코더에서 흔히 사용되는 복잡하고 계산 비용이 많이 드는 모듈 없이 오직 MLP 레이어로만 구성됩니다.
    - **멀티레벨 특징 융합:** MiT 인코더에서 얻은 멀티레벨 특징 $F_i$를 사용하여 다음 단계를 거칩니다:
        1. 각 $F_i$는 MLP 레이어를 통해 채널 차원 $C$를 통일합니다.
        2. 특징들은 원래 해상도의 1/4 크기로 업샘플링됩니다.
        3. 연결된(concatenated) 특징들은 또 다른 MLP 레이어를 통해 융합됩니다.
        4. 최종 MLP 레이어가 $H/4 \times W/4 \times N_{cls}$ 해상도의 최종 분할 마스크 $M$을 예측합니다.
    - **효과성:** 트랜스포머 인코더의 큰 유효 수용 영역(Effective Receptive Field, ERF)을 활용하여 로컬(낮은 레이어) 및 비로컬(높은 레이어) 어텐션을 동시에 포착하며, 이를 통해 간단한 MLP 디코더로도 강력한 표현을 생성할 수 있습니다.

## 📊 Results

- **효율성 및 정확도 (ADE20K, Cityscapes, COCO-Stuff):**
  - SegFormer-B0는 파라미터 수, FLOPs, 속도 측면에서 다른 실시간 모델보다 훨씬 효율적이며, 경쟁력 있는 mIoU를 유지합니다. 예를 들어, ADE20K에서 3.8M 파라미터와 8.4G FLOPs로 37.4% mIoU를 달성합니다.
  - SegFormer-B5는 모든 데이터셋에서 SOTA mIoU를 달성했습니다.
    - ADE20K: 51.8% mIoU (SOTA), SETR 대비 1.6% 우수하며 모델 크기는 4배 작습니다.
    - Cityscapes: 84.0% mIoU (SOTA), SETR 대비 1.8% 이상 우수하며 5배 빠르고 4배 작습니다.
    - COCO-Stuff: 46.7% mIoU, SETR 대비 0.9% 우수하며 4배 작습니다.
- **Mix-FFN vs. 위치 인코딩:**
  - Mix-FFN은 위치 인코딩보다 지속적으로 우수한 성능을 보입니다.
  - 테스트 해상도 변화에 대한 민감도가 현저히 낮습니다 (예: Cityscapes에서 해상도 변경 시 Mix-FFN은 0.7% 하락, PE는 3.3% 하락).
- **유효 수용 영역 (ERF) 평가:**
  - MLP 디코더를 CNN 백본(ResNet, ResNeXt)과 결합했을 때, 트랜스포머(MiT) 인코더와 결합했을 때보다 훨씬 낮은 정확도를 보여 트랜스포머의 큰 ERF가 단순 MLP 디코더의 성공에 중요함을 입증했습니다.
  - 트랜스포머 인코더의 저수준 로컬 특징과 고수준 비로컬 특징을 결합하는 것이 성능에 필수적입니다.
- **강건성 (Cityscapes-C):**
  - SegFormer는 16가지 일반적인 손상 및 교란(노이즈, 블러, 날씨, 디지털) 유형 전반에 걸쳐 기존 방법(예: DeepLabv3+ 변형)보다 현저히 뛰어난 성능을 보였습니다.
  - Gaussian Noise에서 최대 588%, snow weather에서 최대 295%의 상대적 개선을 보여주며 탁월한 제로샷 강건성을 입증했습니다.

## 🧠 Insights & Discussion

- **단순함의 미학:** 이 연구는 계층적 트랜스포머 인코더와 All-MLP 디코더라는 간단하고 경량화된 설계가 시맨틱 분할에서 우수한 성능과 효율성을 달성할 수 있음을 보여주며, 복잡한 모듈 설계 추세에 도전합니다.
- **트랜스포머의 강점 재확인:** 트랜스포머 인코더가 멀티스케일 특징과 로컬/비로컬 어텐션을 자연스럽게 생성하고 큰 유효 수용 영역을 가지는 능력이 SegFormer 성공의 핵심 동인입니다.
- **위치 인코딩의 재고:** 트랜스포머에 필수적이라고 여겨지는 위치 인코딩이 실제로는 불필요하며, 특히 테스트 해상도가 훈련 해상도와 다를 때 성능을 저하시킬 수 있음을 보여줍니다. Mix-FFN은 강건하고 데이터 기반의 대안을 제시합니다.
- **디코더의 중요성 강조:** 많은 연구가 인코더 설계에 집중하지만, SegFormer는 트랜스포머가 생성하는 고유한 특징을 효과적으로 활용할 수 있는 적절한 디코더의 중요성을 강조합니다.
- **강건성:** 손상에 대한 뛰어난 제로샷 강건성은 자율 주행과 같은 안전에 중요한 애플리케이션에 SegFormer가 매우 적합함을 시사합니다.
- **한계점:** 가장 작은 모델인 SegFormer-B0도 3.7M 파라미터를 가지고 있어, 100KB 메모리만 있는 엣지 디바이스와 같은 극도로 제한된 환경에서의 작동 여부는 미래 연구 과제로 남겨져 있습니다.

## 📌 TL;DR

SegFormer는 시맨틱 분할을 위한 간단하고 효율적인 트랜스포머 기반 프레임워크입니다. 이 연구는 기존 트랜스포머 모델의 단일 스케일 특징 출력 및 고정 위치 인코딩 문제를 해결하기 위해 **위치 인코딩이 없는 계층적 트랜스포머 인코더(MiT)**와 **경량 All-MLP 디코더**를 제안합니다. MiT 인코더는 멀티스케일 특징을 생성하고 Mix-FFN을 통해 위치 정보를 효율적으로 학습하며, All-MLP 디코더는 이러한 특징을 간단하게 융합하여 강력한 표현을 생성합니다. SegFormer는 ADE20K, Cityscapes, COCO-Stuff 데이터셋에서 파라미터 수, FLOPs, 속도 및 정확도 측면에서 기존 SOTA 모델을 능가하는 동시에, Cityscapes-C 벤치마크에서 우수한 제로샷 강건성을 보여주었습니다.
