# Pixel-level Encoding and Depth Layering for Instance-level Semantic Labeling

Jonas Uhrig, Marius Cordts, Uwe Franke, Thomas Brox

## 🧩 해결하고자 하는 문제

시각적 장면 이해는 주로 픽셀 단위 의미론적 레이블링(의미론적으로 연결된 영역 분할)과 바운딩 박스 객체 탐지(개별 객체를 대략적인 위치로 식별) 두 가지 방식으로 접근됩니다. 그러나 로봇공학 및 자율주행과 같은 분야에서는 분할의 정밀도와 개별 객체 인스턴스를 구별하는 능력을 결합한 **인스턴스 레벨 의미론적 레이블링**에 대한 필요성이 커지고 있습니다. 기존 방법은 종종 복잡한 다중 작업 아키텍처, 계산 비용이 많이 드는 그래픽 모델 또는 객체 제안(object proposals)에 의존하여 성능이 느리거나 제한적일 수 있습니다. 이 논문은 복잡한 후처리나 제안 방식에 의존하지 않고, 특히 복잡한 도로 장면에서 단일 이미지로부터 정확한 인스턴스 분할, 단안 깊이 추정 및 픽셀 단위 의미론적 레이블링을 동시에 달성하는 것을 목표로 합니다.

## ✨ 주요 기여

- 세 가지 픽셀 단위 출력을 동시에 예측하는 새로운 완전 컨볼루션 네트워크(FCN) 아키텍처를 제안합니다: 의미론적 레이블, 깊이 정보, 그리고 인스턴스 기반 인코딩(인스턴스 중심 방향).
- 복잡한 다중 작업 또는 그래픽 모델 대신, 이 FCN 출력과 간단한 저수준 컴퓨터 비전 기술(템플릿 매칭, 비최대 억제, 제안 융합)을 결합하여 최첨단 인스턴스 분할을 달성할 수 있음을 보여줍니다.
- 강력하고 경계를 암묵적으로 처리하며 FCN에 적합한 픽셀 단위 "인스턴스 중심 방향" 인코딩을 도입하여 효과적인 인스턴스 분리를 가능하게 합니다.
- 기존 방법 대비 KITTI 및 Cityscapes와 같은 도전적인 도로 장면 데이터셋에서 인스턴스 분할에 대해 현저히 우수한 성능을 달성했으며 (예: KITTI에서 평균 37% 상대 개선, Cityscapes에서 AP 거의 두 배 향상) 큰 차이로 앞섭니다.
- 단일 단안 이미지로부터 개별 인스턴스에 대한 신뢰할 수 있는 절대 거리 예측을 제공하여 실제 애플리케이션에 유용한 출력을 제공합니다.
- 단일 입력으로부터 인스턴스 분할, 단안 깊이, 픽셀 단위 의미론적 레이블링으로 구성된 전체적인 장면 표현을 제공합니다.
- 이 접근 방식은 사전 생성된 객체 제안(object proposals)에 의존하지 않는 "제안 없는(proposal-free)" 방식으로, 이미지 내의 임의의 많은 수의 인스턴스에 대해 확장이 용이합니다.

## 📎 관련 연구

본 논문은 인스턴스 레벨 의미론적 레이블링을 두 가지 주요 연구 방향으로 분류합니다.

- **제안 기반(Proposal-based) 방법:** 이 방법들은 먼저 객체 제안(예: R-CNN 변형, MCG 또는 계층적 그림 구조)의 과도한 집합을 생성한 다음, 이를 분류하고 정제하여 인스턴스 세그먼트를 얻습니다. 성능은 초기 제안의 품질에 크게 좌우되며, 각 제안을 개별적으로 분류해야 하므로 속도가 느릴 수 있습니다.
- **제안 없는(Proposal-free) 방법:** 이 방법들은 픽셀 수준에서 분할 및 의미론적 클래스를 직접 추론합니다.

본 논문에서 제안하는 방법은 **제안 없는** 카테고리에 속하며, 기존의 제안 없는 방법들이 가진 한계(예: 훈련의 어려움, 인스턴스 수에 대한 민감성)를 극복하고자 합니다.

## 🛠️ 방법론

이 방법의 핵심은 FCN-8s [21] 모델을 기반으로 확장되어 세 가지 픽셀 단위 출력 채널을 생성하며, 교차 엔트로피 손실로 공동 훈련되는 완전 컨볼루션 네트워크(FCN)입니다.

1. **의미론 채널 (Semantics Channel):** 각 픽셀에 대한 의미론적 레이블(예: 자동차, 보행자, 건물)을 예측합니다.
2. **깊이 채널 (Depth Channel):** 각 객체 픽셀에 대한 깊이 레이블을 예측합니다. 깊이 값은 일련의 이산적인 클래스로 나뉘며, 가까운 객체에 대해 더 정밀한 해상도를 가집니다.
3. **방향 채널 (Direction Channel):** 각 객체 픽셀에 대해 해당 가시 인스턴스 중심을 향하는 2D 방향(각도)을 예측하며, 이 각도는 이산적인 클래스로 표현됩니다 (예: 각 $45^\circ$에 대해 8개 클래스). 이 표현은 경계에서 인스턴스를 명확하게 분리하고 가려짐을 잘 처리하며, 인스턴스 중심 주위에 뚜렷한 패턴을 형성합니다.

**후처리 단계:**

- **템플릿 매칭 (Template Matching):**
  - 예측된 방향 맵에 정규화된 교차 상관(NCC)을 적용하여 인스턴스 중심을 찾습니다.
  - 템플릿의 종횡비와 크기는 의미론적 범주와 예측된 깊이 클래스에 따라 조절됩니다.
- **인스턴스 생성 (Instance Generation):**
  1. **인스턴스 중심 (Instance Centers):** 템플릿 매칭 점수 맵에서 비최대 억제(non-maximum suppression)를 통해 임시 인스턴스 중심을 식별합니다.
  2. **인스턴스 제안 (Instance Proposals):** 예측된 방향을 가진 각 픽셀은 방향 예측과 위치가 일치하는 가장 가까운 임시 인스턴스 중심에 할당됩니다.
  3. **제안 융합 (Proposal Fusion):** 길쭉한 객체나 깊이 오류로 인한 과분할을 수정하기 위해 제안들을 정제합니다. 불완전한 인스턴스 제안이 편향된 방향으로 이웃하는 후보와 일치하면 융합됩니다.
- **최종 출력 (Final Output):** 남은 인스턴스에 평균 깊이와 최빈 의미론적 클래스를 할당하고, 인스턴스가 아닌 픽셀에는 FCN의 의미론 채널에서 얻은 레이블을 할당하여 일관된 장면 표현을 완성합니다.

## 📊 결과

이 방법은 KITTI 및 Cityscapes 데이터셋에서 평가되었습니다.

- **인스턴스 분할:**

  - **KITTI:** 기존의 모든 연구를 능가하며, 모든 지표에서 평균 37%의 상대적 개선을 달성했습니다. `InsF1` 점수는 79.7%를 기록하여 기존 최상위 방법(56.6%)을 크게 앞섰습니다.
  - **Cityscapes:** 기준선인 `MCG+R-CNN` [6]을 모든 지표에서 능가하며, 주요 점수 `AP`를 거의 두 배(4.6%에서 8.9%로) 향상시켰습니다.

- **깊이 추정:**

  - KITTI `test` 세트에서 평균 상대 오류(ARD) 7.7% 및 평균 절대 오류(MAE) 1.7m의 낮은 값을 달성했습니다.
  - Cityscapes `val` 세트에서는 복잡한 장면과 멀리 있는 객체에도 불구하고 ARD 11.3% 및 MAE 7.7m를 달성했습니다. 이는 단일 단안 이미지만 사용되었음을 고려하면 매우 인상적인 결과입니다.

- **픽셀 단위 의미론적 레이블링:**
  - Cityscapes `test` 세트에서 `IoU_{class}` 64.3%와 `iIoU_{class}` 41.6%를 기록하며, 주요 초점이 인스턴스 분할임에도 불구하고 `FCN 8s` [21] 및 `Dilation10` [33]과 같은 최첨단 방법과 동등한 성능을 보였습니다. 특히 카테고리별 인스턴스 기반 점수(`IoU_{category}`)에서는 73.9%로 새로운 최고 성능을 달성했습니다.

## 🧠 통찰 및 논의

- **전체적인 장면 이해:** 이 방법은 단일 단안 이미지로부터 픽셀 단위 의미론, 인스턴스 레벨 분할, 그리고 인스턴스별 깊이를 제공함으로써 포괄적인 장면 이해를 성공적으로 달성합니다. 이는 자율주행과 같은 응용 분야에서 가려짐 추론, 객체 추적, 동작 추정을 가능하게 하는 데 매우 중요합니다.
- **단순성과 효율성:** 복잡한 다중 작업 아키텍처나 계산 비용이 많이 드는 그래픽 모델이 최첨단 성능을 위해 필수적이지 않다는 점이 핵심 통찰력입니다. 강력한 FCN이 제공하는 풍부한 픽셀 단위 단서와 표준 저수준 컴퓨터 비전 기술을 결합하여 우수한 결과를 얻을 수 있음을 보여줍니다.
- **제안 없는 확장성:** 인스턴스 방향의 "픽셀 단위 인코딩"은 이 접근 방식을 제안 없는 방식으로 만들어, 임의의 많은 수의 객체 인스턴스가 있는 장면에서도 잘 확장될 수 있도록 합니다.
- **단안 깊이의 이점:** 단일 단안 이미지로부터 개별 인스턴스에 대한 절대 깊이를 예측하는 능력은 스테레오 데이터가 없거나 신뢰할 수 없을 때 특히 중요한 발전입니다.
- **한계:** Cityscapes와 같은 복잡한 장면에서의 성능은 KITTI보다 낮게 나타났는데, 이는 극심한 혼란, 매우 작고 멀리 있는 객체 처리 등에서 여전히 어려움이 있을 수 있음을 시사합니다. 또한 모든 세 가지 FCN 출력 채널과 융합 단계가 최적의 성능을 위해 필수적임을 절제 연구를 통해 확인했습니다.

## 📌 TL;DR

이 논문은 단일 완전 컨볼루션 네트워크(FCN)를 사용하여 이미지의 모든 픽셀에 대해 의미론, 깊이, 그리고 해당 인스턴스 중심 방향을 예측함으로써 **인스턴스 레벨 의미론적 레이블링** 문제를 해결합니다. 이러한 픽셀 단위 예측을 표준 컴퓨터 비전 기술(템플릿 매칭, 비최대 억제, 제안 융합)과 결합하여, 기존의 복잡한 방법들을 능가하는 **최첨단 인스턴스 분할 및 단안 깊이 추정**을 달성합니다. 특히 KITTI와 Cityscapes 같은 도로 장면 데이터셋에서 **월등한 성능 향상**을 보였으며, 제안 기반 방식의 한계를 넘어 모든 인스턴스를 정확하게 분리하고 그 절대 깊이를 예측합니다.
