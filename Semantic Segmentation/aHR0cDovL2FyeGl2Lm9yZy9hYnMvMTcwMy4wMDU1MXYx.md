# Label Refinement Network for Coarse-to-Fine Semantic Segmentation
Md Amirul Islam, Shujon Naha, Mrigank Rochan, Neil Bruce, and Yang Wang

## 🧩 Problem to Solve
이 논문은 딥 컨볼루션 신경망(CNN)을 사용한 의미론적 이미지 분할(semantic image segmentation), 즉 이미지의 각 픽셀을 해당 객체 클래스에 따라 밀도 있게 레이블링하는 문제를 다룹니다. 기존 CNN 기반 분할 방법들은 주로 네트워크의 최종 단계에서 한 번에 픽셀별 레이블을 예측하여, 픽셀 단위의 정밀한 정보가 손실될 수 있다는 한계가 있었습니다. 본 연구는 이러한 정밀도 손실 문제를 해결하고 픽셀 단위의 밀집된 이미지 레이블링을 효과적으로 수행하는 방법을 제안합니다.

## ✨ Key Contributions
*   **새로운 아키텍처 제안:** Coarse-to-fine 방식으로 의미론적 레이블을 예측하는 Label Refinement Network (LRN)라는 새로운 CNN 아키텍처를 제안합니다.
*   **다단계 해상도 예측:** 기존 방식과 달리, 여러 다른 해상도에서 의미론적 레이블을 예측하며 점진적으로 결과를 정제합니다.
*   **레이블 및 특징 결합:** 거친 해상도에서 얻은 분할 레이블을 합성곱 특징(convolutional features)과 함께 사용하여 더 미세한 해상도의 분할 레이블을 얻습니다.
*   **심층 감독 (Deep Supervision):** 네트워크의 여러 단계에 손실 함수를 정의하여 다단계에서 감독(supervision)을 제공함으로써 네트워크 학습을 강화합니다.
*   **일반적인 적용 가능성:** 의미론적 이미지 분할에 중점을 두지만, 제안된 네트워크 아키텍처는 다른 모든 픽셀 단위 레이블링 작업에 적용할 수 있을 정도로 충분히 일반적입니다.
*   **성능 입증:** 여러 표준 데이터셋에 대한 광범위한 실험을 통해 제안된 모델의 효과성을 입증했습니다.

## 📎 Related Works
*   **CNN 기반 이미지 분할:** FCN (Fully Convolutional Networks) [16] 및 SegNet [1], DeconvNet [18]과 같이 CNN 특징 맵의 공간 차원을 확대하여 픽셀 단위 레이블을 예측하는 접근 방식들을 언급합니다.
*   **다중 스케일 처리:** Laplacian Pyramids [3]와 같이 이미지 구조를 여러 스케일에서 포착하는 초기 연구부터, Eigen et al. [6]의 다중 스케일 CNN, Honari et al. [10]의 coarse-to-fine 특징 결합 방식 등을 포함합니다.
*   **심층 감독 (Deep Supervision):** Inception 모델 [22]에서 보조 분류기를 사용하거나, Lee et al. [15]의 심층 감독 네트워크, Xie et al. [25]의 엣지 감지 연구와 같이 CNN의 여러 단계에 손실 함수를 정의하여 학습을 강화하는 아이디어를 참조합니다.

## 🛠️ Methodology
LRN은 인코더-디코더 프레임워크를 기반으로 합니다. 인코더 네트워크는 입력 이미지에서 특징을 추출하며, SegNet [1]과 유사하게 VGG16 네트워크 [20]를 기반으로 합니다. LRN의 핵심적인 차별점은 디코더 네트워크에 있습니다.

*   **Coarse-to-Fine 예측 과정:**
    1.  **초기 거친 예측 ($s_1(I)$):** 인코더 네트워크의 마지막 합성곱 레이어에서 추출된 특징 맵 $f_5(I)$는 고수준 정보를 포함하지만 공간적으로는 거칩니다. 이 $f_5(I)$에 $3\times3$ 합성곱을 적용하여 클래스 수 $C$와 동일한 채널 차원을 가지는 첫 번째 거친 분할 맵 $s_1(I)$를 생성합니다.
        $$s_1(I) = \text{conv}_{3\times3}(f_5(I))$$
        이 $s_1(I)$에 대해 리사이즈된 Ground Truth $R_1(Y)$와 비교하여 첫 번째 손실 함수 $\mathcal{L}_1$ (크로스 엔트로피 손실)을 정의합니다.
        $$\mathcal{L}_1 = \text{Loss}(R_1(Y), \text{softmax}(s_1(I)))$$
    2.  **점진적 정제 ($s_k(I)$ for $k>1$):** 이후의 더 미세한 분할 맵 $s_k(I)$ (k > 1)를 얻기 위해 **정제 모듈(Refinement Module, RE)**을 사용합니다.
        *   이전 단계의 분할 맵 $s_{k-1}(I)$를 업샘플링합니다.
        *   인코더 네트워크의 해당 합성곱 특징 맵 $f_{7-k}(I)$ (스킵 연결을 통해 연결)와 업샘플링된 $s_{k-1}(I)$를 `concat` (연결)합니다. 이 스킵 연결된 특징 맵은 더 정밀한 공간 정보를 제공합니다.
        *   연결된 특징 맵에 $3\times3$ 합성곱을 적용하여 채널 차원을 클래스 수 $C$로 변환하여 $s_k(I)$를 생성합니다.
        *   이 $s_k(I)$에 대해 해당 크기로 리사이즈된 Ground Truth $R_k(Y)$와 비교하여 손실 함수 $\mathcal{L}_k$를 정의합니다.
        $$s_k(I) = \text{conv}_{3\times3}(\text{concat}(\text{upsample}(s_{k-1}(I)), f_{7-k}(I)))$$
        $$\mathcal{L}_k = \text{Loss}(R_k(Y), \text{softmax}(s_k(I))), \quad \text{where } k=2, \ldots, 6$$

*   **총 손실 함수:** 네트워크는 모든 단계의 손실 함수 $\sum_{k=1}^6 \mathcal{L}_k$의 합을 최적화하여 end-to-end 방식으로 학습됩니다.
*   **학습 상세:** 사전 학습된 VGG-16 네트워크를 인코더 네트워크에 미세 조정(fine-tuning)하여 사용합니다.

## 📊 Results
LRN은 여러 표준 데이터셋에서 최신 기준선 모델 대비 우수한 성능을 달성했습니다.

*   **PASCAL VOC 2012:**
    *   Mean IoU(Intersection over Union) 64.2%를 달성하여 FCN-8s(62.2%), SegNet(59.1%), SegNet+DS(61.1%)를 능가했습니다.
    *   특히, 객체의 미묘한 디테일을 보존하는 데 LRN이 더 효과적임을 질적 결과(Fig. 4)와 단계별 시각화(Fig. 5)를 통해 보여주었습니다.

*   **CamVid (자동차 운전 환경):**
    *   Mean IoU 61.7%를 기록하여 SegNet(50.2%) 및 SegNet+DS(53.7%)를 크게 앞섰습니다.
    *   작은 객체 범주(예: 전봇대, 표지판, 자전거 탑승자)의 모양을 정확하게 유지하는 데 강점을 보였습니다.

*   **SUN RGB-D (실내 장면):**
    *   Mean IoU 33.1%를 달성하여 SegNet(26.3%) 및 SegNet+DS(31.2%) 대비 더 나은 성능을 보여주었습니다.

*   **단계별 분석 (Ablation Study):**
    *   PASCAL VOC 2012, CamVid, SUN RGB-D 데이터셋 모두에서 디코더의 초기 단계 레이블 맵 $s_1$부터 최종 $s_6$까지 Mean IoU가 점진적으로 향상됨을 확인했습니다 (Table 4). 이는 coarse-to-fine 정제 방식이 효과적임을 입증합니다.

## 🧠 Insights & Discussion
*   **Coarse-to-Fine 정제의 효율성:** 네트워크의 디코더에서 점진적으로 미세한 분할 맵을 생성하는 coarse-to-fine 방식은 이미지 디테일을 효과적으로 복원하고 전반적인 분할 정확도를 향상시킵니다. 특히, 초기 단계에서 놓쳤던 객체의 부분들(예: 사람 다리, 양의 다리)을 후반 단계에서 점진적으로 복원하는 모습이 관찰되었습니다.
*   **심층 감독 및 스킵 연결의 기여:** 네트워크의 여러 단계에 손실 함수를 추가하는 심층 감독과 인코더-디코더 간의 스킵 연결을 통해 제공되는 미세한 특징 맵의 통합은 성능 향상에 크게 기여합니다.
*   **작은 객체 처리 능력 강화:** LRN은 특히 CamVid 데이터셋의 전봇대나 표지판과 같이 작고 가는 객체에 대한 분류에서 뛰어난 성능을 보였습니다. 이는 인코더와 디코더 네트워크 간의 순환 연결된 가중치와 스킵 연결을 통한 픽셀들의 가중치 합산 덕분입니다. 이 메커니즘은 풀링 레이어에서 손실될 수 있는 작은 객체들의 디테일을 복원하는 데 도움을 줍니다.
*   **모델의 일반성:** 제안된 아키텍처는 의미론적 분할 외에도 다양한 픽셀 단위 레이블링 문제에 적용될 수 있는 잠재력을 가지고 있습니다. Coarse-to-fine 예측, 심층 감독, 스킵 연결 등 제안된 구조적 변경 사항들은 다양한 CNN 모델의 성능 개선에 기여할 수 있음을 시사합니다.

## 📌 TL;DR
본 논문은 픽셀 단위 의미론적 분할을 위한 **Label Refinement Network (LRN)**를 제안합니다. LRN은 **coarse-to-fine** 방식으로 여러 해상도에서 분할 레이블을 예측하며, **심층 감독**을 위해 네트워크의 각 단계에 손실 함수를 적용합니다. 또한, 거친 레이블과 인코더의 합성곱 특징을 **스킵 연결**을 통해 결합하여 점진적으로 더 정밀한 분할 맵을 생성합니다. 실험 결과, LRN은 PASCAL VOC 2012, CamVid, SUN RGB-D 등 표준 데이터셋에서 기존 모델들을 능가하는 성능을 보였으며, 특히 **작은 객체**의 섬세한 디테일 복원 및 분류에서 뛰어난 효과를 입증했습니다.