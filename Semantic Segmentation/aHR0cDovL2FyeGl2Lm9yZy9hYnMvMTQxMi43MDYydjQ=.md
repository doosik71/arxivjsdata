# SEMANTIC IMAGE SEGMENTATION WITH DEEP CONVOLUTIONAL NETS AND FULLY CONNECTED CRFS

Liang-Chieh Chen, George Papandreou, Iasonas Kokkinos, Kevin Murphy, Alan L. Yuille

## 🧩 Problem to Solve

이 논문은 픽셀 수준의 이미지 분류 작업인 "의미론적 이미지 분할(Semantic Image Segmentation)"의 정확도를 높이는 것을 목표로 합니다. 기존 심층 컨볼루션 신경망(DCNN)은 이미지 분류 및 객체 감지와 같은 고수준 시각 작업에서 뛰어난 성능을 보였지만, 내재된 불변성 특성과 반복적인 풀링(pooling) 및 다운샘플링으로 인해 최종 레이어의 응답이 충분히 로컬화되지 못하여 정확한 객체 경계 분할에 어려움이 있었습니다. 이로 인해 세밀한 공간적 정확도가 필요한 픽셀 수준 분류에서 제한적인 성능을 보였습니다.

## ✨ Key Contributions

- DCNN과 완전 연결 조건부 확률장(Fully Connected Conditional Random Field, CRF)을 결합하여 픽셀 수준 분류의 정밀도를 획기적으로 향상시켰습니다.
- "atrous(홀) 알고리즘"을 활용하여 DCNN 응답을 효율적으로 조밀하게 계산함으로써, 기존 방법 대비 훨씬 빠르고 복잡도를 줄였습니다.
- PASCAL VOC-2012 의미론적 이미지 분할 챌린지에서 71.6%의 IOU(Intersection-Over-Union) 정확도를 달성하여 새로운 최고 성능을 기록했습니다.
- 정확한 객체 경계를 재구성하는 DeepLab 시스템의 뛰어난 능력을 정성적, 정량적으로 입증했습니다.
- 두 가지 잘 확립된 모듈(DCNN과 CRF)의 조합으로 시스템의 단순성과 효율성을 강조했습니다.

## 📎 Related Works

이 논문은 기존 의미론적 분할 접근 방식과 비교하여 자신들의 방법을 차별화합니다.

- **2단계 접근 방식과의 차이:** 객체 탐지나 초픽셀(superpixel) 표현을 사용하여 분할을 먼저 수행하고 DCNN을 적용하는 방식(예: Arbeláez et al., Uijlings et al., Girshick et al., Mostajabi et al.)과 달리, 본 시스템은 픽셀 표현에 직접 작동합니다. 이는 전처리 단계의 잠재적 오류에 의존하지 않는 장점이 있습니다.
- **다른 DCNN 기반 분할과의 차이:**
  - Farabet et al. (2013)은 여러 이미지 해상도에 DCNN을 적용하고 분할 트리를 사용했습니다.
  - Hariharan et al. (2014a)은 DCNN 내의 중간 특징 맵을 연결하여 픽셀 분류에 활용했습니다.
  - Long et al. (2014) 및 Eigen & Fergus (2014)는 DCNN을 전체 이미지에 직접 적용하고, 마지막 완전 연결 레이어를 컨볼루션 레이어로 대체하는 방식(Fully Convolutional Networks, FCN)을 사용했습니다. 이들은 공간적 정확도 문제를 해결하기 위해 특징 맵을 업샘플링하거나 다른 DCNN으로 정제했지만, DeepLab은 atrous 알고리즘을 사용하여 이보다 더 효율적으로 조밀한 스코어를 얻습니다.
- **CRF 활용 방식의 차이:**
  - 기존 CRF는 주로 노이즈가 있는 분할 맵을 스무딩하거나(Rother et al., Kohli et al.), 초픽셀을 노드로 사용하는 지역 쌍별 CRF(Farabet et al.)로 사용되었습니다.
  - 본 논문은 Krähhenbühl & Koltun (2011)의 완전 연결 CRF 모델을 DCNN의 출력과 결합하여, 모든 픽셀을 CRF 노드로 취급하고 장거리 의존성을 활용하며, DCNN 기반 비용 함수를 직접 최적화합니다. 이는 기존 방법보다 훨씬 세밀한 경계 복구가 가능하게 합니다.
- **동시 연구:** 논문 발표 이후 Bell et al. (2014)과 Zheng et al. (2015) 등 유사한 방향으로 DCNN과 완전 연결 CRF를 결합한 다른 연구들이 독립적으로 진행되었음을 언급합니다.

## 🛠️ Methodology

본 논문은 의미론적 이미지 분할을 위해 VGG-16 DCNN과 완전 연결 CRF를 결합하는 DeepLab 시스템을 제안합니다.

1. **DCNN 재설계 및 밀집 특징 추출:**

   - **네트워크 재활용:** ImageNet에서 사전 학습된 16-레이어 VGG-16 네트워크를 사용합니다.
   - **완전 컨볼루션 변환:** VGG-16의 완전 연결(Fully Connected, FC) 레이어를 컨볼루션 레이어로 변환하여 원본 해상도 이미지에 대해 컨볼루션 방식으로 실행합니다.
   - **Atrous(홀) 알고리즘 적용:** DCNN의 출력 스트라이드를 32픽셀에서 8픽셀로 줄여 더 조밀한 스코어를 얻기 위해, 마지막 두 맥스 풀링(max-pooling) 레이어 이후의 서브샘플링을 건너뛰고, 이어지는 컨볼루션 필터에 0을 삽입(또는 특징 맵을 드문드문 샘플링)하여 수용장(receptive field) 크기를 유지하면서 출력 해상도를 높입니다. 이는 효율적인 밀집 특징 맵 계산을 가능하게 합니다.
   - **수용장 크기 제어:** 첫 번째 FC 레이어의 공간 크기를 $7 \times 7$에서 $4 \times 4$ 또는 $3 \times 3$으로 공간적으로 서브샘플링하여 네트워크의 수용장 크기를 제어하고 계산 시간을 단축합니다.
   - **학습:** VGG-16 네트워크의 가중치를 PASCAL VOC 21-방향 픽셀 분류 작업에 맞게 파인튜닝합니다. 손실 함수는 DCNN 출력 맵의 각 공간 위치에 대한 교차 엔트로피 항의 합입니다.
   - **추론:** 테스트 시에는 DCNN에서 나온 조밀한 스코어 맵(로그 확률)을 간단한 이중선형 보간(bilinear interpolation)을 사용하여 8배 확대하여 원본 이미지 해상도와 맞춥니다.
   - **멀티스케일 예측:** 입력 이미지와 첫 4개의 맥스 풀링 레이어 각각의 출력에 MLP(Multi-Layer Perceptron)를 연결하여 중간 레이어의 특징 맵을 활용함으로써 경계 지역의 국지화 정확도를 높입니다.

2. **완전 연결 CRF 적용:**
   - DCNN에서 얻은 스코어 맵을 입력으로 받아 객체 경계를 세밀하게 다듬기 위해 완전 연결 CRF를 적용합니다.
   - **에너지 함수:** $E(x) = \sum_{i} \theta_{i}(x_{i}) + \sum_{ij} \theta_{ij}(x_{i},x_{j})$
     - **단항 포텐셜(Unary Potential) $\theta_{i}(x_{i})$:** DCNN이 계산한 픽셀 $i$의 레이블 할당 확률 $P(x_{i})$의 음수 로그 값($-\log P(x_{i})$)을 사용합니다.
     - **쌍별 포텐셜(Pairwise Potential) $\theta_{ij}(x_{i},x_{j})$:** $\mu(x_{i},x_{j}) = 1$ (만약 $x_{i} \ne x_{j}$일 경우, Potts 모델)인 경우에만 활성화되며, 픽셀 $i$와 $j$ 사이의 거리와 색상 유사도를 인코딩하는 두 개의 가우시안 커널의 합으로 구성됩니다.
       $$ w*1 \exp \left( - \frac{||p_i - p_j||^2}{2\sigma*\alpha^2} - \frac{||I*i - I_j||^2}{2\sigma*\beta^2} \right) + w*2 \exp \left( - \frac{||p_i - p_j||^2}{2\sigma*\gamma^2} \right) $$
            여기서 $p$는 픽셀 위치, $I$는 픽셀 색상 강도를 나타내며, $\sigma_\alpha, \sigma_\beta, \sigma_\gamma$는 가우시안 커널의 "스케일"을 제어하는 하이퍼파라미터입니다.
   - **효율적인 추론:** 완전 연결 CRF는 평균장(mean field) 근사를 통해 효율적으로 근사 추론이 가능하며, 고차원 필터링 알고리즘으로 계산 속도를 더욱 높입니다 (Pascal VOC 이미지 당 평균 0.5초 미만).
   - **학습:** DCNN 학습이 완료된 후, CRF 모델의 파라미터($w_1, \sigma_\alpha, \sigma_\beta$)는 검증 세트의 일부에서 교차 검증을 통해 최적화됩니다.

## 📊 Results

- **PASCAL VOC 2012 성능:** 'trainval' 세트에서 학습하고 'test' 세트에서 평가했을 때, 최고 모델인 DeepLab-MSc-CRF-LargeFOV가 **71.6%의 평균 IOU 정확도**를 달성하여 당시 SOTA를 기록했습니다.
- **CRF의 효과:** DCNN 단독 모델(DeepLab) 대비 완전 연결 CRF를 추가한 DeepLab-CRF 모델은 PASCAL 'val' 세트에서 약 **4%p의 IOU 정확도 향상**(59.8% $\rightarrow$ 63.7%)을 보였습니다. 이는 객체 경계를 정확하게 포착하는 데 CRF가 매우 효과적임을 입증합니다.
- **멀티스케일 특징의 효과:** 멀티스케일 특징(DeepLab-MSc)을 추가하면 약 1.5%p의 성능 향상이 있었으며, 여기에 CRF를 결합했을 때 더욱 큰 시너지 효과를 보였습니다.
- **수용장(Field of View, FOV) 제어:** atrous 알고리즘을 통해 DCNN의 FOV를 조절할 수 있음을 보여주었으며, 큰 FOV(LargeFOV)를 가진 모델들이 더 나은 성능을 보였습니다. DeepLab-CRF-LargeFOV는 DeepLab-CRF-7x7과 동일한 70.3% IOU를 달성하면서도 훨씬 빠르고 적은 파라미터를 가졌습니다.
- **경계 정확도:** 'void' 레이블 주변의 좁은 밴드(trimap) 내에서 픽셀 정확도 및 평균 IOU를 측정했을 때, 멀티스케일 특징과 완전 연결 CRF가 객체 경계 주변의 분할 정확도를 크게 향상시켰습니다.
- **정성적 비교:** FCN-8s나 TTI-Zoomout-16과 같은 다른 SOTA 모델들과 비교했을 때, DeepLab-CRF는 복잡한 객체 경계를 더 잘 포착하는 능력을 시각적으로 입증했습니다.

## 🧠 Insights & Discussion

- 이 연구는 심층 컨볼루션 신경망의 객체 인식 능력과 완전 연결 조건부 확률장의 세밀한 국지화 정확도를 결합함으로써 의미론적 이미지 분할의 성능을 크게 향상시킬 수 있음을 보여주었습니다.
- DCNN이 가진 고수준의 불변성 특성이 픽셀 수준의 정확한 경계 분할에는 한계로 작용하지만, CRF를 후처리 단계에 효과적으로 통합함으로써 이 문제를 극복할 수 있었습니다.
- 특히, atrous(홀) 알고리즘의 적용은 DCNN 응답의 밀도를 높여 계산 효율성을 확보하면서도 정확도 손실 없이 효과적인 성능 향상을 이끌어냈습니다.
- 본 연구는 DCNN과 확률적 그래픽 모델이라는 두 가지 강력한 방법론의 시너지 잠재력을 강조하며, 향후 두 주요 구성 요소를 완전하게 통합하고 end-to-end 방식으로 학습하는 방향으로 연구를 확장할 계획을 제시합니다.
- 또한, 더 많은 데이터셋과 다양한 데이터 소스(깊이 맵, 비디오)에 대한 적용, 그리고 약한 지도(weakly supervised) 학습 방식에 대한 가능성도 언급합니다.

## 📌 TL;DR

DCNN은 고수준 시각 작업에 강하지만 픽셀 분할의 정밀 국지화는 부족했습니다. 이 논문은 이 문제를 해결하기 위해 **Atrous(홀) 알고리즘**으로 조밀한 DCNN 특징 맵을 효율적으로 생성하고, 이를 **완전 연결 CRF**와 결합한 "DeepLab" 시스템을 제안했습니다. 그 결과, PASCAL VOC 2012에서 **71.6% IOU**라는 최고 성능을 달성하며, DCNN의 인식 능력과 CRF의 세밀한 경계 복원 능력을 성공적으로 융합했음을 입증했습니다.
