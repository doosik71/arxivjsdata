{
  "url": "http://arxiv.org/abs/2006.10511v2",
  "title": "Contrastive learning of global and local features for medical image\n  segmentation with limited annotations",
  "authors": "Krishna Chaitanya, Ertunc Erdil, Neerav Karani, Ender Konukoglu",
  "year": 2020,
  "abstract": "A key requirement for the success of supervised deep learning is a large\nlabeled dataset - a condition that is difficult to meet in medical image\nanalysis. Self-supervised learning (SSL) can help in this regard by providing a\nstrategy to pre-train a neural network with unlabeled data, followed by\nfine-tuning for a downstream task with limited annotations. Contrastive\nlearning, a particular variant of SSL, is a powerful technique for learning\nimage-level representations. In this work, we propose strategies for extending\nthe contrastive learning framework for segmentation of volumetric medical\nimages in the semi-supervised setting with limited annotations, by leveraging\ndomain-specific and problem-specific cues. Specifically, we propose (1) novel\ncontrasting strategies that leverage structural similarity across volumetric\nmedical images (domain-specific cue) and (2) a local version of the contrastive\nloss to learn distinctive representations of local regions that are useful for\nper-pixel segmentation (problem-specific cue). We carry out an extensive\nevaluation on three Magnetic Resonance Imaging (MRI) datasets. In the limited\nannotation setting, the proposed method yields substantial improvements\ncompared to other self-supervision and semi-supervised learning techniques.\nWhen combined with a simple data augmentation technique, the proposed method\nreaches within 8% of benchmark performance using only two labeled MRI volumes\nfor training, corresponding to only 4% (for ACDC) of the training data used to\ntrain the benchmark. The code is made public at\nhttps://github.com/krishnabits001/domain_specific_cl."
}