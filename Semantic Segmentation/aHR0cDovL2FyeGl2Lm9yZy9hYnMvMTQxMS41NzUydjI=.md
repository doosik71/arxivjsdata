# Hypercolumns for Object Segmentation and Fine-grained Localization
Bharath Hariharan, Pablo Arbeláez, Ross Girshick, Jitendra Malik

## 🧩 Problem to Solve
컨볼루션 신경망(CNN)은 이미지 분류와 같은 전역적인 인식 작업에서 뛰어난 성능을 보이지만, 객체 분할, 키포인트 위치 파악, 부분 레이블링과 같은 정밀한(fine-grained) 위치 파악 작업에는 한계가 있습니다. 이는 CNN의 마지막 레이어는 높은 수준의 의미론적 정보를 포함하지만 공간 해상도가 너무 낮아 정확한 위치를 파악하기 어렵기 때문입니다. 반대로 초기 레이어는 공간 해상도가 높지만 의미론적 정보가 부족합니다. 따라서 두 가지 장점을 모두 활용하여 픽셀 단위의 정밀한 위치 파악을 가능하게 하는 특징 표현이 필요합니다.

## ✨ Key Contributions
*   **하이퍼컬럼(Hypercolumn) 개념 제안**: 특정 픽셀 위치에서 CNN의 모든 레이어에 걸쳐 해당 픽셀 '위'에 있는 유닛들의 활성화 값들을 하나의 벡터로 쌓아 올린 "하이퍼컬럼"을 픽셀 디스크립터로 정의했습니다.
*   **다양한 미세 위치 파악 작업 성능 향상**:
    *   **동시 검출 및 분할(SDS)**: 기존 최신 기술(49.7 mean AP$_r$)을 60.0으로 크게 향상시켰습니다.
    *   **키포인트 위치 파악**: 기존 접근 방식 대비 3.3점의 성능 향상을 달성했습니다.
    *   **객체 부분 레이블링**: 강력한 베이스라인 대비 평균 6.6점의 성능 향상을 보여주었습니다.
*   **통합된 프레임워크 제시**: 다양한 미세 위치 파악 문제를 픽셀 분류 문제로 통합하고, 하이퍼컬럼을 픽셀 디스크립터로 사용하여 엔드-투-엔드 학습이 가능한 일반적인 신경망 기반 시스템을 제안했습니다.

## 📎 Related Works
*   **다중 레벨 특징 결합**: 라플라시안 피라미드 [8], 'jets' [27], 필터 뱅크 [32] 등 전통적인 컴퓨터 비전에서 다중 스케일/레벨 특징을 결합하는 연구가 있었습니다. CNN에서는 Farabet et al. [15]이 다중 스케일 CNN 출력을, Tompson et al. [37]이 자세 추정에 유사한 아이디어를 사용했습니다. Sermanet et al. [34]은 중간 레이어를 최상위 레이어와 결합했지만, 본 연구는 하위 레이어의 고해상도를 유지하고 상위 레이어를 업샘플링하여 정밀한 위치 파악에 중점을 둡니다. Long et al. [30]도 완전 컨볼루션 네트워크에서 여러 레이어를 사용했습니다.
*   **검출 및 분할**: Hariharan et al. [22]에 의해 소개된 동시 검출 및 분할(SDS)은 바운딩 박스 검출과 시맨틱 분할의 요구 사항을 모두 충족합니다. Borenstein & Ullman [4], Yang et al. [42], Parkhi et al. [33], Dai & Hoiem [12] 등은 바운딩 박스 검출에서 시작하여 인스턴스 분할을 수행했습니다. Girshick et al. [18]과 Hariharan et al. [22]를 비롯한 최근 방법들은 CNN을 사용하여 상향식(bottom-up) 객체 제안(proposal)을 평가합니다.
*   **자세 추정 및 부분 레이블링**: Toshev & Szegedy [38]와 Tompson et al. [37]은 CNN 기반의 자세 추정에서 뛰어난 성능을 보였습니다. Yang & Ramanan [43]과 Gkioxari et al. [21, 20]은 검출 설정에서 사람의 키포인트를 파악하는 연구를 수행했습니다. Yamaguchi et al. [41, 40]과 Luo et al. [31]은 객체 파싱(parsing) 또는 의류 항목 분할과 같은 객체 부분 레이블링에 대해 연구했습니다.

## 🛠️ Methodology
1.  **하이퍼컬럼 특징 추출**:
    *   객체 검출 시스템에서 얻은 바운딩 박스를 잘라 고정된 크기로 조정하고 CNN(예: Krizhevsky et al. [28]의 T-Net 아키텍처)에 입력합니다.
    *   CNN의 각 레이어 출력은 특징 맵(feature map)입니다. 풀링(pooling) 등으로 인해 해상도가 다른 특징 맵들은 bilinear interpolation을 사용하여 원하는 해상도(예: 50x50)로 업샘플링합니다.
    *   각 픽셀 위치에 대해, 업샘플링된 여러 레이어(예: `pool2`, `conv4`, `fc7`)의 해당 픽셀 활성화 값들을 연결하여 하나의 긴 특징 벡터, 즉 하이퍼컬럼을 생성합니다.

2.  **분류기 그리드 보간**:
    *   픽셀의 위치 정보가 중요하므로, 단일 분류기 대신 $K \times K$ ($K=5$ 또는 $10$) 격자의 분류기(로지스틱 회귀)를 훈련합니다.
    *   훈련 시에는 각 훈련 바운딩 박스를 $K \times K$ 격자로 나누고, 각 분류기는 해당 격자 셀의 픽셀 데이터만으로 훈련됩니다.
    *   테스트 시에는 각 픽셀 $i$의 예측 확률 $p_i$를 주변 격자 분류기 $g_k(\cdot)$의 출력 $p_{ik} = g_k(f_i)$을 보간하여 계산합니다: $p_i = \sum_k \alpha_{ik} p_{ik}$. 여기서 $\alpha_{ik}$는 픽셀 위치에 따라 달라지는 가중치입니다.

3.  **효율적인 분류 및 신경망 표현**:
    *   하이퍼컬럼 특징에 선형 분류기를 적용하는 과정은 각 특징 맵에 $1 \times 1$ 컨볼루션을 적용하여 점수 맵(score map)을 생성한 후, 이 점수 맵들을 업샘플링하여 합산하는 것으로 효율적으로 구현될 수 있습니다.
    *   $1 \times 1$ 컨볼루션을 더 일반적인 $n \times n$ 컨볼루션으로 확장하여 픽셀 주변 영역의 활성화 패턴도 고려합니다.
    *   전체 파이프라인은 원본 CNN에 추가 레이어를 접목한 신경망으로 표현됩니다 (그림 2). 이 구조는 엔드-투-엔드 학습(사전 훈련된 네트워크를 미세 조정)을 가능하게 하며, 50x50의 목표 히트맵을 레이블로 사용하여 로지스틱 손실을 최소화합니다.

4.  **훈련 데이터 구성**:
    *   각 카테고리에 대해 ground truth 인스턴스와 70% 이상 겹치는 MCG(Multiscale Combinatorial Grouping) 후보를 긍정 샘플로 선택합니다.
    *   **SDS**: 인스턴스 내부 픽셀은 긍정, 외부는 부정.
    *   **부분 레이블링**: 특정 부분 내부 픽셀은 긍정, 나머지는 부정.
    *   **키포인트 예측**: 실제 키포인트 위치는 긍정, 특정 반경(바운딩 박스 대각선의 10%) 외부 픽셀은 부정.

## 📊 Results
*   **동시 검출 및 분할(SDS)**:
    *   **System 1 (하이퍼컬럼 기반 개선)**: 기존 [22]의 49.7 mean AP$_r$ (0.5)를 52.8로 향상시켰고, 0.7 AP$_r$에서는 25.3에서 33.7로 크게 개선되었습니다. (T-Net 아키텍처)
    *   **System 2 (바운딩 박스 검출에서 시작)**: 효율성을 높이면서도 O-Net 아키텍처를 사용하여 56.5 mean AP$_r$ (0.5) 및 37.0 mean AP$_r$ (0.7)를 달성했습니다. 최종 파이프라인은 60.0 mean AP$_r$ (0.5) 및 40.4 mean AP$_r$ (0.7)로 당시 최첨단 성능을 기록했습니다. 하이퍼컬럼의 효과는 `fc7` 단독 사용 베이스라인과 비교하여 명확하게 드러났습니다.

*   **키포인트 예측**:
    *   VOC2009 `person` 카테고리에서 APK(Average Precision of Keypoints) 지표로 평가했습니다.
    *   미세 조정 없이 하이퍼컬럼을 사용했을 때 17.0 mean APK를 달성하여 기존 최신 기술 [20]의 15.2보다 1.8점 높았습니다.
    *   네트워크 미세 조정을 통해 18.5 mean APK를 달성하여 총 3.3점 개선을 이루었습니다. `fc7`만 사용한 베이스라인(10.6)은 훨씬 낮은 성능을 보였습니다.

*   **부분 레이블링**:
    *   PASCAL VOC의 관절 객체(person, horse, cow, sheep, cat, dog, bird)에 대해 AP$_r$part 지표로 평가했습니다.
    *   하이퍼컬럼 접근 방식(Hyp)은 `fc7` 단독 베이스라인 대비 거의 모든 카테고리에서 큰 성능 향상을 보였습니다 (예: Person 21.9% $\rightarrow$ 28.5%, Horse 16.6% $\rightarrow$ 27.8%). 이는 부분 레이블링의 정확도 향상 때문임을 확인했습니다.

## 🧠 Insights & Discussion
*   하이퍼컬럼 표현은 CNN의 초기 레이어가 가진 공간적 정밀도와 후기 레이어가 가진 의미론적 깊이를 성공적으로 결합하여, 픽셀 단위의 정밀한 위치 파악이 필요한 다양한 fine-grained 작업에서 큰 성능 향상을 가져왔습니다.
*   제안된 방법은 기존의 무거운 파이프라인을 효율적으로 개선하거나, 바운딩 박스 검출에서 직접 고품질 분할을 예측하는 새로운 효율적인 파이프라인을 구축하는 데 성공했습니다.
*   하이퍼컬럼의 유효성은 사용된 특정 CNN 아키텍처(T-Net, O-Net)에 관계없이 일관되게 나타나, 이 표현이 가진 일반적인 강점을 시사합니다.
*   본 연구는 객체 분할 및 위치 파악에 초점을 맞추었지만, 속성 분류나 행동 분류와 같은 다른 fine-grained 비전 작업에서도 하이퍼컬럼이 유용할 수 있음을 시사하며, 이는 향후 연구 과제로 남겨두었습니다.

## 📌 TL;DR
**문제**: 기존 CNN은 상위 레이어의 공간 해상도 부족으로 정밀한 픽셀 수준의 객체 분할 및 위치 파악에 한계가 있었습니다.
**해결책**: 이 논문은 "하이퍼컬럼"이라는 새로운 특징 표현을 제안합니다. 이는 각 픽셀에 대해 CNN의 모든 레이어에서 해당 픽셀 위에 있는 활성화 값들을 결합한 벡터입니다. 이 하이퍼컬럼을 픽셀 디스크립터로 사용하여, KxK 분류기 그리드와 보간법을 통해 위치 의존적인 픽셀 분류를 수행하는 엔드-투-엔드 학습 가능한 신경망 프레임워크를 구축했습니다.
**주요 결과**: 하이퍼컬럼은 동시 검출 및 분할(SDS), 키포인트 예측, 객체 부분 레이블링과 같은 미세 위치 파악 작업에서 기존 최신 기술 대비 상당한 성능 향상을 달성하여, 공간적 정밀도와 의미론적 깊이를 성공적으로 통합하는 강력한 방법을 제시했습니다.