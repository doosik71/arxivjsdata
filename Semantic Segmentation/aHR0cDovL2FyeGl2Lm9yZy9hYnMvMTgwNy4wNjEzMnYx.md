# Effective Use of Synthetic Data for Urban Scene Semantic Segmentation

Fatemeh Sadat Saleh, Mohammad Sadegh Aliakbarian, Mathieu Salzmann, Lars Petersson, and Jose M. Alvarez

## 🧩 Problem to Solve

의미론적 분할(Semantic Segmentation)을 위한 딥 네트워크 훈련은 막대한 양의 레이블링된 데이터를 필요로 합니다. 실제 이미지에 대한 수동 주석 작업은 매우 비용이 많이 들기 때문에, 자동으로 레이블링될 수 있는 합성 데이터(Synthetic Data)의 활용이 연구되어 왔습니다. 그러나 합성 데이터로 훈련된 네트워크는 실제 이미지에서 성능이 현저히 떨어지는 "도메인 시프트(Domain Shift)" 문제를 겪습니다. 기존의 도메인 적응(Domain Adaptation) 방법들은 훈련 시 실제 이미지에 접근해야 한다는 제약이 있어, 새로운 실제 환경에 모델을 바로 배포하기 어렵습니다.

## ✨ Key Contributions

* **도메인 시프트에 대한 새로운 접근 방식:** 합성 데이터만으로 훈련하면서도 실제 이미지에서 효과적인 성능을 달성하는 새로운 방법론을 제시합니다. 이는 훈련 시 실제 이미지를 전혀 사용하지 않습니다.
* **전경 및 배경 클래스의 차등 처리:** 전경(foreground) 클래스와 배경(background) 클래스가 도메인 시프트의 영향을 다르게 받는다는 핵심 관찰을 기반으로 합니다.
  * 합성 이미지에서 전경 객체의 **모양(shape)**은 사실적이지만 **질감(texture)**은 비현실적입니다.
  * 배경 클래스의 **질감**은 비교적 사실적입니다.
* **하이브리드 분할 프레임워크 제안:** 전경 클래스에는 객체 탐지 기반(detection-based) 접근 방식(Mask R-CNN)을, 배경 클래스에는 표준 의미론적 분할 네트워크(DeepLab)를 사용하여 이 두 가지 유형의 예측을 결합합니다.
* **VEIS(Virtual Environment for Instance Segmentation) 환경 및 데이터셋 소개:** 기존 합성 데이터셋의 한계를 극복하기 위해 모든 전경 클래스에 대한 인스턴스 수준(instance-level) 분할 주석을 자동으로 제공하는 새로운 가상 환경과 데이터셋을 개발했습니다.
* **우수한 성능 입증:** Cityscapes 및 CamVid 데이터셋에서 기존 합성 데이터 훈련 방식과 최신 도메인 적응 기법들을 능가하는 성능을 보였습니다. 훈련 시 비지도(unsupervised) 실제 이미지를 활용하면 성능이 더욱 향상될 수 있음을 보여주었습니다.

## 📎 Related Works

* **의미론적 분할(Semantic Segmentation):** 픽셀 수준 이미지 이해를 목표로 하는 연구 (e.g., DeepLab, FCN).
* **약지도 의미론적 분할(Weakly-supervised Semantic Segmentation):** 이미지 태그, 바운딩 박스, 스크리블 등 약한 형태의 주석을 활용하는 방법.
* **합성 데이터셋(Synthetic Datasets):** 컴퓨터 그래픽스를 통해 자동 레이블링된 데이터를 생성 (e.g., SYNTHIA [37], GTA5 [36], VIPER [35]).
* **도메인 적응(Domain Adaptation):** 합성-실제 데이터 간의 도메인 시프트 문제를 해결하기 위해 특징 분포를 정렬하는 방법 (e.g., 도메인 적대적 훈련 [12,13], Cycle-GAN 기반 접근 [19,27]).

## 🛠️ Methodology

1. **전경 및 배경 분할 네트워크 훈련:**
    * **배경 클래스 처리:** GTA5 [36] 데이터셋으로 VGG16 기반의 DeepLab 모델 [4]을 훈련합니다. 이 모델은 넓은 시야(large FOV)와 확장 컨볼루션 레이어(dilated convolution layers)를 사용하며, 실제와 유사한 질감을 가진 배경 클래스에 효과적입니다. (전경 클래스 예측은 나중에 대부분 폐기됨)
    * **전경 클래스 처리:** 저자들이 자체 개발한 VEIS 데이터셋으로 Mask R-CNN [16]을 훈련합니다. VEIS는 비현실적인 질감에도 불구하고 현실적인 모양을 가진 전경 객체에 대한 인스턴스 수준 주석을 자동으로 제공하여, 객체 탐지 및 이진 분할에 강점을 보입니다.
2. **실제 이미지 예측 및 융합:**
    * 훈련된 두 네트워크를 사용하여 실제 이미지에 대한 예측을 수행합니다.
    * **Mask R-CNN 예측 결합:** Mask R-CNN의 인스턴스 예측(bounding box, 이진 마스크, 클래스, 신뢰도)을 신뢰도 점수에 따라 정렬하고, 중첩되는 픽셀을 제거하며 (NMS-like), 단일 전경 분할 맵을 생성합니다.
    * **DeepLab 예측으로 빈 공간 채우기:** Mask R-CNN 예측 후 남은 빈 공간(전경 객체가 없는 영역)은 DeepLab 네트워크의 배경 클래스 예측으로 채웁니다. 각 픽셀은 DeepLab 결과에서 가장 높은 확률을 가진 배경 레이블을 할당받습니다.
3. **비지도 실제 이미지 활용 (선택 사항):**
    * 섹션 3.1에서 얻은 예측을 실제 이미지에 대한 "가짜 정답(pseudo ground-truth)" 레이블로 사용합니다.
    * Mask R-CNN 예측으로 채워진 영역 외의 DeepLab 전경 예측은 신뢰할 수 없으므로 '무시(ignore)' 레이블로 할당합니다.
    * 이 가짜 정답 레이블을 사용하여 새로운 DeepLab 네트워크를 실제 이미지로 훈련하여 성능을 더욱 향상시킵니다.
4. **VEIS 환경 및 데이터셋 구축:**
    * Unity3D [47] 엔진을 사용하여 도시 장면을 수동으로 설계하고 3D 객체를 추가합니다.
    * 각 객체 인스턴스에 고유 ID를 할당하여 인스턴스 수준의 픽셀 단위 레이블을 실시간으로 자동으로 생성합니다.
    * 61305프레임의 인스턴스 수준 의미론적 분할 주석을 포함하는 VEIS 데이터셋을 구축합니다.

## 📊 Results

* **Cityscapes 데이터셋:**
  * 제안하는 방법("Ours")은 GTA5, SYNTHIA, VIPER, VEIS 단독으로 DeepLab을 훈련한 경우보다 훨씬 우수한 성능을 보였습니다 (mIoU 38.0% vs. GTA5 31.3%).
  * 특히 전경 클래스(person, car, truck, bus 등)에서 성능 향상이 두드러집니다.
  * 훈련 시 실제 이미지를 전혀 사용하지 않았음에도 불구하고, 최신 도메인 적응 방법들 (FCNs in Wld [20], Curriculum [51], ROAD [6], CYCADA [19]) 및 약지도 학습 방법 [39]을 능가했습니다 (mIoU 38.0% vs. ROAD 35.9%).
  * 비지도 실제 이미지 활용("Ours&ps-GT") 시 mIoU는 42.5%로 더욱 향상되어, 모든 비교 방법 중 최고 성능을 달성했습니다.
* **CamVid 데이터셋:**
  * 유사한 경향을 보이며, "Ours" (mIoU 47.6%)는 약지도 방법 [39]과 합성 데이터로 훈련된 DeepLab보다 우수했으며, 일부 완전 지도(fully supervised) 방법보다도 좋은 결과를 보였습니다.
* **형태 vs. 질감 분석:**
  * 이진 분류기 실험 결과, 전경 객체의 실루엣(형태)만으로는 실제/합성 데이터를 70.0% 정확도로 구분하기 어려웠지만, 질감을 포함한 객체로는 95.1%의 정확도로 쉽게 구분할 수 있었습니다. 이는 질감이 도메인 시프트에 더 민감하며, 형태는 도메인 시프트에 더 강건하다는 주장을 뒷받침합니다.

## 🧠 Insights & Discussion

* 이 연구의 핵심 통찰은 도메인 시프트가 이미지 내의 모든 클래스에 동일하게 영향을 미치지 않는다는 점입니다. 특히, 전경 객체의 '모양' 정보는 합성 데이터에서도 실제와 유사하게 유지되므로, 이를 활용하는 탐지 기반 접근 방식이 효과적입니다. 반면 배경은 '질감' 정보가 중요하며, 비교적 사실적인 합성 데이터로 훈련된 분할 네트워크가 적합합니다.
* 제안된 방법은 훈련 시 실제 이미지에 전혀 접근하지 않아도 도메인 시프트 문제를 성공적으로 완화하며, 이는 모델 배포의 유연성을 크게 높입니다.
* 비지도 실제 이미지를 활용하는 경우 추가적인 성능 향상을 얻을 수 있으며, 이는 도메인 적응 방법들과 경쟁하는 수준을 넘어섭니다.
* 이 접근 방식은 기존 도메인 적응 기술과 직교(orthogonal)하므로, 향후에는 이 두 가지를 결합하여 더 나은 성능을 달성할 가능성이 있습니다.
* VEIS와 같은 새로운 합성 데이터셋은 비록 완벽하게 사실적이지 않더라도, 특정 정보(예: 객체 모양)를 풍부하게 제공한다면, 적절한 모델(예: 탐지 기반 모델)과 결합하여 실제 환경에서 의미 있는 성능 향상을 가져올 수 있음을 보여줍니다.

## 📌 TL;DR

레이블링 비용이 높은 실제 이미지 대신 합성 데이터로 의미론적 분할 모델을 훈련할 때 발생하는 도메인 시프트 문제를 해결하기 위해, 이 논문은 전경과 배경 클래스를 다르게 처리하는 새로운 방식을 제안합니다. 합성 이미지에서 전경 객체의 `모양`은 사실적이지만 `질감`은 그렇지 않고, 배경은 `질감`이 더 사실적이라는 관찰에 기반하여, 전경은 `Mask R-CNN` 같은 탐지 기반 모델로, 배경은 `DeepLab` 같은 분할 네트워크로 처리한 후 예측을 융합합니다. 또한, 인스턴스 수준 주석을 자동으로 생성하는 합성 데이터셋 `VEIS`를 소개합니다. 이 방법은 훈련 시 실제 이미지를 전혀 보지 않고도 Cityscapes와 CamVid에서 기존 합성 데이터 훈련 및 최신 도메인 적응 기법들을 뛰어넘는 성능을 달성했으며, 비지도 실제 이미지 활용 시 더욱 향상될 수 있음을 입증했습니다.
