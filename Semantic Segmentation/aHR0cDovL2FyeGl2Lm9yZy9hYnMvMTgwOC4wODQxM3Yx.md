# A Brief Survey and an Application of Semantic Image Segmentation for Autonomous Driving
Çağrı Kaymak, Ayşegül Uçar

## 🧩 Problem to Solve
자율 주행 차량은 주변 환경을 정확하게 인지하고 이해해야 안전하게 작동할 수 있습니다. 이를 위해서는 도로, 차량, 보행자 등 다양한 객체를 픽셀 단위로 분류하는 **시맨틱 이미지 분할(Semantic Image Segmentation)** 기술이 필수적입니다. 그러나 기존의 표준 CNN(Convolutional Neural Network) 아키텍처는 풀링(pooling) 및 완전 연결(fully connected) 레이어로 인해 공간 정보를 손실하는 문제가 있어 픽셀 수준의 분할 작업에 부적합합니다. 이 연구는 자율 주행을 위한 시맨틱 이미지 분할에서 심층 학습(Deep Learning) 기반의 FCN(Fully Convolutional Network) 아키텍처의 적용 가능성과 성능을 탐구합니다.

## ✨ Key Contributions
*   **심층 학습 및 FCN 아키텍처 적용**: 자율 주행을 위한 시맨틱 이미지 분할 애플리케이션에 FCN-AlexNet, FCN-8s, FCN-16s, FCN-32s 등 4가지 FCN 아키텍처를 적용했습니다.
*   **전이 학습(Transfer Learning)의 효과 입증**: 무작위 가중치 초기화 방식으로는 성능이 저조함을 확인하고, ImageNet 및 PASCAL VOC 데이터셋으로 사전 훈련된 모델을 전이 학습에 활용하여 성능을 크게 향상시켰습니다.
*   **FCN 아키텍처별 성능 비교**: 각 FCN 모델의 유효성 검사 정확도(validation accuracy)를 비교하고, 시각화를 통해 객체 분할의 정밀도를 분석했습니다. 특히 FCN-8s가 가장 선명하고 정확한 분할 결과를 제공함을 입증했습니다.
*   **SYNTIA-Rand-CVPR16 데이터셋 활용**: 가상 도시 환경에서 생성된 SYNTHIA-Rand-CVPR16 데이터셋을 사용하여 자율 주행 시나리오에서의 모델 성능을 평가했습니다.

## 📎 Related Works
*   **기존 이미지 해석 접근법**: 이미지 분류 [3], 객체 지역화 및 탐지 [4], 시맨틱 분할 [5] 등.
*   **초기 특징 추출 및 분류**: SIFT [7], LBP [8], HOG [9]와 같은 시각적 특징 추출기와 ANN, SVM [11], AdaBoost [12] 등의 분류기 활용.
*   **심층 학습의 부상**: 2006년 Hinton et al. [10]의 ANN 성공 이후, 대규모 데이터셋(ImageNet)과 GPU 기반 병렬 컴퓨팅의 발전으로 심층 학습의 성공 가속화.
*   **시맨틱 분할을 위한 FCN의 발전**:
    *   **Long, Shelhamer, Darrell [20]**: 분류용 CNN (VGG-16)을 FCN으로 전환하여 완전 연결 레이어를 합성곱 레이어로 대체하고, 역합성곱(deconvolutional) 레이어와 스킵 연결(skip connection)을 추가하여 FCN-8s, FCN-16s, FCN-32s를 제안.
    *   **Chen et al. [21]**: FCN 출력에 CRF(Conditional Random Field)를 적용하여 객체 경계 복원 개선.
    *   **Noh, Hong, Han [22]**: VGG-16 기반의 DeconvNet 아키텍처 제안.
    *   **Badrinarayanan, Kendall, Cipolla [27]**: SegNet 제안 (인코더-디코더 구조, 적은 파라미터). Bayesian SegNet [28] 확장.
    *   **자율 주행 관련 연구**: KITTI 데이터셋 활용 다중 데이터셋 학습 [29], 임베디드 시스템용 경량화 분할 네트워크 [30], 시뮬레이션 데이터셋(GTA5, SYNTHIA) 기반 실제 이미지 적응 연구 [31].

## 🛠️ Methodology
1.  **FCN 아키텍처 선정**:
    *   기존 이미지 분류용 CNN(AlexNet, VGG-16)을 기반으로 **FCN-AlexNet**, **FCN-8s**, **FCN-16s**, **FCN-32s** 아키텍처를 사용했습니다.
2.  **CNN을 FCN으로 전환**:
    *   기존 CNN의 완전 연결 레이어를 합성곱 레이어로 변환하여 임의 크기 입력 처리를 가능하게 했습니다.
    *   **역합성곱(Deconvolutional) 레이어 추가**: 공간 해상도를 원래 입력 이미지 크기로 복원하기 위해 업샘플링(upsampling) 레이어를 사용했습니다.
        *   FCN-AlexNet은 최종 합성곱 레이어의 출력을 32배 업샘플링합니다.
        *   FCN-32s는 VGG-16의 `conv7` 레이어를 32배 업샘플링합니다.
        *   **스킵 연결(Skip Connections) 활용**: FCN-16s와 FCN-8s는 VGG-16의 `pool4` (FCN-16s) 및 `pool3` (FCN-8s) 레이어의 낮은 수준 특징 맵을 최종 업샘플링된 출력과 결합하여 더 세밀한 객체 경계를 재구성합니다. FCN-8s는 8x8 픽셀 블록까지 미세 조정된 예측을 가능하게 합니다.
3.  **학습 환경 설정**:
    *   **플랫폼 및 하드웨어**: DIGITS 플랫폼의 Caffe 프레임워크를 사용했으며, NVIDIA GTX Titan X Pascal 12GB GDDR5X GPU를 활용했습니다.
    *   **데이터셋**: SYNTHIA-Rand-CVPR16 [40] 데이터셋을 사용했습니다. 이는 960x720 해상도의 13407개 RGB 이미지와 해당 그라운드 트루스(ground truth) 레이블 이미지로 구성되어 있으며, 12가지 객체 클래스(하늘, 건물, 도로, 보도, 울타리, 식물, 기둥, 자동차, 표지판, 보행자, 자전거 운전자, 빈 공간)를 포함합니다.
    *   **데이터 분할**: 전체 데이터셋의 약 80% (10726개 이미지)를 훈련에, 20% (2681개 이미지)를 검증에 사용했습니다.
    *   **하이퍼파라미터**: 기본 학습률 0.0001, 모멘텀 0.9, 가중치 감소 $10^{-6}$, 배치 크기 1, 감마 0.1, 최대 반복 횟수 321780 (30 에포크)으로 설정했습니다. 최적화 도구로는 SGD(Stochastic Gradient Descent)를 사용했습니다.
4.  **전이 학습 적용**:
    *   무작위 가중치 초기화 시 낮은 성능(약 35%)을 보였기 때문에, FCN-AlexNet은 ImageNet으로 사전 훈련된 AlexNet 모델을, FCN-8s, FCN-16s, FCN-32s는 PASCAL VOC 데이터셋으로 사전 훈련된 모델을 전이 학습하여 초기화했습니다.
    *   `net_surgery.py` 스크립트를 사용하여 완전 연결 레이어의 가중치를 합성곱 레이어로 변환하고, 업샘플링 레이어의 가중치는 이선형 보간(bilinear interpolation)으로 초기화했습니다.
5.  **성능 평가**:
    *   유효성 검사 정확도(Validation Accuracy)를 주요 지표로 사용하고, 시각적 분할 결과물을 분석하여 객체 경계의 선명도와 정확도를 평가했습니다.

## 📊 Results
*   **초기 훈련 (무작위 가중치 초기화)**: FCN-AlexNet의 유효성 검사 정확도는 약 35%에 불과했으며, 대부분의 픽셀을 '건물'로 분류하는 경향을 보였습니다. 이는 데이터셋 내에서 '건물' 클래스가 가장 대표적인 객체였기 때문으로 분석되었습니다.
*   **전이 학습 후 성능**:
    *   **FCN-AlexNet**: 사전 훈련된 모델을 사용한 결과, 유효성 검사 정확도가 29번째 에포크에서 최고 92.4628%에 도달했습니다. 하지만 시각화된 분할 결과에서 객체 윤곽이 여전히 거칠게 나타났습니다.
    *   **FCN-8s**: 사전 훈련된 모델을 사용한 결과, 유효성 검사 정확도가 30번째 에포크에서 최고 96.015%에 도달했습니다. 시각화 결과에서 객체 윤곽이 FCN-AlexNet보다 훨씬 선명하고, 그라운드 트루스 이미지와 유사하게 나타나며 작은 객체도 정확하게 분할했습니다.
    *   **FCN-16s**: 유효성 검사 정확도는 30번째 에포크에서 최고 95.4111%를 기록했습니다. FCN-AlexNet보다는 선명하지만 FCN-8s만큼은 아니었습니다.
    *   **FCN-32s**: 유효성 검사 정확도는 30번째 에포크에서 최고 94.2595%를 기록했습니다. FCN-AlexNet과 매우 유사한 분할 결과를 보였으나 약간의 개선이 있었습니다.
*   **훈련 시간**:
    *   FCN-AlexNet: 34121초
    *   FCN-8s: 128797초
    *   FCN-16s: 128909초
    *   FCN-32s: 130752초
    *   FCN-AlexNet이 다른 FCN 모델에 비해 훈련 시간이 약 1/4 수준으로 상당히 짧았습니다.

## 🧠 Insights & Discussion
*   **전이 학습의 중요성**: 심층 학습 모델의 성능을 향상시키는 데 전이 학습이 매우 중요함을 입증했습니다. 무작위 초기화 방식으로는 유효한 모델을 얻기 어려웠습니다.
*   **스킵 연결의 효과**: FCN-AlexNet(32x 예측)과 FCN-32s는 거친 객체 윤곽을 보였으며, 작은 픽셀 영역을 가진 객체(예: 기둥) 분할에 한계를 보였습니다. 반면, 스킵 연결을 사용하여 더 낮은 레이어의 세밀한 특징을 통합한 FCN-8s는 8x8 픽셀 블록까지 미세 조정된 예측을 통해 가장 선명하고 정확한 분할 결과를 제공했습니다. 이는 픽셀 단위 애플리케이션에서 스킵 연결의 중요성을 강조합니다.
*   **모델 선택**: 모든 FCN 모델이 90% 이상의 정확도를 보였지만, 시각적 분할 품질 측면에서는 FCN-8s가 가장 우수했습니다. 훈련 시간 측면에서는 FCN-AlexNet이 현저히 빨랐으나, 모델 훈련이 단 한 번 수행된다는 점을 고려할 때, 분할 품질이 더 중요한 지표가 됩니다. 따라서 자율 주행 시맨틱 이미지 분할 애플리케이션에는 FCN-8s가 가장 적합한 모델로 판단됩니다.
*   **FCN의 유용성**: 이 연구 결과는 FCN이 시맨틱 이미지 분할과 같은 픽셀 수준의 심층 학습 애플리케이션에 매우 적합한 네트워크 구조임을 보여줍니다.

## 📌 TL;DR
이 논문은 자율 주행을 위한 시맨틱 이미지 분할 문제를 해결하고자 합니다. 표준 CNN이 공간 정보를 손실하는 한계를 극복하기 위해, 완전 합성곱 신경망(FCN) 아키텍처인 FCN-AlexNet, FCN-8s, FCN-16s, FCN-32s를 SYNTHIA-Rand-CVPR16 데이터셋에 적용하고 그 성능을 비교했습니다. 실험 결과, 사전 훈련된 모델을 활용한 전이 학습이 모델 성능을 획기적으로 향상시켰으며, 특히 스킵 연결을 사용하는 FCN-8s가 96% 이상의 높은 정확도와 함께 가장 선명하고 정밀한 객체 분할 결과를 제공하여 자율 주행에 가장 적합한 모델임을 입증했습니다.