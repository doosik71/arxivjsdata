{
  "url": "http://arxiv.org/abs/2306.12156v1",
  "title": "Fast Segment Anything",
  "authors": "Xu Zhao, Wenchao Ding, Yongqi An, Yinglong Du, Tao Yu, Min Li, Ming Tang, Jinqiao Wang",
  "year": 2023,
  "abstract": "The recently proposed segment anything model (SAM) has made a significant\ninfluence in many computer vision tasks. It is becoming a foundation step for\nmany high-level tasks, like image segmentation, image caption, and image\nediting. However, its huge computation costs prevent it from wider applications\nin industry scenarios. The computation mainly comes from the Transformer\narchitecture at high-resolution inputs. In this paper, we propose a speed-up\nalternative method for this fundamental task with comparable performance. By\nreformulating the task as segments-generation and prompting, we find that a\nregular CNN detector with an instance segmentation branch can also accomplish\nthis task well. Specifically, we convert this task to the well-studied instance\nsegmentation task and directly train the existing instance segmentation method\nusing only 1/50 of the SA-1B dataset published by SAM authors. With our method,\nwe achieve a comparable performance with the SAM method at 50 times higher\nrun-time speed. We give sufficient experimental results to demonstrate its\neffectiveness. The codes and demos will be released at\nhttps://github.com/CASIA-IVA-Lab/FastSAM."
}