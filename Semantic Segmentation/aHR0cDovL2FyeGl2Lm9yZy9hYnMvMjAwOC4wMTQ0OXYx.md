# Prior Guided Feature Enrichment Network for Few-Shot Segmentation

Zhuotao Tian, Hengshuang Zhao, Michelle Shu, Zhicheng Yang, Ruiyu Li, Jiaya Jia

## 🧩 Problem to Solve

최신 의미론적 분할(Semantic Segmentation) 방법은 만족스러운 결과를 얻기 위해 충분한 레이블된 데이터를 요구하며, 미분류 클래스(unseen classes)에 대해서는 미세 조정(fine-tuning) 없이 거의 작동하지 않습니다. 소수 샘플 분할(Few-shot Segmentation, FSS)은 적은 수의 레이블된 지원(support) 샘플을 통해 새로운 클래스에 빠르게 적응하는 모델을 학습함으로써 이 문제를 해결하고자 합니다. 하지만 기존 FSS 프레임워크들은 학습 클래스의 고수준 의미 정보를 부적절하게 사용하고 쿼리(query) 및 지원 대상 간의 공간적 불일치(spatial inconsistency)로 인해 미분류 클래스에 대한 일반화 능력 감소라는 문제에 직면해 있습니다.

## ✨ Key Contributions

* **PFENet(Prior Guided Feature Enrichment Network) 제안**: 위에서 언급된 문제를 완화하기 위해 새로운 아키텍처인 PFENet을 제안합니다.
* **학습 불필요한 사전 마스크(Prior Mask) 생성 방법**: 일반화 능력을 유지하면서 모델 성능을 향상시키는 학습 불필요한(training-free) 사전 마스크 생성 방법을 제안합니다. 이 방법은 ImageNet 사전 학습된 고수준 특징을 활용하여 클래스에 둔감한(class-insensitive) 사전 정보를 제공합니다.
* **특징 강화 모듈(Feature Enrichment Module, FEM)**: 지원 특징과 사전 마스크를 사용하여 쿼리 특징을 적응적으로 풍부하게 함으로써 공간적 불일치를 극복하는 FEM을 제안합니다. FEM은 스케일 내(inter-source) 및 스케일 간(inter-scale) 상호작용을 통해 특징을 개선합니다.
* **최첨단 성능 달성**: PASCAL-5$_i$ 및 COCO 데이터셋에서 기존 최첨단(state-of-the-art) 방법들을 큰 폭으로 능가하며, 효율성 손실 없이 우수한 성능을 달성합니다.
* **제로샷(Zero-shot) 시나리오 일반화**: 레이블된 지원 샘플이 없는 제로샷 상황에서도 모델이 놀라운 일반화 능력을 보임을 입증합니다.

## 📎 Related Works

* **의미론적 분할(Semantic Segmentation)**: FCN, DeepLab (ASPP, dilated convolution), PSPNet (Pyramid Pooling Module, PPM)과 같은 획기적인 프레임워크 및 다양한 어텐션 메커니즘(PSANet, Channel-wise attention, Non-local attention)이 개발되었지만, 이들은 대규모 레이블 데이터에 의존하며 희귀하거나 미분류 클래스에 대한 적응이 어렵습니다.
* **소수 샘플 학습(Few-shot Learning)**: 이미지 분류 분야에서 메타 학습 기반(예: MAML) 및 거리 학습 기반(예: Prototypical Network, Relation Network) 방법론이 있습니다. 본 연구는 픽셀 단위 예측이라는 더 어려운 문제인 소수 샘플 분할에 초점을 맞춥니다.
* **소수 샘플 분할(Few-shot Segmentation)**: OSLSM이 이 분야를 처음 다루었으며, PL(Prototypical Learning), CRNet, PANet(Prototype Alignment Network), CANet 등이 발전해왔습니다. 본 연구는 CANet과 유사하게 코사인 유사도 대신 컨볼루션을 사용하지만, 기존 방법론들이 간과했던 일반화 손실 및 공간적 불일치 문제를 주요하게 다룹니다. 또한 PGNet(Graph Attention Unit, GAU)과 같은 최근 방법들과 비교합니다.

## 🛠️ Methodology

PFENet은 학습 불필요 사전 생성 방법과 특징 강화 모듈(FEM)을 핵심으로 합니다.

* **작업 정의**: $K$개의 지원 샘플 $\{I_{S_i}, M_{S_i}\}$가 주어졌을 때, 쿼리 이미지 $I_Q$에서 새로운 클래스 $C_{test}$의 영역을 분할하는 것을 목표로 합니다. 모델은 $C_{train}$에서 학습하고 $C_{test}$에서 평가됩니다 (에피소드 방식).

* **사전 마스크 생성 (학습 불필요)**:
  * **배경**: 기존 연구는 학습 가능한 고수준 특징을 사용하는데, 이는 학습 클래스 $C_{train}$에 과적합되어 일반화 능력을 저해할 수 있습니다. 본 논문은 ImageNet 사전 학습된, 고정된(fixed) 고수준 특징을 사용하여 이러한 편향을 피합니다.
  * **과정**:
        1. 쿼리 이미지 $I_Q$와 지원 이미지 $I_S$에서 공유 백본 네트워크 $F$를 통해 고수준 특징 $X_Q$, $X_S$를 추출합니다 ($X_Q = F(I_Q)$, $X_S = F(I_S)$). 백본 파라미터는 고정됩니다.
        2. 지원 특징 $X_S$에 이진 지원 마스크 $M_S$를 하마다르 곱(Hadamard product)하여 배경 정보를 제거합니다.
        3. $X_Q$의 각 픽셀 특징 벡터 $x_q$와 마스킹된 $X_S$의 각 픽셀 특징 벡터 $x_s$ 사이의 픽셀 단위 코사인 유사도를 계산합니다: $cos(x_q, x_s) = \frac{x_q^T x_s}{\|x_q\|\|x_s\|}$
        4. 각 $x_q$에 대해 모든 지원 픽셀 중 최대 유사도 값을 취하여 대응 값 $c_q$를 얻습니다: $c_q = \max_{s \in \{1,...,hw\}} (cos(x_q, x_s))$.
        5. 이 대응 값들로 구성된 $C_Q$를 쿼리 이미지와 동일한 공간 크기인 $Y_Q$로 재구성하고, 값을 [0, 1] 범위로 정규화하여 최종 사전 마스크를 생성합니다.

* **특징 강화 모듈 (FEM)**:
  * **배경**: 기존의 전역 풀링(global pooling) 방식은 지원 이미지의 공간 정보를 손실시키고, PPM이나 ASPP는 스케일 내 정교화 과정과 스케일 간 계층적 관계를 무시하는 단점이 있습니다.
  * **구조**: FEM은 쿼리 특징, 사전 마스크, 지원 특징을 입력받아 정제된 쿼리 특징을 출력합니다. 이는 세 가지 하위 과정으로 나뉩니다.
        1. **스케일 내(Inter-Source) 강화**: 입력 쿼리 특징 $X_Q$를 적응적 평균 풀링을 통해 $n$개의 다른 공간 크기(예: $\{B_1, ..., B_n\}$)를 가진 서브 쿼리 특징 $X_{FEM}^Q$로 변환합니다. 전역 풀링된 지원 특징 $X_S$와 사전 마스크 $Y_Q$도 각 스케일에 맞춰 확장/리사이징됩니다. 각 스케일 $i$에서 $X_i^Q$, $X_i^S$, $Y_i^Q$를 채널 축으로 연결(concatenate)한 후, 1x1 컨볼루션을 통해 병합된 쿼리 특징 $X_{Q,m}^i$를 생성합니다.
        2. **스케일 간(Inter-Scale) 상호작용 (하향식 경로 선택)**: Inter-scale Merging Module $M$은 상위 스케일의 병합된 특징(보조 특징)에서 추출된 유용한 정보를 하위 스케일의 병합된 특징(주요 특징)으로 선택적으로 전달하여 계층적 관계를 구축합니다. $M$은 보조 특징을 주요 특징과 동일한 크기로 리사이징하고, 1x1 컨볼루션($\alpha$), 두 개의 3x3 컨볼루션($\beta$), 그리고 잔여 연결(residual link)을 사용하여 정제된 특징 $X_{Q,new}^i$를 생성합니다. 하향식 경로(top-down path)가 가장 효과적임이 실험적으로 입증되었습니다.
        3. **정보 집약(Information Concentration)**: 스케일 간 상호작용 후 얻은 $n$개의 정제된 특징 맵 $X_{Q,new}^i$를 원본 공간 크기로 보간(interpolation)하고 연결한 후, 마지막 1x1 컨볼루션을 적용하여 최종 출력 쿼리 특징 $X_{Q,new}$를 얻습니다. 각 $X_{Q,new}^i$에는 중간 감독(intermediate supervision)을 위한 분류 헤드가 부착됩니다.

* **PFENet 아키텍처**:
  * ImageNet 사전 학습된 CNN(ResNet-50/101, VGG-16)이 지원 및 쿼리 이미지에 공유 백본으로 사용됩니다.
  * 백본에서 추출된 중간 수준 특징(conv3x 및 conv4x)은 1x1 컨볼루션을 통해 256 채널로 차원 축소됩니다.
  * 고수준 특징(conv5x)은 사전 마스크 생성에 사용됩니다.
  * FEM은 차원 축소된 쿼리/지원 특징과 사전 마스크를 입력으로 받습니다.
  * FEM의 출력 특징은 컨볼루션 블록과 분류 헤드를 통해 최종 분할 예측을 생성합니다.
  * K-샷 설정의 경우, K개의 풀링된 지원 특징과 K개의 사전 마스크를 각각 평균하여 사용합니다.

* **손실 함수**: 교차 엔트로피 손실을 사용합니다. 총 손실 $L$은 $n$개의 중간 손실 $L_i^1$ (FEM 내부의 각 스케일 출력에 대한 감독)과 최종 예측 손실 $L_2$의 가중 합입니다. $L = \sigma \sum_{i=1}^n L_i^1 + L_2$ 이며, $\sigma=1.0$으로 설정됩니다.

## 📊 Results

* **데이터셋 및 평가 지표**: PASCAL-5$_i$ 및 COCO 데이터셋에서 클래스 mIoU(주요 평가 지표)와 FB-IoU를 사용하여 성능을 평가했습니다.
* **최첨단 성능**: PFENet은 VGG-16, ResNet-50, ResNet-101 백본 모두에서 PASCAL-5$_i$와 COCO 두 데이터셋에서 새로운 최첨단 성능을 달성했습니다. 특히 COCO에서는 클래스 mIoU에서 기존 방법보다 10점 이상 높은 성능 향상을 보였습니다.
* **효율성**: PFENet은 다른 최첨단 방법보다 훨씬 적은 학습 가능한 파라미터(VGG 기반 10.4M, ResNet 기반 10.8M)를 가지며, 1-샷 설정에서 ResNet-50 백본 기준 15.9 FPS의 효율적인 추론 속도를 유지합니다.
* **FEM의 기여**:
  * **스케일 간 상호작용**: 하향식 경로(Top-Down path, TD)가 가장 효과적이며, 모델 크기를 크게 늘리지 않으면서도 상당한 성능 향상을 가져옵니다. 미세한 특징에서 거친 특징으로 정보를 전달하는 것이 반대 경우보다 효과적입니다.
  * **다른 모듈과의 비교**: FEM은 PPM, ASPP, PGNet의 GAU(Graph Attention Unit)보다 우수한 성능을 보였습니다. 이는 FEM의 조건부 스케일 간 상호작용이 멀티스케일 정보 집약에 더 효과적임을 나타냅니다. HRNet의 모듈(HRB)과 비교했을 때, FEM은 적은 파라미터로 비슷한 성능을 내며, FEM의 조건부 특징 선택 메커니즘이 중요합니다.
* **사전 마스크 생성의 기여**:
  * **특징 선택**: 고정된 고수준 특징(ImageNet 사전 학습)을 사용하여 생성된 사전 마스크가 학습 가능한 특징이나 중간 수준 특징을 사용한 경우보다 일반화 능력을 훨씬 잘 유지하며 성능 향상에 기여했습니다. 학습 가능한 고수준 특징은 학습 클래스에 심하게 과적합되어 성능을 저해했습니다.
  * **판별 능력**: 픽셀 단위 유사도에서 최대값을 취하는 방식이 평균값을 취하거나 마스크 풀링된 지원 특징을 사용하는 방식보다 잠재적인 타겟 영역을 더 잘 강조하여 성능이 우수했습니다.
* **완전히 미분류된 객체에 대한 일반화**: FSS-1000 데이터셋(ImageNet에 포함되지 않은 객체 포함) 실험에서, 사전 마스크를 사용하는 베이스라인이 사용하지 않는 베이스라인보다 1.0 IoU 이상 높은 성능을 보이며, 완전히 새로운 객체에 대해서도 뛰어난 일반화 능력을 입증했습니다.
* **백본 학습 영향**: 백본 파라미터를 학습시키는 경우, 과적합으로 인해 성능이 크게 저하되며 학습 시간이 증가합니다. 백본 파라미터를 고정하는 것이 소수 샘플 분할에 더 효과적입니다.
* **결과 안정성**: COCO 데이터셋에서 1,000쌍 대신 20,000쌍의 쿼리-지원 쌍을 사용하여 평가했을 때 훨씬 더 안정적인 결과(낮은 표준편차)를 얻었습니다.
* **제로샷 분할로의 확장**: 지원 샘플 없이 클래스 레이블 임베딩만 사용하여 모델을 수정했을 때, PFENet의 기본 구조가 일부 5-샷 모델보다 높은 성능을 보였으며, FEM은 베이스라인에 1.0 mIoU 포인트 향상을 가져왔습니다 (53.2 $\rightarrow$ 54.2).

## 🧠 Insights & Discussion

* **일반화 능력 보존의 중요성**: 기존 소수 샘플 분할 방법론에서 고수준 특징을 오용하면 학습 클래스에 과적합되어 미분류 클래스에 대한 일반화 능력이 저하됩니다. PFENet의 **학습 불필요 사전 마스크 생성**은 고정된 ImageNet 사전 학습 특징을 활용하여 이러한 문제를 근본적으로 해결하며, 모델이 클래스에 구애받지 않는 의미론적 단서를 활용하도록 돕습니다.
* **공간적 불일치 해결**: 지원 샘플의 전역 풀링은 중요한 공간 정보를 손실시키고, 이는 쿼리 타겟과의 크기 및 자세 불일치를 야기합니다. **FEM**은 이러한 공간적 불일치를 효과적으로 다룹니다.
  * **다중 스케일 상호작용**: 쿼리 및 지원 특징을 여러 스케일에서 융합하는 **스케일 내 강화**를 통해 다양한 해상도에서 특징 상호작용을 가능하게 합니다. 이는 다양한 스케일의 쿼리 타겟을 예측하는 데 유리합니다.
  * **조건부 스케일 간 정보 전달**: **스케일 간 상호작용(하향식 경로)**은 미세한 스케일의 특징으로부터 거친 스케일의 특징으로 유용한 정보를 선택적으로 전달합니다. 이 "조건부" 정보 전달 메커니즘은 단순한 조밀한 융합(HRNet 등)이나 기본적인 풀링(PPM, ASPP)보다 우수하여, 작은 객체 정보가 손실되지 않도록 돕습니다.
* **효율성 및 강건성**: PFENet은 적은 파라미터와 효율적인 속도로 최첨단 성능을 달성하여, 제안된 모듈의 설계 효율성을 입증합니다. 특히 완전히 미분류된 객체(FSS-1000) 및 제로샷 시나리오에서의 강력한 일반화 능력은 PFENet의 강건성을 보여줍니다.
* **향후 연구**: 제안된 사전 생성 및 FEM 디자인을 소수 샘플 객체 탐지 및 소수 샘플 인스턴스 분할 분야로 확장하는 것이 가능할 것입니다.

## 📌 TL;DR

소수 샘플 분할은 적은 수의 레이블된 샘플로 새로운 클래스에 적응해야 하지만, 기존 방법들은 학습 클래스에 대한 고수준 특징 오용으로 인한 일반화 능력 저하와 쿼리/지원 대상 간의 공간적 불일치 문제를 겪습니다. 본 논문은 이러한 문제를 해결하기 위해 **PFENet**을 제안합니다. PFENet은 **학습 불필요 사전 마스크 생성** (고정된 사전 학습 고수준 특징 사용)을 통해 일반화를 유지하면서 의미론적 지침을 제공하고, **특징 강화 모듈(FEM)**을 통해 지원 특징과 사전 마스크를 사용하여 쿼리 특징을 다중 스케일에서 적응적으로 강화합니다. 그 결과, PFENet은 PASCAL-5$_i$와 COCO에서 최첨단 성능을 달성했으며, 적은 파라미터와 높은 효율성을 유지하며 완전히 미분류된 객체 및 제로샷 시나리오에서도 강력한 일반화 능력을 보였습니다.
