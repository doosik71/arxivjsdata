# nnU-Net Revisited: A Call for Rigorous Validation in 3D Medical Image Segmentation

Fabian Isensee, Tassilo Wald, Constantin Ulrich, Michael Baumgartner, Saikat Roy, Klaus Maier-Hein, Paul Jäger

## Problem to Solve

이 논문은 3D 의료 영상 분할에서 `nnU-Net`이 잘 구성된 `U-Net` 모델이 최첨단 성능을 달성할 수 있음을 입증했음에도 불구하고, 이 분야에서 **새로운 아키텍처** (**Transformer**, **Mamba** 등)를 추구하며 우수한 성능을 주장하는 경향이 지속되는 문제를 다룹니다. 저자들은 이러한 주장 중 상당수가 **불충분한 베이스라인**, **부적절한 데이터셋**, **컴퓨팅 자원 무시**와 같은 일반적인 유효성 검사상의 단점들로 인해 **엄격하게 검증되지 못했다**고 주장하며, 이는 **혁신 편향**(**innovation bias**)으로 이어진다고 지적합니다.

## Key Contributions

- 의료 영상 분할 분야의 **유효성 검사 함정**(**validation pitfalls**)을 체계적으로 식별하고 이를 피하기 위한 권장 사항을 제시합니다.
- **철저한 유효성 검사 프로토콜**에 따라 현재 널리 사용되는 분할 방법론들의 **대규모 벤치마킹**을 수행합니다.
- 이 분석을 바탕으로 의료 영상 분할을 위한 **핵심 방법론적 구성 요소**와 **적합한 벤치마킹 데이터셋**을 식별합니다.
- 다양한 하드웨어 역량에 맞춘 잔여 인코더 `U-Net` 기반의 `nnU-Net` 프레임워크 내에서 **3D 의료 분할을 위한 업데이트된 표준화된 베이스라인** (`"M"`, `"L"`, `"XL"`)을 공개합니다.

## Methodology

이 연구는 체계적인 3D 의료 분할 벤치마킹을 수행하며, 기존 연구의 유효성 검사 함정을 피하기 위한 다음과 같은 접근 방식을 사용합니다.

1. **유효성 검사 함정 식별**:

   - **베이스라인 관련 함정**:
     - `P1`: 주장된 혁신을 **혼란스러운 성능 부스터** (**예: 잔여 연결, 추가 학습 데이터, 사전 학습, 불균등한 하드웨어 자원, 앙상블 등**)와 결합합니다.
       - **권장 사항** (**R1**): 제안된 방법이 혼란스러운 성능 부스터와 결합되지 않도록 하여 주장된 혁신의 효과만을 분리합니다.
     - `P2`: **잘 구성되지 않거나 표준화되지 않은 베이스라인**의 부족입니다. `nnU-Net`과 같이 자동 구성 기능을 제공하는 프레임워크와의 비교가 필요합니다.
       - **권장 사항** (**R2**): 고품질 베이스라인 구성을 보장하고, 새로운 방법은 적응 지침을 제공하거나 자동 구성 프레임워크에 통합되어야 합니다.
   - **데이터셋 관련 함정**:
     - `P3`: **불충분한 데이터셋 수량 및 적합성**입니다. 다양한 데이터셋에서 일반적인 방법론적 개선을 테스트할 필요가 있습니다.
       - **권장 사항** (**R3**): 활용되는 데이터셋이 주장된 방법론적 개선을 측정하는 데 적합한 기반 (**충분한 수량 및 다양성**, **개별 데이터셋의 벤치마킹 적합성** 포함)이 되어야 합니다.
     - `P4`: **일관성 없는 보고 관행**입니다. 비표준화된 리더보드 제출 (**앙상블**, **테스트 시간 증강**, **후처리**) 및 결과 선택적 보고를 포함합니다.
       - **권장 사항** (**R4**): **5-겹 교차 검증** (**5-fold cross-validation**)을 사용하고, 이상적으로는 개발 데이터셋 풀과 독립적인 테스트 데이터셋 풀을 구분하여 일반화 가능성을 평가합니다.

2. **비교 방법**:

   - **CNN 기반**: `nnU-Net` (**원본** 및 **잔여 인코더 변형** `ResEnc M/L/XL`), `MedNeXt` (`L k3/k5`), `STU-Net` (`S/B/L`).
   - **Transformer 기반**: `SwinUNETR` (V1/V2), `nnFormer`, `CoTr`.
   - **Mamba 기반**: `U-Mamba` (`Enc/Bot`), `No-Mamba Base` (**원본 연구에 없던 Mamba 레이어 비활성화 버전**).
   - **프레임워크 비교**: `nnU-Net`과 `MONAI` 생태계의 `Auto3DSeg` (`SegResNet`, `DiNTS`, `SwinUNETR` 아키텍처 사용)를 비교합니다.

3. **학습 설정**:

   - 하이퍼파라미터는 자동 구성 기능을 사용하거나, 최적의 기존 구성을 선택하거나, 기본값을 사용하고 필요한 경우 학습률을 조정하여 **표준화된 방식**으로 구성됩니다.
   - 모든 모델은 **스크래치부터 학습**되며, `Auto3DSeg` 프레임워크 내 `SwinUNETR`의 자동 사전 학습 가중치 로딩만 유일한 예외입니다.
   - 모든 학습은 **단일 NVIDIA A100 (40GB VRAM) GPU**에서 동일한 **최대 VRAM 예산**으로 실행됩니다.

4. **활용 데이터셋**:

   - 인기 있고 다양한 6가지 3D 의료 영상 데이터셋 (`BTCV`, `ACDC`, `LiTS`, `BraTS2021`, `KiTS2023`, `AMOS2022`)을 사용합니다.
   - **벤치마킹 적합성**을 `inter-method SD` (**다른 방법 간 성능 표준 편차**)와 `intra-method SD` (**동일 방법 내 폴드 간 성능 표준 편차**)의 비율로 평가합니다. `inter-method SD / intra-method SD` 비율이 높을수록 적합합니다.

5. **평가**:
   - `nnU-Net`이 생성한 분할을 사용하여 **5-겹 교차 검증**을 수행합니다.
   - 주요 지표는 **평균 `Dice Similarity Coefficients`** (**DSC**), 보조 지표는 **`Normalized Surface Dice`** (**NSD**)입니다.
   - 모든 클래스와 5개 폴드에 걸쳐 평균을 내어 일반적인 분할 능력을 평가합니다.

## Results

- **데이터셋 벤치마킹 적합성**: `KiTS`, `AMOS`, `ACDC`는 **낮은 통계적 노이즈**와 **높은 방법론 간 차이**를 보여 벤치마킹에 가장 적합한 데이터셋으로 확인되었습니다. 특히 `KiTS`는 가장 높은 `inter-method SD`를 보였습니다. 반면, `BraTS`와 `BTCV`는 각각 성능 포화 및 높은 통계적 노이즈로 인해 덜 적합합니다.
- **CNN 기반 `U-Net`의 성능 우위**: `nnU-Net` (**원본** 및 `ResEnc` 변형), `MedNeXt`, `STU-Net`, `No-Mamba Base`와 같은 **CNN 기반 `U-Net`** 모델은 6가지 데이터셋 전반에 걸쳐 지속적으로 **강력한 성능**을 보였습니다. `MedNeXt`는 대부분의 데이터셋에서 최고의 성능을 보였으나, 학습 시간이 길고 그 성능 이점의 일부는 **타겟 스페이싱 선택**에서 기인할 수 있음이 밝혀졌습니다.
- **트랜스포머 및 맘바 모델의 한계**: 이전 주장과는 달리, `Transformer` 기반 (`SwinUNETR`, `nnFormer`, `CoTr`) 및 `Mamba` 기반 (`U-Mamba`) 아키텍처는 **CNN 기반 `U-Net`의 성능에 미치지 못했습니다.** 특히 `U-Mamba`의 경우, 이전에 보고된 성능 향상이 `Mamba` 레이어 때문이 아니라 **잔여 `U-Net`과의 결합** 때문이었음이 (`No-Mamba Base`와의 비교를 통해) 드러났습니다.
- **`nnU-Net` 프레임워크의 우위**: `Auto3DSeg` 프레임워크에 포함된 세 가지 방법 모두 `nnU-Net` (**원본**) 베이스라인 성능에 미치지 못하여, `Auto3DSeg` 프레임워크 자체의 **상당한 불리함**을 시사합니다. 동일한 `SwinUNETR` 모델을 사용할 때도 `nnU-Net` 프레임워크가 6개 데이터셋 중 5개에서 더 나은 성능을 보였습니다.
- **모델 스케일링의 중요성**: `nnU-Net ResEnc M/L/XL` 및 `STU-Net S/B/L` 모델 스케일링 실험 결과, `AMOS` 및 `KiTS`와 같은 **더 어려운 작업**에서 컴퓨팅 예산이 증가함에 따라 **성능이 크게 향상**되는 것을 확인했습니다. 이는 **모델 크기와 데이터셋의 난이도**를 고려한 비교의 중요성을 강조합니다.
