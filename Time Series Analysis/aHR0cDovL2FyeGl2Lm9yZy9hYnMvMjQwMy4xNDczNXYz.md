# Foundation Models for Time Series Analysis: A Tutorial and Survey

Yuxuan Liang, Haomin Wen, Yuqi Nie, Yushan Jiang, Ming Jin, Dongjin Song, Shirui Pan, Qingsong Wen

## 🧩 Problem to Solve

기존 시계열 분석 파운데이션 모델(FMs)에 대한 서베이 연구는 주로 응용 분야나 파이프라인 측면에 집중했습니다. 이로 인해 FMs가 시계열 분석에서 뛰어난 성능을 보이는 근본적인 메커니즘, 즉 `왜(why)` 그리고 `어떻게(how)` FMs가 시계열 분석에 이점을 제공하는지에 대한 심층적인 방법론적 이해가 부족했습니다. 이 논문은 이러한 방법론적 이해의 공백을 해소하고, 시계열 FMs의 핵심 요소를 체계적으로 분석하는 것을 목표로 합니다.

## ✨ Key Contributions

- **포괄적이고 최신 정보가 담긴 서베이:** 표준 시계열, 공간 시계열, 궤적 및 이벤트 데이터를 포함하는 광범위한 시계열 파운데이션 모델(TSFMs)에 대한 최신 연구 동향을 종합적으로 제시합니다.
- **새로운 방법론 중심 분류 체계:** TSFMs의 모델 아키텍처, 사전 훈련 기법, 적응 방법, 데이터 양식 등 핵심 구성 요소를 중심으로 하는 새로운 분류 체계를 도입하여, FMs가 시계열 데이터에서 뛰어난 성능을 달성하는 원리와 메커니즘을 심층적으로 분석합니다.
- **미래 연구 방향 제시:** 파운데이션 모델을 활용한 시계열 분석 분야의 미래 연구 기회와 도전 과제를 논의하고 강조하여, 추가 혁신을 장려합니다.

## 📎 Related Works

- **Jin et al. [48]:** 데이터 관점에서 파운데이션 모델을 분류.
- **Jiang et al. [45], Zhang et al. [114], Miller et al. [66]:** 파이프라인 관점에서 파운데이션 모델을 분류.
- 본 서베이 논문은 기존 연구들이 주로 데이터 유형이나 파이프라인 관점에 집중하여 방법론적 메커니즘에 대한 심층적 분석이 부족했던 한계를 지적하며, 자체적인 방법론 중심의 분류를 통해 차별점을 둡니다.

## 🛠️ Methodology

본 서베이는 시계열 파운데이션 모델(TSFMs)을 방법론적 관점에서 체계적으로 분류하고 분석하며, 다음 네 가지 핵심 요소를 중심으로 설명합니다:

1. **데이터 양식 (Data Modality):**

   - **표준 시계열 (Standard Time Series):** 시간 순서와 시간 의존성을 갖는 $X = \{x_{1}, x_{2}, \dots, x_{T}\} \in \mathbb{R}^{T \times D}$ 형태의 데이터.
   - **공간 시계열 (Spatial Time Series):** 시간과 공간 차원을 모두 포함하는 $X = \{X_{1}, X_{2}, \dots, X_{T}\} \in \mathbb{R}^{N \times T \times D}$ 형태의 데이터. 시공간 그래프(spatio-temporal graph)와 시공간 래스터(spatio-temporal raster)로 세분화됩니다.
   - **기타 시계열 (Others):** 궤적(trajectory) 및 이벤트 시퀀스(event sequence)와 같이 시간이 중요한 역할을 하는 다양한 데이터셋을 포함합니다.

2. **모델 아키텍처 (Model Architecture):**

   - **Transformer-기반 모델:** 어텐션 메커니즘($Attention(Q, K, V) = Softmax(QK^{T} / \sqrt{d_{k}})V$)을 활용하여 데이터의 전역적, 장거리 의존성을 포착합니다. 인코더-온리, 디코더-온리, 인코더-디코더 구조가 모두 사용되며, 시계열 패치화(patching), 가역적 인스턴스 정규화(reversible instance normalization), 다중 해상도 분석 등의 기법이 통합됩니다.
   - **Non-Transformer-기반 모델:** 다층 퍼셉트론(MLP), 순환 신경망(RNN), 합성곱 신경망(CNN)과 같은 전통적인 딥러닝 아키텍처를 백본으로 사용하며, 경량성과 효율적인 시퀀스 처리에 중점을 둡니다 (예: TSMixer, RWKV-TS).
   - **확산-기반 모델 (Diffusion-based Models):** 데이터에 노이즈를 점진적으로 추가하고 역으로 제거하는 과정을 학습하여 복잡한 데이터 분포를 모델링합니다. 예측, 결측치 보완, 이상 탐지 등 다양한 시계열 작업에 활용됩니다.

3. **사전 훈련 기법 (Pre-training Techniques):**

   - **완전 지도 학습 (Fully-supervised):** 레이블이 있는 대규모 시계열 데이터셋으로 모델을 훈련하여 일반화 가능한 표현을 학습합니다.
   - **자기 지도 학습 (Self-supervised):** 레이블이 없는 시계열 데이터로부터 특징을 학습합니다.
     - **생성적 (Generative):** 마스킹된 부분 재구성(masked autoencoding) 또는 확률론적 모델링을 통해 원본 입력 공간을 복원합니다.
     - **대조적 (Contrastive):** 정보성 긍정 쌍(positive pairs)을 구성하고 적합하지 않은 부정 쌍(negative pairs)을 필터링하여 표현의 강건성(robustness)을 강화합니다.
     - **하이브리드 (Hybrid):** 생성적 및 대조적 접근 방식을 결합합니다.
   - **다른 모달리티로부터의 사전 훈련:** 거대 언어 모델(LLM), 비전-언어 모델(VLM), 음향 모델(AM) 등 다른 데이터 양식에서 사전 훈련된 모델을 활용합니다.

4. **적응 방법 (Adaptation Methods):**
   - **직접 사용 (Direct Usage, Zero-shot):** 추가적인 미세 조정 없이 사전 훈련된 모델을 대상 작업에 직접 적용합니다.
   - **미세 조정 (Fine-tuning):** 전체 모델 또는 특정 구성 요소를 대상 데이터셋에 맞춰 조정하여 성능을 최적화합니다.
   - **프롬프트 엔지니어링 (Prompt Engineering):** 작업별 텍스트 프롬프트 또는 학습 가능한 프롬프트 벡터를 사용하여 LLM-기반 TSFMs의 능력을 활용합니다.
   - **시계열 토큰화 (Time Series Tokenization):** 시계열 데이터를 효과적으로 임베딩으로 표현하기 위한 기술로, 패치화 및 가역적 인스턴스 정규화 등이 포함됩니다.

## 📊 Results

본 서베이는 TSFMs의 광범위한 발전을 데이터 유형 및 방법론 관점에서 상세히 분석하고 분류했습니다.

- **데이터 유형별 분석:**
  - **표준 시계열:** Lag-Llama, TimeGPT-1, Moirai와 같은 제로샷 예측 모델의 선구적인 노력을 강조하며, LLM4TS, TEMPO처럼 기존 LLM을 시계열 예측에 재활용하는 연구를 조명합니다. Time-LLM, METS와 같은 멀티모달리티 접근법이 금융 및 헬스케어 분야에서 유망한 성과를 보임을 보여줍니다.
  - **공간 시계열:** 교통 예측(ST-LLM, TFM) 및 기후 모델링(FourCastNet, Pangu-Weather) 분야에서 Transformer-기반 및 Diffusion-기반 모델의 초기 단계 연구가 활발히 진행 중이며, 주로 도메인 특화 및 단일 모달리티 작업에 초점을 맞추고 있음을 나타냅니다.
  - **기타 시계열 (궤적, 이벤트):** AuxMobLCast, LLM-Mob 등 LLM을 활용한 인간 이동성 예측과 TrajGDM, Diff Traj와 같은 Diffusion-기반 모델이 궤적 데이터 분석에 활용되고 있음을 보여줍니다.
- **방법론적 관점의 결과:**
  - Transformer 아키텍처가 시계열 분석에서 장거리 의존성을 포착하는 데 지배적인 역할을 하고 있음을 확인합니다.
  - 자기 지도 학습이 대규모 레이블 없는 시계열 데이터를 활용하여 일반화된 지식을 얻는 데 중요함을 입증합니다.
  - LLM, VLM, AM과 같은 다른 모달리티에서 사전 훈련된 모델을 시계열 분석에 재활용하는 추세가 두드러지며, 이를 통해 계산 비용을 절감하고 강력한 시퀀스 모델링 능력을 활용하고 있음을 보여줍니다.
  - 제로샷 추론부터 미세 조정, 프롬프트 엔지니어링, 시계열 토큰화에 이르는 다양한 적응 전략이 TSFMs의 유연성과 효율성을 향상시키는 데 기여하고 있음을 설명합니다.

## 🧠 Insights & Discussion

본 서베이는 TSFMs의 방법론적 기반에 대한 심층적인 이해를 제공하고, 시계열 데이터 분석 분야의 현재 상태와 미래 방향에 대한 중요한 통찰력을 제시합니다.

- **의미:** 방법론 중심의 분류는 연구자들이 FMs가 시계열 분석에서 효과적인 이유와 방법을 명확히 이해하는 데 도움을 줍니다. 이는 시계열 데이터의 고유한 특성과 FMs의 일반화 능력을 연결하는 가교 역할을 합니다.
- **현재 동향:**
  - **LLM의 시계열 재활용:** 자연어 처리(NLP) 분야의 LLM을 시계열 예측 및 분석에 활용하는 트렌드가 강합니다. 이는 LLM의 강력한 시퀀스 모델링 능력과 광범위한 사전 학습 지식을 시계열 데이터에 전이하려는 시도입니다.
  - **자기 지도 학습의 부상:** 대규모 레이블 없는 시계열 데이터의 잠재력을 최대한 활용하기 위해 마스킹된 모델링, 대조 학습 등의 자기 지도 학습 기법이 TSFMs 훈련의 핵심으로 자리 잡고 있습니다.
  - **Diffusion 모델의 가능성:** 복잡한 데이터 분포를 학습하는 Diffusion 모델은 시계열 데이터의 예측, 결측치 보완, 이상 탐지에 혁신적인 해결책을 제시할 잠재력을 보여주고 있습니다.
- **한계 및 미래 연구 방향:**
  - **멀티모달리티 통합:** 현재 대부분의 TSFMs는 단일 모달리티에 집중되어 있습니다. 시계열, 텍스트, 이미지 등 다양한 양식의 데이터를 통합하여 더욱 포괄적이고 일반화된 지식을 학습하는 멀티모달 TSFMs 개발이 유망합니다.
  - **더 효율적인 아키텍처 탐색:** Transformer-기반 모델은 자기 어텐션 메커니즘으로 인해 시퀀스 길이에 대해 $O(L^2)$의 계산 복잡도를 가집니다. Mamba와 같은 상태 공간 모델(state-space models) 등 장기 시퀀스를 효율적으로 처리할 수 있는 새로운 아키텍처 연구가 필요합니다.
  - **더 효과적인 파이프라인 개발:** 시계열 데이터의 고유한 특성인 시간 분포 변화(temporal distribution shift)와 인과 관계(causality)를 효과적으로 다루는 TSFMs 개발이 중요합니다. 또한, 모델의 강력한 해석 가능성(interpretability) 확보도 핵심적인 과제입니다.
  - **프라이버시 보호:** 다양한 소스에서 데이터를 훈련하는 과정에서 민감한 정보가 노출될 위험이 있으므로, 연합 학습(federated learning)과 같은 프라이버시 보호 기술을 TSFMs 훈련에 적용하는 연구가 필수적입니다.

## 📌 TL;DR

이 서베이 논문은 기존 시계열 파운데이션 모델(TSFMs) 연구에서 부족했던 방법론적 이해를 심화하고자 합니다. 이를 위해 데이터 양식, 모델 아키텍처, 사전 훈련 기법, 적응 방법이라는 네 가지 핵심 관점에서 TSFMs를 체계적으로 분류하고 분석하는 새로운 분류 체계를 제시합니다. 핵심적으로, Transformer-기반 모델의 지배력, LLM 재활용 트렌드, 자기 지도 학습의 중요성을 강조하며, 멀티모달리티 통합, 효율적인 아키텍처 탐색, 시간적 특성(분포 변화, 인과 관계) 처리, 프라이버시 보호를 미래 연구의 주요 방향으로 제안합니다.
