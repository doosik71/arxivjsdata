# Deep Time Series Models: A Comprehensive Survey and Benchmark

Yuxuan Wang, Haixu Wu, Jiaxiang Dong, Yong Liu, Chen Wang, Mingsheng Long, Jianmin Wang

## 🧩 Problem to Solve

시계열 데이터는 비선형 패턴과 시간 가변적 추세가 얽혀있는 복잡하고 동적인 특성으로 인해 고유한 분석 과제를 제기합니다. 기존 통계 방법은 선형성과 정상성(stationarity) 가정에 의존하여 이러한 복잡한 관계를 포착하는 데 한계가 있습니다. 최근 딥러닝 모델의 발전에도 불구하고, 다양한 분석 작업과 모델 아키텍처를 포괄하는 심층 시계열 모델에 대한 포괄적인 개요나 공정한 벤치마크가 부족하여 연구 및 실용 적용에 어려움이 있었습니다.

## ✨ Key Contributions

- **포괄적인 심층 시계열 모델 개요:** 다양한 분석 작업(예: 예측, 분류, 결측치 보간, 이상 탐지)에 걸쳐 기존 심층 시계열 모델을 기본 모듈 및 모델 아키텍처 두 가지 관점에서 체계적으로 정리하고 검토했습니다.
- **TSLib (Time Series Library) 벤치마크 개발:** 30개의 주요 모델, 30개의 다양한 데이터셋, 5가지 주요 분석 작업을 지원하는 공정하고 포괄적인 벤치마크 라이브러리인 TSLib을 개발하고 공개했습니다.
- **광범위한 모델 평가 및 통찰:** TSLib을 사용하여 13개의 첨단 심층 시계열 모델을 다양한 작업에 걸쳐 철저히 평가하고, 각 분석 작업에 특정 구조의 모델이 적합하다는 실증적 결과를 도출하여 향후 연구 및 모델 채택에 대한 통찰력을 제공했습니다.
- **기본 설계 원리 분석:** 복잡한 딥 시계열 모델에서 기본 모듈을 분리하여 현재 연구의 근본적인 설계 원리를 밝히고 모델 중심적 관점을 제시했습니다.

## 📎 Related Works

- **특정 작업 또는 모델 아키텍처 중심의 기존 연구:**
  - [8], [9], [10], [11]: 특정 시계열 분석 작업에 대한 딥러닝 방법을 검토했지만, Transformer와 같은 고급 아키텍처를 포함하지 않았습니다.
  - [12], [13]: 특정 딥러닝 아키텍처(예: Graph Neural Networks, Transformers)에 초점을 맞춰 시계열 분석을 검토했습니다.
  - [14], [15] (BasicTS, TFB): 기존 예측 방법의 공정한 평가를 가능하게 하는 예측 벤치마크를 제공했지만, 딥 모델의 아키텍처 설계에 대한 개요는 제공하지 않았습니다.
- **TSLib과의 비교:** TSLib은 이러한 기존 연구의 한계를 극복하고 작업 및 모델을 모두 포괄하는 포괄적인 검토와 함께 벤치마크를 제공합니다.

## 🛠️ Methodology

### 1. 시계열 기본 개념 및 분석 작업 정리

- **시계열 정의:** $X = \{x_1, x_2, ..., x_T\} \in \mathbb{R}^{T \times C}$ (T 시점, C 변수)로 정의하며, 시계열 분석의 핵심은 시점 의존성(temporal dependency)과 변수 간 상관관계(variate correlation)를 포착하는 것입니다.
- **주요 분석 작업:** 예측(Forecasting), 결측치 보간(Imputation), 이상 탐지(Anomaly Detection), 분류(Classification)의 4가지 주요 작업을 다룹니다.

### 2. 심층 시계열 모델의 기본 모듈 검토

전통적인 시계열 분석 도구들이 현대 딥 모델에 통합된 방식을 설명합니다.

- **정상화(Stationarization):**
  - 데이터 정규화 ([35])를 통해 값 분포를 표준화하고 분포 변화를 완화합니다.
  - DAIN [36], RevIN [37], Non-Stationary Transformer (Stationary) [38] 등이 비정상성 문제를 해결하기 위한 특수 레이어를 제안합니다. Stationary는 다음과 같이 요약됩니다:
    $$
    \mu_x = \frac{1}{T} \sum_{i=1}^{T} x_i, \sigma_x^2 = \frac{1}{T} \sum_{i=1}^{T} (x_i - \mu_x)^2, \\
    \bar{X} = \frac{(X - \mu_x)}{\sqrt{\sigma_x^2 + \epsilon}}, \\
    \bar{Y} = \text{Model}(\bar{X}), \\
    \hat{Y} = \sigma_x^2 (\bar{Y} + \mu_x)
    $$
- **분해(Decomposition):**

  - **계절-추세 분해(Seasonal-Trend Decomposition):** Autoformer [22]가 평균 풀링 기반의 분해 블록을 도입하여 추세($X_T$)와 계절성($X_S$) 부분을 분리합니다.
    $$
    X_T = \text{AvgPool}(\text{Padding}(X)), \\
    X_S = X - X_T
    $$
  - **기저 확장(Basis Expansion):** N-BEATS [54]는 계층적 분해를 위해 완전 연결 레이어를 사용하고, N-HiTs [55]는 다중 주파수 샘플링을 통합합니다.
  - **행렬 인수분해(Matrix Factorization):** 고차원 다변량 시계열을 저차원 잠재 공간의 두 행렬 곱으로 분해합니다 (예: TRMF [59], DeepGLO [63]).

- **푸리에 분석(Fourier Analysis):**
  - **시간 영역 모델링:** TimesNet [3]은 FFT를 사용하여 가장 중요한 주파수를 추출하고 1D 시계열을 2D 공간으로 재구성하여 계층적 표현 학습을 촉진합니다. FEDformer [83]는 저주파 및 고주파 성분을 모두 포착합니다.
  - **주파수 영역 모델링:** STFNet [73], StemGNN [87], FreTS [89] 등은 주파수 도메인에서 직접 필터링, 합성곱, 풀링 또는 그래프 합성곱을 수행합니다.

### 3. 심층 시계열 모델 아키텍처 검토

다섯 가지 아키텍처 백본에 따라 기존 접근 방식을 분류합니다.

- **MLP 기반:** N-BEATS [24], DLinear [50], TSMixer [95], TiDE [96], Koopa [98] 등 선형 또는 완전 연결 레이어를 활용합니다.
- **RNN 기반:** LSTNet [110], DeepAR [112], Mamba [118], Neural ODEs [119] 등 순차 데이터 처리에 특화되어 시점 의존성을 포착합니다.
- **CNN 기반:** SCINet [130], Wavenet [131], TCN [132], TimesNet [3], MICN [133] 등 지역적 특징 및 복잡한 패턴 인식을 위해 1D 또는 2D CNN을 사용합니다.
- **GNN 기반:** DCRNN [139], STGCN [140], Graph WaveNet [141], AGCRN [142], MTGNN [143] 등 다변량 데이터의 잠재적 위상 관계를 모델링합니다.
- **Transformer 기반:** self-attention 메커니즘 [152]을 활용하여 장기 시점 의존성과 다변량 상관관계를 포착하며, 토큰화 방식에 따라 분류됩니다.
  - **점 단위(Point-wise) 의존성:** Informer [21], LogSparse [153] 등.
  - **패치 단위(Patch-wise) 의존성:** Autoformer [22], PatchTST [23], Crossformer [155] 등.
  - **시계열 단위(Series-wise) 의존성:** iTransformer [39], TimeXer [161] 등.

### 4. Time Series Library (TSLib) 벤치마크

- **설계 원칙:** 팩토리 패턴 기반의 모듈성과 유연성, 데이터-모델-실험 객체 간의 통일된 인터페이스를 제공합니다.
- **지원 데이터셋:** ETT, Electricity, Weather, Traffic, M4 등 30개 이상의 실제 데이터셋을 포함하며, 장/단기 예측, 분류, 결측치 보간, 이상 탐지 등 5가지 작업을 지원합니다.
- **평가 프로토콜 및 지표:**
  - **장기 예측 및 결측치 보간:** MSE, MAE.
  - **단기 예측:** SMAPE, MASE.
  - **분류:** 정확도(Accuracy).
  - **이상 탐지:** F1-score.
- **실험 설정:** PyTorch 및 NVIDIA A100 GPU 환경에서 Adam optimizer를 사용하며, 각 모델에 대한 광범위한 하이퍼파라미터 탐색을 수행했습니다. look-back 길이 탐색을 통해 공정한 비교를 보장했습니다.

## 📊 Results

- **모델별 성능:**
  - **예측 (장/단기):** iTransformer [39]와 PatchTST [23]를 포함한 Transformer 기반 모델이 가장 우수한 성능을 보였습니다.
  - **분류, 결측치 보간, 이상 탐지:** TimesNet [3] (CNN 기반)이 가장 포괄적이고 효과적인 성능을 보였습니다.
- **아키텍처별 성능 요약 (TSLib 전체 데이터셋 및 작업 평균):**
  - **MLP 기반:** 시계열 예측에서 우수한 성능과 효율성을 보였으나, 다른 작업에서는 효과가 제한적이었습니다.
  - **CNN 기반:** 분류, 결측치 보간, 이상 탐지에서 포괄적인 역량을 입증했습니다.
  - **RNN 기반:** 이상 탐지에서는 좋은 성능을 보였으나, 다른 아키텍처에 비해 효과가 제한적이었습니다.
  - **Transformer 기반:** 다양한 시계열 분석 작업 전반에 걸쳐 매우 경쟁력 있는 성능을 보였으며, 강력한 데이터 모델링 능력 덕분으로 분석됩니다.
- **효율성 분석 (훈련 시간, 추론 시간, 메모리 사용량):**
  - **MLP 기반 모델 및 Mamba [118]:** 가장 뛰어난 효율성을 보였습니다.
  - **CNN 기반 모델 (SCINet [130], TimesNet [3]):** 복잡한 시간 패턴 포착을 위해 다양한 커널을 채택하여 시간이 많이 소요되었습니다.
  - **Transformer 기반:** 토큰화 전략이 효율성에 영향을 미치며, 점 단위 토큰을 사용하는 Autoformer [22]는 패치 단위(PatchTST [23])나 시계열 단위(iTransformer [39])보다 느렸습니다.
  - 효율성과 예측 성능 간의 상충 관계가 확인되었습니다.

## 🧠 Insights & Discussion

- **모델 아키텍처와 작업 특성의 부합:** 특정 모델 아키텍처는 특정 시계열 분석 작업에 더 적합합니다. Transformer는 광범위한 작업에서 강력한 성능을 보이지만, 단순한 MLP는 예측 작업에서 효율성과 성능의 균형을 이룹니다.
- **TSLib의 가치:** TSLib은 모델의 특성에 대한 유용한 통찰력과 모델 선택 가이드를 제공하여 미래 연구 및 실제 적용에 중요한 출발점을 제공합니다.
- **향후 연구 방향:**
  - **시계열 사전 학습(Pre-training):** 레이블링된 데이터 부족을 해결하기 위해 대조 학습(contrastive learning) [187] 및 마스킹 시계열 모델링(masked time series modeling) [16] 기반의 자기 지도(self-supervised) 사전 학습 방식이 중요합니다.
  - **대규모 시계열 모델(Large Time Series Models):** 대규모 언어 모델(LLM)의 성공을 바탕으로 TimeGPT [206], Lag-LlaMa [207], Timer [157]와 같은 시계열 파운데이션 모델(Foundation Models) 개발이 유망합니다. LLM을 시계열 토큰화 및 효율적인 미세 조정(fine-tuning)을 통해 시계열 작업에 적용하는 연구 (예: LLM4TS [211], Chronos [213], GPT4TS [156])와 프롬프팅(prompting)을 활용하는 연구 (예: PromptCast [218], TimeLLM [220])가 진행될 것입니다.
  - **실용적 적용:**
    - **확률론적 예측(Probabilistic Forecasting):** 불확실성 하의 의사결정을 위해 미래 결과의 분포를 예측하는 모델 개발.
    - **극도로 긴 시계열 처리:** 확장성 및 계산 복잡성 문제 해결.
    - **외생 변수(Exogenous Variables) 활용:** 내생 변수와 외생 변수 간의 관계를 모델링하는 통합 프레임워크 구축.
    - **이질적 데이터(Heterogeneous Data) 처리:** 다양한 샘플링 속도, 불규칙성, 길이 척도를 가진 시계열 데이터 처리.

## 📌 TL;DR

이 논문은 복잡하고 동적인 시계열 데이터 분석 문제를 해결하기 위해 **심층 시계열 모델에 대한 포괄적인 조사와 벤치마크를 제시**합니다. 저자들은 기본 모듈과 모델 아키텍처 관점에서 기존 모델들을 체계적으로 검토하고, **TSLib (Time Series Library)**라는 공정하고 포괄적인 벤치마크를 개발했습니다. TSLib은 30개 모델, 30개 데이터셋, 5개 분석 작업을 지원하며, 이를 통해 13개 모델을 평가한 결과, 특정 아키텍처가 특정 작업에 더 적합하며 Transformer 기반 모델이 전반적으로 강력한 성능을 보임을 확인했습니다. MLP 기반 모델은 예측에서 효율적이지만, TimesNet (CNN 기반)은 다방면에서 뛰어난 성능을 보였습니다. 논문은 시계열 사전 학습, 대규모 시계열 모델, 실용적 응용 등 미래 연구 방향에 대한 심도 깊은 논의를 제공합니다.
