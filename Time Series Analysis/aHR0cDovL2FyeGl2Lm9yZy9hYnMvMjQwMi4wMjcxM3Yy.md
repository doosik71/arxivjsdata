# Position: What Can Large Language Models Tell Us about Time Series Analysis

Ming Jin, Yifan Zhang, Wei Chen, Kexin Zhang, Yuxuan Liang, Bin Yang, Jindong Wang, Shirui Pan, Qingsong Wen

## 🧩 Problem to Solve

시계열 분석은 다양한 실제 시스템과 애플리케이션에 필수적이지만, 기존 시계열 모델은 주로 특정 도메인 지식과 광범위한 모델 튜닝에 의존하며 예측 작업에 집중합니다. 이러한 접근 방식은 시계열 분석 역량을 갖춘 범용 인공지능(AGI) 개발과의 간극을 야기합니다. 대규모 언어 모델(LLM)의 최근 발전에도 불구하고, LLM을 시계열 분석에 통합하여 효율적인 의사 결정을 촉진하고 시계열 양식 전환 및 질의 응답과 같은 광범위한 가능성을 여는 보편적인 시계열 분석 지능으로 나아가는 것은 아직 초기 단계에 있습니다.

## ✨ Key Contributions

- **새로운 관점 제시**: LLM 중심 시계열 분석에 대한 저자들의 입장을 표명하고, LLM과 시계열 분석 모델 간의 잠재적 시너지를 설명하며, 이 분야에 대한 연구 집중의 필요성을 강조합니다.
- **체계적인 검토 및 분류**: 기존 예비 작업을 면밀히 검토하고 LLM과 시계열 분석의 세 가지 잠재적 통합 형태를 강조하는 명확한 로드맵을 제시합니다.
- **미래 기회 식별**: 현재 연구에서 다루지 않은 영역을 탐색하고, 이 발전하는 학제 간 분야에서 유망한 미래 연구 방향을 제시합니다.

## 📎 Related Works

- **시계열 분석**: ARIMA, Holt-Winters와 같은 전통적인 통계 모델부터 심층 학습 기반 기법(순환 신경망, 시간 컨볼루션 신경망) 및 사전 학습된 시계열 모델(TimeCLR)에 이르기까지 발전해 왔습니다.
- **대규모 언어 모델 (LLM)**: GPT-4, Llama와 같은 모델들은 모델 및 데이터 규모 확장을 통해 다양한 자연어 처리(NLP) 작업에서 성능 향상을 이끌어냈습니다. 문맥 내 학습(ICL), 지시 따르기, 단계별 추론(Chain-of-Thought)과 같은 LLM의 새로운 능력들이 주목받고 있습니다.
- **LLM과 시계열의 교차점**: LLM의 역량을 시계열 데이터와 같은 다른 데이터 양식으로 확장하려는 초기 연구들이 진행되고 있습니다.

## 🛠️ Methodology

본 논문은 LLM이 시계열 분석에 기여할 수 있는 세 가지 핵심 역할을 제시하며, 각각에 대한 통합 방안을 탐색합니다.

### LLM 지원 증강기 (LLM-assisted Enhancer)

LLM이 시계열 데이터에 대한 이해를 높이고 기존 모델의 지식을 확장하는 방법을 모색합니다.

- **데이터 기반 증강기**: LLM이 시계열 데이터의 패턴과 이상을 이해하는 데 도움이 되는 텍스트 설명 및 요약을 제공합니다.
  - 예시: LLM-MPE (인간 이동성 데이터), SignalGPT (생체 신호), Insight Miner (트렌드 마이닝).
- **모델 기반 증강기**: LLM의 방대한 내부 지식과 추론 능력을 활용하여 기존 시계열 모델의 외부 지식 및 도메인별 컨텍스트 한계를 보완합니다.
  - 접근 방식: 이중 타워 모델, 대조 학습을 통한 정렬(IMU2CLIP, STLLM), 프롬프트 기법 활용(TrafficGPT).

### LLM 중심 예측기 (LLM-centered Predictor)

LLM의 방대한 지식을 예측 및 이상 탐지와 같은 다양한 시계열 작업에 활용합니다.

- **튜닝 기반 예측기**: LLM 매개변수에 접근하여 시계열 데이터를 패치화 및 토큰화하고 관련 텍스트 데이터와 함께 미세 조정합니다.
  - **과정**:
    1. **전처리**: 시간 시리즈를 패치 기반 토큰으로 분할($X_{\text{inp}} = \text{Patching}(X)$)하고, 관련 텍스트 데이터를 토큰화($T_{\text{inp}} = \text{Tokenizer}(T)$)합니다.
    2. **분석**: 이들을 LLM($f_{\triangle \text{LLM}}$)에 입력하고, 추가 태스크 레이어($\text{Task}(\cdot)$)를 통해 예측($\hat{Y}$)을 수행합니다.
       $$
       \hat{Y} = \text{Task}(f_{\triangle \text{LLM}}(X_{\text{inp}}, T_{\text{inp}}, P))
       $$
  - 예시: Time-LLM, OFA, UniTime.
- **비튜닝 기반 예측기**: 폐쇄형 LLM에 적합하며, 시계열 데이터를 LLM의 입력 공간에 맞게 전처리합니다.
  - **과정**:
    1. **전처리**: 원시 시계열을 프롬프트 템플릿($\text{Template}(\cdot)$)이나 사용자 지정 토크나이저($\text{Tokenizer}(\cdot)$)로 처리하여 입력($X_{\text{inp}}$)을 만듭니다.
    2. **분석**: 처리된 입력($X_{\text{inp}}$)을 블랙박스 LLM($f_{\triangle \text{LLM}}$)에 입력하여 응답을 얻고, $\text{Parse}(\cdot)$ 함수를 통해 예측 라벨($\hat{Y}$)을 추출합니다.
       $$
       \hat{Y} = \text{Parse}(f_{\triangle \text{LLM}}(X_{\text{inp}}))
       $$
  - 예시: LLMTime, PromptCast.
- **기타**: 처음부터 대규모 시계열 파운데이션 모델을 구축하는 접근 방식도 논의됩니다.

### LLM 기반 에이전트 (LLM-empowered Agent)

LLM을 일반 목적의 시계열 분석 및 문제 해결을 위한 에이전트로 직접 활용하는 방안을 모색합니다.

- **시계열 특징과 언어 모델 표현 정렬**: 시계열 특징을 사전 학습된 언어 모델 표현과 명시적으로 정렬하여 시간 패턴에 대한 이해를 높입니다.
- **텍스트 임베딩 및 시계열 특징 융합**: 텍스트 임베딩과 시계열 특징을 LLM에 최적화된 형식으로 융합합니다.
- **외부 도구 활용 교육**: LLM이 외부 "도구 상자"에서 적절한 사전 학습된 시계열 모델이나 분석 도구를 식별하고 사용자 쿼리에 따라 사용법을 안내하도록 가르칩니다. LLM은 고수준 에이전트 역할을 하여 도구 활용을 조율합니다.

## 📊 Results

인간 활동 인식(HAR) 데이터베이스를 사용하여 GPT-3.5의 제로-샷 분류 능력을 평가한 결과는 다음과 같습니다:

- **효과적인 분석 에이전트 역할**: LLM은 인간 상호작용 및 시계열 데이터 분석 에이전트로서 뛰어난 성능을 보였으며, 특히 'Stand' 활동은 모두 정확하게 분류되었습니다. 이는 LLM이 일반적인 행동 패턴과 다양한 시계열 작업(분류, 이상 탐지, 데이터 증강)에 대한 심층적인 이해를 가지고 있음을 시사합니다.
- **높은 해석 가능성 및 진실성**: 에이전트 시스템은 높은 해석 가능성과 진실성을 제공하여, 사용자가 LLM의 결정 이유에 대해 문의할 수 있습니다. LLM은 자연어로 분류 추론을 설명할 수 있습니다.
- **복잡한 패턴 이해의 한계**: LLM은 복잡한 시계열 패턴을 이해하는 데 한계를 보입니다. 복잡한 쿼리에 직면했을 때, 기본 분류 알고리즘에 대한 상세 정보가 부족하다는 이유로 답변을 거부할 수 있습니다.
- **편향 및 태스크 선호**: LLM은 훈련 언어 분포에 대한 편향을 보이며 특정 태스크에 강한 선호를 가집니다. 예를 들어, 'Lay' 활동은 'Sit' 및 'Stand'로 잘못 분류되는 경향이 있었습니다.
- **환각 (Hallucination) 문제**: LLM은 그럴듯하지만 잘못된 답변을 생성하는 환각 문제에 취약합니다. 데이터 증강 시 원본 인스턴스를 단순히 복사하고도 그럴듯한 설명을 제공하거나, 오분류에 대한 그럴듯하지만 조작된 정당화를 제시하는 경우가 있었습니다.

## 🧠 Insights & Discussion

- **LLM 지원 증강기**: 시계열 데이터의 희소성과 노이즈 문제를 해결하고 기존 모델에 외부 지식과 분석 능력을 제공하는 유망한 방향입니다. 특히 정보 밀도가 낮은 시계열 데이터에서 LLM의 역할이 중요합니다. 그러나 대규모 데이터셋 처리 시 상당한 시간 및 비용 오버헤드를 유발하며, 보편적으로 효과적인 증강기 개발이 복잡하다는 한계가 있습니다.
- **LLM 중심 예측기**: 시계열 분석에서 크게 발전하여 소수-샷 및 제로-샷 시나리오에서 많은 도메인 특화 모델보다 우수한 성능을 보입니다. 튜닝 기반 방법은 성능과 적응성은 좋지만, 치명적 망각(catastrophic forgetting)과 높은 훈련 비용 문제가 있습니다. 비튜닝 방법은 수동 프롬프트 엔지니어링에 의존하며 예측 안정성이 떨어질 수 있습니다. 향후에는 튜닝 비용을 줄이고 예측 안정성 및 신뢰성을 높이는 방향으로 발전해야 합니다.
- **LLM 기반 에이전트**: 시계열 에이전트 시스템으로서 LLM은 잠재력이 크지만, 부정확성과 환각이라는 문제에 직면합니다. 신뢰성 강화를 위해 효과적인 지시 가이드라인과 도메인별 지식 통합이 필수적입니다. 인간 선호도에 맞춰 정렬하고 변화하는 시계열 데이터에 적응하는 능력 또한 중요합니다. 다중 에이전트 시스템의 탐색은 성능과 신뢰성을 향상시킬 수 있는 유망한 방향입니다.
- **추가 논의**:
  - **책임감 및 투명성**: LLM의 내부 메커니즘을 이해하고, 투명한 개발 및 평가 프레임워크를 구축하는 것이 중요합니다.
  - **프라이버시 및 보안**: 산업 시계열 데이터의 민감성을 고려할 때, 데이터 유출 및 오용에 대한 조치와 윤리적, 규제적 프레임워크가 필수적입니다.
  - **환경 및 계산 비용**: LLM 중심 시계열 분석의 높은 환경 및 계산 비용을 줄이기 위한 최적화 기회와 효율적인 정렬 및 추론 전략 탐색이 필요합니다.

## 📌 TL;DR

LLM은 시계열 분석을 혁신하고 일반 인공지능(AGI) 수준의 지능을 달성할 잠재력을 가지고 있습니다. 이 논문은 LLM을 시계열 데이터 분석을 위한 세 가지 주요 역할(증강기, 예측기, 에이전트)로 분류하고 각 통합 방식과 잠재력을 탐색합니다. LLM은 데이터 이해도를 높이고, 예측 성능을 향상시키며, 복잡한 문제를 해결하는 에이전트 역할을 수행할 수 있지만, 복잡한 패턴 이해의 한계, 편향, 환각과 같은 도전에 직면합니다. 향후 연구는 이러한 한계를 극복하고, LLM의 효율성, 투명성, 신뢰성을 높여 보편적인 시계열 분석 지능 시스템을 구축하는 데 집중해야 합니다.
