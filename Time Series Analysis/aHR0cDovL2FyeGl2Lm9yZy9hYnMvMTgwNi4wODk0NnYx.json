{
  "title": "Multilevel Wavelet Decomposition Network for Interpretable Time Series\n  Analysis",
  "authors": "Jingyuan Wang, Ze Wang, Jianfeng Li, Junjie Wu",
  "year": 2018,
  "url": "http://arxiv.org/abs/1806.08946v1",
  "abstract": "Recent years have witnessed the unprecedented rising of time series from\nalmost all kindes of academic and industrial fields. Various types of deep\nneural network models have been introduced to time series analysis, but the\nimportant frequency information is yet lack of effective modeling. In light of\nthis, in this paper we propose a wavelet-based neural network structure called\nmultilevel Wavelet Decomposition Network (mWDN) for building frequency-aware\ndeep learning models for time series analysis. mWDN preserves the advantage of\nmultilevel discrete wavelet decomposition in frequency learning while enables\nthe fine-tuning of all parameters under a deep neural network framework. Based\non mWDN, we further propose two deep learning models called Residual\nClassification Flow (RCF) and multi-frequecy Long Short-Term Memory (mLSTM) for\ntime series classification and forecasting, respectively. The two models take\nall or partial mWDN decomposed sub-series in different frequencies as input,\nand resort to the back propagation algorithm to learn all the parameters\nglobally, which enables seamless embedding of wavelet-based frequency analysis\ninto deep learning frameworks. Extensive experiments on 40 UCR datasets and a\nreal-world user volume dataset demonstrate the excellent performance of our\ntime series models based on mWDN. In particular, we propose an importance\nanalysis method to mWDN based models, which successfully identifies those\ntime-series elements and mWDN layers that are crucially important to time\nseries analysis. This indeed indicates the interpretability advantage of mWDN,\nand can be viewed as an indepth exploration to interpretable deep learning.",
  "citation": 296
}