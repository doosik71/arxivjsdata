# MOMENT: A Family of Open Time-series Foundation Models

Mononito Goswami, Konrad Szafer, Arjun Choudhry, Yifu Cai, Shuo Li, Artur Dubrawski

## 🧩 Problem to Solve

기존의 대규모 시계열 모델 사전 훈련은 다음 세 가지 주요 문제에 직면해 있습니다:

1. **데이터 부족**: 대규모의 응집력 있는 공개 시계열 저장소가 부재합니다.
2. **데이터 다양성 문제**: 시계열 데이터는 샘플링 속도, 채널 수, 길이, 진폭, 결측값 등 특성이 매우 다양하여 여러 데이터셋을 통합하여 훈련하기 어렵습니다.
3. **벤치마크 미성숙**: 제한된 자원, 시간, 감독 조건에서 시계열 파운데이션 모델을 평가할 수 있는 포괄적인 벤치마크가 아직 초기 단계에 있습니다.

이러한 도전과제를 해결하고 일반 목적의 시계열 분석을 위한 대규모 사전 훈련 모델을 개발하는 것이 목표입니다.

## ✨ Key Contributions

- **Time Series Pile 구축**: 방대하고 다양한 공개 시계열 데이터셋인 "Time Series Pile"을 구축하여 시계열 파운데이션 모델의 대규모 사전 훈련을 위한 기반을 마련했습니다.
- **다중 데이터셋 사전 훈련 기술 개발**: 시계열 데이터의 고유한 특성(다양한 길이, 채널, 해상도, 진폭 등)으로 인한 문제점을 체계적으로 해결하여 대규모 다중 데이터셋 사전 훈련을 가능하게 했습니다.
- **MOMENT 모델군 소개**: 마스크된 시계열 예측 태스크를 사용하여 Time Series Pile에 사전 훈련된 고용량 트랜스포머 모델인 MOMENT 모델군을 공개했습니다.
- **새로운 벤치마크 설계**: 제한된 감독 설정(예: 제로샷 예측, 선형 프로빙 분류)에서 다양한 태스크와 데이터셋에 대해 시계열 파운데이션 모델을 평가하는 벤치마크를 고안했습니다.
- **실증적 통찰 제공**: 사전 훈련된 대규모 시계열 모델의 특성(예: 모델 스케일링의 영향, 교차 모달 전이 학습, 초기화 전략)에 대한 흥미로운 실증적 관찰을 제시했습니다.

## 📎 Related Works

- **트랜스포머 및 패치 기법**: 시계열 데이터에 트랜스포머를 적용할 때 발생하는 쿼드라틱 복잡성 문제를 해결하기 위해 시계열 하위 시퀀스(패치)를 토큰으로 사용하는 Nie et al. (2023)의 PatchTST 연구에서 영감을 받았습니다.
- **마스크 기반 표현 학습**: BERT(Devlin et al., 2019) 및 MAE(Xie et al., 2022)와 같이 언어 및 비전 분야에서 성공적으로 사용된 마스크 기반 자기 지도 학습 기법을 시계열에 적용했습니다. 기존 시계열 연구는 대조 학습(contrastive learning)에 집중했으나, 본 연구는 마스크된 부분 재구성에 중점을 두었습니다.
- **언어 모델(LLMs)을 활용한 교차 모달 전이 학습**: LLMs가 다른 모달리티의 시퀀스 모델링 태스크를 효과적으로 해결할 수 있음을 보여준 Lu et al. (2022) 및 Time-LLM (Jin et al., 2023), GPT4TS (Zhou et al., 2023)와 같은 최근 연구들을 참고했습니다. MOMENT는 시간 시계열 데이터에 특화된 모델이 LLM 기반 모델을 능가할 수 있음을 보여줍니다.
- **미해결 과제**: 대규모 다중 데이터셋 사전 훈련의 이점 및 제한된 감독 설정(제로샷 예측, 소수샷 분류)에서의 시계열 모델링에 대한 연구가 부족하다는 점을 지적합니다.

## 🛠️ Methodology

MOMENT는 대규모 공개 시계열 데이터셋인 Time Series Pile에 마스크된 시계열 예측 태스크를 사용하여 사전 훈련된 트랜스포머 모델입니다.

1. **Time Series Pile 데이터 수집**:

   - Informer 장기 예측 데이터셋, Monash 단기 예측 아카이브, UCR/UEA 분류 아카이브, TSB-UAD 이상 탐지 벤치마크 등 4개의 널리 사용되는 공개 저장소에서 다양한 시계열 데이터를 수집했습니다.
   - 데이터 오염을 방지하기 위해 각 데이터셋을 훈련, 검증, 테스트 세트로 신중하게 분리했으며, 사전 훈련에는 훈련 세트만 사용했습니다.

2. **모델 아키텍처 (MOMENT)**:

   - **트랜스포머 인코더**: 입력 시계열 $T \in \mathbb{R}^{1 \times T}$를 $N$개의 고정 길이 패치(길이 $P=8$)로 분할합니다. 각 패치는 $D$차원 임베딩으로 매핑되며, 마스크된 패치는 특별한 `[MASK]` 임베딩으로 대체됩니다.
   - **다양한 시계열 특성 처리**: 가변 길이는 고정 길이 $T=512$로 샘플링/패딩하여 처리하고, 다변량 시계열은 채널 독립적으로 처리하며, 다양한 시간 분포는 가역 인스턴스 정규화(reversible instance normalization)를 통해 모델링합니다.
   - **경량 재구성 헤드**: 트랜스포머 인코더를 통과한 패치 임베딩을 사용하여 원본 시계열을 재구성합니다.
   - **위치 임베딩**: 상대적 위치 임베딩과 추가적인 절대 사인파 위치 임베딩을 모두 사용합니다.

3. **마스크된 시계열 모델링을 통한 사전 훈련**:

   - 훈련 중 무작위로 패치의 30%를 마스크하고, `[MASK]` 임베딩으로 대체합니다.
   - 사전 훈련 목표는 마스크된 패치에 대한 평균 제곱 오차(MSE)를 최소화하여 원본 시계열을 재구성하는 것입니다.
   - **모델 크기**: Small (4천만), Base (1억 2천 5백만), Large (3억 8천 5백만)의 세 가지 모델을 훈련했습니다.
   - **훈련 설정**: Adam 옵티마이저, 코사인 학습률 스케줄, 그라디언트 클리핑, 혼합 정밀도 훈련을 사용했습니다.

4. **다운스트림 태스크에 대한 미세 조정**:
   - MOMENT는 장기/단기 예측, 분류, 이상 탐지, 보간의 5가지 시계열 분석 태스크에 활용될 수 있습니다.
   - **예측 태스크**: 재구성 헤드를 예측 헤드로 교체하여 선형 투영 계층을 통해 $H$ 길이 시계열을 예측합니다.
   - **다른 태스크**: 재구성 헤드를 유지합니다.
   - **미세 조정 설정**: 전체 모델을 미세 조정하거나, 재구성/예측 헤드를 제외한 모든 파라미터를 고정하는 선형 프로빙(MOMENT$_{LP}$), 또는 재구성 헤드를 그대로 사용하여 명시적인 훈련 없이 예측하는 제로샷(MOMENT$_0$) 설정으로 사용될 수 있습니다.

## 📊 Results

- **장기 예측**: MOMENT$_{LP}$는 대부분의 데이터셋과 예측 기간에서 SOTA(State-of-the-Art)에 가까운 성능을 달성했으며, PatchTST에 이어 2위를 기록했습니다. Time-LLM 및 GPT4TS와 같은 LLM 기반 모델보다 우수한 성능을 보였습니다. N-BEATS는 여러 최신 방법을 능가하는 강력한 기준선임을 입증했습니다.
- **제로샷 단기 예측**: 통계적 방법(Theta, ETS)이 딥러닝 방법보다 우수한 경향을 보였으나, MOMENT는 일부 데이터셋에서 ARIMA보다 낮은 sMAPE를 달성했습니다.
- **분류**: 데이터별 미세 조정 없이도 MOMENT$_0$는 각 클래스에 대한 뚜렷한 표현을 학습하며, 그 표현으로 훈련된 SVM은 TimesNet 및 GPT4TS를 포함한 대부분의 다른 방법보다 높은 정확도를 보였습니다.
- **이상 탐지**: UCR 이상 탐지 아카이브의 44개 시계열에서 MOMENT는 제로샷 및 선형 프로빙 설정 모두에서 TimesNet, GPT4TS, 그리고 2개의 SOTA 이상 탐지 딥러닝 모델(DGHL, Anomaly Transformer)을 지속적으로 능가했습니다. K-최근접 이웃(k-NN)은 VUS-ROC에서 약간 더 좋았지만, Adjusted best $F_1$ 점수는 낮았습니다.
- **보간**: MOMENT$_{LP}$는 모든 ETT 데이터셋에서 가장 낮은 재구성 오차를 달성했습니다. 제로샷 설정에서 MOMENT$_0$는 선형 보간을 제외한 모든 통계적 보간 방법을 일관되게 능가했습니다.
- **모델 스케일링**: 모델 크기가 증가할수록 훈련 손실이 낮아져 LLM과 유사한 스케일링 특성을 보였습니다.
- **교차 모달 전이 학습**: 시계열에 사전 훈련된 MOMENT는 이미지, 텍스트, 이진 데이터에 대한 시퀀스 분류 태스크를 GPT-2 및 Flan-T5와 유사한 수준으로 해결할 수 있음을 보여주었습니다.
- **초기화**: 무작위로 초기화된 MOMENT가 언어 모델링 가중치로 초기화된 모델보다 낮은 훈련 손실에 수렴했습니다.

## 🧠 Insights & Discussion

- MOMENT는 시계열 데이터의 파운데이션 모델 가능성을 보여주며, "Time Series Pile"과 체계적인 사전 훈련 전략이 효과적임을 입증했습니다.
- 특히 데이터셋이 작고 감독 자원이 제한적인 이상 탐지 및 분류 문제에서 MOMENT의 뛰어난 성능은 대규모 사전 훈련의 중요성을 강조합니다.
- 직관적인 시계열 특성(추세, 진폭, 주파수, 위상)을 포착할 수 있지만, 정규화로 인해 수직으로 이동된 시계열을 구분하지 못하는 한계가 있습니다.
- 대규모 모델이 낮은 훈련 손실을 달성하고, 무작위 초기화가 LLM 가중치 초기화보다 더 효과적일 수 있다는 점은 시간 시계열 파운데이션 모델에 대한 중요한 통찰을 제공합니다.
- 교차 모달 전이 학습 능력은 MOMENT가 일반적인 시퀀스 학습 엔진으로 활용될 수 있음을 시사합니다.
- **윤리적 고려사항**: 고위험 환경(예: 의료)에서의 MOMENT 사용 시 예측의 신뢰성과 데이터 품질, 편향 가능성을 신중하게 고려해야 합니다. 투명성 지수 측면에서는 높은 "업스트림 투명성"을 보였지만, 시계열 모델링 맥락에서의 포괄적인 "피해 및 신뢰성 평가" 부족으로 인해 "모델 투명성" 점수는 낮았습니다.

## 📌 TL;DR

MOMENT는 대규모 시계열 데이터 사전 훈련의 난제를 해결하기 위해 도입된 최초의 오픈소스 시계열 파운데이션 모델군입니다. 이 논문은 방대한 "Time Series Pile" 데이터셋을 구축하고, 마스크된 시계열 예측을 통해 트랜스포머 모델을 사전 훈련합니다. MOMENT는 제한된 감독 설정에서도 예측, 분류, 이상 탐지, 보간 등 다양한 시계열 분석 태스크에서 효과적인 성능을 달성하며, 모델 스케일링, 교차 모달 전이 학습, 초기화 방법 등에 대한 중요한 실증적 통찰을 제공합니다.
