# Multilevel Wavelet Decomposition Network for Interpretable Time Series Analysis

Jingyuan Wang, Ze Wang, Jianfeng Li, Junjie Wu

## 🧩 Problem to Solve

시계열 분석을 위한 기존 딥러닝 모델들은 중요한 주파수 정보를 효과적으로 모델링하는 데 부족함이 있었습니다. 웨이블릿 변환과 같은 주파수 영역 방법은 유용하지만, 딥러닝 모델의 전처리 단계에서 독립적으로 사용되어 전역적으로 최적화되지 못하는 한계가 있었습니다. 따라서, 웨이블릿 변환을 딥러닝 프레임워크에 매끄럽게 통합하여 주파수 인지(frequency-aware) 모델을 구축하고, 모델의 해석 가능성(interpretability)을 높이는 것이 주된 연구 문제입니다.

## ✨ Key Contributions

- **다단계 웨이블릿 분해 네트워크 (mWDN) 제안:** 기존의 다단계 이산 웨이블릿 분해(MDWD)의 장점을 유지하면서 딥러닝 프레임워크 내에서 모든 파라미터를 훈련(fine-tuning)할 수 있는 웨이블릿 기반 신경망 구조를 개발했습니다.
- **시계열 분류 및 예측 모델 개발:** mWDN을 기반으로 시계열 분류(TSC)를 위한 **Residual Classification Flow (RCF)**와 시계열 예측(TSF)을 위한 **multi-frequency Long Short-Term Memory (mLSTM)** 두 가지 딥러닝 모델을 제안했습니다.
- **성능 우수성 입증:** 40개 UCR 데이터셋 및 실제 사용자 볼륨 데이터셋에 대한 광범위한 실험을 통해 제안된 모델들이 최첨단 기준선(state-of-the-art baselines)보다 우수한 성능을 보여주었습니다.
- **해석 가능성 분석 방법 제안:** mWDN 기반 모델에 대한 중요도 분석(importance analysis) 방법을 제안하여 시계열 분석에 결정적으로 중요한 요소와 mWDN 레이어를 성공적으로 식별함으로써 모델의 해석 가능성을 확보했습니다.

## 📎 Related Works

- **시계열 분석 방법:**
  - **시간 영역 방법:** RNN, LSTM, CNN 등 최근 딥러닝 모델들은 시계열의 시간적 상관관계나 지역적 패턴을 모델링하지만, 주파수 정보를 직접 활용하지 않는 경우가 많습니다.
  - **주파수 영역 방법:** 이산 푸리에 변환(DFT), Z-변환 등은 시계열을 주파수 스펙트럼으로 변환하여 특징으로 활용합니다.
- **웨이블릿 분해:** 다단계 이산 웨이블릿 분해(MDWD)는 시간-주파수 특징을 포착하는 데 효과적이지만, 보통 딥러닝 모델의 전처리 도구로 느슨하게 결합되어 사용됩니다.
- **시계열 분류(TSC):** 거리 기반(DTW), 특징 기반(SAX), 앙상블 방법(COTE) 등이 있으며, 최근에는 딥러닝 기반의 자동 특징 추출(MLP, FCN, ResNet) 연구가 활발합니다.
- **시계열 예측(TSF):** ARIMA, SARIMA와 같은 고전적인 모델과 함께, RNN, LSTM, SAE와 같은 딥러닝 모델이 복잡한 비선형 상관관계를 모델링하는 데 활용됩니다.
- **주파수 분석과 딥러닝 통합:** Clockwork RNN, SFM 등 일부 연구에서 주파수 분석 방법론을 딥러닝 프레임워크에 도입하려는 시도가 있었으나, 웨이블릿 변환을 신경망의 일부로 내장하여 엔드투엔드(end-to-end) 학습을 달성한 연구는 드뭅니다.

## 🛠️ Methodology

1. **다단계 웨이블릿 분해 네트워크 (mWDN):**

   - 표준 다단계 이산 웨이블릿 분해(MDWD)를 딥러닝 프레임워크 내에서 근사적으로 구현합니다.
   - 시계열 $x$를 하위 수준의 저주파($x_l^{(i)}$) 및 고주파($x_h^{(i)}$) 서브 시리즈로 계층적으로 분해합니다.
   - 분해 과정은 시그모이드(sigmoid) 활성화 함수와 훈련 가능한 가중치 행렬 $W_l^{(i)}$, $W_h^{(i)}$ 및 바이어스 $b_l^{(i)}$, $b_h^{(i)}$를 사용하는 다음과 같은 함수로 정의됩니다:
     $$a_l^{(i)} = \sigma(W_l^{(i)}x_l^{(i-1)} + b_l^{(i)})$$
     $$a_h^{(i)} = \sigma(W_h^{(i)}x_l^{(i-1)} + b_h^{(i)})$$
   - $W_l^{(i)}$와 $W_h^{(i)}$는 Daubechies 4 Wavelet 필터 계수로 초기화되지만, 학습 과정에서 데이터 분포에 맞게 미세 조정됩니다.
   - $a_l^{(i)}$와 $a_h^{(i)}$는 평균 풀링(average pooling) 레이어를 통해 1/2 다운샘플링되어 $x_l^{(i)}$와 $x_h^{(i)}$가 됩니다.

2. **Residual Classification Flow (RCF) for TSC:**

   - mWDN의 각 레벨에서 생성된 서브 시리즈 $x_h^{(i)}$와 $x_l^{(i)}$를 입력으로 받아 독립적인 순방향 신경망 $\psi(\cdot)$ (예: MLP, FCN, ResNet)으로 처리합니다.
   - 잔차 학습(residual learning) 방식을 사용하여 여러 분류기의 출력을 결합합니다: $\hat{c}^{(i)} = S(\hat{c}^{(i-1)} + u^{(i)})$, 여기서 $u^{(i)} = \psi(x_h^{(i)}, x_l^{(i)}, \theta_\psi)$ 이고 $S(\cdot)$는 소프트맥스(softmax) 분류기입니다.
   - 다양한 시간/주파수 해상도에서 시계열의 패턴을 다중 시점(multi-view)으로 활용합니다.

3. **Multi-frequency Long Short-Term Memory (mLSTM) for TSF:**

   - mWDN을 사용하여 입력 시계열을 여러 고주파 및 저주파 서브 시리즈 $X^{(N)} = \{x_h^{(1)}, \dots, x_h^{(N)}, x_l^{(N)}\}$로 분해합니다.
   - 각 서브 시리즈는 독립적인 LSTM 서브 네트워크의 입력으로 사용되어 미래 상태를 예측합니다.
   - 모든 LSTM 출력은 완전 연결 신경망(fully connected neural network)을 통해 앙상블(ensemble)되어 최종 예측을 수행합니다.

4. **최적화:**

   - **RCF:** 심층 감독(deep supervision) 방법을 사용하여 각 분류기의 교차 엔트로피 손실에 가중치를 부여한 합을 목적 함수로 사용합니다.
   - **mLSTM:** 사전 훈련(pre-training) 단계에서는 예측될 미래 상태의 실제 웨이블릿 성분과 LSTM 출력 간의 Frobenius Norm을 최소화하고, 이후 미세 조정(fine-tuning) 단계에서는 MSE(Mean Squared Error)를 사용하여 전체 모델을 훈련합니다.
   - **백프로파게이션:** RCF와 mLSTM의 모든 파라미터는 엔드투엔드로 백프로파게이션 알고리즘을 통해 훈련됩니다.
   - **정규화:** mWDN의 가중치 행렬 $W_l^{(i)}$, $W_h^{(i)}$에 L2 정규화 항을 추가하여 초기 웨이블릿 필터 값에서 너무 멀어지지 않도록 강제합니다 ( catastropic forgetting 방지).
     $$J^* = J(\theta) + \alpha \sum_i \|W_l^{(i)} - \tilde{W_l}^{(i)}\|_F^2 + \beta \sum_i \|W_h^{(i)} - \tilde{W_h}^{(i)}\|_F^2$$
     여기서 $\tilde{W}$는 $\epsilon=0$인 초기 가중치 행렬입니다.

5. **중요도 분석 (Interpretability):**
   - 모델 $M$의 출력 $p$에 대한 입력 시계열의 $i$번째 요소 $x_i$ 또는 mWDN의 중간 레이어 출력 $a$의 중요도를 정량화합니다.
   - 모델의 민감도(sensibility)를 해당 요소/레이어 출력에 대한 모델 출력의 부분 미분 절대값으로 정의합니다: $S(x_i) = \left|\frac{\partial M(x_i)}{\partial x_i}\right|$ 및 $S_a(x) = \left|\frac{\partial M(a(x))}{\partial a(x)}\right|$.
   - 중요도는 훈련 데이터셋 내 모든 샘플에 대한 민감도의 평균으로 계산합니다: $I(x_i) = \frac{1}{J}\sum_{j=1}^J S(\tilde{x}_i^{(j)})$.

## 📊 Results

- **시계열 분류(TSC) 성능 (40개 UCR 데이터셋):**
  - **FCN-RCF**가 가장 많은 데이터셋에서 1위를 차지하고 가장 낮은 MPCE(Mean Per-Class Error) 값을 달성하며 최고 성능을 기록했습니다.
  - MLP-RCF, FCN-RCF, ResNet-RCF와 같은 RCF 모델은 해당 베이스라인 모델(MLP, FCN, ResNet)보다 훨씬 우수한 성능을 보여 RCF 프레임워크의 효과를 입증했습니다.
  - ResNet-RCF는 고정된 파라미터를 가진 표준 MDWD를 사용하는 Wavelet-RCF보다 뛰어난 성능을 보였는데, 이는 훈련 가능한 mWDN 파라미터의 장점을 명확히 보여줍니다.
- **시계열 예측(TSF) 성능 (실제 WuxiCellPhone 사용자 볼륨 데이터셋):**
  - **mLSTM**은 SAE, RNN, LSTM, wLSTM(고정 MDWD 기반)을 포함한 모든 기준선 모델 대비 지속적으로 우수한 예측 성능(낮은 MAPE, RMSE)을 달성했습니다.
  - 예측 기간 길이나 예측 시점 간격이 달라져도 mLSTM의 우위는 유지되었으며, wLSTM 대비 성능 향상은 훈련 가능한 mWDN의 효과를 다시 한번 확인시켜주었습니다.
- **해석 가능성 (중요도 분석):**
  - **TSF (WuxiCellPhone):** 시계열에서 가장 최근의 요소들이 예측에 더 중요했으며, mWDN의 저주파 레이어(전반적인 경향)가 예측 성공에 결정적인 역할을 하는 것으로 나타났습니다.
  - **TSC (ECGFiveDays):** ECG 시계열의 T-파(T-Wave)에 해당하는 요소들이 분류에 가장 중요하게 식별되었는데, 이는 심장 기능 이상과 관련이 있다는 의학적 지식과 일치합니다. 분류 태스크에서는 mWDN의 고주파 레이어(비정상적인 변동)가 더 중요한 것으로 나타났는데, 이는 개인 간의 차이나 질병 식별에 고주파 정보가 더 중요함을 시사합니다.

## 🧠 Insights & Discussion

- **주파수 정보의 중요성:** mWDN을 통해 딥러닝 모델에 주파수 정보를 통합함으로써 시계열 분류 및 예측 성능이 크게 향상되었습니다.
- **훈련 가능한 웨이블릿의 강점:** 기존의 고정된 웨이블릿 변환 필터를 사용하는 대신, mWDN에서 웨이블릿 필터 파라미터를 훈련 가능하게 함으로써, 웨이블릿의 사전 지식과 실제 데이터의 가능도 사이에서 최적의 균형을 찾아 전역적으로 최적화된 모델을 구축할 수 있었습니다.
- **모델 해석 가능성 제공:** mWDN은 웨이블릿 분해의 물리적 의미를 계승하므로, 제안된 중요도 분석 방법을 통해 시계열의 어느 부분이, 그리고 mWDN의 어느 주파수 레이어가 모델의 최종 결정에 중요했는지 파악할 수 있습니다. 이는 딥러닝 모델의 "블랙박스" 문제를 해결하는 데 중요한 단초를 제공합니다.
- **태스크별 주파수 중요도의 차이:** 시계열 예측에서는 전반적인 추세를 나타내는 저주파 성분이 더 중요하고, 시계열 분류(특히 이상 감지)에서는 미묘한 패턴이나 변동을 나타내는 고주파 성분이 더 중요하다는 것을 중요도 분석을 통해 밝혀냈습니다.

## 📌 TL;DR

**문제:** 시계열 분석을 위한 딥러닝 모델들이 주파수 정보를 효과적으로 활용하지 못하고, 웨이블릿 변환과의 통합 및 해석 가능성이 부족함.
**제안 방법:** 훈련 가능한 웨이블릿 파라미터를 가진 신경망인 **mWDN**을 제안하여 주파수 인지 딥러닝 모델을 구축. mWDN 기반으로 시계열 분류를 위한 **RCF**와 시계열 예측을 위한 **mLSTM**을 개발하고, 모델의 해석 가능성을 높이는 중요도 분석 방법을 제시.
**주요 결과:** RCF와 mLSTM이 다양한 시계열 데이터셋에서 최첨단 성능을 달성했으며, mWDN의 훈련 가능한 파라미터가 고정된 웨이블릿보다 우수함을 입증. 중요도 분석을 통해 시계열 요소와 mWDN 레이어의 중요성을 성공적으로 식별하여 모델의 해석 가능성을 증명.
