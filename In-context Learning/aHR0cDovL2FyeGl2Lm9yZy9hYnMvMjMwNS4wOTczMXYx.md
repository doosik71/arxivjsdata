# What In-Context Learning “Learns” In-Context: Disentangling Task Recognition and Task Learning

Jane Pan, Tianyu Gao, Howard Chen, Danqi Chen

## 🧩 Problem to Solve

대규모 언어 모델(LLMs)의 인컨텍스트 학습(ICL) 메커니즘은 아직 완전히 이해되지 않고 있습니다. 일부 연구에서는 LLM이 사전 학습에서 이미 학습된 개념을 단순히 회상하는 것이라고 주장하는 반면, 다른 연구에서는 ICL이 데모를 통해 암묵적인 학습을 수행한다고 제안합니다. 이 논문은 ICL이 데모를 활용하는 두 가지 방법을 명확히 구분하고, 이들이 LLM의 크기 및 데모 수에 따라 어떻게 발현되는지 분석하는 것을 목표로 합니다.

## ✨ Key Contributions

- **ICL 메커니즘의 이분법적 분석**: ICL을 '태스크 인식(Task Recognition, TR)'과 '태스크 학습(Task Learning, TL)'의 두 가지 주요 능력으로 명확히 구분했습니다.
  - **태스크 인식(TR)**: LLM이 데모를 통해 태스크를 인식하고 사전 학습된 지식을 적용하는 능력. 이는 정답 레이블이 없어도 가능합니다.
  - **태스크 학습(TL)**: LLM이 데모에서 사전 학습 시 접하지 않은 새로운 입력-레이블 매핑을 학습하는 능력.
- **TR의 특성 규명**: TR은 모델의 크기나 데모의 수가 증가해도 성능이 크게 향상되지 않으며, 작은 모델에서도 유의미한 성능을 보입니다.
- **TL의 스케일 의존성 발견**: TL은 모델의 크기가 커질수록 능력이 발현되고, 데모의 수가 많아질수록 성능이 꾸준히 향상됩니다.
- **실험적 증명**: GPT-3, LLaMA, OPT 세 가지 LLM 계열과 다양한 분류 데이터셋에 걸쳐 통제된 실험을 통해 TR과 TL의 역할을 성공적으로 분리하고 그 특성을 밝혔습니다.

## 📎 Related Works

- **Xie et al. (2022)**: ICL을 암묵적인 베이지안 추론으로 설명하며, 모델이 사전 학습된 "개념"을 데모를 통해 식별한다고 제안합니다.
- **Min et al. (2022)**: ICL 성능이 정답 레이블에 둔감하다는 경험적 증거를 제시하며, 제한된 정보만으로도 ICL이 작동할 수 있음을 보여줍니다. 이 연구는 본 논문의 RANDOM 설정과 관련이 깊습니다.
- **Akyürek et al. (2023), von Oswald et al. (2022), Dai et al. (2023)**: 트랜스포머 기반 모델이 데모를 통해 "내부 모델"을 업데이트하는 암묵적 경사하강법을 수행할 수 있다고 가정합니다. 이는 ICL이 실제 학습을 수행한다는 가설을 뒷받침합니다.
- **Chan et al. (2022), Razeghi et al. (2022)**: 사전 학습 코퍼스의 분포 특성이 ICL에 미치는 영향을 조사합니다.
- **Yoo et al. (2022)**: 본 논문의 RANDOM 및 ABSTRACT 설정과 유사한 실험을 수행했지만, 모델 크기나 데모 수의 효과에 대한 심층적인 분석은 부족했습니다.
- **Wei et al. (2023)**: 유사한 결과를 얻었으며, 인스트럭션 튜닝이 TL보다 의미론적 사전 지식을 강화한다고 보여주었습니다.

## 🛠️ Methodology

연구자들은 ICL의 TR과 TL 능력을 분리하기 위해 레이블 공간을 조작하는 세 가지 설정을 설계하고, 이를 LLM의 크기와 데모 수에 따라 분석했습니다.

1. **GOLD 설정**:
   - 표준 ICL 설정으로, 자연어 프롬프트와 정답 입력-레이블 쌍을 사용합니다.
   - 이는 TR과 TL 능력이 동시에 반영되는 상황입니다.
2. **RANDOM 설정**:
   - GOLD와 동일한 자연어 프롬프트를 사용하지만, 데모 레이블은 레이블 공간에서 균일하게 무작위 샘플링됩니다.
   - 이 설정은 LLM이 입력 분포와 레이블 분포를 통해 태스크를 인식하지만, 올바른 입력-레이블 매핑을 학습할 수는 없도록 하여 **TR 능력만**을 반영합니다.
3. **ABSTRACT 설정**:
   - 최소한의 프롬프트(태스크 정보 없음)와 사전 학습 시 입력과 함께 나타나지 않은 추상적인 기호(예: 숫자, 문자, 무작위 기호)를 레이블로 사용합니다. 각 프롬프트에 대해 무작위 1:1 매핑 $\phi: Y \to Y^*$를 샘플링하여 편향을 피합니다.
   - 이 설정은 모델이 사전 학습된 지식에 의존하기 어렵게 하여 **TL 능력만**을 반영합니다.
4. **모델 및 데이터셋**:
   - GPT-3 (350M ~ 175B), LLaMA (7B ~ 65B), OPT (350M ~ 66B) 세 가지 LLM 계열을 사용했습니다.
   - 감성 분석, 유해성 탐지, 자연어 추론/문장 의역 탐지, 주제/입장 분류 등 4가지 유형의 16개 분류 데이터셋에 대해 실험했습니다.
5. **평가**:
   - 각 테스트 예시에 대해 훈련 세트에서 다른 데모 세트를 샘플링하는 프로토콜을 따랐습니다.
   - 각 태스크 유형별로 3가지 프롬프트 템플릿을 수동으로 설계했으며, 데이터셋과 프롬프트에 대한 평균 정확도를 보고했습니다.

## 📊 Results

- **전반적인 추세**:
  - **GOLD**는 항상 최상의 성능을 보였습니다 (예상대로 TR과 TL 모두 활용).
  - **RANDOM (TR)** 곡선은 모델 크기나 데모 수에 따라 거의 증가하지 않고 대체로 평탄했습니다.
  - **ABSTRACT (TL)** 곡선은 모델 크기와 데모 수가 증가함에 따라 점점 더 가파른 기울기를 보였습니다. 작은 모델이나 적은 데모 수($K$)에서는 ABSTRACT가 RANDOM보다 낮은 성능을 보였지만, 가장 큰 모델과 $K=32$ 데모에서는 ABSTRACT가 RANDOM을 훨씬 능가했습니다.
- **태스크 인식(TR)의 특성**:
  - 모든 모델 계열에서 RANDOM 설정의 성능은 모델 크기나 데모 수에 관계없이 유사했습니다.
  - 가장 작은 350M 모델에서도 8개의 데모만으로 무작위 추측보다 유의미하게 높은 성능을 달성하며, TR이 모델 크기나 데모 수에 따라 크게 확장되지 않는 폭넓은 능력임을 시사했습니다.
- **태스크 학습(TL)의 스케일 의존성**:
  - TL은 모델 크기에 크게 의존했습니다. 작은 모델에서는 데모 수에 관계없이 성능이 비슷했지만, 큰 모델일수록 ABSTRACT(TL) 성능이 크게 증가했습니다.
  - 데모 수가 증가할수록 TL 성능이 향상되었습니다. GPT-3 davinci(175B)와 OPT-66B는 16개의 데모만으로도 새로운 레이블 매핑을 학습하여 GOLD 성능에 근접했습니다. 이는 TL이 대규모 모델에서만 가능하며 더 많은 데모를 통해 개선됨을 보여줍니다.
- **추상 레이블 유형의 영향**:
  - 숫자, 문자, 기호와 같은 세 가지 유형의 추상 레이블 모두 유사한 TL 추세를 보였습니다. 숫자와 문자가 기호보다 일관되게 더 나은 성능을 보였는데, 이는 사전 학습 코퍼스에서 더 자주 등장하여 더 "자연스러운" 레이블 공간으로 작용하기 때문일 수 있습니다.
- **태스크 난이도의 영향**:
  - 태스크가 간단할수록 ABSTRACT(TL)가 모델 크기 및 데모 수에 따라 더 잘 확장되었습니다. 예를 들어, 자연어 추론(NLI)과 같은 어려운 태스크에서는 감성 분석보다 ABSTRACT 곡선이 더 평탄하게 나타나, 모델이 사전 학습된 지식에 더 많이 의존함을 시사했습니다.

## 🧠 Insights & Discussion

이 연구는 ICL이 단일한 현상이 아니라 '태스크 인식(TR)'과 '태스크 학습(TL)'이라는 두 가지 이질적인 능력으로 구성되어 있음을 명확히 밝혔습니다. TR은 작은 모델에서도 기본적인 수준으로 발휘되며 모델 스케일에 따라 크게 향상되지 않는 반면, TL은 대규모 모델에서 나타나는 emergent ability로, 모델 크기와 데모 수에 비례하여 성능이 크게 향상됩니다. 이러한 발견은 ICL의 작동 방식에 대한 이해를 심화하고, 향후 ICL 연구에서 이 두 가지 현상을 구분하여 실험 조건을 명확히 해야 할 필요성을 제기합니다.

**제한 사항**:

- 이 연구는 분류 태스크에만 초점을 맞췄으며, 다른 유형의 NLP 태스크에 대한 TR/TL 분석은 향후 연구로 남겨졌습니다.
- 모델이 추상 레이블에 대한 새로운 매핑을 "학습"하는 메커니즘은 여전히 불분명합니다. 암묵적 경사하강법 또는 사전 학습된 개념으로의 매핑과 같은 가설이 있지만, 이러한 내재적 작동 방식에 대한 추가적인 연구가 필요합니다.

## 📌 TL;DR

ICL은 '태스크 인식(TR)'과 '태스크 학습(TL)'으로 나뉩니다. TR은 모델 크기나 데모 수에 무관하게 발현되지만 성능이 확장되지 않습니다. 반면 TL은 대규모 모델에서만 나타나는 능력으로, 모델 스케일과 데모 수가 증가함에 따라 크게 향상됩니다. 이는 ICL 연구에서 두 가지 현상을 구분할 필요성을 시사합니다.
