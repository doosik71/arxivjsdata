{
  "url": "http://arxiv.org/abs/2406.05835v2",
  "title": "Mamba YOLO: A Simple Baseline for Object Detection with State Space\n  Model",
  "authors": "Zeyu Wang, Chen Li, Huiying Xu, Xinzhong Zhu, Hongbo Li",
  "year": 2024,
  "abstract": "Driven by the rapid development of deep learning technology, the YOLO series\nhas set a new benchmark for real-time object detectors. Additionally,\ntransformer-based structures have emerged as the most powerful solution in the\nfield, greatly extending the model's receptive field and achieving significant\nperformance improvements. However, this improvement comes at a cost as the\nquadratic complexity of the self-attentive mechanism increases the\ncomputational burden of the model. To address this problem, we introduce a\nsimple yet effective baseline approach called Mamba YOLO. Our contributions are\nas follows: 1) We propose that the ODMamba backbone introduce a \\textbf{S}tate\n\\textbf{S}pace \\textbf{M}odel (\\textbf{SSM}) with linear complexity to address\nthe quadratic complexity of self-attention. Unlike the other Transformer-base\nand SSM-base method, ODMamba is simple to train without pretraining. 2) For\nreal-time requirement, we designed the macro structure of ODMamba, determined\nthe optimal stage ratio and scaling size. 3) We design the RG Block that\nemploys a multi-branch structure to model the channel dimensions, which\naddresses the possible limitations of SSM in sequence modeling, such as\ninsufficient receptive fields and weak image localization. This design captures\nlocalized image dependencies more accurately and significantly. Extensive\nexperiments on the publicly available COCO benchmark dataset show that Mamba\nYOLO achieves state-of-the-art performance compared to previous methods.\nSpecifically, a tiny version of Mamba YOLO achieves a \\textbf{7.5}\\%\nimprovement in mAP on a single 4090 GPU with an inference time of \\textbf{1.5}\nms. The pytorch code is available at:\n\\url{https://github.com/HZAI-ZJNU/Mamba-YOLO}"
}