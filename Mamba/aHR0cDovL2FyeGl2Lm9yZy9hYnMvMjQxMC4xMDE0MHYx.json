{
  "title": "Hi-Mamba: Hierarchical Mamba for Efficient Image Super-Resolution",
  "authors": "Junbo Qiao, Jincheng Liao, Wei Li, Yulun Zhang, Yong Guo, Yi Wen, Zhangxizi Qiu, Jiao Xie, Jie Hu, Shaohui Lin",
  "year": 2024,
  "url": "http://arxiv.org/abs/2410.10140v1",
  "abstract": "State Space Models (SSM), such as Mamba, have shown strong representation\nability in modeling long-range dependency with linear complexity, achieving\nsuccessful applications from high-level to low-level vision tasks. However,\nSSM's sequential nature necessitates multiple scans in different directions to\ncompensate for the loss of spatial dependency when unfolding the image into a\n1D sequence. This multi-direction scanning strategy significantly increases the\ncomputation overhead and is unbearable for high-resolution image processing. To\naddress this problem, we propose a novel Hierarchical Mamba network, namely,\nHi-Mamba, for image super-resolution (SR). Hi-Mamba consists of two key\ndesigns: (1) The Hierarchical Mamba Block (HMB) assembled by a Local SSM\n(L-SSM) and a Region SSM (R-SSM) both with the single-direction scanning,\naggregates multi-scale representations to enhance the context modeling ability.\n(2) The Direction Alternation Hierarchical Mamba Group (DA-HMG) allocates the\nisomeric single-direction scanning into cascading HMBs to enrich the spatial\nrelationship modeling. Extensive experiments demonstrate the superiority of\nHi-Mamba across five benchmark datasets for efficient SR. For example, Hi-Mamba\nachieves a significant PSNR improvement of 0.29 dB on Manga109 for $\\times3$\nSR, compared to the strong lightweight MambaIR."
}