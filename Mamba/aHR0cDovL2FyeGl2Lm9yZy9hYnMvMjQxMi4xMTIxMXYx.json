{
  "title": "Deep Learning-based Approaches for State Space Models: A Selective\n  Review",
  "authors": "Jiahe Lin, George Michailidis",
  "year": 2024,
  "url": "http://arxiv.org/abs/2412.11211v1",
  "abstract": "State-space models (SSMs) offer a powerful framework for dynamical system\nanalysis, wherein the temporal dynamics of the system are assumed to be\ncaptured through the evolution of the latent states, which govern the values of\nthe observations. This paper provides a selective review of recent advancements\nin deep neural network-based approaches for SSMs, and presents a unified\nperspective for discrete time deep state space models and continuous time ones\nsuch as latent neural Ordinary Differential and Stochastic Differential\nEquations. It starts with an overview of the classical maximum likelihood based\napproach for learning SSMs, reviews variational autoencoder as a general\nlearning pipeline for neural network-based approaches in the presence of latent\nvariables, and discusses in detail representative deep learning models that\nfall under the SSM framework. Very recent developments, where SSMs are used as\nstandalone architectural modules for improving efficiency in sequence modeling,\nare also examined. Finally, examples involving mixed frequency and\nirregularly-spaced time series data are presented to demonstrate the advantage\nof SSMs in these settings."
}