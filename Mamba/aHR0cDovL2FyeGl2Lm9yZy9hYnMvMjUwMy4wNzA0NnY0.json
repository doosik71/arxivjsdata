{
  "title": "MambaFlow: A Mamba-Centric Architecture for End-to-End Optical Flow\n  Estimation",
  "authors": "Juntian Du, Zhihu Zhou, Runzhe Zhang, Yuan Sun, Pinyi Chen, Keji Mao",
  "year": 2025,
  "url": "http://arxiv.org/abs/2503.07046v4",
  "abstract": "Recently, the Mamba architecture has demonstrated significant successes in\nvarious computer vision tasks, such as classification and segmentation.\nHowever, its application to optical flow estimation remains unexplored. In this\npaper, we introduce MambaFlow, a novel framework designed to leverage the high\naccuracy and efficiency of the Mamba architecture for capturing locally\ncorrelated features while preserving global information in end-to-end optical\nflow estimation. To our knowledge, MambaFlow is the first architecture centered\naround the Mamba design tailored specifically for optical flow estimation. It\ncomprises two key components: (1) PolyMamba, which enhances feature\nrepresentation through a dual-Mamba architecture, incorporating a Self-Mamba\nmodule for intra-token modeling and a Cross-Mamba module for inter-modality\ninteraction, enabling both deep contextualization and effective feature fusion;\nand (2) PulseMamba, which leverages an Attention Guidance Aggregator (AGA) to\nadaptively integrate features with dynamically learned weights in contrast to\nnaive concatenation, and then employs the intrinsic recurrent mechanism of\nMamba to perform autoregressive flow decoding, facilitating efficient flow\ninformation dissemination. Extensive experiments demonstrate that MambaFlow\nachieves remarkable results comparable to mainstream methods on benchmark\ndatasets. Compared to SEA-RAFT, MambaFlow attains higher accuracy on the Sintel\nbenchmark, demonstrating stronger potential for real-world deployment on\nresource-constrained devices. The source code will be made publicly available\nupon acceptance of the paper."
}