# Visual Mamba: A Survey and New Outlooks

RUI XU, SHU YANG, YIHUI WANG, YU CAI, BO DU, HAO CHEN

## 🧩 Problem to Solve

거대 모델 시대에 시퀀스 모델링은 데이터 내 장거리 의존성(long-range dependencies)을 효과적으로 포착하고 긴 시퀀스 길이로 인한 막대한 계산 부담을 처리해야 하는 중요한 과제에 직면해 있습니다. 기존의 주요 기초 아키텍처들은 이러한 문제에서 각각 한계를 가집니다.

- **Convolutional Neural Networks (CNNs)**: 지역적인 수용 필드(local receptive fields)에 의존하여 지역적 패턴 모델링에 효율적이지만, 전역적 정보가 필요한 복잡한 시각 태스크에서 장거리 맥락(larger spatial contexts)을 포착하는 데 한계가 있습니다.
- **Vision Transformers (ViTs)**: 자기 어텐션(self-attention) 메커니즘을 통해 이미지 내 장거리 의존성을 효과적으로 포착하지만, 패치 수에 대해 이차 비례하는 $O(L^2)$의 계산 복잡도를 가져 확장성에 제약이 있습니다.
  Mamba는 이러한 CNN의 지역 지각 한계와 Transformer의 이차 계산 복잡도를 극복하며, 시각 기초 아키텍처로서의 큰 잠재력을 보여주었습니다.

## ✨ Key Contributions

이 논문은 급속도로 발전하는 Visual Mamba 분야의 연구 동향을 종합적으로 분석하며 다음과 같은 핵심 기여를 제시합니다.

- Mamba [20, 46] 모델의 기본 원리 및 기존 상태 공간 모델(State Space Model, SSM)과의 차이점을 명확하게 설명합니다.
- 대표적인 Visual Mamba 백본 네트워크를 심층적으로 분석하고, 핵심 원리 및 혁신적인 측면을 밝힙니다.
- 이미지, 비디오, 포인트 클라우드, 멀티모달 데이터 등 다양한 모달리티에 따른 Mamba의 적용 사례를 체계적으로 분류하고 심층 분석하여 각 모달리티에 Mamba 아키텍처가 어떻게 적응하고 이점을 제공하는지 강조합니다.
- Mamba를 시각 태스크에 적용하기 위한 핵심 요소인 "스캐닝 기법(scanning techniques)"을 식별하고, 기능과 다양한 애플리케이션에서의 유연성을 명확히 하기 위해 이를 세분화하여 제시합니다.
- Visual Mamba 모델의 현재 당면 과제(확장성, 인과성, 인컨텍스트 학습, 신뢰성 등)를 분석하고, 이 분야의 미래 연구 방향 및 새로운 전망을 제시합니다.

## 📎 Related Works

- **Convolutional Neural Networks (CNNs) [64, 90, 169]**: 지역적 수용 필드와 공간 불변성을 활용하여 시각 데이터 처리.
- **Vision Transformers (ViTs) [29]**: 자기 어텐션 메커니즘 [183]을 사용하여 이미지 패치 시퀀스를 처리, 장거리 의존성 포착.
- **State Space Model (SSM)**: 입력과 출력 시퀀스를 잠재 상태를 사용하여 연결하는 일반적인 개념 [50].
- **Structured State Space Model (S4) [49]**: SSM의 계산 및 메모리 제약을 해결하기 위해 상태 행렬을 재매개변수화.
- **Mamba-1 [46]**: SSM에 선택 메커니즘을 통합하여 입력에 따라 정보를 선택적으로 전파/망각, 하드웨어 인지 알고리즘으로 효율적인 계산 가능. H3 아키텍처 [38]에서 영감을 받음.
- **Mamba-2 [20]**: SSM과 어텐션의 변형 사이의 연결을 확립하고, 선택적 SSM을 SSD(State Space Duality) 알고리즘으로 정교화하여 계산 효율성 향상.
- **Visual Mamba Models**: VMamba [116], Vim [262], PlainMamba [225], Mamba-ND [97], GlobalMamba [187] 등 Mamba를 시각 태스크에 적용한 초기 및 대표적인 모델들.

## 🛠️ Methodology

### Mamba의 정식화

Mamba는 S4 [49]의 상태 공간 모델(SSM)을 기반으로 입력에 따라 매개변수를 조정하는 선택 메커니즘을 통합하여 맥락 기반 추론 능력을 향상시킵니다.

1. **상태 공간 모델 (SSM)**:
   - 1D 입력 신호 $x(t)$를 $N$차원 잠재 상태 $h(t)$를 통해 1D 출력 신호 $y(t)$로 매핑하는 선형 상미분 방정식으로 표현됩니다:
     $$h'(t) = A h(t) + B x(t), \quad y(t) = C h(t)$$
     여기서 $A \in \mathbb{R}^{N \times N}$, $B \in \mathbb{R}^{N \times 1}$, $C \in \mathbb{R}^{1 \times N}$는 매개변수입니다.
   - 이산화 규칙(zero-order hold)을 사용하여 연속 매개변수 $A, B$를 이산형 $A, B$로 변환합니다:
     $$A = \exp(\Delta A), \quad B = (\Delta A)^{-1}(\exp(\Delta A) - I) \cdot \Delta B$$
   - 이산화된 SSM은 순환 신경망(RNN)처럼 $h_t = A h_{t-1} + B x_t, y_t = C h_t$로 계산되지만, 효율적인 병렬 훈련을 위해 합성곱으로 재구성할 수 있습니다:
     $$K = (CB, CAB, \dots, CA^{L-1}B), \quad \mathcal{Y} = \mathcal{X} * K$$
2. **Mamba-1: 선택적 SSM (Selective SSM)**:
   - SSM 매개변수 $B, C, \Delta$를 입력 시퀀스 $x$의 함수로 만들어 문맥 기반 추론을 가능하게 합니다:
     $$B = s_B(x), \quad C = s_C(x), \quad \Delta = \tau_{\Delta}(\text{Parameter} + s_{\Delta}(x))$$
   - 선택적 SSM은 RNN이나 합성곱으로 직접 계산할 수 없으므로, 하드웨어 인지 알고리즘(병렬 스캔, 커널 퓨전, 재계산)을 사용하여 효율적으로 계산합니다.
3. **Mamba-2: 상태 공간 이중성 (State Space Duality, SSD)**:
   - SSM 변환을 행렬 형태로 재정의하여 어텐션 변형과의 연결을 확립합니다.
   - SSD 알고리즘을 도입하여 블록 분해를 활용함으로써 계산 및 메모리 효율성을 2-8배 향상시킵니다.
   - Mamba-1 블록에서 순차적 선형 프로젝션을 제거하고 SSM 매개변수 $A, B, C$를 병렬로 생성하는 등 블록 구조를 단순화합니다.

### Visual Mamba 백본 네트워크

시각 Mamba 백본 네트워크는 주로 토큰화 방법, 스캐닝 기법, 아키텍처 디자인에 초점을 맞춰 개발됩니다.

1. **토큰화 (Tokenization)**:

   - 2D 이미지를 스템 모듈(컨볼루션 레이어 및 선형 프로젝션)을 통해 시각 토큰 시퀀스로 변환합니다.
   - 1D 또는 2D 구조를 유지하며 SSM 변환을 적용합니다. 위치 임베딩은 선택 사항입니다.
   - GlobalMamba [187]와 같이 주파수 대역으로 이미지를 분할하여 토큰화하는 방식도 있습니다.

2. **스캐닝 기법 (Scanning Techniques)**:
   Mamba의 1D 인과적 스캔 메커니즘을 비인과적 시각 데이터에 적용하기 위한 핵심 기술입니다. 4가지 그룹으로 분류됩니다:

   - **스캔 방향 (Scan Direction)**:
     - **단방향(Single-directional, SD)**: Mamba의 원래 스캐닝 방식.
     - **양방향(Bi-directional, BD)**: 순방향 및 역방향 스캔을 통해 수용 필드를 상호 보완적으로 확장합니다.
   - **스캔 축 (Scan Axis)**:
     - 2D 이미지의 경우 **수평(H), 수직(V), 좌측 대각선(LD), 우측 대각선(RD)**.
     - 3D 데이터의 경우 **깊이(D)** 차원.
     - Vim-F [245]는 **주파수 영역(F)**에서 스캐닝을 적용합니다.
     - **채널(C)** 차원 스캐닝을 통해 채널별 정보 포착을 시도하기도 합니다.
   - **스캔 연속성 (Scan Continuity)**:
     - **래스터(Raster) 스캐닝**: 컴퓨터 메모리 레이아웃에 따라 이미지를 시퀀스로 평탄화하나, 공간적 불연속성을 유발할 수 있습니다.
     - **지그재그(Zigzag) 스캐닝**: 지그재그 경로를 따라 직렬화하여 인접 토큰 간의 공간적 연속성을 유지합니다.
     - **힐베르트(Hilbert) 스캐닝**: 공간 채움 곡선을 활용하여 토큰 간의 공간적 관계를 효과적으로 보존합니다.
     - **재정렬(Reordering) 스캐닝**: 시퀀스를 분할하여 고정된 순서로 샘플링합니다.
     - **셔플(Shuffle) 스캐닝**: 토큰 시퀀스 순서를 무작위화하여 위치 변환 불변성을 강화합니다.
   - **스캔 샘플링 (Scan Sampling)**:
     - **전역 샘플링(Global Sampling)**: 전체 이미지에 대해 작동합니다.
     - **지역 샘플링(Local Sampling)**: 이미지를 하위 이미지로 나누어 각 내부에서 스캔하여 지역적 의존성 포착을 개선합니다.
     - **아트루스 샘플링(Atrous Sampling)**: 건너뛰기 샘플링을 통해 전역적 의존성을 포착하며 계산 복잡도를 줄입니다.
     - **다중 스케일 샘플링(Multi-scale Sampling)**: 깊이별 컨볼루션을 사용하여 다중 스케일 특성 맵을 생성, 장거리 망각 문제를 완화하고 계산 비용을 줄입니다.
     - **쿼드트리 샘플링(Quadtree Sampling)**: 특징 기반으로 토큰의 지역성 점수를 추정하여 적응적으로 창 사분면으로 분할합니다.
     - **채널 샘플링(Channel Sampling)**: 이미지 채널을 그룹으로 나누어 계산 효율성을 높입니다.

3. **아키텍처 (Architecture)**:
   - **순수 Mamba 네트워크**: Vim [262], VMamba [116], PlainMamba [225], Mamba-ND [97]와 같이 Mamba 블록에만 의존합니다. VMamba의 SS2D (2D-Selective-Scan)는 입력 패치를 4개의 스캔 경로로 펼쳐 병렬로 처리 후 병합합니다.
   - **하이브리드 Mamba 네트워크**: MSVMamba [165], LocalMamba [75], SiMBA [143]와 같이 CNN 또는 어텐션과 Mamba 아키텍처를 결합하여 상호 보완적인 이점을 활용합니다.
   - **구조**: 계층적(hierarchical) 구조는 다운샘플링 레이어를 포함하여 계층적 표현을 생성하며, 평면적(plain) 구조는 동일한 블록을 쌓아 올립니다.

### 최적화 전략

아키텍처 개선 외에도 토큰 가지치기(token pruning) [240], SSD의 비인과 모드 적용(VSSD [164]), 2D SSM 확장(V2M [186], Spatial-Mamba [213]), 교차 레이어 특성 집계(SparX-Mamba [122]), 멀티 해상도 병렬 설계(HRVMamba [243]), 자기회귀 사전 훈련(ARM [153], MAP [118]) 등 다양한 최적화 전략이 탐색되었습니다.

## 📊 Results

Visual Mamba는 ImageNet-1K, MS COCO, ADE20K 등 표준 컴퓨터 비전 벤치마크에서 CNN 및 Transformer 기반 아키텍처와 비교되었습니다.

- **이미지 분류 (Image Classification)**:

  - Mamba 기반 네트워크는 유사한 계산 복잡도에서 CNN 기반 RegNetY [150] 및 Transformer 기반 DeiT [178]보다 우수한 성능을 보입니다.
  - 많은 Visual Mamba 네트워크가 CNN 기반 MambaOut [234] 및 Transformer 기반 Swin Transformer [119]를 능가했습니다.
  - 그러나 SVT [141], Wave-ViT [232], VOLO [236]와 같은 최첨단 Transformer 기반 네트워크는 여전히 Mamba보다 우수한 성능을 보였습니다.
  - 대부분의 Mamba 기반 네트워크는 소규모 구현에 국한되어 있으며, 대규모 모델로의 확장 및 성능 향상이 필요합니다.

- **객체 탐지 및 인스턴스 분할 (Object Detection and Instance Segmentation)**:

  - MS COCO 벤치마크에서 Mask R-CNN [63]을 사용하여 평가한 결과, Visual Mamba 네트워크는 CNN 기반 ConvNeXt [120]를 능가하며, 대부분의 Transformer 기반 모델보다 우수한 성능을 보였습니다.
  - 이는 Mamba의 장거리 의존성 포착 능력과 동적 가중치 활용이 밀집 예측(dense prediction) 태스크에 유리함을 시사합니다.
  - 그러나 SG-Former [154]와 같은 일부 Transformer 모델에는 미치지 못했습니다.

- **의미론적 분할 (Semantic Segmentation)**:
  - ADE20K 벤치마크에서 UperNet [214]을 사용하여 평가한 결과, Mamba 기반 네트워크는 모든 CNN 기반 네트워크와 대부분의 Transformer 기반 네트워크를 능가했습니다.
  - 객체 탐지 결과와 유사하게 SG-Former [154]보다는 성능이 낮았습니다.
  - 이 결과는 Mamba가 밀집 예측 태스크에서 효과적임을 다시 한번 입증합니다.

**요약**: Visual Mamba 네트워크는 유망한 성능을 보이지만, 최첨단 Transformer 기반 네트워크에는 미치지 못하며, 더 큰 모델 구성으로 확장하기 위한 추가 연구가 필요합니다.

## 🧠 Insights & Discussion

### 확장성 (Scalability)

1. **모델 크기 (Model Size)**: Mamba는 이론적으로 시퀀스 길이에 대해 선형적으로 확장되지만, 대규모 네트워크 구성에서 안정성 문제(vanishing/exploding gradients)에 직면합니다 [142, 143]. 현재 대부분의 Visual Mamba 모델은 소규모에 머물러 있으며, 성능 향상 및 대규모 확장을 위한 추가 안정화 기법과 자기 지도 사전 훈련(self-supervised pre-training) 전략 [153]이 필요합니다. Mamba-2 [20]는 SSD 알고리즘과 행렬 믹서 관점을 통해 성능 향상 방향을 제시합니다.
2. **데이터 (Data)**: Mamba는 고해상도 및 다차원 데이터(예: 고해상도 원격 감지 이미지, 3D 의료 이미지, 포인트 클라우드) 및 대규모 데이터셋(예: 다중 시간 원격 감지 이미지, 장기 비디오 프레임) 처리에 큰 잠재력을 가집니다. 또한, 매개변수 효율성과 내재된 지역 귀납적 편향(local inductive bias) 덕분에 소규모 데이터셋에서도 고성능을 유지하는 소형 Mamba 모델 개발 가능성이 있습니다.
3. **하드웨어 인지 (Hardware-aware)**: Mamba-1은 커널 퓨전 및 재계산을 통해 재귀 모드 훈련의 효율성을 높였으나, GPU 소비가 Transformer 대비 일관되게 감소하지는 않습니다 [201]. Mamba-2 [20]는 SSM과 어텐션 간의 이론적 연결을 통해 SSD 알고리즘을 도입하여 텐서 병렬화, 시퀀스 병렬화 등 Transformer의 시스템 최적화를 활용할 수 있게 합니다. 미래 연구는 Visual Mamba 모델의 계산 효율성을 높이는 하드웨어 인지 접근 방식에 집중해야 합니다.
4. **태스크 (Task)**: Mamba의 효율성과 장시퀀스 모델링 능력은 고차원 데이터 처리, 대규모 데이터셋 처리, 멀티모달 학습(시계열, 확장 텍스트 등), 실시간 대화형 시스템, 자율 주행 등 고속 및 고효율 애플리케이션에 적합합니다.

### 인과성 (Causality)

Mamba는 본질적으로 예측이 이전 및 현재 입력에만 의존하는 인과적 시스템입니다 [46]. 이는 자기회귀 모델에는 적합하지만, 비인과적 특성을 지닌 공간적 이미지의 본질과 상충됩니다.

- **불일치**: 다중 스캐닝 기법(방향, 축, 연속성, 샘플링)을 활용하여 전역적 수용 필드를 확보하려 하지만, 근본적인 인과성 문제를 해결하지 못하며, 스캔 순서에 따른 불일치와 불필요한 편향을 초래합니다. Transformer의 자기 어텐션은 모든 토큰을 일관되게 고려하여 이러한 문제를 피합니다.
- **중복성**: 여러 스캐닝 전략의 도입은 중복 정보를 발생시켜 모델 효율성을 저해하고 효과적인 지식 추출을 방해할 수 있습니다.
  따라서 Mamba가 시각 데이터의 다양한 위치에 있는 토큰을 일관되고 우아하게 고려하는 적절한 접근 방식을 설계하는 것이 중요한 과제입니다.

### 인컨텍스트 학습 (In-context Learning, ICL)

Mamba 모델은 Transformer와 유사하게 ICL 능력을 보여주며, 회귀 ICL 태스크 및 희소 패리티 학습에서 경쟁력 있는 성능을 달성했습니다 [140]. Mamba의 내재된 인과성은 Transformer의 ICL 확장 시 제약이 되는 위치 임베딩의 필요성을 제거합니다. 그러나 Mamba는 비표준 검색 기능(memory-intensive tasks)과 관련된 태스크에서는 어려움을 겪을 수 있습니다 [81]. Mamba-2 [20]에서는 이러한 태스크에서 상당한 개선을 보였으며, ICL 효율성은 문맥 내 예시 수에 비례하여 증가하는 것으로 나타났습니다 [45].

### 신뢰성 (Trustworthiness)

1. **해석 가능성 (Interpretability)**: Mamba의 NLP 애플리케이션에 대한 해석 가능성 연구는 진행되었지만 [45, 140, 160], 시각 태스크에서 Mamba가 효과적으로 작동하는 이유에 대한 깊은 이해는 여전히 부족합니다 [1, 80]. Visual Mamba의 독특한 학습 특성과 RNN, CNN, ViT와 같은 다른 기초 아키텍처와의 유사성에 대한 심층적인 해석이 필요합니다.
2. **일반화 (Generalization)**: Mamba의 숨겨진 상태는 도메인 특정 정보를 축적하거나 증폭시켜 일반화 성능에 부정적인 영향을 미칠 수 있습니다 [54, 121]. 1D 스캐닝 전략은 도메인 특정 편향을 포착할 수 있으므로, 도메인 불가지론적(domain-agnostic) 정보 처리를 위한 해결책이 요구됩니다.
3. **안전성 (Safety)**: VMamba [116]는 적대적 탄력성(adversarial resilience)과 강건성(robustness)에서 강점을 보였지만, 확장성 측면에서 한계를 드러냈습니다 [30]. 매개변수 $\Delta$는 견고한 반면 $B$와 $C$는 공격에 취약하며, 스캐닝 궤적의 연속성 및 공간 정보의 무결성에 민감하다는 점이 밝혀졌습니다. Visual Mamba의 안전성 강화는 미해결 과제입니다.

## 📌 TL;DR

Mamba는 Transformer의 이차 계산 복잡도($O(L^2)$) 문제를 선형 시간($O(L)$)으로 해결하면서도 강력한 장거리 시퀀스 모델링 능력을 제공하는 혁신적인 아키텍처입니다. 이 논문은 Mamba의 1D 인과적 특성을 2D/3D 시각 데이터의 비인과적 특성에 맞게 조정하기 위한 '스캐닝 기법'과 아키텍처를 분석한 Visual Mamba의 종합적인 최신 연구 동향을 제시합니다. 실험 결과 Mamba 기반 모델은 이미지 분류, 객체 탐지, 의미론적 분할 등 다양한 시각 태스크에서 CNN과 일반 Transformer를 능가하는 유망한 성능을 보였습니다. 그러나 최첨단 Transformer에 비해 아직 성능 격차가 존재하며, 대규모 모델로의 확장 시 불안정성, 인과성 불일치 문제, 인컨텍스트 학습 및 신뢰성(해석 가능성, 일반화, 안전성) 등 해결해야 할 과제들이 남아있습니다. 향후 연구는 이러한 도전 과제들을 해결하여 Visual Mamba의 잠재력을 완전히 발휘하는 데 중점을 둘 것입니다.
