{
  "title": "SR-Mamba: Effective Surgical Phase Recognition with State Space Model",
  "authors": "Rui Cao, Jiangliu Wang, Yun-Hui Liu",
  "year": 2024,
  "url": "http://arxiv.org/abs/2407.08333v1",
  "abstract": "Surgical phase recognition is crucial for enhancing the efficiency and safety\nof computer-assisted interventions. One of the fundamental challenges involves\nmodeling the long-distance temporal relationships present in surgical videos.\nInspired by the recent success of Mamba, a state space model with linear\nscalability in sequence length, this paper presents SR-Mamba, a novel\nattention-free model specifically tailored to meet the challenges of surgical\nphase recognition. In SR-Mamba, we leverage a bidirectional Mamba decoder to\neffectively model the temporal context in overlong sequences. Moreover, the\nefficient optimization of the proposed Mamba decoder facilitates single-step\nneural network training, eliminating the need for separate training steps as in\nprevious works. This single-step training approach not only simplifies the\ntraining process but also ensures higher accuracy, even with a lighter spatial\nfeature extractor. Our SR-Mamba establishes a new benchmark in surgical video\nanalysis by demonstrating state-of-the-art performance on the Cholec80 and\nCATARACTS Challenge datasets. The code is accessible at\nhttps://github.com/rcao-hk/SR-Mamba."
}