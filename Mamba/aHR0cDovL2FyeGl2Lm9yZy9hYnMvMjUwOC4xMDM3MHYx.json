{
  "title": "eMamba: Efficient Acceleration Framework for Mamba Models in Edge\n  Computing",
  "authors": "Jiyong Kim, Jaeho Lee, Jiahao Lin, Alish Kanani, Miao Sun, Umit Y. Ogras, Jaehyun Park",
  "year": 2025,
  "url": "http://arxiv.org/abs/2508.10370v1",
  "abstract": "State Space Model (SSM)-based machine learning architectures have recently\ngained significant attention for processing sequential data. Mamba, a recent\nsequence-to-sequence SSM, offers competitive accuracy with superior\ncomputational efficiency compared to state-of-the-art transformer models. While\nthis advantage makes Mamba particularly promising for resource-constrained edge\ndevices, no hardware acceleration frameworks are currently optimized for\ndeploying it in such environments. This paper presents eMamba, a comprehensive\nend-to-end hardware acceleration framework explicitly designed for deploying\nMamba models on edge platforms. eMamba maximizes computational efficiency by\nreplacing complex normalization layers with lightweight hardware-aware\nalternatives and approximating expensive operations, such as SiLU activation\nand exponentiation, considering the target applications. Then, it performs an\napproximation-aware neural architecture search (NAS) to tune the learnable\nparameters used during approximation. Evaluations with Fashion-MNIST, CIFAR-10,\nand MARS, an open-source human pose estimation dataset, show eMamba achieves\ncomparable accuracy to state-of-the-art techniques using 1.63-19.9$\\times$\nfewer parameters. In addition, it generalizes well to large-scale natural\nlanguage tasks, demonstrating stable perplexity across varying sequence lengths\non the WikiText2 dataset. We also quantize and implement the entire eMamba\npipeline on an AMD ZCU102 FPGA and ASIC using GlobalFoundries (GF) 22 nm\ntechnology. Experimental results show 4.95-5.62$\\times$ lower latency and\n2.22-9.95$\\times$ higher throughput, with 4.77$\\times$ smaller area,\n9.84$\\times$ lower power, and 48.6$\\times$ lower energy consumption than\nbaseline solutions while maintaining competitive accuracy."
}