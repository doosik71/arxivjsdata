{
  "title": "Vision Mamba Distillation for Low-resolution Fine-grained Image\n  Classification",
  "authors": "Yao Chen, Jiabao Wang, Peichao Wang, Rui Zhang, Yang Li",
  "year": 2024,
  "url": "http://arxiv.org/abs/2411.17980v1",
  "abstract": "Low-resolution fine-grained image classification has recently made\nsignificant progress, largely thanks to the super-resolution techniques and\nknowledge distillation methods. However, these approaches lead to an\nexponential increase in the number of parameters and computational complexity\nof models. In order to solve this problem, in this letter, we propose a Vision\nMamba Distillation (ViMD) approach to enhance the effectiveness and efficiency\nof low-resolution fine-grained image classification. Concretely, a lightweight\nsuper-resolution vision Mamba classification network (SRVM-Net) is proposed to\nimprove its capability for extracting visual features by redesigning the\nclassification sub-network with Mamba modeling. Moreover, we design a novel\nmulti-level Mamba knowledge distillation loss boosting the performance, which\ncan transfer prior knowledge obtained from a High-resolution Vision Mamba\nclassification Network (HRVM-Net) as a teacher into the proposed SRVM-Net as a\nstudent. Extensive experiments on seven public fine-grained classification\ndatasets related to benchmarks confirm our ViMD achieves a new state-of-the-art\nperformance. While having higher accuracy, ViMD outperforms similar methods\nwith fewer parameters and FLOPs, which is more suitable for embedded device\napplications. Code is available at https://github.com/boa2004plaust/ViMD."
}