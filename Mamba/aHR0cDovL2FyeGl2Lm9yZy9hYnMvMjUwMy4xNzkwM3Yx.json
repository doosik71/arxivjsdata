{
  "title": "GLADMamba: Unsupervised Graph-Level Anomaly Detection Powered by\n  Selective State Space Model",
  "authors": "Yali Fu, Jindong Li, Qi Wang, Qianli Xing",
  "year": 2025,
  "url": "http://arxiv.org/abs/2503.17903v1",
  "abstract": "Unsupervised graph-level anomaly detection (UGLAD) is a critical and\nchallenging task across various domains, such as social network analysis,\nanti-cancer drug discovery, and toxic molecule identification. However,\nexisting methods often struggle to capture the long-range dependencies\nefficiently and neglect the spectral information. Recently, selective State\nSpace Models (SSMs), particularly Mamba, have demonstrated remarkable\nadvantages in capturing long-range dependencies with linear complexity and a\nselection mechanism. Motivated by their success across various domains, we\npropose GLADMamba, a novel framework that adapts the selective state space\nmodel into UGLAD field. We design View-Fused Mamba (VFM) with a\nMamba-Transformer-style architecture to efficiently fuse information from\ndifferent views with a selective state mechanism. We also design\nSpectrum-Guided Mamba (SGM) with a Mamba-Transformer-style architecture to\nleverage the Rayleigh quotient to guide the embedding refining process.\nGLADMamba can dynamically focus on anomaly-related information while discarding\nirrelevant information for anomaly detection. To the best of our knowledge,\nthis is the first work to introduce Mamba and explicit spectral information to\nUGLAD. Extensive experiments on 12 real-world datasets demonstrate that\nGLADMamba outperforms existing state-of-the-art methods, achieving superior\nperformance in UGLAD. The code is available at\nhttps://github.com/Yali-F/GLADMamba."
}