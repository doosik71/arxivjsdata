{
  "title": "Exploring the Limitations of Mamba in COPY and CoT Reasoning",
  "authors": "Ruifeng Ren, Zhicong Li, Yong Liu",
  "year": 2024,
  "url": "http://arxiv.org/abs/2410.03810v3",
  "abstract": "Transformers have become the backbone of modern Large Language Models (LLMs);\nhowever, their inference overhead grows linearly with the sequence length,\nposing challenges for modeling long sequences. In light of this, Mamba has\nattracted attention for maintaining a constant inference size, with empirical\nevidence demonstrating that it can match Transformer performance in sequence\nmodeling while significantly reducing computational costs. However, an open\nquestion remains: can Mamba always bring savings while achieving performance\ncomparable to Transformers? In this paper, we focus on analyzing the expressive\nability of Mamba to perform our defined COPY operation and Chain of Thought\n(CoT) reasoning. First, inspired by the connection between Mamba and linear\nattention, we show that constant-sized Mamba may struggle to perform COPY\noperations while Transformers can handle them more easily. However, when the\nsize of Mamba grows linearly with the input sequence length, it can accurately\nperform COPY, but in this case, Mamba no longer provides overhead savings.\nBased on this observation, we further analyze Mamba's ability to tackle CoT\ntasks, which can be described by the Dynamic Programming (DP) problems. Our\nfindings suggest that to solve arbitrary DP problems, the total cost of Mamba\nis still comparable to standard Transformers. However, similar to efficient\nTransformers, when facing DP problems with favorable properties such as\nlocality, Mamba can provide savings in overhead. Our experiments on the copy\nand CoT tasks further demonstrate Mamba's limitations compared to Transformers\nin learning these tasks."
}