{
  "title": "Demystify Mamba in Vision: A Linear Attention Perspective",
  "authors": "Dongchen Han, Ziyi Wang, Zhuofan Xia, Yizeng Han, Yifan Pu, Chunjiang Ge, Jun Song, Shiji Song, Bo Zheng, Gao Huang",
  "year": 2024,
  "url": "http://arxiv.org/abs/2405.16605v2",
  "abstract": "Mamba is an effective state space model with linear computation complexity.\nIt has recently shown impressive efficiency in dealing with high-resolution\ninputs across various vision tasks. In this paper, we reveal that the powerful\nMamba model shares surprising similarities with linear attention Transformer,\nwhich typically underperform conventional Transformer in practice. By exploring\nthe similarities and disparities between the effective Mamba and subpar linear\nattention Transformer, we provide comprehensive analyses to demystify the key\nfactors behind Mamba's success. Specifically, we reformulate the selective\nstate space model and linear attention within a unified formulation, rephrasing\nMamba as a variant of linear attention Transformer with six major distinctions:\ninput gate, forget gate, shortcut, no attention normalization, single-head, and\nmodified block design. For each design, we meticulously analyze its pros and\ncons, and empirically evaluate its impact on model performance in vision tasks.\nInterestingly, the results highlight the forget gate and block design as the\ncore contributors to Mamba's success, while the other four designs are less\ncrucial. Based on these findings, we propose a Mamba-Inspired Linear Attention\n(MILA) model by incorporating the merits of these two key designs into linear\nattention. The resulting model outperforms various vision Mamba models in both\nimage classification and high-resolution dense prediction tasks, while enjoying\nparallelizable computation and fast inference speed. Code is available at\nhttps://github.com/LeapLabTHU/MLLA."
}