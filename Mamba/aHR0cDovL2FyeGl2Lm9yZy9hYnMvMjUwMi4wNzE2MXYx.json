{
  "title": "A Survey on Mamba Architecture for Vision Applications",
  "authors": "Fady Ibrahim, Guangjun Liu, Guanghui Wang",
  "year": 2025,
  "url": "http://arxiv.org/abs/2502.07161v1",
  "abstract": "Transformers have become foundational for visual tasks such as object\ndetection, semantic segmentation, and video understanding, but their quadratic\ncomplexity in attention mechanisms presents scalability challenges. To address\nthese limitations, the Mamba architecture utilizes state-space models (SSMs)\nfor linear scalability, efficient processing, and improved contextual\nawareness. This paper investigates Mamba architecture for visual domain\napplications and its recent advancements, including Vision Mamba (ViM) and\nVideoMamba, which introduce bidirectional scanning, selective scanning\nmechanisms, and spatiotemporal processing to enhance image and video\nunderstanding. Architectural innovations like position embeddings, cross-scan\nmodules, and hierarchical designs further optimize the Mamba framework for\nglobal and local feature extraction. These advancements position Mamba as a\npromising architecture in computer vision research and applications.",
  "citation": 7
}