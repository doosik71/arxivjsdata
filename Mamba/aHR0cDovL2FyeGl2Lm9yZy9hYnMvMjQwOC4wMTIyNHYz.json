{
  "title": "Multi-head Spatial-Spectral Mamba for Hyperspectral Image Classification",
  "authors": "Muhammad Ahmad, Muhammad Hassaan Farooq Butt, Muhammad Usama, Hamad Ahmed Altuwaijri, Manuel Mazzara, Salvatore Distefano",
  "year": 2024,
  "url": "http://arxiv.org/abs/2408.01224v3",
  "abstract": "Spatial-Spectral Mamba (SSM) improves computational efficiency and captures\nlong-range dependencies, addressing Transformer limitations. However,\ntraditional Mamba models overlook rich spectral information in HSIs and\nstruggle with high dimensionality and sequential data. To address these issues,\nwe propose the SSM with multi-head self-attention and token enhancement\n(MHSSMamba). This model integrates spectral and spatial information by\nenhancing spectral tokens and using multi-head attention to capture complex\nrelationships between spectral bands and spatial locations. It also manages\nlong-range dependencies and the sequential nature of HSI data, preserving\ncontextual information across spectral bands. MHSSMamba achieved remarkable\nclassification accuracies of 97.62\\% on Pavia University, 96.92\\% on the\nUniversity of Houston, 96.85\\% on Salinas, and 99.49\\% on Wuhan-longKou\ndatasets. The source code is available at\n\\href{https://github.com/MHassaanButt/MHA\\_SS\\_Mamba}{GitHub}."
}