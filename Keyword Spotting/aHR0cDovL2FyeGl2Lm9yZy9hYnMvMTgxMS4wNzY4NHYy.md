# EFFICIENT KEYWORD SPOTTING USING DILATED CONVOLUTIONS AND GATING

Alice Coucke, Mohammed Chlieh, Thibault Gisselbrecht, David Leroy, Mathieu Poumeyrol, Thibaut Lavril

## 🧩 Problem to Solve

저자들은 연속적인 오디오 스트림에서 특정 키워드를 탐지하는 웨이크 워드(wake-word) 탐지 기술인 키워드 스포팅(Keyword Spotting, KWS)의 효율적인 구현을 목표로 합니다. 특히, 이 시스템들은 저자원(low-resource) 기기에서 실시간으로 동작하며 높은 정확도와 낮은 메모리 및 계산 비용을 요구합니다. 기존의 순환 신경망(RNN) 기반 모델은 긴 시간적 의존성을 포착할 수 있지만, 연속적인 입력 스트림에서 상태 포화(state saturation) 문제를 겪을 수 있어 주기적인 상태 재설정이 필요하다는 한계가 있습니다. 컨볼루션 신경망(CNN)은 효율적이지만 작은 모델로는 넓은 패턴을 포착하기 어렵습니다. 따라서, 저자들은 상태를 사용하지 않으면서도 넓은 시간적 맥락을 효율적으로 처리하고, 포화 문제를 피하며, 계산 비용을 제한하는 종단 간(end-to-end) KWS 모델을 개발하고자 합니다.

## ✨ Key Contributions

- **확장 컨볼루션 기반의 새로운 KWS 모델 제안:** WaveNet 아키텍처에서 영감을 받아 확장 컨볼루션(dilated convolutions), 게이팅(gated activations), 잔차 연결(residual connections)을 활용하는 종단 간 상태 비저장(stateless) 시간 모델링 KWS 아키텍처를 제시했습니다. 이는 깊은 네트워크를 저자원 환경에서도 훈련 가능하게 합니다.
- **"키워드 종료 시점" 레이블링 전략 도입:** 키워드 종료 시점 주변의 특정 시간 구간에만 타겟 레이블 1을 할당하고 배경 프레임에 마스킹을 적용하는 새로운 레이블링 방식을 개발했습니다. 이는 모델의 정확도를 높이고 키워드의 시작이 아닌 종료 시점 근처에서 탐지되도록 유도합니다.
- **최첨단 성능 달성:** 제안된 모델이 LSTM 셀을 사용하고 max-pooling 손실로 훈련된 순환 신경망과 다른 CNN 기반 모델보다 현저히 낮은 오탐율(False Rejection Rate, FRR)을 보이며 우수한 성능을 입증했습니다.
- **오픈 데이터셋 공개:** "Hey Snips" 웨이크 워드 발화를 담은 대규모 데이터셋(2.2K 이상의 화자가 발화한 약 11K개의 긍정 예시와 86.5K개의 부정 예시)을 공개하여 웨이크 워드 탐지 연구 분야의 투명성과 재현성을 증진하는 데 기여했습니다.

## 📎 Related Works

- **전통적인 KWS:** HMM(Hidden Markov Models) 기반의 접근 방식 [1, 2, 3].
- **초기 딥러닝 KWS:** 완전 연결 네트워크(fully-connected networks)를 사용한 소형 KWS 솔루션 [4].
- **CNN 기반 KWS:** 지역적 의존성을 활용하는 CNN [5, 6]. 추론 속도와 계산 비용 면에서 효율적이지만, 작은 모델로는 넓은 패턴 포착에 한계가 있습니다.
- **RNN 기반 KWS:** LSTM 셀을 사용하여 긴 시간적 맥락을 활용하는 RNN 기반 KWS [7, 8, 9]. 그러나 연속 입력 스트림에서 상태 포화 문제가 발생할 수 있습니다 [10].
- **WaveNet 아키텍처:** 음성 합성 [11] 및 음성 활동 탐지(Voice Activity Detection, VAD) [10]에 성공적으로 적용된, 확장 컨볼루션, 게이팅, 잔차 연결을 사용하는 모델. 본 논문은 이 아키텍처를 KWS에 최초로 적용했습니다.
- **ResNet 기반 KWS:** [12]에서는 KWS에 ResNet을 적용했으나, WaveNet과 달리 skip-connection 및 게이팅을 활용하지 않고 주파수 영역에서 컨볼루션을 적용하여 계산 비용이 증가하는 차이가 있습니다.

## 🛠️ Methodology

1. **음향 특징 추출:** 오디오 입력으로부터 25ms 윈도우에서 10ms 간격으로 20차원 로그 멜 필터뱅크 에너지(log-Mel filterbank energies, LFBEs)를 추출합니다.
2. **신경망 아키텍처 (WaveNet에서 영감):**
   - **확장 인과 컨볼루션(Dilated Causal Convolutions):** 표준 컨볼루션과 달리 일부 입력 값을 건너뛰어 필터 크기 증가 없이 수용 필드(receptive field)를 넓힙니다. 이를 통해 모델 파라미터 수의 증가 없이 장기적인 시간 패턴을 포착할 수 있습니다. 인과 컨볼루션은 예측이 이전 타임스탬프에만 의존하게 하여 추론 시 지연 시간을 줄입니다. 네트워크의 수용 필드 $r = \sum_{i} d_{i}(s_{i}-1)$는 각 레이어의 확장률 $d_{i}$와 필터 크기 $s_{i}$에 따라 결정됩니다.
   - **게이팅 활성화(Gated Activations):** tanh와 sigmoid 활성화 함수의 조합으로 정보 전파를 제어하며 오디오 신호를 효과적으로 모델링합니다.
   - **잔차 연결(Residual Connections):** 깊은 네트워크 훈련 시 발생할 수 있는 기울기 소실(vanishing gradients) 문제를 해결하고 수렴 속도를 높이기 위해 각 레이어 사이에 도입됩니다. 각 레이어는 다음 레이어로 전달되는 출력과 건너뛰어 최종 출력에 합산되는 출력의 두 가지 출력을 생성합니다. 이를 통해 24개 레이어로 구성된 깊은 네트워크를 훈련할 수 있으며, 이는 1.83초의 넓은 수용 필드를 제공합니다.
3. **스트리밍 추론(Streaming Inference):** 확장 컨볼루션은 이전 계산 결과를 메모리에 캐싱하여 새로운 입력 프레임이 들어올 때 효율적인 추론을 가능하게 합니다. 이는 FLOPS(Floating Point Operations per Second)를 크게 줄여 프로덕션 환경에 적합합니다.
4. **키워드 종료 시점 레이블링(End-of-keyword Labeling):**
   - 키워드 끝을 중심으로 $\Delta t$ 시간 간격 내의 프레임에만 타겟 1을 할당하는 이진 레이블링 방식을 사용합니다. 개발 세트에서 최적의 $\Delta t$ 값은 160ms로 설정되었습니다.
   - 긍정 샘플에서 레이블링 윈도우 바깥의 배경 프레임을 무시하는 마스킹(masking) 기법을 적용합니다.
   - 이 방식은 모델이 키워드가 충분히 제공된 후에 탐지하도록 유도하며, 음소 정렬(phoneme alignment) 없이 키워드 종료 시점만 필요하므로 구현이 간단합니다. 또한, 마스킹 덕분에 레이블링 경계의 불확실성에 더욱 강건합니다.
5. **실험 설정:** 초기 인과 컨볼루션 레이어 1개와 24개의 게이트 확장 컨볼루션 레이어로 구성됩니다. 확장률은 $\{1, 2, 4, 8\}$의 반복 시퀀스를 사용하며, 잔차 연결과 스킵 연결이 포함됩니다. Adam 옵티마이저와 Xavier 초기화를 사용합니다.

## 📊 Results

제안된 WaveNet 모델은 LSTM 및 CNN 베이스라인과 비교하여 "Hey Snips" 공개 데이터셋에서 탁월한 성능을 보였습니다.

- **주요 성능 지표 (시간당 0.5 FAH, 거짓 경보율):**
  - **WaveNet (제안 모델):**
    - 파라미터 수: 222K
    - 초당 곱셈 연산(FLOPS): 22M
    - 깨끗한 환경 FRR: 0.12%
    - 노이즈 환경(5dB SNR) FRR: 1.60%
  - **LSTM 베이스라인:**
    - 파라미터 수: 257K
    - 초당 곱셈 연산(FLOPS): 26M
    - 깨끗한 환경 FRR: 2.09%
    - 노이즈 환경(5dB SNR) FRR: 11.21%
  - **CNN 베이스라인:**
    - 파라미터 수: 244K
    - 초당 곱셈 연산(FLOPS): 172M
    - 깨끗한 환경 FRR: 2.51%
    - 노이즈 환경(5dB SNR) FRR: 13.18%
- **성능 우위:** WaveNet 모델은 깨끗한 환경에서 LSTM 대비 94%, CNN 대비 95%의 FRR 감소를, 노이즈 환경에서는 LSTM 대비 86%, CNN 대비 88%의 FRR 감소를 달성했습니다. 이는 유사한 파라미터 수에서 더 적은 FLOPS로 훨씬 우수한 성능을 의미합니다.
- **절제 분석(Ablation Study):**
  - "키워드 종료 시점" 레이블링 제거 시 FRR이 깨끗한 환경에서 +0.36%, 노이즈 환경에서 +1.33% 증가하여 이 레이블링의 중요성을 보여주었습니다. 특히 노이즈 환경에서 효과가 컸습니다.
  - 마스킹 제거 시 FRR이 깨끗한 환경에서 +0.28%, 노이즈 환경에서 +0.46% 증가했습니다.
  - 게이팅 제거 시 FRR이 깨끗한 환경에서 +0.24%, 노이즈 환경에서 +2.57% 증가하여, 게이팅이 특히 노이즈 환경에서 성능 향상에 크게 기여함을 확인했습니다.
  - 잔차 연결 또는 스킵 연결 중 하나만 제거하는 것은 성능에 큰 영향을 미치지 않았지만, 이 둘 중 하나라도 없으면 깊은 네트워크 훈련이 어려웠습니다.

## 🧠 Insights & Discussion

이 연구는 WaveNet 아키텍처의 핵심 요소인 확장 컨볼루션, 게이팅, 잔차 연결이 KWS 작업, 특히 저자원 기기에서의 웨이크 워드 탐지에 매우 효과적임을 입증했습니다. 이 모델은 RNN 기반 접근 방식의 상태 포화 문제를 피하면서도 긴 시간적 의존성을 포착할 수 있는 종단 간 상태 비저장 모델의 가능성을 제시합니다. 특히, 키워드 종료 시점에 초점을 맞춘 맞춤형 레이블링 전략은 모델의 정확도를 크게 향상시키는 중요한 요인이었습니다. 이는 모델이 키워드 전체 맥락을 충분히 학습한 후 탐지하도록 유도하여 오탐율을 줄이는 데 기여합니다. 또한, 공개 데이터셋의 제공은 경쟁이 치열한 KWS 분야에서 투명성과 재현성을 높이는 데 중요한 역할을 합니다. 향후 연구는 기록 하드웨어, 억양, 원거리 환경 등 다양한 도메인으로의 모델 적응에 초점을 맞출 것입니다.

## 📌 TL;DR

**문제:** 저자원 기기용 키워드 스포팅(KWS)은 실시간, 고정확도, 낮은 메모리/계산 비용을 요구하지만, RNN의 상태 포화 문제와 CNN의 넓은 패턴 포착 한계가 있었습니다.

**방법:** 저자들은 WaveNet 아키텍처에서 영감을 받아 확장 인과 컨볼루션, 게이팅 활성화, 잔차 연결을 사용하는 종단 간 상태 비저장 KWS 모델을 제안했습니다. 또한, 키워드 종료 시점 주변에만 레이블을 부여하는 새로운 "키워드 종료 시점" 레이블링 전략과 마스킹 기법을 도입했습니다.

**발견:** 제안된 모델은 LSTM 및 CNN 베이스라인보다 깨끗한 환경과 노이즈 환경 모두에서 훨씬 낮은 오탐율(FRR)을 달성하며 우수한 성능을 입증했습니다. 이는 낮은 계산 비용으로도 효율적인 KWS가 가능함을 보여줍니다. 더불어, 연구팀은 "Hey Snips" 웨이크 워드 공개 데이터셋을 제공하여 KWS 연구의 발전에 기여했습니다.
