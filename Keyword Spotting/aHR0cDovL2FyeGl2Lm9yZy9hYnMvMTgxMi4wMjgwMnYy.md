# END-TO-END STREAMING KEYWORD SPOTTING

Raziel Alvarez, Hyun-Jin Park

## 🧩 Problem to Solve

최근 음성 비서의 확산으로 "Ok Google"과 같은 키워드 스포팅(Keyword Spotting, KWS) 시스템은 모바일, 가전제품, IoT 기기와 같은 다양한 기기에서 중요해졌습니다. 이러한 기기들은 배터리 구동 방식이거나 컴퓨팅 자원이 제한적인 경우가 많으므로, KWS 시스템은 높은 품질과 효율성을 동시에 갖춰야 합니다.

기존의 KWS 시스템은 주로 신호 처리 프론트엔드, 음향 인코더, 디코더와 같이 독립적으로 훈련되고 수동으로 설계된 여러 하위 시스템으로 구성됩니다. 이러한 접근 방식은 개별 구성 요소를 최적화하는 데 복잡성을 추가하고, 리소스 최적화 및 전체적인 품질 면에서 최적화되지 못하는 단점이 있습니다. 특히 임베디드 애플리케이션에 비해 계산 복잡도가 높은 경향이 있습니다.

이 논문은 스트리밍 오디오에서 키워드의 존재 여부를 직접 예측하기 위해 인코딩 및 디코딩 구성 요소를 단일 딥 뉴럴 네트워크(DNN)에 통합하고 엔드-투-엔드로 훈련함으로써 이러한 문제를 해결하고자 합니다.

## ✨ Key Contributions

- **효율적인 메모리화된 신경망 토폴로지 (SVDF 레이어)**: DNN 깊이에 걸쳐 이전 활성화(activation)에 대한 메모리를 유지함으로써 파라미터와 관련 계산을 더 잘 활용하는 효율적인 신경망 구조를 제안합니다. 이 토폴로지는 SVDF(Single Value Decomposition Filter) 레이어를 기반으로 하며, 작은 필터를 사용하여 파라미터 및 계산 제어를 세밀하게 할 수 있습니다.
- **엔드-투-엔드 훈련 방법**: 키워드 스포팅 점수를 직접 생성하도록 DNN을 엔드-투-엔드로 훈련하는 방법을 제시합니다. 이는 기존의 다단계 접근 방식과 달리, 단일 DNN으로 인코더와 디코더를 동시에 최적화합니다.
- **우수한 성능 및 효율성**: 제안된 시스템은 기존 접근 방식 대비 탐지 품질, 모델 크기, 계산량 모두에서 뛰어난 성능을 보입니다. 특히 기존 시스템보다 5배 이상 작고 계산량이 적음에도 불구하고 더 높은 품질을 달성합니다.

## 📎 Related Works

- **전통적인 KWS 시스템**: HMM(Hidden Markov Model)을 사용하여 DNN의 음향 특성을 "키워드" 및 "배경" 클래스로 분류하거나, 음향 모델 출력의 시간적 통합을 수행하여 탐지 가능성 점수를 생성하는 방식 [1, 2, 3, 4, 5, 6, 7, 8, 9, 10].
- **CTC 훈련 DNNs**: RNN(Recurrent Neural Networks) 기반의 CTC(Connectionist Temporal Classification) 훈련 DNN [11]이나, 빔 서치(beam search) 디코딩에 의존하는 시퀀스-투-시퀀스(sequence-to-sequence) 훈련 모델 [12]도 사용되었으나, 임베디드 애플리케이션에는 계산적으로 복잡하다는 단점이 있습니다.
- **컨볼루션 신경망(CNN) 기반 KWS**: 기존 연구 [14]에서 소형 KWS를 위해 컨볼루션 신경망을 사용한 사례와 비교 평가합니다.
- **SVDF 레이어**: 본 논문에서 제안하는 SVDF (Single Value Decomposition Filter) 레이어는 [15]에서 완전 연결 레이어를 낮은 랭크(rank) 근사로 대체하기 위해 처음 도입되었습니다.
- **선형 병목 계층(linear bottleneck layers)**: 파라미터 수를 줄이기 위해 [18, 19, 10]에서 사용된 병목 계층을 SVDF와 결합하여 활용합니다.

## 🛠️ Methodology

이 논문은 인코딩 및 디코딩 구성 요소를 단일 신경망에 통합하여 스트리밍 오디오에서 키워드 존재 여부에 대한 추정(점수)을 직접 생성하도록 훈련될 수 있는 새로운 엔드-투-엔드 키워드 스포팅 시스템을 제안합니다.

1. **효율적인 메모리화된 신경망 토폴로지**:
   - **SVDF (Single Value Decomposition Filter) 레이어**: [15]에서 소개된 SVDF 레이어를 사용합니다. 이 레이어는 저랭크(low-rank) 근사를 통해 완전 연결 레이어를 근사화합니다.
   - **작동 방식**:
     - 각 노드 $m$에서 입력 벡터 $X_t$가 특징 필터 $\beta^{(m)}$를 통과하고, 결과 스칼라 출력이 이전 추론 단계에서 계산된 $T-1$개의 값에 연결됩니다.
     - 메모리는 $T$ 크기의 슬라이딩 윈도우를 형성하며, 새로운 엔트리를 추가하고 오래된 엔트리를 제거합니다.
     - 최종적으로 시간 필터 $\alpha^{(m)}$가 적용되어 출력 $a_t^{(m)}$를 생성합니다:
       $$a_t^{(m)} = f\left(\sum_{i=0}^{T-1} \alpha_i^{(m)} \sum_{j=1}^F \beta_j^{(m)} x_{(t-T+i),j}\right)$$
     - 이는 각 추론의 상태를 독립적으로 유지하며, RNN과 달리 상태를 재귀적으로 사용하거나 전체 상태를 덮어쓰지 않습니다.
   - **장점**:
     - 컨볼루션에 비해 파라미터 및 계산량에 대한 세밀한 제어가 가능합니다.
     - 리셉티브 필드(receptive field)의 명시적인 크기 조절을 통해 과거 정보를 얼마나 기억할지 정밀하게 제어할 수 있습니다.
     - RNN-LSTM보다 뛰어난 성능을 보이며, 상태를 주기적으로 재설정하는 복잡한 로직이 필요 없습니다.
     - 선형 병목 레이어와 잘 결합하여 파라미터 수를 크게 줄일 수 있습니다.
   - **네트워크 구조**: SVDF 레이어와 병목 레이어가 번갈아 쌓인 깊은 네트워크 구조를 사용합니다 (그림 3 참조).
2. **엔드-투-엔드 신경망 훈련 방법**:

   - **레이블 생성**:
     - 프론트엔드에서 생성된 로그-멜 필터뱅크 에너지와 클래스 레이블 $c \in \{0, 1\}$ 쌍으로 구성된 입력 시퀀스 $\lt X_t, c \gt$를 생성합니다.
     - 키워드("Ok Google"의 경우 "l")의 마지막 구성 요소에 해당하는 모든 시퀀스 엔트리에 $1$을 할당하고, 나머지는 $0$을 할당합니다 (그림 2 참조).
     - 훈련 안정성을 위해 긍정(positive) 및 부정(negative) 예제의 균형을 맞추기 위해 마지막 키워드 구성 요소의 시작 부분부터 $1$ 레이블을 가진 엔트리를 고정된 양만큼 추가합니다.
   - **훈련 레시피**:
     - **손실 함수**: 단순한 프레임 레벨 교차 엔트로피(Cross-Entropy, CE) 손실 $\lambda_t(W) = -\log y_c(X_t, W)$를 사용합니다.
     - **최적화**: 비동기 확률적 경사 하강법(ASGD)을 사용합니다.
     - **두 가지 훈련 방식**:
       - **인코더+디코더 (2단계)**: 먼저 음향 인코더를 훈련하고 (사전 훈련된 파라미터 포함), 그 다음 인코더의 출력과 생성된 레이블을 사용하여 디코더를 훈련합니다. 이 단계에서 인코더의 파라미터는 고정됩니다. 과적합 경향이 있는 모델에 유용합니다.
       - **엔드-투-엔드 (1단계)**: DNN 전체를 직접 엔드-투-엔드로 훈련합니다. 인코더 섹션을 사전 훈련된 모델로 초기화할 수 있으며, 인코더 섹션 조정 정도를 0에서 1 사이의 적응률로 조절할 수 있습니다 (0은 인코더+디코더와 동일). 과적합 경향이 적은 작은 모델에서 특히 더 좋은 성능을 보입니다.

3. **실험 설정**:
   - **프론트엔드**: 30ms 윈도우(10ms 오버랩)로 스트리밍 오디오에서 40차원 로그-멜 필터뱅크 에너지를 생성합니다.
   - **베이스라인 모델**: [14]의 시스템(Baseline$_{1850K}$)을 사용합니다. 1D 컨볼루션 레이어 1개와 완전 연결 레이어 3개로 구성되며 약 1.7M 파라미터와 1.8M MAC 연산을 가집니다.
   - **엔드-투-엔드 모델**: 3가지 크기(E2E$_{700K}$, E2E$_{318K}$, E2E$_{40K}$)와 2가지 훈련 방식(1단계, 2단계)으로 구성됩니다. 이 모델들은 SVDF 레이어를 사용하며, Baseline$_{1850K}$ 대비 훨씬 적은 파라미터와 MAC 연산을 가집니다.
   - **데이터셋**: "Ok Google" 및 "Hey Google" 키워드에 대한 1백만 개의 익명화된 수기 전사 발화를 사용합니다. 배경 소음 및 잔향을 시뮬레이션하기 위해 다중 스타일 훈련 데이터를 생성합니다. Clean non-accented, Clean accented, High pitched, Query logs의 4가지 테스트 세트로 평가합니다.

## 📊 Results

- **성능 비교 (ROC 곡선)**:
  - 가장 큰 두 엔드-투-엔드 모델(E2E$_{318K2stage}$ 및 E2E$_{700K2stage}$)은 Baseline$_{1850K}$보다 훨씬 작은 크기와 낮은 복잡성에도 불구하고 인식 품질에서 훨씬 뛰어난 성능을 보였습니다.
  - 특히 E2E$_{318K2stage}$ 및 E2E$_{700K2stage}$는 대부분의 테스트 조건에서 Baseline$_{1850K}$ 대비 최대 60%의 상대적 오거절(FR)률 감소를 보여주었습니다.
  - E2E$_{318K2stage}$는 Baseline$_{1850K}$가 사용하는 계산량의 약 26%만 사용하면서도 상당한 개선을 보였습니다.
- **소형 모델의 훈련 방식 비교**:
  - E2E$_{40K1stage}$ 및 E2E$_{40K2stage}$ 모델을 통해 1단계(엔드-투-엔드) 훈련과 2단계(인코더+디코더) 훈련의 성능을 비교했습니다.
  - 1단계 훈련이 모든 조건에서 2단계 훈련보다 뛰어났으며, 특히 "clean" 환경에서는 Baseline$_{1850K}$의 성능에 상당히 근접했습니다.
  - E2E$_{40K1stage}$는 Baseline$_{1850K}$의 파라미터 2.3%와 계산량 3.2%만을 사용한다는 점을 고려할 때 이는 상당한 성과입니다.
- **오거절(FR)률 at 0.1 FA/h**:
  - Table 1에서 볼 수 있듯이, 0.1 FA/h (시간당 0.1 오수락)의 낮은 오수락률(FA) 지점에서 평가한 결과, 가장 큰 두 엔드-투-엔드 모델은 모든 데이터셋에서 베이스라인을 능가하여 Clean 조건에서 약 40%, 다른 두 세트에서 20-40%의 FR률 감소를 달성했습니다.
  - 작은 모델에서는 1단계 훈련이 2단계 훈련보다 우수하며, Clean 조건에서 Baseline$_{1850K}$와 유사한 FR률을 보였습니다.

## 🧠 Insights & Discussion

- **엔드-투-엔드 훈련의 효과**: 인코더와 디코더를 단일 DNN으로 통합하여 엔드-투-엔드로 훈련하는 방식이 기존의 다단계 접근 방식보다 우수함을 입증했습니다. 이는 최적화를 공동으로 수행함으로써 전체 시스템의 성능을 향상시킬 수 있음을 시사합니다.
- **효율성 및 자원 절감**: 제안된 시스템은 기존 SOTA 시스템 대비 5배 이상 적은 모델 크기와 계산량으로도 더 높은 탐지 품질을 달성합니다. 이는 배터리 구동 장치나 계산 자원이 제한된 임베디드 장치에 KWS를 배포하는 데 매우 중요합니다.
- **SVDF 토폴로지의 이점**: SVDF 레이어는 파라미터 및 계산 제어에 대한 세밀한 제어를 제공하며, 명시적인 리셉티브 필드 크기 조절을 통해 불필요한 과거 정보에 주의를 기울이는 문제를 피할 수 있어, RNN-LSTM보다 뛰어난 성능을 보이는 것으로 나타났습니다.
- **훈련 안정성**: 레이블 생성 시 긍정 및 부정 예제의 균형을 맞추는 것이 훈련 안정성에 중요함을 보여주었습니다.
- **단일 모델의 장점**: 프론트엔드와 신경망 외에는 아무것도 필요하지 않아, 새로운 키워드로의 확장이나 새로운 훈련 데이터로의 미세 조정이 더 용이합니다.
- **제한 및 향후 연구**: 현재는 프론트엔드 신호 처리를 DNN에 통합하지 않았지만, 이는 향후 연구 방향 중 하나로 고려될 수 있습니다. 또한, 다른 손실 함수 탐색 및 다중 채널 지원으로 일반화하는 것도 미래 과제입니다.

## 📌 TL;DR

이 논문은 스트리밍 오디오 키워드 스포팅을 위한 **엔드-투-엔드 딥 뉴럴 네트워크(DNN) 시스템**을 제안합니다. 이 시스템은 **효율적인 SVDF(Single Value Decomposition Filter) 레이어 기반 토폴로지**와 **단일 신경망으로 인코더 및 디코더를 공동으로 최적화하는 엔드-투-엔드 훈련 방법**을 핵심으로 합니다. 결과적으로, 제안된 모델은 기존 시스템보다 **5배 이상 작고 계산량이 적음에도 불구하고 탐지 품질에서 최대 60%의 오거절(FR)률 감소**를 달성하여, 자원 제약이 있는 임베디드 장치에 매우 적합함을 입증했습니다.
