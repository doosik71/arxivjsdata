# Convolutional Recurrent Neural Networks for Small-Footprint Keyword Spotting

Sercan Ö. Arık, Markus Kliegl, Rewon Child, Joel Hestness, Andrew Gibiansky, Chris Fougner, Ryan Prenger, Adam Coates

## 🧩 Problem to Solve

키워드 스포팅(KWS) 시스템은 인간-기술 인터페이스의 핵심 요소로서, 낮은 오탐(False Alarm, FA)율에서 최대의 탐지 정확도를 달성하는 동시에, 모델 크기(footprint), 지연 시간(latency), 복잡성을 최소화해야 합니다. 특히 스마트폰이나 스마트 홈 센서와 같이 메모리 및 연산 자원이 제한적인 소비자 기기에 임베드될 수 있도록 소형 모델이어야 합니다.

기존 딥러닝 기반 KWS 접근 방식들의 한계는 다음과 같습니다:

- **DNN(Deep Neural Networks)**: 입력의 구조나 컨텍스트를 무시하여 시간 또는 주파수 도메인의 강한 의존성을 활용하기 어렵습니다.
- **CNN(Convolutional Neural Networks)**: 지역적 구조를 잘 활용하지만, 넓은 필터나 깊은 구조 없이는 전체 프레임에 걸친 컨텍스트를 모델링하기 어렵습니다.
- **RNN(Recurrent Neural Networks)**: 컨텍스트를 모델링할 수 있으나, 연속적인 시간 및 주파수 단계 간의 구조를 학습하지 못합니다.
- **기존 CRNN(Convolutional Recurrent Neural Networks)**: 대규모 모델에서도 CTC(Connectionist Temporal Classification) 손실을 사용하여 높은 정확도와 낮은 FA율을 동시에 달성하기 어려웠습니다.

본 논문은 CNN과 RNN의 장점을 결합하여 이러한 한계를 극복하고, 소형 모델(small-footprint)로 높은 성능을 달성하는 것을 목표로 합니다.

## ✨ Key Contributions

- **소형 CRNN 아키텍처 제안**: 약 23만 개의 파라미터를 가진 소형 Convolutional Recurrent Neural Network (CRNN) 아키텍처를 제안하여 KWS에 적용했습니다. 이는 기존 대규모 모델 대비 매우 작은 규모입니다.
- **CE 손실 함수 및 정렬 전략 활용**: CTC 손실 대신 CE(Cross-Entropy) 손실을 사용하여 소형 모델에서 더 나은 성능을 유도했으며, 대규모 음성 인식 모델(Deep Speech 2)을 활용한 정밀한 훈련 샘플 정렬 방법을 개발했습니다.
- **효과적인 훈련 전략 도입**:
  - **하드 네거티브 마이닝(Hard Negative Mining)**: 어려운 음성 샘플을 채굴하여 훈련에 사용함으로써 오탐율을 효과적으로 줄이고 성능을 향상시켰습니다.
  - **데이터 증강**: 잡음 추가 및 타이밍 지터(timing jitter)를 통해 모델의 강건성(robustness)을 높였습니다. 원거리(far-field) 환경에 대한 강건성을 위한 증강 방법도 탐구했습니다.
- **성능 및 효율성 입증**: 5 dB SNR에서 0.5 FA/시간당 97.71%의 높은 정확도를 달성하며, 낮은 지연 시간과 적은 연산 복잡도(약 30M FLOPs)로 임베디드 기기 환경에 적합함을 보였습니다.
- **CNN 대비 우위 입증**: 동일한 파라미터 제약 하에 재최적화된 CNN 아키텍처보다 특히 낮은 SNR 조건에서 우수한 성능과 잡음 강건성을 입증했습니다.

## 📎 Related Works

- **전통적인 KWS**: 시퀀스 검색 알고리즘을 사용한 Hidden Markov Models (HMMs) [1].
- **딥러닝 기반 KWS**:
  - DNNs: 모델 압축 기법 [3,4] 또는 다중 스타일 훈련 접근 방식 [5,6]과 결합.
  - CNNs: KWS를 위한 컨볼루션 신경망 [7,8].
  - RNNs: CTC 손실을 사용한 캐릭터 레벨 RNN [9,10].
  - CRNNs: CTC 손실을 사용한 엔드-투-엔드 KWS 아키텍처 [11].
- **음성 인식 시스템**: 대규모 음성 인식 시스템에서 성공적으로 활용된 CRNN 아키텍처 [12-14].
- **입력 표현**: PCEN(Per-Channel Energy Normalization) 멜 스펙트로그램 [8].
- **순환 유닛**: Gated Recurrent Units (GRUs) [15], Long Short-Term Memory (LSTM) 유닛 [16].
- **최적화**: ADAM 최적화 알고리즘 [17].

## 🛠️ Methodology

1. **엔드-투-엔드 아키텍처 (End-to-end Architecture)**:

   - **입력 전처리**: 원시 시간-도메인 오디오를 PCEN(Per-Channel Energy Normalized) 멜 스펙트로그램으로 변환. 16kHz 샘플링 레이트, 10ms 스트라이드, 40 채널, 1.5초 프레임 길이로 `40 x 151` 차원의 입력을 생성합니다.
   - **컨볼루션 계층**: 2D PCEN 특징을 입력으로 받아, 시간 및 주파수 차원을 따라 2D 필터링을 수행하여 지역적 구조를 학습합니다.
   - **순환 계층**: 컨볼루션 계층의 출력을 입력으로 받아 양방향(bidirectional) GRU [15] 또는 LSTM [16] 유닛을 사용하여 전체 프레임에 걸친 장기 컨텍스트를 모델링합니다. GRU는 낮은 복잡도에서 더 나은 성능을 위해 선호됩니다.
   - **완전 연결(FC) 계층**: 순환 계층의 출력을 받아 연결합니다.
   - **소프트맥스 디코딩**: 두 개의 뉴런에 대해 소프트맥스를 적용하여 키워드 여부를 나타내는 스칼라 점수를 얻습니다.
   - **활성화 함수**: 모든 계층에서 ReLU(Rectified Linear Units)를 사용합니다.
   - **모델 크기**: 약 25만 개 이하의 파라미터로 모델 크기를 제한하여 임베디드 환경에 최적화합니다.

2. **엔드-투-엔드 훈련 (End-to-end Training)**:

   - **손실 함수**: 이진 레이블(키워드/비키워드)에 대한 CE(Cross-Entropy) 손실을 최적화합니다. 이는 소형 아키텍처에서 CTC 손실보다 효율적입니다.
   - **정밀한 정렬**: Deep Speech 2와 같은 대규모 음성 인식 모델을 사용하여 각 시간 인스턴스에 대한 키워드 문자의 확률 분포 푐$_k$(1 ≤ $k$ ≤ $K$)를 얻습니다. 이 분포를 스무딩하고, 알고리즘 1에 제시된 휴리스틱 알고리즘을 사용하여 키워드의 시작 및 끝 시간을 정밀하게 정렬합니다.
   - **데이터 증강**:
     - **잡음 추가**: 훈련 샘플에 $[-5, 15]$ dB SNR 범위에서 샘플링된 전력을 가진 잡음을 추가하여 모델의 강건성을 높입니다.
     - **타이밍 지터**: 정렬 오류에 대한 강건성을 위해 무작위 타이밍 지터를 도입합니다.
     - **하드 네거티브 마이닝**: 미리 수렴된 모델을 사용하여 대규모 공개 비디오 데이터셋(훈련/개발/테스트 세트에 사용되지 않음)에서 어려운 음성 샘플을 채굴하고, 이를 사용하여 훈련을 계속합니다.
     - **원거리 증강**: 원거리 환경에 대한 강건성을 위해 다양한 임펄스 응답(impulse responses)을 사용하여 훈련 샘플을 증강합니다.
   - **최적화**: ADAM 최적화 알고리즘 [17]을 사용하며, 배치 크기는 64입니다. 학습률은 초기 0.001에서 0.0003으로 감소시킵니다.

3. **평가**: 1.5초 길이의 중첩 프레임(100ms 시프트)에 대해 스트리밍 시나리오로 추론을 수행합니다. 평가지표는 FRR(False Rejection Rate)과 FA(False Alarms) per hour입니다.

## 📊 Results

- **CRNN 성능**: 약 229k 파라미터를 가진 CRNN 모델은 5 dB SNR의 테스트 세트에서 0.5 FA/시간당 97.71%의 정확도(FRR 2.29%)를 달성했습니다. 10 dB SNR에서는 98.71%, 20 dB SNR에서는 99.3%의 정확도를 보였습니다.
- **모델 크기 vs. 성능**: 모델 크기가 클수록 일반적으로 성능이 향상되지만, GRU가 LSTM보다 낮은 복잡도에서 더 나은 성능을 보였고, 순환 계층 수를 늘리는 것보다 컨볼루션 필터 수나 순환 은닉 유닛 수를 늘리는 것이 더 효과적이었습니다. 최적의 파라미터 세트를 통해 모델 크기 대비 성능의 균형점을 찾았습니다.
- **CNN과의 비교**: 동일한 250k 파라미터 제한 하에 최적화된 CNN 아키텍처 대비, 제안된 CRNN 모델은 5 dB SNR에서 1 FA/시간당 및 0.5 FA/시간당 FRR에서 약 51% 더 낮은 값을 기록하며 우수한 성능을 보였습니다. SNR이 높을수록 성능 차이는 줄어들었습니다.
- **추론 지연 시간**: 229k 파라미터 CRNN 모델의 추론 연산 복잡도는 약 30M FLOPs로, 현대 스마트폰에서 인간의 반응 시간(약 280ms)보다 훨씬 빠르게 실시간 추론이 가능합니다.
- **훈련 데이터의 영향**:
  - 긍정 샘플 수 증가: 모델 용량 제한으로 인해 긍정 샘플 수를 무작정 늘리는 것은 성능 향상에 제한적인 영향을 미쳤습니다.
  - 하드 네거티브 마이닝: 테스트 세트의 FRR을 크게 감소시켜 성능 향상에 효과적이었습니다.
- **잡음 강건성**: CRNN 아키텍처는 특히 낮은 SNR 값에서 CNN 아키텍처보다 우수한 성능을 보여 잡음 신호에 더 잘 적응하는 능력을 입증했습니다.
- **원거리 강건성**: 원거리 증강된 훈련 샘플을 사용하면 원거리 테스트 세트에서 성능 저하가 현저히 줄었지만, 원본 데이터 세트에서는 훈련/테스트 불일치로 인해 약간의 성능 저하가 관찰되었습니다.

## 🧠 Insights & Discussion

- **모델 용량의 한계와 최적화**: 소형 모델의 경우, 단순히 긍정 샘플 수를 늘리는 것만으로는 성능 향상에 한계가 있습니다. 모델의 용량을 효율적으로 활용하기 위한 아키텍처 선택(예: GRU 선호, 필터 및 유닛 수 최적화)과 훈련 전략(예: 하드 네거티브 마이닝)이 중요합니다.
- **잡음 환경에서의 CRNN의 강점**: CRNN의 순환 계층은 전체 프레임에서 정보를 처리하여 개별 샘플의 잡음 특성에 더 잘 적응할 수 있습니다. 이는 특히 낮은 SNR 조건에서 CNN보다 뛰어난 잡음 강건성으로 이어집니다. CNN은 이와 동등한 수준의 정보 전파를 위해 훨씬 넓은 필터나 깊은 구조가 필요합니다.
- **훈련 데이터의 현실성 반영**: KWS 시스템의 성능은 훈련 세트가 실제 적용 환경(잡음 수준, 원거리 조건 등)을 얼마나 잘 반영하는지에 크게 좌우됩니다. 데이터 증강은 이러한 현실성을 반영하는 강력한 수단이지만, 훈련/테스트 불일치를 피하도록 신중하게 적용해야 합니다.
- **실용적인 솔루션**: 본 논문에서 제안된 소형 CRNN 모델은 높은 정확도, 낮은 오탐율, 작은 모델 크기, 낮은 지연 시간이라는 까다로운 요구사항을 모두 충족하여 임베디드 KWS 시스템을 위한 실용적이고 효과적인 솔루션을 제공합니다.
- **향후 개선의 여지**: 인간의 KWS 성능이 매우 뛰어나다는 점을 고려할 때, 제안된 모델은 우수한 결과를 보였음에도 불구하고 여전히 성능 개선의 여지가 남아있음을 시사합니다.

## 📌 TL;DR

본 논문은 임베디드 장치용 소형 키워드 스포팅(KWS) 시스템을 위해 컨볼루션 및 순환 신경망(CRNN) 아키텍처를 연구한다. 기존 DNN, CNN, RNN의 한계를 극복하고, 작은 모델 크기(~230k 파라미터)로 높은 정확도와 낮은 오탐율(FA)을 달성하는 것을 목표로 한다. 저자들은 지역 구조 파악을 위한 컨볼루션 계층과 장기 컨텍스트 모델링을 위한 순환 계층을 결합하고, CE 손실 함수, 정밀한 정렬, 하드 네거티브 마이닝, 데이터 증강 등 효과적인 훈련 전략을 제안한다. 결과적으로 제안된 CRNN 모델은 5dB SNR에서 0.5 FA/시간당 97.71%의 정확도를 달성하며, 기존 CNN 기반 모델 대비 우수한 성능과 잡음 강건성을 보였다. 이는 임베디드 KWS 시스템을 위한 실용적인 솔루션임을 입증한다.
