# CONTRASTIVE LEARNING WITH AUDIO DISCRIMINATION FOR CUSTOMIZABLE KEYWORD SPOTTING IN CONTINUOUS SPEECH

Yu Xi, Baochen Yang, Hao Li, Jiaqi Guo, Kai Yu

## 🧩 Problem to Solve

맞춤형 키워드 스포팅(KWS)은 연속 음성 환경에서 실제 적용 잠재력이 높지만, 음성 결합(co-articulation) 및 스트리밍 단어 분할로 인해 다른 텍스트에도 유사한 오디오 패턴이 발생하여 오탐(false alarms)을 유발하기 쉽습니다. 기존 대조 학습(CL) 기반 KWS 접근 방식은 주로 미리 분할된 고립 단어에 대해 오디오-텍스트 매칭 전략만을 사용했기 때문에, 연속 음성 환경의 이러한 문제를 효과적으로 해결하지 못했습니다. 따라서, 오디오 혼동에 대한 판별 능력을 갖춘 강건한 키워드 표현 학습이 필요합니다.

## ✨ Key Contributions

- 기존 오디오-텍스트 매칭 전략과 달리, 오디오 판별(audio discrimination) 능력을 도입한 새로운 대조 학습(CLAD) 접근 방식을 제안하여 키워드 표현 품질을 향상시켰습니다. 또한, 유사하고 혼동을 유발하는 음성 세그먼트를 생성하기 위한 데이터 증강 기법을 설계했습니다.
- CLAD 훈련을 위해 슬라이딩 윈도우 수준의 InfoNCE 손실 함수를 사용했습니다. InfoNCE는 풍부한 긍정 및 부정 샘플 활용을 지원하여 오디오-텍스트 매칭과 오디오-오디오 판별 기준을 모두 효과적으로 수행하는 데 특히 유용합니다.
- CLAD에서 학습된 표현을 기반으로 엔드-투-엔드 맞춤형 KWS 시스템을 구축했습니다. 이 시스템은 동일한 음향 모델을 사용하는 기존의 2단계 접근 방식보다 더 나은 성능과 훨씬 빠른 속도를 달성하며, 키워드 간 표준 편차가 낮아 안정성을 보여줍니다.

## 📎 Related Works

맞춤형 KWS 시스템은 주로 두 가지 범주로 나뉩니다:

- **2단계 접근 방식 (Two-stage approaches)**:
  - 음향 모델링 단계와 비정형적인 키워드 검색 단계로 구성됩니다.
  - ASR(자동 음성 인식) 검색 과정과 유사한 그래프 검색(Graph search)이 널리 사용되며, 가중 유한 상태 변환기(WFST)가 주요 방식입니다.
  - 딥러닝 기반 음향 모델과 후처리 모듈(Posterior handling module)을 결합한 방법들이 제안되었으나, 검색 과정이 자원 소모적이어서 특정 응용 분야에서 사용이 제한될 수 있습니다.
- **엔드-투-엔드 시스템 (End-to-end systems) - 표현 매칭 기반**:
  - 등록된 키워드 참조와 감지 대상 음성 데이터를 모두 입력으로 사용하며, 키워드 음성 표현이 비키워드 음성보다 등록된 참조 패턴과 더 유사해야 한다는 아이디어를 기반으로 합니다.
  - 복잡한 검색 방법이 필요 없으며, 간단한 표현 특징 매칭으로 KWS 결정이 가능합니다.
  - 질의 기반 예시(QByE)와 메트릭 학습(Metric learning) 접근 방식이 있으며, 최근에는 텍스트 기반 등록 방식이 인기를 얻고 있습니다.
  - 텍스트 기반 등록은 사용자 친화적이지만, 유사한 발음의 음성 처리 및 혼동되는 키워드 음성에서 오탐을 유발하기 쉽습니다.
  - 기존 표현 학습 기반 시스템은 주로 미리 분할된 고립 KWS에 적용되었으며, 연속 음성 KWS는 스트리밍 작동 모드와 음성 결합 효과로 인해 효과적인 부정 샘플 생성과 표현 학습에 어려움이 있습니다. 특히 오디오 혼동에 대한 판별 능력 부족은 오탐 증가의 주요 원인입니다.

## 🛠️ Methodology

본 논문은 연속 음성 환경에서 맞춤형 KWS를 위한 오디오 판별 기반 대조 학습(CLAD) 접근 방식을 제안합니다. 시스템의 주요 구성 요소와 훈련/추론 절차는 다음과 같습니다.

1. **프레임 수준 음향 모델(AM) 훈련**:

   - CLAD 시스템의 고수준 표현 생성을 위해 프레임 수준 음향 추출기를 사전 훈련합니다.
   - 모델링 단위는 모노폰(monophones)이며, 강제 정렬(forced alignments)을 통해 프레임 수준 훈련 목표를 설정합니다.
   - AM은 교차 엔트로피(CE) 기준으로 지도 학습 방식으로 훈련되며, CLAD 시스템 훈련 중에는 고정(frozen)됩니다.

2. **훈련 쌍 및 훈련 전략**:

   - 일반 ASR 데이터를 효과적으로 활용하기 위해 키워드 근처의 슬라이딩 세그먼트를 사용한 데이터 증강 전략을 설계합니다.
   - **슬라이딩 윈도우 길이 추정 ($L_{seg}$)**:
     - 훈련 및 추론 간의 일관성을 위해 키워드의 윈도우 길이를 다음 공식으로 추정합니다.
       $$L_{seg} = T_{mean} \cdot N_{phns} + L_{margin}$$
     - 여기서 $N_{phns}$는 키워드의 음소 수, $T_{mean}$은 평균 음소 길이, $L_{margin}$은 문맥 정보 및 음성 결합 효과를 고려한 추가 길이입니다.
   - **오디오-텍스트 매칭을 위한 대조 학습 ($L_{at}$)**:
     - 텍스트와 오디오 표현 간의 매칭 상관관계를 학습하기 위해 InfoNCE 손실을 사용합니다.
     - 긍정 쌍은 오디오 세그먼트 $A^p_{i,j,k}$와 해당 텍스트 키워드 $W_{i,j}$로 구성됩니다. 부정 쌍은 $A^p_{i,j,k}$와 미니배치 내의 다른 텍스트 키워드들입니다.
       $$L_{at} = - \sum_{i,j,k} \log \frac{\exp \left( \text{Sim} \left( A^p_{i,j,k}, W_{i,j} \right) / \tau_{at} \right)}{\exp \left( \text{Sim} \left( A^p_{i,j,k}, W_{i,j} \right) / \tau_{at} \right) + \sum_{w \neq (i,j)} \exp \left( \text{Sim} \left( A^p_{i,j,k}, W_w \right) / \tau_{at} \right)}$$
   - **오디오-오디오 판별을 위한 대조 학습 ($L_{aa}$)**:
     - 연속 음성에서 유사한 부정 샘플을 구별하기 위해 오디오-오디오 판별 능력을 학습합니다.
     - 추정된 윈도우와 실제 키워드 위치 간의 오버랩 비율을 기반으로 긍정 및 부정 오디오 세그먼트를 추출합니다. 동일 키워드의 긍정 오디오 세그먼트 쌍은 긍정 쌍이 되고, 긍정 오디오와 부정 오디오 세그먼트 쌍은 부정 쌍이 됩니다.
       $$L_{aa} = - \sum_{i,j} \sum_{k,l,k \neq l} \log \frac{\exp \left( \text{Sim} \left( A^p_{i,j,k}, A^p_{i,j,l} \right) / \tau_{aa} \right)}{\exp \left( \text{Sim} \left( A^p_{i,j,k}, A^p_{i,j,l} \right) / \tau_{aa} \right) + \sum_{x=1}^M \exp \left( \text{Sim} \left( A^p_{i,j,k}, A^n_{i,j,x} \right) / \tau_{aa} \right)}$$
   - **최종 CLAD 손실 기준 ($L$)**:
     - 오디오-오디오 판별과 오디오-텍스트 매칭의 균형을 맞추기 위해 가중치 $\alpha$를 사용하여 두 손실을 결합합니다.
       $$L = \alpha L_{aa} + L_{at}$$

3. **키워드 표현 매칭을 통한 엔드-투-엔드 KWS**:
   - 추론 시, $\text{Equation (1)}$로 추정된 길이의 오디오 세그먼트를 연속적으로 슬라이딩하며, 각 세그먼트의 임베딩과 등록된 텍스트 키워드의 임베딩 간의 코사인 유사도를 계산합니다.
   - 가장 높은 유사도 점수를 키워드 점수로 간주하며, 임계값을 초과하면 키워드로 감지하고 1초의 쿨다운 기간을 적용하여 반복 활성화를 방지합니다.

## 📊 Results

- **고립 KWS 성능 (LibriPhrase)**:
  - CLAD는 고립 KWS에 특화된 CMCD, Triplet, SoftTriple, InfoNCE 등 기존 표현 학습 기반 방법들과 비교했을 때, 유사하거나 약간 더 우수한 성능(EER 및 AUC)을 달성했습니다. 이는 연속 음성을 위해 설계되었음에도 고립 환경에서 효과적임을 보여줍니다.
- **연속 KWS 성능 (LibriSpeech KWS 버전)**:
  - 다양한 키워드 개수(5개부터 50개)에 대해 기존 2단계 접근 방식(그래프 기반, 후처리 모듈 기반)과 비교했을 때, CLAD는 `test-clean` 및 `test-other` 데이터셋 모두에서 일관된 성능 향상(더 높은 Micro Recall)을 보였습니다. 특히 `test-other`와 같은 복잡한 환경에서 기존 모델의 성능 저하가 컸던 반면, CLAD는 강건한 성능을 유지했습니다.
- **오디오 판별의 중요성**:
  - 오디오-오디오 판별 구성 요소 없이 오디오-텍스트 CL만 사용했을 때 성능이 크게 저하되었습니다. 이는 오디오 판별 전략이 연속 음성에서 키워드와 지역적으로 유사한 부정 샘플을 효과적으로 구별하는 데 필수적이며, 전반적인 성능 향상에 결정적인 역할을 함을 입증합니다.
- **추론 속도**:
  - CLAD 시스템은 기존 그래프 기반 및 후처리 모듈 기반 베이스라인보다 현저히 빠른 추론 속도(상대적 속도 가속(RSA)이 최대 16.95배)를 보였습니다. 이는 엔드-투-엔드 표현 매칭 방식이 시간 소모적인 검색 모듈의 필요성을 없앤 덕분입니다.

## 🧠 Insights & Discussion

- **오디오 판별의 핵심 역할**: 연속 음성 KWS의 고질적인 문제인 오탐은 음성 결합 및 스트리밍 환경으로 인한 오디오 유사성에서 비롯됩니다. 본 연구는 오디오-텍스트 매칭과 더불어 오디오-오디오 판별 능력을 학습시키는 CLAD가 이러한 오디오 혼동을 효과적으로 해결하여 모델의 강건성과 정확도를 크게 향상시킴을 보여주었습니다.
- **엔드-투-엔드 시스템의 효율성 및 실용성**: CLAD는 복잡한 검색 모듈이 필요한 2단계 KWS 시스템에 비해 훨씬 빠른 추론 속도를 제공하면서도 우수한 성능을 유지합니다. 이는 실시간 응용 프로그램 및 리소스 제약이 있는 온-디바이스(on-device) KWS 작업에 CLAD가 매우 적합함을 시사합니다.
- **일반화 및 안정성**: CLAD는 다양한 키워드 수와 음향 환경에서 일관된 성능 향상을 보였으며, 키워드 간의 성능 편차가 낮다는 점은 시스템의 뛰어난 일반화 능력과 안정성을 나타냅니다. 이는 사용자가 임의의 키워드를 정의할 수 있는 맞춤형 KWS 시스템의 중요한 이점입니다.
- **InfoNCE 손실의 적합성**: InfoNCE 손실 함수는 긍정 및 부정 샘플을 유연하게 활용할 수 있어, 오디오-텍스트 매칭과 오디오-오디오 판별이라는 두 가지 중요한 학습 목표를 효과적으로 통합하는 데 매우 적합함을 입증했습니다.

## 📌 TL;DR

본 논문은 연속 음성 환경에서 맞춤형 키워드 스포팅(KWS)의 오탐 문제를 해결하기 위해 오디오 판별 기능을 갖춘 대조 학습(CLAD)이라는 새로운 엔드-투-엔드 방법을 제안합니다. 기존 CL 기반 KWS가 오디오-텍스트 매칭에만 집중했던 것과 달리, CLAD는 슬라이딩 윈도우 수준 InfoNCE 손실을 사용하여 오디오-텍스트 매칭과 오디오-오디오 판별 능력을 동시에 학습합니다. 실험 결과, CLAD는 고립 KWS에서 기존 방법과 대등하거나 더 나은 성능을 보였고, 연속 KWS에서는 기존 2단계 시스템보다 대부분의 테스트 설정에서 우수한 성능과 최대 16배 빠른 추론 속도를 달성했습니다. 핵심은 오디오 판별 능력이 연속 음성에서의 오탐을 줄이고 모델의 강건성을 크게 향상시킨다는 점입니다.
