# QUERY-BY-EXAMPLE ON-DEVICE KEYWORD SPOTTING

Byeonggeun Kim, Mingu Lee, Jinkyu Lee, Yeonseok Kim, and Kyuwoong Hwang

## 🧩 Problem to Solve

기존 키워드 스포팅(KWS) 시스템은 주로 미리 정의된 키워드(예: "Alexa")에 의존하며, 이를 위해 많은 훈련 데이터가 필요합니다. 본 논문은 사용자가 직접 제공한(query-by-example) 예시를 통해 어떠한 키워드든 장치 내(on-device)에서 인식할 수 있는 사용자 맞춤형 KWS 시스템을 개발하는 것을 목표로 합니다. 특히, 장치 내 환경에서 충분한 음성(negative) 예제가 부족하여 신뢰할 수 있는 임계값(threshold)을 설정하기 어렵다는 문제를 해결하고자 합니다.

## ✨ Key Contributions

- **사용자 맞춤형 Query-by-Example KWS 시스템 제안**: 몇 개의 사용자 키워드 발화만으로 사용자별 모델을 생성합니다.
- **음소 후방확률 기반 FST 활용**: Connectionist Temporal Classification (CTC) 기반의 소형 자동 음성 인식(ASR) 모델에서 출력된 음소 수준 후방확률(posteriorgram)을 사용하여 유한 상태 변환기(FST) 가설 그래프를 구축합니다. 이는 어휘 외 문제(out-of-vocabulary, OOV)를 방지하여 어떤 키워드든 등록할 수 있게 합니다.
- **새로운 임계값 예측 방법 제안**: 장치 내 시스템의 고질적인 문제인 음성 예제 부족을 해결하기 위해, 등록된 쿼리 발화를 재배열하여 쿼리별 음성(negative) 예제를 생성하고 이를 사용하여 사용자-키워드별 임계값을 예측합니다.
- **단순하면서도 뛰어난 성능 입증**: 제안된 시스템은 단순함을 유지하면서도 기존의 최신 KWS 시스템들과 비교할 만한 성능을 보여줍니다.

## 📎 Related Works

- **미리 정의된 키워드 스포팅 (Predefined KWS)**:
  - "Alexa", "Okay Google" 등 특정 키워드를 위해 대량의 데이터를 수집하고 신경망(NN)을 훈련합니다.
  - 음향 인코더와 시퀀스 매칭 디코더(HMM 기반)를 분리하거나, RNN, Dilated Convolution, SVD 필터 등을 사용하는 End-to-end NN 아키텍처를 사용합니다.
- **Query-by-Example KWS (임의 키워드 인식)**:
  - 초기에는 ASR 음소 후방확률과 동적 시간 워핑(DTW)을 사용하여 키워드 샘플과 테스트 발화를 비교했습니다 [7, 8, 9].
  - CTC ASR 후방확률과 편집 거리(edit distance) 또는 후방확률 자체를 사용한 방법 [10, 11].
  - LSTM 출력 벡터의 유사도 점수를 계산하거나 [12], RNN-T 모델을 사용한 End-to-end NN 기반 시스템 [13, 14].
- **기타 KWS 연구**: 다중 키워드 감지 [15, 16, 17, 18], 소규모 데이터셋을 위한 KWS (DTW를 이용한 데이터 증강, Few-shot 메타 학습) [19, 20].

## 🛠️ Methodology

제안된 시스템은 음향 모델(Acoustic Model), 디코더(Decoder), 임계값 예측(Threshold Prediction)의 세 부분으로 구성됩니다.

1. **음향 모델 (Acoustic Model)**

   - **모델**: 소형 Connectionist Temporal Classification (CTC) 기반 ASR 모델 [21]을 사용합니다.
   - **입력/출력**: 입력 특징 $X = x_1, x_2, \ldots, x_T$에 대해 $N$차원의 활성화(activation) $O = o_1, o_2, \ldots, o_T$를 출력합니다. 여기서 $o_n^t$는 시간 $t$에서 단위 $n$이 관찰될 확률입니다.
   - **음소 집합**: 39개의 문맥 독립 음소 $L$에 빈(blank) 출력 $\phi$와 공백(space)을 추가한 $L' = L \cup \{\phi, \text{space}\}$를 사용합니다.
   - **확률 계산**: $P(Y|X) = \sum_{P \in B^{-1}(Y)} p(P|X)$와 같이 경로(path) $P$의 조건부 확률을 주변화하여 레이블 시퀀스 $Y$의 조건부 확률을 계산합니다. $B$는 반복을 제거하고 $\phi$를 없애는 매핑 함수입니다 (예: $B(x\phi yy\phi z) = xyz$).

2. **키워드 스포팅 디코더 (Keyword Spotting Decoder)**

   - **등록 단계 (Query Enrollment)**:
     - 사용자가 발화한 몇 개의 키워드 샘플을 입력으로 받습니다.
     - AM 출력에서 각 시간 프레임에서 최대 후방확률을 갖는 음소를 선택(max-decoding)하여 경로 $P$를 얻습니다.
     - $B$ 매핑을 통해 가설(hypothesis) $Y'$ (음소 시퀀스)를 정의합니다 (예: 'Hey Snapdragon' -> 'HH.EY. .S.N.AE.P.T. .A.AE.G.AH.N').
     - 이 가설을 순차적 음소 제약 조건으로 사용하여 좌-우향(left-to-right) FST 시스템을 구축합니다.
   - **테스트 단계 (Keyword Spotting)**:
     - 입력 오디오 $X'$에 대해 가설 FST에 대한 로그-가능도(log-likelihood) 점수 $log p(X'|Y')$를 계산합니다.
     - FST는 $L$개의 상태 $S = [s^{(i)}]$를 가지며, $y'_k \in S$인 순서화된 가설 $Y'$를 따릅니다.
     - 상태 전이 확률 $a_{ij}(t)$는 가설을 따르도록 정의됩니다.
     - 로그 가능도 점수는 다음 근사식을 따릅니다:
       $$ \log p(X'|Y') \propto \max*{q, t_0} \left[ \log\left\{\pi \prod*{t=t*0+1}^T a*{q*{t-1}q_t} \prod*{t=t_0}^T p(q_t|x'\_t)\right\} \right] $$
            여기서 $\pi$는 초기 상태 확률이고 $p(q_t|x'_t)$는 AM의 후방확률에 비례합니다.
     - 빔 서치(beam search)를 통해 $q$와 $t_0$를 최적화하여 점수를 최대화합니다.
     - 점수는 비-빈 상태(non-blank state)의 수로 정규화됩니다.

3. **장치 내 임계값 예측 (On-device Threshold Prediction)**
   - **문제**: 장치 내 KWS 시스템은 음성 예제가 부족하여 정확한 임계값 결정이 어렵습니다.
   - **해결책**:
     - **쿼리별 음성 예제 생성**: 쿼리 발화를 파형(waveform)에서 세 부분으로 나누고, 이들을 섞어서 원래 신호와 다른 새로운 음성(negative) 발화를 생성합니다 (예: 그림 1 참조). 각 부분 경계에서 16개 샘플을 오버랩하고 한쪽 삼각형 윈도우를 적용하여 부드러운 전환을 보장합니다.
     - **임계값 결정**: 임계값 $\delta^{(Q,H)}$는 양성(positive) 점수 평균과 음성(negative) 점수 평균의 가중 평균으로 정의됩니다:
       $$ \delta^{(Q,H)} = \frac{\tau}{A(A-1)} \sum*{(a,a') | a \neq a'} F*{Y'_a}(X'_{a'}) + \frac{(1-\tau)}{A \cdot B} \sum*{(a,b)} F*{Y'_a}(Z_b) $$
       여기서 $F_{Y}(X)$는 테스트 발화 $X$에 대한 가설 $Y$의 로그 가능도 점수입니다. $\tau$는 하이퍼파라미터이며, $A$는 쿼리 수, $B$는 음성 예제 수입니다. 이 방법은 생성된 음성 예제 $Z_b$를 사용하여 임계값을 예측합니다.

## 📊 Results

- **데이터셋**: 'Hey Snapdragon' (1,112 발화, 50 화자)과 'Hey Snips' (993 발화, 61 화자)의 공개 데이터셋을 사용했습니다. WSJ-SI200 [22]을 음성 샘플로 사용했습니다.
- **성능 비교 (FST vs S-DTW)**:
  - 제안된 FST 기반 방법은 S-DTW (Subsequence DTW) 기준선보다 일관되게 우수한 성능을 보였습니다 (낮은 FRR, False Rejection Rate).
  - 'Hey Snapdragon' 키워드가 'Hey Snips'보다 더 나은 성능을 보였는데, 'Hey Snips'가 짧아 오경보(False Alarm)가 발생하기 쉽기 때문입니다.
- **임계값 예측**:
  - 기준선(무작위 일반 음성 100개 사용)과 비교하여, 쿼리별 음성 예제 생성 방법은 양성 및 음성 점수 간에 더 강한 양의 상관관계를 보여주었습니다 (R 값이 -0.04/-0.21에서 0.25/0.40으로 증가).
  - 제안된 방법은 두 키워드('Hey Snapdragon', 'Hey Snips') 모두에 대해 0.050 FA/hr의 목표를 정확히 달성하며 일관된 성능을 보였습니다. 반면, 기준선은 키워드 간 편차(0.001 FA/hr 대 0.088 FA/hr)가 컸습니다.
  - 제안된 방법은 기준선에 비해 훨씬 적은 음성 예제(10개 vs 100개)를 사용하면서도 더 낮은 FRR을 달성했습니다 (예: 'Hey Snapdragon'에서 3.95% vs 17.77% FRR).
- **타 시스템과의 비교**: 제안된 시스템은 기존의 미리 정의된 KWS 시스템 및 query-by-example 시스템과 비교할 만한 경쟁력 있는 FRR (0.05 FA/hr 기준)을 보여주었습니다.

## 🧠 Insights & Discussion

- **장점**: 제안된 시스템은 단순한 구조임에도 불구하고 사용자별, 장치 내 키워드 스포팅 작업에서 강력한 성능을 발휘합니다. 특히 음소 후방확률과 FST를 사용함으로써 OOV 문제를 회피하고, 쿼리별 음성 예제 생성을 통해 장치 내 환경에서 중요한 임계값 결정 문제를 효과적으로 해결합니다.
- **효과적인 임계값 예측**: 쿼리 발화를 재배열하여 생성된 음성 예제는 실제 쿼리와 유사한 음향적 특성을 가지면서도 키워드를 포함하지 않으므로, 사용자 및 쿼리별 임계값을 결정하는 데 매우 유용합니다. 이는 임의의 일반 음성 샘플을 사용하는 것보다 훨씬 일관되고 안정적인 성능을 제공합니다.
- **한계 및 향후 연구**: 공개 데이터 접근성 부족으로 다양한 키워드에 대한 광범위한 테스트에 한계가 있습니다. 현재의 임계값 예측 방식이 단순하므로, 쿼리별 음성 예제를 활용하는 더 정교한 임계값 예측 방법을 연구하고 다양한 키워드에 대한 추가적인 실험이 필요합니다.

## 📌 TL;DR

본 논문은 사용자별 Query-by-Example 장치 내 키워드 스포팅 시스템을 제안합니다. 이 시스템은 소형 CTC ASR 모델로 음소 후방확률을 생성하고, 이를 기반으로 키워드의 FST 가설 그래프를 구축하여 어떠한 키워드도 등록할 수 있습니다. 특히, 장치 내 환경에서 부족한 음성 예제 문제를 해결하기 위해 쿼리 발화를 재배열하여 쿼리별 음성 예제를 생성하고, 이를 활용해 안정적이고 일관된 임계값을 예측하는 방법을 제시합니다. 이 방법은 단순한 구조에도 불구하고 기준선보다 우수한 성능을 보였으며, 다양한 키워드에 대해 견고한 오경보율을 달성하며 기존 최신 시스템과 비교 가능한 결과를 나타냈습니다.
