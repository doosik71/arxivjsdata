# Deep Spoken Keyword Spotting: An Overview

IVÁN LÓPEZ-ESPEJO, ZHENG-HUA TAN, JOHN HANSEN, AND JESPER JENSEN

## 🧩 Problem to Solve

이 논문은 급변하는 딥러닝 기반 음성 키워드 스포팅(KWS) 기술에 대한 최신의 포괄적인 개요를 제공하고자 합니다. 기존의 KWS 개요 논문들은 오래되었거나 최신 기술 발전을 충분히 다루지 못하며, 딥 KWS는 일반 음성 인식(ASR)과 구별되는 고유한 문제를 가지고 있습니다. 특히, 경량(small-footprint) 장치에서의 활용이 증가함에 따라 연구자들과 실무자들에게 KWS의 주요 구성 요소, 견고성, 응용 분야, 데이터셋, 평가 지표 및 미래 연구 방향에 대한 심층적인 분석이 필요합니다.

## ✨ Key Contributions

- **포괄적인 KWS 시스템 분석**: 음성 특징 추출, 음향 모델링, 사후 처리 등 딥 KWS 시스템의 세 가지 핵심 구성 요소에 대한 심층적인 분석을 제공합니다.
- **견고성 및 응용 분야 검토**: 배경 소음, 원거리 조건 등에 대한 시스템의 견고성을 높이는 방법론과 KWS의 다양한 실제 응용 사례를 자세히 설명합니다.
- **데이터셋 및 평가 지표 해설**: 딥 KWS 연구에 사용되는 주요 데이터셋(특히 Google Speech Commands Dataset)과 성능 평가에 활용되는 다양한 지표(정확도, ROC/DET 곡선, F-score 등)를 비판적으로 분석합니다.
- **성능 비교 및 미래 방향 제시**: 최신 딥 KWS 시스템들의 성능과 계산 복잡성을 비교하고, 음향 모델 압축, 준지도 학습, 개인화, 다채널 KWS 등 미래 연구 방향을 제시합니다.
- **오디오-비주얼 KWS 탐구**: 음성 정보 외에 시각 정보까지 활용하는 오디오-비주얼 KWS 분야의 가능성과 현황을 소개합니다.

## 📎 Related Works

- **초기 KWS 접근 방식**: 대규모 어휘 연속 음성 인식(LVCSR) 시스템 기반의 KWS (높은 계산 복잡성) 및 키워드/필러(filler) 은닉 마르코프 모델(HMM) 접근 방식(GMM 대신 DNN 사용)이 언급됩니다.
- **최신 ASR 동향**: KWS의 핵심 부분인 음향 모델링과 관련된 최근 ASR 개요 논문들을 참조합니다.
- **기존 KWS 개요 논문**: 이 논문 이전의 소수의 KWS 개요 글들이 있으나, 최신 딥 KWS 접근 방식 및 데이터셋을 피상적으로만 다루거나 오래된 정보를 포함하고 있다고 지적됩니다.

## 🛠️ Methodology

이 논문은 딥 음성 키워드 스포팅 기술에 대한 문헌 검토 방식으로 진행됩니다. 현대 딥 KWS 시스템의 일반적인 파이프라인은 세 가지 주요 블록으로 구성됩니다:

1. **음성 특징 추출 (Speech Feature Extraction)**

   - 입력 신호 $x(m)$를 컴팩트한 음성 표현 $X$로 변환합니다. $X \in R^{K \times T}$
   - **Mel-scale 관련 특징**: log-Mel 스펙트럼 및 Mel-주파수 켑스트럼 계수(MFCC)가 가장 널리 사용됩니다.
   - **순환 신경망(RNN) 특징**: 가변 길이 데이터를 고정 길이 임베딩으로 요약하여 QbE KWS(Query-by-Example Keyword Spotting)에 활용됩니다.
   - **저정밀도 특징**: 모델의 에너지 소비 및 메모리 공간을 줄이기 위해 양자화된 특징(예: 8비트 log-Mel 스펙트럼, 2비트 전력 변화)을 사용합니다.
   - **학습 가능한 필터뱅크 특징**: 종단 간(end-to-end) 학습의 일환으로 필터뱅크 파라미터를 최적화합니다.
   - **기타 특징**: 멀티프레임 이동 시간 유사성(MFSTS) 및 DTW-CNN 하이브리드 접근 방식 등이 있습니다.

2. **음향 모델링 (Acoustic Modeling)**

   - 음성 특징 $X$를 입력으로 받아 다양한 키워드 및 비키워드 클래스에 대한 사후 확률 $P(C_n | X^{\{i\}}, \theta)$을 생성합니다.
   - **완전 연결 피드포워드 신경망(FFNN)**: 초기 딥 KWS 시스템에서 사용되었으나, 더 효율적인 CNN, RNN으로 대체되었습니다.
   - **컨볼루션 신경망(CNN)**: 시간-주파수 상관관계를 활용하여 FFNN보다 적은 파라미터로 더 나은 성능을 제공합니다. 잔차 학습(Residual learning), Dilated convolution, Temporal convolution, Depthwise separable convolution 등이 통합되어 사용됩니다.
   - **순환 신경망(RNN) 및 시간 지연 신경망(TDNN)**: 음성의 시간적 종속성을 모델링하는 데 적합하며, LSTM, GRU와 같은 아키텍처가 사용됩니다.
     - **연결주의 시간 분류(CTC)**: 프레임 수준 레이블 없이도 훈련이 가능한 정렬-자유(alignment-free) 알고리즘입니다.
     - **시퀀스-투-시퀀스(Seq2Seq) 모델**: 인코더-디코더 구조로, RNN-Transducer(RNN-T) 등이 KWS에 적용됩니다.
     - **어텐션 메커니즘**: Seq2Seq 모델의 인코더가 전체 입력 시퀀스를 요약하는 문제를 돕고, 키워드가 포함될 가능성이 높은 음성 섹션에 집중하게 합니다.
   - **음향 모델 훈련**:
     - **손실 함수**: 교차 엔트로피 손실($L_{CE}$)이 가장 보편적이며, 최대 풀링(max-pooling) 손실($L_{MP}$) 및 Focal loss($L_{FL}$)도 사용됩니다.
     - **최적화**: SGD(확률적 경사 하강법)와 Adam이 주로 사용되며, 학습률 감소 및 가중치 감쇠, 드롭아웃과 같은 정규화 기법이 적용됩니다.

3. **사후 처리 (Posterior Handling)**
   - 음향 모델이 생성하는 사후 확률 시퀀스 $y^{\{i\}}$를 처리하여 키워드 존재 여부를 최종적으로 결정합니다.
   - **비-스트리밍(Non-streaming) 모드**: 각 단어가 포함된 독립적인 입력 세그먼트를 분류하는 방식입니다.
   - **스트리밍(Streaming) 모드**: 연속적인 오디오 스트림을 실시간으로 처리하며, 원시 사후 확률을 시간적으로 스무딩하는 것이 일반적입니다. 오탐지를 방지하기 위해 키워드 감지 후 짧은 시간 동안 시스템 트리거를 강제 중단하는 메커니즘이 사용됩니다. 다중 단어 키워드나 서브워드 단위의 클래스를 처리하기 위해 신뢰도 점수 $S^{\{i\}}_c$를 계산하거나 탐색 가능한 래티스(lattice)를 구축하는 방법이 활용됩니다.

**견고성 방법론**:

- **프런트엔드 방법**: AGC(자동 이득 제어) (PCEN 포함), DNN 특징 강화, 적응형 소음 제거(ANC), 빔포밍 등이 포함됩니다.
- **백엔드 방법**: 멀티스타일 훈련(데이터 증강을 통한 소음 및 잔향), 적대적 훈련, 키워드 데이터 부족에 대한 견고성 (TTS를 통한 합성 데이터 생성), 클래스 불균형 문제 해결(Focal loss, Hard-example mining) 등이 있습니다.

**데이터셋**:

- LibriSpeech, TIDIGITS, TIMIT, WSJ 등 ASR에서 사용되던 데이터셋과 Mobvoi, Google Speech Commands Dataset(v1, v2), Hey Snips 등 KWS 전용 데이터셋을 분석합니다. 특히 Google Speech Commands Dataset의 인기도와 한계(균형 잡힌 클래스, 비-스트리밍 모드)를 지적합니다.

**평가 지표**:

- 정확도(Accuracy), ROC(Receiver Operating Characteristic) 곡선 및 DET(Detection Error Trade-off) 곡선(AUC, EER 포함), 정밀도-재현율(Precision-Recall) 곡선 및 F-score 등을 설명하며, 특히 클래스 불균형 상황에서 정확도의 한계를 강조합니다.

## 📊 Results

- **음향 모델 성능 경향**: Google Speech Commands Dataset(GSCD) v1 및 v2에 대한 성능 비교 결과, FFNN 기반 모델(91.2% 정확도)은 성능이 가장 낮았고, CNN, RNN, CRNN 기반 모델들이 더 좋은 성능을 보였습니다.
- **CNN의 강세**: CNN 기반 모델이 로컬 시간-주파수 상관관계를 활용하여 경쟁력 있는 성능을 제공하며, 특히 잔차 연결(residual connections), Dilated convolution 또는 Temporal convolution을 활용하여 긴 시간-주파수 의존성을 포착하는 모델(예: TC-ResNet, DS-ResNet)들이 높은 정확도(96.2%~96.7%)와 적은 파라미터 수를 달성했습니다.
- **최신 기술의 발전**: 신경망 아키텍처 탐색(NAS)을 통해 자동으로 설계된 모델(NoisyDARTS-TC14)은 108k 파라미터로 97.18% 정확도를 달성하여 수동 설계 모델보다 우수함을 보여주었습니다. Keyword Transformer(KWT-3)는 5백만 개 이상의 파라미터로 GSCD v2에서 98.56%의 최신 성능을 기록하며, 계산 복잡성보다 KWS 성능 최적화에 중점을 둔 경향을 보여주었습니다.
- **견고성 및 개인화**: AGC, PCEN, ANC, 빔포밍 등 프런트엔드 방법과 멀티스타일 훈련, 적대적 훈련, TTS 기반 데이터 증강 등 백엔드 방법이 KWS 시스템의 견고성을 크게 향상시켰음이 확인되었습니다. 스피커 검증과 결합한 개인화 KWS 시스템에 대한 연구도 진행되고 있습니다.
- **데이터셋 한계**: Google Speech Commands Dataset은 표준 벤치마크로 널리 사용되지만, 클래스 균형이 현실적이지 않고 비-스트리밍 평가 모드가 실제 시나리오를 반영하기 어렵다는 한계가 있습니다.

## 🧠 Insights & Discussion

- **ASR 발전의 영향**: 미래 KWS 연구는 종단 간 ASR 연구의 발전, 특히 핸드크래프트(handcrafted) 음성 특징을 대체하는 최적의 특징 학습과 음향 모델에 통합되는 방향에서 큰 영향을 받을 것으로 예상됩니다.
- **음향 모델링의 발전 방향**: 실생활 환경에서 KWS 성능 향상과 계산 복잡성 감소라는 두 가지 목표를 동시에 추구하며, 특히 효율적인 컨볼루션 블록 개발에 초점을 맞출 것입니다. 신경망 아키텍처 탐색(NAS)이 음향 모델 아키텍처 설계에 더 큰 역할을 할 것입니다.
- **모델 압축의 중요성**: 경량 장치에 KWS 기술을 내장하는 응용 분야가 많아짐에 따라, 모델 파라미터 양자화, 신경망 가지치기(pruning), 지식 증류(knowledge distillation) 등의 모델 압축 연구가 매우 중요해질 것입니다. 이는 온-디바이스(on-device) 재훈련이나 개인화된 키워드 포함을 가능하게 합니다.
- **새로운 학습 패러다임**: 대규모의 레이블 없는 음성 데이터를 활용하기 위한 준지도 학습(semi-supervised learning) 방법론이 크게 성장할 수 있습니다.
- **개인화 및 다채널 KWS**: 사용자 맞춤형 키워드 스포팅 시스템에 대한 수요 증가로 효율적인 개방형 어휘 KWS 및 공동 KWS-화자 검증 연구가 더욱 활발해질 것입니다. 또한, 여러 마이크를 사용하는 소형 장치의 이점을 활용하는 다채널 KWS(예: 빔포밍) 연구가 아직 미개척 분야로 남아있어 큰 성능 향상을 가져올 수 있습니다.

## 📌 TL;DR

이 논문은 급변하는 딥러닝 기반 음성 키워드 스포팅(KWS) 기술에 대한 최신 종합 개요를 제공합니다. 기존 연구들의 한계를 지적하며 음성 특징 추출, 딥러닝 기반 음향 모델링(주로 CNN, RNN), 사후 처리 방법론을 상세히 분석합니다. 또한, 소음 및 원거리 조건에 대한 견고성 확보 방안과 음성 비서 활성화 등 다양한 응용 사례를 제시합니다. Google Speech Commands Dataset과 같은 주요 데이터셋 및 평가 지표를 검토하고, 최신 모델들의 성능 및 계산 복잡성을 비교하여, 잔차 연결, 깊이별 분리형 컨볼루션 등을 통합한 CNN 기반 모델이 높은 성능과 경량화를 동시에 달성함을 보여줍니다. 미래 연구 방향으로는 종단 간 ASR의 영향, 모델 압축, 준지도 학습, 개인화, 다채널 KWS 등의 중요성을 강조합니다.
