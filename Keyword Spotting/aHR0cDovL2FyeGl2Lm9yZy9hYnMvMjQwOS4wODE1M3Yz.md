# Dark Experience for Incremental Keyword Spotting

Tianyi Peng, Yang Xiao

## 🧩 Problem to Solve

엣지 디바이스에서 사용되는 음성 키워드 스팟팅(KWS) 시스템은 제한된 키워드 세트로 훈련되기 때문에, 새로운 키워드를 접할 때 성능 저하가 발생합니다. 소량의 데이터로 모델을 미세 조정(few-shot fine-tuning)하는 접근 방식은 이 문제를 해결하려 하지만, 이전에 학습한 지식을 잊어버리는 치명적인 망각(catastrophic forgetting) 현상을 초래합니다. 기존의 점진적 연속 학습(Progressive Continual Learning, CL) 전략은 태스크-ID 정보에 의존하거나 저장 공간 요구 사항이 증가하는 등의 한계가 있어 경량 디바이스에는 실용적이지 않습니다. 특히 KWS에서의 클래스-증분 학습(Class-Incremental Learning, CIL)은 덜 연구되었으며, 기존 접근 방식들은 음성 클립 내의 풍부한 문맥을 간과하는 경향이 있습니다.

## ✨ Key Contributions

- **DE-KWS(Dark Experience for Keyword Spotting) 제안**: 이전 경험을 증류하기 위해 '어두운 지식(dark knowledge)'을 활용하는 새로운 KWS를 위한 CIL 접근 방식을 소개합니다.
- **리허설(Rehearsal) 및 증류(Distillation) 결합**: 모델이 과거 데이터를 기억하도록 돕기 위해 Ground Truth 레이블과 Logit에 내재된 어두운 지식을 활용하여 리허설과 증류를 결합합니다.
- **메모리 버퍼 활용**: 훈련 과정 전반에 걸쳐 샘플, 레이블, Logit을 저장하는 메모리 버퍼를 사용합니다.
- **연속적인 Logit 샘플링**: 태스크 경계에 의존하지 않고 훈련 궤적 전반에 걸쳐 Logit을 연속적으로 샘플링하여 모델의 점진적인 진화를 포착하고 적응력을 향상시킵니다.
- **뛰어난 성능 및 효율성**: Google Speech Command 데이터셋에서 기존 CL 베이스라인보다 평균 정확도에서 우수한 성능을 보이며, 모델 크기를 증가시키지 않아 리소스가 제한된 엣지 디바이스에 적합합니다.

## 📎 Related Works

- **기존 KWS 시스템**: 딥러닝 기반 KWS (Chen et al.), TC-ResNet (Choi et al.)
- **Few-shot Fine-tuning**: 새로운 시나리오에 모델을 적응시키기 위한 방식 (Awasthi et al., Mazumder et al., Parnami and Lee). 하지만 치명적 망각 문제 발생 (McCloskey and Cohen).
- **연속 학습(CL)**: 치명적 망각 극복을 위한 광범위한 연구 분야 (Wang et al., Van de Ven and Tolias, Masana et al.). 음성 처리 분야에서도 적용 (Xiao et al.).
- **점진적 CL for KWS**: 새로운 데이터에 적응하면서 이전 지식 유지 (Huang et al.).
- **CIL for KWS**: 다양성 기반 샘플러 및 자기 증류 접근 방식 (RK, Xiao et al.), 리플레이 기반 듀얼 메모리 멀티모달 프레임워크 (DM3, Yang et al.).
- **Dark Experience Replay (DER)**: 과거 Logit을 저장하여 훈련 궤적 전반에 걸쳐 경험을 증류하는 방법 (Buzzega et al.).
- **Dark Knowledge**: Ground Truth 레이블에는 포착되지 않는 클래스 관계에 대한 암묵적 정보 (Hinton et al.).

## 🛠️ Methodology

DE-KWS는 KWS를 위한 클래스-증분 학습(CIL) 문제로 정의하며, 새로운 데이터에 지속적으로 적응하면서 이전 데이터를 기억하고 전체 평균 정확도를 최적화하는 모델 $f(x;\theta)$를 목표로 합니다.
$$ \min*{\theta} \sum*{t=0}^{T} E*{(x,y)\sim D_t} [L*{CE}(y,f(x;\theta))] $$
여기서 $L_{CE}$는 교차 엔트로피 손실을 나타냅니다.

1. **메모리 버퍼($M_{\tau_{t-1}}$)**: 과거 태스크 $\tau_{t-1}$까지의 경험(입력 오디오 샘플, Ground Truth 레이블, 모델 Logit)을 저장합니다.
2. **리허설(Rehearsal)**:
   - 버퍼에서 샘플 $(x', y')$을 무작위로 추출하여 과거 태스크에 대한 모델의 기억을 강화하는 리허설 손실 $L_R$을 계산합니다.
     $$ L*R = E*{(x',y')\sim M*{\tau*{t-1}}} [L_{CE}(y',f(x';\theta_{\tau_{t-1}}))] $$
3. **증류(Distillation)**:
   - 모델의 전체 파라미터 대신 이전 모델의 Logit $z''$ (pre-softmax 출력 $h(\cdot;\theta_{\tau_{t-1}})$)을 저장하여 메모리 비용을 줄입니다. 이 Logit에는 클래스 관계에 대한 '어두운 지식'이 포함되어 있습니다.
   - 버퍼에서 샘플 $(x'', z'')$을 무작위로 추출하여 증류 손실 $L_D$를 계산합니다. 이는 현재 모델의 응답이 이전 Logit과 일관성을 유지하도록 보장합니다.
     $$ L*D = E*{(x'',z'')\sim M*{\tau*{t-1}}} [L_{MSE}(z'',h(x'';\theta_{\tau_{t-1}}))] $$
   - **연속적인 Logit 샘플링**: 훈련 과정 전반에 걸쳐 Logit을 연속적으로 샘플링하며, 데이터 스트림 길이가 알려지지 않은 경우에도 각 데이터 포인트가 버퍼에 저장될 동일한 기회를 갖도록 저수지 샘플링(Reservoir Sampling)을 사용합니다.
4. **훈련 개요**:
   - 현재 태스크의 스트리밍 데이터가 모델에 입력되어 현재 태스크에 대한 손실 $L_C$ (교차 엔트로피)를 계산합니다.
   - 스트리밍 데이터, 레이블 및 해당 Logit이 저수지 샘플링을 통해 버퍼에 샘플링되어 채워집니다.
   - 버퍼에서 데이터 쌍을 두 번 샘플링하여 리허설 손실 $L_R$과 증류 손실 $L_D$를 각각 계산합니다.
   - 최종 목적 함수는 세 가지 손실 항의 가중 합입니다.
     $$ L\_{DE-KWS} = L_C + \alpha L_R + \beta L_D $$
   - 여기서 $\alpha$와 $\beta$는 손실 간의 균형을 맞추는 하이퍼파라미터입니다.

- **백본 네트워크**: 경량 KWS 모델인 TC-ResNet-8을 사용하며, 입력으로 MFCC (40) 특징을 사용합니다.

## 📊 Results

- **데이터셋**: Google Speech Command dataset v1 (GSC)에서 실험을 수행했으며, 30개의 명령어를 6개, 10개, 20개의 태스크로 나누어 점진적 학습 능력을 평가했습니다.
- **주요 성능**:
  - DE-KWS는 버퍼 크기가 200일 때 85.13%의 평균 정확도(ACC)와 -0.048의 Backward Transfer (BWT)를 달성하여 기존 CIL 베이스라인(DM3 83.35% ACC, -0.058 BWT)을 능가했습니다.
  - 버퍼 크기가 500일 때는 89.24%의 ACC와 -0.034의 BWT로 성능이 더욱 향상되었습니다.
  - 버퍼 크기가 1500일 때는 91.17%의 ACC와 -0.026의 BWT를 기록하며, 상한선인 Joint Training (95.70%)에 근접한 성능을 보였습니다.
  - DE-KWS는 첫 번째 태스크(T1)에서 다른 방법들보다 일관되게 우수한 성능을 유지하며(6개 태스크 후 80.13% ACC), 장기 기억 유지 능력이 뛰어남을 입증했습니다.
- **모델 크기**: 모델 파라미터 수를 증가시키지 않고 이러한 성능 향상을 달성했습니다.
- **어블레이션 스터디(Ablation Study)**: 리허설과 증류 구성 요소가 모두 DE-KWS의 정확도 유지 및 망각 감소에 중요함을 보여주었으며, 최적의 하이퍼파라미터는 $\alpha=0.5, \beta=1.0$임을 확인했습니다.
- **태스크 수 증가에 대한 강건성**: 태스크 수가 10개 또는 20개로 증가하는 시나리오에서도 DE-KWS는 일관되게 다른 베이스라인보다 우수한 성능을 유지하며, 치명적 망각을 효과적으로 처리하는 능력을 입증했습니다.

## 🧠 Insights & Discussion

DE-KWS는 '어두운 지식'과 리허설 및 증류 기법의 결합을 통해 KWS의 연속 학습에서 지식 유지와 새로운 태스크 적응 사이의 균형을 효과적으로 달성했습니다. Logit을 활용한 증류는 모델이 이전 태스크의 응답을 유지하도록 도우며, 훈련 전반에 걸친 Logit의 연속적인 샘플링은 모델의 진화를 부드럽게 포착하여 태스크 경계가 모호한 실제 시나리오에 더욱 적합하게 만듭니다. 이는 어두운 경험이 모델이 새로운 태스크에 적응하는 동안 초기 태스크의 핵심 특징을 유지하는 정규화 방법으로 작용함을 시사합니다. 모델 크기를 증가시키지 않으면서도 기존 베이스라인을 뛰어넘는 성능을 보여주어, 리소스 제약이 있는 엣지 디바이스에 매우 실용적인 솔루션을 제공합니다.

## 📌 TL;DR

KWS 시스템이 새로운 키워드에 적응할 때 발생하는 치명적 망각 문제를 해결하기 위해, DE-KWS는 Ground Truth 레이블을 사용하는 리허설과 Logit에 담긴 '어두운 지식'을 활용한 증류를 결합합니다. 메모리 버퍼에 과거 경험(샘플, 레이블, Logit)을 저장하고, 훈련 전반에 걸쳐 Logit을 연속적으로 샘플링하여 지식 유지를 강화합니다. Google Speech Command 데이터셋에서 DE-KWS는 모델 크기 증가 없이 기존 연속 학습 베이스라인 대비 평균 정확도에서 우수한 성능을 보였으며, 치명적 망각을 효과적으로 줄여 엣지 디바이스에 적합한 솔루션임을 입증했습니다.
