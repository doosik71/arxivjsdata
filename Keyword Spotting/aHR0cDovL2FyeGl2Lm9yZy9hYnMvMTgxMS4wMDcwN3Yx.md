# Training Neural Speech Recognition Systems with Synthetic Speech Augmentation

Jason Li, Ravi Gadde, Boris Ginsburg, Vitaly Lavrukhin

## 🧩 Problem to Solve

정확한 자동 음성 인식(ASR) 시스템을 구축하기 위해서는 다양한 화자가 발화한 수많은 시간의 레이블링된 음성 샘플을 포함하는 대규모 데이터셋이 필수적입니다. 하지만 이러한 공개 데이터셋의 부족은 ASR 연구 발전을 저해하는 주요 문제로 작용하고 있습니다. 특히, 아주 큰 End-to-End 신경망 ASR 모델을 훈련시키기 위한 방대한 양의 데이터 확보가 어렵다는 한계가 있습니다.

## ✨ Key Contributions

- 데이터 부족 문제를 해결하기 위해 자연 음성 데이터셋을 합성 음성으로 증강하는 방법을 제안했습니다.
- 외부 언어 모델(LM) 없이 문자 기반 ASR 모델에서 LibriSpeech 데이터셋에 대한 새로운 최신(state-of-the-art, SOTA) 단어 오류율(WER)을 달성했습니다.
- 합성 데이터를 통해 기존 모델보다 훨씬 깊은 ASR 모델(최대 54개 레이어)을 성공적으로 훈련할 수 있음을 입증했습니다.
- 합성 데이터 증강이 드롭아웃, 시간 스트레칭, 노이즈 추가와 같은 전통적인 정규화(regularization) 및 데이터 증강 기법보다 더 효과적임을 보여주었습니다.
- 자연 음성과 합성 음성을 50/50 비율로 혼합할 때 가장 좋은 성능을 얻을 수 있음을 발견했습니다.

## 📎 Related Works

- **Deep Speech (Hannun et al., 2014; Amodei et al., 2016)**: End-to-End 딥러닝 기반 ASR 시스템의 선구적인 연구로, 음향 모델링 및 HMM을 딥 뉴럴 네트워크로 대체했습니다.
- **Wav2Letter (Collobert et al., 2016)**: Wave2Letter+ 모델의 기반이 된 End-to-End 컨볼루션 신경망(CNN) 기반 ASR 시스템입니다.
- **신경 언어 모델(Zeyer et al., 2018; Povey et al., 2018; Han et al., 2018)**: 순환 신경망(RNN) 형태의 언어 모델을 사용하여 ASR 성능을 향상시킨 최근 연구들입니다.
- **합성 데이터 기반 기계 번역 시스템 (Sennrich et al., 2015)**: 합성 데이터를 사용하여 번역 시스템을 개선한 연구에서 영감을 받았습니다.
- **신경 음성 합성 모델 (van den Oord et al., 2016; Shen et al., 2018)**: 높은 품질의 합성 음성 생성을 저렴하게 가능하게 한 최근 발전들입니다.
- **Tacotron-2 (Shen et al., 2018) 및 Global Style Tokens (GST) (Wang et al., 2018)**: 합성 음성 생성에 사용된 기술들입니다.
- **저자원 언어 ASR을 위한 합성 음성 사용 (Rygaard, 2015)**: 합성 음성이 저자원 언어의 음성 인식을 개선하는 데 사용된 선행 연구입니다.

## 🛠️ Methodology

1. **합성 음성 데이터셋 생성**:

   - OpenSeq2Seq 툴킷의 Tacotron-2와 유사한 모델에 Global Style Tokens (GST)를 추가하여 여러 화자 ID를 학습했습니다.
   - T2-GST 모델은 MAILABS English-US 데이터셋(약 100시간, 3명의 화자)으로 훈련되어 다양한 발화 스타일과 억양을 학습했습니다.
   - LibriSpeech 훈련 데이터셋(train-clean-100, train-clean-360, train-other-500)의 전사를 MAILABS 데이터셋의 스타일 스펙트로그램과 무작위로 페어링하여 LibriSpeech 훈련 오디오와 동일한 크기의 합성 데이터셋을 생성했습니다.
   - 디코더의 사전 네트워크(prenet) 드롭아웃 비율(46%, 48%, 50%)을 조절하여 오디오를 미묘하게 변형시키고 발화 속도를 변경하여 합성 데이터셋의 크기를 LibriSpeech 훈련 데이터셋의 3배로 늘렸습니다.

2. **신경 음성 인식 모델 (Wave2Letter+)**:

   - 로그 멜 스케일 스펙트로그램을 입력으로 받아 문자를 출력하는 End-to-End 컨볼루션 신경망(CNN) 모델입니다.
   - 기존 Wav2Letter 모델을 기반으로 다음과 같은 수정 사항을 적용했습니다: ReLU 활성화 함수, 배치 정규화, 컨볼루션 블록 간 잔차 연결, Connectionist Temporal Classification (CTC) 손실 함수, Layer-wise Adaptive Rate Clipping (LARC)을 사용한 그라디언트 클리핑.
   - 19개 레이어의 기본 모델 외에 24, 34, 44, 54개 레이어를 가진 더 깊은 네트워크를 실험했습니다.

3. **합성 데이터를 활용한 훈련**:
   - 합성 데이터와 원본 LibriSpeech 훈련 데이터를 결합하여 훈련 데이터셋을 구성했습니다.
   - 자연 데이터와 합성 데이터를 50/50 비율로 샘플링하는 것이 가장 효과적임을 발견했습니다.
   - 합성 데이터 증강의 효과를 드롭아웃, 시간 스트레칭, 노이즈 추가와 같은 전통적인 정규화 및 증강 기법과 비교했습니다.

## 📊 Results

- **SOTA WER 달성 (탐욕 디코딩, 언어 모델 없음)**:
  - 54개 레이어 Wave2Letter+ 모델이 test-clean에서 4.32%, test-other에서 14.08%의 WER을 달성했습니다. 이는 이전 최고 성능(test-clean 4.87%, test-other 15.39%)을 뛰어넘는 결과입니다.
- **합성 증강의 효과**:
  - 결합된 데이터셋으로 훈련된 모델들은 LibriSpeech 원본 데이터로만 훈련된 모델보다 일관적으로 더 나은 성능을 보였습니다 (예: 34개 레이어 모델의 test-clean WER이 5.10%에서 4.66%로 향상).
- **최적의 혼합 비율**:
  - 자연 데이터와 합성 데이터를 50/50으로 혼합했을 때 가장 낮은 WER을 기록했습니다. 합성 데이터만으로 훈련했을 경우 WER이 크게 증가하여 (test-clean 49.80%), 합성 데이터 단독으로는 자연 데이터의 다양성을 완전히 포착하지 못함을 시사했습니다.
- **전통적 증강과의 비교**:
  - 합성 데이터 증강은 WER 개선에 있어 전통적인 정규화 기법(드롭아웃, 시간 스트레칭, 노이즈 추가)보다 훨씬 우수한 성능을 보였습니다. 전통적인 기법들은 미미한 개선을 보이거나 오히려 성능을 저하시키기도 했습니다.
- **언어 모델 적용 시**:
  - 빔 서치(빔 폭 128)와 4-gram OpenSLR 언어 모델을 함께 사용했을 때, 54개 레이어 모델은 test-other에서 12.21%의 WER을 달성하여 LSTM 언어 모델과 비슷한 성능을 보였습니다.

## 🧠 Insights & Discussion

- 합성 데이터는 대규모 신경 ASR 시스템을 효과적으로 구축할 수 있게 하며, 모델의 깊이를 늘리는 데 기여합니다.
- 합성 데이터의 품질과 다양성이 중요합니다. 현재 3명의 화자로부터 생성된 합성 데이터는 여전히 LibriSpeech의 광범위한 다양성을 모두 포착하지 못할 수 있으며, 더 많은 화자 스타일을 학습하는 합성 모델을 사용한다면 성능이 더욱 향상될 수 있습니다.
- 합성 데이터만으로는 충분하지 않으며, 자연 음성 데이터와 합성 데이터를 적절한 비율로 혼합하는 것이 중요합니다. 합성 데이터는 강력한 정규화 효과를 제공하여 모델의 일반화 성능을 높입니다.
- **한계**: 현재 사용된 합성 음성 생성 모델은 MAILABS의 3명의 화자에 기반하고 있어, 합성 데이터의 화자 다양성이 제한적일 수 있습니다.
- **향후 계획**: 더 많은 노이즈가 추가된 대규모 합성 데이터셋을 생성하고, LibriSpeech 전사 외에 다른 소스의 텍스트를 사용하여 더 다양한 구문을 포함하는 합성 데이터를 만들 계획입니다.

## 📌 TL;DR

- **문제**: ASR 훈련을 위한 대규모 레이블링된 음성 데이터셋 부족이 대규모 End-to-End 신경망 ASR 모델 훈련의 걸림돌입니다.
- **제안**: 자연 음성 데이터셋을 합성 음성으로 증강하는 방법을 통해 이 문제를 해결합니다.
- **방법**: Tacotron-2 기반 모델로 LibriSpeech 데이터셋 규모에 맞춰 합성 음성(다양한 드롭아웃 설정으로 볼륨 증가)을 생성합니다. 이 합성 데이터와 원본 데이터를 50/50 비율로 혼합하여 Wave2Letter+라는 깊은 CNN 기반 ASR 모델을 훈련합니다.
- **성과**: 외부 언어 모델 없이 문자 기반 ASR에서 SOTA WER (test-clean 4.32%, test-other 14.08%)을 달성했습니다. 합성 데이터 증강이 전통적인 정규화 기법보다 훨씬 효과적임을 입증했습니다.
