# Small-Footprint Keyword Spotting with Multi-Scale Temporal Convolution

Ximin Li, Xiaodong Wei, Xiaowei Qin

## 🧩 Problem to Solve

스마트 기기 및 서비스 로봇과 같은 저사양(low-resource) 온디바이스(on-device) 환경에서 키워드 스포팅(Keyword Spotting, KWS) 시스템을 구현하는 것은 여전히 많은 과제를 안고 있습니다. 특히, 작은 모델 크기(small footprint)와 높은 정확도(high accuracy)라는 두 가지 상충되는 목표 사이에서 효과적인 균형점을 찾는 것이 주된 문제입니다. 기존 2D CNN 기반 방법들은 저주파수와 고주파수 간의 의존성을 포착하는 데 어려움을 겪으며, 1D 시간 컨볼루션 기반 방법들 또한 고정된 커널 크기로 인해 단기 및 장기 시간 정보를 모두 효과적으로 통합하는 데 한계가 있었습니다. 키워드의 특성이 시간 스케일에 따라 다르게 나타나므로, 다양한 스케일의 시간 정보를 포착하는 것이 중요합니다.

## ✨ Key Contributions

- **Temporal Efficient Neural Network (TENet) 제안**: 깊이별(depthwise) 시간 컨볼루션을 기반으로 한 경량 KWS 모델을 제안했습니다.
- **Multi-branch Temporal Convolution Module (MTConv) 개발**: 풍부한 멀티 스케일 시간 특징을 얻기 위해 MTConv를 제안했습니다. 이 모듈은 훈련 단계에서는 다양한 커널 크기를 가진 여러 브랜치를 사용하지만, 추론 단계에서는 표준 시간 컨볼루션으로 등가 변환(kernel fusion)되어 추가적인 파라미터나 계산 비용 없이 성능 향상을 달성합니다.
- **최첨단(State-of-the-Art) 성능 달성**: Google Speech Commands 데이터셋에서 기본 TENet 모델(TENet12)은 100K 파라미터로 96.6%의 정확도를 달성하며, 기존 최첨단 모델과 유사한 정확도를 훨씬 적은 파라미터로 구현했습니다. MTConv를 적용하여 훈련된 TENet 모델은 동일한 파라미터 수로 정확도를 96.8%까지 추가적으로 향상시켰습니다.

## 📎 Related Works

- **KWS 시스템**: "Hey Siri" [1], "Alexa" [2,3], "Okay Google" [4]과 같은 음성 비서 활성화 및 간단한 명령어(예: "yes", "no") 감지에 사용됩니다.
- **DNNs for KWS**: 딥러닝의 성공에 힘입어 KWS를 위한 효율적인 소형 솔루션들이 제시되었습니다 [5, 6, 7, 8, 9].
- **CNNs for KWS**: 특히 CNN은 제한된 메모리와 연산 자원 환경에서 KWS 문제 해결에 적용되어 우수한 정확도를 보였습니다 [6].
- **1D Temporal Convolution**: 2D CNN의 한계를 극복하고 고수준 주파수 특징을 추출하기 위해 1D 시간 컨볼루션을 활용하는 연구들이 진행되었습니다 [8, 9].
- **MobileNetV2**: 인버티드 잔차(inverted residual) 구조 [11]는 제안된 IBB(inverted bottleneck block)의 영감이 되었습니다.
- **ResNet**: 지름길 연결(shortcuts) [12]은 모델의 차원 일치 시 사용되었습니다.

## 🛠️ Methodology

### 1. 데이터 전처리

- **필터링**: 노이즈 감소를 위해 20Hz/4kHz 대역통과 필터를 적용합니다.
- **MFCC 특징 추출**: 30ms 윈도우 크기와 10ms 프레임 시프트로 40차원 Mel-Frequency Cepstrum Coefficient (MFCC) 프레임을 생성합니다.
- **네트워크 입력**: MFCC 특징을 $I \in \mathbb{R}^{T \times F}$ 형태로 신경망에 입력합니다. 여기서 $F$는 MFCC 특징의 차원이고, $T$는 프레임 수입니다.

### 2. Temporal Efficient Neural Network (TENet)

- **시계열 입력**: 입력 MFCC 특징을 시간 축을 따라 컨볼루션이 이루어지는 $X \in \mathbb{R}^{T \times 1 \times C}$ 형태의 시계열로 처리합니다.
- **Inverted Bottleneck Block (IBB)**: MobileNetV2 [11]의 inverted residual 구조에서 영감을 받아 TENet의 핵심 빌딩 블록으로 IBB를 도입했습니다.
  - **구성**: $1 \times 1$ 컨볼루션 (채널 확장), $9 \times 1$ 깊이별 컨볼루션 (경량 필터링), $1 \times 1$ 컨볼루션 (채널 축소)으로 이루어집니다.
  - **목적**: 첫 $1 \times 1$ 컨볼루션은 입력 채널을 고차원 부분 공간으로 확장하고, $9 \times 1$ 깊이별 컨볼루션은 채널별 필터링을 수행하며, 마지막 $1 \times 1$ 컨볼루션은 정보를 저차원 부분 공간으로 다시 압축합니다.
  - **확장 비율**: 확장 계층의 채널 크기와 병목 계층의 채널 크기 비율을 3으로 설정하여 효율성과 성능의 균형을 맞춥니다.
  - **잔차 연결(Shortcuts)**: 입력과 출력 크기가 일치할 경우 병목 계층 사이에 직접적인 잔차 연결을 사용하며, 일치하지 않을 경우 $1 \times 1$ 컨볼루션을 사용하여 차원을 맞춥니다.
  - **활성화 및 정규화**: ReLU 활성화 함수와 배치 정규화(Batch Normalization) [13]를 사용합니다.
- **TENet 아키텍처**: IBB 계층을 쌓아 TENet6 및 TENet12와 같은 TENet 구현을 구성합니다. (그림 2 참조)

### 3. Multi-Scale Temporal Convolution (MTConv)

- **다중 브랜치 구조**: TENet의 표준 깊이별 컨볼루션 계층을 대체하기 위해 다양한 커널 크기(예: $3 \times 1, 5 \times 1, 9 \times 1$)를 가진 여러 브랜치로 구성된 MTConv를 도입합니다. (그림 3 참조)
- **특징 강화**: 각 브랜치는 고유한 시간 스케일 패턴을 학습하여 단기 및 장기 시간 정보 특징을 동시에 통합하고 풍부한 시간 특징 공간을 생성합니다.
- **요소별 합산**: 각 브랜치의 출력은 요소별(element-wise)로 합산되어 ReLU 계층의 입력으로 사용됩니다. 이는 출력을 연결(concatenating)하는 대신 통합하는 방식으로, 커널 퓨전의 가능성을 열어줍니다.
- **커널 퓨전 (Kernel Fusion)**:
  - **훈련 단계**: MTConv는 여러 브랜치로 구성되어 다양한 스케일의 시간 정보를 학습합니다.
  - **추론 단계**: 훈련된 MTConv는 표준 깊이별 컨볼루션으로 등가 변환될 수 있습니다. 이는 MTConv의 각 브랜치 커널을 패딩 및 스케일링하여 동일한 크기로 만든 후 요소별로 합산하여 하나의 확장된 커널($\hat{F}$)과 편향($\hat{\beta}$)을 생성함으로써 이루어집니다.
  - **수학적 유도**:
    $$O_{t,1,j} = \sum_{i=1}^{3} O^{(i)}_{t,1,j} = \sum_{i=-k_m}^{k_m} M_{t+i,1,j} \hat{F}_{i+k+1,1,j} + \hat{\beta}_j$$
    여기서 $\hat{F} = \hat{F}^{(1)} \oplus \hat{F}^{(2)} \oplus \hat{F}^{(3)}$ 이고 $\hat{\beta} = \hat{\beta}^{(1)} + \hat{\beta}^{(2)} + \hat{\beta}^{(3)}$ 입니다.
  - **이점**: 이 메커니즘을 통해 훈련 시 모델의 표현력을 높여 성능을 개선하면서도, 추론 시에는 추가적인 파라미터나 계산 비용 없이 베이스 모델과 동일한 효율성을 유지할 수 있습니다.

## 📊 Results

- **기존 방법과의 비교 (표 1)**:
  - TENet 모델은 적은 파라미터와 연산으로 기존 방법들에 필적하거나 능가하는 성능을 보였습니다.
  - 예를 들어, TENet12는 TC-ResNet14-1.5 [8]와 동일한 96.6%의 정확도를 달성했지만, 파라미터는 1/3 수준이며 연산량도 더 적습니다.
  - 가장 작은 TENet6-narrow는 17K 파라미터로 96.0%의 정확도를 달성하여 res15 [7]와 유사한 성능을 14배 적은 파라미터와 1617배 적은 곱셈 연산으로 달성했습니다.
- **MTConv의 영향 (표 2)**:
  - MTConv를 사용하여 훈련된 TENet 모델은 그렇지 않은 모델보다 0.15% ~ 0.32% 더 높은 정확도를 달성했습니다.
  - TENet12-MTConv는 96.84%의 정확도로 가장 우수한 성능을 보였습니다. 이는 MTConv가 풍부한 멀티 스케일 시간 정보를 학습하여 성능을 개선할 수 있음을 보여줍니다.
- **다양한 커널 스케일의 영향 (표 3)**:
  - MTConv에서 브랜치 수가 증가할수록(예: $9 \times 1$ 단일 커널에서 $3 \times 1, 5 \times 1, 7 \times 1, 9 \times 1$ 네 가지 커널 사용) 정확도가 점진적으로 향상되었습니다. 이는 커널 스케일을 늘리는 것이 포괄적인 시간 특징 학습을 풍부하게 한다는 것을 입증합니다.
- **ROC 곡선 (그림 4)**: TENet12-MTConv는 모든 작동 지점에서 다른 모든 기준 모델들보다 뛰어난 성능을 보였습니다.

## 🧠 Insights & Discussion

본 연구는 KWS의 핵심 과제인 작은 풋프린트와 높은 정확도 간의 균형을 성공적으로 해결했습니다. Inverted Bottleneck Block (IBB) 기반의 TENet은 경량 모델임에도 불구하고 최첨단 수준의 정확도를 달성하며, 효율적인 아키텍처 설계를 입증했습니다. 특히 Multi-branch Temporal Convolution (MTConv) 모듈의 도입은 모델이 다양한 시간 스케일의 정보를 효과적으로 포착할 수 있도록 하여 성능 향상에 크게 기여했습니다.

더 중요한 점은 MTConv의 커널 퓨전 메커니즘입니다. 이 메커니즘 덕분에 훈련 시에는 멀티 스케일 정보를 활용하여 모델의 학습 능력을 극대화할 수 있었지만, 추론 시에는 단일 컨볼루션 계층으로 변환되어 추가적인 파라미터나 계산 비용 없이 베이스 모델과 동일한 효율성을 유지할 수 있었습니다. 이는 온디바이스 배포를 위한 KWS 시스템에서 중요한 장점입니다. 연구 결과는 넓은 네트워크일수록 MTConv를 통한 풍부한 시간 정보 학습의 효과가 더 크다는 것을 시사합니다.

## 📌 TL;DR

KWS에서 작은 풋프린트와 높은 정확도를 동시에 달성하기 위해, MobileNetV2의 인버티드 병목 블록 기반의 경량 모델인 TENet과 멀티 스케일 시간 특징을 학습하는 MTConv를 제안합니다. MTConv는 훈련 시 다양한 커널 크기를 가진 멀티 브랜치로 작동하며, 추론 시에는 커널 퓨전을 통해 추가 비용 없이 표준 컨볼루션으로 변환되어 효율성을 유지합니다. Google Speech Command Dataset에서 TENet12-MTConv는 100K 파라미터로 96.8%의 정확도를 달성하며, 적은 리소스로 최첨단 성능을 제공합니다.
