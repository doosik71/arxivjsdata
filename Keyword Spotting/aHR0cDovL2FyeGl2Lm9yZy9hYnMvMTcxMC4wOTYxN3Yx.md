# STREAMING SMALL-FOOTPRINT KEYWORD SPOTTING USING SEQUENCE-TO-SEQUENCE MODELS
Yanzhang He, Rohit Prabhavalkar, Kanishka Rao, Wei Li, Anton Bakhtin, Ian McGraw

## 🧩 Problem to Solve
본 논문은 메모리 및 연산 능력이 제한적인 모바일 기기에 배포할 수 있는 스트리밍(온라인) 키워드 스포팅(KWS) 시스템을 개발하는 문제를 다룹니다. 기존 KWS 시스템은 주로 특정 키워드에 맞춰 훈련되거나, 대규모 어휘 연속 음성 인식(LVCSR) 시스템을 사용하여 오프라인으로 작동하는 경우가 많았습니다. 이러한 방식은 새로운 키워드에 대한 재훈련의 필요성, 어휘 외 단어(Out-Of-Vocabulary, OOV) 문제, 높은 연산 비용 등의 한계를 가집니다. 본 연구는 모든 어휘에 대해 임의의 키워드 구문을 스트리밍 방식으로 정확하게 탐지하면서, 동시에 모델의 크기(small-footprint)를 작게 유지하는 방법을 모색합니다.

## ✨ Key Contributions
*   **RNN-T 기반 스트리밍 KWS 시스템 제안**: 전-신경망(all-neural) 방식의 종단 간(end-to-end) 학습 시퀀스-투-시퀀스 모델인 Recurrent Neural Network Transducer (RNN-T)를 활용하여 스트리밍 KWS 시스템을 개발했습니다.
*   **서브워드 유닛으로서 음소 또는 글자소리(grapheme) 예측**: RNN-T 모델을 음소(phoneme) 또는 글자소리(grapheme)를 서브워드 유닛으로 예측하도록 훈련하여, OOV 문제 없이 임의의 키워드 구문을 탐지할 수 있도록 했습니다.
*   **새로운 키워드 편향(biasing) 기술 도입**: 관심 키워드에 대한 주의(attention) 메커니즘을 사용하여 RNN-T 시스템이 특정 키워드를 향해 편향되도록 하는 독창적인 기술을 제안했습니다. 이를 통해 검색 과정에서 키워드를 더 효과적으로 탐지할 수 있도록 합니다.
*   **성능 우수성 입증**: 제안된 편향 기술이 적용된 RNN-T 시스템이 기존의 강력한 Connectionist Temporal Classification (CTC) 기반 "keyword-filler" 기준선 시스템보다 KWS 성능을 크게 향상시킴을 보여주었습니다 (오류율 39% 감소).
*   **'단어 끝(end-of-word, $\langle eow \rangle$)' 기호의 효과 확인**: 음소 기반 모델에서 '단어 끝' 기호($\langle eow \rangle$)를 추가하는 것이 오경보(False Alarm, FA)를 줄이고 성능을 향상시키는 데 중요함을 입증했습니다.

## 📎 Related Works
*   **오프라인 KWS**: LVCSR을 통한 단어 또는 서브워드 래티스(lattice) 구축 및 인덱싱 방식 [1, 2, 3].
*   **온라인 KWS (키워드 특정)**: 피드포워드 심층 신경망 [4, 5, 6], 컨볼루션 신경망 [7], 순환 신경망 [8, 9, 10] 등을 사용한 특정 키워드 식별. (예: "Okay Google", "Alexa", "Hey Siri")
*   **온라인 KWS (임의 키워드)**: 구조적 서포트 벡터 머신 [12, 13], 예시 기반 질의(Query-by-Example) [14, 15].
*   **종단 간 시퀀스-투-시퀀스 모델**:
    *   음성 인식 분야에서 RNN-T [16, 17], 순환 신경망 얼라이너(Recurrent Neural Aligner) [18], CTC [19] (글자소리 [20, 21], 음절 [22], 단어 [23] 타겟), 어텐션 기반 모델 [24, 25, 26].
    *   KWS 분야에서 LSTM-CTC를 이용한 음소 래티스 생성 [29], 어텐션 기반 모델을 통한 n-best 리스트 생성 [31], 직접적인 종단 간 KWS [32].
*   **CTC 기반 LVCSR 시스템**: [33, 34, 35].
*   **키워드-필러 모델**: [36] 및 필러 모델의 제약 조건에 대한 이전 연구 [38, 39, 40].

## 🛠️ Methodology
1.  **RNN-T 모델 아키텍처**:
    *   **인코더 네트워크(Encoder Network)**: 입력 음향 특징 $x = [x_1, \dots, x_T]$를 고수준 표현 $h_{enc_t}$로 매핑합니다. 5개의 500개 LSTM 셀 레이어로 구성되며, 경량화를 위해 양자화 및 저랭크 투영 레이어를 사용합니다.
    *   **예측 네트워크(Prediction Network)**: 이전의 비-빈(non-blank) 출력 레이블 $y_u$에 명시적으로 조건화되어 다음 레이블을 예측합니다. 1개의 500개 LSTM 셀 레이어로 구성됩니다.
    *   **조인트 네트워크(Joint Network)**: 인코더의 출력 $h_{enc_t}$와 예측 네트워크의 출력 $p_u$를 결합하여 최종 로짓 $z_{t,u}$를 계산합니다.
    $$h_{joint_{t,u}} = \text{tanh}(Ah_{enc_t} + Bp_u + b)$$
    $$z_{t,u} = Dh_{joint_{t,u}} + d$$
    *   이 로짓은 $\{Y \cup \langle b \rangle\}$ (출력 타겟 및 빈 기호)에 대한 확률로 변환됩니다.
2.  **키워드 편향(Keyword Biasing) 메커니즘**:
    *   예측 네트워크에 어텐션 메커니즘을 추가하여 관심 키워드 $k = [k_1, \dots, k_M, k_{M+1}]$ (여기서 $k_{M+1}$은 $\langle n/a \rangle$ 기호)에 대한 컨텍스트 벡터 $c_u$를 계산합니다.
    *   컨텍스트 벡터는 이전 예측 네트워크 상태 $h_{att_{u-1}}$와 키워드 임베딩 $k_{enc_j}$ 간의 점곱 어텐션(dot-product attention)을 통해 계산됩니다.
    $$\beta_{j,u} = \langle \phi(k_{enc_j}), \psi(h_{att_{u-1}}) \rangle \quad \text{for each } 1 \le j \le M+1$$
    $$\alpha_{j,u} = \frac{e^{\beta_{j,u}}}{\sum_{j'=1}^{M+1} e^{\beta_{j',u}}}$$
    $$c_u = \sum_{j=1}^{M+1} \alpha_{j,u} k_{enc_j}$$
    *   훈련 시 키워드 $k$가 발화 $x$에 존재하는 예시(확률 $p_{kw}$)와 존재하지 않는 예시(확률 $1-p_{kw}$)를 모두 사용합니다. 키워드가 존재할 경우, 해당 키워드 뒤에 특별한 $\langle eokw \rangle$ 기호를 삽입하여 모델이 키워드 구문에 주의를 기울이도록 돕습니다.
3.  **'단어 끝(End-of-Word, $\langle eow \rangle$)' 기호**:
    *   음소 언어 모델(LM) 훈련 시 각 단어의 발음 끝에 $\langle eow \rangle$ 기호를 삽입합니다 (예: "the cat sat" $\rightarrow$ "D V$\langle eow \rangle$ k{t$\langle eow \rangle$ s{t$\langle eow \rangle$"). 이는 LM이 암묵적으로 단어 수준의 의존성을 모델링하고 정확한 단어 경계를 학습하도록 돕습니다.
    *   검색 시에는 두 $\langle eow \rangle$ 마커 사이 또는 문장 시작 마커와 $\langle eow \rangle$ 마커 사이에 있는 키워드만 고려합니다.
4.  **디코딩 및 후처리**:
    *   빔 검색(beam search) 알고리즘을 사용하며, 매 단계에서 최대 50개의 높은 점수 후보를 유지합니다.
    *   RNN-T 모델의 출력 사후확률 분포가 '뾰족한(peaky)' 경향을 완화하기 위해 온도(temperature) $\tau$를 이용한 스무딩을 적용합니다 (예: $\tau=2.0$ 또는 $2.2$).
5.  **기준선 시스템**:
    *   **CTC 기반 LVCSR**: 64K 단어 어휘를 사용한 LVCSR 시스템으로 N-best 가설을 생성한 후, 키워드 포함/미포함 가설의 확률 비를 기반으로 신뢰도 점수를 계산합니다.
    *   **CTC 기반 키워드-필러 모델**: 키워드 경로와 필러(배경) 경로를 가진 두 개의 디코더 그래프를 사용합니다. 음소 루프, 단어 루프, 음소 N-그램 LM (단어 끝 기호 유무에 따라)을 사용하여 성능을 비교합니다.
6.  **데이터 및 평가**: 약 18,000시간의 학습 데이터(Google 음성 검색 트래픽), 노이즈 및 반향에 강인하도록 다중 조건 훈련(Multi-Condition Training, MTR) 및 다중 음량 훈련을 적용합니다. ROC 곡선(FR vs. FA)을 사용하여 성능을 평가하며, 시간당 0.05 FA에서의 FR율을 주요 지표로 사용합니다.

## 📊 Results
*   **CTC 기준선 성능**:
    *   $\langle eow \rangle$ 토큰이 추가된 음소 N-그램 LM을 사용하는 CTC 모델이 가장 좋은 기준선 성능을 보였습니다. 시간당 0.05 FA에서 14.5%의 FR(False Reject)율을 달성했습니다.
    *   $\langle eow \rangle$ 토큰이 없는 음소 LM은 오경보가 크게 증가했습니다.
    *   임베디드 LVCSR 시스템은 어휘 내 키워드에 대해 29.8%의 FR율을 기록하며 CTC 기준선보다 성능이 낮았습니다.
*   **RNN-T 모델 성능**:
    *   $\langle eow \rangle$ 토큰을 사용하는 RNN-T 음소 모델은 시간당 0.05 FA에서 11.1%의 FR율을 달성하여 최상의 CTC 기준선(14.5%)을 능가했습니다.
    *   RNN-T 글자소리 모델은 음소 모델보다 성능이 낮았습니다 (14.0% FR). 이는 일부 키워드의 철자법 변형 때문으로 분석됩니다.
*   **키워드 편향 적용 RNN-T 성능**:
    *   어텐션 기반 키워드 편향 기술을 RNN-T 음소 시스템에 추가했을 때 성능이 크게 향상되었습니다. 시간당 0.05 FA에서 8.9%의 FR율을 달성하여, 최상의 CTC 기준선 대비 39%의 FR율 감소를 보였습니다.
    *   대부분의 키워드가 0-15% 범위의 낮은 FR율을 보였으며, 소수의 이상치만 있었습니다.
*   **어텐션 가중치 시각화**: 긍정 발화에서 키워드에 해당하는 음소를 예측할 때 어텐션 가중치가 키워드 타겟을 따라 대각선으로 집중되는 패턴이 관찰되어, 편향 메커니즘이 효과적으로 작동함을 시사합니다. 키워드 탐지 후에는 $\langle n/a \rangle$ 레이블에 높은 어텐션 가중치가 할당되었습니다.

## 🧠 Insights & Discussion
*   **RNN-T의 우수성**: RNN-T는 음향 모델과 언어 모델 요소를 단일 시스템에서 공동으로 훈련하므로 KWS에 매우 효과적입니다. 이는 CTC가 가지는 조건부 독립성 가정을 극복하고, 이전 예측 이력을 명시적으로 고려하여 언어 모델링을 개선하기 때문입니다.
*   **음소 타겟의 중요성**: 글자소리 타겟보다 음소 타겟이 KWS 성능에 더 효과적이었습니다. 이는 훈련 데이터 내 키워드 구문의 다양한 정서법적 표현(orthographic representations)으로 인한 문제를 음소 기반 모델이 더 잘 처리할 수 있기 때문으로 보입니다.
*   **$\langle eow \rangle$ 기호의 역할**: '단어 끝' 기호($\langle eow \rangle$)는 음소 기반 KWS 시스템에서 오경보를 줄이는 데 결정적인 역할을 합니다. 이 기호는 음소 시퀀스 내에서 단어 경계를 암묵적으로 모델링하여, 특정 키워드 음소가 다른 단어의 일부로 우연히 일치하여 발생하는 오탐지를 줄이는 데 기여합니다.
*   **키워드 편향의 효과**: 제안된 어텐션 기반 키워드 편향 기술은 RNN-T가 특정 키워드에 집중하도록 유도하여 KWS 성능을 크게 향상시킵니다. 이 기술은 모델에 큰 지연이나 추가적인 계산 오버헤드를 유발하지 않아 스트리밍 환경에 적합합니다.
*   **실용적 의의**: 본 연구는 소형 기기에서 임의의 키워드를 스트리밍으로 탐지할 수 있는 효율적이고 정확한 KWS 시스템의 가능성을 제시합니다. 특히 'Okay Google'과 같은 음성 비서 기능 구현에 중요한 진전을 이룹니다.

## 📌 TL;DR
*   **문제**: 모바일 기기에서 작은 크기의 모델로 임의의 키워드를 스트리밍 방식으로 정확하게 탐지하는 키워드 스포팅(KWS) 시스템을 개발하는 것.
*   **제안 방법**: 음소(phoneme)를 예측하도록 훈련된 Recurrent Neural Network Transducer (RNN-T) 모델을 사용하며, 여기에 단어 끝($\langle eow \rangle$) 기호와 관심 키워드에 대한 주의(attention) 기반 편향(biasing) 메커니즘을 추가하여 모델이 키워드에 더 집중하도록 유도합니다.
*   **핵심 결과**: 제안된 RNN-T 시스템은 기존의 강력한 CTC 기반 기준선 시스템보다 훨씬 우수한 성능을 보였으며, 시간당 0.05회의 오경보(FA)율에서 8.9%의 오거절(FR)율을 달성하여 기준선 대비 FR율을 39% 감소시켰습니다. 특히 음소 타겟과 $\langle eow \rangle$ 기호, 그리고 키워드 편향 기술이 성능 향상에 결정적인 역할을 했습니다.