# 제한된 예제로 키워드 스포터에게 새로운 키워드를 학습시키기
Abhijeet Awasthi, Kevin Kilgour, Hassan Rom

## 🧩 해결하고자 하는 문제
최신 KWS(Keyword Spotting) 모델은 일반적으로 대규모 데이터셋으로 훈련되며, 미리 정의된 소수의 키워드 어휘에 국한됩니다. 이는 모델이 광범위한 미확인 키워드로 전이되는 능력을 제한하며, 사용자가 선택한 새로운 키워드를 소수의 예제로만으로 학습하여 KWS 모델을 개인화하는 것이 중요하지만 어렵다는 문제가 있습니다.

## ✨ 주요 기여
*   다수의 키워드 인식 태스크로 사전 훈련된 음성 임베딩 모델인 **KeySEM(KeywordSpeechEMbedding)**을 제안합니다.
*   KeySEM이 제공하는 음성 표현은 제한된 수의 예제로부터 새로운 키워드를 학습하는 데 매우 효과적임을 입증했습니다.
*   여러 데이터셋에서 다양한 관련 연구와 비교하여, KeySEM이 더 적은 훈련 예제로도 일관되게 우수한 성능을 달성함을 보여줍니다.
*   KeySEM이 영어 발화로만 사전 훈련되었음에도 불구하고, 다른 4개 언어(일본어, 포르투갈어, 폴란드어, 에스페란토) 데이터셋에서도 성능 향상이 나타나 KeySEM이 키워드 스포팅 태스크에 잘 맞는 유용한 표현을 학습함을 시사합니다.
*   이전에 학습된 키워드를 재훈련할 필요 없이 새로운 키워드를 순차적으로 학습할 수 있는 KeySEM의 능력을 입증하여, 배포 후 학습 및 맞춤화가 용이한 온디바이스 환경에 적합함을 보여줍니다.

## 📎 관련 연구
*   **KWS 모델:** 짧은 음성 세그먼트를 사전 정의된 키워드로 분류하는 태스크입니다. CNN 기반 [1, 4] 및 다양한 아키텍처 비교 연구 [17] 등이 있습니다.
*   **제한된 데이터 환경에서의 KWS:**
    *   ASR 모델 가중치 초기화 [18], 데이터 증강 [3, 21] (SpecAugment [21]).
    *   메타 학습 [19] (MAML [22]), 소수 예제 학습 (few-shot learning) [20] (Prototypical Networks [23]).
    *   멀티태스크 학습 [2]: Lin et al. [2]의 연구는 본 연구와 가장 유사하며, 125개의 KWS 분류기가 각각 40개의 키워드 어휘를 학습하는 멀티태스크 설정에서 임베딩 모델을 사전 훈련했습니다. KeySEM은 이와 달리 15K개의 훨씬 큰 어휘를 단일 태스크로 학습하며, Lin et al. [2] 대비 1/1000 수준의 적은 데이터로도 우수한 성능을 보였습니다.
*   **범용 음성 표현 학습:** TRILL [10]과 같은 비지도 학습 기반의 임베딩 모델이 있지만, KeySEM은 키워드 스포팅 태스크에 직접적으로 정렬된 지도 학습 사전 훈련 방식을 사용합니다.

## 🛠️ 방법론
1.  **KeySEM 사전 훈련:**
    *   **모델 아키텍처:** KeySEM($F_{\theta}: U \rightarrow \mathbb{R}^{d}$)은 2초 길이의 음성 세그먼트를 96차원 임베딩 벡터로 매핑하는 CNN 기반 모델입니다. 입력은 40차원 로그-멜 특징입니다.
    *   **사전 훈련 태스크:** $P_{\phi}(y|F_{\theta}(u))$ 모델의 일부로, 대규모 어휘 $V$에 속하는 키워드 $y$로 음성 세그먼트 $u$를 분류하는 태스크입니다. $\phi$는 SoftMax 활성화 전 선형 레이어의 파라미터입니다.
    *   **데이터셋($D$):** 공개된 LibriSpeech 코퍼스 [8]와 강제 정렬 데이터 [25, 26]를 사용하여 생성되었습니다. 15.2K개 이상의 서로 다른 n-그램(n $\le$ 5, 최소 10자, 10회 이상 발생)에서 추출된 250시간 분량의 키워드 발화로 구성됩니다.
    *   **손실 함수:** 교차 엔트로피 손실 $L = -\sum_{y \in V} \sum_{u \in U_y} \log(P_{\phi}(y|F_{\theta}(u)))$을 최소화합니다.
    *   **최적화:** Adam Optimizer [24], 학습률 $5e^{-4}$, 배치 크기 1024, 1M 스텝.
    *   **목표:** 사전 훈련 시 많은 키워드를 동시에 분류하도록 학습함으로써 $F_{\theta}$가 식별력이 높고 일반화 가능한 음성 표현을 학습하도록 합니다.
2.  **KWS 모델 학습 (다운스트림 태스크):**
    *   사전 훈련된 선형 레이어 $\phi$를 무작위로 초기화된 선형 레이어로 교체한 후, 대상 KWS 데이터셋에 대해 교차 엔트로피 손실을 최소화합니다.
    *   **두 가지 학습 전략:**
        *   **고정 (fix):** $F_{\theta}$의 가중치를 고정하고 새로운 선형 레이어만 훈련합니다 (키워드당 96개의 훈련 가능한 파라미터).
        *   **미세 조정 (FT):** $F_{\theta}$의 모든 가중치를 미세 조정합니다.
    *   **임베딩 시각화 (PCA):** KeySEM 임베딩은 다른 키워드(심지어 유사한 발음의 키워드 포함)에 대해 잘 분리된 클러스터를 형성하여 우수한 식별력을 보여줍니다.

## 📊 결과
*   **전체 데이터 비교:**
    *   KeySEM (FT)은 Speech Commands, LibriKWS (clean/other), Common Voice (일본어, 에스페란토, 폴란드어, 포르투갈어) 등 모든 데이터셋에서 전반적으로 최고의 성능을 보였습니다.
    *   KeySEM (fix) 또한 LibriKWS 데이터셋에서 매우 경쟁력 있는 결과(LK-c에서 99.8%, LK-o에서 97.8%)를 보였으며, 특히 훈련 데이터가 제한적일 때 과적합을 방지하여 KeySEM (FT) 및 다른 방법들보다 우수했습니다.
*   **제한된 데이터 실험 (키워드당 5개 예제):**
    *   KeySEM (fix)은 다른 방법론 대비 현저히 우수한 성능을 달성했습니다:
        *   **Speech Commands (SC):** KeySEM (fix) 86.5% vs. MTLEmb (fix) 79.1%.
        *   **LibriKWS-clean (LK-c):** KeySEM (fix) 98.5% vs. MTLEmb (fix) 43.9% (매우 큰 폭의 개선).
        *   **LibriKWS-other (LK-o):** KeySEM (fix) 94.5% vs. MTLEmb (fix) 33.1% (매우 큰 폭의 개선).
        *   **Common Voice (비영어권):** KeySEM이 영어 발화로만 사전 훈련되었음에도 불구하고, MTLEmb (fix) 대비 7%에서 61%p의 절대적 성능 향상을 보였습니다.
*   **새로운 키워드 순차 학습:**
    *   KeySEM의 가중치를 고정했을 때, 새로운 키워드를 순차적으로 학습하더라도 이전에 학습된 클래스의 성능 저하는 점진적이며 치명적이지 않았습니다 (전체 정확도 86.1%, 동시 학습 시 86.5%와 유사).
    *   반면, 임베딩 모델을 미세 조정할 경우 이전에 학습된 클래스의 정확도가 치명적으로 감소했습니다 (최종 전체 정확도 24.3%).

## 🧠 통찰 및 논의
*   **KeySEM의 우수성:** KeySEM이 특히 저데이터 환경에서 우수한 성능을 보이는 주된 이유는 두 가지입니다:
    1.  **더 큰 어휘 사전 훈련:** 15K개 키워드로 사전 훈련함으로써 Lin et al. [2]의 방법(헤드당 40개 키워드)보다 더 식별력 있는 특징을 학습합니다.
    2.  **간단한 다운스트림 분류기:** KeySEM은 간단한 선형 레이어(키워드당 96개 파라미터)와 함께 작동하도록 사전 훈련되어, Lin et al. [2]에서 사용된 컨볼루션 헤드(각 50K개 파라미터)보다 제한된 훈련 데이터에서 과적합에 덜 취약합니다.
*   **교차 언어 일반화:** KeySEM이 영어로만 사전 훈련되었음에도 비영어권 데이터셋에서 놀라운 성능을 보인 것은 KeySEM이 언어를 넘어 일반화될 수 있는 유용하고 태스크에 정렬된 음성 표현을 학습했음을 시사합니다.
*   **온디바이스 개인화:** KeySEM은 새로운 키워드 학습에 소수의 예제만 필요하고, 가중치 고정 시 치명적인 망각 없이 순차 학습이 가능하여 온디바이스 환경의 배포 후 맞춤화에 매우 적합합니다.

## 📌 TL;DR
*   **문제:** 기존 KWS 모델은 제한된 어휘와 대규모 데이터셋에 의존하여 새로운 키워드를 소량의 예제로 학습하기 어렵습니다.
*   **제안 방법:** 이 연구는 대규모 키워드(15K개) 분류 태스크로 사전 학습된 음성 임베딩 모델인 KeySEM을 제안합니다. KeySEM은 음성 세그먼트를 식별하기 용이한 고차원 임베딩으로 매핑하여 소량의 예제로도 새로운 키워드 스포터를 효율적으로 학습할 수 있게 합니다.
*   **주요 결과:** KeySEM은 다양한 데이터셋(영어 및 비영어권 언어 포함)에서 기존 방법론 대비 일관되게 우수한 성능을 보였으며, 특히 학습 데이터가 제한적일 때 최대 61%p 이상의 정확도 향상을 달성했습니다. 또한, KeySEM의 임베딩 가중치를 고정하면 이전에 학습된 키워드에 대한 성능 저하 없이 새로운 키워드를 순차적으로 학습할 수 있음을 입증하여 온디바이스 환경에서의 사용자 맞춤화에 매우 적합함을 보여주었습니다.