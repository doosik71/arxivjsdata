{
  "title": "Jasper: An End-to-End Convolutional Neural Acoustic Model",
  "authors": "Jason Li, Vitaly Lavrukhin, Boris Ginsburg, Ryan Leary, Oleksii Kuchaiev, Jonathan M. Cohen, Huyen Nguyen, Ravi Teja Gadde",
  "year": 2019,
  "url": "http://arxiv.org/abs/1904.03288v3",
  "abstract": "In this paper, we report state-of-the-art results on LibriSpeech among\nend-to-end speech recognition models without any external training data. Our\nmodel, Jasper, uses only 1D convolutions, batch normalization, ReLU, dropout,\nand residual connections. To improve training, we further introduce a new\nlayer-wise optimizer called NovoGrad. Through experiments, we demonstrate that\nthe proposed deep architecture performs as well or better than more complex\nchoices. Our deepest Jasper variant uses 54 convolutional layers. With this\narchitecture, we achieve 2.95% WER using a beam-search decoder with an external\nneural language model and 3.86% WER with a greedy decoder on LibriSpeech\ntest-clean. We also report competitive results on the Wall Street Journal and\nthe Hub5'00 conversational evaluation datasets.",
  "citation": 342
}