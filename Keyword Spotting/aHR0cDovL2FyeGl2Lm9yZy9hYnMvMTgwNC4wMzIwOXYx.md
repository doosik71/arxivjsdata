# Speech Commands: A Dataset for Limited-Vocabulary Speech Recognition

Pete Warden

## 🧩 Problem to Solve

이 논문은 기존의 대규모 문장 단위 자동 음성 인식(ASR) 데이터셋이 온디바이스(on-device) 키워드 스포팅(keyword spotting) 시스템 훈련 및 평가에 적합하지 않다는 문제를 다룹니다. 온디바이스 키워드 스포팅은 다음과 같은 제약 조건을 가집니다:

- **제한된 컴퓨팅 자원:** 모바일 기기 프로세서는 서버보다 컴퓨팅 능력이 훨씬 낮습니다.
- **에너지 효율성:** 배터리 수명이 중요한 모바일 기기에서 지속적으로 실행되어야 하므로 매우 에너지 효율적이어야 합니다.
- **노이즈 처리:** 대부분의 입력이 침묵이나 배경 소음이므로 오탐(false positive)을 최소화해야 합니다.
- **단어 단위 인식:** 전체 문장이 아닌 단일 단어나 짧은 구문을 인식하는 것이 중요합니다.
- **사생활 보호 및 비용:** 모든 오디오를 클라우드로 보내는 것은 비용이 많이 들고 사생활 위험을 증가시킵니다.

이러한 특수한 요구사항을 충족하며, 재현 가능하고 비교 가능한 정확도 측정 기준을 제공하는 표준화된 데이터셋의 필요성이 연구의 핵심 문제입니다.

## ✨ Key Contributions

- **새로운 데이터셋 공개:** 키워드 스포팅 시스템 훈련 및 평가를 위한 "Speech Commands" 오디오 데이터셋을 공개했습니다.
- **온디바이스 요구사항 반영:** 휴대폰 및 노트북 마이크를 통해 수집된, 실제 환경의 잡음을 포함하는 발화를 특징으로 합니다.
- **개방형 라이선스:** Creative Commons BY 4.0 라이선스로 배포하여 연구자 및 개발자들이 쉽게 접근하고 활용할 수 있도록 했습니다.
- **표준화된 평가 방법론 제시:** 데이터셋 분할(훈련/검증/테스트) 및 Top-One 에러, 스트리밍 에러와 같은 평가 지표를 제안하여 모델 간의 객관적인 비교를 가능하게 합니다.
- **기준선(Baseline) 결과 제공:** 데이터셋으로 훈련된 모델의 기준선 성능을 제공하여 향후 연구의 비교점을 제시합니다.
- **다양한 활용 가능성:** 하드웨어 제조업체가 칩의 정확도와 에너지 효율성을 입증하고, 머신러닝 및 하드웨어 공동 설계를 촉진하는 데 기여합니다.

## 📎 Related Works

- **Mozilla Common Voice:** 20,000명의 500시간 이상 음성을 담은 대규모 데이터셋으로, 문장 단위로 정렬되어 있으며 Creative Commons Zero 라이선스로 제공됩니다. 키워드 스포팅보다는 일반 ASR에 적합합니다.
- **LibriSpeech:** 1,000시간 분량의 읽힌 영어 음성 데이터셋으로, Creative Commons BY 4.0 라이선스로 제공됩니다. 문장 단위 레이블만 있어 키워드 스포팅에는 부적합합니다.
- **TIDIGITS:** 300명의 화자가 발화한 25,000개의 숫자 시퀀스를 포함하며, 상업적 라이선스로만 이용 가능하고 구형 파일 형식이라 디코딩이 어렵습니다. 저자의 초기 키워드 스포팅 실험에 사용되었습니다.
- **CHiME-5:** 사람들의 가정에서 녹음된 50시간 분량의 음성 데이터셋으로, 제한된 라이선스와 문장 단위 정렬을 특징으로 합니다.

## 🛠️ Methodology

1. **데이터 수집 요구사항 정의:**
   - **실제 환경 오디오:** 스튜디오 녹음 대신 휴대폰/노트북 마이크로 실제 환경(잡음 포함)에서 녹음.
   - **영어 집중:** 수집 및 품질 관리를 용이하게 하기 위해 영어에 집중. 다양한 억양 포함 시도.
   - **화자 독립성:** 많은 수의 다양한 화자 참여 유도.
   - **개인 식별 정보 회피:** 성별, 민족성 등 개인 정보는 수집하지 않음.
   - **표준화된 발화:** 모든 발화를 1초 길이로 제한하고 단일 단어만 녹음.
2. **단어 선택:**
   - **핵심 단어:** "Yes", "No", "Up", "Down" 등 IoT/로봇 공학 명령에 유용한 10개 단어와 0-9 숫자, 그리고 버전 2에서 4개 단어 추가.
   - **"알 수 없는 단어" (Unknown Word):** 키워드가 아닌 음성을 무시하는 모델의 능력을 테스트하기 위해 "Bed", "Bird" 등 발음이 유사하거나 다양한 음소를 포함하는 단어 포함.
3. **수집 구현:**
   - **오픈 소스 웹 애플리케이션:** WebAudioAPI를 활용한 웹 기반 애플리케이션으로 오디오를 녹음. (데스크톱 브라우저, Android 지원, iOS는 미지원)
   - **동의 프로세스:** 사용자에게 참여 동의를 명확히 받고 세션 쿠키로 동의 기록.
   - **녹음 과정:** 사용자에게 무작위로 단어를 표시하고 1.5초 동안 녹음. 클라이언트 측에 저장 후 사용자가 검토하여 서버로 업로드.
   - **익명성:** 랜덤 생성된 세션 ID를 화자 식별자로 사용하며 개인 식별 정보와 연결되지 않도록 함.
   - **참여자 모집:** 소셜 미디어와 유료 크라우드소싱을 통해 자원 봉사자 모집.
4. **품질 관리:**
   - **자동 필터링:** OGG 압축 파일 크기가 5KB 미만인 (매우 짧거나 조용한) 클립 삭제.
   - **WAV 변환 및 리샘플링:** OGG 파일을 16KHz PCM WAV 파일로 변환.
   - **가장 큰 섹션 추출 (Extract Loudest Section):** 오디오 클립의 전체 볼륨을 분석하여 너무 조용한 클립 (0.004 미만) 제거. 발화가 중앙에 오도록 가장 큰 볼륨의 1초 구간을 추출.
   - **수동 검토:** 크라우드소싱을 통해 사람이 단어를 식별하고, 기대 레이블과 일치하지 않는 클립 제거.
5. **릴리스 프로세스:**
   - 화자 ID를 8자리 16진수 ID로 해싱하여 개인 식별 정보 제거.
6. **배경 잡음 추가:**
   - 키워드 스포팅의 중요한 능력인 음성 비포함 오디오 구분을 위해, 다양한 배경 잡음(예: 물소리, 기계음, 백색/핑크 노이즈)을 담은 1분 길이의 WAV 파일 추가.

## 📊 Results

- **최종 데이터셋 규모:** 35개 단어, 105,829개 발화. 2,618명의 고유 화자 참여.
- **파일 형식:** 각 발화는 1초(또는 그 이하) 길이의 WAVE 파일로 저장되며, 16비트 단일 채널 PCM 값, 16KHz 샘플 레이트.
- **용량:** 압축되지 않은 파일은 약 3.8GB, gzip 압축된 tar 아카이브는 2.7GB.
- **데이터 분할:** `validation_list.txt`와 `testing_list.txt`를 제공하여 훈련, 검증, 테스트 세트를 명확히 분리합니다. 파일 이름 해시 함수를 사용하여 세트 할당의 일관성을 유지합니다.
- **기준선 Top-One 에러:**
  - 훈련된 모델은 10개 목표 단어, "Unknown Word", "Silence"의 12가지 범주에 대해 평가됩니다.
  - TensorFlow 튜토리얼의 최상위 모델(V2 데이터 사용)은 88.2%의 Top-One 정확도를 달성했습니다.
  - V1 데이터로 훈련된 모델은 85.4%, V2 데이터로 훈련하고 V1 테스트 세트로 평가한 모델은 89.7%를 기록하여 V2 데이터가 정확도 향상에 기여함을 보여줍니다.
- **스트리밍 에러 지표:**
  - 연속 오디오 스트림에 대한 모델 성능을 측정합니다.
  - V2 데이터로 훈련된 기준선 모델은 49.0% 일치(matched), 3.0% 오분류(wrongly), 0.0% 오탐(false positives) 결과를 보였습니다.
  - 이 지표는 주어진 시간 허용치 내에서 올바르게 식별된 단어(Matched), 음성으로 구별했으나 잘못된 클래스로 분류된 단어(Wrong), 음성이 없는 구간에서 감지된 단어(False Positive)를 나타냅니다.

## 🧠 Insights & Discussion

- **오픈 리서치 촉진:** 이 데이터셋은 ImageNet이 컴퓨터 비전 분야에 기여한 것처럼 음성 인식 분야의 연구 및 협업을 촉진하고 모델 품질을 향상시킬 것입니다.
- **하드웨어 최적화:** 공개적으로 이용 가능한 작업이 제품 요구사항을 반영함으로써 칩 공급업체는 하드웨어의 정확도와 에너지 사용량을 쉽게 비교할 수 있는 방식으로 시연할 수 있으며, 이는 하드웨어 최적화 및 공동 설계를 유도합니다.
- **재현성 및 비교 가능성:** 표준화된 데이터 수집 및 평가 방법론은 다양한 아키텍처 및 플랫폼 간의 공정한 비교를 가능하게 하여 연구 진행 속도를 높입니다.
- **온디바이스 ASR의 중요성:** 개인 정보 보호, 네트워크 지연, 비용 문제로 인해 온디바이스 키워드 스포팅이 필수적이며, 이 데이터셋은 이러한 모델 개발에 초점을 맞춥니다.
- **한계점 및 개선 방향:** 초기에는 영어에만 초점을 맞추었으나, 전이 학습 및 수집 애플리케이션의 오픈 소스화를 통해 다른 언어 확장 가능성을 열어두었습니다. iOS 미지원은 아쉬운 점으로 언급됩니다.

## 📌 TL;DR

이 논문은 저전력 온디바이스 키워드 스포팅 시스템 개발을 위한 개방형 오디오 데이터셋인 "Speech Commands"를 소개합니다. 제한된 컴퓨팅 자원과 에너지 효율성을 고려하여 휴대폰/노트북 마이크로 다양한 화자의 짧은 단어(명령어, 숫자, 기타 단어) 발화를 수집하고, 배경 소음 데이터를 포함합니다. 자동 필터링 및 수동 검토를 포함한 체계적인 품질 관리 과정을 거쳐 35개 단어, 10만 개 이상의 발화를 포함하는 데이터셋을 구축했습니다. Top-One 에러 및 스트리밍 에러와 같은 표준화된 평가 지표와 기준선 모델 성능(Top-One 정확도 88.2%)을 제시하여, 연구자 및 하드웨어 제조업체가 모델을 개발하고 비교하는 데 필요한 기반을 제공하며 오픈 소스 연구를 촉진합니다.
