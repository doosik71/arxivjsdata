# Temporal Convolution for Real-time Keyword Spotting on Mobile Devices

Seungwoo Choi, Seokjun Seo, Beomjun Shin, Hyeongmin Byun, Martin Kersner, Beomsu Kim, Dongyoung Kim, Sungjoo Ha

## 🧩 Problem to Solve

스마트 기기에서 음성 기반 사용자 상호작용을 가능하게 하는 핵심 기술인 키워드 스포팅(KWS)은 높은 정확도와 낮은 지연 시간(latency)을 동시에 요구합니다. 제한된 하드웨어 자원을 가진 모바일 기기에서 빠르고 정확한 KWS 모델을 구현하는 것은 매우 어려운 과제입니다. 특히, 기존의 2D 컨볼루션 기반 KWS 접근 방식은 적절한 성능을 달성하기 위해 많은 연산량을 필요로 하며, 모바일 기기에서의 실제 지연 시간에 대한 정량적 분석이 부족했습니다. FLOPs와 같은 간접적인 지표 대신 실제 모바일 기기에서의 추론 시간 측정에 대한 필요성이 제기됩니다.

## ✨ Key Contributions

- **TC-ResNet 제안**: 모바일 기기에서 실시간 KWS를 위한 빠르고 정확한 컨볼루션 신경망인 TC-ResNet을 제안합니다. 이 모델은 시간 차원(temporal dimension)을 따라 1D 컨볼루션(temporal convolution)을 활용합니다.
- **최고 수준 성능 달성**: Google Speech Command Dataset에서 Google Pixel 1 기준으로 기존 SOTA CNN 기반 KWS 모델 대비 **385배 빠른 속도**와 **0.3%p 향상된 정확도**를 달성했습니다.
- **구현 코드 및 벤치마크 도구 공개**: 제안하는 모델 및 기존 베이스라인 모델들의 구현 코드와 모델 학습 및 모바일 기기 평가를 위한 종단간(end-to-end) 파이프라인을 공개하여 재현성을 높였습니다.
- **시간 컨볼루션의 효과 입증**: 시간 컨볼루션이 모바일 KWS에서 2D 컨볼루션에 비해 연산량을 크게 줄이고 정확도를 향상시키는 데 기여함을 실험적으로 입증했습니다.

## 📎 Related Works

- **CNN 기반 KWS**: Sainath et al. [6]은 소형 CNN 모델을 제안했으며, Zhang et al. [7]은 메모리 및 연산 제약 조건 내에서 신경망 아키텍처를 탐색하고 평가했습니다. Tang and Lin [8]은 잔여(residual) 아키텍처와 팽창 컨볼루션(dilated convolutions)을 활용하여 정확도와 모델의 소형화를 동시에 달성했습니다. 이들 연구는 주로 시-주파수(time-frequency) 표현을 2D 컨볼루션으로 처리했습니다.
- **음향 및 음성 영역에서의 1D 컨볼루션**: Lim et al. [23] 및 Choi et al. [24]과 같은 이전 연구들에서도 음향 및 음성 도메인에서 1D 컨볼루션의 사용이 증가하고 있었습니다. 그러나 본 연구는 이들과 달리 시-주파수 표현의 주파수 축이나 원본 오디오 신호 대신 **시간 축을 따라 1D 컨볼루션**을 적용합니다.

## 🛠️ Methodology

- **입력 데이터 처리 (시간 컨볼루션)**:
  - 대부분의 기존 2D 컨볼루션 기반 KWS 모델은 MFCC(Mel-Frequency Cepstral Coefficients) $I ∈ R^{t × f}$를 $X_{2d} ∈ R^{t × f × 1}$ 형태의 2D 이미지로 간주하여 처리합니다. 여기서 $t$는 시간, $f$는 주파수 특징을 나타냅니다.
  - 본 논문에서는 MFCC를 시계열 데이터로 해석하여, 각 시간 프레임의 MFCC 특징 $f$를 채널로 간주하고 입력 텐서를 $X_{1d} ∈ R^{t × 1 × f}$로 재구성하여 시간 컨볼루션(1D 컨볼루션)을 적용합니다.
- **시간 컨볼루션의 장점**:
  - **넓은 수용 영역(Receptive Field)**: 제안된 방식은 모든 하위 수준 특징이 다음 레이어의 상위 수준 특징을 형성하는 데 항상 참여하므로, 적은 수의 레이어로도 전체 주파수 범위를 커버하는 풍부한 정보를 활용할 수 있습니다. 이는 많은 레이어를 쌓을 필요 없이 더 나은 성능을 가능하게 합니다.
  - **적은 공간 및 낮은 연산 복잡도**: 2D 컨볼루션 $W_{2d} ∈ R^{3 × 3 × 1 × c}$와 제안된 시간 컨볼루션 $W_{1d} ∈ R^{3 × 1 × f × c'}$가 동일한 파라미터 수를 가질 때, 시간 컨볼루션은 훨씬 적은 연산을 요구합니다. 또한, 시간 컨볼루션의 출력 특징 맵 $Y_{1d} ∈ R^{t × 1 × c'}$은 2D 컨볼루션의 $Y_{2d} ∈ R^{t × f × c}$보다 작아, 후속 레이어의 연산 부담과 메모리 사용량을 크게 줄입니다.
- **TC-ResNet 아키텍처**:
  - 널리 사용되는 ResNet [15] 아키텍처를 기반으로 하며, $3 × 3$ 커널 대신 $m × 1$ 커널(첫 레이어는 $m=3$, 다른 레이어는 $m=9$)을 사용합니다.
  - 컨볼루션 및 완전 연결(FC) 레이어에는 바이어스가 없으며, 각 배치 정규화(Batch Normalization) 레이어는 스케일링 및 쉬프팅을 위한 학습 가능한 파라미터를 가집니다.
  - 입력과 출력 차원이 일치하는 경우 항등(identity) 쇼트컷을 사용하고, 그렇지 않은 경우 conv-BN-ReLU를 추가하여 차원을 맞춥니다.
  - Tang and Lin [8]과 달리, 본 모델은 strided convolution을 사용하여 유효 수용 영역을 증가시키고 dilated convolution은 사용하지 않습니다.
  - **TC-ResNet8**: 3개의 잔여 블록과 {16, 24, 32, 48} 채널을 가집니다.
  - **TC-ResNet14**: TC-ResNet8보다 2배 많은 잔여 블록을 포함합니다.
  - **폭 승수(Width Multiplier, $k$)**: 각 레이어의 채널 수를 조절하여 모델의 용량 유연성을 제공합니다 (예: TC-ResNet8-1.5).
- **실험 설정**:
  - **데이터셋**: Google Speech Commands Dataset [14] (1초 길이의 음성 파일, 30개 범주 중 12개 클래스 사용).
  - **데이터 증강 및 전처리**: 무작위 시프트 및 노이즈 주입. 30ms 윈도우 길이, 10ms 스트라이드로 40개의 MFCC 특징 추출.
  - **훈련**: TensorFlow [18] 사용, 가중치 감소(weight decay) 0.001, 드롭아웃 0.5, SGD 옵티마이저 (모멘텀 0.9, 미니 배치 100), 3만 이터레이션. 학습률은 0.1에서 시작하여 1만 이터레이션마다 10으로 나눔. 조기 종료(early stopping) 사용.
  - **평가**: 정확도 (15회 평균), ROC 곡선 (micro-averaging), FLOPs [20] (TensorFlow 프로파일링 도구로 전체 연산 포함), 모든 파라미터 수.
  - **추론 시간 측정**: Google Pixel 1 모바일 기기에서 TensorFlow Lite Android 벤치마크 도구 [22]를 사용하여 측정 (단일 코어에서 50회 평균). MFCC를 입력으로 받는 첫 레이어부터 측정하여 모델 자체의 성능에 집중.

## 📊 Results

- **Google Speech Command Dataset 성능 (표 1)**:
  - TC-ResNet8은 96.1%의 정확도와 1.1ms의 추론 시간을 달성했습니다.
  - SOTA 모델인 Res15 (95.8% 정확도, 424ms 추론 시간)와 비교하여, TC-ResNet8은 **385배 빠른 속도**와 **0.3%p 향상된 정확도**를 보였습니다.
  - 자원 제약 환경을 위해 설계된 DS-CNN-S (94.4% 정확도, 1.6ms 추론 시간)에 비해서도 TC-ResNet8은 1.5배 빠르고 1.7%p 더 정확합니다.
  - 더 넓고 깊은 모델인 TC-ResNet14-1.5는 96.6%의 최고 정확도를 달성했습니다.
- **ROC 곡선 (그림 3)**: TC-ResNet14-1.5는 가장 작은 AUC(Area Under Curve) 값을 보여, 다른 베이스라인 모델에 비해 오알람율(false alarm rate)이 동일할 때 타겟 키워드를 놓칠 확률(false reject rate)이 가장 낮음을 입증했습니다. 이는 KWS 시스템의 사용자 경험에 매우 중요합니다.
- **시간 컨볼루션의 영향 (표 2 - Ablation Study)**:
  - TC-ResNet8과 동일한 아키텍처 및 파라미터 수를 가지지만 $3 × 3$ 2D 컨볼루션을 사용하는 2D-ResNet8은 유사한 정확도를 보였으나 (TC-ResNet8 대비) **9.2배 느렸습니다** (10.1ms vs 1.1ms).
  - 2D-ResNet8에 풀링 레이어를 추가하여 연산량을 줄인 2D-ResNet8-Pool은 추론 시간을 개선했지만, 정확도가 1.2%p 하락했으며 여전히 TC-ResNet8 대비 **3.2배 느렸습니다**.
  - 이는 시간 컨볼루션이 2D 컨볼루션 또는 풀링이 적용된 2D 컨볼루션에 비해 속도와 정확도 측면에서 모두 우월함을 명확하게 보여줍니다.

## 🧠 Insights & Discussion

- 시간 컨볼루션은 MFCC의 주파수 구성 요소를 채널로 취급하고 시간 축을 따라 컨볼루션을 수행함으로써, 얕은 네트워크에서도 넓은 수용 영역을 확보하고 MFCC 특징을 효과적으로 추출할 수 있습니다.
- 이러한 접근 방식은 기존 2D 컨볼루션 대비 연산 복잡도와 메모리 사용량을 획기적으로 줄여, 모바일 기기에서의 실시간 KWS 구현에 매우 적합합니다.
- FLOPs와 같은 간접 지표 대신 Google Pixel 1과 같은 실제 모바일 기기에서의 추론 시간을 정량적으로 분석함으로써, 제안 모델의 실질적인 성능 이점을 명확히 보여주었습니다.
- 향후 연구에서는 다양한 네트워크 아키텍처에 대한 시간 컨볼루션의 효능을 분석하는 것이 유망할 것으로 언급됩니다.

## 📌 TL;DR

**문제**: 모바일 기기에서의 실시간 키워드 스포팅(KWS)은 높은 정확도와 낮은 지연 시간을 요구하지만, 기존 2D CNN 모델은 연산량이 많아 느리고 비효율적이었습니다.

**방법**: 본 논문은 MFCC(Mel-Frequency Cepstral Coefficients)를 2D 이미지로 간주하는 대신, 주파수 특징을 채널로 하여 시간 축을 따라 1D 컨볼루션(temporal convolution)을 적용하는 TC-ResNet을 제안합니다. 이 방식은 적은 레이어로도 넓은 수용 영역을 확보하고 연산 복잡도를 크게 줄여줍니다.

**결과**: 제안된 TC-ResNet은 Google Speech Commands Dataset을 Google Pixel 1에서 평가했을 때, 기존 SOTA 2D CNN 모델(Res15) 대비 **385배 빠른 속도**와 **0.3%p 향상된 정확도**를 달성했습니다. Ablation 연구를 통해 시간 컨볼루션이 2D 컨볼루션 방식보다 속도와 정확도 면에서 모두 우수함을 입증했습니다.
