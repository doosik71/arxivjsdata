# OPEN-VOCABULARY KEYWORD-SPOTTING WITH ADAPTIVE INSTANCE NORMALIZATION

Aviv Navon, Aviv Shamsian, Neta Glazer, Gill Hetz, Joseph Keshet

## 🧩 Problem to Solve

이 연구는 사용자 정의 키워드를 음성 발화 내에서 정확하게 탐지하는 오픈-보캐블러리 키워드 스포팅(KWS)의 어려운 과제를 해결하는 것을 목표로 합니다. 기존 KWS 방법들은 다음 한계에 직면해 있습니다:

- 미리 정의된 키워드 세트에만 제한되거나, 새로운 키워드에 대한 재훈련/미세 조정이 필요합니다.
- 소수 학습(few-shot learning) 또는 예시 기반 질의(query-by-example) 접근 방식은 새로운 키워드에 대한 성능이 여전히 제한적이며, 여러 음성 예시가 필요하여 특히 저자원 언어에서는 어렵습니다.
- 최근의 오픈-보캐블러리 KWS 시스템은 음성 및 텍스트 정보를 공통 임베딩 공간에 정렬하는 방식에 의존하지만, 이는 음성-텍스트 표현 불일치, 음소 모델 의존성(저자원 언어에 부적합), 그리고 영어 벤치마크에만 평가되는 한계를 가집니다.
  궁극적으로, 추가 예시나 최적화 없이 다국어에서 사용자 정의 키워드를 정확하게 탐지할 수 있는 완전히 적응 가능한 KWS 접근 방식이 필요합니다.

## ✨ Key Contributions

- **AdaKWS 제안**: 텍스트 인코더가 키워드에 따라 정규화 파라미터를 출력하고, 이 파라미터가 음성 입력 처리에 사용되는 적응형 인스턴스 정규화(AdaIN) 계층 기반의 새로운 KWS 접근 방식인 AdaKWS를 제안합니다.
- **하드 부정 키워드 예시 마이닝 기법 도입**: 음향적으로 유사한 키워드에 대한 오탐을 줄이고 모델을 효과적으로 훈련하기 위해, 문자 치환, 키워드 연결, 최근접 키워드(Nearest Keyword) 방식을 포함하는 새로운 하드 부정 예시 마이닝(hard negative keyword mining) 기법을 소개합니다.
- **다국어 및 저자원 언어 일반화 능력 입증**: 다양하고 도전적인 다국어 벤치마크(VoxPopuli, LibriPhrase)에서 최신 KWS 및 ASR 베이스라인 대비 상당한 성능 향상을 입증했습니다. 또한 훈련 중 한 번도 보지 못한 저자원 언어(Fleurs) 및 데이터셋(Multilingual LibriSpeech)에 대한 뛰어난 일반화 능력을 시연했습니다.
- **전체 문장 단위 훈련**: 키워드만 포함하는 분할된 음성 샘플 대신 전체 문장(최대 30초)으로 모델을 훈련하여 단어 수준의 정렬이나 값비싼 전처리 없이도 사용 가능한 훈련 데이터 양을 크게 늘렸습니다.

## 📎 Related Works

- **사전 정의 키워드 KWS**: 특정 키워드 세트 탐지에 훈련되어 새로운 키워드에 대한 재훈련이 필요한 방법들 [3, 4, 5].
- **소수 학습 및 예시 기반 질의 KWS**: 몇 개의 음성 예시를 통해 새로운 키워드를 탐지하려는 보다 유연한 대안 [6, 7, 8, 9, 10, 11, 12]. 그러나 OOV(Out-Of-Vocabulary) 키워드에 대한 성능 한계와 음성 예시 필요성이 단점으로 지적됩니다.
- **오픈-보캐블러리 KWS (음성-텍스트 임베딩 정렬)**: 텍스트 인코더를 사용하여 음성 및 텍스트 정보를 공통 잠재 공간에 정렬하여 훈련 중 보지 못한 키워드로 일반화하는 방법들 [13, 14, 15]. 본 논문은 이러한 방법들의 한계(표현 불일치, 음소 모델 의존성, 영어 중심 평가)를 지적합니다.
- **ASR 기반 KWS**: Whisper [17]와 같이 음성을 텍스트로 전사한 후 키워드 존재 여부를 검색하는 방법.

## 🛠️ Methodology

AdaKWS 모델은 크게 두 가지 빌딩 블록으로 구성됩니다: 텍스트 인코더($h$)와 음성 분류기($f$).

1. **모델 아키텍처**:

   - **음성 인코더 (Frozen Whisper)**: 사전 훈련된 Whisper 트랜스포머 인코더 [17]를 사용하며, 훈련 중 가중치를 고정(frozen)합니다.
   - **키워드 적응형 모듈**: 음성 인코더에서 나온 음성 표현은 두 개의 순차적인 키워드 적응형 모듈로 전달됩니다. 각 모듈은 표준 트랜스포머 인코더 블록에서 Layer Normalization 레이어를 AdaIN(Adaptive Instance Normalization) 레이어로 교체한 것입니다.
     - **AdaIN**: $AdaIN(z,v) = \sigma_v \frac{z-\mu_z}{\sigma_z} + \mu_v$
       여기서 $z$는 음성 표현이고, $v$는 타겟 키워드입니다. $\mu_z, \sigma_z$는 $z$의 통계치이고, $\mu_v, \sigma_v$는 키워드 $v$에 조건화된 스케일 및 시프트 파라미터입니다.
   - **텍스트 인코더 ($h$)**: 경량 4계층 문자 기반 LSTM으로 256개의 히든 차원을 가집니다. 이 인코더는 입력 키워드 $v$를 AdaIN 레이어에서 사용될 정규화 파라미터 $\theta_v = (\mu(v), \sigma(v))$로 매핑합니다.
   - **최종 분류기**: 키워드 조건화된 음성 표현은 max-pooling 된 후 선형 분류기로 전달되어 키워드 $v$가 음성 $x$에 존재하는 확률 $P(v|x)$를 예측합니다.

2. **훈련 절차**:

   - **훈련 가능 파라미터**: 텍스트 인코더의 파라미터 $\varphi$와 AdaIN 레이어 외의 음성 분류기 공유 파라미터 $\theta$가 훈련됩니다.
   - **역전파**: 텍스트 인코더 파라미터 $\varphi$는 $ \nabla*\varphi L(x,v) = (\nabla*\varphi \theta*v)^T \nabla*{\theta_v} L(x,v) $와 같이 체인 룰을 통해 업데이트됩니다.
   - **데이터**: 단어 수준 정렬이나 전처리 없이 전체 문장(최대 30초)을 사용하여 훈련합니다.

3. **부정 샘플링 (Hard Negative Sampling)**:
   음향적으로 유사한 키워드로부터 모델을 훈련하기 위해 다음 방법을 사용합니다.
   - **무작위 부정(Random Negative)**: 훈련 데이터에 없는 키워드를 무작위로 샘플링합니다. (효과가 미미하다고 판단)
   - **문자 치환(Character Substitution)**: 긍정 키워드 $v^+$의 하나 이상의 문자를 무작위로 또는 음향적으로 유사한 문자로 대체하여 부정 키워드를 생성합니다 (예: "s" $\to$ "z").
   - **키워드 연결(Keyword Concatenation)**: 긍정 키워드 $v^+$에 다른 무작위 키워드 $v$를 연결하여 부정 키워드를 생성합니다 (예: $v^- = v \circ v^+$ 또는 $v^- = v^+ \circ v$).
   - **최근접 키워드(Nearest Keyword, NK)**: 텍스트 임베딩 표현 $e(v)$ 공간에서 긍정 키워드 $v^+$에 음향적으로 가장 유사한(코사인 거리 최소) 키워드를 부정 예시 $v^-$로 샘플링합니다.

## 📊 Results

AdaKWS는 다양한 벤치마크에서 최신 KWS 및 ASR 베이스라인 대비 우수한 성능을 보여주었습니다.

- **VoxPopuli 데이터셋**:

  - AdaKWS는 Whisper 베이스라인 대비 F1 스코어에서 6% 이상, 최대 15개 언어에서 우위를 점하며, 약 10배 적은 파라미터로도 뛰어난 성능을 보였습니다 (예: AdaKWS-Small 94.6% vs Whisper-Large-V2 88.4% Overall F1).

- **LibriPhrase 데이터셋**:

  - AdaKWS는 도전적인 LibriPhrase Hard 벤치마크에서 현재 SOTA 방법(CED)을 크게 능가했습니다 (예: AdaKWS-Small 95.09% AUC vs CED 92.70% AUC).

- **새로운 언어 및 데이터셋에 대한 일반화 (Zero-Shot)**:

  - **Multilingual LibriSpeech (MLS)**: AdaKWS-Small 모델은 Whisper large-v2 베이스라인과 유사한 성능을 달성하면서도 약 160배 빠른 추론 시간(11ms vs 1836ms)을 보였습니다.
  - **Fleurs (저자원, 새로운 언어)**: 훈련에 사용되지 않은 아이슬란드어, 몰타어, 스와힐리어, 우즈베크어 등 4개 저자원 언어에서 Whisper 베이스라인 대비 상당한 성능 향상을 입증했습니다 (예: AdaKWS-Tiny 71.9% vs Whisper-Large-V2 48.1% Overall F1).

- **어블레이션 연구 (부정 샘플링)**:
  - 부정 샘플링 전략의 중요성이 확인되었습니다. 무작위 샘플링만으로는 낮은 성능을 보였으나, 최근접 키워드(NK), 키워드 연결(Concatenation), 문자 치환(Swap)을 결합한 방법이 가장 높은 F1 스코어(92.87%)를 달성하여 AdaKWS 성능에 결정적인 영향을 미침을 보여주었습니다.

## 🧠 Insights & Discussion

- **적응형 정규화의 효과**: AdaKWS는 텍스트 인코더에서 생성된 키워드 조건부 정규화 파라미터를 사용하여 음성 입력 처리에 적응하는 새로운 패러다임을 제시합니다. 이는 음성과 텍스트 표현을 공동 임베딩 공간에 정렬하는 대신, 텍스트 정보를 음성 처리 파이프라인에 직접 주입하여 더 긴밀한 상호작용을 가능하게 합니다.
- **강력한 일반화 능력**: AdaKWS는 훈련 중 보지 못한 언어와 데이터셋에 대해 뛰어난 제로샷(zero-shot) 일반화 성능을 보여주며, 이는 다양한 언어 환경에서의 실용적인 KWS 애플리케이션 가능성을 높입니다.
- **효율성**: Whisper-Large-V2와 비슷한 성능을 보이면서도 훨씬 적은 파라미터와 압도적으로 빠른 추론 속도를 제공하여, 자원 제약이 있는 환경에서도 유용할 수 있음을 시사합니다.
- **하드 부정 샘플링의 중요성**: 음향적으로 유사한 키워드를 구별하는 능력은 KWS에서 매우 중요하며, 본 연구에서 제안된 하드 부정 샘플링 기법들이 모델의 견고성과 성능에 핵심적인 역할을 함을 입증했습니다.
- **ASR 기반 방법의 한계 극복**: 전체 문장을 전사한 후 텍스트를 검색하는 Whisper와 같은 ASR 기반 방법은 높은 계산 비용과 긴 추론 시간, 그리고 키워드 자체의 음향적 특성을 직접적으로 활용하기 어렵다는 한계가 있습니다. AdaKWS는 이러한 한계를 극복하며 더 효율적이고 정교한 키워드 탐지를 가능하게 합니다.

## 📌 TL;DR

AdaKWS는 텍스트 인코더로 생성된 키워드 조건부 정규화 파라미터를 사용하여 음성 입력을 처리하는 오픈-보캐블러리 키워드 스포팅 모델입니다. 이 모델은 하드 부정 예시 마이닝 기법과 결합하여 다국어 및 저자원 언어 환경에서 최첨단 성능을 달성하며, 기존 베이스라인 대비 뛰어난 정확도와 추론 효율성을 보여주면서 새로운 키워드와 언어에 대한 강력한 일반화 능력을 입증했습니다.
