# Keyword Transformer: A Self-Attention Model for Keyword Spotting

Axel Berg, Mark O’Connor, Miguel Tairum Cruz

## 🧩 Problem to Solve

키워드 스포팅(Keyword Spotting, KWS) 분야에서 트랜스포머(Transformer) 아키텍처는 주로 컨볼루션(Convolutional) 또는 순환(Recurrent) 인코더 위에 셀프-어텐션(Self-Attention) 메커니즘을 추가하는 방식으로 사용되어 왔다. 이 연구의 주요 문제는 사전 훈련이나 추가 데이터 없이도 KWS에 완전히 셀프-어텐션 기반의 트랜스포머 아키텍처를 직접 적용하여, 기존의 복합적인 모델(CNN, RNN, 어텐션을 혼합한 모델)을 능가하는 성능을 달성할 수 있는지 탐구하는 것이다. 특히, Google Speech Commands와 같은 비교적 작은 데이터셋에서 효율적이고 간단한 구조로 최첨단 성능을 보이는 모델을 개발하는 것이 목표이다.

## ✨ Key Contributions

- 트랜스포머 아키텍처를 키워드 스포팅에 적용하는 방법을 연구하고, 주파수 도메인보다 시간 도메인에 셀프-어텐션을 적용하는 것이 더 효과적임을 발견했습니다.
- Vision Transformer (ViT)에서 영감을 받은 완전히 셀프-어텐션 기반의 아키텍처인 Keyword Transformer (KWT)를 소개했습니다. KWT는 기존 키워드 스포팅 모델의 대체재로 사용될 수 있으며, 학습된 어텐션 마스크와 위치 임베딩의 효과를 시각화하여 분석했습니다.
- Google Speech Commands 데이터셋을 사용하여 KWT를 여러 태스크에서 평가하고, 최첨단 컨볼루션, 순환, 어텐션 기반 모델들과 비교했습니다.
- 모바일 폰에서의 KWT 모델 지연 시간(latency)을 분석하여, 엣지(edge) 환경 사용 사례에서 경쟁력이 있음을 입증했습니다.

## 📎 Related Works

- **트랜스포머 아키텍처:** Vaswani et al.의 "Attention is all you need" [1]는 트랜스포머의 기본을 제시했으며, 이 아키텍처는 NLP, 컴퓨터 비전, 음성 인식 등 다양한 도메인에서 성공을 거두었습니다.
- **Vision Transformer (ViT):** Dosovitskiy et al. [2]이 이미지 분류에 트랜스포머를 적용하여 CNN을 능가하는 성능을 보였으며, 본 연구의 패치 기반 접근 방식에 영감을 주었습니다. Touvron et al. [3]은 ViT의 데이터 효율성을 개선했으며, 본 연구는 이를 밀접하게 따릅니다.
- **키워드 스포팅 모델:**
  - Deep Neural Network (DNN), Convolutional Neural Network (CNN), Recurrent Neural Network (RNN), Hybrid-Tree [15] 등 다양한 머신러닝 기법이 활용됩니다.
  - 음성 전처리에는 멜-주파수 켑스트럼 계수(MFCC) [16]가 일반적으로 사용됩니다.
  - Zhang et al. [17]의 Depthwise-Separable CNN (DS-CNN)은 메모리 및 연산 효율성 측면에서 우수한 성능을 보여주었습니다.
  - 시간 컨볼루션(Temporal Convolutions) [19, 20] 및 셀프-어텐션 확장 모델 [12] (예: Att-RNN)도 연구되었습니다.
  - Rybakov et al. [13]의 MHAtt-RNN은 Google Speech Commands 데이터셋에서 이전 최첨단(State-of-the-Art, SOTA) 성능을 달성했으며, 본 연구에서는 교사 모델로 활용되었습니다.
- **지식 증류 (Knowledge Distillation):** Hinton et al. [26]이 제안한 기법으로, 사전 훈련된 교사 모델의 예측을 학생 모델 훈련의 보조 손실로 활용합니다. Touvron et al. [3]은 트랜스포머를 위한 증류 토큰(distillation token)을 도입하여 적은 데이터에서도 이점을 얻었습니다.
- **트랜스포머의 정규화:** PostNorm [1] 및 PreNorm [24, 32] 방식이 있으며, 본 연구에서는 PostNorm이 더 나은 성능을 보였습니다.

## 🛠️ Methodology

1. **입력 전처리:** 오디오 파형은 멜-스케일 스펙트로그램 $X \in \mathbb{R}^{T \times F}$ (시간 윈도우 $T$, 주파수 $F$)으로 변환됩니다.
2. **선형 투영:** 주파수 도메인 특성들은 선형 투영 행렬 $W_0 \in \mathbb{R}^{F \times d}$를 사용하여 더 높은 차원 $d$로 투영됩니다.
3. **클래스 토큰 및 위치 임베딩:** 학습 가능한 클래스 임베딩 $X_{\text{class}} \in \mathbb{R}^{1 \times d}$가 투영된 특성들과 시간 도메인으로 연결됩니다. 또한, 학습 가능한 위치 임베딩 행렬 $X_{\text{pos}} \in \mathbb{R}^{(T+1) \times d}$가 이 결합된 입력에 추가됩니다. 최종 트랜스포머 인코더 입력은 $X_0 = [X_{\text{class}}; XW_0] + X_{\text{pos}}$입니다.
4. **트랜스포머 인코더:** $L$개의 멀티-헤드 어텐션(Multi-Head Attention, MSA) 및 다층 퍼셉트론(Multi-Layer Perceptron, MLP) 블록으로 구성됩니다 (여기서 $L=12$).
   - **셀프-어텐션 (SA):** $SA(X_l) = \text{Softmax}\left(\frac{QK^T}{\sqrt{d_h}}\right)V$ 공식으로 계산됩니다.
   - **멀티-헤드 어텐션 (MSA):** $k$개의 SA 출력을 연결하고 다시 투영하여 얻습니다. $k$ 값(1, 2, 3)에 따라 KWT-1, KWT-2, KWT-3 모델로 나뉩니다.
   - **정규화:** PostNorm 아키텍처를 사용하며, LayerNorm(LN)이 MSA 및 MLP 블록 후에 적용됩니다. MLP에는 GELU 활성화 함수가 사용됩니다.
   - 블록 출력은 다음과 같이 계산됩니다:
     $$\tilde{X}_l = \text{LN}(\text{MSA}(X_{l-1}) + X_{l-1}), \quad l=1,...,L$$
     $$X_l = \text{LN}(\text{MLP}(\tilde{X}_l) + \tilde{X}_l), \quad l=1,...,L$$
5. **분류 헤드:** 최종 트랜스포머 블록에서 나온 클래스 임베딩 출력이 선형 분류기에 입력되어 최종 예측을 수행합니다.
6. **지식 증류 (선택 사항):**
   - 학습 가능한 증류 토큰(distillation token)을 입력에 추가합니다.
   - 증류 토큰의 출력은 선형 분류기에 입력됩니다.
   - 사전 훈련된 교사 모델(MHAtt-RNN)의 하드 결정 $y_t$와 실제 레이블 $y$를 사용하여 다음과 같은 결합 손실로 훈련됩니다: $L = \frac{1}{2} L_{\text{CE}}(\psi(Z_{\text{sc}}), y) + \frac{1}{2} L_{\text{CE}}(\psi(Z_{\text{sd}}), y_t)$, 여기서 $\psi$는 소프트맥스 함수이고 $L_{\text{CE}}$는 교차 엔트로피 손실입니다.
   - 추론 시에는 클래스 및 증류 토큰 예측을 평균하여 최종 예측을 생성합니다.
7. **데이터 증강:** 무작위 시간 이동, 리샘플링, 배경 잡음, SpecAugment [28] (시간/주파수 마스킹) 등의 기법이 사용됩니다.
8. **훈련:** AdamW 옵티마이저, 코사인 학습률 스케줄, 웜업, 가중치 감소(weight decay) 0.1, 레이블 스무딩(label smoothing) 0.1을 사용합니다.

## 📊 Results

- **Google Speech Commands 정확도:**
  - KWT 모델(특히 지식 증류가 적용된 KWT-3$_{\text{D}}$ 및 KWT-2$_{\text{D}}$)은 Google Speech Commands V2 데이터셋에서 새로운 최첨단 정확도를 달성했습니다. V2-12 명령어 태스크에서 98.56% (KWT-3$_{\text{D}}$), V2-35 명령어 태스크에서 97.74% (KWT-2$_{\text{D}}$)를 기록하며 이전 SOTA인 MHAtt-RNN을 능가했습니다.
  - 더 작은 V1-12 데이터셋에서는 KWT 모델이 MHAtt-RNN과 비슷한 성능을 보였지만 크게 능가하지는 못했는데, 이는 트랜스포머가 더 많은 데이터에서 이점을 얻는 경향이 있음을 시사합니다.
  - 지식 증류(Knowledge Distillation)는 대부분의 시나리오에서 KWT의 정확도를 향상시키는 데 효과적이었습니다.
- **어블레이션 연구:**
  - **패치 크기 / 어텐션 도메인:** 시간 도메인 어텐션(예: 패치 크기 (40, 1))이 가장 좋은 성능을 보였습니다. 직사각형 또는 주파수 도메인 패치는 정확도가 낮았습니다.
  - **정규화:** PostNorm이 다른 도메인에서의 결과와 달리 키워드 스포팅에서는 PreNorm보다 성능이 더 좋았습니다.
- **어텐션 시각화:**
  - 학습된 어텐션 마스크는 모델이 오디오 신호의 중요한 부분에 효과적으로 집중하고 배경 잡음을 억제할 수 있음을 보여주었습니다.
  - 위치 임베딩의 코사인 유사도 분석 결과, 가까운 위치 임베딩은 높은 유사도를 보인 반면, 먼 위치 임베딩은 거의 직교하는 경향을 보였습니다.
- **지연 시간 측정:**
  - KWT 모델은 모바일 폰(OnePlus 6)에서 기존 최첨단 모델들(DS-CNN, TC-ResNet, MHAtt-RNN)과 비교하여 경쟁력 있는 추론 지연 시간을 보였습니다 (KWT-3 약 4ms).

## 🧠 Insights & Discussion

- **단순성과 효율성:** KWT는 완전히 셀프-어텐션 기반의 모델임에도 불구하고, 키워드 스포팅에서 기존의 복잡한 하이브리드 모델(CNN+RNN+어텐션)을 능가하는 성능을 보여주며, 트랜스포머 아키텍처의 단순하고 직접적인 적용이 매우 효과적임을 입증했습니다.
- **시간 도메인 어텐션의 중요성:** 오디오 패치에서 셀프-어텐션이 시간 도메인에서 더 효과적이라는 발견은 키워드 스포팅에 있어 매우 중요하며, 이는 시간적 컨볼루션의 성공과도 일맥상통합니다. 이는 키워드 탐지에 시간적 관계가 핵심임을 시사합니다.
- **정규화 선택의 특이점:** PostNorm이 PreNorm보다 더 나은 성능을 보인 것은 다른 트랜스포머 응용 분야에서의 결과와 상반되는 것이므로, 다양한 도메인에서 정규화 전략의 역할에 대한 추가 연구가 필요함을 시사합니다.
- **데이터 효율성:** 트랜스포머는 일반적으로 대규모 데이터셋에서 이점을 얻지만, KWT는 사전 훈련이나 추가 데이터 없이도 비교적 작은 Google Speech Commands 데이터셋에서 SOTA를 달성했습니다. 이는 특히 지식 증류와 결합될 때 실제 KWS 응용 분야에서의 잠재력을 강조합니다.
- **엣지 장치 적용 가능성:** 모바일 장치에서의 경쟁력 있는 지연 시간은 KWT가 저지연을 위해 특별히 설계되지 않았음에도 불구하고, 온-디바이스(on-device), 상시 작동(always-on) 키워드 스포팅 애플리케이션에 실용적임을 보여줍니다. 다른 트랜스포머 도메인에서 개발된 추가 최적화(예: 희소성, 양자화)를 적용하면 지연 시간과 에너지 소비를 크게 줄일 수 있습니다.
- **향후 연구:** 본 논문은 향후 연구에서 대규모 사전 훈련, 모델 압축(예: 5.5배 지연 시간 감소), 하드웨어 인식 최적화(예: 4059배 에너지 감소) 등 다른 트랜스포머 도메인에서 얻은 이점들을 활용하여 KWS 애플리케이션을 위한 KWT를 더욱 향상시킬 수 있음을 제안합니다.

## 📌 TL;DR

**문제:** 기존 키워드 스포팅(KWS) 모델에서 셀프-어텐션은 주로 보조적인 역할에 그쳤으며, 완전히 트랜스포머 기반의 아키텍처가 KWS에 직접 적용될 수 있는지, 그리고 복잡한 하이브리드 모델을 능가할 수 있는지에 대한 탐구가 필요했습니다.
**방법:** 본 논문은 Vision Transformer (ViT)에서 영감을 받아, 멜-스케일 스펙트로그램을 시간 도메인 패치로 분할하고 학습 가능한 클래스 토큰 및 위치 임베딩과 함께 트랜스포머 인코더에 입력하는 완전히 셀프-어텐션 기반의 Keyword Transformer (KWT)를 제안합니다. 또한, 지식 증류를 통해 모델 성능을 더욱 향상시켰습니다.
**주요 발견:** KWT는 Google Speech Commands V2 데이터셋에서 새로운 최첨단(SOTA) 정확도(12 명령어 태스크 98.56%, 35 명령어 태스크 97.74%)를 달성했습니다. 특히, 시간 도메인 어텐션이 효과적이며, PostNorm이 PreNorm보다 우수함을 발견했습니다. 또한, KWT는 모바일 장치에서 경쟁력 있는 추론 지연 시간을 보여 엣지 환경에 적합함을 입증했습니다. 이는 트랜스포머 아키텍처의 직접적인 적용이 KWS 분야에서 강력한 대안이 될 수 있음을 시사합니다.
