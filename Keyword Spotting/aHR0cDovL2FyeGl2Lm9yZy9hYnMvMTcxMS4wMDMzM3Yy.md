# AN EXPERIMENTAL ANALYSIS OF THE POWER CONSUMPTION OF CONVOLUTIONAL NEURAL NETWORKS FOR KEYWORD SPOTTING

Raphael Tang, Weijie Wang, Zhucheng Tu, Jimmy Lin

## 🧩 Problem to Solve

음성 기반 대화형 에이전트에서 "Hey Siri"와 같은 트리거 문구를 감지하는 키워드 스포팅(KWS)은 모바일 및 엣지 장치에서 로컬로 처리되어야 합니다. 이러한 장치의 전력 제약으로 인해 KWS 모델은 "작은 footprint"를 가져야 합니다. 기존 연구에서는 모델의 footprint를 모델 매개변수($\text{parameters}$) 수와 순방향 추론 패스($\text{feedforward inference pass}$)의 곱셈 연산($\text{multiplies}$) 수로 측정해왔습니다. 그러나 이러한 값들은 실제 전력 소비를 대변하는 "프록시(proxy) 측정치"일 뿐이며, 실제 배포 환경에서의 경험적 성능은 여러 요인에 의해 결정됩니다. 이 논문의 주요 목표는 이러한 프록시 측정치들이 실제 KWS CNN의 전력 소비량을 얼마나 잘 예측하는지 실험적으로 검증하는 것입니다.

## ✨ Key Contributions

- Raspberry Pi에서 키워드 스포팅을 위한 컨볼루션 신경망(CNN)의 실제 전력 소비량을 최초로 측정 및 분석했습니다.
- 곱셈 연산 수가 에너지 사용량($R^2 = 0.9641$)과 지연 시간($R^2 = 0.8863$)을 예측하는 좋은 지표임을 확인했습니다.
- 매개변수 수도 에너지 사용량($R^2 = 0.7498$)과 지연 시간을 예측하지만, 곱셈 연산 수보다는 상관관계가 약함을 보였습니다.
- 모델 정확도와 에너지 소비량 사이에 강하고 놀랍도록 선형적인 상관관계($R^2 = 0.8919$)가 있음을 입증하며, "얻는 것이 있으면 지불해야 한다(you get what you pay for)"는 원칙을 확인했습니다.
- 프록시 측정치가 유용하긴 하지만, 유사한 곱셈 연산 수를 가진 모델도 에너지 프로필이 다를 수 있으므로 해석에 주의해야 한다고 제언했습니다.

## 📎 Related Works

- **Chen et al. [1]:** HMM 기반 접근 방식의 대안으로 KWS에 다층 퍼셉트론(MLP)을 도입했습니다.
- **Sainath and Parada [2]:** CNN을 사용하여 KWS에서 더 나은 결과를 달성했으며, 저전력 애플리케이션을 위한 모델 footprint 감소를 주요 동기로 언급했습니다. 본 논문은 이들의 CNN 모델을 기반으로 실험을 진행했습니다.
- **Arik et al. [3], Sun et al. [4]:** KWS에 순환 신경망(RNN)을 적용했지만, 본 논문은 CNN을 소형 footprint KWS의 표준 베이스라인으로 선택했습니다.
- **Canziani et al. [6]:** NVIDIA Jetson TX1 보드에서 컴퓨터 비전 작업용 딥 신경망의 전력 소비, 추론 시간 및 정확도 간의 관계를 연구했습니다. 본 논문은 이와 유사한 분석을 KWS에 대해 Raspberry Pi와 같은 "더 약한(wimpy)" 장치에서 수행했습니다.
- **Google Speech Commands Dataset [5]:** 벤치마크 데이터셋으로 활용되었습니다.
- **Tang and Lin [7] (Honk):** 본 연구에서 사용된 TensorFlow KWS 모델의 PyTorch 재구현 오픈소스 프로젝트입니다.

## 🛠️ Methodology

1. **모델 선정:** Sainath and Parada [2]가 제안한 여러 CNN 변형(예: `trad-fpool3`, `one-fstride{4,8}`, `tpool{2,3}`, `trad-pool2`, `one-stride1`)을 평가했습니다.
2. **데이터셋:** Google의 Speech Commands Dataset [5] (30개의 짧은 단어와 배경 소음에 대한 65,000개의 1초 음성 발화)을 사용했습니다. 분류 작업은 10개 키워드, 침묵, 알 수 없음 등 총 12개 클래스로 구성됩니다.
3. **특징 추출:**
   - 입력 오디오에 20Hz/4kHz 대역 통과 필터를 적용하여 노이즈를 줄였습니다.
   - 30ms 윈도우와 10ms 프레임 시프트를 사용하여 40차원 Mel-Frequency Cepstrum Coefficient (MFCC) 프레임을 구성했습니다.
   - 1초 간격으로 모든 프레임을 쌓아 모델의 2차원 입력 $X \in \mathbb{R}^{t \times f}$을 생성했습니다.
   - 컨볼루션 계층의 가중치는 $W \in \mathbb{R}^{m \times r \times n}$로 표현됩니다.
4. **하드웨어 환경:** Raspbian Stretch (4.9.41-v7+)를 실행하는 Raspberry Pi 3 Model B (ARM Cortex-A53)를 사용했습니다.
5. **소프트웨어 및 배포:**
   - PyTorch (Honk [7] 기반)로 개발 및 훈련된 모델을 ONNX를 사용하여 Caffe2로 내보냈습니다.
   - Raspberry Pi에서 Caffe2를 `-mfpu=neon` 플래그와 함께 소스에서 빌드하여 ARM NEON 최적화를 활용했습니다.
   - Raspberry Pi의 Caffe2 서비스에서 모델 추론을 수행했습니다.
6. **전력 측정:**
   - Raspberry Pi는 Watts Up Pro 미터에 연결되었으며, 미터의 USB 포트를 통해 외부 노트북에서 1Hz 주파수로 전력 측정값을 프로그래밍 방식으로 읽었습니다.
   - 에너지 및 최고 전력 측정값은 Raspberry Pi의 유휴 전력 소비량(1.9W)을 제외했습니다.
   - 각 Caffe2 서비스 호출 전후로 측정을 시작/중지하여 특정 모델의 모든 테스트 예제(총 2,567개)에 대한 전력을 측정했습니다.
7. **평가 지표:** 정확도, 매개변수 수, 곱셈 연산 수, 쿼리당 지연 시간, 쿼리당 에너지, 최고 전력 소비량을 측정하고 분석했습니다.

## 📊 Results

- **곱셈 연산 수와의 상관관계:**
  - 모델의 곱셈 연산 수와 쿼리당 에너지 사용량 사이에 매우 강한 양의 선형 관계를 보였습니다 ($R^2 = 0.9641, p = 0.0001$).
  - 곱셈 연산 수와 쿼리당 지연 시간 사이에도 강한 양의 선형 관계를 보였습니다 ($R^2 = 0.8863, p = 0.0015$).
- **매개변수 수와의 상관관계:**
  - 매개변수 수와 쿼리당 에너지 사용량 사이에 양의 선형 관계를 보였습니다 ($R^2 = 0.7498, p = 0.0118$).
  - 매개변수 수와 쿼리당 지연 시간 사이에도 양의 선형 관계를 보였습니다 ($R^2 = 0.7237, p = 0.0152$).
  - 곱셈 연산 수와 비교했을 때 상관관계의 강도는 더 약했습니다.
- **정확도 대 에너지:**
  - 모델 정확도와 에너지 사용량 사이에 강한 양의 상관관계($R^2 = 0.8919, p = 0.0014$)가 있음을 발견했습니다. 즉, 정확도가 높은 모델일수록 전력 소비량이 더 많았습니다.
- **프록시 지표의 한계:** `tpool2`와 `trad-pool2`처럼 유사한 곱셈 연산 수를 가진 모델들도 에너지 프로필(예: `tpool2`는 40% 느리고 25% 더 많은 에너지를 소비하지만, `trad-pool2`는 최고 전력 소비량이 더 높음)에서 상당한 차이를 보일 수 있음을 확인했습니다.

## 🧠 Insights & Discussion

- 이 연구를 통해 모델 매개변수 수와 곱셈 연산 수는 KWS CNN의 실제 에너지 소비량과 지연 시간을 예측하는 데 유용한 프록시 지표임이 확인되었습니다. 특히 곱셈 연산 수는 더 강력한 예측력을 가집니다.
- 그러나 이러한 프록시 지표만으로는 모델의 실제 전력 성능을 완전히 설명할 수 없으며, 유사한 프록시 값을 가진 모델들 사이에서도 실제 전력 소모량에 유의미한 차이가 발생할 수 있습니다. 따라서 최종적인 모델 평가를 위해서는 실제 전력 측정이 여전히 필요합니다.
- "얻는 것이 있으면 지불해야 한다"는 원칙에 따라, 이 연구에서 사용된 CNN 아키텍처 군에서는 모델 정확도가 높아질수록 전력 소비량도 선형적으로 증가하는 경향을 보였습니다. 이는 소형 footprint KWS 모델을 설계할 때 정확도와 전력 소비량 간의 불가피한 트레이드오프가 존재함을 시사합니다.
- 이러한 결과는 전력 소비를 최적화하는 소형 footprint KWS 모델 개발 시 프록시 측정치를 가이드라인으로 활용할 수 있지만, 그 해석에는 신중해야 함을 강조합니다.

## 📌 TL;DR

- **문제:** 키워드 스포팅(KWS) CNN 모델의 '모델 크기(footprint)'를 매개변수 수와 곱셈 연산 수로 측정하는 기존 방식이 실제 전력 소비량을 얼마나 잘 예측하는지 확인되지 않았음.
- **제안 방법:** Raspberry Pi에서 다양한 KWS CNN 모델의 실제 전력 소비량을 측정하고, 기존 프록시 지표(매개변수 수, 곱셈 연산 수)와의 상관관계를 분석함.
- **주요 결과:**
  - 곱셈 연산 수는 에너지 사용량 및 지연 시간과 매우 강한 양의 선형 상관관계를 보임($R^2 = 0.9641$ for energy).
  - 매개변수 수도 양의 상관관계를 보였으나 곱셈 연산 수보다는 약함.
  - 모델 정확도와 에너지 사용량 사이에도 강한 양의 선형 상관관계가 있어, 정확도를 높이려면 더 많은 전력이 필요함을 확인.
  - 프록시 지표는 유용하지만, 실제 전력 측정으로 최종 평가를 보완해야 함을 시사함.
