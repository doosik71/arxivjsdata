# 시간 지연 신경망을 이용한 효율적인 키워드 스포팅 (Efficient keyword spotting using time delay neural networks)

Samuel Myer, Vikrant Singh Tomar

## 🧩 Problem to Solve

현대 핸즈프리 음성 제어 장치에서 사용자가 장치를 "깨우기" 위해 사전 정의된 키워드(wake-word)를 말하는 키워드 스포팅(Keyword Spotting, KWS) 기능의 정확도와 효율성을 높이는 것입니다. 특히, 다음과 같은 문제를 해결하고자 합니다:

- **정확도 향상:** 오탐지(False Positives)와 미탐지(False Negatives)를 최소화하여 사용자 경험을 개선해야 합니다. 이는 깨끗한 환경뿐만 아니라 잡음이 많은 환경에서도 견고하게 작동해야 합니다.
- **연산 효율성:** 제한된 하드웨어 리소스(예: 저전력 장치)와 전력 소비를 고려하여 실시간으로 동작할 수 있도록 낮은 연산 복잡도와 메모리 사용량을 유지해야 합니다.
- **데이터 부족:** 키워드 스포팅 모델 훈련에 사용할 수 있는 특정 키워드 데이터셋이 종종 제한적일 수 있으므로, 이를 극복할 수 있는 학습 전략이 필요합니다.

## ✨ Key Contributions

- 새로운 **2단계 시간 지연 신경망(TDNN) 아키텍처**를 제안하여 키워드 스포팅 성능을 크게 향상시켰습니다.
- 대규모 음성 코퍼스에서 폰(phone) 목표로 **사전 학습한 후, 더 작은 키워드 데이터셋으로 전이 학습(transfer learning)**을 적용하는 효과적인 학습 전략을 사용했습니다.
- 인하우스 데이터셋과 Google Speech Commands 데이터셋 모두에서 기존 CNN 기반 모델 대비 **오탐지 및 미탐지율을 크게 개선**했습니다.
- **중간 결과 캐싱(caching) 및 프레임 건너뛰기(frame skipping)**와 같은 연산 최적화 기법을 도입하여 연산 복잡도를 **최대 89%까지 절감**했습니다.
- HMM과 같은 추가 모델 없이 **종단 간(end-to-end) TDNN 아키텍처**를 사용하여 시스템의 복잡성을 줄였습니다.

## 📎 Related Works

- **완전 연결 신경망(FCNNs):** [1]
- **컨볼루션 신경망(CNNs):** 키워드 스포팅에 CNN을 활용한 연구들 [2, 3]. 본 논문의 베이스라인 모델인 `cnn-one-fstride4`도 CNN 기반 [2].
- **순환 신경망(RNNs):** RNN 기반 키워드 스포팅 연구 [4, 5], 컨볼루션 레이어와 결합한 CRNN [6].
- **2차원 Grid-LSTM RNNs:** 시간 및 주파수 차원에서 시퀀스를 학습하여 좋은 결과를 보였으나 높은 연산 복잡도를 가짐 [7].
- **기존 TDNN 연구:** TDNN을 HMM과 결합하여 키워드 스포팅에 사용한 연구 [10].
- **전이 학습 및 멀티태스크 학습:** 키워드 스포팅에서 데이터 제한 및 과적합 방지를 위해 흔히 사용되는 기법 [2, 10, 13, 14].

## 🛠️ Methodology

1. **2단계 TDNN 아키텍처:**
   - **입력 특징:** 25ms 프레임 크기, 10ms 프레임 이동으로 추출된 41차원 로그-멜 필터뱅크(FBANK) 특징을 사용합니다.
   - **phone-NN (첫 번째 단계):**
     - 11 프레임(125ms)의 컨텍스트를 입력으로 받습니다.
     - 대규모 음성 인식(LVCSR) 코퍼스에서 폰(monophone) 목표(3가지 비침묵 폰 유형, 5가지 침묵 폰 유형)로 사전 학습됩니다.
     - 이 단계의 출력(소프트맥스 레이어 제외)은 word-NN의 입력으로 사용됩니다.
   - **word-NN (두 번째 단계):**
     - phone-NN의 출력에 대해 시간 축을 따라 5프레임 풀링 크기와 4 스트라이드로 최대 풀링(max-pooling)을 적용하여 차원을 축소합니다.
     - 두 개의 완전 연결 레이어와 소프트맥스 레이어로 구성되며, 키워드 레이블을 목표로 학습됩니다.
     - 전체 네트워크는 80프레임(815ms)의 입력 컨텍스트를 사용하며, 출력 레이어는 각 목표 키워드와 배경/채움 음성을 위한 유닛을 가집니다.
2. **전이 학습:**
   - phone-NN은 132개의 폰 목표를 사용하여 대규모 LVCSR 코퍼스에서 가중치를 초기화합니다.
   - 이후 소프트맥스 레이어를 제거하고 word-NN 레이어를 추가한 뒤, 전체 네트워크를 키워드 데이터셋으로 학습합니다.
3. **디코딩:**
   - 키워드 확률은 9프레임 너비의 이동 평균 필터를 사용하여 스무딩됩니다.
   - 스무딩된 확률에 임계값을 적용하여 키워드 감지를 트리거합니다.
4. **연산 효율성 최적화:**
   - **중간 결과 캐싱:** phone-NN의 출력 폰 포스테리어(posterior)를 버퍼에 캐싱하여 중복 계산을 줄입니다.
   - **프레임 건너뛰기(Frame Skipping):** 추론 시 2 또는 4의 스트라이드로 프레임을 건너뛰어 계산량을 크게 줄이면서도 정확도에 미치는 영향을 최소화합니다.

## 📊 Results

- **인하우스 데이터셋:**
  - 제안된 TDNN은 0.5 FA/hr (시간당 오경보) 고정 시 기존 CNN 모델 대비 미탐지율(FRR)에서 크게 개선된 성능을 보였습니다.
    - 깨끗한 데이터: TDNN 3.1% vs CNN 22.7% (**87% 상대적 감소**).
    - 잡음 데이터(10dB SNR): TDNN 5.8% vs CNN 27.9% (**71% 상대적 감소**).
  - TDNN은 CNN 모델 대비 곱셈 연산 수(Mul/s)도 **50% 절감**했습니다 (TDNN 25.1M Mul/s vs CNN 50.3M Mul/s).
- **Google Speech Commands 데이터셋:**
  - 원본 데이터셋: TDNN은 베이스라인 CNN 대비 **12%의 상대적 오류 감소**를 달성했습니다 (TDNN 5.7% 오류율 vs CNN 6.5% 오류율).
  - 파생 데이터셋(연속 음성 시뮬레이션): TDNN은 베이스라인 CNN 대비 **39%의 상대적 오류 감소**를 달성했습니다 (TDNN 15.2% 오류율 vs CNN 24.8% 오류율).
- **프레임 건너뛰기:**
  - 2 또는 4의 스트라이드로 프레임을 건너뛰었을 때, 키워드 스포팅 정확도에 미치는 영향은 매우 미미했습니다 (FRR 3.1% (건너뛰기 없음) $\rightarrow$ 4.8% (2 스트라이드) $\rightarrow$ 3.9% (4 스트라이드)).
  - 4 스트라이드 건너뛰기를 통해 연산 복잡도를 **최대 75%까지 추가 절감**할 수 있었습니다.

## 🧠 Insights & Discussion

- 본 논문은 키워드 스포팅을 위한 2단계 TDNN 아키텍처가 기존 CNN 기반 모델보다 우수한 정확도를 제공함을 입증했습니다. 특히, 오탐지율을 낮추면서 미탐지율을 크게 줄이는 데 성공했습니다.
- 전이 학습 전략은 제한된 키워드 데이터셋에서도 모델이 견고하게 학습하고 일반화될 수 있도록 돕는 핵심 요소였습니다.
- 연산 최적화(캐싱, 프레임 건너뛰기)는 정확도를 크게 희생하지 않으면서도 모델의 실제 배포 가능성을 높여주는 중요한 기법입니다. 이는 저전력/제한된 하드웨어 환경에서 연속적으로 음성을 청취하는 시스템에 매우 중요합니다.
- TDNN의 더 긴 입력 컨텍스트가 성능 향상에 기여하지만, 아키텍처 자체의 우수성이 단순한 컨텍스트 증가 이상의 이점을 제공한다는 점이 확인되었습니다.
- 단, Speech Commands 데이터셋의 경우, 원본 데이터셋에서는 개선 효과가 인하우스 데이터셋만큼 크지 않았습니다. 이는 데이터셋의 특성(예: 단일 명령어 vs. 연속 음성)에 따라 모델의 이점이 다르게 나타날 수 있음을 시사합니다.
- 향후 연구에서는 프레임 건너뛰기 기법을 양자화(quantization) 또는 이진화(binarization)와 같은 다른 최적화 기법과 결합하여 추가적인 성능 향상을 모색할 수 있을 것입니다.

## 📌 TL;DR

본 논문은 키워드 스포팅을 위한 효율적인 2단계 시간 지연 신경망(TDNN)을 제안합니다. 이 모델은 대규모 코퍼스에서 폰 목표로 전이 학습된 후 키워드 목표로 미세 조정됩니다. 제안된 TDNN은 인하우스 및 Google Speech Commands 데이터셋에서 기존 CNN 기반 모델 대비 오탐지 및 미탐지율을 크게 줄였으며, 동시에 중간 결과 캐싱 및 프레임 건너뛰기와 같은 최적화 기법을 통해 연산량을 최대 89%까지 절감했습니다. 이를 통해 저전력 장치에서도 높은 정확도로 실시간 키워드 스포팅이 가능함을 보여주었습니다.
