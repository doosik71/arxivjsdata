{
  "title": "Contrastive Augmentation: An Unsupervised Learning Approach for Keyword\n  Spotting in Speech Technology",
  "authors": "Weinan Dai, Yifeng Jiang, Yuanjing Liu, Jinkun Chen, Xin Sun, Jinglei Tao",
  "year": 2024,
  "url": "http://arxiv.org/abs/2409.00356v1",
  "abstract": "This paper addresses the persistent challenge in Keyword Spotting (KWS), a\nfundamental component in speech technology, regarding the acquisition of\nsubstantial labeled data for training. Given the difficulty in obtaining large\nquantities of positive samples and the laborious process of collecting new\ntarget samples when the keyword changes, we introduce a novel approach\ncombining unsupervised contrastive learning and a unique augmentation-based\ntechnique. Our method allows the neural network to train on unlabeled data\nsets, potentially improving performance in downstream tasks with limited\nlabeled data sets. We also propose that similar high-level feature\nrepresentations should be employed for speech utterances with the same keyword\ndespite variations in speed or volume. To achieve this, we present a speech\naugmentation-based unsupervised learning method that utilizes the similarity\nbetween the bottleneck layer feature and the audio reconstructing information\nfor auxiliary training. Furthermore, we propose a compressed convolutional\narchitecture to address potential redundancy and non-informative information in\nKWS tasks, enabling the model to simultaneously learn local features and focus\non long-term information. This method achieves strong performance on the Google\nSpeech Commands V2 Dataset. Inspired by recent advancements in sign spotting\nand spoken term detection, our method underlines the potential of our\ncontrastive learning approach in KWS and the advantages of Query-by-Example\nSpoken Term Detection strategies. The presented CAB-KWS provide new\nperspectives in the field of KWS, demonstrating effective ways to reduce data\ncollection efforts and increase the system's robustness.",
  "citation": 0
}