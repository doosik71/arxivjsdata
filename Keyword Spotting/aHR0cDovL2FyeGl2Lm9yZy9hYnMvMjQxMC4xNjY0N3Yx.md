# GE2E-KWS: GENERALIZED END-TO-END TRAINING AND EVALUATION FOR ZERO-SHOT KEYWORD SPOTTING

Pai Zhu, Jacob W. Bartel, Dhruuv Agarwal, Kurt Partridge, Hyun Jin Park, Quan Wang

## 🧩 Problem to Solve

기존 키워드 스포팅(KWS)은 "Hey Google"과 같은 미리 정의된 소수의 키워드를 탐지하는 데 중점을 두었으며, 이는 제한적인 어휘와 새로운 키워드에 대한 재학습의 필요성이라는 한계를 가집니다. 사용자가 오디오 또는 텍스트를 통해 자신만의 키워드를 지정할 수 있는 맞춤형, 제로샷(zero-shot) KWS에 대한 수요가 증가하고 있습니다. 이를 위해 효율적인 음성 임베딩 기반 솔루션이 필요하지만, 대규모 ASR 인코더는 온디바이스 실행에 너무 크고, 기존 분류 기반 모델은 매칭 정확도가 낮으며, 트립렛 손실(triplet loss) 기반 접근 방식은 샘플링 비효율성 및 수렴 불안정성 문제를 겪었습니다. 또한, 맞춤형 KWS 모델의 성능을 체계적이고 신뢰할 수 있게 평가할 수 있는 표준화된 방법론이 부족합니다.

## ✨ Key Contributions

- **GE2E(Generalized End-to-End) 손실의 KWS 적용**: 화자 확인(speaker verification) 영역의 GE2E 손실을 맞춤형 KWS에 최초로 적용했습니다. 이는 런타임 등록 및 검증 과정을 훈련 중에 시뮬레이션하며, 배치 내 키워드별 등록 중심점(enrollment centroid)을 생성하여 모든 테스트 발화와 비교함으로써 트립렛 손실 대비 수렴 안정성 및 훈련 효율성을 크게 향상시켰습니다.
- **새로운 종단 간 평가 프로세스 제안**: 실세계 오디오 등록 및 맞춤형 키워드 탐지를 모방하는 체계적인 평가 프로세스를 설계했습니다. Speech Commands 데이터셋을 활용하여 깨끗한 환경 및 노이즈 환경에서 키워드 매칭 정확도를 직접 측정하는 지표(AUC, EER 등)를 정의했습니다.
- **경량화된 Conformer 모델 최적화**: Conformer 모델을 맞춤형 KWS에 적용하고 튜닝하여, 419KB의 양자화된 모델로 7.5GB ASR 인코더 대비 23.6%p, 동일 크기의 트립렛 손실 모델 대비 60.7%p의 상대적 AUC 성능 향상을 달성했습니다. 이 모델은 메모리 사용량이 적고, 온디바이스에서 연속적으로 스트리밍 가능하며, 새로운 키워드에 대한 재훈련이 필요 없는 제로샷 기능을 지원합니다.

## 📎 Related Works

- **전통적인 KWS**: 미리 정의된 키워드(예: "Hey Google") 탐지에 중점을 둔 소형 모델 연구 [1, 2, 3].
- **맞춤형 KWS**:
  - **템플릿 매칭**: DTW(Dynamic Time Warping) [4] 등. 키워드 선택의 제약이나 새로운 키워드에 대한 재훈련 필요.
  - **음소 분류**: [5] 등.
  - **음성 임베딩 기반**:
    - **ASR 인코더**: 음성을 텍스트로 변환하는 ASR 시스템의 인코더 [8]를 활용하여 발화 임베딩 생성. 높은 정확도를 보이나, 모델 크기가 커 온디바이스 연속 실행에 부적합.
    - **음성 분류 인코더**: 분류 작업으로 훈련된 모델의 은닉층에서 음성 임베딩 추출 [9, 10, 11, 12]. 온디바이스에 적합하나, 발화 매칭 품질을 직접 측정하지 않는 분류 정확도로 평가되어 실제 KWS 성능이 좋지 않음 [9].
- **트립렛 손실(Triplet Loss)**: 얼굴 인식(FaceNet [14]) 및 화자 분할(speaker diarization) [15, 16], 화자 확인(speaker verification) [17]에 널리 사용. 최근 KWS에도 적용 [18, 19]되었으나, 비효율적인 샘플링(배치당 하나의 앵커 발화-양성-음성 쌍)으로 인해 훈련 속도가 느리고 수렴 안정성이 떨어짐.
- **GE2E 손실**: 화자 확인 분야에서 제안된 손실 함수 [22].

## 🛠️ Methodology

1. **GE2E 손실(Generalized End-to-End Loss)**
   - **개념**: 화자 확인에 사용된 GE2E 손실 [22]을 KWS에 적용. 훈련 배치 내 모든 발화를 등록(enrollment) 및 테스트 발화로 나눕니다.
   - **등록 중심점($c_i$) 계산**: 각 키워드($Pr_i$)에 대해, $Y/2$개의 등록 발화 임베딩($e_{ij}$)의 평균을 취하여 등록 중심점 $c_i$를 계산합니다.
     $$c_i = \frac{1}{Y/2} \sum_{j=1, j(mod~2)\neq0}^{Y} e_{ij}$$
   - **양성($p_i$) 및 음성($n_i$) 예제 정의**:
     - 양성 예제($p_i$): 동일 키워드의 남은 테스트 발화들.
     - 음성 예제($n_i$): 다른 키워드의 모든 테스트 발화들.
   - **GE2E 손실 계산**: 중심점 $c_i$와 양성 예제 간의 코사인 유사도는 최대화하고, 음성 예제 간의 코사인 유사도는 최소화합니다.
     $$L(c_i) = \log \sum_{n \in n_i} \exp \cos(c_i, n) - \log \sum_{p \in p_i} \exp \cos(c_i, p)$$
   - **장점**: 다중 발화로 중심점을 구성하여 샘플링 분산을 줄여 수렴 안정성을 높이고, 임베딩 유사도 계산을 행렬 연산으로 포매팅하여 계산 효율성을 높입니다.
2. **모델 아키텍처**
   - **LSTM 모델**: 표준 3계층 LSTM [20]을 사용하며, 히든 레이어 및 출력 레이어 차원을 조절하여 성능과 모델 크기 간의 균형을 맞춥니다.
   - **Conformer 모델**: ASR 분야의 SOTA 모델인 Conformer [21]를 사용합니다. Transformer의 전역 상호작용 포착 능력과 CNN의 지역 특징 활용 능력을 결합합니다. Conformer 블록 수, MHSA 헤드 수, 임베딩 크기 등을 튜닝합니다.
3. **양자화(Quantization)**
   - TensorFlow Lite [25]의 동적 범위 양자화(dynamic range quantization)를 사용하여 가중치 및 활성화 함수를 8비트 정밀도로 동적으로 양자화하여 모델 크기를 줄이고 온디바이스 실행 효율성을 높입니다.
4. **훈련 데이터 및 인프라**: MSWC(Multilingual Spoken Words Corpus) 데이터셋 [26] (3만 8천 개 구절, 530만 개 발화)을 사용합니다. TensorFlow/Lingvo [27] 프레임워크를 기반으로 자동 스트리밍 추론 변환 기능을 활용합니다.
5. **평가 데이터 및 프로세스**: Speech Commands 데이터셋 [13]의 테스트 분할(35개 구절, 1만 1천 개 발화)을 사용합니다. 각 구절에 대해 10개의 발화를 등록 데이터셋으로 무작위 선택하고, 나머지를 테스트에 사용합니다. 등록 중심점과 모든 테스트 발화 임베딩 간의 코사인 유사도를 계산하여 매칭 품질을 측정합니다. 깨끗한 환경과 3~15dB의 3-way MTR 백그라운드 노이즈가 추가된 환경에서 모두 평가합니다.
6. **평가 지표**:
   - **코사인 유사도 히스토그램**: 등록 중심점과 동일 키워드의 테스트 발화(True Positive), 다른 키워드의 테스트 발화(True Negative) 간 유사도 점수를 히스토그램으로 시각화합니다.
   - **DET(Detection Error Tradeoff) 곡선**: 다양한 임계값에 대해 FAR(False Acceptance Rate)과 FRR(False Rejection Rate)을 계산하여 곡선을 그립니다.
   - **AUC(Area Under the DET Curve) 및 EER(Equal Error Rate)**: DET 곡선의 성능을 수치적으로 비교하기 위한 지표. AUC와 EER이 낮을수록 모델 성능이 우수합니다. 모든 구절에 대해 평균화된 집계(aggregated) AUC 및 EER을 사용합니다.

## 📊 Results

- **GE2E Conformer의 뛰어난 성능**: 419KB로 양자화된 GE2E Conformer 모델은:
  - 7.5GB ASR 인코더 대비 평균 AUC에서 상대적으로 23.6%p 더 우수 (ASR: 0.66%, GE2E Conformer: 0.504%).
  - 동일 크기(419KB)의 트립렛 손실 Conformer 모델 대비 평균 AUC에서 상대적으로 60.7%p 더 우수 (트립렛: 1.283%, GE2E Conformer: 0.504%).
  - 1.4MB 음성 분류 인코더(6.44% AUC)보다 월등히 뛰어납니다.
- **다양한 모델 크기별 성능**:
  - GE2E 손실 기반 LSTM 및 Conformer 모델에 대한 크기별 성능 분석 결과, Conformer는 작은 모델 크기에서 LSTM보다 좋은 결과를 보이며, 특히 노이즈 환경에서 지역 컨텍스트로부터 노이즈를 탐지하는 능력 덕분에 더 강건한 성능을 보입니다.
  - 모델 크기가 커질수록 성능이 향상되지만, 특정 시점(예: Conformer 18MB, LSTM 15MB) 이후에는 성능 향상이 둔화되거나 포화됩니다.
- 모델은 온디바이스에서 연속 실행 가능하며, 새로운 키워드에 대한 재훈련이 필요 없는 제로샷 기능을 지원합니다.

## 🧠 Insights & Discussion

- **GE2E 손실의 효과성**: GE2E 손실은 다수의 발화를 통해 등록 중심점을 구성하고 이를 배치 내 모든 테스트 발화와 비교함으로써, 기존 트립렛 손실의 샘플링 비효율성과 수렴 불안정성 문제를 해결합니다. 이는 훈련 속도를 가속화하고 모델 성능을 크게 향상시킵니다.
- **Conformer 아키텍처의 적합성**: Conformer는 Transformer의 전역적 특징과 CNN의 지역적 특징을 결합하여 음성 임베딩 생성에 매우 효과적임을 입증했습니다. 특히 노이즈 환경에서의 우수한 성능은 실제 온디바이스 환경에서의 강건성을 시사합니다.
- **경량화 및 제로샷의 중요성**: 419KB에 불과한 양자화된 Conformer 모델이 대규모 ASR 모델보다 우수한 성능을 달성한 것은 온디바이스, 제로샷 KWS 솔루션의 실현 가능성을 보여줍니다. 이는 사용자가 재훈련 없이 맞춤형 키워드를 쉽게 설정할 수 있도록 하여 개인화된 음성 인터페이스의 가능성을 확장합니다.
- **새로운 평가 방법론의 필요성**: 기존 분류 정확도 기반의 평가 방식으로는 실제 KWS 성능을 정확히 측정하기 어렵다는 점을 지적하며, 제안된 종단 간 평가 프로세스는 실세계 환경을 모방하여 모델의 실제 유용성을 평가하는 데 중요한 기반을 제공합니다.
- **한계**: 모델 크기와 성능 사이에는 여전히 트레이드오프가 존재하며, 특정 디바이스 및 런타임 제약 조건에 따라 적절한 모델을 선택해야 합니다.

## 📌 TL;DR

본 논문은 온디바이스 맞춤형, 제로샷 키워드 스포팅(KWS)의 효율성과 정확도를 높이기 위해 **GE2E(Generalized End-to-End) 손실**을 KWS 훈련에 적용했습니다. 발화를 등록 및 테스트 그룹으로 나누고, 등록 발화로부터 키워드별 **등록 중심점**을 생성하여 모든 테스트 발화와 비교함으로써 트립렛 손실 대비 **수렴 안정성과 훈련 효율성**을 크게 향상시켰습니다. 또한, 실세계를 모방한 **종단 간 평가 프로세스**와 지표를 제안했습니다. 결과적으로, 419KB로 양자화된 GE2E Conformer 모델은 7.5GB ASR 인코더보다 **23.6%p,** 동일 크기의 트립렛 손실 모델보다 **60.7%p** 더 높은 평균 AUC를 달성하며, 온디바이스에서 재훈련 없이 새로운 키워드를 탐지하는 고성능 경량 제로샷 KWS 솔루션을 제공합니다.
