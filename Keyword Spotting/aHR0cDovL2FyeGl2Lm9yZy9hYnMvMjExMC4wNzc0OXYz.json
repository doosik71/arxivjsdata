{
  "title": "Attention-Free Keyword Spotting",
  "authors": "Mashrur M. Morshed, Ahmad Omar Ahsan",
  "year": 2021,
  "url": "http://arxiv.org/abs/2110.07749v3",
  "abstract": "Till now, attention-based models have been used with great success in the\nkeyword spotting problem domain. However, in light of recent advances in deep\nlearning, the question arises whether self-attention is truly irreplaceable for\nrecognizing speech keywords. We thus explore the usage of gated MLPs\n--previously shown to be alternatives to transformers in vision tasks-- for the\nkeyword spotting task. We provide a family of highly efficient MLP-based models\nfor keyword spotting, with less than 0.5 million parameters. We show that our\napproach achieves competitive performance on Google Speech Commands V2-12 and\nV2-35 benchmarks with much fewer parameters than self-attention-based methods.",
  "citation": 10
}