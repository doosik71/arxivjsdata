# TRAINING KEYWORD SPOTTERS WITH LIMITED AND SYNTHESIZED SPEECH DATA

James Lin, Kevin Kilgour, Dominik Roblek, Matthew Sharifi

## 🧩 Problem to Solve

스마트 디바이스의 확산으로 음성 제어 기능의 수요가 증가함에 따라, 임의의 키워드 세트를 인식하기 위한 키워드 스포팅(Keyword Spotting, KWS) 모델을 신속하게 개발해야 할 필요성이 커지고 있습니다. 그러나 이러한 모델을 훈련하기 위한 충분한 실제 음성 데이터를 확보하는 것은 시간과 비용이 많이 드는 어려운 과제입니다. 이 논문은 제한된 실제 음성 데이터만으로도 효율적으로 KWS 모델을 훈련할 수 있는 방안을 모색합니다.

## ✨ Key Contributions

- **사전 훈련된 음성 임베딩 모델의 활용:** KWS 모델 훈련에 필요한 실제 데이터 양을 35,000개에서 2,000개 미만으로 크게 줄일 수 있는 효과적인 음성 임베딩 모델을 제안합니다.
- **합성 음성 데이터의 유효성 입증:** 사전 훈련된 음성 임베딩 모델 위에 훈련된 헤드 모델의 경우, 합성 음성 데이터만으로 훈련해도 실제 음성 데이터로 훈련한 모델과 유사한 높은 정확도를 달성할 수 있음을 보여줍니다.
  - 합성 음성 3,220개로 훈련된 헤드 모델은 92.6%의 정확도를 달성하여, 50개 이상의 실제 음성 예제로 훈련된 헤드 모델 또는 4,000개 이상의 실제 음성 예제로 훈련된 풀(full) 모델과 동등한 성능을 보였습니다.
- **신속한 모델 프로토타이핑:** 헤드 모델은 단일 GPU에서 몇 분 이내에 훈련될 수 있어, KWS 모델의 빠른 개발 및 맞춤화를 가능하게 합니다.
- **데이터 부족 문제 해결:** 합성 음성이 실제 데이터를 완전히 대체하거나, 기존의 제한된 실제 데이터를 보강하여 모델 성능을 크게 향상시킬 수 있음을 입증합니다.

## 📎 Related Works

- **키워드 스포팅 시스템:**
  - DNN 기반 시스템: Chen et al. [2] ("okay Google"), TDNN-HMM [16] 및 DNN-HMM [11] (Amazon Alexa), Sigitia et al. [15] (Apple Siri).
  - 컨볼루션 네트워크 기반 시스템: Coucke et al. [5] (dilated convolutions, WaveNet [9]), Choi et al. [3] (ResNet [6] 기반 시간적 컨볼루션, Speech Commands 데이터셋에서 96.6% 정확도).
- **합성 음성을 이용한 데이터 증강:**
  - 일반적인 연구들 [13, 7, 12, 8] 및 Tacotron 2 [14] 기반 합성기 활용 연구 [7, 12].
- **전이 학습(Transfer Learning) 및 다중 작업 학습(Multi-task Learning):**
  - Sun et al. [16] (전체 음성 인식 시스템을 사용하여 KWS 초기화, 하위 계층 공유), Raju et al. [11] (유사한 다중 목표 훈련 설정).

## 🛠️ Methodology

1. **모델 아키텍처:**
   - 메모리 및 연산 능력이 제한된 환경(예: DSP)에 최적화된 약 400k 파라미터의 소형 모델.
   - **임베딩 모델 (Embedding Model):**
     - 5개의 컨볼루션 블록(약 330k 가중치)으로 구성되며, 32차원 로그 멜 특징 벡터($60\text{Hz}$ ~ $3800\text{Hz}$)를 입력받아 80ms마다 96차원 특징 벡터를 출력합니다.
   - **헤드 모델 (Head Model):**
     - 1개의 컨볼루션 블록과 분류 블록(약 55k 가중치)으로 구성됩니다.
     - 분류 블록은 연속적인 예측을 위한 Maxpool + $1\times 1$ Convolution 또는 단일 단어 평가를 위한 Maxpool + Fully Connected Layer를 사용합니다. 본 논문의 결과는 Fully Connected Layer 방식을 기반으로 합니다.
2. **임베딩 모델 훈련:**
   - 임의의 키워드 세트에 유용한 임베딩을 생성하도록 훈련됩니다.
   - 5,000개의 키워드(대부분 2~3단어 길이)를 40개씩 125개의 그룹으로 나누어 사용합니다.
   - 각 그룹에 대해 125개의 KWS 모델을 병렬로 훈련하며, 이 모델들은 임베딩 모델 부분의 가중치를 공유합니다 (Figure 1 참조).
   - 훈련 데이터: YouTube에서 얻은 약 2억 개의 2초 오디오 클립(1억 개는 타겟 키워드 포함, 1억 개는 비타겟).
   - TensorFlow [1]를 사용하여 20개의 GPU에서 2일간 훈련되었으며, TensorFlow Hub에 공개되어 있습니다.
3. **헤드 모델 훈련:**
   - 사전 훈련된 임베딩 모델(미세 조정 비활성화) 위에 훈련됩니다.
   - 적은 데이터셋(예: 1,000개 예제)으로 단일 GPU에서 30-40초 만에 수렴하며, 훈련 시간이 매우 빠릅니다.
   - 새로운 타겟 키워드당 96개의 추가 가중치만 필요하여 키워드 수에 잘 확장됩니다.
4. **실험 설정:**
   - **데이터:**
     - 실제 음성 데이터: Speech Commands 데이터셋 [17] (35개 단어의 8만 개 짧은 발화). 이 데이터셋은 임베딩 모델 훈련에는 사용되지 않았습니다.
     - 합성 음성 데이터: Tacotron 2 [14] 기반의 텍스트-음성 합성(TTS) 시스템으로 92개 음성을 사용하여 Speech Commands의 35개 단어를 합성했습니다.
   - **평가:** Speech Commands 평가 세트를 사용하며, 다양한 크기의 훈련 세트(단어당 1~1,000개 예제)를 무작위로 20번 선택하여 훈련하고 평균 및 표준 편차를 계산했습니다.
   - **합성 음성 활용 사례:**
     - **대체 (Replacement):** 합성 음성으로만 훈련하고 점진적으로 실제 예제로 대체.
     - **증강 (Augmentation):** 합성 음성 데이터에 실제 음성 데이터를 추가.
   - **기존 데이터 증강 기법:** 피치/템포 시프트, 방 잔향 효과, 백색 노이즈 추가 등을 시도했으나 유의미한 성능 향상은 없었습니다.

## 📊 Results

- **베이스라인 (전체 Speech Commands 데이터 훈련):**
  - 풀 모델: 97.4% 정확도
  - 헤드 모델 (임베딩 사용): 97.7% 정확도
- **제한된 데이터 성능 비교 (표 1):**
  - 합성 데이터 3220개로 훈련된 풀 모델: 56.7%
  - 실제 데이터 3220개로 훈련된 풀 모델: 88.7%
  - **합성 데이터 3220개로 훈련된 헤드 모델 (임베딩 사용): 92.6%**
  - 실제 데이터 3220개로 훈련된 헤드 모델 (임베딩 사용): 95.3%
  - **주요 결과:** 임베딩을 사용하는 헤드 모델은 합성 데이터만으로도 풀 모델이 더 많은 실제 데이터로 달성하는 정확도에 근접하거나 능가하는 성능을 보였습니다. 특히 합성 데이터만으로 훈련된 헤드 모델(92.6%)은 실제 데이터 3220개로 훈련된 풀 모델(88.7%)보다 높은 정확도를 기록했습니다.
- **데이터 등가성:**
  - 합성 음성만으로 훈련된 헤드 모델(92.6% 정확도)은 단어당 50개의 실제 예제(총 약 1,750개)로 훈련된 헤드 모델 또는 단어당 4,000개 이상의 실제 예제(총 약 14만 개)로 훈련된 풀 모델의 정확도와 동등했습니다.
- **실제 데이터 대체 (그림 2):**
  - 합성 데이터의 일부를 적은 양의 실제 데이터로 대체하는 것만으로도 순수 합성 데이터와 순수 실제 데이터 간의 성능 격차를 크게 줄일 수 있습니다. 약 50%의 데이터를 실제 데이터로 대체하면 정확도 차이가 거의 90% 줄어듭니다.
- **실제 데이터 증강 (그림 3):**
  - 단어당 1,000개의 실제 예제가 있는 경우, 합성 데이터 추가는 추가적인 개선을 제공하지 않습니다.
  - 단어당 실제 예제 수가 줄어들수록(예: 125개), 합성 데이터 추가가 모델 성능에 긍정적인 영향을 미칩니다.
  - 특히 단어당 5~10개의 실제 예제와 같이 데이터가 매우 제한적일 때, 합성 데이터 증강은 최대 3%p의 절대 정확도 향상을 가져옵니다. 합성 데이터로 증강된 헤드 모델은 실제 예제가 0개인 경우(즉, 합성 데이터로만 훈련된 경우)에도 단어당 125개의 실제 예제로 훈련된 풀 모델보다 높은 정확도를 유지했습니다.

## 🧠 Insights & Discussion

- 이 연구의 핵심은 사전 훈련된 **음성 임베딩 모델**의 중요성입니다. 이 임베딩 모델은 원시 오디오 특징으로부터 키워드 스포팅에 유용한 고수준 특징을 추출하여, 헤드 모델이 제한된 실제 데이터나 합성 데이터만으로도 효율적으로 학습할 수 있도록 합니다. 이는 임베딩 없이 훈련된 풀 모델이 유사한 정확도에 도달하기 위해 훨씬 더 많은 데이터가 필요하다는 점에서 명확히 드러납니다.
- **합성 음성 데이터**는 강력한 임베딩 모델과 결합될 때 실제 음성 데이터를 효과적으로 대체하거나 보강할 수 있는 현실적인 대안입니다. 이는 값비싸고 시간 소모적인 실제 데이터 수집의 필요성을 대폭 줄여주며, KWS 모델의 빠른 개발과 맞춤화를 가능하게 합니다.
- 합성 음성에 대한 기존 데이터 증강 기법(피치/템포 시프트 등)의 효과가 미미했던 것은, 임베딩 모델이 이미 대규모의 다양한 실제 데이터(YouTube 오디오)로 훈련되어 이러한 왜곡에 강건하게 학습되었기 때문일 수 있습니다.
- 이 접근 방식은 저전력 온디바이스 KWS 시스템에 특히 유용하며, 클라우드 기반 또는 풀 온디바이스 ASR 시스템에 비해 개인 정보 보호 문제와 연산 비용을 줄이는 데 기여합니다.
- **한계점 및 향후 연구:** 논문에서는 향후 제한된 연산 리소스를 가진 소형 디바이스에서 모델을 효율적으로 훈련하는 방법에 대한 연구 계획을 언급합니다.

## 📌 TL;DR

제한된 실제 음성 데이터로 키워드 스포팅(KWS) 모델을 훈련하는 문제를 해결하기 위해, 사전 훈련된 **음성 임베딩 모델**과 **합성 음성 데이터**를 활용하는 방안을 제안합니다. 이 방식은 실제 데이터 수집의 필요성을 크게 줄이며, 합성 음성만으로 훈련된 헤드 모델이 50개 이상의 실제 예제로 훈련된 헤드 모델 또는 4,000개 이상의 실제 예제로 훈련된 풀 모델과 동등한 92.6%의 정확도를 달성함을 입증합니다. 이는 KWS 모델의 신속한 개발과 맞춤화를 가능하게 하는 효율적인 접근 방식입니다.
