{
  "title": "Enhancing Synthetic Training Data for Speech Commands: From ASR-Based\n  Filtering to Domain Adaptation in SSL Latent Space",
  "authors": "Sebastião Quintas, Isabelle Ferrané, Thomas Pellegrini",
  "year": 2024,
  "url": "http://arxiv.org/abs/2409.12745v1",
  "abstract": "The use of synthetic speech as data augmentation is gaining increasing\npopularity in fields such as automatic speech recognition and speech\nclassification tasks. Despite novel text-to-speech systems with voice cloning\ncapabilities, that allow the usage of a larger amount of voices based on short\naudio segments, it is known that these systems tend to hallucinate and\noftentimes produce bad data that will most likely have a negative impact on the\ndownstream task. In the present work, we conduct a set of experiments around\nzero-shot learning with synthetic speech data for the specific task of speech\ncommands classification. Our results on the Google Speech Commands dataset show\nthat a simple ASR-based filtering method can have a big impact in the quality\nof the generated data, translating to a better performance. Furthermore,\ndespite the good quality of the generated speech data, we also show that\nsynthetic and real speech can still be easily distinguishable when using\nself-supervised (WavLM) features, an aspect further explored with a CycleGAN to\nbridge the gap between the two types of speech material.",
  "citation": 0
}