{
  "title": "Depthwise Separable Convolutional ResNet with Squeeze-and-Excitation\n  Blocks for Small-footprint Keyword Spotting",
  "authors": "Menglong Xu, Xiao-Lei Zhang",
  "year": 2020,
  "url": "http://arxiv.org/abs/2004.12200v2",
  "abstract": "One difficult problem of keyword spotting is how to miniaturize its memory\nfootprint while maintain a high precision. Although convolutional neural\nnetworks have shown to be effective to the small-footprint keyword spotting\nproblem, they still need hundreds of thousands of parameters to achieve good\nperformance. In this paper, we propose an efficient model based on depthwise\nseparable convolution layers and squeeze-and-excitation blocks. Specifically,\nwe replace the standard convolution by the depthwise separable convolution,\nwhich reduces the number of the parameters of the standard convolution without\nsignificant performance degradation. We further improve the performance of the\ndepthwise separable convolution by reweighting the output feature maps of the\nfirst convolution layer with a so-called squeeze-and-excitation block. We\ncompared the proposed method with five representative models on two\nexperimental settings of the Google Speech Commands dataset. Experimental\nresults show that the proposed method achieves the state-of-the-art\nperformance. For example, it achieves a classification error rate of 3.29% with\na number of parameters of 72K in the first experiment, which significantly\noutperforms the comparison methods given a similar model size. It achieves an\nerror rate of 3.97% with a number of parameters of 10K, which is also slightly\nbetter than the state-of-the-art comparison method given a similar model size.",
  "citation": 47
}