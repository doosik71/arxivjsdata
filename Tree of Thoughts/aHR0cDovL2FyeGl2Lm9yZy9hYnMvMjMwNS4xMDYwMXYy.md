# Tree of Thoughts: Deliberate Problem Solving with Large Language Models

Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Thomas L. Griffiths, Yuan Cao, Karthik Narasimhan

## 🧩 Problem to Solve

기존의 대규모 언어 모델(LLM)은 추론 시 토큰 단위의 왼쪽에서 오른쪽으로 진행되는 의사결정 과정에 갇혀 있습니다. 이는 탐색, 전략적 미리 보기(strategic lookahead)가 필요하거나 초기 결정이 중요한 역할을 하는 작업에서 LLM의 성능을 저하시킵니다. 인간 인지의 "이중 처리(dual process)" 모델(빠르고 자동적인 System 1과 느리고 신중한 System 2)에 비추어 볼 때, LLM의 단순한 연관적 토큰 수준 선택은 System 1에 해당하며, 더 신중한 System 2 계획 과정의 보완이 필요합니다.

## ✨ Key Contributions

- **Tree of Thoughts (ToT) 프레임워크 도입**: 널리 사용되는 Chain of Thought (CoT) 접근 방식을 일반화하여, 문제 해결의 중간 단계 역할을 하는 일관된 텍스트 단위("생각")를 탐색할 수 있도록 합니다.
- **신중한 의사결정 능력 강화**: LLM이 여러 추론 경로를 고려하고, 다음 행동을 결정하기 위해 스스로 선택을 평가하며, 필요할 때 미리 보거나 되돌아가서 전역적인 결정을 내릴 수 있도록 합니다.
- **LLM 기반 탐색 휴리스틱 구현**: 이전의 프로그래밍되거나 학습된 탐색 휴리스틱과 달리, LLM 자체의 자기 평가 및 숙고를 통해 탐색 휴리스틱을 구현합니다.
- **탁월한 문제 해결 능력 입증**: Game of 24, 창의적 글쓰기, 미니 십자말풀이와 같이 비자명한 계획 또는 탐색이 필요한 세 가지 새로운 작업에서 LLM의 문제 해결 능력을 크게 향상시켰습니다. 예를 들어, Game of 24에서 GPT-4는 CoT 프롬프트로 4%의 성공률을 보였지만, ToT는 74%를 달성했습니다.

## 📎 Related Works

- **Input-output (IO) 프롬프팅**: LLM을 사용하는 가장 일반적인 방법.
- **Chain-of-thought (CoT) 프롬프팅 [38]**: 입력($x$)과 출력($y$) 사이에 일련의 중간 생각($z_1, \dots, z_n$)을 도입하여 복잡한 문제 해결을 돕습니다.
- **Self-consistency with CoT (CoT-SC) [36]**: $k$개의 독립적인 CoT 체인을 샘플링한 후 가장 빈번한 출력을 선택하는 앙상블 접근 방식입니다.
- **LLM을 활용한 계획 및 의사결정 [12, 42, 37, 13, 35, 41, 40]**: LLM이 문제 설정 및 환경 상태에 따라 합리적인 계획을 제안할 수 있도록 합니다.
- **RAP (Reasoning with Language Model is Planning with World Model) [9]**: ToT와 유사하게 언어 모델 추론을 MCTS 기반의 계획으로 다루는 동시 연구입니다.
- **자기 반성 (Self-reflection) [28, 20, 24, 4, 17]**: LLM이 자신의 생성물을 평가하고 피드백을 제공하여 개선하는 메커니즘입니다. "Self-eval guided decoding" [39]은 LLM 자체 평가를 통해 트리 탐색을 수행합니다.
- **프로그램 기반 LLM 생성 [14, 44, 6, 43]**: LLM의 동작을 체계적인 절차나 상징적 프로그램으로 조직하는 연구입니다.
- **고전적 탐색 방법 (A\*, MCTS) [10, 11, 2]**: 문제 해결을 위한 휴리스틱 탐색 알고리즘을 현대적으로 재해석하여 LLM의 자기 평가를 휴리스틱으로 사용합니다.

## 🛠️ Methodology

ToT는 모든 문제를 트리 탐색으로 간주하며, 각 노드는 입력과 지금까지의 생각 시퀀스($s = [x, z_{1 \dots i}]$)를 나타내는 부분적인 해결책인 '상태'입니다. ToT를 구현하기 위한 네 가지 핵심 질문은 다음과 같습니다:

1. **생각 분해 (Thought decomposition)**:
   - 문제의 특성을 활용하여 중간 생각 단계를 설계합니다.
   - 생각은 LLM이 유망하고 다양한 샘플을 생성할 수 있을 만큼 "작고", 문제 해결 방향으로의 진척도를 평가할 수 있을 만큼 "커야" 합니다.
   - 예시: 십자말풀이에서는 몇 단어, Game of 24에서는 한 줄의 방정식, 창의적 글쓰기에서는 전체 단락의 쓰기 계획.
2. **생각 생성기 $G(p_{\theta}, s, k)$ (Thought generator)**: 주어진 상태 $s$에서 다음 생각 단계에 대한 $k$개의 후보를 생성하는 두 가지 전략을 고려합니다.
   - **(a) CoT 프롬프트에서 독립적으로 샘플링**: 생각 공간이 풍부하고 i.i.d. 샘플이 다양성을 유도할 때(예: 창의적 글쓰기).
   - **(b) "제안 프롬프트"를 사용하여 순차적으로 제안**: 생각 공간이 더 제한적일 때(예: Game of 24, 십자말풀이).
3. **상태 평가기 $V(p_{\theta}, S)$ (State evaluator)**: 검색 알고리즘이 탐색할 상태와 순서를 결정하기 위한 휴리스틱 역할을 합니다. LLM을 사용하여 상태에 대해 신중하게 추론합니다.
   - **(a) 각 상태 개별적으로 평가**: $V(p_{\theta}, S)(s) \sim p_{\text{value}{\theta}}(v|s)$. LLM이 스칼라 값($v$, 예: 1-10) 또는 분류(예: sure/likely/impossible)를 생성합니다. 몇 번의 미리 보기 시뮬레이션이나 상식을 통해 평가가 이루어집니다.
   - **(b) 상태 간 투표**: $V(p_{\theta}, S)(s) = 1[s=s^*]$. LLM이 "투표 프롬프트"를 통해 가장 유망한 상태 $s^* \sim p_{\text{vote}{\theta}}(s^*|S)$에 투표합니다.
4. **탐색 알고리즘 (Search algorithm)**: 트리 구조에 따라 다양한 탐색 알고리즘을 적용할 수 있습니다.
   - **(a) 너비 우선 탐색 (BFS)** (Algorithm 1): 각 단계에서 가장 유망한 $b$개의 상태 집합을 유지합니다. 깊이가 얕은 트리(Game of 24, 창의적 글쓰기)에 사용됩니다.
   - **(b) 깊이 우선 탐색 (DFS)** (Algorithm 2): 가장 유망한 상태를 먼저 탐색하여 최종 출력에 도달하거나, 상태 평가기가 문제 해결이 불가능하다고 판단하면 서브트리를 가지치기하고 부모 상태로 되돌아갑니다. 깊은 탐색 문제(미니 십자말풀이)에 사용됩니다.

## 📊 Results

- **Game of 24**:
  - ToT (너비 $b=5$)는 74%의 성공률을 달성하여, IO(7.3%), CoT(4.0%), CoT-SC(9.0%)를 크게 능가했습니다. ToT (b=1)도 45%의 성공률을 보였습니다.
  - CoT는 60%의 샘플에서 첫 번째 단계부터 실패하는 경우가 많아, 기존 좌-우 디코딩의 한계를 드러냈습니다.
- **창의적 글쓰기**:
  - ToT는 GPT-4의 일관성 점수에서 평균 7.56점을 기록하여, IO(6.19점)와 CoT(6.93점)보다 높은 점수를 받았습니다.
  - 인간 평가에서도 ToT가 CoT보다 41%의 경우에서 선호되었고, CoT가 선호된 경우는 21%에 불과했습니다 (38%는 유사).
- **미니 십자말풀이 (5x5)**:
  - ToT는 단어 수준에서 60%의 성공률을 달성하고 20개 게임 중 4개를 해결하여, IO 및 CoT의 16% 미만의 성공률과 비교하여 훨씬 우수했습니다.
  - 최적의 DFS 상태를 선택하는 Oracle 설정에서는 7/20 게임을 해결하여, 휴리스틱 개선의 여지를 보여주었습니다.
  - 가지치기 및 백트래킹의 중요성을 확인하는 실험에서, 가지치기 없는 탐색(-prune)은 성능이 저하되었으며, 백트래킹 없는 탐색(-backtrack)은 단어 성공률이 20%에 그쳤습니다.

## 🧠 Insights & Discussion

- **의미**: ToT는 LLM의 연관적 "System 1"을 문제 해결 경로를 탐색하는 "System 2" 기반의 신중한 과정으로 성공적으로 보완했습니다.
  - **일반성**: IO, CoT, CoT-SC는 ToT의 특수한 경우로 볼 수 있습니다.
  - **모듈성**: 기반 LLM, 생각 분해, 생성, 평가, 탐색 절차를 모두 독립적으로 변경할 수 있습니다.
  - **적응성**: 다양한 문제 특성, LLM 기능 및 리소스 제약을 수용할 수 있습니다.
  - **편의성**: 추가 학습 없이 미리 학습된 LLM만으로 충분합니다.
  - **해석 가능성**: 결과적으로 생성되는 고수준의 언어 추론은 모델 결정의 해석 가능성을 높입니다.
- **한계**:
  - GPT-4가 이미 뛰어난 많은 기존 작업에는 ToT가 불필요할 수 있습니다.
  - 샘플링 방법보다 더 많은 리소스(예: GPT-4 API 비용)가 필요합니다.
  - 가지치기 휴리스틱이 완벽하지 않아 일부 상황에서 최적의 해를 놓칠 수 있습니다.
- **미래 방향**:
  - 코딩, 데이터 분석, 로봇 공학 등 실제 세계의 의사결정 애플리케이션에 LLM을 적용할 때 더 복잡한 작업에서 ToT의 활용 가능성이 있습니다.
  - 성능-비용 트레이드오프를 사용자 지정하고 효율성을 개선할 여지가 많습니다 (예: 빔 크기 조정, 조기 종료).
  - ToT 스타일의 고수준 반사실적 의사결정을 사용하여 LLM을 미세 조정하면 문제 해결 능력을 더욱 향상시킬 수 있습니다.
  - 외부 지식 검색 또는 웹 상호작용과 통합하여 지식 불확실성 하에서의 문제 해결 능력을 보강할 수 있습니다.

## 📌 TL;DR

LLM의 토큰 단위, 순차적 추론의 한계를 극복하기 위해, 본 논문은 Chain of Thought를 확장한 **Tree of Thoughts (ToT)** 프레임워크를 제안합니다. ToT는 LLM이 **'생각' 단위로 여러 추론 경로를 탐색**하고, **자체 평가를 통해 신중하게 의사결정**하며, **미리 보기 및 백트래킹**을 수행하도록 합니다. Game of 24 (4% $\rightarrow$ 74%), 창의적 글쓰기, 미니 십자말풀이와 같은 복잡한 문제 해결 작업에서 **GPT-4의 성능을 획기적으로 향상**시켰습니다. ToT는 LLM의 "System 1" 연관적 추론에 "System 2" 계획 능력을 부여하여 범용 문제 해결 능력을 강화합니다.
