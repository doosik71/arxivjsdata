# A neural attention model for speech command recognition

Douglas Coimbra de Andrade, Sabato Leo, Martin Loesener Da Silva Viana, Christoph Bernkopf

## 🧩 Problem to Solve

이 논문은 클라우드 기반의 대규모 음성 인식 시스템 대신, 휴대 기기나 마이크로컨트롤러와 같은 자원 제약적인 환경에서 로컬로 실행될 수 있는 가볍고 정확한 음성 명령어 인식 모델의 필요성을 다룹니다. 기존 시스템은 간단한 명령어조차도 복잡한 클라우드 처리를 거쳐야 하므로, 인터넷 연결이 불안정하거나 지연 시간에 민감한 애플리케이션에는 적합하지 않습니다.

## ✨ Key Contributions

- 음성 명령어 인식 및 언어 식별에서 최첨단 성능을 달성하면서도 로컬에서 실행하기에 충분히 작은 크기를 유지하는 새로운 어텐션 기반 순환 네트워크 아키텍처를 설계했습니다.
- 어텐션 가중치를 시각화하여 어텐션 메커니즘이 정확도를 향상시키고 음성 인식 모델을 설명 가능하게 만드는 방식을 보여주었습니다.
- 추가 연구를 가능하게 하는 오픈 소스 코드 (제출 후 공개 예정)를 제공합니다.

## 📎 Related Works

- **키워드 스팟팅(KWS):** 오디오 데이터베이스 색인화 및 마이크로컨트롤러에서의 로컬 음성 모델 실행과 같은 광범위한 엔지니어링 응용 분야에서 중요합니다.
- **신경망 어텐션 모델:** Bahdanau et al.(2014)과 Vaswani et al.(2017)의 연구를 통해 긴 시퀀스-투-시퀀스 모델에서 성능이 향상되었으며, Xu et al.(2015)의 이미지 캡션 작업에서 볼 수 있듯이 입력의 어떤 부분이 예측에 사용되는지 이해하는 데 강력합니다.
- **기존 명령어 인식 연구:** 심층 잔차 네트워크(Tang & Lin, Arik et al., Sainath & Parada) 및 제한된 크기 아키텍처(Zhang et al.)를 사용한 연구가 진행되었습니다. 이 논문은 단일 단어 인식에서 어텐션의 적용을 심층적으로 탐구합니다.
- **해석 가능성:** 어텐션 메커니즘은 심층 학습의 "블랙박스 문제"를 부분적으로 해결하여 모델이 결과를 어떻게 도출하는지 설명 가능하게 만듭니다(Lei et al., 2018).

## 🛠️ Methodology

제안된 모델은 Keras 프레임워크와 TensorFlow 백엔드를 기반으로 구현되었습니다. `kapre` 라이브러리를 사용하여 GPU 상에서 멜 스케일 스펙트로그램을 효율적으로 계산합니다.

1. **입력 처리:** 원본 WAV 오디오 파일(약 $16\text{kHz}$ 샘플링 레이트)을 모델의 입력으로 직접 사용합니다.
2. **멜 스케일 스펙트로그램 계산:** 비학습 가능한 `kapre` 레이어를 사용하여 $80$개 밴드의 멜 스케일 스펙트로그램을 계산합니다. 이를 위해 $1024$개의 이산 푸리에 변환 포인트와 $128$개의 홉 사이즈를 사용합니다.
3. **컨볼루션 레이어:** 멜 스펙트로그램(2D 출력)에 컨볼루션을 적용하여 오디오 파일의 시간 차원에서 지역적 관계를 추출합니다.
4. **양방향 LSTM (Bi-LSTM) 레이어:** 두 개의 스택형 양방향 LSTM 유닛을 사용하여 오디오 파일에서 양방향(순방향 및 역방향)의 장기적인 의존성을 포착합니다.
5. **어텐션 메커니즘:**
   - 마지막 LSTM 레이어의 출력 벡터 중 하나(중간 벡터)를 쿼리 벡터로 추출하고, 이를 댄스 레이어를 사용하여 투영합니다.
   - 이 쿼리 벡터는 LSTM 출력의 가중 평균을 계산하는 데 사용되어, 오디오에서 가장 관련성이 높은 부분을 식별합니다.
6. **분류:** 어텐션 메커니즘을 통해 가중치가 부여된 LSTM 출력은 세 개의 완전 연결(Dense) 레이어를 거쳐 최종 분류를 수행하며, 마지막 레이어는 소프트맥스 활성화 함수를 사용합니다.
7. **훈련:** 최대 $40$ 에포크 동안 훈련하며, $10$ 에포크 동안 검증 세트에서 개선이 없으면 조기 종료합니다. Adam 옵티마이저를 사용했으며, 초기 학습률은 $0.001$, $10$ 에포크마다 $0.4$로 감소시키고, 배치 크기는 $64$로 설정했습니다.

## 📊 Results

제안된 어텐션 RNN 모델은 Google Speech Commands Dataset V1 및 V2의 다양한 명령어 인식 태스크에서 새로운 최첨단 성능을 달성했습니다.

- **Google Speech Commands V1:**
  - $20$ 명령어 인식: $94.1\%$
  - $12$ 명령어 인식: $95.6\%$
  - $35$ 단어 인식: $93.9\%$
  - "left-right" 인식: $99.2\%$
- **Google Speech Commands V2:**
  - $20$ 명령어 인식: $94.5\%$ (Warden (2018)의 기준선 $88.2\%$를 크게 상회)
  - $12$ 명령어 인식: $96.9\%$
  - $35$ 단어 인식: $93.9\%$
  - "left-right" 인식: $99.4\%$
- **모델 크기:** 훈련 가능한 파라미터가 $202\text{K}$개에 불과하여 매우 작은 메모리 공간을 차지합니다.
- **어텐션 시각화:** 어텐션 플롯은 모델이 음성 분류 시 모음 전환과 같이 음성에서 중요한 정보를 포함하는 영역에 집중한다는 직관과 일치함을 보여줍니다.
- **혼동 행렬:** "three"와 "tree", "no"와 "down"처럼 음성적으로 유사한 단어 쌍에서 혼동이 발생할 수 있음을 보여주며, 이는 문맥 정보가 필요함을 시사합니다.

## 🧠 Insights & Discussion

- **해석 가능성 및 통찰력:** 어텐션 메커니즘은 딥러닝 모델의 "블랙박스" 특성을 완화하여, 모델이 특정 범주를 선택하기 위해 오디오의 어떤 부분(주로 모음 전환 영역)을 고려했는지 설명할 수 있게 합니다. 이는 엔지니어링 애플리케이션에서 매우 바람직한 특징입니다.
- **모델의 강점:** 매우 작은 모델 크기에도 불구하고 여러 KWS(키워드 스팟팅) 태스크에서 최첨단 정확도를 달성하여, 자원 제약적인 환경에서의 로컬 실행 가능성을 입증했습니다.
- **한계점 및 개선 방향:**
  - 외부 데이터셋의 노이즈를 포함한 오디오 샘플 증강의 효과는 탐구되지 않았습니다. 이는 모델 정확도를 더욱 높일 수 있는 잠재적인 방법입니다.
  - "three"와 "tree", "no"와 "down"과 같은 음성적으로 유사한 단어 쌍은 모델이 혼동하기 쉬우며, 이를 해결하기 위해서는 문장 내의 추가적인 문맥 정보가 필요합니다. 이는 설계 단계에서 명령어 선택 시 고려되어야 할 부분입니다.
  - 향후 연구에서는 데이터 증강, 사전 학습된 모델 활용, 더 복잡한 명령어를 위한 단어 쌍 스태킹(sequence-to-sequence 모델 또는 다중 어텐션 레이어), 자동 언어 식별, 오디오로부터 음성 병리 감지 등에 대한 추가 조사가 이루어질 수 있습니다.

## 📌 TL;DR

- **문제:** 인터넷 연결 없이 로컬에서 실행 가능한 가볍고 정확한 음성 명령어 인식 모델이 필요합니다.
- **제안 방법:** 원본 WAV 파일을 입력으로 받아 멜 스펙트로그램을 생성하고, 컨볼루션 레이어와 양방향 LSTM을 통해 시간적 특징 및 장기 의존성을 추출한 후, 어텐션 메커니즘을 사용하여 분류에 가장 중요한 오디오 영역을 식별하는 새로운 어텐션 기반 순환 신경망 아키텍처를 제안합니다.
- **주요 결과:** Google Speech Commands V1 및 V2 데이터셋에서 (예: V2 20-명령어 태스크에서 $94.5\%$ 정확도) 새로운 최첨단 성능을 달성했으며, $202\text{K}$개의 적은 파라미터로도 효율성을 입증했습니다. 또한 어텐션 메커니즘을 통해 모델의 해석 가능성을 높여, 중요한 음성 구간(특히 모음 전환)에 모델이 집중하는 것을 시각적으로 보여줍니다.
