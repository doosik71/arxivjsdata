{
  "title": "Risk-Sensitive Generative Adversarial Imitation Learning",
  "authors": "Jonathan Lacotte, Mohammad Ghavamzadeh, Yinlam Chow, Marco Pavone",
  "year": 2018,
  "url": "http://arxiv.org/abs/1808.04468v2",
  "abstract": "We study risk-sensitive imitation learning where the agent's goal is to perform at least as well as the expert in terms of a risk profile. We first formulate our risk-sensitive imitation learning setting. We consider the generative adversarial approach to imitation learning (GAIL) and derive an optimization problem for our formulation, which we call it risk-sensitive GAIL (RS-GAIL). We then derive two different versions of our RS-GAIL optimization problem that aim at matching the risk profiles of the agent and the expert w.r.t. Jensen-Shannon (JS) divergence and Wasserstein distance, and develop risk-sensitive generative adversarial imitation learning algorithms based on these optimization problems. We evaluate the performance of our algorithms and compare them with GAIL and the risk-averse imitation learning (RAIL) algorithms in two MuJoCo and two OpenAI classical control tasks.",
  "citation": 46
}