# Generalization Guarantees for Imitation Learning

Allen Z. Ren, Sushant Veer, and Anirudha Majumdar

## 🧩 Problem to Solve

모방 학습(Imitation Learning)으로 학습된 제어 정책은 불완전한 데모나 전문가의 정책을 정확히 추론하지 못하는 문제로 인해 새로운 환경에 대한 일반화에 종종 실패합니다. 본 연구는 로봇 시스템이 풍부한 감각 입력(예: RGB-D 이미지), 복잡한 동역학, 신경망 기반 정책 아키텍처를 가질 때, 이러한 모방 학습 정책의 새로운 환경에 대한 엄격한 일반화 보장을 제공하는 것이 목표입니다.

## ✨ Key Contributions

- **PAC-Bayes 기반의 엄격한 일반화 보장:** PAC-Bayes 이론을 활용하여 모방 학습 정책의 새로운 환경에서의 예상 비용에 대한 상한을 제공합니다. 이는 로봇 시스템에서 모방 학습 정책에 대한 일반화 보장을 제공하는 최초의 시도입니다.
- **두 단계 학습 파이프라인 제안:**
  1. **사전 정책 분포 학습 (Prior Policy Distribution Learning):** 조건부 변분 오토인코더(Conditional Variational Autoencoder, cVAE)를 사용하여 다중 모드 전문가 행동을 내재화한 "사전(prior)" 정책 분포($P_0$)를 학습합니다.
  2. **일반화 경계 최적화를 통한 미세 조정 (Fine-tuning for Generalization):** PAC-Bayes 일반화 경계를 명시적으로 최적화하여 사전 분포를 "미세 조정(fine-tune)"함으로써 "사후(posterior)" 정책 분포($P$)를 도출합니다.
- **강력한 일반화 경계 및 실제 성능과의 일치성 입증:** 다양한 컵 잡기, 시각 피드백 기반 평면 푸싱, 시각 기반 실내 내비게이션 등 세 가지 로봇 작업 시뮬레이션에서 강력하고 실제 성능과 밀접하게 일치하는 일반화 경계를 입증했습니다.
- **하드웨어 제로샷 일반화:** 조작(manipulation) 작업에 대한 하드웨어 실험을 통해 시뮬레이션에서 학습된 정책이 추가 훈련 없이 실제 로봇에 성공적으로 일반화됨을 보여주었습니다.
- **다중 모드 사전 분포의 이점 확인:** 단일 모드 사전 분포에 비해 다중 모드 사전 분포가 PAC-Bayes 훈련을 가속화하고 사후 정책의 성능을 향상시키는 데 기여함을 밝혔습니다.

## 📎 Related Works

- **다중 모드 모방 학습 (Multi-modal Imitation Learning):** 전문가 데이터의 다중 모드 특성을 포착하기 위해 잠재 변수 모델을 사용하는 연구들(예: [17, 18, 19, 20, 10])이 있었으나, 본 연구는 이를 사전 정책 분포에 통합하여 미세 조정을 가속화하고 더 나은 일반화 경계를 얻는 데 활용합니다.
- **불완전한 데모로부터의 학습 (Learning from Imperfect Demonstrations):** 불완전한 데모나 예측 불가능한 상태에서 발생하는 오류를 완화하기 위해 모방 학습된 정책을 미세 조정하거나(예: [21, 23]), 노이즈 주입(예: [24, 13]), 하이브리드 보상 사용(예: [2]) 등의 방법이 연구되었지만, 엄격한 일반화 보장을 제공하지 못했습니다.
- **학습 기반 제어를 위한 일반화 보장 (Generalization Guarantees for Learning-based Control):** PAC-Bayes Control 프레임워크(예: [26, 27, 28])는 학습 기반 제어에 대한 안전 및 일반화 보장을 제공하지만, 본 연구는 이 프레임워크를 모방 학습 정책에 적용하여, 다중 모드 전문가 데모를 활용해 기존 연구([27, 28])보다 훨씬 강력한 일반화 보장을 얻습니다.

## 🛠️ Methodology

본 연구의 훈련 파이프라인은 두 단계로 구성됩니다.

1. **다중 모드 행동 복제(Multi-Modal Behavioral Cloning)를 통한 사전 분포 $P_0$ 학습:**

   - **cVAE 활용:** 전문가 데모 $\left\{\zeta_i\right\}_{i=1}^M$를 사용하여 조건부 변분 오토인코더(cVAE)를 훈련합니다. cVAE는 잠재 변수 $z$에 다중 모드 전문가 행동을 임베딩합니다.
   - **인코더 및 디코더:**
     - 인코더 $q_\phi(z|o, a)$는 신경망 가중치 $\phi$로 매개변수화되며, 각 데모 $\zeta_i = \{(o_t, a_t)\}_{t=1}^T$로부터 잠재 변수 $z$를 샘플링합니다.
     - 디코더 $\pi_{\theta, z}: O \to A$는 신경망 가중치 $\theta$와 샘플링된 잠재 변수 $z$로 매개변수화되며, 각 단계에서 관측 $o$로부터 행동 $a$를 재구성합니다.
   - **손실 함수:** 재구성 손실 $L_{\text{rec}}(\pi_{\theta,z}(o_t), a_t)$와 KL 정규화 손실 $D_{\text{KL}}(q_\phi(z|o_{1:T}, a_{1:T})||p(z))$의 조합을 최적화합니다. 여기서 $p(z)$는 다변수 단위 가우시안 분포 $N(0,I)$입니다.
   - **결과:** 잠재 분포 $p(z) = N(0,I)$와 디코더 네트워크의 최적화된 가중치 $\theta^*$를 얻습니다. $p(z)$는 정책 공간 $\Pi = \{\pi_{\theta^*, z}: O \to A | z \in \mathbb{R}^{n_z}\}$에 대한 사전 분포 $P_0$로 간주됩니다.

2. **PAC-Bayes 일반화 경계 최적화를 통한 사후 분포 $P$ 미세 조정:**
   - **PAC-Bayes 이론 적용:** PAC-Bayes 제어 프레임워크를 활용하여 새로운 훈련 환경 세트 $S = \{E_1, ..., E_N\}$에서 사전 정책 분포 $P_0$를 미세 조정하여 사후 정책 분포 $P$를 얻습니다.
   - **일반화 경계 $C_{\text{PAC}}$:** 실제 예상 비용 $C_D(P)$의 상한인 $C_{\text{PAC}}(P, P_0)$를 최소화합니다.
     $$C_D(P) \le C_{\text{PAC}}(P, P_0) := C_S(P) + \sqrt{\frac{\text{KL}(P\|P_0) + \log\left(\frac{2\sqrt{N}}{\delta}\right)}{2N}}$$
     여기서 $C_S(P)$는 훈련 환경에서의 경험적 비용이며, $\text{KL}(P\|P_0)$는 사후 분포 $P$와 사전 분포 $P_0$ 간의 KL 발산입니다.
   - **최적화 방법:** 경험적 비용 $C_S(P)$의 그래디언트가 분석적으로 계산될 수 없으므로, Natural Evolutionary Strategies (NES) [31]와 같은 블랙박스 최적화 기법을 사용합니다.
     - NES는 Monte-Carlo 방법을 통해 손실 함수의 그래디언트를 추정하고, 이를 자연 그래디언트로 변환하여 훈련을 가속화합니다.
     - 훈련 중, 각 환경 $E_j$에 대해 사후 분포 $N_\psi$에서 정책 $z$를 샘플링하고 롤아웃을 수행하여 비용 $C(\pi_{\theta^*,z}; E)$를 계산합니다. 이 비용은 그래디언트 추정에 사용됩니다.
   - **최종 경계 계산:** ES 훈련 후, 최적의 $\psi^*$를 사용하여 경험적 훈련 비용 $\hat{C}_S(N_{\psi^*})$, 샘플 수렴 경계 $\bar{C}_S(N_{\psi^*}; L, \delta')$, 그리고 최종 일반화 경계 $C_{\text{bound}}(N_{\psi^*})$를 계산합니다. $C_{\text{bound}}(N_{\psi^*})$는 $1-\delta-\delta'$ 확률로 $C_D(N_{\psi^*}) \le C_{\text{bound}}(N_{\psi^*})$를 만족합니다.

## 📊 Results

본 연구는 세 가지 로봇 작업을 통해 접근 방식의 효과를 입증했습니다.

1. **다양한 컵 잡기 (Grasping Diverse Mugs):**

   - **사전 성능:** 새로운 시뮬레이션 환경에서 83.3%의 성공률. 다양한 그립(grasp) 포즈를 생성하는 다중 모드 동작 포착.
   - **사후 성능 및 일반화 경계:** $N=500$개의 훈련 환경으로 미세 조정한 결과, PAC-Bayes 경계 $C^*_{\text{bound}} = 0.070$ (93.0% 성공률 보장). 시뮬레이션 테스트 환경에서는 98.4%의 성공률을 달성하여 경계의 타이트함(tightness)을 보여주었습니다.
   - **하드웨어 결과:** 제로샷(zero-shot) 방식으로 실제 로봇에 배포하여 100%, 100%, 96%의 높은 성공률을 기록, 시뮬레이션에서 훈련된 PAC-Bayes 경계를 검증.

2. **실시간 시각 피드백을 이용한 평면 박스 푸싱 (Planar Box Pushing with Real-time Visual Feedback):**

   - **사전 성능:** "Easy" 작업에서 84.2%, "Hard" 작업에서 74.9%의 성공률.
   - **사후 성능 및 일반화 경계:** $N=500, 1000, 2000$개의 훈련 환경 사용. 사후 정책의 성능은 사전 정책에 비해 약 10% 향상되었습니다. "Hard" 작업에서 로봇이 일관되게 상자의 모서리를 미는 동작을 학습하는 등 도전적인 작업을 더 잘 수행합니다.
     - **예시 (N=1000):** "Easy" 작업 보장 88.8% (실제 93.7%), "Hard" 작업 보장 79.1% (실제 86.4%).
   - **하드웨어 결과:** "Easy" 작업에서 80.0%, 86.7%, 93.3%, "Hard" 작업에서 80.0%, 80.0%, 80.0%의 성공률을 보여, 시뮬레이션 대비 약간의 성능 저하가 있었으나 여전히 좋은 결과를 보였습니다.

3. **시각 기반 실내 내비게이션 (Vision-based Indoor Navigation):**
   - **사전 성능:** 새로운 시뮬레이션 환경에서 65.4%의 성공률을 달성, 훈련된 cVAE가 다양한 궤적을 생성함을 보여주었습니다.
   - **사후 성능 및 일반화 경계:** $N=500, 1000$개의 훈련 환경으로 미세 조정한 결과, 성능이 향상되었습니다.
     - **예시 (N=1000):** PAC-Bayes 경계 74.1% (실제 79.9% 성공률).
   - **다중 모드 사전 분포의 이점:** 단일 모드 사전 분포에 비해 다중 모드 사전 분포가 PAC-Bayes 훈련을 더 빠르게 진행시키고 더 나은 사후 성능(0.799 vs 0.706 성공률)을 달성했습니다.

## 🧠 Insights & Discussion

- **PAC-Bayes의 효과적인 활용:** 본 연구는 PAC-Bayes 이론이 모방 학습 정책의 새로운 환경에 대한 일반화 성능을 엄격하게 보장하는 데 강력한 도구임을 입증했습니다. 이는 이전 연구에서 종종 부족했던 부분입니다.
- **실험적 검증:** 시뮬레이션과 실제 하드웨어 모두에서 제안된 방법론의 효과와 일반화 경계의 타이트함을 성공적으로 보여주었습니다. 특히, 조작 작업에서의 제로샷 하드웨어 일반화는 이 접근 방식의 실용적 잠재력을 강조합니다.
- **다중 모드 행동의 중요성:** cVAE를 통해 다중 모드 전문가 행동을 사전 분포에 내재화하는 것이 PAC-Bayes 미세 조정을 가속화하고 더 나은 일반화 성능을 달성하는 데 중요함을 밝혔습니다. 이는 정책이 다양한 선택지를 탐색하고 새로운 환경에 더 잘 적응하도록 돕습니다.
- **한계 및 향후 연구:**
  - **cVAE 훈련의 어려움:** cVAE 훈련이 상당한 튜닝을 요구하며, 고차원 이미지를 입력으로 하는 긴 시퀀스를 임베딩하는 것이 어려울 수 있습니다. 이는 프레임워크가 장기적인(long-horizon) 작업을 처리하는 데 한계로 작용합니다.
  - **장기적인 작업 처리:** 물 붓기처럼 여러 단계로 구성된 복잡한 작업에는 개별 단계에 대한 별도의 잠재 분포 학습이 필요할 수 있습니다.
  - **데이터 증강과의 결합:** DAgger(Dataset Aggregation) 알고리즘과 같이 추가 전문가 지식을 지속적으로 주입하는 방법과 PAC-Bayes 프레임워크를 결합하는 것이 흥미로운 향후 연구 방향이 될 수 있습니다.
- **sim2real 갭:** 푸싱 작업의 하드웨어 결과에서 일부 "Easy" 작업이 경계에 미치지 못하는 경우가 있었는데, 이는 실제 카메라의 불완전한 깊이 이미지와 시뮬레이션-실제 동역학의 미묘한 차이 때문일 수 있습니다.

## 📌 TL;DR

이 논문은 모방 학습 정책의 새로운 환경에 대한 일반화 실패 문제를 해결하기 위해 **PAC-Bayes 이론** 기반의 **엄격한 일반화 보장** 프레임워크를 제안합니다. 방법론은 **다중 모드 행동 복제**를 통해 **사전 정책 분포($P_0$)**를 학습한 후, **PAC-Bayes 일반화 경계를 명시적으로 최적화**하여 **사후 정책 분포($P$)**를 **미세 조정**하는 두 단계로 구성됩니다. 결과적으로, 컵 잡기, 평면 푸싱, 실내 내비게이션 작업 시뮬레이션에서 **강력하고 타이트한 일반화 경계**를 달성했으며, 조작 작업의 **하드웨어 제로샷 일반화**를 통해 실제 적용 가능성을 입증했습니다. 특히, 다중 모드 사전 분포가 훈련 가속화와 성능 향상에 기여함을 보여주었습니다.
