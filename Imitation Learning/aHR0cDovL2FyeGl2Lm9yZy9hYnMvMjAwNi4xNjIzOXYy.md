# An Imitation Learning Approach for Cache Replacement

Evan Zheran Liu, Milad Hashemi, Kevin Swersky, Parthasarathy Ranganathan, Junwhan Ahn

## 🧩 Problem to Solve

캐시 적중률은 프로그램 실행 속도에 결정적인 영향을 미치지만, 캐시 교체(새로운 라인을 삽입할 때 어떤 캐시 라인을 내보낼지 결정하는 것)는 미래의 접근 패턴을 예측해야 하므로 매우 어려운 문제입니다. 기존의 캐시 교체 정책들은 특정 일반적인 접근 패턴에 맞춰진 휴리스틱에 의존하여 다양한 복잡한 접근 패턴에서는 성능이 저하되는 한계가 있었습니다. 이론적으로 최적의 교체 결정을 내리는 Belady's 정책은 미래 접근을 알아야 하므로 실제 적용이 불가능합니다.

## ✨ Key Contributions

- 캐시 교체 문제를 모방 학습(Imitation Learning, IL) 문제로 재정의하고, 미래 접근을 아는 오라클 정책인 Belady's를 새로운 방식으로 활용하여 과거 접근 이력만으로 최적의 정책을 근사하는 **PARROT**을 제안했습니다.
- 종단 간(end-to-end) 캐시 교체를 위한 신경망 아키텍처와 성능 향상을 위한 여러 지도 학습 태스크(순위 손실, 재사용 거리 예측)를 개발했습니다.
- PARROT은 13개의 메모리 집약적인 SPEC CPU 벤치마크에서 기존 최고 성능 정책 대비 캐시 미스율을 평균 20% 감소시켰습니다. 또한 대규모 웹 검색 벤치마크에서는 LRU 정책 대비 캐시 적중률을 61% 향상시켰습니다.
- 동적으로 변하는 행동 공간, 지연된 보상, 실질적인 영향력 등 흥미로운 도전 과제를 가진 캐시 교체 문제를 새로운 IL/RL 벤치마크로 제시하고, 관련 Gym 환경을 공개했습니다.

## 📎 Related Works

- **LRU (Least Recently Used)**: 가장 오랫동안 사용되지 않은 캐시 라인을 교체하는 대표적인 휴리스틱 기반 정책.
- **RRIP (Re-Reference Interval Prediction)**: 재참조 간격 예측을 사용하여 캐시 교체를 수행하는 정책.
- **Hawkeye (Jain & Lin, 2016) 및 Glider (Shi et al., 2019)**: Belady's 정책으로부터 학습을 시도한 초기 작업들. 캐시 라인이 곧 재사용될지 여부를 이진 분류기로 예측하지만, 최종 교체 결정에는 여전히 전통적인 휴리스틱에 의존하여 정책의 표현력을 제한했습니다.
- **Wang et al. (2019)**: 캐시 교체를 마르코프 결정 과정(MDP)으로 정의하고 강화 학습(RL)을 적용했으나 PARROT 대비 낮은 성능을 보였습니다.
- **DAgger (Ross et al., 2011)**: 모방 학습에서 합성 오류(compounding errors)를 방지하기 위해 전문가 정책과 현재 학습된 정책을 번갈아 사용하여 훈련 데이터를 수집하는 알고리즘.
- **Transformer (Vaswani et al., 2017) 및 BiDAF (Seo et al., 2016)**: PARROT의 신경망 아키텍처에 영감을 준 모델들.

## 🛠️ Methodology

PARROT은 캐시 교체 문제를 에피소드 마르코프 결정 과정(MDP)으로 정의하고 모방 학습을 통해 Belady's 정책을 근사합니다.

1. **모델 아키텍처**:
   - 현재 캐시 접근($m_t$, $pc_t$)을 임베딩하고 LSTM에 통과시켜 셀 상태 $c_t$와 은닉 상태 $h_t$를 얻습니다.
   - 과거 $H$개의 은닉 상태 $[h_{t-H+1}, ..., h_t]$를 캐시 접근 이력 및 현재 접근 임베딩으로 사용합니다.
   - 각 캐시 라인 $l_w$에 대해 임베딩 $e(l_w)$를 쿼리로 사용하고, 과거 $H$개 은닉 상태를 키로 사용하여 어텐션 메커니즘을 통해 컨텍스트 $g_w$를 생성합니다.
   - 최종 Dense 레이어와 Softmax를 $g_w$에 적용하여 교체 정책 $\pi_{\theta}(a_t=w|s_t)$를 얻고, 가장 높은 확률을 가진 라인을 퇴출합니다.
2. **훈련 알고리즘 (DAgger 활용)**:
   - DAgger(Dataset Aggregation) 알고리즘을 사용하여 합성 오류를 방지합니다. 훈련 중에는 현재 학습된 정책 $\pi_{\theta}$를 따라 상태 B를 수집하고, 주기적으로 정책을 업데이트하며 B를 재수집합니다.
   - Belady's 정책이 미래 접근이 알려져 있으면 훈련 중 어떤 상태에서도 쿼리될 수 있다는 점을 활용합니다.
3. **순위 손실 (Ranking Loss)**:
   - 단순 로그 우도(Log-Likelihood, LL) 손실 대신, 재사용 거리를 관련성 지표로 사용하는 NDCG(Normalized Discounted Cumulative Gain)의 미분 가능한 근사치를 손실 함수 $L_{rank}^{\theta}(s_t, \pi^*)$로 사용합니다. 이는 재사용 거리가 짧은 라인을 퇴출하는 것에 더 큰 페널티를 부여하여 캐시 적중률 최적화에 기여합니다.
4. **재사용 거리 예측 (Auxiliary Task)**:
   - 각 캐시 라인의 로그 재사용 거리를 예측하는 보조 태스크를 추가합니다. 모델의 네트워크는 이 예측 헤드와 정책 헤드를 공유하며, 재사용 거리 예측 학습은 네트워크의 표현 학습을 돕습니다. 최종 손실은 $L_{\theta} = L_{rank}^{\theta} + L_{reuse}^{\theta}$입니다.
5. **실용성 개선 (바이트 임베더)**:
   - 모델 크기 감소를 위해 각 PC 및 메모리 주소에 대해 고유한 임베딩을 학습하는 대신, 모든 메모리 주소에서 공유되는 바이트 임베더를 제안합니다. 이는 각 바이트를 개별적으로 임베딩한 후 연결하여 선형 레이어를 통과시키는 방식입니다.

## 📊 Results

- **캐시 적중률 개선**: PARROT (전체 모델)은 SPEC CPU2006 벤치마크에서 LRU 대비 평균 16% 높은 캐시 적중률을 달성했으며, 웹 검색 벤치마크에서는 LRU 대비 13.5% 높은 캐시 적중률(정규화된 캐시 적중률 61%p)을 보였습니다.
- **SOTA 대비 성능**: PARROT은 기존 최고 성능 정책인 Glider를 13개 SPEC2006 프로그램 중 10개에서 능가하며, 평균 20%p 더 높은 정규화된 캐시 적중률을 기록했습니다.
- **모델 크기**: PARROT(바이트 임베더)는 Glider 대비 여전히 평균 8%p 높은 정규화된 캐시 적중률을 달성하며, 모델 크기가 훨씬 작아 실용성이 높습니다.
- **일반화 능력**: PARROT은 훈련 데이터에서 볼 수 없었던 새로운 코드 경로, 메모리 주소(mcf에서 21.6%, 웹 검색에서 5.3%의 새로운 주소) 및 PC에 대해서도 높은 캐시 적중률을 유지하며 우수한 일반화 능력을 보였습니다.
- **어블레이션 연구**:
  - **재사용 거리 예측**: 보조 태스크로 재사용 거리 예측을 포함하는 것이 캐시 적중률을 크게 향상시켰습니다. 간접적으로 보조 손실로 활용하는 것이 직접 예측 결과로 교체 라인을 결정하는 것보다 더 효과적이었습니다.
  - **DAgger**: 온-정책(on-policy) 훈련(DAgger)은 오프-정책(off-policy) 훈련 대비 평균 9.8%p 높은 정규화된 캐시 적중률 개선을 가져왔습니다.
  - **순위 손실**: 로그 우도 손실 대비 순위 손실을 사용하는 것이 캐시 적중률을 3.5%p 향상시켰습니다.
- **이력 길이**: PARROT은 과거 80개 접근까지 이력 길이가 길어질수록 성능이 향상되었으며, 그 이후에는 포화 상태에 도달했습니다. 이는 Glider(약 30개 접근에서 포화)보다 더 많은 과거 정보를 효과적으로 활용함을 시사합니다.

## 🧠 Insights & Discussion

- 이 연구는 모방 학습을 통해 종단 간 캐시 교체 정책을 학습하는 새로운 기반을 마련했으며, Belady's 최적 정책과의 성능 격차를 크게 줄였습니다.
- PARROT은 CPU 캐시뿐만 아니라 소프트웨어 캐시, 데이터베이스, 운영 체제 등 다른 캐시 구조에도 적용 가능하며, 특히 소프트웨어 캐시는 더 높은 정책 지연 시간을 허용하므로 유망한 적용 분야입니다.
- **제한 사항 및 향후 연구**:
  - **실용성**: 학습된 정책을 실제 시스템에 배포할 때 발생하는 모델 크기 및 지연 시간 오버헤드를 줄이기 위한 증류(distillation), 가지치기(pruning), 양자화(quantization)와 같은 기술 연구가 필요합니다.
  - **계층적 캐시 교체**: 다단계 캐시 구조(CPU 및 웹 서비스에서 일반적)를 위한 최적의 정책은 아직 알려져 있지 않으며, 이는 심층 학습 및 강화 학습 연구의 유망한 영역입니다.
  - **지연 시간 최소화**: 현재 목표는 캐시 미스를 최소화하는 것이지만, 캐시 미스는 가변적인 지연 시간을 유발하므로 강화 학습을 통해 직접 지연 시간을 최소화하는 방향으로 정책을 미세 조정할 수 있습니다.
- 캐시 교체 문제는 지연된 보상, 동적 행동 공간, 큰 상태 공간, 새로운 메모리 주소 및 PC에 대한 일반화 능력 요구 등 ML 연구 커뮤니티에 흥미로운 도전 과제를 제공합니다.

## 📌 TL;DR

캐시 교체 문제를 해결하기 위해, 이 논문은 미래 접근 정보를 아는 Belady's 최적 정책을 모방 학습하는 종단 간 신경망 기반 접근 방식인 **PARROT**을 제안합니다. PARROT은 DAgger를 활용한 훈련, 순위 손실, 재사용 거리 예측 보조 태스크를 통해 과거 접근 이력만을 기반으로 최적 정책을 효과적으로 근사합니다. 실험 결과, PARROT은 기존 최고 성능 정책 대비 캐시 미스율을 20% 감소시키고, LRU 대비 캐시 적중률을 61% 향상시키며, 뛰어난 일반화 능력을 입증했습니다. 이는 캐시 교체 분야에 새로운 학습 기반 프레임워크를 제시합니다.
