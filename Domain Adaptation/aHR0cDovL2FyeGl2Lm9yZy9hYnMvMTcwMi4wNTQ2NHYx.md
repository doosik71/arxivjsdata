# Adversarial Discriminative Domain Adaptation

Eric Tzeng, Judy Hoffman, Kate Saenko, Trevor Darrell

## 🧩 Problem to Solve

딥 신경망은 대규모 데이터셋으로 훈련될 때 다양한 시각적 작업과 도메인에 유용할 수 있는 표현을 학습할 수 있지만, "데이터셋 편향(dataset bias)" 또는 "도메인 시프트(domain shift)" 현상으로 인해 새로운 데이터셋이나 작업에 잘 일반화되지 않습니다. 이러한 문제를 해결하기 위해 네트워크를 특정 작업에 맞게 미세 조정하는 것이 일반적이지만, 이는 대량의 레이블링된 데이터가 필요하여 비용이 많이 들고 어렵습니다. 비지도 도메인 적응(unsupervised domain adaptation)은 레이블링되지 않은 타겟 도메인에서도 모델이 잘 작동하도록 돕는 것을 목표로 합니다. 기존의 적대적 도메인 적응 방법들은 생성 모델 기반이거나 가중치 공유 방식에 제한이 있어, 판별 작업에 최적화되지 않거나 큰 도메인 시프트를 처리하는 데 한계가 있었습니다. 본 논문은 이러한 한계를 극복하고 더 효과적인 비지도 도메인 적응 방법을 제안하고자 합니다.

## ✨ Key Contributions

- **일반화된 적대적 적응 프레임워크 제안:** 기존의 최신 적대적 적응 방법들을 포괄하는 새로운 통합 프레임워크를 제시하여, 서로 다른 접근 방식들 간의 관계를 명확히 하고 새로운 방법론 설계의 기반을 마련했습니다.
- **ADDA(Adversarial Discriminative Domain Adaptation) 제안:** 일반화된 프레임워크의 새로운 인스턴스로, 판별 모델링, 비공유 가중치(untied weight sharing), GAN 손실을 결합한 ADDA를 제안합니다. 이는 기존 방법보다 더 효과적이면서도 훨씬 간단합니다.
- **최첨단 성능 달성:** 표준 교차 도메인 숫자 분류 작업(MNIST, USPS, SVHN) 및 새롭고 더 어려운 교차 양식(cross-modality) 객체 분류 작업(RGB-to-Depth)에서 비지도 적응 분야의 최첨단 결과를 뛰어넘는 성능을 입증했습니다.
- **생성 모델링의 불필요성 시사:** 판별 작업에 있어 입력 이미지 분포의 생성 모델링이 필수는 아니며, 잠재 특징 공간이 도메인 불변(domain invariant)하다면 충분하다는 것을 보여줍니다.

## 📎 Related Works

- **MMD(Maximum Mean Discrepancy) 기반 방법:**
  - **DDC [5]:** 판별적이고 도메인 불변적인 표현 학습을 위해 MMD를 분류 손실과 함께 사용합니다.
  - **DAN [6]:** MMD를 재현 커널 힐베르트 공간에 임베드된 레이어에 적용하여 두 분포의 고차 통계량을 매칭합니다.
  - **CORAL [8]:** 두 분포의 평균과 공분산을 매칭하여 도메인 시프트를 줄입니다.
- **적대적 적응 방법:**
  - **[12] (Domain Confusion):** 도메인 분류기를 추가하여 도메인 예측이 균일 분포에 가깝도록 유도하는 도메인 혼동 손실을 사용합니다.
  - **[11] (Gradient Reversal):** 도메인 불변성을 이진 분류 문제로 다루고, 도메인 분류기의 손실을 직접 최대화하기 위해 기울기 역전 계층(gradient reversal layer)을 사용합니다.
  - **DRCN [9]:** [11]과 유사하지만 타겟 도메인 이미지를 재구성하는 학습도 수행합니다.
- **생성적 적대 신경망(GANs):**
  - **GAN [10]:** 생성자 $G$와 판별자 $D$를 적대적으로 학습시켜 데이터를 생성합니다.
  - **BiGAN [14]:** GAN을 확장하여 이미지 데이터로부터 잠재 공간으로의 역 매핑도 학습합니다.
  - **CGAN [15]:** GAN에 추가적인 조건부 정보를 입력으로 사용하여 조건부 분포를 생성합니다.
  - **CoGAN [13]:** 도메인 전이 문제에 GAN을 적용, 두 개의 GAN을 훈련하여 원본 및 타겟 이미지를 생성하며 고수준 레이어 파라미터를 공유하여 도메인 불변 특징 공간을 학습합니다. 하지만 이 방법은 도메인 간 유사성이 높은 경우(예: MNIST-USPS)에 주로 효과적이며, 더 이질적인 도메인에는 어려움을 겪습니다.

## 🛠️ Methodology

ADDA는 먼저 일반화된 적대적 비지도 적응 프레임워크를 정의하고, 이 프레임워크 내에서 특정 설계 선택을 통해 ADDA를 구성합니다.

1. **일반화된 적대적 적응 프레임워크:**

   - **목표:** 원본 도메인($p_s(x,y)$)과 타겟 도메인($p_t(x,y)$) 간의 매핑 분포 거리($M_s(X_s)$와 $M_t(X_t)$)를 최소화하여 원본 분류 모델 $C_s$를 타겟 도메인에 직접 적용할 수 있도록 합니다.
   - **손실 함수:**
     - **분류 손실 ($L_{\text{cls}}$):** 원본 매핑 $M_s$와 분류기 $C$를 레이블링된 원본 데이터에 대해 훈련합니다.
       $$ \min*{M_s, C} L*{\text{cls}}(X*s, Y_s) = E*{(x*s, y_s) \sim (X_s, Y_s)} \left[ - \sum*{k=1}^K \mathbf{1}\_{[k=y_s]} \log C(M_s(x_s)) \right] $$
     - **도메인 판별자 손실 ($L_{\text{adv}}^D$):** 도메인 판별자 $D$는 원본 및 타겟 매핑에서 나온 데이터 포인트가 각각 원본 또는 타겟 도메인에서 왔는지 분류하도록 훈련됩니다.
       $$ L*{\text{adv}}^D(X_s, X_t, M_s, M_t) = -E*{x*s \sim X_s}[\log D(M_s(x_s))] -E*{x_t \sim X_t}[\log(1-D(M_t(x_t)))] $$
     - **매핑 적대적 손실 ($L_{\text{adv}}^M$):** 원본 및 타겟 매핑은 특정 제약 $\psi(M_s, M_t)$ 하에 적대적 목적에 따라 최적화됩니다.
       $$ \min*{D} L*{\text{adv}}^D(X*s, X_t, M_s, M_t) \\ \min*{M*s, M_t} L*{\text{adv}}^M(X_s, X_t, D) \quad \text{s.t.} \, \psi(M_s, M_t) $$
   - **설계 선택 요소:**
     - **기반 모델:** 생성 모델 (예: CoGAN) 또는 판별 모델 (예: Gradient Reversal).
     - **가중치 공유:** 가중치 공유(tied weights) 또는 비공유(untied weights).
     - **적대적 손실:** Minimax(Gradient Reversal), Domain Confusion, GAN loss (inverted labels).

2. **ADDA의 특정 설계 선택:**

   - **기반 모델:** **판별 모델**을 사용합니다. 최종 작업이 판별적 표현 학습이므로, 이미지를 생성하는 데 필요한 파라미터는 불필요하다고 가정합니다.
   - **가중치 공유:** **비공유 가중치(untied weights)**를 사용하여 원본 및 타겟 매핑을 독립적으로 학습합니다. 이는 더 유연한 학습 패러다임을 제공하고 도메인별 특징 추출을 가능하게 합니다.
   - **적대적 손실:** **반전된 레이블을 사용한 표준 GAN 손실**을 사용합니다. 원본 분포가 고정된 상태에서 생성 분포가 이를 모방하도록 학습하는 GAN 설정과 유사하게, 원본 모델을 고정한 채 타겟 모델만 적대적으로 학습하여 원본 분포와 일치시킵니다.
     $$ L*{\text{adv}}^M(X_s, X_t, D) = -E*{x_t \sim X_t}[\log D(M_t(x_t))] $$

3. **훈련 절차 (단계별 최적화):**
   1. **사전 훈련 (Pre-training):** 레이블링된 원본 데이터($X_s, Y_s$)를 사용하여 원본 인코더 CNN ($M_s$)과 분류기 ($C$)를 $L_{\text{cls}}$로 훈련합니다.
   2. **적대적 적응 (Adversarial Adaptation):**
      - 타겟 인코더 CNN ($M_t$)의 파라미터를 사전 훈련된 $M_s$로 초기화합니다.
      - $M_s$ (및 $C$)의 파라미터는 고정합니다.
      - 도메인 판별자 $D$는 $M_s(X_s)$와 $M_t(X_t)$를 구별하도록 $L_{\text{adv}}^D$를 사용하여 훈련합니다.
      - $M_t$는 $M_t(X_t)$가 $M_s(X_s)$와 구별할 수 없도록 $D$를 속이도록 $L_{\text{adv}}^M$를 사용하여 훈련합니다.
   3. **테스트:** 타겟 이미지는 학습된 타겟 인코더 $M_t$를 통해 공유 특징 공간으로 매핑되고, 사전 훈련된 원본 분류기 $C$에 의해 분류됩니다.

## 📊 Results

- **숫자 분류 도메인 적응 (MNIST, USPS, SVHN):**
  - **MNIST→USPS:** ADDA는 0.894의 정확도를 달성하여 CoGAN(0.912)과 유사한 최첨단 성능을 보였습니다.
  - **USPS→MNIST:** ADDA는 0.901의 정확도를 달성하여 CoGAN(0.891)보다 우수했습니다.
  - **SVHN→MNIST:** ADDA는 0.760의 정확도를 달성하여 Gradient Reversal(0.739) 및 Domain Confusion(0.681)을 능가했습니다. CoGAN은 이질적인 도메인 특성으로 인해 수렴하지 못했습니다.
- **교차 양식 도메인 적응 (NYUD: RGB→Depth):**
  - 원본 전용(Source only) 모델의 평균 정확도 13.9%에서 ADDA는 21.1%로 크게 향상되었습니다.
  - 일부 카테고리(예: `counter`)에서는 정확도가 2.9%에서 44.7%로 급증했습니다.
  - ADDA는 레이블링된 Depth 데이터 없이도 Depth 이미지에 대한 유용한 표현을 학습함을 보여주었습니다.
  - 혼동 행렬 분석 결과, 원본 전용 모델이 'pillow'와 같은 특정 클래스에 과도하게 편향되는 경향이 있었던 반면, ADDA는 훨씬 더 다양한 클래스를 예측하며 'chair'와 'table' 사이의 혼동과 같이 합리적인 실수를 보였습니다.

## 🧠 Insights & Discussion

- **프레임워크의 유용성:** 제안된 통합 프레임워크는 기존 적대적 적응 방법들을 비교하고 이해하는 데 도움을 주며, ADDA와 같은 새로운 방법론을 설계하는 데 유용한 가이드를 제공합니다.
- **판별 모델링의 중요성:** ADDA의 성공은 판별 작업에 있어 입력 이미지 분포를 생성적으로 모델링하는 것이 필수는 아니며, 도메인 불변적인 판별 표현을 학습하는 것이 핵심임을 시사합니다.
- **비공유 가중치의 이점:** 타겟 모델을 원본 모델과 분리하여 비대칭 매핑을 학습하는 비공유 가중치 방식은 더 큰 도메인 시프트를 유연하게 처리할 수 있으며, CoGAN과 같은 생성 모델이 실패하는 경우에도 효과적입니다.
- **훈련 전략의 중요성:** 비공유 가중치를 사용할 때, 사전 훈련된 원본 모델로 타겟 모델을 초기화하고 적대적 훈련 중에 원본 모델을 고정하는 것이 타겟 모델이 퇴화된 솔루션을 학습하는 것을 방지하는 데 중요합니다.
- **도메인 시프트 완화 효과:** ADDA를 통해 학습된 표현은 비적응 특징보다 타겟 도메인의 지도 학습 데이터로 학습된 특징과 더 유사하여, 도메인 시프트의 영향을 효과적으로 되돌릴 수 있음을 추가적으로 입증합니다.
- **제한 사항:** NYUD 데이터셋 실험에서 모든 클래스의 성능이 향상된 것은 아니며, 일부 클래스(예: `pillow`, `nightstand`)는 성능 저하를 보이기도 했습니다. 이는 희귀 클래스나 특정 특징 변환에 대한 적응의 한계를 나타낼 수 있습니다.

## 📌 TL;DR

**문제:** 딥러닝 모델은 도메인 시프트 때문에 레이블링되지 않은 타겟 도메인에서 성능이 저하되며, 기존 적대적 적응 방법은 판별 작업에 비효율적이거나 큰 도메인 시프트에 취약합니다.

**제안 방법:** ADDA(Adversarial Discriminative Domain Adaptation)는 일반화된 적대적 적응 프레임워크를 기반으로 판별 모델링, 비공유 가중치, GAN 손실을 결합한 새로운 비지도 도메인 적응 방법입니다. 원본 모델을 사전 훈련한 후, 타겟 인코더를 원본 모델로 초기화하고 원본 모델을 고정한 채 도메인 판별자와 적대적으로 훈련하여 타겟 특징을 원본 특징 공간과 구별할 수 없도록 만듭니다.

**주요 발견:** ADDA는 숫자 분류(MNIST, USPS, SVHN) 및 교차 양식 객체 분류(RGB→Depth)에서 최첨단 성능을 달성했습니다. 이는 기존 생성 모델 기반 방법보다 더 간단하고 큰 도메인 시프트에 강하며, 판별적 학습과 비대칭 매핑이 비지도 도메인 적응에 매우 효과적임을 입증합니다.
