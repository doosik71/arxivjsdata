# TENT: FULLY TEST-TIME ADAPTATION BY ENTROPY MINIMIZATION

Dequan Wang, Evan Shelhamer, Shaoteng Liu, Bruno Olshausen, Trevor Darrell

## 🧩 Problem to Solve

심층 신경망은 훈련(소스) 데이터와 동일한 분포의 테스트 데이터에 대해서는 높은 정확도를 달성하지만, 새로운 데이터 분포(예: 이미지 손상, 도메인 이동)에 대해서는 일반화 성능이 현저히 저하됩니다. 이러한 "데이터셋 시프트(dataset shift)"는 실제 환경에서 모델을 배포할 때 큰 문제입니다. 기존의 적응(adaptation) 방법들은 일반적으로 소스 데이터, 타겟 데이터 레이블, 또는 훈련 시의 모델 수정 등을 필요로 합니다. 하지만, 소스 데이터나 레이블을 사용할 수 없는 "완전한 테스트-시간 적응(fully test-time adaptation)" 환경에서 모델이 스스로 새로운 데이터에 적응해야 하는 실용적인 문제에 대한 효과적인 해결책이 부족합니다.

## ✨ Key Contributions

- **"완전한 테스트-시간 적응" 설정 제안**: 소스 데이터나 레이블 없이 오직 타겟 데이터와 모델 파라미터만을 사용하여 추론 중에 모델을 적응시키는 실용적인 설정을 강조했습니다.
- **Tent (Test Entropy Minimization) 방법론 제안**: 모델 예측의 엔트로피(불확실성)를 최소화하여 일반화 오류를 줄이는 새로운 테스트-시간 적응 기법을 제시했습니다. 엔트로피는 오류 및 데이터 시프트와 직접적인 연관이 있음을 보여주었습니다.
- **최첨단 성능 달성 (ImageNet-C)**: 이미지 손상(corruption)에 대한 강건성(robustness) 벤치마크인 ImageNet-C에서 44.0%의 오류율을 기록하며 이전 최첨단 방법(adversarial noise training의 50.2%)을 능가하는 새로운 SOTA (State-Of-The-Art)를 달성했습니다.
- **소스-프리 도메인 적응 능력 입증**: 숫자 인식(SVHN에서 MNIST/MNIST-M/USPS), 의미론적 분할(semantic segmentation, GTA에서 Cityscapes), VisDA-C 벤치마크에서 소스 데이터 없이 온라인으로 적응할 수 있음을 입증했으며, 일부 경우에는 소스 데이터를 사용하는 방법과 비견할 만한 성능을 보였습니다.
- **훈련 변경 불필요**: 기존 모델 훈련 과정을 전혀 변경하지 않고, 단 한 epoch의 테스트-시간 최적화만으로 이러한 개선을 달성했습니다.

## 📎 Related Works

- **훈련-시간 적응 (Train-Time Adaptation)**:
  - 도메인 적응(Domain Adaptation, DA): 소스 및 타겟 데이터를 함께 사용하여 도메인 간의 손실을 최소화합니다 (예: feature alignment, adversarial invariance, shared proxy tasks).
  - 트랜스덕션(Transduction): 훈련 및 테스트 데이터를 함께 최적화하여 특정 테스트 인스턴스에 더 잘 맞춥니다.
  - **Tent와의 차이점**: 이 방법들은 소스/훈련 데이터와 타겟/테스트 데이터를 동시에 사용하는 것을 요구하지만, Tent는 오직 타겟 데이터만을 사용하여 적응합니다.
- **소스-프리 적응 (Source-Free Adaptation)**:
  - Li et al. (2020), Kundu et al. (2020): 생성 모델링(generative modeling)에 의존하고 여러 모델과 여러 손실 함수를 최적화합니다.
  - Kundu et al. (2020), Liang et al. (2020) (SHOT): 훈련 과정을 변경하며, SHOT은 정보 최대화(entropy minimization과 diversity regularization)를 사용하지만, 다른 손실 함수와 파라미터화를 가집니다.
  - **Tent와의 차이점**: Tent는 생성 모델링이 필요 없고, 훈련을 변경하지 않으며, 더 효율적인 단일 손실 함수와 파라미터화를 사용하여 온라인 적응에 중점을 둡니다.
- **테스트-시간 적응 (Test-Time Adaptation)**:
  - 테스트-시간 훈련 (Test-Time Training, TTT) (Sun et al., 2019b): 테스트 중에 최적화하지만, 이미지 회전 인식과 같은 "프록시 작업(proxy task)"에 의존하며 훈련 과정을 변경해야 합니다.
  - 테스트-시간 정규화 (Test-Time Normalization, BN) (Schneider et al., 2020; Nado et al., 2020): 배치 정규화(batch normalization) 통계량을 테스트 데이터에 맞춰 업데이트합니다.
  - **Tent와의 차이점**: Tent는 프록시 작업이 필요 없고 훈련을 변경하지 않으며, BN의 기반 위에 추가적인 특징 변조(feature modulation)를 통해 성능을 향상시킵니다.
- **엔트로피 최소화 (Entropy Minimization)**:
  - 도메인 적응, 준지도 학습(semi-supervised learning), 퓨샷 학습(few-shot learning)에서 정규화(regularizer)로 사용됩니다 (Grandvalet & Bengio, 2005; Lee, 2013; Carlucci et al., 2017 등).
  - **Tent와의 차이점**: Tent는 테스트-시간 적응을 위해 _오직_ 엔트로피를 _유일한_ 손실 함수로 사용한 최초의 방법입니다.
- **특징 변조 (Feature Modulation)**:
  - 배치 정규화(Batch Normalization), 그룹 정규화(Group Normalization), FiLM 등에서 입력에 따라 모델을 변화시키기 위해 사용됩니다. 주로 훈련 중에 지도 학습 손실로 최적화되고 테스트 중에는 고정됩니다.
  - **Tent와의 차이점**: Tent는 비지도 손실(엔트로피)을 사용하여 *테스트 중*에 변조 파라미터를 최적화함으로써 새로운 타겟 데이터에 적응할 수 있도록 합니다.

## 🛠️ Methodology

Tent는 모델의 예측 엔트로피를 최소화함으로써 테스트-시간에 모델을 최적화합니다. 이는 모델의 특징(feature)을 변조(modulate)하는 방식으로 이루어집니다.

1. **호환 가능한 모델**:

   - 감독된 작업(supervised task)을 위해 사전 훈련되어 있어야 합니다.
   - 확률적 예측(probabilistic predictions)을 생성할 수 있어야 합니다 (예: softmax 출력).
   - 빠른 반복 최적화를 위해 미분 가능(differentiable)해야 합니다.
   - 일반적인 딥러닝 모델(예: 분류기)은 이러한 요구사항을 충족합니다.

2. **엔트로피 목적 함수**:

   - 목표는 모델 예측 $\hat{y} = f_{\theta}(x_t)$의 샤논 엔트로피(Shannon entropy) $H(\hat{y})$를 최소화하는 것입니다.
   - $H(\hat{y}) = -\sum_{c} p(\hat{y}_{c}) \log p(\hat{y}_{c})$
   - 이는 예측만을 기반으로 하므로 비지도(unsupervised) 목적 함수입니다. 단일 예측 최적화 시 모든 확률을 가장 높은 클래스에 할당하는 얕은 해(trivial solution)를 방지하기 위해 배치(batch) 내에서 공유되는 파라미터에 대해 공동으로 최적화합니다.

3. **변조 파라미터 (Modulation Parameters)**:

   - 소스 모델의 전체 파라미터 $\theta$를 변경하면 훈련으로부터 이탈할 수 있고 비효율적일 수 있습니다.
   - 대신, Tent는 정규화(normalization) 레이어 내의 채널-별(channel-wise) 어파인 변환(affine transformation) 파라미터 $\{\gamma_{l,k}, \beta_{l,k}\}$만을 최적화합니다. 이들은 선형(스케일 및 시프트)이며 저차원(low-dimensional)이므로 효율적입니다.
   - **정규화**: 입력 $x$를 평균 $\mu$ 및 표준 편차 $\sigma$를 사용하여 $\bar{x} = (x - \mu) / \sigma$로 정규화합니다. 여기서 $\mu, \sigma$는 타겟 데이터에서 추정됩니다.
   - **변환**: $\bar{x}$를 스케일 $\gamma$와 시프트 $\beta$에 대한 어파인 파라미터로 $x' = \gamma \bar{x} + \beta$로 변환합니다. 여기서 $\gamma, \beta$는 엔트로피 손실로 최적화됩니다.
   - 소스 모델의 배치 정규화(Batch Normalization) 레이어를 재활용하여 이 통계치와 어파인 파라미터를 업데이트합니다.

4. **알고리즘 단계**:
   - **초기화 (Initialization)**:
     - 최적화할 파라미터로 각 정규화 레이어 $l$ 및 채널 $k$의 어파인 변환 파라미터 $\{\gamma_{l,k}, \beta_{l,k}\}$를 수집합니다.
     - 나머지 모델 파라미터 $\theta \setminus \{\gamma_{l,k}, \beta_{l,k}\}$는 고정됩니다.
     - 소스 데이터에서 얻은 정규화 통계량 $\{\mu_{l,k}, \sigma_{l,k}\}$는 버려집니다.
   - **반복 (Iteration)**:
     - 각 배치(batch) 데이터에 대해 정규화 통계량과 변환 파라미터를 업데이트합니다.
     - **순전파 (Forward Pass)**: 각 레이어에서 정규화 통계량($\mu, \sigma$)을 현재 배치 데이터로부터 추정합니다.
     - **역전파 (Backward Pass)**: 예측 엔트로피의 기울기 $\nabla H(\hat{y})$를 사용하여 변환 파라미터 $\gamma, \beta$를 업데이트합니다. 이 업데이트는 현재 배치에 대한 예측을 따르며 다음 배치에 영향을 미칩니다. 효율성을 위해 각 테스트 인스턴스당 하나의 기울기 계산만 필요합니다.
   - **종료 (Termination)**:
     - 온라인 적응(online adaptation)의 경우, 테스트 데이터가 있는 한 반복을 계속합니다.
     - 오프라인 적응(offline adaptation)의 경우, 모델을 먼저 업데이트한 후 추론을 반복합니다. 여러 epoch에 걸쳐 적응을 계속할 수도 있습니다.

## 📊 Results

- **손상에 대한 강건성 (Corruption Robustness)**:

  - **CIFAR-10/100-C**: 가장 심한 손상 수준에서 다른 모든 방법(BN, PL, RG, UDA-SS, TTT)보다 낮은 오류율을 보였습니다. CIFAR-10-C에서 14.3% (BN은 17.3%), CIFAR-100-C에서 37.3% (BN은 42.6%)를 달성했습니다.
  - **ImageNet-C**: 모든 손상 유형에서 평균 44.0%의 오류율을 달성하여 이전 SOTA인 ANT (50.2%) 및 BN (49.9%)을 뛰어넘는 새로운 SOTA를 기록했습니다. 온라인 적응으로 44.0%, 오프라인 적응으로 42.3%까지 개선되었습니다. 훈련을 변경하거나 외부 이미지를 사용하지 않고도 대부분의 손상 유형에서 ANT보다 성능이 좋았습니다.

- **소스-프리 도메인 적응 (Source-Free Domain Adaptation)**:

  - **숫자 인식 (SVHN $\to$ MNIST/MNIST-M/USPS)**: 소스 모델 및 BN보다 항상 낮은 오류율을 보였으며, 3가지 경우 중 2가지에서 소스 데이터를 사용하는 도메인 적응 방법(RG, UDA-SS)보다 낮은 오류율을 달성했습니다. SVHN-to-MNIST에서 1 epoch에 10.0%, 10 epochs에 8.2% 오류율을 달성했습니다.
  - **의미론적 분할 (GTA $\to$ Cityscapes)**: mIoU(평균 Intersection-over-Union)가 소스 모델의 28.8%에서 BN의 31.4%, 그리고 Tent의 35.8%로 향상되었습니다. 단일 이미지에 대한 적응도 가능함을 보여주었습니다.
  - **VisDA-C 챌린지**: ResNet-50 모델에서 소스 모델의 56.1% 오류율을 Tent 적용 후 45.6%로 감소시켰고, 최종 분류기를 제외한 모든 레이어를 업데이트했을 때 39.6%까지 개선했습니다.

- **분석 결과 (Analysis)**:
  - **엔트로피 및 오류 감소**: Tent는 실제로 예측 엔트로피와 작업 손실(softmax cross-entropy)을 모두 감소시킵니다.
  - **특징 변조의 필요성**: 정규화 통계량과 변환 파라미터를 모두 업데이트하는 것이 중요하며, 전체 모델 파라미터를 업데이트하는 것은 오히려 성능을 저하시킬 수 있습니다.
  - **일반화 능력**: 적응은 특정 테스트 인스턴스에 국한되지 않고 타겟 데이터 전반에 걸쳐 일반화됩니다.
  - **변조의 특성**: Tent의 변조는 특징을 손상된 데이터의 참조 특징과 유사하게 만드는 것이 아니라, 타겟 레이블에 최적화된 오라클(oracle)과 유사하게 만듭니다. 이는 단순히 특징을 복원하는 것을 넘어선 작업별 효과를 시사합니다.
  - **아키텍처 일반화**: 컨볼루션 네트워크(ResNet)뿐만 아니라 self-attention 기반(SAN) 및 equilibrium solving 기반(MDEQ) 아키텍처에도 동일한 설정으로 성공적으로 적용되어 오류를 줄였습니다.

## 🧠 Insights & Discussion

Tent는 테스트-시간 엔트로피 최소화를 통해 데이터 시프트 상황에서 일반화 오류를 줄이는 효과적인 방법을 제시합니다. 이는 모델 예측 자체의 피드백을 활용하여 스스로 개선하는 "진정한 자기-지도 학습적 자기-개선(truly self-supervised self-improvement)" 방식을 보여줍니다. 프록시 작업 없이도 감독 작업에 의해 완전히 정의된 방식으로 오류를 줄인다는 점이 주목할 만합니다.

**함의**:

- **자기-지도 학습의 새로운 관점**: 프록시 작업 없이도 모델의 내재된 불확실성(엔트로피)을 줄이는 것이 성능 향상으로 이어진다는 것을 보여줍니다.
- **실용적 적용 가능성**: 소스 데이터나 레이블 없이 모델을 배포해야 하는 현실적인 시나리오에서 중요한 해결책을 제공합니다.

**한계 및 향후 연구 방향**:

- **다양한 시프트에 대한 적용**: CIFAR 10.1, ImageNetV2와 같이 "자연스럽지만 알려지지 않은 시프트"에는 아직 성능 개선이 제한적입니다. 적대적 시프트(adversarial shifts)와 같은 더 어려운 유형의 시프트에도 적용 가능성을 탐색해야 합니다.
- **더 일반적인 파라미터 적응**: 현재는 정규화 레이어의 어파인 변환 파라미터만 변조하지만, 모델의 더 많은 부분을 업데이트하여 표현력을 높일 수 있는 "표현적이면서도 신뢰할 수 있는" 파라미터를 식별하는 연구가 필요합니다.
- **더욱 효과적이고 효율적인 손실 함수**: 엔트로피는 광범위한 작업에 적용 가능하지만, 최적화를 위해 배치가 필요하며 한 번에 하나의 인스턴스에 에피소드적으로 업데이트할 수 없습니다. 더 적은 계산으로 로컬 최적화를 위한 효율적인 손실이나, 표현(representation) 자체에 정의된 손실 함수를 탐색할 수 있습니다. 엔트로피와 캘리브레이션(calibration) 간의 상호작용도 연구 가치가 있습니다.

## 📌 TL;DR

Tent는 소스 데이터나 레이블 없이 **테스트-시간에 모델을 데이터 시프트에 적응**시키는 새로운 방법입니다. 모델 **예측의 엔트로피를 최소화**하는 것을 목표로 하며, 이는 모델의 **정규화 레이어 내 어파인 변환 파라미터**를 온라인으로 업데이트하여 이루어집니다. 훈련 과정을 변경하지 않고 단 한 epoch의 테스트-시간 최적화만으로 **ImageNet-C에서 44.0% 오류율로 새로운 최첨단 성능을 달성**했으며, 소스 데이터 없이도 숫자 인식 및 의미론적 분할에서 성공적인 도메인 적응을 보였습니다.
