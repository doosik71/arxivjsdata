# Maximum Density Divergence for Domain Adaptation

Jingjing Li, Erpeng Chen, Zhengming Ding, Lei Zhu, Ke Lu and Heng Tao Shen

## 🧩 Problem to Solve

본 논문은 비지도 도메인 적응(Unsupervised Domain Adaptation, UDA) 문제, 즉 레이블이 풍부한 소스 도메인에서 레이블이 없는 타겟 도메인으로 지식을 전이하는 문제를 다룹니다. 두 도메인의 데이터 분포가 현저히 다를 때 발생하는 분포 불일치(distribution divergence)를 효과적으로 완화하는 것이 핵심 과제입니다. 기존의 최신 UDA 방법들은 주로 적대적 학습(adversarial training)을 사용하거나 분포 간의 차이를 정의하는 메트릭을 최소화하는 방식인데, 적대적 학습은 도메인 판별자가 완전히 혼동되더라도 두 도메인이 잘 정렬된다는 보장이 없는 '평형 도전(equilibrium challenge)' 문제에 직면하며, 메트릭 학습은 활용할 수 있는 메트릭 자체가 제한적이라는 한계가 있습니다.

## ✨ Key Contributions

- **새로운 손실 함수 MDD(Maximum Density Divergence) 제안:** 도메인 분포 간의 간극을 정량화하고 최소화하기 위해 인터-도메인 발산(inter-domain divergence)을 최소화하고 인트라-클래스 밀도(intra-class density)를 최대화하는 새로운 MDD 손실 함수를 제안합니다. MDD는 마진 분포(marginal distribution)와 조건부 분포(conditional distribution)를 모두 고려하며, 딥 러닝 아키텍처에 효율적으로 통합될 수 있도록 실용적인 변형을 제공합니다.
- **적대적 도메인 적응의 평형 도전 완화:** 적대적 도메인 적응에서 발생하는 평형 도전 문제를 완화하기 위해 제안된 MDD 손실을 적대적 학습 프레임워크에 추가적인 손실 함수로 활용합니다. 이를 통해 도메인 판별자를 혼동시키는 동시에 명시적으로 분포 불일치를 최소화하여 학습 안정성을 높이고 성능을 개선합니다.
- **Adversarial Tight Match (ATM) 방법론 제안:** MDD 손실을 적대적 도메인 적응 네트워크에 통합한 새로운 비지도 도메인 적응 방법론인 ATM을 제안합니다.
- **SOTA 성능 달성:** 네 가지 벤치마크(고전적 및 대규모 데이터셋 포함)에서 광범위한 실험을 통해 제안된 ATM 방법이 기존 최신 방법들보다 뛰어난 성능을 달성함을 입증합니다. 특히, SVHN→MNIST 평가에서 89.2%에서 96.1%로 성능을 크게 향상시켰습니다.

## 📎 Related Works

- **메트릭 학습 기반 도메인 적응:**
  - **MMD (Maximum Mean Discrepancy):** 두 샘플의 평균 함수 값 차이를 측정하며, 널리 사용됩니다 (예: JAN [16]).
  - **공분산(Covariance):** 도메인 간의 공분산을 최소화합니다 (예: Deep CORAL [15]).
  - **H-divergence:** 분류기 기반 발산으로, 일반화 한계 분석에 주로 사용됩니다.
  - **KL-divergence:** 분포 간의 차이를 측정하지만, 미니 배치 분포에 최적화될 때 실제 분포로 일반화되기 어렵습니다.
- **적대적 도메인 적응:**
  - 도메인 판별자와 특징 학습 네트워크를 적대적으로 훈련하여 도메인 불변 특징을 학습합니다 (예: ADDA [7], CoGAN [19], DANN/RevGrad [20]).
  - **CDAN (Conditional Domain Adversarial Network) [4]:** 조건부 GAN의 아이디어를 공유하여 도메인 불변 특징 학습의 평형 도전을 일부 완화하려 시도합니다.

## 🛠️ Methodology

본 논문은 **Maximum Density Divergence (MDD)**를 정의하고 이를 적대적 학습 프레임워크에 통합한 **Adversarial Tight Match (ATM)**를 제안합니다.

1. **Maximum Density Divergence (MDD) 정의:**

   - **MDD 정의:** 두 도메인 $P$와 $Q$의 데이터 분포에 대해 MDD는 다음과 같이 정의됩니다.
     $$MDD(P,Q) = E_{X_s \sim P, X_t \sim Q}[\|X_s - X_t\|_2^2] + E_{X_s, X'_s \sim P}[\|X_s - X'_s\|_2^2] + E_{X_t, X'_t \sim Q}[\|X_t - X'_t\|_2^2]$$
     여기서 첫 번째 항은 인터-도메인 발산을 최소화하고, 두 번째 및 세 번째 항은 인트라-도메인 밀도를 최대화하여 각 도메인 내의 샘플들을 더 밀집하게 만듭니다.
   - **실용적인 MDD 손실 ($L_{mdd}$) 계산:**
     - 딥 네트워크의 배치 학습 환경을 고려하여 모든 쌍별 거리를 계산하는 대신, 배치 내에서 샘플링된 $n_b$개의 소스 샘플과 $n_b$개의 타겟 샘플에 대해 관련된 위치의 쌍별 거리만 계산합니다.
     - 인트라-도메인 밀도 항을 계산하기 위해 배치 내에서 동일한 레이블을 가진 샘플들을 $X'_s, X'_t$로 간주합니다. 타겟 도메인의 레이블을 알 수 없으므로, 예측기(predictor)를 통해 얻은 **가상 레이블(pseudo labels)**을 사용합니다.
     - 최종 $L_{mdd}$는 다음과 같습니다.
       $$L_{mdd} = \frac{1}{n_b}\sum_{i=1}^{n_b}\|f_{s,i} - f_{t,i}\|_2^2 + \frac{1}{m_s}\sum_{y_{s,i}=y'_{s,j}}\|f_{s,i} - f'_{s,j}\|_2^2 + \frac{1}{m_t}\sum_{y_{t,i}=y'_{t,j}}\|f_{t,i} - f'_{t,j}\|_2^2$$
       여기서 $f$는 특징 학습기 $F$에 의해 학습된 특징이며, $m_s, m_t$는 해당 클래스에 속하는 샘플 수입니다.
   - **이론적 특성:** MDD는 대칭 KL-diver전스의 하한이며, $P=Q$일 경우 MDD는 0이 됩니다.

2. **Cross-Domain Adversarial Tight Match (ATM) 프레임워크:**
   - ATM은 특징 학습기 $F$, 예측기(predictor), 도메인 판별기 $D$로 구성됩니다.
   - **전체 목적 함수:** 적대적 손실 $L_{adv}$와 MDD 손실 $L_{mdd}$를 결합하여 최적화합니다.
     $$\min_F \max_D L_{adv} + \alpha L_{mdd}$$
     여기서 $\alpha > 0$는 MDD 손실의 균형을 조절하는 매개변수입니다.
   - **적대적 손실 ($L_{adv}$):** CDAN [4]과 유사하게 소스 도메인에 대한 교차 엔트로피 분류 손실과 도메인 판별자를 혼동시키는 조건부 적대적 손실로 구성됩니다. 특징 $f$와 그에 상응하는 분류 예측 $p$의 결합 변수 $h = \Pi(f,p)$를 사용하여 조건부 적대적 학습을 수행합니다.
   - **최적화:** 미니 배치 확률적 경사 하강법(SGD)을 사용하여 $F$와 $D$ 네트워크를 업데이트합니다.

## 📊 Results

- **숫자 인식 (MNIST, USPS, SVHN):**
  - ATM은 기존 SOTA 방법인 CDAN을 모든 평가에서 능가하며, 특히 가장 어려운 SVHN→MNIST 태스크에서 89.2%에서 **96.1%**로 크게 향상되었습니다.
  - 소스 전용 모델 및 타겟 완전 지도 학습 결과와 비교했을 때, ATM은 타겟 완전 지도 학습 결과에 매우 근접한 성능을 보입니다.
- **객체 인식 (Office-31):**
  - ResNet-50 및 AlexNet 기반 특징 학습 모두에서 ATM은 CDAN을 능가했습니다. 특히 D→A 및 W→A와 같은 어려운 태스크에서 각각 3.1% 및 4.2% (ResNet-50)의 성능 향상을 보였습니다.
  - 이는 MDD가 다양한 백본 네트워크에 대해 일반화 가능한 기술임을 입증합니다.
- **다양한 시나리오 (ImageCLEF-DA) 및 대규모 데이터셋 (Office-Home):**
  - ImageCLEF-DA에서 CDAN 대비 평균 약 2%의 정확도 향상을 달성했습니다.
  - Office-Home 데이터셋의 12개 평가 모두에서 SOTA 성능을 달성하며, 평균적으로 CDAN보다 2.1% 더 높은 정확도를 기록하여 대규모 데이터셋에서도 우수한 일반화 능력을 보였습니다.
- **모델 분석:**
  - **학습 안정성:** MDD 손실의 통합으로 CDAN보다 손실 곡선이 더 부드러워지고, 20 에포크 이내에 안정적으로 수렴함을 확인했습니다.
  - **매개변수 민감도:** $\alpha = 0.01$에서 최적의 성능을 보였으며, 이는 MDD 손실이 적대적 손실과 다른 스케일을 가지므로 작은 가중치가 필요함을 시사합니다.
  - **MDD의 효과:** MDD 손실은 학습 과정에서 안정적으로 감소하며, CDAN보다 더 작은 A-거리(분포 발산 측정)를 달성하여 도메인 정렬 능력이 우수함을 보였습니다.
  - **가상 레이블:** 가상 레이블의 정확도는 훈련 반복에 따라 꾸준히 증가했습니다.
  - **시각화:** t-SNE 시각화 결과는 ATM이 학습한 특징이 타겟 도메인에서 더 잘 분리되고 두 도메인이 더 잘 정렬됨을 보여줍니다.
  - **정성적 연구:** CDAN이 오분류한 혼동되는 샘플(예: 숫자 4와 9)을 ATM이 올바르게 분류하는 것을 확인했습니다.

## 🧠 Insights & Discussion

본 논문의 핵심 통찰은 적대적 학습의 "평형 도전" 문제를 해결하기 위해 단순히 판별자를 혼동시키는 것을 넘어, 명시적인 분포 거리 측정 기준인 MDD를 동시에 최적화하는 것이 효과적이라는 것입니다. MDD는 인터-도메인 발산 최소화와 인트라-클래스 밀도 최대화를 동시에 수행함으로써 도메인 불변 특징을 학습할 뿐만 아니라, 각 클래스 내의 응집력을 높여 특징의 판별력을 강화합니다. 이러한 결합 접근 방식은 두 도메인 분포가 명확하게 정렬되도록 보장하여, 기존 적대적 도메인 적응 방법들이 갖는 한계를 극복하고 학습 안정성 및 성능을 크게 향상시킵니다. MDD는 $P=Q$일 때 0이 되는 이론적 특성을 가지며, 이는 목표 달성에 대한 강력한 정당성을 제공합니다. 가상 레이블링을 통해 타겟 도메인의 조건부 분포 정보까지 활용함으로써 더욱 세밀한 정렬이 가능합니다. 이 연구는 비지도 도메인 적응 분야에서 적대적 학습과 메트릭 학습의 장점을 성공적으로 융합한 사례를 제시하며, 향후 도메인 일반화(domain generalization)와 같은 더욱 어려운 문제에 대한 확장 가능성을 보여줍니다.

## 📌 TL;DR

레이블이 있는 소스 도메인과 레이블이 없는 타겟 도메인 간의 분포 불일치를 해결하는 비지도 도메인 적응(UDA)에서, 기존 적대적 학습의 평형 도전 문제를 완화하기 위해 본 논문은 **Maximum Density Divergence (MDD)**라는 새로운 손실 함수를 제안합니다. MDD는 도메인 간의 발산을 최소화하고 클래스 내 밀도를 최대화하며, 타겟 도메인의 가상 레이블을 활용하여 마진 및 조건부 분포를 모두 정렬합니다. MDD를 적대적 학습 프레임워크에 통합한 **Adversarial Tight Match (ATM)** 방법은 네 가지 벤치마크에서 기존 최신 방법들을 능가하는 성능을 달성하여, 적대적 학습과 명시적 분포 거리 최소화의 시너지가 UDA의 성능과 안정성을 크게 향상시킬 수 있음을 입증했습니다.
