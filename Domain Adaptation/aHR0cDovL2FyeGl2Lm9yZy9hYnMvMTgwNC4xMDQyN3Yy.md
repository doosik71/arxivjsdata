# Open Set Domain Adaptation by Backpropagation

Kuniaki Saito, Shohei Yamamoto, Yoshitaka Ushiku, and Tatsuya Harada

## 🧩 Problem to Solve

본 논문은 **알 수 없는 클래스를 포함하는 타겟 도메인**에 소스 도메인의 지식을 전달하는 **개방형 세트 도메인 적응(Open Set Domain Adaptation, OSDA)** 문제를 다룹니다.

- **기존 도메인 적응의 한계:** 대부분의 기존 도메인 적응 방법은 소스 및 타겟 도메인이 모든 클래스를 공유하는 '닫힌 세트(closed-set)' 시나리오를 가정합니다.
- **기존 OSDA의 한계:** 기존 OSDA 연구 [2]는 타겟 도메인에 없는 '알 수 없는' 클래스의 소스 샘플이 주어진다고 가정했지만, 이러한 '알 수 없는 소스 샘플'을 수집하는 것도 실용적이지 않고 비용이 많이 듭니다.
- **본 논문의 문제 정의:** 본 논문은 '알 수 없는 소스 샘플'이 전혀 제공되지 않으며, 소스 도메인에는 '알려진 클래스(known class)' 샘플만 있고, 타겟 도메인에는 '알려진 클래스'와 '알 수 없는 클래스' 샘플이 모두 포함된, 더욱 현실적이고 도전적인 OSDA 시나리오를 제시합니다. 이 설정에서 핵심 과제는 알 수 없는 타겟 샘플을 '알 수 없음'으로 분류하면서, 알려진 타겟 샘플은 정확한 알려진 카테고리로 분류하는 것입니다. 기존의 분포 매칭(distribution matching) 방법은 알 수 없는 타겟 샘플까지 소스에 정렬시켜 이 문제를 해결하기 어렵습니다.

## ✨ Key Contributions

- 알 수 없는 소스 샘플이 제공되지 않는, 더욱 도전적인 개방형 세트 도메인 적응(OSDA) 시나리오를 제시했습니다.
- 이 문제 해결을 위한 새로운 적대적 학습(adversarial learning) 기반 방법론을 제안했습니다. 이 방법은 특징 생성기(feature generator)가 알 수 없는 타겟 샘플을 알려진 샘플로부터 효과적으로 분리하는 표현을 학습할 수 있도록 합니다.
- 다양한 숫자 및 객체 데이터셋(Office, VisDA, Digits)에 대한 광범위한 실험을 통해 제안된 방법의 효과성과 우수성을 입증했습니다.
- 학습 시 레이블 없는 알 수 없는 샘플이 제공되는 표준 개방형 세트 인식(open set recognition) 실험에서도 본 방법의 효과를 시연하여 범용성을 보였습니다.

## 📎 Related Works

- **도메인 적응(Domain Adaptation):** 이미지 인식에서 레이블이 풍부한 소스 도메인의 지식을 레이블이 부족한 타겟 도메인으로 전이하는 데 초점을 맞춥니다.
  - **분포 매칭 방법:** 도메인 간의 특징 분포를 일치시켜 도메인 불변(domain-invariant) 특징을 추출합니다. 대표적으로 Generative Adversarial Networks (GAN) [16] 기반 방법(예: [4, 15, 17, 18])과 Maximum Mean Discrepancy (MMD) [21] 기반 방법(예: [6, 7, 22, 23])이 있습니다.
  - **한계:** 이러한 방법들은 타겟 도메인에 소스에 없는 클래스가 존재할 수 있다는 가정을 하지 않기 때문에, 알 수 없는 타겟 샘플까지 소스 샘플에 정렬시켜 알 수 없는 샘플 탐지를 어렵게 만듭니다.
- **개방형 세트 인식(Open Set Recognition):** 학습 시 주어지지 않은 '알 수 없는' 샘플을 테스트 시 '알 수 없음'으로 거부하면서 '알려진' 샘플은 올바르게 분류하는 것을 목표로 합니다.
  - **주요 방법:** Multi-class open set SVM [24], OpenMax 레이어 [25], GAN을 이용한 알 수 없는 샘플 생성 [26] 등이 있습니다.
  - **한계:** 대부분의 기존 방법은 훈련 시 알 수 없는 샘플에 대한 명시적인 감독(supervision)을 받지 않으며, 도메인 적응 문제에서 발생하는 도메인 시프트(domain shift) 상황을 고려하지 않습니다.

## 🛠️ Methodology

본 논문은 특징 생성기(Generator, G)와 분류기(Classifier, C)로 구성된 새로운 적대적 학습 프레임워크를 제안합니다. 분류기 C는 $K$개의 알려진 클래스와 1개의 알 수 없는 클래스를 포함하는 총 $K+1$차원의 확률을 출력합니다.

1. **모델 구성 요소:**

   - **특징 생성기 (G):** 입력 이미지 $x_s$ 또는 $x_t$로부터 특징을 생성합니다.
   - **분류기 (C):** 생성된 특징을 입력받아 $K+1$차원 확률 분포 $p(y|x)$를 출력합니다. $1 \sim K$ 차원은 알려진 클래스 확률, $K+1$ 차원은 알 수 없는 클래스 확률을 나타냅니다.

2. **학습 목표 및 절차:**

   - **소스 샘플($x_s, y_s$) 분류:** 분류기 C와 생성기 G는 표준 교차 엔트로피 손실 $L_s(x_s, y_s)$를 사용하여 소스 샘플을 올바르게 분류하도록 훈련됩니다.
     $$ L_s(x_s,y_s) = -\log(p(y=y_s|x_s)) $$
   - **타겟 샘플($x_t$)에 대한 적대적 학습:**
     - **분류기 C의 목표:** 타겟 샘플 $x_t$에 대해 알 수 없는 클래스 확률 $p(y=K+1|x_t)$이 상수 $t$ (여기서 $0 < t < 1$, 실험에서 $t=0.5$ 사용)가 되도록 이진 교차 엔트로피 손실 $L_{adv}(x_t)$를 최소화합니다. 이는 알 수 없는 클래스에 대한 가상의 결정 경계를 생성하는 역할을 합니다.
       $$ L\_{adv}(x_t) = -t\log(p(y=K+1|x_t))-(1-t)\log(1-p(y=K+1|x_t)) $$
     - **생성기 G의 목표:** 분류기 C를 속여 $L_{adv}(x_t)$를 최대화합니다. 즉, $p(y=K+1|x_t)$가 $t$와 다른 값을 가지도록 만듭니다. 이를 통해 생성기 G는 두 가지 선택지를 가지게 됩니다:
       - $p(y=K+1|x_t)$를 $t$보다 낮춰 소스 샘플과 정렬시킵니다 (알려진 타겟 샘플의 경우).
       - $p(y=K+1|x_t)$를 $t$보다 높여 타겟 샘플을 '알 수 없음'으로 거부합니다 (알 수 없는 타겟 샘플의 경우).
   - **최종 손실 함수:**
     - 분류기 C는 $\min_C L_s(x_s,y_s) + L_{adv}(x_t)$를 최소화합니다.
     - 생성기 G는 $\min_G L_s(x_s,y_s) - L_{adv}(x_t)$를 최소화합니다.
   - **구현:** 기울기 역전 레이어(Gradient Reversal Layer) [4]를 활용하여 분류기와 생성기의 매개변수를 동시에 효율적으로 업데이트합니다.

3. **기존 방법과의 차별점:**
   - 훈련 데이터에 알 수 없는 타겟 샘플이 포함되어 있음(어떤 샘플이 알 수 없는지 명시적으로 알지 못해도)을 활용하여, 특징 추출기가 알 수 없는 샘플을 거부하는 표현을 학습할 수 있습니다.
   - 기존 방법들이 고정된 임계값을 사용하는 것과 달리, 본 방법은 샘플마다 다른 분류 출력을 할당하여 동적으로 결정 경계를 형성합니다.
   - 특징 추출기가 알려진 클래스와 알 수 없는 클래스 사이의 가상 결정 경계를 인식하고, 이에 따라 알려진 소스 샘플과 유사한 샘플은 정렬시키고 유사하지 않은 샘플은 분리하도록 학습합니다.

## 📊 Results

제안된 방법은 Office, VisDA, Digits 데이터셋에서 광범위하게 평가되었으며, OSVM, MMD+OSVM, BP+OSVM과 같은 기준선들을 대부분의 시나리오에서 큰 폭으로 능가했습니다.

- **Office 데이터셋 (10개 공유 클래스 및 20개 공유 클래스 시나리오):**
  - AlexNet 및 VGGNet 기반 실험 모두에서 기준선보다 일관되게 높은 OS (전체 클래스 평균 정확도) 및 OS\* (알려진 클래스만 평균 정확도) 점수를 달성했습니다.
  - MMD 및 BP와 같은 기존 분포 매칭 방법은 알 수 없는 타겟 샘플의 존재로 인해 성능 향상에 어려움을 겪거나 오히려 저하되는 경향을 보였습니다.
  - t-SNE 특징 시각화를 통해, 본 방법은 알 수 없는 타겟 샘플을 알려진 샘플로부터 명확하게 분리하는 반면, 기존 방법들은 모든 타겟 샘플을 소스 샘플과 정렬시키려는 경향을 보임을 확인했습니다.
  - 타겟 도메인 내 알 수 없는 샘플의 비율과 학습 신호 $t$ 값의 변화에 대한 강건성을 입증했습니다. $t$가 1에 가까워질수록 모델이 알 수 없는 샘플을 잘 분리하지 못하고 전체 정확도가 감소하는 현상을 관찰했습니다.
- **VisDA 데이터셋 (합성 이미지에서 실제 이미지로의 적응):**
  - 대부분의 클래스와 평균 정확도("Avg", "Avg known")에서 다른 방법들을 능가했습니다.
  - 알려진 클래스(자전거, 버스, 자동차 등)와 알 수 없는 클래스(비행기, 말, 칼 등)가 뚜렷이 다른 경우, 알 수 없는 클래스에 대한 정확도가 더 높게 나타나 분리 능력을 시사했습니다.
  - 일부 잘못 분류된 예시를 통해, 이미지 내 다중 객체 또는 객체 가려짐이 분류를 어렵게 만들 수 있음을 보였습니다.
- **Digits 데이터셋 (SVHN-MNIST, USPS-MNIST, MNIST-USPS):**
  - 0-4를 알려진 클래스로, 5-9를 알 수 없는 클래스로 설정한 실험에서 제안된 방법이 다른 기준선들을 크게 앞섰습니다.
  - 특히 USPS-MNIST 및 MNIST-USPS 시나리오에서 높은 정확도를 보였으며, 도메인 차이가 큰 SVHN-MNIST에서도 우수했습니다.
- **반지도 학습 개방형 세트 인식 적용:**
  - 도메인 시프트가 없는 환경에서, 레이블이 지정된 알려진 샘플과 레이블 없는 알 수 없는 샘플이 주어졌을 때도 OSVM보다 우수한 성능을 보였습니다.
  - 'Ours + OSVM' 조합이 단독 'Ours'보다 성능이 극적으로 향상된 경우도 있었는데, 이는 생성기가 좋은 표현을 학습했으나 분류기가 특정 상황에서 최적으로 훈련되지 않았을 가능성을 시사합니다.

## 🧠 Insights & Discussion

- **알 수 없는 샘플 분리 메커니즘:** 본 연구의 핵심은 특징 생성기가 알 수 없는 타겟 샘플을 알려진 타겟 샘플로부터 분리하는 표현을 학습할 수 있다는 점입니다. 이는 분류기가 타겟 샘플을 '알 수 없음'으로 분류할 확률을 $t$로 설정하도록 학습되는 적대적 프레임워크 덕분입니다. 생성기는 분류기를 속이기 위해 알려진 샘플은 소스에 정렬하고, 알 수 없는 샘플은 $t$ 값에서 멀어지도록(주로 높은 알 수 없음 확률을 가지도록) 밀어냅니다.
- **실용성 증대:** '알 수 없는 소스 샘플'을 요구하지 않는다는 점에서 기존 OSDA 방법보다 실제 적용 가능성이 훨씬 높습니다. 이는 "알 수 없음"이라는 개념 자체를 정의하기 위한 방대한 양의 알 수 없는 소스 샘플 수집 비용을 절감합니다.
- **$t$ 값의 역할:** 상수 $t$의 선택은 모델의 거부 기준에 중요한 영향을 미칩니다. $t$가 1에 가까워지면 모든 타겟 샘플을 소스에 정렬시키려는 기존 도메인 적응 방법과 유사해져, 알 수 없는 샘플의 분리 능력이 저하됩니다. $t=0.5$는 알려진/알 수 없는 결정의 균형점을 제공하는 효과적인 선택으로 확인되었습니다.
- **제한 사항 및 향후 연구:** 본 방법은 대부분의 경우 뛰어난 성능을 보였지만, VisDA 데이터셋의 특정 이미지(다중 객체, 가려진 객체)나 SVHN-MNIST와 같이 도메인 차이가 매우 큰 시나리오에서는 개선의 여지가 있었습니다. 향후 연구에서는 이러한 상황에서의 성능 향상과 더 일반적인 개방형 세트 인식 문제로의 확장을 모색할 수 있을 것입니다.

## 📌 TL;DR

본 논문은 알 수 없는 소스 샘플 없이 타겟 도메인의 미지 클래스를 효과적으로 식별해야 하는 도전적인 개방형 세트 도메인 적응(OSDA) 문제를 해결합니다. 저자들은 특징 생성기(G)와 분류기(C)를 포함하는 새로운 적대적 학습 방법론을 제안합니다. 분류기 C는 알려진 소스 샘플을 정확히 분류하고, 타겟 샘플에 대해서는 알 수 없는 클래스 확률을 상수 $t$로 예측하도록 훈련됩니다. 반면 생성기 G는 분류기를 속여 오류를 최대화하는데, 이는 알려진 타겟 샘플은 소스에 정렬시키고, 알 수 없는 타겟 샘플은 '알 수 없음'으로 거부하는 이중적인 선택지를 가짐으로써 달성됩니다. 이 방법은 특징 생성기가 알 수 없는 타겟 샘플을 알려진 샘플로부터 효과적으로 분리하는 표현을 학습하게 합니다. Office, VisDA, Digits 데이터셋에 대한 광범위한 실험을 통해 제안된 방법이 기존 기준선들을 크게 능가하며, 실제 환경에서 레이블 없는 데이터를 효과적으로 활용할 수 있음을 입증했습니다.
