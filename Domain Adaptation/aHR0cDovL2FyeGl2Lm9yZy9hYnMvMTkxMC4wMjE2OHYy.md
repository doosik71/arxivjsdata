# CROSS LINGUAL TRANSFER LEARNING FOR ZERO-RESOURCE DOMAIN ADAPTATION

Alberto Abad, Peter Bell, Andrea Carmantini, Steve Renals

## 🧩 Problem to Solve

자동 음성 인식(ASR) 분야에서 딥 뉴럴 네트워크(DNN) 모델의 출현에도 불구하고, 다양한 사용 도메인에서 견고하게 작동하는 음향 모델을 구축하는 것은 여전히 어려운 과제입니다. 특히, 저-자원화된 언어(Low-Resourced Language, LR)의 경우, 타겟 도메인에서 전사된(transcribed) 훈련 데이터가 전혀 없거나 매우 제한적인 상황이 많습니다. 기존의 DNN 도메인 적응 방법들은 대개 타겟 도메인의 일부 전사 데이터를 가정하지만, 이는 LR 언어에는 적용하기 어렵습니다. 본 연구는 이러한 '제로-리소스 도메인 적응' 시나리오, 즉 LR 언어에 대한 타겟 도메인 훈련 데이터가 전혀 없는 상황에서 ASR 시스템의 성능을 향상시키는 방법을 제안합니다.

## ✨ Key Contributions

- **교차 언어 도메인 적응 방법론 제안**: 잘-자원화된 언어(Well-Resourced Language, WR)에서 학습된 특정 도메인 변환을 LR 언어로 전이시켜, LR 언어에 대한 어떠한 타겟 도메인 훈련 데이터도 없이 ASR 시스템 성능을 향상시키는 새로운 접근 방식을 제시합니다.
- **다국어 공유 레이어 DNN 아키텍처**: DNN의 초기 레이어가 언어 독립적인 음향 특성을 인코딩한다는 가설을 바탕으로, 파라미터 변환을 LR 및 WR 언어 간에 의미 있게 공유할 수 있는 다국어 네트워크 아키텍처를 설계했습니다.
- **높은 WER 개선율 달성**: 영어-스페인어 실험에서 스페인어 방송 뉴스(BN) 타겟 도메인 데이터에 대해 $29\%$의 상대적 WER(Word Error Rate) 개선을 달성했습니다. 이는 LR 훈련 데이터 부족으로 인한 성능 손실의 약 $50\%$를 복구한 수치입니다.
- **다양한 LR 언어에 대한 효과 입증**: 영어와 덜 관련된 타갈로그어 및 리투아니아어와 같은 LR 언어에서도 $18-27\%$의 상대적 WER 개선을 보여, 제안된 방법론의 일반성과 견고성을 입증했습니다.
- **타 방법론 대비 우수성**: 다중 작업(multi-task) 및 다중 조건(multi-condition) 훈련 기반의 다른 교차 언어 접근 방식들보다 잘-자원화된 언어 데이터를 더 효과적으로 활용하여 LR 타겟 도메인의 음향 모델링을 개선했습니다.

## 📎 Related Works

본 연구는 DNN 도메인 적응 분야의 여러 기존 연구에서 영감을 받았습니다.

- **DNN 도메인 적응**:
  - 데이터 증강(Data augmentation) [1].
  - i-벡터 [2], 후처리(posterior) 또는 병목(bottleneck) 특징 [3, 4]과 같은 보조 특징 사용.
  - 선택된 파라미터 적응 (예: LHUC [6], LIN [18], Factorized Hidden Layer Adaptation [7]).
  - 적대적 방법(Adversarial methods) [8].
- **준-지도 학습(Semi-supervised learning) 접근 방식**: 전사되지 않은 타겟 도메인 데이터를 자동으로 전사하여 활용하는 방법 [9, 10, 11]이 있지만, 이는 원본 시스템 성능에 민감하고 많은 연산 비용이 필요합니다.
- **다중 작업(Multi-task) 및 다국어(Multi-lingual) 학습**: 여러 작업을 동시에 학습하기 위해 초기 레이어를 공유하는 방식 [13, 14, 15]과 이를 ASR에서 다국어 네트워크 학습에 적용한 연구 [16, 17]들이 있습니다.

## 🛠️ Methodology

본 연구에서 제안하는 교차 언어 도메인 적응 방법은 DNN 기반 음향 모델에 대한 세 단계의 프로세스를 따릅니다.

1. **다국어 훈련 (Multi-lingual training)**:
    - LR 언어와 WR 언어 모두의 소스 도메인(예: 대화형 전화 음성, CTS) 데이터를 사용하여 초기 다국어 네트워크를 훈련합니다.
    - 네트워크 아키텍처는 여러 개의 **공유(shared) 초기 TDNN 레이어**와 각 언어에 특화된 **최종 레이어**로 구성됩니다. 이 공유 레이어는 언어 독립적인 하위 수준 음향 정보를 인코딩한다고 가정합니다.
    - 각 언어의 음소(senone) 분류를 목표로 하는 다중 작업 학습 방식을 사용합니다.

2. **도메인 적응 (Domain adaptation)**:
    - WR 언어의 타겟 도메인(예: 방송 뉴스, BN) 데이터만을 사용하여 다국어 네트워크의 **공유 레이어**의 가중치를 적응시킵니다.
    - 이때, 언어 특화 최종 레이어는 **고정**(freezing)된 상태를 유지합니다.
    - 이는 새로 적응될 변환이 언어 독립적이며 타겟 도메인의 특정 음향 특성과 관련될 것이라는 가설에 근거합니다.
    - 단순 역전파(backpropagation) 업데이트를 사용하여 가중치를 조정하며, 실험 결과 3개의 첫 번째 은닉 공유 레이어를 1 에포크 동안 적응시키는 것이 최적의 성능을 보였습니다.

3. **가중치 전이 (Weight transfer)**:
    - 적응된 공유 레이어의 가중치를 원래 LR 언어 네트워크의 최종, 언어 종속 레이어에 전이시킵니다.
    - 이 과정을 통해 LR 언어는 타겟 도메인에 적응된 음향 모델을 얻게 되며, LR 타겟 도메인 데이터는 전혀 사용되지 않습니다.

**실험 환경**:

- **툴킷**: Kaldi
- **음향 특징**: 40차원 고해상도 MFCC와 3차원 피치/음성 관련 특징을 사용하며, 모든 데이터는 8kHz로 다운샘플링되어 훈련 및 평가됩니다.
- **네트워크 아키텍처**: 7개의 TDNN 은닉 레이어(각 650 유닛, ReLU 활성화)를 공유 레이어로 사용하고, 각 언어에 대해 650 유닛의 최종 완전 연결 레이어(ReLU)와 Softmax 레이어를 추가합니다.
- **언어 모델(LM)**: ASR 디코딩 시 항상 도메인 일치 언어 모델을 사용하며, 이는 텍스트 데이터가 전사 음성 데이터보다 획득하기 쉽다는 가정을 바탕으로 합니다.

## 📊 Results

- **영어-스페인어 실험 (WR: 영어, LR: 스페인어)**:
  - 소스 도메인(CTS)에서 훈련된 단일 언어 모델이 타겟 도메인(BN) 스페인어 데이터 디코딩 시 $40.0\%$의 높은 WER을 보였습니다. (오라클 BN 모델의 $19.2\%$ 대비)
  - CTS 소스 도메인 데이터로 **다국어 훈련**만으로 스페인어 BN WER을 $40.0\%$에서 $32.9\%$로 감소시켰습니다 ($17.8\%$ 상대적 개선).
  - 여기에 **제안된 교차 언어 도메인 적응 방법** (WR BN 데이터를 사용한 공유 레이어 적응)을 적용했을 때, 스페인어 WER은 $32.9\%$에서 $28.4\%$로 더욱 감소했습니다. 이는 초기 $40.0\%$ 대비 $29\%$의 상대적 WER 개선에 해당합니다.
  - 다른 교차 언어 접근 방식(다중 작업, 다중 조건)과 비교했을 때, 제안된 방법이 WR 데이터를 LR 타겟 도메인 음향 모델링에 더 효과적으로 활용하여 우수한 성능을 보였습니다.

- **MATERIAL 언어 실험 (LR: 타갈로그어, 리투아니아어)**:
  - 영어와 덜 관련되어 있고, 소스-타겟 도메인 조건 매칭이 좋지 않은 타갈로그어와 리투아니아어에 대해서도 유의미한 개선을 달성했습니다.
  - **타갈로그어**: 광대역 조건 평균 WER이 $57.3\%$에서 $46.8\%$로 감소 ($18.3\%$ 상대적 개선).
  - **리투아니아어**: 광대역 조건 평균 WER이 $44.0\%$에서 $31.9\%$로 감소 ($27.5\%$ 상대적 개선).
  - 특히 방송 뉴스(BN) 서브 조건에서 타갈로그어 $21.2\%$, 리투아니아어 $30.7\%$의 더 높은 상대적 WER 개선을 보였습니다.

## 🧠 Insights & Discussion

- **초기 레이어의 언어 독립성 확인**: DNN의 초기 레이어가 언어와 무관하게 기본적인 음향 특성을 인코딩한다는 가설을 실험적으로 입증했습니다. 이는 WR 언어에서 학습된 도메인 적응 지식을 LR 언어로 성공적으로 전이하는 핵심 메커니즘이 됩니다.
- **제로-리소스 문제의 효과적인 해결**: LR 언어에 대한 타겟 도메인 훈련 데이터가 전혀 없는 상황에서 ASR 성능을 크게 향상시킬 수 있는 실용적이고 효과적인 방법론을 제시합니다. 이는 저자원 언어 ASR 개발에 큰 의미를 가집니다.
- **전이 정보의 한계**: WR 언어에서 LR 언어로 전이 가능한 정보의 양에는 한계가 있는 것으로 보입니다. WR 언어의 성능은 적응 레이어 및 에포크 증가에 따라 지속적으로 향상되는 경향을 보이는 반면, LR 언어의 성능은 특정 지점 이후로는 덜 민감한 반응을 보였습니다.
- **향후 연구 방향**:
  - 현재의 프레임 레벨(frame-level) 교차 엔트로피 훈련 방식을 시퀀스 훈련 모델(sequence-trained models)로 확장.
  - 다국어 다중 도메인 데이터로 훈련된 병목 특징(bottleneck features)이나 SAT 벡터 기반 접근 방식(예: i-벡터)과 같은 다른 교차 언어 정보 전이 방법과의 결합을 탐구하여 추가적인 성능 향상을 모색할 수 있습니다.

## 📌 TL;DR

LR 언어에 대한 타겟 도메인 데이터가 전혀 없는 '제로-리소스 도메인 적응' 문제를 해결하기 위해, 다국어 네트워크 구조를 활용한 교차 언어 전이 학습 방법을 제안합니다. 이 방법은 WR 언어(예: 영어)의 타겟 도메인 데이터를 사용하여 다국어 DNN의 공유 레이어를 적응시키고, 이 학습된 변환을 LR 언어(예: 스페인어, 타갈로그어, 리투아니아어)로 전이합니다. 실험 결과, 스페인어 BN 도메인에서 $29\%$의 상대적 WER 개선을 달성했으며, 다른 LR 언어에서도 $18-27\%$의 유의미한 개선을 보여, 타겟 도메인 LR 데이터 없이도 효과적인 도메인 적응이 가능함을 입증했습니다.
