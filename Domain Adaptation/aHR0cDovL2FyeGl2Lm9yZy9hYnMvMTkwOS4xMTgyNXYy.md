# UNSUPERVISED DOMAIN ADAPTATION THROUGH SELF-SUPERVISION

Yu Sun, Eric Tzeng, Trevor Darrell, Alexei A. Efros

## 🧩 Problem to Solve

본 논문은 비지도 도메인 적응(Unsupervised Domain Adaptation, UDA) 문제를 다룹니다. 이 설정에서는 레이블이 지정된 훈련 데이터는 소스 도메인에만 존재하며, 타겟 도메인에는 레이블이 없는 데이터만 주어집니다. 목표는 소스 도메인에서 학습된 모델이 레이블이 없는 타겟 도메인에서도 우수한 성능을 보이는 것입니다. 기존 UDA 방법들은 주로 특징 공간의 분포 불일치를 최소화하기 위해 최대 평균 불일치(Maximum Mean Discrepancy, MMD)나 적대적 학습(Adversarial Learning)을 사용하지만, 이러한 방법들은 minimax 최적화 문제를 수반하여 훈련이 어렵고 불안정하며 하이퍼파라미터 튜닝이 까다롭다는 문제가 있습니다.

## ✨ Key Contributions

- **자기 지도 학습을 통한 도메인 정렬**: 지도 학습 없이도 소스 및 타겟 도메인의 특징 표현을 효과적으로 정렬하기 위해 자기 지도(self-supervised) 보조 과제를 활용하는 새로운 접근 방식을 제안합니다.
- **Minimax 최적화 회피**: 기존 UDA 방법의 복잡하고 불안정한 minimax 최적화 문제를 완전히 피하고, 간단하고 안정적인 최적화 알고리즘을 사용하여 도메인 적응을 수행합니다.
- **자기 지도 과제 설계 가이드라인 제시**: 도메인 적응에 적합한 자기 지도 과제(예: 회전, 뒤집기, 패치 위치 예측)를 선택하고 설계하는 방법에 대한 통찰력을 제공하며, 픽셀 재구성 과제(예: 컬러화, 인페인팅)의 부적합성을 지적합니다.
- **공동 학습 프레임워크**: 주 과제(소스 도메인에서 지도 학습)와 여러 자기 지도 보조 과제(양 도메인에서 학습)를 동시에 공동 학습하는 방법을 제안합니다.
- **SOTA(State-of-the-Art) 성능 달성**: 7개의 표준 벤치마크 중 4개에서 최신 성능을 달성했으며, 의미론적 분할(semantic segmentation) 적응에서도 경쟁력 있는 결과를 보여줍니다.
- **다른 적응 방법과의 조합 가능성**: 픽셀 수준 적응 방법(예: CyCADA)과도 잘 결합되어 추가 성능 향상을 입증합니다.
- **하이퍼파라미터 튜닝 및 조기 종료 휴리스틱**: 타겟 레이블이 없는 UDA 설정에서 활용할 수 있는 간단하고 실용적인 하이퍼파라미터 튜닝 및 조기 종료 휴리스틱을 제안합니다.

## 📎 Related Works

- **비지도 도메인 적응(Unsupervised Domain Adaptation)**:
  - **특징 공간 정렬**: 소스 및 타겟 도메인의 특징 분포를 정렬하는 것을 목표로 합니다.
    - **MMD 기반**: 재현 커널 힐베르트 공간(Reproducing Kernel Hilbert Space)에서 두 도메인 평균 간의 거리를 최소화 (Long et al., 2015; 2017).
    - **적대적 학습 기반**: 도메인 분류기를 훈련하여 특징 추출기가 소스와 타겟을 구별하지 못하게 학습 (Ganin et al., 2016; Tzeng et al., 2017).
    - 이들은 모두 minimax 최적화 문제로, 훈련의 어려움과 불안정성이라는 단점을 가집니다.
  - **이미지 변환**: 생성 모델을 사용하여 소스 이미지를 타겟 도메인 이미지처럼 변환 (Hoffman et al., 2017).
  - **가상 레이블/자체 앙상블**: 소스에서 훈련된 모델로 타겟 데이터에 가상 레이블을 추정하여 학습 (Saito et al., 2017).
- **자기 지도 특징 학습(Self-Supervised Feature Learning)**:
  - 레이블이 없는 데이터에서 자체적으로 레이블을 생성하여 보조(pretext) 과제를 해결함으로써 유용한 특징 표현을 학습하는 분야입니다. 예시로는 컬러화 (Zhang et al., 2016b), 이미지 인페인팅 (Pathak et al., 2016), 직소 퍼즐 해결 (Noroozi & Favaro, 2016), 이미지 회전 예측 (Gidaris et al., 2018) 등이 있습니다.
  - 대부분의 기존 자기 지도 학습 연구는 사전 학습(pre-training) 단계로 활용되었으나, 본 논문은 자기 지도 과제를 주 과제와 함께 공동으로 학습한다는 점에서 차이가 있습니다.
  - Ghifary et al. (2016)은 UDA에 자기 지도 학습을 사용했지만, 타겟 데이터에만 denoising autoencoder를 적용하여 본 논문과는 다른 철학과 성능을 보입니다.

## 🛠️ Methodology

본 논문은 선택된 $K$개의 자기 지도 과제를 사용하여 다음 최적화 문제를 해결합니다.

1. **자기 지도 과제 선택**: 도메인 적응에 적합한 자기 지도 과제는 도메인 간의 무의미한 시각적 차이(예: 밝기, 색상)에 덜 민감해야 합니다. 픽셀 수준 재구성 과제(예: 컬러화, 인페인팅, 노이즈 제거 오토인코더)는 이러한 차이를 부각시켜 도메인 분리를 유발할 수 있으므로 부적합하다고 판단하며, 구조적 정보를 예측하는 분류 기반 과제를 선호합니다.

   - **회전 예측 (Rotation Prediction)**: 입력 이미지를 0°, 90°, 180°, 270°로 회전시킨 후, 모델이 원래 회전 각도를 예측하도록 훈련합니다.
   - **뒤집기 예측 (Flip Prediction)**: 이미지를 무작위로 수직 뒤집기 한 후, 뒤집기 여부를 예측하도록 훈련합니다. (수평 뒤집기는 일반적으로 데이터 증강에 사용되므로 제외).
   - **패치 위치 예측 (Patch Location Prediction)**: 이미지에서 무작위로 잘라낸 패치가 어디에서 왔는지 예측합니다. 작은 이미지에서는 4사분면 분류 문제로, 큰 이미지에서는 2차원 회귀 문제로 접근합니다.

2. **공동 학습 프레임워크**:

   - **아키텍처**: 모든 과제(주 과제 $L_0$ 및 자기 지도 과제 $L_k$)는 공통 특징 추출기 $\phi$를 공유하며, 각 과제에는 전용의 낮은 용량의 헤드 $h_k$가 연결됩니다. 이는 헤드들이 고수준 특징을 공유하도록 강제하여 정렬을 유도합니다.
   - **손실 함수**: 주 예측 과제 $L_0$는 레이블이 있는 소스 데이터 $S$에 대해 적용되며, 각 자기 지도 과제 $L_k$는 소스 $S$와 타겟 $T$ 양쪽에서 생성된 자기 지도 샘플에 대해 적용됩니다. 전체 최적화 목표는 다음과 같습니다:
     $$ \min*{\phi, h_k, k=0...K} \mathcal{L}\_0(S; \phi, h_0) + \sum*{k=1}^K \mathcal{L}_k(S, T; \phi, h_k) $$
     여기서 $\mathcal{L}\_0(S; \phi, h_0) = \sum_{(x,y) \in S} \mathcal{L}_0(h_0(\phi(x)), y)$ 이고,
     $\mathcal{L}\_k(S, T; \phi, h_k) = \sum_{(f*k(x), \tilde{y}) \in \mathcal{F}\_k(S)} \mathcal{L}\_k(h_k(\phi(f_k(x))), \tilde{y}) + \sum*{(f_k(x), \tilde{y}) \in \mathcal{F}\_k(T)} \mathcal{L}\_k(h_k(\phi(f_k(x))), \tilde{y})$ 입니다.
   - **훈련 절차**: SGD를 사용하여 모델을 최적화합니다. 자기 지도 과제의 배치 샘플링 시, 소스와 타겟 도메인에서 각각 절반씩 샘플을 가져와 균형을 유지합니다. 이는 어느 한 도메인이 특징 학습을 지배하지 않도록 합니다.

3. **하이퍼파라미터 튜닝 및 조기 종료 휴리스틱**: UDA 설정에서는 타겟 레이블이 없으므로 검증 세트를 사용할 수 없습니다. 따라서, 본 논문은 다음의 휴리스틱을 제안합니다:
   - 학습된 특징 공간에서 소스와 타겟 검증 세트 간의 평균 거리(선형 MMD) $D(S', T'; \phi) = \left\| \frac{1}{m}\sum_{x \in S'}\phi(x) - \frac{1}{n}\sum_{x \in T'}\phi(x) \right\|_2$를 계산합니다.
   - 소스 검증 세트에서의 주 과제 오류와 위 평균 거리를 각각 정규화한 후 합산하여 최소가 되는 에포크에서 조기 종료합니다. 이는 모델이 판별력을 유지하면서도 도메인 정렬을 유도하도록 합니다.

## 📊 Results

- **객체 인식 벤치마크**:
  - 7개의 표준 도메인 적응 벤치마크(예: MNIST→MNIST-M, CIFAR-10→STL-10) 중 4개에서 SOTA 성능을 달성했습니다.
  - 특히 자연스러운 장면 객체 인식 벤치마크에서는 회전, 위치, 뒤집기 3가지 자기 지도 과제를 모두 사용했을 때 뛰어난 성능 향상을 보였습니다.
  - SVHN 벤치마크에서는 자기 지도 회전 과제가 주변부의 인접한 숫자 조각을 보고 속이는 방식으로 풀려 성능이 저하되는 실패 사례가 발생했으며, 이는 자기 지도 과제의 설계가 해당 애플리케이션에 적합해야 함을 시사합니다.
- **의미론적 분할 벤치마크 (GTA5→Cityscapes)**:
  - 소스 전용 기준선(mIoU 25.3%) 대비 유의미한 성능 향상(mIoU 28.9%)을 보였습니다.
  - 픽셀 수준 적응 방법인 CyCADA와 결합했을 때, CyCADA 단독 성능(mIoU 39.5%)보다 더욱 향상된 성능(mIoU 41.2%)을 달성하여, 본 방법이 다른 적응 전략과 상호 보완적으로 작동할 수 있음을 입증했습니다.

## 🧠 Insights & Discussion

- **자기 지도 학습의 새로운 지평**: 본 연구는 비지도 도메인 적응 문제에서 적대적 학습의 대안으로 자기 지도 학습의 강력한 잠재력을 보여줍니다. 자기 지도 학습은 minimax 최적화의 복잡성과 불안정성을 피하고, 더 간단하고 안정적인 훈련 과정을 제공합니다.
- **자기 지도 과제 설계의 중요성**: 자기 지도 과제의 성공은 해당 애플리케이션의 도메인 특성과 주 과제에 대한 적합성에 크게 좌우됩니다. 도메인 전문 지식을 활용하여 특정 애플리케이션에 맞는 자기 지도 과제를 설계하는 것이 중요합니다.
- **향후 연구 방향**: 현재 자기 지도 과제들은 주로 이미지 분류를 위해 설계되었지만, 의미론적 분할과 같은 픽셀 수준 과제에는 더 적합한 새로운 자기 지도 과제를 개발하는 것이 필요합니다. 또한, 타겟 도메인의 샘플 수가 매우 적을 때 적대적 학습 기반 방법보다 본 방법이 더 유리할 수 있는 가능성이 있으며, 이는 추가 연구 주제가 될 수 있습니다.

## 📌 TL;DR

**문제**: 레이블된 소스 데이터와 레이블 없는 타겟 데이터 간의 분포 차이로 인해 모델 성능이 저하되는 비지도 도메인 적응(UDA)의 어려움. 기존 방법은 불안정한 minimax 최적화에 의존하여 학습이 어렵고 불안정합니다.

**제안 방법**: 본 논문은 이러한 문제를 해결하기 위해 여러 자기 지도(self-supervised) 과제를 소스 및 타겟 도메인 모두에서 주 분류 과제와 함께 공동으로 학습하는 새로운 접근 방식을 제안합니다. 이미지 회전, 뒤집기, 패치 위치 예측과 같은 구조적 분류 과제를 활용하여 도메인 간의 무의미한 시각적 차이에 덜 민감한 특징 표현을 학습하고, 특징 공간에서 두 도메인을 정렬합니다. 모든 과제는 공유 특징 추출기와 저용량 헤드를 통해 안정적으로 훈련됩니다.

**주요 결과**: 제안된 방법은 간단한 구현에도 불구하고 7개 객체 인식 벤치마크 중 4개에서 SOTA 성능을 달성했으며, 의미론적 분할에서도 유의미한 개선을 보였습니다. 또한, 기존 픽셀 수준 적응 방법과도 효과적으로 결합되어 추가 성능 향상을 입증했습니다. 이 연구는 불안정한 적대적 학습을 피하면서 안정적이고 효율적인 도메인 적응을 가능하게 하는 자기 지도 학습의 강력한 잠재력을 보여줍니다.
