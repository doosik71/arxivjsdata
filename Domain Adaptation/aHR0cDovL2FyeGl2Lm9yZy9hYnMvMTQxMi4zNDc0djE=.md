# Deep Domain Confusion: Maximizing for Domain Invariance

Eric Tzeng, Judy Hoffman, Ning Zhang, Kate Saenko, Trevor Darrell

## 🧩 Problem to Solve

최근 심층 CNN(Convolutional Neural Network) 모델은 대규모 데이터셋으로 훈련될 경우 데이터셋 편향(dataset bias)을 줄여주지만 완전히 제거하지는 못합니다. 새로운 도메인에서 심층 모델을 미세 조정(fine-tuning)하려면 상당한 양의 데이터가 필요하지만, 많은 애플리케이션에서는 이러한 데이터를 확보하기 어렵습니다. 기존의 심층 모델 도메인 적응(domain adaptation) 방법은 고정된 표현(representation) 중에서 선택하거나, 얕은 모델에 국한되어 심층 CNN의 강력한 의미론적 표현 능력을 충분히 활용하지 못했습니다.

## ✨ Key Contributions

- **새로운 CNN 아키텍처 제안**: 분류 손실(classification loss)과 도메인 불변성(domain invariance)을 동시에 최적화하기 위해 적응 계층(adaptation layer)과 추가적인 도메인 혼동 손실(domain confusion loss)을 도입한 CNN 아키텍처를 제안했습니다.
- **도메인 혼동 측정 지표(MMD) 활용**: Maximum Mean Discrepancy (MMD)를 기반으로 하는 도메인 혼동 측정 지표를 사용하여 적응 계층의 차원(dimension)과 CNN 아키텍처 내에서의 최적 위치(depth)를 결정하는 모델 선택 방법론을 제시했습니다.
- **최첨단 성능 달성**: 표준 벤치마크 시각 도메인 적응 태스크에서 이전의 모든 공개된 결과들을 능가하는 경험적 성능을 보였습니다. 특히, 미세 조정 과정에서 MMD를 정규화 항으로 사용하여 데이터셋 편향에 강건한 표현을 학습했습니다.
- **지도 및 비지도 적응 지원**: 제안된 방법이 소량의 레이블된 타겟 데이터가 있는 지도 적응(supervised adaptation)과 레이블된 타겟 데이터가 없는 비지도 적응(unsupervised adaptation) 시나리오 모두에 효과적임을 입증했습니다.

## 📎 Related Works

- **데이터셋 편향 및 도메인 적응**: Torralba와 Efros [32]에 의해 대중화된 문제이며, 소스 및 타겟 데이터 분포의 차이를 극복하기 위한 다양한 방법이 제안되었습니다 [10, 33, 2, 29, 25, 22, 17, 16, 19, 20].
- **심층 특징 기반 적응**: ImageNet에서 학습된 심층 중간 계층 특징이 도메인 편향을 효과적으로 제거함을 보여주었습니다 [11, 21].
- **병렬 CNN 아키텍처**: Siamese 네트워크 [7, 9]는 불변 표현 학습에 효과적이지만, 훈련 인스턴스마다 레이블이 필요하여 비지도 설정에는 적용하기 어렵습니다.
- **다중 모달 심층 학습**: 서로 다른 입력 모달리티에 불변하는 표현을 학습하기 위해 탐구되었지만 [27], 주로 생성적 맥락에서 작동하여 지도 CNN의 표현력을 활용하지 못했습니다.
- **MMD 기반 도메인 적응**: [14]는 denoising autoencoder와 MMD 도메인 혼동 손실을 사용하여 얕은 네트워크에서 도메인 불변 표현을 학습했지만, 심층 CNN의 강력한 의미론적 표현 능력이 부족했습니다.
- **심층 아키텍처의 한계**: [8]은 소스 및 타겟 CNN 아키텍처를 공동으로 훈련하는 것을 제안했으나, 두 계층으로 제한되어 ImageNet [4]으로 사전 훈련된 더 깊은 아키텍처에 비해 성능이 현저히 낮았습니다.

## 🛠️ Methodology

본 논문은 Krizhevsky 아키텍처 [24]를 기반으로, 적응 계층(adaptation layer)을 추가하고 도메인 혼동 손실(domain confusion loss)을 활용하여 도메인 불변적인 표현을 학습합니다.

1. **목표 함수**: 분류 정확도($L_C$)를 최소화하고 동시에 도메인 간의 거리를 최소화하여 도메인 불변성을 최대화하는 종합적인 손실 함수를 정의합니다. 도메인 간의 거리 측정에는 Maximum Mean Discrepancy (MMD) [6]가 사용됩니다.
   $$
   L = L_C(X_L, y) + \lambda \text{MMD}^2(X_S, X_T)
   $$
   여기서 $L_C(X_L, y)$는 레이블된 데이터 $X_L$에 대한 분류 손실이고, $\text{MMD}^2(X_S, X_T)$는 소스 데이터 $X_S$와 타겟 데이터 $X_T$ 간의 거리 제곱입니다. $\lambda$는 도메인 혼동의 강도를 조절하는 하이퍼파라미터입니다.
   $$
   \text{MMD}(X_S, X_T) = \left\| \frac{1}{|X_S|} \sum_{x_s \in X_S} \phi(x_s) - \frac{1}{|X_T|} \sum_{x_t \in X_T} \phi(x_t) \right\|
   $$
2. **새로운 CNN 아키텍처**:
   - Krizhevsky 아키텍처에 저차원 "병목(bottleneck)" 적응 계층을 추가합니다. 이 계층은 소스 분류기의 훈련을 정규화하여 소스 분포의 특정 뉘앙스에 과적합되는 것을 방지합니다.
   - 도메인 거리 손실(MMD)은 이 병목 계층 위에 적용되어 표현이 소스 및 타겟 도메인에 불변하도록 직접 정규화합니다.
3. **모델 선택 (적응 계층의 위치 및 차원 결정)**:
   - **위치 (Depth)**: 사전 훈련된 CNN의 각 완전 연결(fully connected) 계층에서 소스 및 타겟 데이터의 특징을 추출하고, 경험적 MMD 거리를 최소화하는 계층을 선택합니다. 실험에서는 `fc7` 계층 다음이 최적의 위치로 확인되었습니다.
   - **차원 (Width)**: 다양한 차원의 적응 계층을 가진 여러 네트워크를 미세 조정하고, 새로운 저차원 표현에서 소스-타겟 MMD를 계산하여 이를 최소화하는 차원을 선택합니다. 실험에서는 256차원이 합리적인 선택으로 나타났습니다.
4. **공동 훈련**:
   - 가중치를 공유하는 소스 및 타겟 CNN으로 구성됩니다.
   - 분류 손실은 레이블된 예시에만 적용됩니다.
   - 도메인 혼동 손실(MMD)은 두 도메인의 모든 데이터에 적용됩니다.
   - 네트워크는 미니배치 단위로 소스 및 타겟 데이터를 모두 사용하여 공동으로 훈련됩니다. 적응 계층 뒤에 분류 브랜치와 MMD 브랜치로 나뉩니다.
5. **미세 조정**:
   - 정규화 하이퍼파라미터 $\lambda = 0.25$로 설정하여, 분류에 중점을 두되 과적합을 피할 수 있는 충분한 정규화를 제공합니다.
   - 적응 계층과 분류기 계층의 학습률은 사전 훈련된 모델의 하위 계층보다 10배 높게 설정됩니다.
   - 표준 역전파(backpropagation) 최적화를 통해 미세 조정이 진행됩니다.

## 📊 Results

- **Office 데이터셋 평가**: Amazon, DSLR, Webcam의 세 도메인에서 31개 범주에 대한 표준 도메인 적응 벤치마크인 Office 데이터셋 [29]을 사용했습니다.
- **적응 계층 위치 선택**: MMD가 `fc7`을 최적의 적응 계층 위치로 정확하게 식별했으며, 이는 타겟 도메인에서의 분류 성능과 반비례 관계를 보였습니다 (낮은 MMD는 높은 정확도).
- **적응 계층 차원 선택**: MMD를 사용하여 256차원을 적응 계층의 차원으로 선택했습니다. 이는 테스트 성능을 최대화하는 설정은 아니었지만, 합리적인 선택임을 확인했습니다.
- **최첨단 성능 달성**:
  - **지도 적응 (Supervised Adaptation)**: 제안된 방법은 평균 91.9%의 정확도를 달성하여, 기존의 최첨단 방법(예: DaNN 69.4%, DeCAF$_{6}$ S+T의 Amazon→Webcam 80.7%)을 크게 능가했습니다. Amazon→Webcam 태스크에서 84.1%의 정확도를 보였습니다.
  - **비지도 적응 (Unsupervised Adaptation)**: 평균 81.2%의 정확도를 달성하여, 기존 방법(예: DaNN 59.9%, DeCAF$_{6}$ S의 Amazon→Webcam 52.2%)을 크게 앞섰습니다. Amazon→Webcam 태스크에서 59.4%의 정확도를 기록했습니다.
- **과적합 방지 효과**: MMD 정규화가 없는 경우 초기 훈련 속도는 빠르지만 빠르게 과적합되어 테스트 정확도가 떨어지는 반면, MMD 정규화를 사용하면 훈련은 느리지만 과적합을 방지하여 최종적으로 더 높은 테스트 정확도를 달성했습니다.
- **t-SNE 시각화**: 학습된 표현은 원본 `fc7` 표현에 비해 클래스 내에서는 타겟과 소스 도메인 이미지가 잘 섞이면서도, 클래스 간에는 더 밀집된 클러스터를 형성하여 도메인 불변성이 성공적으로 학습되었음을 시각적으로 입증했습니다.

## 🧠 Insights & Discussion

- **도메인 불변 표현 학습의 효과**: MMD 기반의 도메인 혼동 손실을 심층 분류 모델의 훈련 과정에 통합함으로써, 분류에 유용하면서도 도메인 변화에 불변하는 강력한 표현을 효과적으로 학습할 수 있음을 입증했습니다. 이는 이전 방법들이 고정된 특징을 사용하거나 얕은 네트워크에 머물렀던 한계를 극복합니다.
- **MMD의 다각적 활용**: MMD 측정 지표를 적응 계층의 최적 위치와 차원을 선택하는 데 활용하는 것이 효과적인 모델 선택 전략임을 보여주었습니다. 또한, 훈련 과정에서 정규화 항으로 사용하여 과적합을 방지하고 일반화 성능을 향상시키는 데 기여했습니다.
- **실용적 이점**: 레이블된 타겟 데이터가 거의 없거나 전혀 없는 현실적인 시나리오(지도 및 비지도 적응)에서 심층 CNN의 강력한 특징 학습 능력을 유지하면서도 도메인 편향 문제를 해결할 수 있는 실용적인 방법을 제공합니다.
- **한계 및 향후 연구**: 적응 계층 차원 선택 시 MMD와 성능 간의 관계가 항상 완벽하게 선형적이지 않을 수 있으며, 더 정밀한 샘플링을 통해 최적의 차원을 찾을 여지가 있을 수 있습니다.

## 📌 TL;DR

본 논문은 심층 CNN의 도메인 편향 문제를 해결하기 위해, 적응 계층과 Maximum Mean Discrepancy(MMD) 기반의 도메인 혼동 손실을 도입한 새로운 CNN 아키텍처를 제안합니다. MMD는 적응 계층의 위치와 차원을 결정하는 데 사용되며, 훈련 시에는 분류 손실과 함께 도메인 불변 표현을 학습하는 정규화 항으로 기능합니다. 이 방법은 표준 Office 벤치마크에서 기존의 모든 도메인 적응 방법론을 크게 능가하는 최첨단 성능을 달성하여, 심층 표현 학습에 도메인 혼동 개념을 통합하는 것이 효과적임을 입증했습니다.
