# Domain-Adversarial Neural Networks

Hana Ajakan, Pascal Germain, Hugo Larochelle, François Laviolette, Mario Marchand

## 🧩 Problem to Solve

도메인 적응(Domain Adaptation) 환경에서는 훈련 데이터(소스 도메인)와 테스트 데이터(타겟 도메인)가 유사하지만 다른 분포에서 생성됩니다. 이러한 분포 차이로 인해 소스 도메인에서 훈련된 모델이 타겟 도메인에서 성능이 저하되는 문제가 발생합니다. 본 연구는 레이블이 지정된 소스 데이터와 레이블이 지정되지 않은 타겟 데이터를 활용하여, 두 도메인 모두에서 잘 일반화될 수 있는 데이터 표현을 학습하는 알고리즘을 개발하는 것을 목표로 합니다. 기존 접근 방식들은 주로 노이즈에 강인한 표현을 학습하거나 선형/비선형 분류기를 사용하는 데 중점을 두었지만, 도메인 간의 명시적인 구분 불가능성을 직접적으로 최적화하는 방법은 부족했습니다.

## ✨ Key Contributions

- **도메인 적대적 신경망(DANN) 제안**: 도메인 적응 이론(Ben-David et al., 2006; 2010)에서 영감을 받아, 신경망의 은닉 계층이 소스 레이블을 예측하는 동시에 입력의 도메인(소스 또는 타겟)에 대해 정보를 주지 않도록 학습하는 새로운 표현 학습 알고리즘인 DANN을 소개합니다.
- **적대적 훈련 목표 함수 구현**: 신경망의 은닉 계층이 분류 작업을 위해 예측적이면서도, 도메인 분류기를 속여 소스와 타겟 도메인을 구분할 수 없도록 하는 훈련 목표 함수를 제안합니다. 이는 도메인 불변(domain-invariant) 표현 학습을 명시적으로 구현합니다.
- **우수한 성능 입증**: 감성 분석 벤치마크(Amazon Reviews 데이터셋)에서 DANN이 표준 신경망이나 SVM보다 우수한 성능을 보임을 실험적으로 확인했습니다.
- **mSDA와의 시너지 효과**: 최첨단 mSDA(Marginalized Stacked Denoising Autoencoders)와 DANN을 결합했을 때 더욱 향상된 성능을 달성하여, 노이즈 강인성과 도메인 불변성 학습이 상호 보완적인 접근 방식임을 보여줍니다.
- **H-divergence의 직접적인 최적화**: DANN은 이론적으로 H-divergence를 최소화하는 것을 목표로 하며, 이는 도메인 적응 이론을 직접적으로 알고리즘에 통합한 것입니다.

## 📎 Related Works

- **선형 표현 학습**: Bruzzone & Marconcini (2010), Germain et al. (2013), Cortes & Mohri (2014) 등 선형 분류기와 표현 학습에 중점을 두었습니다.
- **비선형 표현 학습 (신경망)**: Glorot et al. (2011), Li et al. (2014) 등 신경망을 활용한 도메인 적응 연구가 진행되었습니다.
- **mSDA (Marginalized Stacked Denoising Autoencoders)**: Chen et al. (2012)은 노이즈에 강인한 특징 표현을 학습하여 도메인 적응에서 뛰어난 성능을 보였습니다.
- **도메인 적응 이론**: Ben-David et al. (2006; 2010)은 효과적인 도메인 전이를 위해 소스와 타겟 도메인이 구분 불가능한 표현을 찾아야 함을 제안했습니다. DANN은 이 이론에 직접적으로 영감을 받았습니다.
- **유사 적대적 학습**: Huang & Yates (2012)는 Ben-David et al.의 이론에서 영감을 받아 HMM 표현을 학습했지만, DANN이 H-divergence를 더 직접적으로 최적화합니다. Zemel et al. (2013)은 보조 레이블에 무관한 공정한 표현 학습을 제안했습니다.
- **일반적인 적대적 (Minimax) 학습**: Bagnell (2005), Liu & Ziebart (2014)는 입력 분포 변화에 강인한 선형 분류기 학습에 관한 연구를 수행했습니다. Goodfellow et al. (2014)의 GAN(Generative Adversarial Networks)은 비지도 생성 모델링에 적대적 목표 함수를 적용했으며, DANN은 이와 유사하게 적대적 목표를 사용하되 지도 학습 기반의 도메인 적응에 적용합니다.

## 🛠️ Methodology

DANN은 다음과 같은 단계로 학습됩니다.

1. **신경망 아키텍처**:
   - 입력 $x$를 특징 표현 $h(x)$로 매핑하는 은닉 계층 $h(x) = \text{sigm}(b+Wx)$.
   - $h(x)$를 바탕으로 분류 예측 $f(x) = \text{softmax}(c+Vh(x))$를 수행하는 출력 계층.
   - $h(x)$를 바탕으로 $x$가 소스 도메인에서 왔는지(1) 타겟 도메인에서 왔는지(0)를 예측하는 도메인 분류기 $o(x) = \text{sigm}(d+u^T h(x))$.
2. **훈련 목표 함수**:
   - 소스 도메인 $S=\{(x_i^s, y_i^s)\}_{i=1}^m$에 대한 분류 손실을 최소화합니다.
     $$ L*{cls}(f(x_i^s), y_i^s) = -\log f*{y_i^s}(x_i^s) $$
   - 소스 $h(x_i^s)$와 타겟 $h(x_i^t)$ 표현 간의 도메인 구별 손실 $L_d$를 사용하여 도메인 분류기가 소스 및 타겟 도메인을 구분하지 못하도록 만듭니다.
     $$ L*{dom}(o(x), z) = -z\log(o(x)) - (1-z)\log(1-o(x)) $$
     도메인 분류기가 잘 분류하지 못하도록 하기 위해, $L*{dom}$을 *최대화*하는 방식으로 학습됩니다.
   - 최종 목표 함수는 다음과 같은 min-max 형태를 가집니다:
     $$ \min*{W,V,b,c} \left[ \frac{1}{m} \sum*{i=1}^m L*{cls}(f(x_i^s), y_i^s) + \lambda \max*{u,d} \left( -\frac{1}{m} \sum*{i=1}^m L*{dom}(o(x*i^s), 1) - \frac{1}{m'} \sum*{i=1}^{m'} L\_{dom}(o(x_i^t), 0) \right) \right] $$
        여기서 $\lambda > 0$는 도메인 적응 정규화 항의 가중치를 조절하는 하이퍼파라미터입니다.
3. **학습 알고리즘 (Algorithm 1)**:
   - 확률적 경사 하강법(SGD)을 사용하여 최적화합니다.
   - **순전파(Forward Propagation)**: 입력 $x$에 대해 은닉 표현 $h(x)$, 분류 예측 $f(x)$, 도메인 예측 $o(x)$를 계산합니다.
   - **역전파(Backpropagation)**:
     - 분류 예측 오류를 기반으로 $V, c$를 업데이트합니다 (일반적인 경사 하강).
     - 도메인 예측 오류를 기반으로 $u, d$를 업데이트합니다. 이 매개변수들은 도메인 분류 손실을 *최대화*하므로, 경사 방향으로 업데이트됩니다 (예: $u \leftarrow u + \alpha \Delta u$).
     - **핵심**: 은닉 계층의 매개변수 $W, b$는 분류 손실을 *최소화*하는 방향으로 업데이트되지만, 도메인 분류기에서 오는 그레디언트는 *반대 방향*으로 전달됩니다. 즉, 도메인 분류기가 도메인을 잘 구분하지 못하도록 은닉 계층의 표현을 조정합니다. 이를 위해 도메인 분류기에서 은닉 계층으로 역전파되는 그레디언트에 $-1$을 곱한 것과 같은 효과를 줍니다 ($\lambda$가 이미 음의 부호를 포함).
   - 조기 종료(Early stopping)를 사용하여 훈련을 중단합니다.

## 📊 Results

- **장난감 문제 (Inter-twinning Moons)**:
  - DANN은 소스 및 타겟 예제를 모두 완벽하게 분류하는 결정 경계를 학습했습니다. 반면 표준 NN은 타겟 도메인에 완전히 적응하지 못했습니다.
  - PCA 분석 결과, DANN의 은닉 계층 표현은 타겟 도메인의 점들이 소스 도메인의 점들 사이에 균일하게 분포되어 도메인을 구별하기 어렵게 만들었습니다. 표준 NN은 뚜렷한 타겟 도메인 클러스터를 보였습니다.
  - DANN의 도메인 분류기는 소스 및 타겟 분포를 전혀 구별하지 못했습니다 (정확도 약 50%). 이는 DANN이 도메인 불변 표현을 효과적으로 학습했음을 의미합니다.
- **감성 분석 (Amazon Reviews Dataset)**:
  - **원본 데이터**: DANN은 12가지 도메인 적응 태스크에서 표준 NN 및 SVM보다 현저히 뛰어난 성능을 보였습니다 (각각 0.90, 0.97의 Poisson binomial test 확률). 이는 DANN의 도메인 적응 정규화가 효과적임을 입증합니다.
  - **mSDA와 결합**: mSDA로 추출된 특징 표현에 DANN을 적용했을 때, DANN+mSDA는 mSDA+NN 및 mSDA+SVM보다 더 우수한 성능을 달성했습니다 (각각 0.82, 0.88의 확률). 이는 DANN의 도메인 불가지론적 학습이 mSDA의 노이즈 강인성 학습과 상호 보완적임을 시사합니다.
- **Proxy A-distance (PAD)**:
  - DANN 표현은 원본 데이터 및 표준 NN 표현에 비해 PAD 값을 일관되게 감소시켰습니다. 이는 DANN이 소스 및 타겟 도메인 간의 식별 가능성을 효과적으로 줄여 도메인 불변 표현을 학습한다는 이론적 주장을 뒷받침합니다.
  - mSDA 단독으로 사용했을 때는 PAD 값이 원본 데이터보다 높아질 수 있었지만, DANN과 mSDA를 결합했을 때 PAD가 크게 감소하여 성능 향상의 원인을 설명했습니다.

## 🧠 Insights & Discussion

- **이론과 실제의 연결**: DANN은 Ben-David et al.의 도메인 적응 이론, 즉 도메인 간의 표현 불가지론적 특성을 확보하는 것이 중요하다는 주장을 직접적으로 신경망 학습에 구현하여 그 효과를 입증했습니다.
- **적대적 학습의 강점**: 적대적 훈련 방식은 도메인 특정적인 특징과 태스크 관련 특징을 효과적으로 분리하여, 도메인 불변적인 표현을 학습하는 데 강력한 도구임을 보여주었습니다.
- **상호 보완적 접근**: mSDA와 DANN의 결합을 통해 노이즈에 강인한 특징 학습과 도메인 불변 특징 학습이 상호 보완적인 전략이며, 함께 적용될 때 더 나은 결과를 얻을 수 있음을 시사합니다.
- **향후 연구**:
  - 더 깊은 신경망 아키텍처에 DANN을 적용하는 연구가 가능합니다.
  - 단일 소스 적응을 넘어 다중 소스 적응 문제 및 이진 분류 외의 다른 학습 태스크로의 확장 가능성이 있습니다.
  - DANN과 denoising autoencoder를 직접 통합하여, 현재의 2단계 절차를 개선할 수 있는 잠재력이 있습니다.

## 📌 TL;DR

- **문제**: 도메인 적응은 훈련(소스) 및 테스트(타겟) 데이터 분포의 차이로 인해 모델 성능이 저하되는 것을 방지하는 것이 중요합니다.
- **제안 방법**: DANN(Domain-Adversarial Neural Networks)은 신경망의 은닉 계층이 소스 레이블을 정확히 예측하는 동시에, 도메인 분류기를 속여 소스와 타겟 도메인을 구분할 수 없도록 적대적으로 학습함으로써 도메인 불변 표현을 생성합니다.
- **주요 결과**: DANN은 장난감 문제와 실제 감성 분석 데이터셋에서 기존 방법들을 능가하는 성능을 보였으며, 최첨단 mSDA와 결합 시 더 높은 성능을 달성하여 도메인 불변성 학습의 효과와 다른 표현 학습 방식과의 시너지 효과를 입증했습니다. 이는 이론적인 H-divergence 최소화가 실제 도메인 적응에 유효함을 보여줍니다.
