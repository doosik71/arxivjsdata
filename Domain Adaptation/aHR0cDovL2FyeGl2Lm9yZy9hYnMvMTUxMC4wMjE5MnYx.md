# Simultaneous Deep Transfer Across Domains and Tasks

Eric Tzeng, Judy Hoffman, Trevor Darrell, Kate Saenko

## 🧩 해결할 문제

기존 딥 CNN 모델은 대규모 데이터셋으로 학습하더라도 데이터셋 편향(dataset bias)을 완전히 제거하지 못합니다. 새로운 도메인에서 모델을 미세 조정(fine-tuning)하려면 많은 양의 레이블링된 데이터가 필요하지만, 실제 애플리케이션에서는 이러한 레이블이 부족하거나 전혀 없는 경우가 많습니다. 특히, 일부 클래스에만 레이블이 있는 준지도 학습(semi-supervised) 환경에서 도메인 간의 효과적인 지식 전이(knowledge transfer)가 필요합니다.

## ✨ 주요 기여

- **새로운 CNN 아키텍처 제안**: 레이블 없는 및 부분적으로 레이블링된 타겟 도메인 데이터를 활용하여 도메인 불변성(domain invariance)과 태스크 간 정보 전이(task transfer)를 동시에 최적화하는 CNN 아키텍처를 제안합니다.
- **도메인 불변성 최적화**: 도메인 혼란 손실(domain confusion loss)을 사용하여 원본 및 타겟 도메인의 특징 분포를 최대한 유사하게 만들어 도메인 전이를 용이하게 합니다. 이는 도메인 분류기가 두 도메인을 구별하기 어렵게 만듭니다.
- **태스크 간 정보 전이**: 소프트 레이블 분포 매칭 손실(soft label distribution matching loss)을 사용하여 원본 도메인에서 학습된 경험적 범주 상관 관계(empirical category correlations)를 타겟 도메인으로 전이합니다. 이를 통해 클래스 간의 관계를 보존합니다.
- **최고 성능 달성**: 두 가지 표준 벤치마크 시각 도메인 적응 태스크(Office 데이터셋 및 Cross-dataset collection)에서 지도 학습 및 준지도 학습 설정 모두에서 기존의 발표된 결과들을 능가하는 성능을 보였습니다.
- **준지도 학습 환경에서의 효과 입증**: 타겟 도메인에서 레이블이 없는 클래스에 대해서도 학습된 정보를 효과적으로 전이하여 성능 향상을 이끌어냅니다.

## 📎 관련 연구

- **시각 도메인 적응 문제**: 데이터 분포 변화를 극복하기 위한 다양한 접근 방식 (예: 특징 공간 변환으로 원본-타겟 정렬 [28,23,11,15]).
- **CNN 기반 특징 표현**: 심층 표현이 도메인 이동의 영향을 크게 줄이는 데 효과적임 [9,19].
- **병렬 CNN 아키텍처**: Siamese 네트워크 [6,8]와 같은 모델은 불변 표현(invariant representations) 학습에 효과적이지만, 레이블링된 데이터가 필요하여 준지도/비지도 환경으로 확장하기 어려움.
- **도메인 불변 표현 학습**: 제한된 깊이의 네트워크에서 MMD(Maximum Mean Discrepancy) 도메인 혼란 손실을 사용하여 도메인 불변 표현을 학습하는 시도 [13], 혹은 직접적으로 도메인 불변성을 최적화하는 동시대 연구들 [12,24]. 그러나 본 논문은 더 강력한 측정 방법과 최적화 방식을 사용하며, 준지도 설정에서 태스크 전이 문제를 다룸.
- **모델 압축/증류(Distillation)**: 분류기 출력 분포를 사용하여 네트워크를 증류하는 선행 연구 [3,16]에서 영감을 받았으며, 이 기술을 도메인 적응 설정에 최초로 적용하여 도메인 간 클래스 상관관계를 전이함.

## 🛠️ 방법론

본 연구는 도메인 불변 표현 학습과 태스크 간 정보 전이를 위한 새로운 CNN 아키텍처를 제안하며, 다음의 손실 함수들을 공동으로 최적화합니다.

1. **분류 손실($L_C$)**:

   - 원본 도메인의 레이블링된 데이터 $\{x_S, y_S\}$와 타겟 도메인의 부분적으로 레이블링된 데이터 $\{x_T, y_T\}$에 대한 표준 소프트맥스 분류 손실입니다.
     $$L_C(x,y;\theta_{repr},\theta_C) = - \sum_k \mathbf{1}[y=k] \log p_k$$
     - 여기서 $p = \text{softmax}(\theta_C^T f(x;\theta_{repr}))$입니다.

2. **도메인 혼란 손실($L_{conf}$)**:

   - 네트워크가 도메인 불변 특징 표현을 학습하도록 돕기 위해 도입됩니다.
   - **도메인 분류기($\theta_D$) 학습**: 특징 표현 $f(x;\theta_{repr})$가 주어진 상태에서 입력 이미지가 원본 도메인(source, $d=0$)에서 왔는지 타겟 도메인(target, $d=1$)에서 왔는지를 예측하는 이진 분류기 $fcD$ (파라미터 $\theta_D$)를 학습합니다.
     $$L_D(x_S, x_T, \theta_{repr}; \theta_D) = - \sum_d \mathbf{1}[y_D=d] \log q_d$$
     - 여기서 $q = \text{softmax}(\theta_D^T f(x;\theta_{repr}))$입니다.
   - **도메인 혼란 최적화**: 도메인 분류기의 성능을 저하시켜 두 도메인의 특징 분포를 최대한 유사하게 만듭니다. 이를 위해 도메인 분류기의 출력 $q$가 균일 분포($1/D$, 여기서 $D=2$)와 교차 엔트로피를 최소화하도록 $\theta_{repr}$를 업데이트합니다.
     $$L_{conf}(x_S, x_T, \theta_D; \theta_{repr}) = - \sum_d \frac{1}{D} \log q_d$$
     - $\theta_D$는 $L_D$를 최소화하고, $\theta_{repr}$는 $L_{conf}$를 최소화하도록 반복적으로 업데이트합니다.

3. **소프트 레이블 손실($L_{soft}$)**:

   - 클래스 간의 관계를 원본에서 타겟으로 전이하여 태스크 전이를 달성합니다.
   - **소프트 레이블 정의**: 원본 네트워크에서 각 범주 $k$에 대해 학습된 평균 출력 확률 분포($l^{(k)}$)를 소프트 레이블로 사용합니다. 이때, 높은 온도(temperature) $\tau$를 사용하여 소프트맥스 분포를 부드럽게 만들어 클래스 간의 유사도 정보를 보존합니다.
   - **손실 계산**: 타겟 도메인의 레이블링된 이미지 $x_T$에 대해, 해당 이미지의 범주 $y_T$에 해당하는 원본 소프트 레이블 $l^{(y_T)}$과 현재 네트워크의 소프트 활성화 $p = \text{softmax}(\theta_C^T f(x_T;\theta_{repr})/\tau)$ 간의 교차 엔트로피를 최소화합니다.
     $$L_{soft}(x_T, y_T; \theta_{repr}, \theta_C) = - \sum_i l^{(y_T)}_i \log p_i$$

4. **전체 공동 손실 함수**:
   $$
   \begin{aligned}
   L(x_S, y_S, x_T, y_T, \theta_D; \theta_{repr}, \theta_C) = \; & L_C(x_S, y_S, x_T, y_T; \theta_{repr}, \theta_C) \\
   & + \lambda L_{conf}(x_S, x_T, \theta_D; \theta_{repr}) \\
   & + \nu L_{soft}(x_T, y_T; \theta_{repr}, \theta_C)
   \end{aligned}
   $$
   - $\lambda$와 $\nu$는 하이퍼파라미터로, 각각 도메인 혼란과 소프트 레이블의 최적화에 미치는 영향을 조절합니다.

## 📊 결과

- **Office 데이터셋 (지도 학습 설정)**:
  - 타겟 도메인 각 범주당 3개의 레이블링된 예제가 주어지는 환경에서 평가되었습니다.
  - 소프트 레이블 또는 도메인 혼란만 사용한 미세 조정은 하드 레이블 학습(Source+Target CNN) 대비 일관된 성능 향상을 보였습니다.
  - 두 손실을 함께 사용했을 때 평균적으로 미미하지만 가장 높은 성능을 달성하여, 기존 SOTA 방법론(DeCAF, DaNN 등)을 뛰어넘었습니다 (평균 정확도 82.22%).
- **Office 데이터셋 (준지도 학습 설정)**:
  - 전체 31개 범주 중 15개 범주에 대해서만 각 10개의 레이블링된 타겟 예제가 주어지고, 나머지 16개(held-out) 범주에서 성능을 평가했습니다.
  - 제안된 방법의 모든 변형(소프트 레이블만, 도메인 혼란만, 둘 다)이 기준 모델들을 능가했습니다.
  - 특히, 도메인 혼란과 소프트 레이블이 모두 전체 성능 향상에 크게 기여했습니다 (평균 정확도 66.4%). 이는 레이블 없는 타겟 데이터가 있을 때 네트워크가 도메인 불변성을 암묵적으로 강제하기 어렵기 때문입니다.
- **ImageNet $\rightarrow$ Caltech-256 (Cross-dataset)**:
  - 타겟 도메인에서 범주당 1, 3, 5개의 레이블링된 예제로 제한된 환경에서 평가되었습니다.
  - 제안된 방법은 모든 시나리오에서 기준 모델(Source CNN, Source+Target CNN)을 크게 능가했습니다.
  - 특히 타겟 레이블링된 예제가 적을수록(1, 3개) 성능 향상 폭이 가장 컸습니다. 타겟 레이블이 전혀 없을 때에도 작동하여 상당한 정확도를 보였습니다.

## 🧠 통찰 및 논의

- **도메인 불변성 입증**: 도메인 혼란 손실을 통해 학습된 특징 표현은 도메인 분류기가 두 도메인(예: Amazon과 Webcam)을 구별하는 데 매우 어려움을 겪도록 만듭니다 (테스트 정확도 99% $\rightarrow$ 56%). 이는 제안된 방법이 효과적으로 도메인 불변 표현을 학습했음을 시사합니다.
- **소프트 레이블을 통한 태스크 전이**: 준지도 학습 환경에서 레이블이 없는 클래스(예: 모니터)에 대해서도, 관련 있는 레이블링된 클래스(예: 랩톱 컴퓨터)의 소프트 레이블 정보를 활용하여 올바르게 분류할 수 있었습니다. 이는 소프트 레이블이 클래스 간의 유사도 정보를 효과적으로 전이함을 보여줍니다.
- **제한된 레이블 데이터에서의 강점**: 제안된 방법은 타겟 도메인에 레이블링된 데이터가 적거나 없을 때 기존 미세 조정 전략보다 훨씬 뛰어난 성능을 보입니다. 타겟 레이블 데이터가 충분할 경우에는 표준 미세 조정 전략이 제안된 접근 방식의 성능에 근접할 수 있습니다.
- **실용성**: 제안된 아키텍처는 타겟 도메인에서 범주당 레이블링된 데이터가 제한적이거나 없을 때 대체 미세 조정 전략으로 쉽게 구현될 수 있습니다.

## 📌 TL;DR

이 논문은 딥 CNN 모델이 새로운 도메인으로 적응할 때 레이블링된 데이터가 부족한 문제를 해결하기 위해 새로운 아키텍처를 제안합니다. 이 아키텍처는 **도메인 혼란 손실**을 통해 도메인 불변 특징을 학습하고, **소프트 레이블 손실**을 통해 원본 도메인의 클래스 상관관계를 타겟 도메인으로 전이합니다. 두 손실을 공동으로 최적화함으로써, 레이블이 매우 적거나 없는 준지도 학습 환경에서도 기존 최첨단 방법들을 능가하는 분류 성능을 달성하며, 특히 레이블링된 타겟 데이터가 희소할 때 큰 효과를 발휘합니다.
