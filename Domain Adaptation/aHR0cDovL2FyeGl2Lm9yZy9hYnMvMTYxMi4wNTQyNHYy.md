# Unsupervised Pixel–Level Domain Adaptation with Generative Adversarial Networks

Konstantinos Bousmalis, Nathan Silberman, David Dohan, Dumitru Erhan, Dilip Krishnan

## 🧩 Problem to Solve

최신 기계 학습 알고리즘, 특히 딥러닝 모델 학습을 위한 대규모의 잘 주석된(annotated) 이미지 데이터셋을 수집하는 것은 많은 작업에서 엄청나게 비쌉니다. 이의 매력적인 대안은 지상 진실(ground-truth) 주석이 자동으로 생성되는 합성(synthetic) 데이터를 렌더링하는 것입니다. 그러나 합성 이미지로만 훈련된 모델은 실제 이미지에 대해 일반화하는 데 어려움을 겪는(domain gap) 문제가 있습니다. 기존 비지도 도메인 적응(unsupervised domain adaptation) 방법들은 이러한 한계를 극복하기 위해 두 도메인 간의 표현을 매핑하거나 도메인 불변(domain-invariant) 특징을 추출하려 했지만, 타겟 도메인에서만 지도 학습된 모델만큼의 성능에는 미치지 못했습니다.

## ✨ Key Contributions

- **픽셀 수준 도메인 변환**: GAN(Generative Adversarial Network) 기반 모델을 사용하여 소스 도메인 이미지를 타겟 도메인에서 추출된 것처럼 보이도록 픽셀 수준에서 비지도 방식으로 변환하는 새로운 접근 방식을 제안합니다.
- **작업별 아키텍처와의 분리**: 도메인 적응 프로세스를 작업별 분류기 아키텍처와 독립적으로 분리하여, 도메인 적응 모델을 재훈련하지 않고도 작업별 구성 요소를 변경할 수 있게 합니다.
- **레이블 공간 전반의 일반화**: 테스트 시 타겟 레이블 공간이 훈련 시 레이블 공간과 다를 수 있는 경우를 처리할 수 있습니다.
- **훈련 안정화**: 생성된 이미지와 원본 소스 이미지 모두에서 훈련되는 작업별 손실($L_t$) 및 픽셀 유사성 정규화(content-similarity regularization, $L_c$)를 도입하여 모드 붕괴(mode collapse)를 방지하고 훈련을 안정화합니다.
- **데이터 증강(Data Augmentation)**: 소스 이미지와 확률적 노이즈 벡터($z$)를 조건으로 하여 타겟 도메인 이미지와 유사한 무제한의 확률적 샘플을 생성할 수 있습니다.
- **높은 해석 가능성**: 도메인 적응된 이미지 출력을 통해 적응 과정을 추상적인 특징 벡터보다 훨씬 쉽게 해석할 수 있습니다.
- **최고 성능 달성**: 여러 비지도 도메인 적응 시나리오에서 기존 최첨단(state-of-the-art) 방법들을 큰 폭으로 능가합니다.
- **미학습 클래스로의 일반화**: 훈련 중 보지 못한 객체 클래스에 대해서도 적응 프로세스가 일반화됨을 입증합니다.

## 📎 Related Works

- **비지도 도메인 적응**:
  - **DANN (Domain–Adversarial Neural Network)** [Ganin et al. 2014, 2016]: 도메인 불변 특징을 추출하기 위해 도메인 분류기와 그래디언트 반전 계층(gradient reversal layer)을 사용합니다.
  - **MMD (Maximum Mean Discrepancy)** [Tzeng et al. 2014, Long et al. 2015]: 도메인 간 특징 불일치(discrepancy)를 최소화하여 도메인 적응을 수행합니다.
  - **DSN (Domain Separation Networks)** [Bousmalis et al. 2016]: 도메인 고유(private) 및 공통(common) 구성 요소를 명시적으로 분리합니다.
  - **CORAL (Correlation Alignment)** [Sun et al. 2016]: 특징 수준에서 한 도메인에서 다른 도메인으로의 매핑을 학습합니다.
- **GAN (Generative Adversarial Networks)** [Goodfellow et al. 2014]: 생성자와 판별자의 경쟁 학습을 통해 데이터를 생성합니다.
  - **이미지 조건부 GAN**: Ledig et al. (초고해상도), Yoo et al. (의류 이미지 생성) 등 이미지를 조건으로 하는 GAN 연구들이 있었으나, 본 논문은 이미지와 노이즈 벡터 모두를 조건으로 하는 점에서 차이가 있습니다.
  - **Coupled GANs (CoGAN)** [Liu & Tuzel 2016]: 생성자와 판별자가 가중치를 공유하는 쌍으로 구성되어 비지도 도메인 적응을 위한 대응되는 이미지 쌍을 생성합니다.
- **스타일 전이 (Style Transfer)** [Gatys et al. 2015, Johnson et al. 2016]: 특정 이미지의 스타일을 다른 이미지에 적용하는 것을 목표로 하며, 본 연구의 도메인 *전체*의 스타일을 적응시키는 것과는 다릅니다.

## 🛠️ Methodology

PixelDA 모델은 생성자($G$), 판별자($D$), 그리고 작업별 분류기($T$)로 구성됩니다.

1. **생성자 $G(x_s, z; \theta_G) \rightarrow x_f$**:
   - 입력: 소스 도메인 이미지 $x_s$와 노이즈 벡터 $z \sim p_z$.
   - 출력: 타겟 도메인에서 샘플링된 것처럼 보이는 적응된("가짜") 이미지 $x_f$.
   - 아키텍처: 잔차 연결(residual connection)을 포함한 컨볼루션 신경망으로, 원본 이미지의 해상도를 유지합니다. 노이즈 벡터 $z$는 추가 채널로 입력 이미지에 연결됩니다.
2. **판별자 $D(x; \theta_D)$**:
   - 입력된 이미지 $x$가 타겟 도메인에서 샘플링되었을 가능성($d$)을 출력합니다.
   - 생성자가 만든 가짜 이미지 $X_f$와 실제 타겟 도메인 이미지 $X_t$를 구별하려고 시도합니다.
   - 아키텍처: 컨볼루션 신경망.
3. **작업별 분류기 $T(x; \theta_T) \rightarrow \hat{y}$**:
   - 이미지 $x \in \{X_f, X_t\}$에 대해 작업별 레이블 $\hat{y}$를 할당합니다.
   - 도메인 적응 과정과 분리되어 있어, 작업에 따라 유연하게 변경할 수 있습니다.
4. **학습 목표 (Minimax Optimization)**:
   $$ \min*{\theta_G, \theta_T} \max*{\theta_D} \alpha L_d(D,G) + \beta L_t(G,T) + \gamma L_c(G) $$
   - **도메인 손실 ($L_d$)**: 생성자가 $D$를 속여 타겟 도메인 이미지와 구별할 수 없는 이미지를 생성하도록 유도하는 표준 GAN의 적대적 손실입니다.
     $$ L*d(D,G) = E*{x*t}[\log D(x_t; \theta_D)] + E*{x_s,z}[\log(1-D(G(x_s,z;\theta_G);\theta_D))] $$
   - **작업별 손실 ($L_t$)**:
     - 분류의 경우: Softmax 교차 엔트로피 손실.
     - 모델 불안정성과 클래스 할당 변화를 피하기 위해 적응된 이미지 $G(x_s,z)$와 원본 소스 이미지 $x_s$ **모두**에 대해 $T$를 훈련합니다.
     - 자세 추정(pose estimation)의 경우: 분류 손실과 쿼터니언(quaternion)에 대한 3D 회전 메트릭을 결합합니다.
   - **콘텐츠 유사성 손실 ($L_c$)**: (객체가 검은 배경에 렌더링된 경우와 같이 사전 지식이 있을 때 선택적으로 사용)
     - 생성된 전경(foreground)과 소스 전경 간의 차이를 패널티하는 마스크드 쌍별 평균 제곱 오차(masked pairwise mean squared error, MPSE)를 사용합니다.
     - 생성 과정을 원본 이미지 콘텐츠에 고정시키고 훈련을 안정화하는 데 도움을 줍니다.
       $$ L*c(G) = E*{x*s,z} \left[ \frac{1}{k} \left\|(x_s - G(x_s,z;\theta_G)) \circ m\right\|*{2}^{2} - \frac{1}{k^2} \left( (x_s - G(x_s,z;\theta_G))^{T} m \right)^{2} \right] $$
        여기서 $m$은 이진 마스크, $k$는 픽셀 수, $\circ$는 아다마르 곱(Hadamard product)입니다.
5. **훈련 과정**: $(\theta_D, \theta_T)$와 $\theta_G$ 매개변수를 교대로 업데이트하는 방식으로 최적화됩니다. Adam 옵티마이저를 사용합니다.

## 📊 Results

- **정량적 결과**:
  - **MNIST to USPS**: PixelDA는 95.9%의 정확도를 달성하여 SOTA(DANN 85.1%, DSN 91.3%, CoGAN 91.2%)를 크게 능가했으며, 'Target-only'(96.5%)에 근접했습니다.
  - **MNIST to MNIST-M**: PixelDA는 98.2%의 정확도를 달성하여 SOTA(DANN 77.4%, DSN 83.2%, CoGAN 62.0%)를 크게 능가했을 뿐만 아니라, 'Target-only' 기준선(96.4%)마저 뛰어넘었습니다.
  - **Synthetic Cropped LineMod to Cropped LineMod (분류 및 자세 추정)**:
    - 분류 정확도: PixelDA는 99.98%를 달성하여 DSN(100.00%)과 거의 일치했습니다.
    - 평균 각도 오차(자세): PixelDA는 $23.5^{\circ}$를 달성하여 이전 SOTA(DSN $53.27^{\circ}$)보다 오차를 **절반 이상 감소**시켰습니다.
- **정성적 결과**:
  - 생성된 이미지(예: MNIST-M 배경, LineMod의 사실적인 배경 및 광도 조정)는 시각적으로 그럴듯하며 타겟 도메인의 이미지처럼 보입니다.
  - 최근접 이웃 분석을 통해 모델이 타겟 훈련 이미지를 단순히 **암기하는 것이 아니라** 생성적 변환을 학습하고 있음을 확인했습니다 (그림 3, 4).
- **모델 분석**:
  - **배경 변화에 대한 강건함**: PixelDA는 소스 이미지의 배경이 복잡한 경우(예: ImageNet 배경)에도 성능 향상을 보였으며, 단순히 검은 배경에만 의존하지 않습니다.
  - **미학습 클래스로의 일반화**: LineMod 객체의 절반만으로 훈련되었을 때도, PixelDA는 훈련 중 보지 못한 객체 클래스에 대해 높은 정확도(98.98%)와 낮은 자세 오차($31.69^{\circ}$)를 유지하며 강력한 일반화 능력을 입증했습니다.
  - **훈련 안정성**: 작업별 손실($L_t$)과 콘텐츠 유사성 손실($L_c$)의 사용은 모델 성능의 표준 편차를 크게 줄여, 훈련 안정성을 향상시켰습니다 (표 5).
- **준지도 학습(Semi-supervised Learning) 환경**: 소량의 레이블링된 타겟 데이터(1,000개)가 제공되었을 때, PixelDA는 성능을 더욱 향상시켰습니다 (예: LineMod 자세 오차가 비지도 환경의 $23.5^{\circ}$에서 $13.31^{\circ}$로 감소). 이는 '1000-only' 및 'Synth+1000' 기준선을 능가하는 결과입니다.

## 🧠 Insights & Discussion

- **유연성과 모듈성**: 픽셀 수준 적응은 도메인 적응 프로세스를 작업별 모델과 명확하게 분리하여 유연성과 모듈성을 크게 향상시킵니다. 이는 재훈련 없이 작업별 아키텍처를 교체할 수 있게 합니다.
- **높은 해석 가능성**: 추상적인 특징 변환과 달리, 도메인 적응된 이미지를 시각적으로 출력함으로써 적응 프로세스를 더 쉽게 이해하고 해석할 수 있습니다.
- **강력한 일반화 능력**: 모델은 복잡한 픽셀 수준 변환(예: 배경 생성, 광도 조정)을 효과적으로 학습하며, 훈련 시 보지 못한 클래스에도 잘 일반화되는 것으로 나타났습니다.
- **GAN 훈련 안정화**: 작업별 손실과 콘텐츠 유사성 손실의 전략적 도입은 GAN 훈련의 일반적인 불안정성(모드 붕괴, 클래스 할당 변경) 문제를 해결하여 모델의 신뢰성을 높입니다.
- **가정의 한계**: 이 방법은 도메인 간 차이가 주로 낮은 수준(노이즈, 해상도, 조명, 색상)이며, 높은 수준(객체 유형, 기하학적 변화)의 차이는 아니라고 가정합니다. 이는 중요한 고수준 도메인 변화가 있는 경우 잠재적인 한계가 될 수 있습니다.
- **실용적 가치**: 소량의 레이블링된 타겟 데이터를 준지도 학습 환경에서 효과적으로 활용하여 성능을 더욱 향상시킬 수 있음을 보여주어, 실제 적용 가능성을 높입니다.

## 📌 TL;DR

레이블링된 데이터셋 구축의 높은 비용 문제를 해결하기 위해, 이 논문은 **GAN 기반의 픽셀 수준 도메인 적응(PixelDA)** 방법을 제안합니다. 이 방법은 소스 도메인 이미지를 타겟 도메인의 스타일을 갖도록 변환하며, 기존 도메인 적응 방법과 달리 **작업별 아키텍처와 도메인 적응 과정을 분리**합니다. 또한, 학습 안정화를 위한 **작업별 손실($L_t$) 및 콘텐츠 유사성 손실($L_c$)**을 도입하여, MNIST, LineMod와 같은 데이터셋에서 기존 SOTA 성능을 크게 뛰어넘는 동시에, 훈련 시 보지 못한 클래스에도 **높은 일반화 성능**을 보입니다. 이는 합성 데이터의 실제 적용 가능성을 크게 높이는 중요한 기여입니다.
