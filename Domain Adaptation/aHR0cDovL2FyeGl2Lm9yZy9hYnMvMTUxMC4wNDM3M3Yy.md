# Scatter Component Analysis: A Unified Framework for Domain Adaptation and Domain Generalization

Muhammad Ghifary, David Balduzzi, W. Bastiaan Kleijn, and Mengjie Zhang

## 🧩 Problem to Solve

이 논문은 레이블링된 학습 데이터가 원본 도메인(source domain)에서만 제공되고 대상 도메인(target domain)은 다르거나 레이블이 없는 상황에서 분류 작업을 수행하는 문제를 다룹니다. 이는 **도메인 적응(Domain Adaptation, DA)**과 **도메인 일반화(Domain Generalization, DG)**라는 두 가지 밀접하게 관련된 프레임워크와 관련이 있습니다. DA는 레이블 없는 대상 도메인 정보를 활용할 수 있지만, DG는 그렇지 않다는 차이가 있습니다. 기존의 최신 DA 및 DG 알고리즘들은 종종 계산 비효율적이며, 일반적으로 두 문제를 동시에 해결할 수 있는 통합된 접근 방식이 부족하다는 문제가 있습니다.

## ✨ Key Contributions

- **산포(Scatter)의 정의 및 활용**: 분포의 중심으로부터 평균 제곱 거리를 정량화하는 단순한 기하학적 함수인 '산포'를 제안합니다. 이 산포를 통해 클래스 분리도 최대화, 도메인 불일치 최소화, 데이터 전체의 가변성 최대화, 그리고 동일 레이블 내 유사성 유지라는 네 가지 요구 사항을 인코딩할 수 있음을 보여주며, Linear Discriminant Analysis (LDA), Principal Component Analysis (PCA), Maximum Mean Discrepancy (MMD) 등 기존 개념과의 관계를 확립합니다.
- **산포 성분 분석(Scatter Component Analysis, SCA)** 알고리즘 제안: DA와 DG 문제 모두에 적용할 수 있는 빠르고 효율적인 산포 기반 특징 학습 알고리즘인 SCA를 개발했습니다. SCA의 최적화 문제는 일반화된 고유값 문제로 귀결되어 Kernel PCA와 유사한 시간 복잡도로 빠르고 정확한 해를 제공합니다. 이는 DA와 DG 모두에 적용 가능한 최초의 다목적 알고리즘 중 하나입니다.
- **이론적 일반화 경계 유도**: 도메인 적응의 경우 SCA에 대한 이론적 일반화 경계를 유도했습니다. 이 분석은 '도메인 산포(domain scatter)'가 SCA의 일반화 성능을 제어하며, '불일치 거리(discrepancy distance)'와 직접적인 관련이 있음을 보여줍니다.
- **포괄적인 실험 검증**: 벤치마크 교차 도메인 객체 인식 데이터셋에 대한 광범위한 실험을 통해 SCA가 여러 최신 알고리즘보다 훨씬 빠르면서도 DA 및 DG 모두에서 최신 수준의 분류 정확도를 제공함을 입증했습니다.

## 📎 Related Works

- **지도 학습의 한계**: 레이블링된 대규모 데이터셋에 대한 성공에도 불구하고, 레이블 획득 비용과 데이터셋 편향(dataset bias)으로 인해 학습 모델이 다른 데이터셋에 잘 일반화되지 못하는 문제가 있습니다.
- **도메인 적응(Domain Adaptation)**: 원본 도메인의 레이블과 대상 도메인의 레이블 없는 샘플을 활용하여 대상 도메인에 대한 좋은 모델을 생성하는 것을 목표로 합니다.
  - **접근 방식**: 분류기 적응(A-SVMs, DAM), 샘플 재가중/선택(TJM), 특징 변환(TCA/SSTCA, GFK, SA, CORAL, TSC, DIP, 딥러닝 기반 방법) 등이 있습니다.
  - **이론적 배경**: $d_A$-distance [57]와 불일치 거리(discrepancy distance) [27]를 기반으로 한 일반화 경계 연구가 있습니다.
- **도메인 일반화(Domain Generalization)**: 레이블 없는 대상 샘플을 사용할 수 없는 상황에서 여러 원본 도메인의 샘플을 활용하여 새로운 대상 도메인에 잘 일반화되는 함수를 학습하는 것을 목표로 합니다.
  - **주요 알고리즘**: DICA [19] (Kernel PCA를 확장하여 분포 가변성(distributional variance) 및 중심 부분 공간(central subspace) 통합), Undo-Bias [21], UML [20], LRE-SVM [22] 등이 있습니다.
- **기존 방법의 문제점**: 많은 최신 DA 및 DG 알고리즘은 비효율적인 최적화 문제를 수반하며, DA와 DG 방법론이 서로 호환되지 않는 경우가 많습니다. LRE-SVM만이 두 문제 모두에 적용 가능한 몇 안 되는 알고리즘 중 하나로 언급됩니다.

## 🛠️ Methodology

SCA는 재현 커널 힐베르트 공간(RKHS)에서 '산포(scatter)'라는 기하학적 측도를 활용하여 데이터셋 편향에 불변하는 표현을 학습하는 것을 목표로 합니다. 이는 다음 네 가지 요구 사항을 산포를 통해 정량화하고 최적화하여 달성됩니다.

1. **총 산포(Total Scatter)**: 모든 도메인의 평균 분포에 대한 산포를 나타내며, 데이터 전체의 가변성($ \Psi\_{\phi}(\bar{P}\_X) $)을 최대화하여 Kernel PCA와 유사한 역할을 합니다.
2. **도메인 산포(Domain Scatter)**: 여러 도메인의 평균 맵(mean map) 간의 산포를 나타내며, 도메인 불일치($ \Psi(\{\mu*{P^1_X}, ..., \mu*{P^m_X}\}) $)를 최소화하여 Maximum Mean Discrepancy (MMD) 및 분포 가변성과 유사한 역할을 합니다.
3. **클래스 내 산포(Within-Class Scatter)**: 각 클래스 내 샘플들의 산포를 합산한 것으로, 동일 레이블을 공유하는 샘플들의 유사성을 최대화합니다($ \sum*{k=1}^C \Psi*{\phi}(P^l\_{X|k}) $).
4. **클래스 간 산포(Between-Class Scatter)**: 각 클래스 평균 맵 간의 산포를 나타내며, 다른 레이블을 가진 샘플들의 분리도($ \Psi (\{\mu*{P^l*{X|k=1}}, ..., \mu*{P^l*{X|k=C}}\}) $)를 최대화하여 Fisher의 선형 판별 분석(Fisher's Linear Discriminant)과 유사한 역할을 합니다.

**SCA의 목적 함수**:
SCA는 다음 비율을 최대화하는 변환 행렬 $ B $를 찾습니다.
$$ \operatorname{argmax}_B \frac{\text{총 산포} + \text{클래스 간 산포}}{\text{도메인 산포} + \text{클래스 내 산포}} $$
이를 수식으로 표현하면 다음과 같습니다:
$$ \operatorname{argmax}_{B \in \mathbb{R}^{n \times k}} \operatorname{Tr} \left( B^T \left( (1-\beta) \frac{1}{n} KK + \beta P \right) B \right) $$
$$ \text{s.t. } \operatorname{Tr} \left( B^T \left( \delta KLK + Q + K \right) B \right) = 1 $$
여기서 $ K $는 커널 행렬, $ L, P, Q $는 산포 항에서 파생된 행렬이며, $ \beta, \delta > 0 $는 각각 총 산포/클래스 간 산포와 도메인 산포 간의 균형을 조절하는 하이퍼파라미터입니다.

**해결 방법**:
이 최적화 문제는 일반화된 고유값 문제 $ ((1-\beta)\frac{1}{n}KK+\beta P) B^_ = (\delta KLK+K+Q) B^_ \Lambda $로 변환될 수 있으며, 이를 통해 빠르고 정확한 해 $ B^\* $를 얻을 수 있습니다.

**커널 및 하이퍼파라미터 설정**:

- RBF 커널($ \exp(-\frac{\|a-b\|^2}{\sigma^2}) $)을 사용하며, 커널 대역폭 $ \sigma $는 샘플 간 중간 거리 휴리스틱으로 분석적으로 설정됩니다.
- 도메인 적응 시 $ \delta=1 $로 고정하고 $ k, \beta $를 튜닝합니다.
- 도메인 일반화 시 $ \beta=1 $로 고정하고 $ k, \delta $를 튜닝합니다.
- 모든 튜닝은 원본 도메인 레이블을 사용한 5-겹 교차 검증을 통해 이루어집니다.

## 📊 Results

- **실행 시간 성능**: SCA는 최신 알고리즘들에 비해 상당한 속도 우위를 보입니다.
  - DA에서 TJM보다 3~6배, TSC보다 50배 이상 빠릅니다.
  - DG에서 Undo-Bias, UML, LRE-SVM보다 5~20배 빠르며, KPCA나 DICA와 유사한 속도를 가집니다 (O($kn^2$) 복잡도).
- **도메인 적응 (DA) 성능**:
  - **합성 데이터**: SCA는 클래스별로 더 밀집된 클러스터와 뚜렷한 간격을 보여, 더 쉬운 분류를 가능하게 합니다.
  - **실제 객체 인식**: USPS+MNIST, MSRC+VOC2007, Office+Caltech 데이터셋에서 1-NN, L-SVM, DAM 등 다양한 분류기를 사용했을 때, SCA는 지속적으로 최고 또는 두 번째로 높은 평균 정확도를 달성하여 TJM과 같은 기존 최신 방법보다 우수하거나 동등한 성능을 보였습니다. 특히, 일부 경우(예: MSRC+VOC2007)에는 비지도 버전인 uSCA가 더 높은 정확도를 기록했습니다.
- **도메인 일반화 (DG) 성능**:
  - VLCS, Office+Caltech, IXMAS 데이터셋에서 SCA는 대부분의 개별 작업과 평균 성능에서 Undo-Bias, UML, LRE-SVM과 같은 최신 DG 알고리즘을 능가하는 최고의 성능을 달성했습니다.
  - SCA는 원본 데이터(Raw) 대비 상당한 성능 향상을 제공하며, DICA나 uSCA와 같은 일부 알고리즘보다 뛰어난 경우가 많습니다.

## 🧠 Insights & Discussion

- **통합 프레임워크의 성공**: SCA는 산포라는 단일 기하학적 측도를 통해 도메인 적응과 도메인 일반화 문제를 성공적으로 통합했습니다. 이는 기존에 분리되어 연구되던 두 문제를 한 프레임워크 내에서 해결할 수 있는 효율적인 방법을 제시합니다.
- **산포의 중요성**: 산포는 분류 가능성, 도메인 불일치, 일반화 성능을 제어하는 핵심적인 통합 지표임이 이론적, 실험적으로 입증되었습니다. 특히 '도메인 산포'는 도메인 적응의 일반화 경계를 확립하는 데 중요한 역할을 합니다.
- **효율성과 정확성의 균형**: SCA는 일반화된 고유값 문제로의 변환을 통해 빠른 계산 속도와 함께 최신 수준의 분류 정확도를 달성했습니다. 이는 실시간 학습 단계가 필요한 응용 분야에 적합합니다.
- **확장성 및 유연성**: SCA는 Kernel PCA, Kernel Fisher Discriminant, TCA의 자연스러운 확장으로 볼 수 있으며, 클래스 산포에 대상 레이블을 통합하여 준지도 도메인 적응으로 쉽게 확장될 수 있습니다. 또한, 대규모 문제 해결을 위해 무작위 특징(random features)을 사용하여 속도를 더욱 높일 가능성이 있습니다.
- **남은 과제**: 데이터셋 편향 문제는 여전히 완전히 해결되지 않은 과제입니다. 강력한 특징 추출 방법을 사용하더라도 모든 교차 도메인 작업에서 만족스러운 성능을 보장하지 못하며, 덜 강력한 특징을 사용할 때는 성능이 더욱 저하됩니다. 이는 더 근본적인 특징 학습 알고리즘 개발의 필요성을 시사합니다.

## 📌 TL;DR

**문제**: 기존 도메인 적응(DA) 및 도메인 일반화(DG) 알고리즘은 계산상 비효율적이고, 데이터셋 편향(dataset bias)으로 인해 한 도메인에서 학습한 모델이 다른 도메인에 잘 일반화되지 못하는 문제를 겪습니다. 또한, DA와 DG를 통합적으로 해결하는 효율적인 프레임워크가 부족합니다.

**제안 방법**: 본 논문은 **산포 성분 분석(Scatter Component Analysis, SCA)**을 제안합니다. SCA는 재현 커널 힐베르트 공간(RKHS)에서 '산포(scatter)'라는 기하학적 측도를 활용하여 특징 표현을 학습하는 빠르고 통합적인 알고리즘입니다. SCA는 클래스 분리도를 최대화하고 데이터의 전체 가변성을 높이며, 동시에 도메인 간 불일치와 클래스 내 산포를 최소화하는 투영을 찾습니다. 이 최적화 문제는 일반화된 고유값 문제로 변환되어 빠르고 정확한 해를 제공합니다.

**핵심 결과**: SCA는 DA와 DG 설정 모두에서 최신 수준의 분류 정확도를 달성하며, 기존 최신 알고리즘들(예: TJM, LRE-SVM)보다 훨씬 빠릅니다. 또한, '도메인 산포'가 DA의 일반화 성능을 제어함을 보여주는 이론적 경계를 확립하여 산포의 중요성을 강조합니다. SCA는 두 문제를 효율적으로 해결하는 효과적인 통합 프레임워크임을 입증했습니다.
