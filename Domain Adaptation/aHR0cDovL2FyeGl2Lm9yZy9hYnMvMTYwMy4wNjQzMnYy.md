# Beyond Sharing Weights for Deep Domain Adaptation

Artem Rozantsev, Mathieu Salzmann, Pascal Fua

---

## 🧩 해결하고자 하는 문제

특정 도메인의 데이터로 학습된 분류기는 관련이 있지만 다른 도메인에 적용될 때 성능이 저하되는 경향이 있습니다. 새로운 도메인에서 많은 샘플에 주석을 다는 것은 비용이 많이 들고 비실용적인 경우가 많습니다. 기존의 딥 도메인 적응(Deep Domain Adaptation) 방법들은 소스 및 타겟 도메인에 대해 네트워크 가중치를 공유하여 도메인 불변(domain-invariant) 특징을 학습하려고 시도하지만, 이는 분류기의 식별력(discriminative power)에 해로울 수 있다는 가설이 제기됩니다.

## ✨ 주요 기여

- **두 스트림 아키텍처 제안**: 소스 도메인과 타겟 도메인에 각각 작동하는 두 개의 CNN 스트림을 가진 아키텍처를 도입했습니다.
- **가중치 연관성 모델링**: 기존의 가중치 공유 방식과 달리, 상응하는 계층의 가중치가 서로 `선형 변환` 관계를 가지도록 정규화하는 새로운 손실 함수($L_w$)를 제안하여 도메인 간의 명시적인 이동(shift)을 모델링합니다.
- **MMD 기반의 자동 계층 선택 기준**: 어떤 계층의 가중치를 공유하고 어떤 계층은 공유하지 않을지($L_w$를 적용할지)를 결정하는 MMD(Maximum Mean Discrepancy) 기반의 기준을 제시했습니다.
- **성능 향상 입증**: 여러 객체 인식 및 탐지 작업에서 기존 최첨단 방법보다 더 높은 정확도를 달성하며, 가중치를 공유하는 네트워크를 지속적으로 능가함을 감독 및 비감독 설정 모두에서 입증했습니다.
- **다양한 작업에 대한 일반화**: 분류 및 회귀 문제(UAV 탐지, 얼굴 자세 추정, Office, MNIST+USPS 데이터셋) 모두에서 합성 데이터를 활용하는 효과를 보여주었습니다.

## 📎 관련 연구

- **전통적인 도메인 적응**: SVM [11, 4], Boosted Decision Trees [3]와 같은 분류기를 사용하거나, 선형 [41] 또는 비선형 [30] 교차 도메인 변환 학습, 부분 공간 정렬 [12] 또는 보간 [20, 19, 6]을 통해 도메인 이동을 다룹니다.
- **딥러닝 기반 도메인 적응**:
  - **미세 조정(Fine-tuning)**: 소스 데이터로 사전 학습된 모델을 타겟 데이터로 미세 조정 [17, 37].
  - **MMD(Maximum Mean Discrepancy) 기반**: 딥 네트워크로 학습된 소스 및 타겟 데이터 표현 간의 MMD 손실을 최소화하여 도메인 불변 특징을 학습 [44, 34]. 대표적으로 DDC(Deep Domain Confusion) [44]가 있습니다.
  - **도메인 혼란(Domain Confusion) 분류기**: 학습된 특징이 도메인 불변이라면 도메인 분류기가 제대로 작동하지 않아야 한다는 아이디어를 활용 [14, 43]. 대표적으로 GRL(Gradient Reversal Layer) [14]이 있습니다.
  - **가중치 공유**: 위에 언급된 대부분의 딥러닝 기반 접근 방식들은 소스 및 타겟 도메인 모두에 동일한 아키텍처와 가중치를 사용하여 도메인 불변 특징을 학습하려 합니다.

## 🛠️ 방법론

본 논문의 핵심 아이디어는 딥 네트워크가 다른 도메인에 적응하기 위해 가중치가 관련되어 있지만 각 도메인마다 달라야 한다는 것입니다. 이를 구현하기 위해 다음과 같은 방법을 사용합니다.

- **두 스트림 아키텍처**:
  - 하나의 스트림은 소스 데이터($X_s, Y_s$)에, 다른 하나는 타겟 데이터($X_t, Y_t$)에 작동합니다.
  - 두 스트림은 공동으로 학습됩니다.
- **손실 함수**: 전체 네트워크는 다음 손실 함수를 최소화하도록 학습됩니다.
  $$L(\theta_s, \theta_t | X_s, Y_s, X_t, Y_t) = L_s + L_t + L_w + L_{MMD}$$
  - $L_s$: 소스 스트림의 표준 분류 손실. (예: 로지스틱 손실 또는 힌지 손실)
    $$L_s = \frac{1}{N_s}\sum_{i=1}^{N_s}c(\theta_s|x_s^i,y_s^i)$$
  - $L_t$: 타겟 스트림의 표준 분류 손실. 비감독 시나리오에서는 $N_t^l = 0$이므로 이 항은 무시됩니다.
    $$L_t = \frac{1}{N_t^l}\sum_{i=1}^{N_t^l}c(\theta_t|x_t^i,y_t^i)$$
  - $L_w$ (가중치 정규화): 두 스트림의 상응하는 계층 가중치 $\theta_s^j, \theta_t^j$ 간의 `선형 변환`을 장려합니다.
    - 다음 두 가지 형태 중 하나를 사용합니다 (실험적으로 지수 형태가 더 나은 결과를 보였습니다).
      - $L_2$ 노름: $r_w(\theta_s^j, \theta_t^j) = ||a_j \theta_s^j + b_j - \theta_t^j||_2^2$
      - 지수 형태: $r_w(\theta_s^j, \theta_t^j) = \exp(||a_j \theta_s^j + b_j - \theta_t^j||_2) - 1$
    - $a_j$와 $b_j$는 각 계층 $j \in \Omega$에 대해 학습되는 스칼라 파라미터입니다.
    - $\Omega$는 파라미터를 공유하지 않는 계층의 인덱스 집합입니다.
  - $L_{MMD}$ (비감독 정규화): 소스 및 타겟 스트림의 최종 특징 표현 간의 MMD를 최소화합니다. 이는 두 도메인의 특징 분포가 유사하도록 유도합니다.
    $$r_u(\theta_s, \theta_t|X_s, X_t) = \sum_{i,i'}\frac{k(f_s^i,f_s^{i'})}{(N_s)^2} - 2\sum_{i,j}\frac{k(f_s^i,f_t^j)}{N_s N_t} + \sum_{j,j'}\frac{k(f_t^j,f_t^{j'})}{(N_t)^2}$$
    - 여기서 $k(\cdot,\cdot)$는 RBF 커널을 사용합니다.
- **학습 과정**:
  1. 소스 스트림을 소스 데이터만 사용하여 사전 학습합니다.
  2. 사전 학습된 소스 가중치로 타겟 스트림 가중치를 초기화합니다.
  3. 선형 변환 파라미터 $a_j = 1$, $b_j = 0$으로 초기화합니다.
  4. AdaDelta 알고리즘 [45]과 역전파(backpropagation)를 사용하여 미니 배치 단위로 모든 파라미터를 공동으로 학습합니다.
- **계층 선택 기준**: MMD$^2$ 값을 사용하여 어떤 계층의 가중치를 공유하고 어떤 계층은 공유하지 않을지 결정합니다. MMD$^2$ 값이 낮을수록 도메인 이동을 더 잘 설명하는 것으로 간주합니다.

## 📊 결과

- **UAV 탐지 (감독 학습, 합성→실제)**:
  - `UAV-200(small)` 데이터셋에서 DDC [44]를 포함한 최첨단 방법들을 정확도 면에서 크게 능가했습니다 (본 방법: 0.92 vs DDC: 0.89).
  - `UAV-200(full)` 데이터셋에서는 DDC 대비 약 10% AP(Average Precision) 향상 (본 방법: 0.732 vs DDC: 0.664)을 보였으며, 모든 손실 항이 성능 향상에 기여했습니다.
  - 적은 수의 실제 샘플(200개)만으로도 많은 실제 샘플(2500개)로 학습된 단일 스트림 모델과 유사한 성능을 달성하여 합성 데이터 활용의 효율성을 입증했습니다.
- **Office 데이터셋 (비감독 분류)**:
  - Amazon→Webcam, DSLR→Webcam, Webcam→DSLR의 모든 쌍에서 GRL [14]을 포함한 최첨단 방법들보다 높은 평균 정확도를 달성했습니다 (본 방법(+GRL): 0.908 vs GRL: 0.895).
  - MMD 기반 기준으로 마지막 두 개의 완전 연결 계층의 가중치를 공유하지 않는 것이 최적의 구성으로 결정되었습니다.
- **MNIST-USPS (비감독 분류)**:
  - M→U 및 U→M 적응 모두에서 DDC [44]를 포함한 기존 방법들보다 뛰어난 성능을 보였습니다 (본 방법: 0.640 vs DDC: 0.554).
  - 모든 계층에서 가중치를 공유하지 않는 것이 최상의 성능을 보였습니다.
- **얼굴 자세 추정 (감독 회귀, 합성→실제)**:
  - DDC [44]보다 높은 PCP(Percentage of Correctly estimated landmarks)-점수를 달성했습니다 (본 방법: 62.8% vs DDC: 60.3%).

## 🧠 통찰 및 논의

- **가설 검증**: 가중치를 공유하지 않고 도메인 이동을 명시적으로 모델링하는 것이 도메인 불변성을 강제하는 것보다 일반적으로 더 유익하다는 본 논문의 초기 가설이 모든 실험에서 일관되게 검증되었습니다.
- **응용 분야에 따른 계층 선택**: 최적의 가중치 비공유 계층 선택은 애플리케이션에 따라 다릅니다.
  - UAV 탐지(저수준 외관 변화): 초기 컨볼루션 계층에서 가중치 비공유가 효과적입니다.
  - Office 데이터셋(더 복잡한 고수준 변화): 마지막 두 개의 완전 연결 계층에서 가중치 비공유가 효과적입니다.
- **MMD의 실용성**: MMD 기반의 기준이 유효성 검사 데이터가 없는 경우에도 올바른 네트워크 구성을 선택하는 효과적인 방법을 제공하여, 제안된 두 스트림 접근 방식의 실용성을 높입니다.
- **향후 연구**: 더 복잡한 가중치 변환과 이러한 변환 파라미터에 대한 효과적인 제약 조건을 설계하는 연구가 필요합니다.

## 📌 TL;DR

- **문제**: 기존 딥 도메인 적응은 가중치를 공유하여 도메인 불변 특징을 학습하지만, 이는 식별력을 저해할 수 있습니다.
- **방법**: 소스와 타겟 도메인 각각에 대한 `두 스트림 CNN`을 제안합니다. 이 아키텍처는 상응하는 계층의 가중치가 `선형 변환` 관계를 통해 서로 `관련되지만 공유되지는 않도록` 정규화합니다. 또한, MMD 기반의 기준을 사용하여 어떤 계층의 가중치를 공유하지 않을지(`related but not shared`) 자동으로 결정합니다.
- **결과**: 감독 및 비감독 설정에서 분류(UAV, Office, MNIST-USPS) 및 회귀(얼굴 자세 추정)와 같은 다양한 작업에서 최첨단 성능을 달성하며, 도메인 불변성 강제 대신 도메인 이동을 명시적으로 모델링하는 것이 더 효과적임을 입증했습니다. MMD 기반 기준은 최적의 계층 구성 선택에 도움을 줍니다.
