# Learning to Transfer Examples for Partial Domain Adaptation

Zhangjie Cao, Kaichao You, Mingsheng Long, Jianmin Wang, and Qiang Yang

## 🧩 Problem to Solve

기존 도메인 적응(Domain Adaptation) 연구는 소스 도메인과 타겟 도메인이 동일한 레이블 공간을 공유한다는 가정을 전제로 합니다. 하지만 현실 세계에서는 타겟 레이블이 소스 레이블의 부분집합인 _부분 도메인 적응(Partial Domain Adaptation, PDA)_ 시나리오가 더 흔합니다. 이 시나리오에서는 레이블이 지정되지 않은 타겟 도메인의 레이블을 알 수 없기 때문에, 소스 도메인에 타겟 도메인과 공유되지 않는 "아웃라이어(outlier)" 클래스들이 존재하게 됩니다.

이러한 PDA 상황에서 발생하는 주요 문제는 다음과 같습니다:

1. **긍정적 전이 촉진:** 공유된 클래스에 속하는 _관련 있는_ 소스 예제를 어떻게 식별하고 전이하여 지식 전이를 촉진할 것인가?
2. **부정적 전이 완화:** 아웃라이어 클래스에 속하는 _관련 없는_ 소스 예제를 어떻게 무시하여 모델 성능을 저해하는 부정적 전이를 완화할 것인가?
   기존 PDA 방법들은 아웃라이어 클래스의 부정적인 영향을 충분히 해소하지 못하며, 식별적인(discriminative) 정보를 활용하지 않아 전이 가능성(transferability) 평가가 미흡하다는 한계가 있었습니다.

## ✨ Key Contributions

본 논문은 부분 도메인 적응(PDA)을 위한 통합된 접근 방식인 **Example Transfer Network (ETN)**를 제안하며, 다음과 같은 주요 기여를 합니다:

- **통합된 전이 가능성 가중치 프레임워크:** 도메인 불변 표현 학습과 소스 예제의 전이 가능성을 정량화하는 점진적인 가중치 체계를 공동으로 학습합니다. 특히, 소스 분류기($G_y$)와 도메인 식별자($G_d$) 모두에 전이 가능성 가중치를 적용하여 관련 없는 예제의 영향을 효과적으로 줄입니다.
- **식별적 정보가 통합된 전이 가능성 정량화:** 보조 도메인 식별자($\tilde{G_d}$)와 보조 레이블 예측기($\tilde{G_y}$)를 활용하여 식별적 정보를 전이 가능성 측정에 통합합니다. 이는 공유 클래스와 아웃라이어 클래스 간의 모호성을 해결하고, 더 정확하고 식별적인 전이 가능성 가중치 $w(x_s)$를 생성합니다.
- **부정적 전이 효과적인 완화:** 아웃라이어 클래스에 속하는 소스 예제에 낮은 가중치를 부여함으로써, 소스 분류기와 도메인 식별자 학습 모두에서 아웃라이어 클래스의 부정적인 영향을 효과적으로 줄이고, 관련 예제의 긍정적인 전이를 촉진합니다.
- **최첨단 성능 달성:** 여러 벤치마크 데이터셋(Office-31, Office-Home, ImageNet-Caltech)에서 기존 PDA 방법들 대비 일관되게 최첨단 성능을 달성하여 모델의 효과성과 견고성을 입증했습니다.

## 📎 Related Works

본 연구는 다음 주요 선행 연구들을 참조합니다:

- **일반 도메인 적응(Standard Domain Adaptation):**
  - **모멘트 매칭(Moment Matching):** DAN [21], RTN [22], JAN [23]과 같이 도메인 간의 분포 모멘트를 직접 매칭하여 도메인 불변 특징을 학습하는 방법들.
  - **적대적 학습(Adversarial Training):** DANN [10], ADDA [37], Cycada [17]와 같이 도메인 식별자와 특징 추출기가 적대적으로 경쟁하며 도메인 불변 특징을 학습하는 방법들.
- **부분 도메인 적응(Partial Domain Adaptation, PDA):**
  - **Selective Adversarial Network (SAN) [5]:** 여러 개의 적대적 네트워크와 가중치 메커니즘을 사용하여 아웃라이어 클래스의 소스 예제를 선택적으로 제외합니다.
  - **Partial Adversarial Domain Adaptation (PADA) [6]:** 하나의 적대적 네트워크를 사용하고, 소스 분류기에 클래스 수준의 가중치를 추가하여 SAN을 개선합니다.
  - **Importance Weighted Adversarial Nets (IWAN) [43]:** 보조 도메인 분류기의 시그모이드(Sigmoid) 출력을 사용하여 소스 예제가 타겟 도메인에 속할 확률을 도출하고, 이를 적대적 도메인 네트워크에서 소스 예제에 대한 가중치로 사용합니다.
- **오픈-셋 도메인 적응(Open-Set Domain Adaptation, OSDA):** 테스트 시 인라이어(inlier)를 정확하게 인식하면서 아웃라이어(outlier)를 거부하는 것을 목표로 합니다 [4, 33]. ETN과 달리 OSDA는 훈련 중에 공유 클래스가 알려져 있다고 가정하는 경우가 많습니다.

## 🛠️ Methodology

ETN은 다음 단계로 구성된 미니맥스 최적화(minimax optimization) 문제를 통해 학습됩니다:

1. **전이 가능성 가중치 프레임워크 ($G_f, G_y, G_d$):**

   - **목표:** 전이 가능한 특징 추출기($G_f$)와 적응형 분류기($G_y$)를 학습하여 도메인 간 분포 차이를 줄이고 타겟 위험을 최소화합니다.
   - **손실 함수:**
     - 소스 분류기($G_y$)의 손실 ($E_{G_y}$): 가중치 $w(x_s)$가 적용된 소스 분류 손실과 타겟 예제의 불확실성을 최소화하는 엔트로피 최소화 항을 포함합니다.
       $$E_{G_y} = \frac{1}{n_s} \sum_{i=1}^{n_s} w(x_s_i) L(G_y(G_f(x_s_i)), y_s_i) + \frac{\gamma}{n_t} \sum_{j=1}^{n_t} H(G_y(G_f(x_t_j)))$$
     - 도메인 식별자($G_d$)의 손실 ($E_{G_d}$): 가중치 $w(x_s)$가 적용된 소스 도메인 분류 손실과 타겟 도메인 분류 손실을 포함합니다.
       $$E_{G_d} = - \frac{1}{n_s} \sum_{i=1}^{n_s} w(x_s_i) \log (G_d(G_f(x_s_i))) - \frac{1}{n_t} \sum_{j=1}^{n_t} \log (1 - G_d(G_f(x_t_j)))$$
   - **최적화 목표:**
     - $(\hat{\theta_f}, \hat{\theta_y}) = \arg \min_{\theta_f, \theta_y} E_{G_y} - E_{G_d}$ (특징 추출기와 분류기는 도메인 식별자를 속이고 분류 성능을 높임)
     - $(\hat{\theta_d}) = \arg \min_{\theta_d} E_{G_d}$ (도메인 식별자는 소스와 타겟 도메인을 구분)

2. **예제 전이 가능성 정량화 ($w(x_s)$):**

   - **보조 레이블 예측기 ($\tilde{G_y}$):** 특징 추출기 $G_f$의 출력에 대해 누출 소프트맥스(leaky-softmax) 활성화 함수를 사용하여 $|C_s|$차원 벡터 $z$를 예측합니다.
     $$\tilde{\sigma}(z) = \frac{\exp(z)}{|C_s| + \sum_{c=1}^{|C_s|} \exp(z_c)}$$
     이 예측기는 소스 예제에 대해 특정 소스 클래스에 속할 확률을 높게, 타겟 예제에 대해서는 불확실한 예측을 하도록 훈련됩니다.
   - **보조 도메인 식별자 ($\tilde{G_d}$):** $\tilde{G_y}$의 출력 ($ \tilde{G*{yc}}(G_f(x_i)) $)의 합으로 정의되어 각 예제가 소스 도메인에 속할 확률을 계산합니다.
        $$\tilde{G_d}(G_f(x_i)) = \sum*{c=1}^{|C*s|} \tilde{G*{yc}}(G_f(x_i))$$
        $\tilde{G_d}(G_f(x_i))$ 값이 작을수록 해당 예제가 타겟 도메인에 더 가깝고 공유 레이블 공간에 속할 가능성이 높다고 판단합니다.
   - **보조 모듈 학습 ($E_{\tilde{G_y}}, E_{\tilde{G_d}}$):**
     - $E_{\tilde{G_y}}$: 소스 레이블에 대한 다중 작업(one-vs-rest) 이진 분류 손실로 $\tilde{G_y}$를 훈련합니다.
     - $E_{\tilde{G_d}}$: $\tilde{G_d}$가 소스 및 타겟 특징을 구분하도록 훈련합니다.
       이러한 방식은 $\tilde{G_d}$가 레이블 정보와 도메인 정보를 모두 활용하여 식별적인 가중치를 생성하도록 합니다.
   - **전이 가능성 가중치 계산:**
     $$w(x_s_i) = 1 - \tilde{G_d}(G_f(x_s_i))$$
     가중치는 미니배치 내에서 정규화됩니다.

3. **최종 미니맥스 최적화:** 위에서 정의된 모든 목적 함수를 통합하여 $\theta_f, \theta_y, \theta_d, \theta_{\tilde{y}}$ 매개변수를 공동으로 최적화합니다.

## 📊 Results

ETN은 ResNet-50 및 VGG 백본을 사용하여 Office-31, Office-Home, ImageNet-Caltech과 같은 여러 벤치마크 데이터셋에서 광범위하게 평가되었습니다.

- **최첨단 성능:** ETN은 모든 데이터셋과 백본 네트워크에서 평균 정확도 면에서 기존의 심층 학습 및 (부분) 도메인 적응 방법들을 일관되게 능가하며 최첨단(state-of-the-art) 결과를 달성했습니다.
  - Office-Home: 평균 70.45% 정확도로 경쟁 방법들(SAN 65.30%, IWAN 63.56%)을 크게 앞섰습니다.
  - Office-31: 평균 96.73% 정확도로 SAN (94.96%) 및 IWAN (94.69%)보다 높은 성능을 보였습니다.
  - ImageNet-Caltech (대규모 데이터셋): 평균 79.08% 정확도로, 많은 아웃라이어 클래스(ImageNet→Caltech의 경우 916개)가 있는 경우에도 ETN이 SAN (76.51%) 및 IWAN (75.70%)보다 훨씬 견고함을 보여주었습니다.
- **모듈별 효과 검증 (Ablation Study):**
  - "ETN w/o classifier"는 ETN보다 성능이 낮았는데, 이는 소스 분류기에 가중치를 부여하는 메커니즘이 아웃라이어 클래스의 부정적인 영향을 줄이고 공유 레이블 공간에 집중하는 데 중요하다는 것을 보여줍니다.
  - "ETN w/o auxiliary"는 ETN보다 훨씬 낮은 성능을 보였는데, 이는 보조 분류기가 도메인 식별자에 레이블 정보를 주입하여 식별적인 가중치를 생성하고 관련 없는 예제를 필터링하는 데 필수적임을 입증합니다.
- **수렴 성능:** ETN은 다른 비교 방법들보다 더 효율적이고 안정적으로 수렴하여 가장 낮은 테스트 오류율에 도달했습니다.

## 🧠 Insights & Discussion

ETN의 성공은 다음 통찰력에 기반합니다.

- **식별적 가중치 학습의 중요성:** 기존 PDA 방법들은 전이 가능성을 평가할 때 도메인 정보만을 사용하거나 소스 분류기에는 가중치를 적용하지 않아 한계가 있었습니다. ETN은 보조 레이블 예측기를 통해 식별적 정보를 전이 가능성 정량화에 통합함으로써, 공유 클래스와 아웃라이어 클래스를 더욱 명확하게 구분하고 아웃라이어 예제에 거의 0에 가까운 가중치를 할당할 수 있음을 입증했습니다. 이는 특징 시각화(t-SNE) 및 가중치 시각화에서도 뚜렷하게 나타났습니다.
- **소스 분류기에 대한 가중치의 영향:** 소스 분류기($G_y$) 학습 과정에서 관련 없는 소스 예제에 낮은 가중치를 부여함으로써, 모델은 타겟 도메인과 관련된 지식에 더 집중할 수 있게 됩니다. 이는 "ETN w/o classifier" 변형과의 비교를 통해 확인되었으며, 모델의 견고성과 성능 향상에 기여합니다.
- **다양한 PDA 시나리오에 대한 견고성:** 타겟 클래스 수가 감소하여 부정적 전이가 심화되는 시나리오에서도 ETN은 일관되게 안정적인 성능을 보여주었습니다. 특히 대규모 데이터셋에서 많은 아웃라이어 클래스가 존재할 때 다른 방법들보다 월등한 성능을 발휘하며, 실제 적용 가능성을 높입니다.
- **한계 및 향후 연구:** 본 연구는 타겟 클래스가 훈련 시 완전히 알려지지 않은 PDA 시나리오를 다룹니다. 향후 연구에서는 오픈-셋 도메인 적응(OSDA)과 같이 타겟 도메인에 완전히 새로운 클래스가 존재할 수 있는 보다 일반적인 오픈-셋 시나리오로 확장을 고려할 수 있습니다.

## 📌 TL;DR

ETN은 부분 도메인 적응(PDA)을 위한 강력한 신경망으로, 소스 레이블 공간이 타겟 레이블 공간을 포함하는 상황에서 부정적 전이를 완화합니다. 핵심 아이디어는 소스 예제의 전이 가능성을 식별적으로 정량화하고, 이 가중치를 소스 분류기 및 도메인 식별자 학습 모두에 적용하는 것입니다. ETN은 보조 레이블 예측기와 보조 도메인 식별자를 사용하여 공유 클래스와 아웃라이어 클래스를 명확히 구분하는 가중치를 학습하며, 이를 통해 관련 예제만 효과적으로 전이시킵니다. 여러 벤치마크 데이터셋에서 기존 방법들을 능가하는 최첨단 성능을 달성하여, PDA 문제에 대한 효과적이고 견고한 해결책을 제시합니다.
