# Maximum Classifier Discrepancy for Unsupervised Domain Adaptation

Kuniaki Saito, Kohei Watanabe, Yoshitaka Ushiku, and Tatsuya Harada

## 🧩 Problem to Solve

비지도 도메인 적응(Unsupervised Domain Adaptation, UDA)은 레이블이 풍부한 소스 도메인에서 레이블이 없는 타겟 도메인으로 지식을 전이하는 것을 목표로 합니다. 기존의 적대적 학습 기반 UDA 방법들은 다음과 같은 두 가지 주요 문제점을 가지고 있습니다:

1. **태스크별 결정 경계 미고려:** 도메인 분류기가 단순히 특징이 소스인지 타겟인지만을 구분하려 하므로, 클래스 간의 태스크별 결정 경계를 고려하지 않습니다. 이로 인해 학습된 특징 생성기는 클래스 경계 근처에서 모호한(ambiguous) 타겟 특징을 생성할 수 있습니다.
2. **분포 일치화의 어려움:** 각 도메인의 고유한 특성 때문에 소스와 타겟 도메인 간의 특징 분포를 완전히 일치시키는 것은 어렵습니다.

## ✨ Key Contributions

- **새로운 적대적 학습 기반 DA 방법론 제안:** 태스크별 결정 경계를 고려하여 타겟 도메인의 분포를 정렬하려는 새로운 적대적 학습 기반 도메인 적응 방법을 제안합니다.
- **장난감 문제(Toy Problem)를 통한 동작 확인:** 제안된 방법이 실제 어떻게 동작하는지 직관적으로 이해할 수 있도록 장난감 문제에서 그 동작을 시각적으로 확인했습니다.
- **다양한 태스크에서의 광범위한 평가:** 숫자 분류, 객체 분류, 의미론적 분할 등 다양한 컴퓨터 비전 태스크에서 제안된 방법의 성능을 광범위하게 평가하여 우수성을 입증했습니다.

## 📎 Related Works

- **분포 일치화 방법:** 오토인코더(Ghifary et al.), 클러스터링 및 의사 레이블(Sener et al.), 도메인 간 이미지 변환(Taigman et al.) 등 다양한 방법이 존재합니다. 특히, 생성적 적대 신경망(GAN) 기반의 도메인 분류기(DANN [8])나 최대 평균 불일치(MMD [22, 21])를 사용하여 소스와 타겟 도메인 특징 분포를 정렬하려는 시도들이 있습니다. 이러한 방법들은 일반적으로 태스크별 결정 경계와 타겟 샘플 간의 관계를 명시적으로 고려하지 않는다는 한계가 있습니다.
- **컨센서스 정규화(Consensus Regularization) [23]:** 다중 소스 도메인 적응이나 다중 뷰 학습에서 여러 분류기의 출력 간 컨센서스를 최대화하는 기법입니다. 본 논문에서 제안하는 방법은 두 분류기의 불일치(discrepancy)를 최소화하는 방향으로 학습이 진행되며, 단일 소스 도메인에서도 상이한 분류기를 구성할 수 있다는 점에서 차이가 있습니다.

## 🛠️ Methodology

본 논문은 특징 생성기 $G$와 두 개의 태스크별 분류기 $F_1, F_2$를 활용하는 적대적 학습 방식을 제안합니다. 핵심 아이디어는 두 분류기의 타겟 샘플에 대한 예측 불일치($d(p_1(y|x_t), p_2(y|x_t))$)를 사용하여 소스 분포의 지원(support) 범위 밖에 있는 타겟 샘플을 탐지하는 것입니다.

- **불일치(Discrepancy) 손실 함수:**
  두 분류기의 확률적 출력 $p_1, p_2$ 간의 절대 차이 합(L1-거리)을 불일치 손실로 정의합니다:
  $$d(p_1, p_2) = \frac{1}{K} \sum_{k=1}^{K} |p_{1k} - p_{2k}|$$
  여기서 $p_{1k}$와 $p_{2k}$는 각각 분류기 $F_1$과 $F_2$가 클래스 $k$에 대해 예측한 확률을 나타냅니다.

- **학습 과정 (세 단계의 적대적 학습):**

  1. **Step A (소스 분류 정확도 보장):** 생성기 $G$와 분류기 $F_1, F_2$를 소스 도메인 샘플($X_s, Y_s$)에 대해 올바르게 분류하도록 훈련합니다. 이는 태스크별 식별 특징을 추출하는 데 중요합니다. 목적 함수는 소프트맥스 교차 엔트로피 손실을 최소화하는 것입니다.
     $$ \min\_{G,F_1,F_2} L(X_s,Y_s) $$
  2. **Step B (타겟 불일치 최대화):** 생성기 $G$를 고정한 상태에서 분류기 $F_1, F_2$를 훈련하여 타겟 샘플($X_t$)에 대한 예측 불일치를 최대화합니다. 이와 동시에 소스 샘플에 대한 분류 손실은 계속 최소화합니다. 이는 $F_1, F_2$가 소스 지원 범위 밖의 타겟 샘플을 효과적으로 탐지하도록 만듭니다.
     $$ \min*{F_1,F_2} L(X_s,Y_s) - L*{adv}(X*t) $$
     여기서 $L*{adv}(X*t) = E*{x_t \sim X_t}[d(p_1(y|x_t), p_2(y|x_t))]$입니다.
  3. **Step C (타겟 불일치 최소화):** 분류기 $F_1, F_2$를 고정한 상태에서 생성기 $G$를 훈련하여 타겟 샘플에 대한 예측 불일치를 최소화합니다. 이 과정은 생성기가 $F_1, F_2$를 속여 타겟 특징이 소스 지원 범위 내로 들어오도록 유도합니다. 이 단계는 동일한 미니배치에 대해 $n$번 반복됩니다.
     $$ \min*{G} L*{adv}(X_t) $$

- **이론적 통찰:** 본 방법은 Ben-David et al. [1]이 제안한 $\mathcal{H}\Delta\mathcal{H}$-distance 이론에 기반을 두고 있으며, 타겟 도메인의 오류 상한과 관련이 있습니다. 특히, 두 분류기 예측의 불일치를 최대화하고 이를 다시 최소화하는 미니맥스 문제는 이론의 핵심 구성 요소와 유사합니다.

## 📊 Results

- **장난감 데이터셋:** 제안된 방법은 타겟 샘플을 고려하여 결정 경계를 효과적으로 조정했으며, 두 분류기가 타겟 샘플에 대해 거의 동일한 예측을 제공하여 대부분의 타겟 샘플을 올바르게 분류했습니다.
- **숫자 데이터셋 (SVHN→MNIST, SYN SIGNS→GTSRB, MNIST↔USPS):**
  - 대부분의 설정에서 MMD, DANN 등 기존의 SOTA(State-of-the-Art) 도메인 일치화 방법을 크게 능가하는 성능을 보였습니다.
  - 생성기 업데이트 횟수 $n$이 증가할수록 성능이 향상되는 경향을 보였습니다.
  - 훈련 중 불일치 손실이 감소함에 따라 정확도가 향상되는 것이 확인되어, 불일치 최소화가 정확한 적응으로 이어짐을 입증했습니다.
  - t-SNE 시각화 결과, 본 방법은 소스와 타겟 분포를 완전히 일치시키지 않으면서도, 타겟 샘플이 각 클래스에 대해 식별력 있게 정렬됨을 보여주었습니다.
- **VisDA 객체 분류 데이터셋 (합성→실제):**
  - MMD 및 DANN보다 훨씬 우수한 정확도를 달성했습니다.
  - 일부 클래스에서 "소스 전용(Source Only)" 모델보다 성능이 떨어지는 다른 방법들과 달리, 본 방법은 모든 클래스에서 "소스 전용" 모델보다 나은 성능을 보였습니다.
- **의미론적 분할 (GTA5→Cityscapes, Synthia→Cityscapes):**
  - 합성 이미지에서 실제 이미지로의 도메인 차이가 큰 상황에서도, "소스 전용" 모델 및 DANN 대비 mIoU(mean Intersection-over-Union)를 크게 개선했습니다.
  - 정성적 결과 또한 타겟 이미지에 대한 분할 성능이 시각적으로 향상되었음을 보여주었습니다.
  - 추가적으로, Gradient Reversal Layer(GRL)를 사용한 학습 방식도 유사한 성능을 달성하여 학습 과정을 간소화할 수 있음을 입증했습니다.

## 🧠 Insights & Discussion

- **태스크별 결정 경계 활용의 중요성:** 이 논문의 핵심 통찰은 두 개의 태스크별 분류기 간의 불일치를 활용하여 소스 지원 범위 밖에 있는 타겟 샘플, 즉 모호하거나 잘못 분류될 가능성이 있는 샘플을 효과적으로 식별한다는 점입니다. 이 불일치를 최소화하도록 생성기를 학습시킴으로써, 타겟 특징이 분류기들이 합의하는, 즉 소스 지원 범위 내의 식별력 있는 영역으로 유도됩니다.
- **기존 방법론의 한계 극복:** 기존의 도메인 분류기 기반 방법들이 단순히 도메인 불변 특징을 생성하려 하여 클래스 경계 부근에서 모호한 특징을 만드는 문제를 MCD는 태스크별 결정 경계를 명시적으로 고려하여 해결합니다.
- **다목적성 및 견고성:** 분류, 의미론적 분할 등 다양한 컴퓨터 비전 태스크와 서로 다른 도메인 간의 적응 문제에서 뛰어난 성능을 보여, 제안된 방법론의 일반성과 견고성을 입증했습니다.
- **이론적 기반:** $\mathcal{H}\Delta\mathcal{H}$-distance 이론과의 연결은 제안된 적대적 목표 함수에 대한 강력한 이론적 정당성을 제공합니다.
- **한계점:** 생성기 업데이트 횟수 $n$은 중요한 하이퍼파라미터이며, $n$ 값이 클수록 훈련 시간이 길어질 수 있습니다. 하지만 Gradient Reversal Layer(GRL)의 도입은 이 하이퍼파라미터를 제거하고 훈련 과정을 간소화할 가능성을 제시합니다.

## 📌 TL;DR

기존 도메인 적응(DA) 방법들이 태스크별 결정 경계를 고려하지 않아 모호한 타겟 특징을 생성하고 도메인 분포를 완전히 일치시키기 어려운 문제를 해결하기 위해, 본 논문은 **최대 분류기 불일치(Maximum Classifier Discrepancy, MCD)** 기반의 비지도 도메인 적응(UDA) 방법을 제안합니다. 이 방법은 두 개의 태스크별 분류기($F_1, F_2$)를 사용하여 소스 분포의 지원(support) 범위 밖에 있는 타겟 샘플을 탐지하고, 특징 생성기(G)는 이 분류기들의 예측 불일치(discrepancy)를 최소화하도록 학습됩니다. 결과적으로, MCD는 분류 및 의미론적 분할 등 다양한 벤치마크에서 기존 SOTA(State-of-the-Art) 방법을 능가하는 성능을 보였으며, 이는 태스크별 결정 경계를 활용하여 타겟 특징을 소스 분포의 지원 범위 내로 끌어들여 보다 식별력 있는 특징을 생성하기 때문입니다.
