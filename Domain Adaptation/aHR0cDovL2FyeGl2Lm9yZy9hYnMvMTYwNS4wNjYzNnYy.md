# Deep Transfer Learning with Joint Adaptation Networks

Mingsheng Long, Han Zhu, Jianmin Wang, Michael I. Jordan

## 🧩 Problem to Solve

딥러닝 모델은 대규모 레이블 데이터셋이 있을 때 뛰어난 성능을 보이지만, 다양한 타겟 도메인에 대해 충분한 레이블 데이터를 수동으로 확보하는 것은 어렵습니다. 전이 학습(Transfer Learning)은 레이블이 풍부한 소스 도메인 데이터를 활용하여 레이블이 부족한 타겟 도메인에 적용하는 것을 목표로 합니다.
그러나 소스 및 타겟 도메인 간의 데이터 분포(특히 $P(X, Y)$와 같은 결합 분포) 차이(Domain Shift)는 모델 성능 저하의 주요 원인입니다. 기존의 딥 전이 학습 방법들은 주로 특징의 *주변 분포(Marginal Distribution)*를 정렬하는 데 집중했으며, 심층 신경망의 여러 계층에서 나타나는 *결합 분포의 차이*는 제대로 다루지 못했습니다. 이는 심층 특징이 네트워크를 따라 일반적인 것에서 특정적인 것으로 전환될 때 더욱 두드러집니다.

## ✨ Key Contributions

- **결합 적응 네트워크 (Joint Adaptation Networks, JAN)**: 비지도 도메인 적응을 위한 새로운 딥 전이 학습 프레임워크를 제안했습니다.
- **결합 최대 평균 불일치 (Joint Maximum Mean Discrepancy, JMMD)**: 여러 도메인 특정 계층의 활성화에 대한 *결합 분포*를 측정하고 정렬하는 새로운 기준을 도입했습니다. 이는 특징의 주변 분포만 정렬하던 기존 MMD 기반 방법들의 한계를 극복합니다.
- **선형 시간 JMMD 추정**: JMMD의 효율적이고 비편향적인 선형 시간 추정량을 도출하여, 미니 배치 SGD(Stochastic Gradient Descent)를 통한 확장 가능한 학습을 가능하게 했습니다.
- **적대적 JMMD (JAN-A)**: JMMD의 판별력을 극대화하기 위해 신경망을 사용한 적대적 학습 전략을 제안하여, 소스 및 타겟 도메인 분포를 더욱 명확하게 구별하고 적응 성능을 향상시켰습니다.
- **최첨단 성능 달성**: 표준 도메인 적응 벤치마크(Office-31, ImageCLEF-DA)에서 최첨단 결과를 달성했습니다.

## 📎 Related Works

- **얕은 전이 학습 (Shallow Transfer Learning)**: 불변 특징 표현 학습 또는 인스턴스 중요도 추정(예: TCA, GFK). 도메인 특정 변동 요인을 억제하지 못하고 수제 특징에 의존하는 한계가 있습니다.
- **심층 전이 학습 (Deep Transfer Learning)**: 심층 신경망을 활용하여 전이 가능한 표현을 학습하고, 심층 신경망 내에 도메인 적응 모듈을 통합합니다(예: DDC, DAN, RevGrad, RTN). 대부분 _주변 분포_ 정렬에 초점을 맞추며, 조건부 분포가 변하지 않거나 특정 변환만 적용된다는 가정을 합니다.
- **조건부 분포의 커널 임베딩**: 조건부 분포의 커널 임베딩을 기반으로 타겟 및 조건부 이동을 수정하는 방법을 탐색하지만, 종종 추가 가정이 필요하거나 심층 신경망의 결합 분포 이동에 직접 적용하기 어렵습니다.
- **MMD (Maximum Mean Discrepancy)**: 주변 분포 불일치를 측정하기 위해 심층 도메인 적응에서 널리 사용되는 커널 기반 두 샘플 테스트 통계량입니다. 본 논문은 MMD가 심층 신경망에서 결합 분포에 직접적으로 정의되거나 사용되지 않았음을 지적합니다.

## 🛠️ Methodology

본 논문은 여러 도메인 특정 계층의 활성화에 대한 *결합 분포*를 도메인 간에 일치시킴으로써 비지도 도메인 적응 문제를 해결하는 결합 적응 네트워크(JAN)를 제안합니다.

1. **아키텍처**:

   - CNN (AlexNet, ResNet)을 전이 파이프라인으로 확장합니다.
   - 활성화가 안전하게 전이될 수 없는 "도메인 특정 계층"($L$)을 식별합니다 (예: AlexNet의 경우 $\{fc6, fc7, fc8\}$, ResNet의 경우 $\{pool5, fc\}$).
   - 이러한 계층의 결합 활성화 $P(Z^{s1}, \ldots, Z^{s|\mathcal{L}|})$ 및 $Q(Z^{t1}, \ldots, Z^{t|\mathcal{L}|})$는 원래의 결합 분포 $P(X^s, Y^s)$ 및 $Q(X^t, Y^t)$의 대리자(surrogates)로 간주됩니다.

2. **결합 최대 평균 불일치 (JMMD)**:

   - 결합 분포의 힐베르트 공간 임베딩을 사용하여 두 결합 분포 $P(\mathbf{Z}^{s1}, \ldots, \mathbf{Z}^{s|\mathcal{L}|})$와 $Q(\mathbf{Z}^{t1}, \ldots, \mathbf{Z}^{t|\mathcal{L}|})$ 간의 불일치를 측정하기 위해 정의됩니다.
   - JMMD는 다음과 같이 정의됩니다:
     $$ D_\mathcal{L}(P,Q) = \| \mathcal{C}_{\mathbf{Z}^{s,1:|\mathcal{L}|}}(P) - \mathcal{C}_{\mathbf{Z}^{t,1:|\mathcal{L}|}}(Q) \|_{ \otimes_{l=1}^{|\mathcal{L}|} \mathcal{H}^l }^2 \tag{8} $$
     여기서 $C_{\mathbf{Z}^{s,1:|L|}}(P)$는 소스 도메인의 결합 분포에 대한 커널 평균 임베딩이며, $\otimes_{l=1}^{|L|} \phi_l(x_l)$은 텐서곱 힐베르트 공간의 특징 맵으로 내적 $\langle \otimes_{l=1}^{|L|} \phi_l(x_l), \otimes_{l=1}^{|L|} \phi_l(x'_l) \rangle = \prod_{l=1}^{|L|} k_l(x_l, x'_l)$을 만족합니다.
   - 경험적 추정량은 다음과 같습니다:
     $$
     \begin{aligned}
     \hat{D}_\mathcal{L}(P,Q) = & \; \frac{1}{n_s^2} \sum_{i=1}^{n_s} \sum_{j=1}^{n_s} \prod_{l \in \mathcal{L}} k^l(\mathbf{z}_i^{sl}, \mathbf{z}_j^{sl}) \\ & + \frac{1}{n_t^2} \sum_{i=1}^{n_t} \sum_{j=1}^{n_t} \prod_{l \in \mathcal{L}} k^l(\mathbf{z}_i^{tl}, \mathbf{z}_j^{tl}) \\ & - \frac{2}{n_s n_t} \sum_{i=1}^{n_s} \sum_{j=1}^{n_t} \prod_{l \in \mathcal{L}} k^l(\mathbf{z}_i^{sl}, \mathbf{z}_j^{tl})
     \end{aligned} \tag{9}
     $$
     이는 서로 다른 계층의 변수들 간의 상호작용을 포착합니다.
   - 효율적인 확장을 위해 *선형 시간 비편향 추정량*을 사용합니다:
     $$
     \begin{aligned}
     \hat{D}_\mathcal{L}(P,Q) = & \; \frac{2}{n} \sum_{i=1}^{n/2} \left( \prod_{l \in \mathcal{L}} k^l(\mathbf{z}_{2i-1}^{sl}, \mathbf{z}_{2i}^{sl}) + \prod_{l \in \mathcal{L}} k^l(\mathbf{z}_{2i-1}^{tl}, \mathbf{z}_{2i}^{tl}) \right) \\
     & - \frac{2}{n} \sum_{i=1}^{n/2} \left( \prod_{l \in \mathcal{L}} k^l(\mathbf{z}_{2i-1}^{sl}, \mathbf{z}_{2i}^{tl}) + \prod_{l \in \mathcal{L}} k^l(\mathbf{z}_{2i-1}^{tl}, \mathbf{z}_{2i}^{sl}) \right)
     \end{aligned} \tag{11}
     $$

3. **최적화 목표 (JAN)**:

   - 소스 분류 손실과 JMMD 페널티의 합을 최소화합니다:
     $$
     \min_f \frac{1}{n_s} \sum_{i=1}^{n_s} J(f(\mathbf{x}_i^s), \mathbf{y}_i^s) + \lambda \hat{D}_\mathcal{L}(P,Q)
     \tag{10}
     $$
     여기서 $J(\cdot, \cdot)$는 교차 엔트로피 손실이며, $\lambda$는 트레이드오프 매개변수입니다.

4. **적대적 결합 적응 네트워크 (JAN-A)**:

   - 커널 기반 MMD의 잠재적 문제점(기울기 소실, 풍부하지 않은 함수 클래스)을 해결하기 위해 적대적 학습을 도입합니다.
   - JMMD 부분에 여러 완전 연결 계층(매개변수 $\theta$로 구성)을 추가합니다.
   - 최소-최대 (minimax) 목표를 최적화합니다:
     $$
     \min_f \max_\theta \frac{1}{n_s} \sum_{i=1}^{n_s} J(f(\mathbf{x}_i^s), \mathbf{y}_i^s) + \lambda \hat{D}_\mathcal{L}(P,Q; \theta)
     \tag{12}
     $$
     도메인 판별자(JMMD with $\theta$)는 소스 및 타겟 분포의 구별 가능성을 *최대화*하도록 훈련되고, 특징 추출기 $f$는 이러한 구별 가능성(및 분류 손실)을 *최소화*하도록 훈련됩니다.

5. **학습**:
   - 역전파를 사용한 확률적 경사 하강법(SGD)을 사용합니다.
   - 안정적인 학습을 위해 $\lambda$에 대한 점진적 스케줄링(0에서 1로 점진적 증가)과 학습률 어닐링 전략을 적용합니다.
   - 대역폭이 훈련 데이터의 중간 쌍별 제곱 거리로 설정된 가우시안 커널을 사용합니다.

## 📊 Results

- **최첨단 성능 달성**: JAN 모델(JAN 및 JAN-A 모두)은 표준 비지도 도메인 적응 벤치마크인 Office-31 및 ImageCLEF-DA에서 일관되게 최첨단 분류 정확도를 달성했습니다.
- **어려운 작업에서의 성능 향상**: JAN은 소스와 타겟 도메인이 크게 다르며 소스 도메인이 더 작은 "어려운" 전이 작업(예: Office-31의 D$\rightarrow$A, W$\rightarrow$A)에서 상당한 정확도 향상을 보였습니다. "쉬운" 작업에서는 비교 가능한 성능을 유지했습니다.
- **이전 딥 전이 학습 방법보다 우수**: JAN은 DDC, DAN, RevGrad, RTN과 같은 이전 방법들을 상당한 차이로 능가했습니다. 이는 주로 *주변 분포*만을 적응시킨 이전 방법(RevGrad는 단일 계층, DAN/RTN은 여러 _독립적_ 계층)과 달리, 여러 계층에서 *결합 분포*를 적응시키는 것의 중요성을 강조합니다.
- **더 깊은 네트워크의 이점**: ResNet 기반 방법은 AlexNet 기반 방법보다 현저히 우수한 성능을 보였으며, 매우 깊은 CNN이 더 전이 가능한 표현을 학습함을 확인했습니다. JAN은 ResNet 기반 모델에서도 성능을 더욱 향상시켰는데, 이는 매우 깊은 네트워크에서도 도메인 불일치가 여전히 존재하며 JAN이 이를 효과적으로 감소시킨다는 것을 나타냅니다.
- **JAN-A의 장점**: JAN-A(JMMD에 대한 적대적 학습 포함)는 JAN보다 지속적으로 우수한 성능을 보였으며, 소스 및 타겟 분포의 구별 가능성을 최대화함으로써 JMMD를 더 풍부한 함수 클래스에서 최적화하는 이점을 입증했습니다.

## 🧠 Insights & Discussion

- **강력한 결합 분포 적응**: t-SNE 시각화 결과, JAN은 DAN에 비해 타겟 카테고리를 훨씬 명확하게 구별하는 것을 보여주며, 다중 계층 활성화의 결합 분포를 적응시키는 것이 강력한 접근 방식임을 시사합니다.
- **효과적인 도메인 간극 감소**: A-거리 분석 결과, JAN 특징은 CNN 및 DAN 특징에 비해 도메인 간 간극($d_A$)을 상당히 감소시키는 것으로 나타났습니다.
- **결합 불일치 측정으로서의 JMMD**: JMMD를 직접 계산한 결과, JAN은 CNN 및 DAN보다 소스 및 타겟 결합 활성화 간의 JMMD를 더 효과적으로 감소시켰습니다. 이는 JMMD의 측정 유효성과 이를 최소화하는 방법의 성공을 입증합니다.
- **매개변수 민감도 ($\lambda$)**: JMMD 매개변수 $\lambda$의 트레이드오프가 정확도에 대해 종형 곡선(bell-shaped curve)을 보였는데, 이는 분류 손실과 도메인 정렬 사이의 적절한 균형이 최적의 전이 가능성에 중요함을 시사합니다.
- **수렴 성능**: JAN은 비모수적 JMMD 덕분에 가장 빠르게 수렴했습니다. JAN-A는 RevGrad와 유사한 수렴 속도를 가졌지만, 전체 수렴 과정에서 정확도를 크게 향상시켜 견고성과 효과를 보여주었습니다.
- **시사점**: JAN은 심층 전이 학습에서 결합 분포 적응의 중요성을 강조하고, 기존 방법들의 주변 분포 적응에 대한 한계를 극복합니다. JAN-A는 적대적 학습을 통해 JMMD의 판별력을 더욱 강화하여 복잡한 고차원 공간에서도 효과적인 적응을 가능하게 합니다.

## 📌 TL;DR

**문제:** 딥 전이 학습은 도메인 이동, 특히 딥 네트워크 계층에서 특징과 레이블의 _결합 분포_ 불일치 문제에 직면하지만, 기존 방법들은 대부분 *주변 분포*에만 초점을 맞춰왔습니다.
**방법:** 본 논문은 소스 및 타겟 도메인 간의 _다중 도메인 특정 계층_ 활성화의 *결합 분포*를 정렬하는 **결합 적응 네트워크 (JAN)**를 제안합니다. 이 결합 분포 불일치를 측정하기 위해 효율적인 선형 시간 추정량을 사용하는 **결합 최대 평균 불일치 (JMMD)**를 도입합니다. **JAN-A**라는 적대적 버전은 신경망을 사용한 최소-최대 최적화를 통해 JMMD의 판별력을 더욱 향상시킵니다.
**결과:** JAN 및 JAN-A는 표준 벤치마크에서 최첨단 결과를 달성했으며, 특히 어려운 전이 작업에서 상당한 개선을 보였습니다. 이는 딥 네트워크에서 더욱 전이 가능한 표현을 학습하는 데 있어 *결합 분포 적응*의 중요성과 효과를 입증합니다.
