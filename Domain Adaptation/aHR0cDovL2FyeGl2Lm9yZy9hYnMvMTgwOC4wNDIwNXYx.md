# Partial Adversarial Domain Adaptation

Zhangjie Cao, Lijia Ma, Mingsheng Long, and Jianmin Wang

## 🧩 Problem to Solve

기존의 도메인 적응(Domain Adaptation, DA) 방법들은 소스(source) 도메인과 타겟(target) 도메인이 동일한 레이블 공간을 공유한다고 가정합니다. 그러나 빅데이터 시대에는 ImageNet과 같이 거대한 소스 도메인에서 Caltech-256과 같은 작은 타겟 도메인으로 딥 모델을 전이해야 하는 경우가 많으며, 이 경우 소스 도메인의 레이블 공간이 타겟 도메인의 레이블 공간을 포괄하는(즉, 타겟 레이블 공간이 소스 레이블 공간의 부분집합인) **부분 도메인 적응(Partial Domain Adaptation)** 시나리오가 발생합니다.

이 시나리오에서, 타겟 도메인에는 존재하지 않는 소스 도메인의 '이상치 클래스(outlier source classes)'는 특징 분포를 잘못 정렬시켜 성능을 저하시키는 **부정적 전이(negative transfer)** 문제를 야기합니다. 기존 방법들은 전체 소스 도메인을 타겟 도메인과 매칭하려고 시도하므로, 이러한 레이블 공간 불일치에 취약합니다. 학습 중에 타겟 클래스를 알 수 없기 때문에 어떤 클래스가 이상치 클래스인지 식별하고 그 영향을 완화하는 것이 핵심 과제입니다.

## ✨ Key Contributions

- **부분 도메인 적응(Partial Domain Adaptation)**이라는 새로운 도메인 적응 시나리오를 정의하고, 소스 레이블 공간이 타겟 레이블 공간을 포함($C_t \subset C_s$)하는 보다 일반적인 상황을 다룹니다.
- **PADA(Partial Adversarial Domain Adaptation)**라는 종단 간(end-to-end) 딥러닝 프레임워크를 제안합니다.
- PADA는 소스 분류기 학습과 도메인 적대 학습(domain adversarial learning) 모두에서 이상치 소스 클래스 데이터의 기여도를 낮춤으로써 부정적 전이를 동시에 완화합니다.
- 공유 레이블 공간 내에서 특징 분포를 효과적으로 매칭하여 긍정적 전이(positive transfer)를 촉진합니다.
- 여러 벤치마크 데이터셋에서 부분 도메인 적응 태스크에 대해 최첨단(state-of-the-art) 성능을 달성함을 실험을 통해 입증했습니다.

## 📎 Related Works

- **일반적인 도메인 적응:** 수동 레이블링 부담을 줄이기 위해 서로 다른 분포를 따르는 도메인 간의 격차를 줄이는 연구 [1, 2].
- **딥 도메인 적응:** 딥 네트워크를 활용하여 도메인 불변 특징 표현을 학습하는 방법들.
  - **MMD(Maximum Mean Discrepancy) 기반 방법:** DAN [7], RTN [8], JAN [9]은 MMD를 최소화하여 분포의 커널 임베딩을 매칭합니다.
  - **적대적 도메인 적응:** DANN [10], ADDA [12]는 도메인 판별자를 사용하여 도메인 간 특징을 구분할 수 없도록 특징 추출자를 훈련하는 2인 미니맥스 게임(two-player minimax game)을 수행합니다.
- **레이블 공간 불일치 관련 연구:** Label Efficient Learning (LEL) [25]은 엔트로피 최소화와 쌍별 유사성(pairwise similarity)을 확장하여 다른 레이블 공간을 다루지만, 여전히 부분 도메인 적응의 이상치 클래스 문제를 직접적으로 다루지는 않습니다. Adaptive Deep Learning [26]은 도메인 이동에 책임이 있는 이미지 영역을 국소화하여 부정적 전이를 줄이려 시도하지만, 관련 영역이 없는 이미지에서는 실패할 수 있습니다.
- **기존 방법의 한계:** 대부분의 기존 딥 도메인 적응 방법은 소스와 타겟 도메인이 동일한 레이블 공간을 공유($C_s = C_t$)한다는 가정을 전제로 하므로, 부분 도메인 적응 시나리오에 직접 적용하기 어렵습니다.

## 🛠️ Methodology

PADA는 기존 DANN(Domain Adversarial Neural Network) 프레임워크를 부분 도메인 적응 시나리오에 맞게 확장합니다. 핵심 아이디어는 이상치 소스 클래스($C_s \setminus C_t$)에 속하는 데이터의 기여도를 낮추는 것입니다.

1. **클래스 가중치($\gamma$) 계산:**

   - 타겟 도메인 데이터 $D_t = \{x_i^t\}_{i=1}^{n_t}$에 대해 현재 훈련된 소스 분류기 $G_y(G_f(x_i^t))$의 소프트맥스(softmax) 확률 예측 $\hat{y}_i$를 얻습니다.
   - 타겟 데이터는 이상치 클래스에 속하지 않으므로, 이상치 클래스에 대한 평균 예측 확률은 낮을 것입니다. 이 원리를 이용하여 각 소스 클래스의 기여도를 나타내는 가중치 벡터 $\gamma$를 다음과 같이 계산합니다:
     $$ \gamma = \frac{1}{n*t} \sum*{i=1}^{n_t} \hat{y}\_i $$
   - $\gamma$는 $|C_s|$ 차원 벡터이며, 각 원소 $\gamma_k$는 소스 클래스 $k$의 기여도를 나타냅니다.
   - 계산된 가중치 벡터는 $\gamma \leftarrow \gamma / \max(\gamma)$와 같이 최댓값으로 정규화하여 사용합니다. 이는 공유 클래스에 높은 가중치를, 이상치 클래스에는 낮은 가중치를 부여합니다.

2. **PADA의 목적 함수:** PADA는 DANN의 목적 함수를 기반으로 하되, 소스 도메인 데이터에 대해 계산된 클래스 가중치를 적용합니다.

   - $G_f$: 특징 추출기, $G_y$: 소스 분류기, $G_d$: 도메인 판별기
   - $L_y$: 소스 분류 손실 (예: 크로스 엔트로피)
   - $L_d$: 도메인 판별 손실 (예: 이진 크로스 엔트로피)
   - $\lambda$: 손실 간 균형을 맞추는 하이퍼파라미터
     $$ C(\theta*f, \theta_y, \theta_d) = \frac{1}{n_s} \sum*{x*i \in D_s} \gamma*{y*i} L_y(G_y(G_f(x_i)), y_i) \\ - \lambda \left( \frac{1}{n_s} \sum*{x*i \in D_s} \gamma*{y*i} L_d(G_d(G_f(x_i)), d_i) + \frac{1}{n_t} \sum*{x*i \in D_t} L_d(G_d(G_f(x_i)), d_i) \right) $$
    여기서 $y_i$는 소스 데이터 $x_i$의 실제 레이블이며, $\gamma*{y_i}$는 해당 레이블에 대한 클래스 가중치입니다.

3. **최적화:** 이 목적 함수는 미니맥스 게임으로 최적화됩니다.

   - 특징 추출기($G_f$)와 소스 분류기($G_y$)의 파라미터($\theta_f, \theta_y$)는 목적 함수를 최소화합니다.
   - 도메인 판별기($G_d$)의 파라미터($\theta_d$)는 목적 함수를 최대화합니다.
     $$ (\hat{\theta}_f, \hat{\theta}\_y) = \arg \min_{\theta*f, \theta_y} C(\theta_f, \theta_y, \theta_d) $$
    $$ (\hat{\theta}\_d) = \arg \max*{\theta_d} C(\theta_f, \theta_y, \theta_d) $$

4. **아키텍처:** ResNet-50과 같은 딥 CNN을 특징 추출기($G_f$)로 사용하며, 그 뒤에 분류기($G_y$)와 도메인 판별기($G_d$)가 연결됩니다. 도메인 판별기 훈련 시에는 Gradient Reversal Layer (GRL)를 사용하여 특징 추출자가 도메인 불변 특징을 학습하도록 유도합니다. 가중치 $\gamma$는 분류기 손실과 소스 도메인에 대한 판별기 손실에 적용됩니다.

## 📊 Results

PADA는 다양한 부분 도메인 적응 태스크에서 최첨단 성능을 달성했습니다.

- **Office-31, Office-Home, ImageNet-Caltech, VisDA2017** 데이터셋에 대한 광범위한 실험에서 PADA는 ResNet-50, DAN, DANN, RTN, ADDA, JAN, LEL 등 모든 비교 방법보다 높은 분류 정확도를 기록했습니다.
- 특히, Office-31의 A→W (작은 도메인 격차) 및 Office-Home의 Cl→Rw (큰 도메인 격차), ImageNet→Caltech (대규모 소스 및 타겟 도메인)와 같은 다양한 시나리오에서 PADA는 상당한 정확도 향상을 보였습니다.
- **어블레이션 연구(Ablation Study):**
  - PADA-classifier (소스 분류기에 가중치 미적용) 및 PADA-adversarial (도메인 적대 학습에 가중치 미적용) 변형을 통해 PADA의 완전한 메커니즘이 각각의 구성 요소보다 우수함을 입증했습니다. 이는 가중치 메커니즘이 소스 분류기 및 도메인 판별기 모두에 적용될 때 가장 효과적임을 보여줍니다.
- **수렴 성능:** PADA는 다른 방법들보다 빠르고 안정적으로 가장 낮은 테스트 오류로 수렴하며, 이는 부정적 전이로 인해 불안정하거나 오류가 증가하는 다른 방법들과 대조됩니다.

## 🧠 Insights & Discussion

- **부정적 전이 완화의 중요성:** 기존의 딥 DA 방법들은 부분 도메인 적응 태스크에서 ResNet-50보다 낮은 성능을 보이는 경우가 많았는데, 이는 이상치 소스 클래스로 인한 부정적 전이 때문임을 보여줍니다. PADA는 이 영향을 효과적으로 회피합니다.
- **가중치 메커니즘의 효과:** PADA의 가중치 메커니즘은 타겟 데이터가 이상치 소스 클래스에 할당될 확률이 낮다는 관찰을 기반으로 작동합니다. 이는 소스 분류기 출력을 통해 이상치 클래스를 자동으로 식별하고, 해당 클래스에 속하는 소스 데이터의 영향을 줄여줍니다.
- **DANN 대비 강점:** DANN과 같은 적대적 네트워크 기반 방법은 비선형 판별기를 혼란시키기 위해 강력한 매칭 능력을 가지지만, 이는 이상치 클래스가 있는 경우 오히려 부정적 전이에 더 취약하게 만듭니다. PADA는 이러한 적대적 메커니즘의 강력함을 유지하면서도, 가중치 메커니즘을 통해 이상치 클래스의 해로운 영향을 제거하여 성능을 크게 향상시킵니다.
- **RTN 대비 우위:** 엔트로피 최소화로 부정적 전이를 간접적으로 완화하는 RTN보다 PADA가 모든 태스크에서 더 우수한 성능을 보였는데, 이는 PADA의 직접적인 가중치 부여 방식이 이상치 클래스 처리에는 더 효과적임을 시사합니다.
- **클래스 가중치 통계 분석:** PADA가 학습한 클래스 가중치는 공유 클래스에 훨씬 더 큰 가중치를, 그리고 일부 이상치 클래스에는 거의 0에 가까운 가중치를 부여함으로써, 공유/이상치 클래스를 효과적으로 구별함을 시각적으로 증명합니다. DANN은 이상치 클래스에도 여전히 상당한 가중치를 할당하여 부정적 전이에 취약함을 보여주었습니다.
- **타겟 클래스 수의 영향:** 타겟 클래스 수가 감소할수록(즉, 이상치 소스 클래스의 비율이 증가할수록) PADA가 DANN을 능가하는 성능 차이가 커집니다. 이는 PADA가 더 극단적인 부분 도메인 적응 시나리오에서도 효과적임을 의미합니다. 타겟 클래스 수가 31개(표준 DA)일 때는 PADA와 DANN의 성능이 비슷하여, 가중치 메커니즘이 이상치 클래스가 없을 때 오작동하지 않음을 보여줍니다.
- **t-SNE 특징 시각화:** PADA의 t-SNE 임베딩은 소스와 타겟 도메인의 다른 클래스들을 잘 구별하면서도, 타겟 데이터가 올바른 공유 소스 클래스와 정렬되고 이상치 소스 클래스의 영향을 받지 않음을 시각적으로 보여줍니다.

## 📌 TL;DR

- **문제:** 기존 도메인 적응(DA)은 소스와 타겟 도메인의 레이블 공간이 동일하다고 가정하지만, 실제로는 소스 레이블이 타겟 레이블을 포함하는 '부분 도메인 적응' 시나리오가 많다. 이 시나리오에서는 소스 도메인에만 존재하는 '이상치 클래스(outlier classes)'가 학습에 부정적인 영향(negative transfer)을 미쳐 성능을 저하시킨다.
- **제안 방법:** 이 논문은 부분 도메인 적응을 위한 'Partial Adversarial Domain Adaptation (PADA)'을 제안한다. PADA는 타겟 데이터의 분류기 출력(softmax 확률)을 활용하여 각 소스 클래스에 대한 가중치($\gamma$)를 계산한다. 이 가중치는 이상치 클래스에는 낮은 값을, 공유 클래스에는 높은 값을 부여한다.
- **핵심 메커니즘:** 이 가중치를 소스 분류기 훈련 및 도메인 판별기 훈련에 적용하여, 이상치 소스 클래스의 기여도를 낮추고 공유 레이블 공간 내에서 특징 분포 일치를 최대화하여 긍정적 전이(positive transfer)를 촉진한다.
- **결과:** PADA는 Office-31, Office-Home, ImageNet-Caltech 등 다양한 벤치마크 데이터셋에서 기존 최첨단 DA 방법들을 크게 능가하는 성능을 보였다. 이는 PADA가 이상치 클래스로 인한 부정적 전이를 효과적으로 완화하고 관련 소스 데이터로부터의 긍정적 전이를 증진한다는 것을 입증한다.
