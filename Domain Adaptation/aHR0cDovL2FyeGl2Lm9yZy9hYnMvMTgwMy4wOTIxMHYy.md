# Importance Weighted Adversarial Nets for Partial Domain Adaptation

Jing Zhang, Zewei Ding, Wanqing Li, Philip Ogunbona

## 🧩 Problem to Solve

기존의 도메인 적응(Domain Adaptation, DA) 방법론들은 일반적으로 소스 도메인과 타겟 도메인의 레이블 공간(class spaces)이 동일하다고 가정합니다. 그러나 실제 시나리오에서는 더 크고 다양한 소스 도메인에서 클래스 수가 더 적은 타겟 도메인으로 지식을 전달해야 하는 경우가 많으며, 이를 부분 도메인 적응(Partial Domain Adaptation)이라고 합니다. 이 경우, 타겟 도메인에 존재하지 않는 소스 도메인의 "이상치(outlier)" 클래스 샘플들이 도메인 간 분포 차이를 직접적으로 줄이는 것을 방해하여 지식 전달의 효과를 떨어뜨릴 수 있습니다. 따라서 이 논문은 부분 도메인 적응 환경에서 소스 도메인의 이상치 클래스 샘플을 식별하고, 동시에 공유 클래스 간의 도메인 시프트(domain shift)를 효과적으로 줄이는 방법을 제안합니다.

## ✨ Key Contributions

- **부분 도메인 적응을 위한 가중치 기반 적대적 네트워크(Adversarial Nets) 제안:** 소스 도메인의 이상치 샘플을 식별하고 공유 클래스 간의 도메인 시프트를 줄이는 새로운 적대적 네트워크 기반 방법을 제시합니다.
- **샘플 중요도 가중치 부여 체계:** 첫 번째 도메인 분류기($D$)의 활성화 값을 기반으로 소스 샘플의 중요도 가중치를 학습합니다. 이 가중치는 이상치 클래스에서 온 샘플에 낮은 가중치를, 공유 클래스에서 온 샘플에 높은 가중치를 부여합니다.
- **이중 도메인 분류기 전략:** 중요도 가중치 학습을 위한 첫 번째 도메인 분류기($D$)와 가중치가 적용된 소스 샘플 및 타겟 샘플 간의 미니맥스 게임(minimax game)을 수행하는 두 번째 도메인 분류기($D_0$)를 도입합니다.
- **이론적 정당성:** 제안된 가중치 적대적 네트워크가 가중치가 적용된 소스 밀도와 타겟 밀도 사이의 젠슨-섀넌 발산(Jensen-Shannon divergence)을 줄이는 것과 이론적으로 동일함을 증명합니다.
- **타겟 도메인 구조 보존:** 엔트로피 최소화(entropy minimization) 원리를 사용하여 타겟 도메인 피처 추출기($F_t$)를 추가로 제약하여 타겟 데이터의 구조를 보존하고 클래스 간 낮은 밀도 분리를 촉진합니다.
- **우수한 성능:** 여러 크로스-도메인 객체 데이터셋(Office+Caltech-10, Office-31, Caltech256→Office10)에서 기존 도메인 적응 방법들을 크게 능가하며, 최신 부분 도메인 적응 방법과 비교할 만한 성능을 달성합니다.

## 📎 Related Works

- **MMD (Maximum Mean Discrepancy) 기반 방법:** 통계적 모멘트 매칭을 통해 도메인 차이를 줄입니다. 예: DAN [14], RTN [18], CMD [27], Deep CORAL [22].
- **적대적 학습 기반 방법:** 도메인 분류기가 소스/타겟 샘플을 구별하지 못하도록 피처 추출기를 훈련하여 도메인 불변 피처를 학습합니다. 예: DANN [7], ADDA [24], Bousmalis et al. [3].
- **Batch Normalization 통계 기반 방법:** 소스 및 타겟 분포를 표준 분포로 정렬합니다. 예: Li et al. [13], Carlucci et al. [19].
- **부분 도메인 적응 방법:**
  - SAN (Selective Adversarial Networks) [4]: 각 클래스에 대한 별도의 도메인 분류기를 훈련하고 인스턴스-레벨 및 클래스-레벨 가중치를 도입합니다. 본 논문의 방법은 더 적은 수의 분류기를 사용하여 확장성 및 계산 효율성 측면에서 차이가 있습니다.

## 🛠️ Methodology

본 논문은 비지도 부분 도메인 적응(unsupervised partial domain adaptation) 설정을 다루며, 여기서 타겟 레이블 공간 $Y_t$는 소스 레이블 공간 $Y_s$의 부분집합 ($Y_t \subseteq Y_s$)이고, 도메인 시프트($p_s(x) \neq p_t(x)$)가 존재합니다.

1. **소스 판별 모델 사전 학습:**

   - 소스 도메인 피처 추출기 $F_s$와 분류기 $C$는 레이블이 있는 소스 데이터 $D_s = \{(x_i^s, y_i^s)\}_{i=1}^{n_s}$를 사용하여 분류 손실 $L_s$를 최소화하도록 사전 학습됩니다.
   - $L_s(F_s, C) = -\mathbb{E}_{x, y \sim p_s(x, y)} \sum_{k=1}^K \mathbb{1}_{[k=y]} \log C(F_s(x))$

2. **샘플 중요도 가중치 학습 ($D$):**

   - 표준 적대적 네트워크 설정과 유사하게 첫 번째 도메인 분류기 $D$를 학습합니다. $D$는 소스 피처 $F_s(x)$와 타겟 피처 $F_t(x)$를 구별합니다.
   - $ \min*{F_s, F_t} \max*{D} L(D, F*s, F_t) = \mathbb{E}*{x \sim p*s(x)} [\log D(F_s(x))] + \mathbb{E}*{x \sim p_t(x)} [\log(1-D(F_t(x)))] $
   - 최적의 $D^*(z) = p_s(z) / (p_s(z) + p_t(z))$일 때, 소스 샘플 $z$에 대한 중요도 가중치는 다음과 같이 정의됩니다:
     - $ \tilde{w}(z) = 1 - D^\*(z) = \frac{1}{\frac{p_s(z)}{p_t(z)} + 1} $
     - 이 가중치는 소스 도메인에 대한 확률이 높을수록(즉, 타겟 도메인과 구별될 가능성이 높을수록) 낮아집니다. 이는 이상치 클래스의 샘플이 낮은 가중치를 받도록 합니다.
   - 가중치는 정규화됩니다: $ w(z) = \tilde{w}(z) / \mathbb{E}\_{z \sim p_s(z)} [\tilde{w}(z)] $.
   - 이 $D$의 기울기는 $F_t$ 업데이트에 사용되지 않고, 오직 중요도 가중치 계산에만 사용됩니다.

3. **가중치 기반 도메인 적응 ($D_0, F_t$):**

   - 두 번째 도메인 분류기 $D_0$는 가중치가 적용된 소스 샘플 $w(z)F_s(x)$와 타겟 샘플 $F_t(x)$ 간의 도메인 차이를 구별하도록 훈련됩니다. $F_t$는 이 차이를 최소화합니다.
   - $ \min*{F_t} \max*{D*0} L_w(D_0, F_s, F_t) = \mathbb{E}*{x \sim p*s(x)} [w(z) \log D_0(F_s(x))] + \mathbb{E}*{x \sim p_t(x)} [\log(1-D_0(F_t(x)))] $
   - 이 미니맥스 게임은 가중치가 적용된 소스 밀도 $w(z)p_s(z)$와 타겟 밀도 $p_t(z)$ 사이의 젠슨-섀넌 발산을 줄이는 것과 동등합니다.
   - $F_s$와 $F_t$는 서로 다른(unshared) 피처 추출기로, 도메인 특이적(domain-specific) 피처를 학습할 수 있습니다. $F_t$는 $F_s$의 파라미터로 초기화됩니다.

4. **타겟 데이터 구조 보존:**

   - $F_t$는 타겟 샘플 $x_t$에 대한 소스 분류기 $C$의 출력 엔트로피를 최소화하도록 추가로 제약됩니다.
   - $ \min*{F_t} \mathbb{E}*{x \sim p_t(x)} [H(C(F_t(x)))] $
   - 이 항은 타겟 데이터가 클래스 경계에서 낮은 밀도를 가지도록 유도하여 클래스 분리를 강화합니다. 특히, $C$는 고정된 채로 $F_t$만 제약하여 초기에 잘못된 클래스에 고착되는 부작용을 줄입니다.

5. **전체 목적 함수 및 최적화:**
   - 전체 학습 과정은 세 단계로 나뉩니다.
     1. $F_s, C$를 소스 분류 손실 $L_s$로 사전 학습.
     2. $D, D_0, F_t$를 동시에 최적화. $D$는 가중치 $w(z)$를 제공하고, $D_0$는 가중치가 적용된 소스 샘플과 타겟 샘플 간의 미니맥스 게임을 수행하며, $F_t$는 이 미니맥스 손실과 타겟 엔트로피 최소화 손실을 모두 최소화합니다.
   - 미니맥스 게임을 해결하기 위해 GRL (Gradient Reversal Layer)을 사용합니다.

## 📊 Results

- **Office+Caltech-10, Office-31, Caltech256→Office10 데이터셋:** 부분 도메인 적응 시나리오에서 실험을 수행했습니다.
- **기준선 대비 우월한 성능:** AlexNet+bottleneck, RevGrad [7], RTN [18], ADDA-grl [24]과 같은 기존 도메인 적응 방법들보다 훨씬 뛰어난 성능을 보였습니다.
- **최신 방법과 비교:** 부분 도메인 적응 최신 방법인 SAN [4]과 유사하거나 더 나은 성능을 달성했으며, SAN보다 적은 수의 파라미터(분류기)를 사용하므로 계산 효율성이 더 높습니다.
- **가중치 체계의 효과 검증:** t-SNE 시각화를 통해 제안된 가중치 체계가 소스 도메인의 이상치 클래스 샘플을 효과적으로 식별하고, 타겟 도메인 샘플을 관련 소스 공유 클래스에 잘 정렬함을 보여주었습니다.
- **타겟 클래스 수 변화에 강건함:** 타겟 클래스 수가 줄어들수록 제안된 방법의 상대적 성능 향상이 더 컸습니다.
- **비-부분 도메인 적응 설정에서도 안정적:** 전통적인 전체 도메인 적응 설정에서도 최신 방법들과 비교하여 성능 저하가 없음을 확인했습니다.
- **비공유 피처 추출기의 이점:** 소스 및 타겟 도메인에 비공유(unshared) 피처 추출기를 사용하는 것이 공유 피처 추출기를 사용하는 것보다 더 나은 성능을 보였습니다.

## 🧠 Insights & Discussion

- 이 논문은 기존 도메인 적응 방법의 핵심 가정(동일한 레이블 공간)을 재고하고, 실제적이고 도전적인 부분 도메인 적응 문제에 대한 효과적인 해결책을 제시합니다.
- 이상치 클래스 샘플에 대한 중요도 가중치 부여는 소스 도메인에 이상치 클래스가 포함되어 있을 때 발생할 수 있는 부정적인 지식 전달(negative transfer)을 효과적으로 완화합니다.
- 두 단계의 적대적 학습 구조(하나의 분류기는 가중치 학습, 다른 하나는 도메인 적응)는 복잡한 부분 도메인 적응 문제를 체계적으로 해결하는 강력한 방법입니다.
- 타겟 엔트로피 최소화를 피처 추출기에만 적용함으로써, 초기 학습 단계에서 큰 도메인 시프트로 인해 타겟 샘플이 잘못된 클래스에 고착되는 위험을 줄일 수 있습니다.
- SAN과 같은 다른 부분 도메인 적응 방법보다 적은 수의 도메인 분류기를 사용하여 계산 효율성을 높였다는 점은 실용적인 가치가 큽니다.
- 향후 연구에서는 더 큰 규모의 부분 도메인 적응 시나리오에 대한 확장 가능성을 탐구할 수 있습니다.

## 📌 TL;DR

이 논문은 타겟 도메인이 소스 도메인보다 적은 수의 클래스를 가질 때 발생하는 부분 도메인 적응 문제를 해결합니다. 핵심 아이디어는 두 개의 적대적 네트워크를 사용하여, 첫 번째 분류기로 소스 도메인의 이상치 샘플에 낮은 가중치를 부여하는 샘플 중요도 가중치를 학습하고, 이 가중치가 적용된 소스 샘플과 타겟 샘플 간의 분포를 두 번째 분류기로 정렬하는 것입니다. 이 방법은 가중치가 적용된 소스와 타겟 분포 간의 젠슨-섀넌 발산을 최소화하는 것으로 이론적으로 증명되며, 타겟 엔트로피 최소화를 통해 타겟 데이터 구조를 보존합니다. 실험 결과, 이 방법은 기존 도메인 적응 및 부분 도메인 적응 방법론들보다 우수한 성능을 보이며, 특히 소스 도메인 이상치 클래스를 효과적으로 무시하고 공유 클래스에 집중하여 성공적인 지식 전달을 가능하게 합니다.
