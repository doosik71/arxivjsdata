# Contrastive Adaptation Network for Unsupervised Domain Adaptation

Guoliang Kang, Lu Jiang, Yi Yang, Alexander G. Hauptmann

## 🧩 Problem to Solve

기존의 비지도 도메인 적응(UDA) 방법들은 소스 도메인과 타겟 도메인 간의 전체적인 분포 불일치(예: MMD, JMMD)를 최소화하는 데 중점을 두었으나, 이 과정에서 클래스 정보를 무시하는 경향이 있었습니다. 이는 다른 클래스의 샘플들이 잘못 정렬되거나, 타겟 도메인에 대해 일반화 능력이 떨어지는 판별 경계(decision boundary)를 학습하여 성능 저하를 초래할 수 있습니다. 즉, 클래스 간의 경계를 명확히 구분하지 못하고 도메인 레벨에서만 데이터를 정렬하여, 클래스별 오정렬(misalignment)이 발생할 수 있습니다.

## ✨ Key Contributions

- **새로운 불일치 메트릭인 Contrastive Domain Discrepancy (CDD) 도입**: 클래스 인지(class-aware) 정렬을 수행하여 비지도 도메인 적응의 성능을 향상시켰습니다.
- **Contrastive Adaptation Network (CAN) 제안**: CDD를 사용하여 End-to-End 방식으로 훈련할 수 있는 네트워크를 제안했습니다.
- **최첨단 성능 달성**: Office-31 벤치마크에서 기존 최고 성능을 능가했으며, 도전적인 VisDA-2017 벤치마크에서도 매우 경쟁력 있는 성능을 보였습니다.

## 📎 Related Works

- **클래스-불가지론적 도메인 정렬 (Class-agnostic domain alignment)**:
  - GANin et al.의 RevGrad [10, 11]는 도메인 분류기를 사용하여 도메인 불변 특징을 학습합니다.
  - Long et al.의 DAN [22] 및 JAN [25]은 MMD 및 Joint MMD를 통해 도메인 불일치를 최소화합니다.
  - 이러한 방법들은 샘플의 클래스 정보를 고려하지 않고 도메인 레벨에서 불일치를 측정합니다.
- **판별적 도메인 불변 특징 학습 (Discriminative domain-invariant feature learning)**:
  - ADR [31] 및 MCD [32]는 적대적 학습 방식을 통해 판별력이 낮은 특징이 생성되는 것을 방지합니다.
  - Long et al. [23] 및 Pei et al. [28]은 클래스 정보를 고려하여 도메인 불일치를 측정하지만, 본 연구는 클래스 내/간 불일치를 명시적으로 모델링하고 교차 최적화 전략을 사용한다는 점에서 차이가 있습니다.
- **클래스 내 압축성 및 클래스 간 분리성 모델링 (Intra-class compactness and inter-class separability modeling)**:
  - 대조 손실(contrastive loss) [12] 및 삼중항 손실(triplet loss) [33]과 같이 클래스 내 응집도와 클래스 간 분리도를 명시적으로 모델링하는 방법들이 있습니다.
  - 본 연구는 이러한 아이디어를 단일 도메인이 아닌 도메인 간 적응에 적용합니다.

## 🛠️ Methodology

CAN은 클래스 인지 도메인 정렬을 위해 **Contrastive Domain Discrepancy (CDD)**라는 새로운 메트릭을 최적화합니다.

1. **Contrastive Domain Discrepancy (CDD) 정의**:
   - CDD는 조건부 데이터 분포 간의 차이에 기반하며, MMD를 활용합니다.
   - **클래스 내 도메인 불일치($ \hat{D}\_{cc} $)**: 같은 클래스 내 소스 및 타겟 샘플의 특징 표현을 가깝게 만듭니다.
   - **클래스 간 도메인 불일치($ \hat{D}\_{cc'} $)**: 다른 클래스 간의 특징 표현을 판별 경계에서 멀리 떨어뜨려 분리도를 극대화합니다.
   - 전체 CDD는 다음과 같이 정의됩니다:
     $$
     \hat{D}_{cdd} = \frac{1}{M} \sum_{c=1}^{M} \hat{D}_{cc}(\hat{y}_{t}^{1:n_t}, \phi) - \frac{1}{M(M-1)} \sum_{c=1}^{M} \sum_{c' \neq c}^{M} \hat{D}_{cc'}(\hat{y}_{t}^{1:n_t}, \phi)
     $$
     여기서 첫 번째 항은 클래스 내 불일치 합의 평균을, 두 번째 항은 클래스 간 불일치 합의 평균을 나타냅니다. 클래스 내 불일치는 최소화하고, 클래스 간 불일치는 최대화하여 도메인 적응 성능을 향상시킵니다.
2. **전반적인 목적 함수**:
   - 네트워크의 여러 FC 레이어에 걸쳐 CDD를 최소화합니다: $ \hat{D}_{cdd}^L = \sum_{l=1}^{L} \hat{D}\_{cdd}^l $
   - 소스 도메인 레이블 데이터에 대한 교차 엔트로피 손실($ \mathcal{L}\_{ce} $)과 결합하여, 최종 목적 함수는 다음과 같습니다:
     $$
     \min_{\theta} \mathcal{L} = \mathcal{L}_{ce} + \beta \hat{D}_{cdd}^L
     $$
     여기서 $ \beta $는 불일치 패널티 항의 가중치입니다.
3. **CAN 최적화 (Optimizing CAN)**:
   - **교차 최적화 (Alternative Optimization, AO)**: 타겟 레이블이 미지수인 UDA 문제 해결을 위해, 타겟 레이블 가설($ \hat{y}\_t $)과 특징 표현($ \phi $)을 교대로 최적화합니다.
     - **클러스터링 단계**: 현재 특징 표현이 고정된 상태에서, 스페리컬 K-means 클러스터링을 사용하여 타겟 샘플의 가설 레이블을 업데이트합니다. 각 클래스의 타겟 클러스터 중심은 해당 클래스의 소스 클러스터 중심을 기반으로 초기화됩니다. 모호한(ambiguous) 타겟 샘플(클러스터 중심에서 멀리 떨어진) 및 클래스(클러스터 중심 주변에 타겟 샘플이 적은)는 CDD 계산에서 제외됩니다. 훈련이 진행됨에 따라 더 많은 샘플과 클래스가 포함됩니다.
     - **특징 적응 단계**: 업데이트된 타겟 레이블을 기반으로 CDD를 계산하고 최소화하여 네트워크 파라미터 $ \theta $를 역전파를 통해 업데이트합니다. 이 과정은 K 스텝 동안 반복됩니다.
   - **클래스 인지 샘플링 (Class-aware Sampling, CAS)**: 미니 배치 훈련 효율성을 높이기 위해, 각 반복에서 무작위로 선택된 클래스 서브셋 내의 각 클래스에 대해 소스 및 타겟 데이터를 샘플링합니다. 이는 미니 배치 내에서 모든 선택된 클래스에 대한 클래스 내 불일치를 계산할 수 있도록 합니다.

## 📊 Results

- **Office-31 벤치마크**: 6가지 UDA 태스크에서 CAN이 모든 기존 최신 방법들을 능가하며 평균 90.6%의 분류 정확도를 달성했습니다. 이는 JAN 대비 6.3%p, MADA 대비 5.4%p 향상된 수치입니다.
- **VisDA-2017 벤치마크**: 12개 클래스에 걸쳐 평균 87.2%의 정확도로 다른 기준선 방법들을 능가했습니다. VisDA-2017 경쟁에서 1위를 차지했던 Self-ensembling (SE) [9] 방법(84.3%)보다 2.9%p 높은 성능을 보였습니다. 단일 모델로 공식 평가 서버에 제출했을 때 87.4%의 경쟁력 있는 정확도를 달성했습니다.
- **시각화 (t-SNE)**: CAN으로 학습된 특징 표현은 t-SNE 시각화에서 JAN에 비해 더 높은 클래스 내 압축성(intra-class compactness)과 더 큰 클래스 간 여백(inter-class margin)을 보여주며, 이는 더 판별적인 특징이 학습되었음을 입증합니다.
- **정확성 향상**: 클래스 정보를 고려하는 것이 도메인 적응에 유익하며, CAN의 클래스 정보 활용 방식이 MADA, ADR, MCD보다 효과적임을 보여줍니다.

## 🧠 Insights & Discussion

- **클래스 간 도메인 불일치의 효과**: 클래스 내 불일치만 사용하는 경우보다 클래스 간 불일치를 함께 고려하는 CDD(CAN)가 더 나은 적응 성능을 보여줍니다. 이는 클래스 내 불일치를 완전히 제거하기 어렵기 때문에, 클래스 간 불일치를 최대화함으로써 모델이 소스 데이터에 과적합될 가능성을 줄이고 일반화 능력을 향상시키는 데 기여합니다.
- **교차 최적화(AO) 및 클래스 인지 샘플링(CAS)의 중요성**: 두 가지 핵심 구성 요소가 CAN의 성능에 크게 기여함이 입증되었습니다. AO가 없는 경우(w/o. AO)에도 CDD는 레이블 노이즈에 어느 정도 강건함을 보여주지만, AO와 CAS를 모두 적용했을 때 가장 좋은 성능을 달성합니다.
- **의사(pseudo) 타겟 레이블 활용 방식**: 클러스터링을 통해 얻은 의사 레이블을 단순히 교차 엔트로피 손실에 사용하는 것보다, CDD 메트릭을 통해 클래스 인지 도메인 불일치를 명시적으로 모델링하고 최적화하는 것이 더 효과적인 적응과 노이즈 강건성을 제공합니다.
- **CDD 값의 변화**: 훈련 중 CAN의 CDD 값이 꾸준히 감소하는 경향을 보이며, 이는 제안된 추정 방식이 실제(ground-truth) CDD의 좋은 대리(proxy) 역할을 하고 있음을 시사합니다. CDD 최소화가 정확도 향상으로 이어진다는 점이 확인됩니다.
- **하이퍼파라미터 민감도**: 균형 가중치 $ \beta $에 대한 모델의 민감도가 낮으며, 넓은 범위에서 기준선 방법보다 우수한 성능을 유지합니다. 이는 CDD의 강건한 정규화 효과를 보여줍니다.

## 📌 TL;DR

기존 UDA 방법들의 클래스 정보 무시 문제를 해결하기 위해, Contrastive Adaptation Network (CAN)가 제안되었다. CAN은 클래스 내 도메인 불일치를 최소화하고 클래스 간 도메인 불일치를 최대화하는 새로운 Contrastive Domain Discrepancy (CDD) 메트릭을 사용한다. 타겟 레이블 추정을 위한 클러스터링 기반의 교차 최적화(AO)와 효율적인 학습을 위한 클래스 인지 샘플링(CAS) 전략을 통해, Office-31 및 VisDA-2017 벤치마크에서 SOTA 또는 매우 경쟁력 있는 성능을 달성하며 더 판별적인 특징 표현을 학습한다.
