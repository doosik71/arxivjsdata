# Generalized Source-free Domain Adaptation

Shiqi Yang, Yaxing Wang, Joost van de Weijer, Luis Herranz, Shangling Jui

## 🧩 Problem to Solve

기존의 도메인 적응(Domain Adaptation, DA) 방법론들은 일반적으로 타겟 도메인에 적응하는 과정에서 소스 도메인 데이터에 접근해야 합니다. 하지만 이는 데이터 프라이버시, 컴퓨팅 자원 제한 등 다양한 실제 환경에서 실현 불가능한 경우가 많습니다. 최근의 Source-free Domain Adaptation (SFDA) 방법들은 사전 훈련된 소스 모델만을 활용하여 타겟 도메인에 적응하지만, 이 과정에서 소스 도메인에 대한 모델의 성능이 저하(catastrophic forgetting)되는 문제가 발생합니다. 따라서 본 논문은 소스 데이터 없이 타겟 도메인에 적응한 후에도 **소스 도메인과 타겟 도메인 모두에서 좋은 성능을 유지**해야 하는 새로운 도메인 적응 패러다임인 **Generalized Source-free Domain Adaptation (G-SFDA)**를 제시하고 이 문제를 해결하고자 합니다.

## ✨ Key Contributions

- **G-SFDA 패러다임 제안**: 소스 데이터에 접근하지 않고도 소스 사전 훈련 모델이 타겟 도메인에 적응하는 동시에 소스 도메인에서의 성능을 유지해야 하는 새로운 도메인 적응 패러다임을 제안합니다.
- **Local Structure Clustering (LSC) 도입**: 소스 데이터 없이 타겟 도메인 적응을 위해 특징 공간에서 로컬 이웃 정보를 활용하는 LSC 기법을 제안합니다. 이는 타겟 특징과 의미론적으로 유사한 이웃 간의 일관된 예측을 장려합니다.
- **Sparse Domain Attention (SDA) 제안**: 각 도메인에 대해 서로 다른 특징 채널을 활성화하는 SDA를 제안합니다. SDA는 타겟 적응 중 역전파(backpropagation) 기울기(gradient)를 정규화하여 소스 도메인 정보를 보존하는 데 사용됩니다.
- **뛰어난 성능 입증**: 기존 SFDA 방법들이 소스 도메인에서 성능 저하를 겪는 반면, 제안된 방법은 소스 도메인 성능을 성공적으로 유지합니다. 또한 타겟 도메인 성능 측면에서도 VisDA 벤치마크에서 85.4%로 SOTA(State-Of-The-Art)를 달성하는 등 기존 방법들과 동등하거나 더 우수한 성능을 보여줍니다.

## 📎 Related Works

- **도메인 적응 (Domain Adaptation, DA)**:
  - **분포 정렬**: 모멘트 매칭 ([21,37,39]), 적대적 학습 (DANN [7], CDAN [22], DIRT-T [35]) 등이 특징 분포를 정렬하여 도메인 간의 차이를 줄입니다.
  - **기타 접근**: MCD [31]는 여러 분류기 간의 예측 다양성을 활용하고, AFN [44]은 특징 노름(feature norm)을 조절하며, SRDC [38]는 판별적 클러스터링을 통해 적응을 달성합니다. LSC와 가장 관련 깊은 DANCE [29]는 유니버설 DA를 위한 이웃 클러스터링 기반 방법입니다.
- **소스 없는 도메인 적응 (Source-free Domain Adaptation, SFDA)**:
  - USFDA [14], FS [15], DECISION [2] 등의 연구가 있습니다.
  - SHOT [20]은 소스 분류기를 고정하고 상호 정보량(mutual information) 최대화 및 의사 레이블(pseudo-label)을 통해 타겟 특징을 분류기에 맞춥니다.
  - 3C-GAN [18]은 조건부 GAN을 기반으로 타겟 스타일 학습 이미지를 합성합니다.
  - BAIT [46]는 다양한 분류기 기반 DA 방법을 SFDA에 적용하도록 확장합니다.
  - 기존 SFDA는 타겟 성능에 중점을 두어 소스 성능을 유지하지 못합니다.
- **지속적 도메인 적응 (Continual Domain Adaptation, CDA)**:
  - CL(Continual Learning) [13,19,23,25]은 재앙적 망각(catastrophic forgetting)을 방지하는 데 중점을 두지만, 레이블이 있는 새로운 태스크에 맞춰져 있습니다.
  - CDA [4,26,36]는 지속적으로 변화하는 도메인에 적응하려 하지만, 대부분 소스 데이터에 접근해야 합니다. [16]은 소스 프리 방식이나, 클래스 증분 단일 타겟 도메인 적응에 초점을 맞춥니다.

## 🛠️ Methodology

본 논문은 다음의 두 가지 핵심 구성 요소를 통해 G-SFDA 문제를 해결합니다.

1. **Local Structure Clustering (LSC)**
   - **개념**: 타겟 도메인의 특징들이 클래스별로 클러스터를 형성한다고 가정하며, 특징 공간에서 가까운 이웃들은 유사한 예측을 공유해야 한다는 아이디어에 기반합니다.
   - **구현**:
     - 타겟 특징을 저장하는 특징 뱅크 $F$와 해당 소프트맥스 예측 점수를 저장하는 점수 뱅크 $S$를 구축합니다.
     - 각 타겟 샘플 $x_i$에 대해 특징 뱅크에서 코사인 유사도를 기반으로 $k$개의 최근접 이웃 $N_k$를 찾습니다.
     - LSC 손실 $L_{LSC}$는 현재 샘플의 예측 $p(x_i)$와 이웃의 저장된 예측 $s(N_k)$ 간의 일관성을 장려하고, 예측 불균형을 방지하기 위해 KL-다이버전스 항을 포함합니다:
       $$L_{LSC} = -\frac{1}{n}\sum_{i=1}^{n}\sum_{k=1}^{K}\log[p(x_i)\cdot s(N_k)] + \sum_{c=1}^{C}KL(\bar{p}_c||q_c)$$
       여기서 $\bar{p}$는 예측된 레이블의 경험적 분포이며, $q$는 균일 분포입니다.
2. **Sparse Domain Attention (SDA)**

   - **개념**: 각 도메인에 대해 특징 추출기 $f$의 출력 중 일부 채널만 활성화하는 희소(sparse) 도메인 어텐션 벡터 $A_{i \in \{s,t\}}$를 사용합니다. 이는 소스 및 타겟 도메인별 정보 흐름을 분리합니다.
   - **구현**:
     - $A_i = \sigma(100 \cdot e_i)$와 같이 임베딩 레이어의 출력 $e_i$를 시그모이드 함수에 통과시켜 거의 이진적인 어텐션 마스크를 생성합니다. $A_s$와 $A_t$는 소스 도메인에서 사전 훈련되며, 타겟 적응 중에는 고정됩니다.
     - **기울기 정규화**: 타겟 적응 중에 소스 도메인 정보를 유지하기 위해, 소스 어텐션 $A_s$에 의해 활성화된 채널로 흐르는 기울기를 정규화합니다.
       $$W_f^l \leftarrow W_f^l - (\bar{A}_s \mathbf{1}_h^T) \odot \frac{\partial L}{\partial W_f^l}$$
       $$W_g \leftarrow W_g - \frac{\partial L}{\partial W_g} \odot (\mathbf{1}_C \bar{A}_s^T)$$
       여기서 $\odot$는 요소별 곱셈, $\mathbf{1}_k$는 모든 원소가 1인 $k$차원 벡터, $\bar{A}_s = \mathbf{1} - A_s$입니다. 이는 특징 추출기의 마지막 레이어 $W_f^l$와 분류기 $W_g$의 소스 관련 가중치 업데이트를 억제하여 망각을 방지합니다.

3. **통합 학습 (Unified Training)**:

   - **소스 사전 훈련**: 먼저 소스 도메인 $D_s$에서 $A_s$와 $A_t$를 모두 사용하여 모델을 훈련합니다.
   - **타겟 적응**: 타겟 도메인 $D_t$에 적응할 때는 LSC 손실을 최소화하며, 특징 뱅크 및 이웃 검색 시 타겟 어텐션 $A_t$를 적용한 특징($f(x_i) \odot A_t$)을 사용합니다. 동시에 SDA 기울기 정규화를 적용하여 소스 정보를 보호합니다.

4. **도메인 ID 추정 (Domain-ID Estimation)**: 추론 시 도메인 ID를 알 수 없는 경우를 대비하여 소스 도메인의 적은 수의 이미지(클래스당 1개 등)를 저장하여 도메인 분류기를 훈련하고 도메인 ID를 추정합니다.

5. **지속적 소스 없는 도메인 적응 (Continual Source-free Domain Adaptation)**: 여러 타겟 도메인에 순차적으로 적응해야 하는 상황에서는, 현재 타겟 도메인을 제외한 모든 도메인 어텐션의 최대값으로 구성된 $A'$를 사용하여 기울기를 정규화합니다.

## 📊 Results

- **타겟 중심 도메인 적응 (SFDA)**:
  - **VisDA**: 제안된 방법은 기존 DA 및 SFDA 방법론들을 능가하며, SOTA인 85.4%의 타겟 정확도를 달성했습니다. 특히 SHOT 대비 2.5%p 더 높은 성능입니다.
  - **Office-Home**: 기존 SFDA 방법인 SHOT보다 약간 낮은 성능(0.5%p)을 보였지만, 기존 DA 방법들과는 동등한 수준을 유지합니다.
- **일반화된 소스 없는 도메인 적응 (G-SFDA)**:
  - **조화 평균 (Harmonic Mean, $\mathrm{H}$)**: 소스 정확도($Acc_S$)와 타겟 정확도($Acc_T$)의 조화 평균인 $\mathrm{H} = \frac{2 \cdot Acc_S \cdot Acc_T}{Acc_S + Acc_T}$를 평가 지표로 사용했을 때, 제안된 방법은 SHOT보다 VisDA에서 4.6%p, Office-Home에서 8.8%p 더 높은 $\mathrm{H}$ 값을 달성했습니다. 이는 주로 소스 성능 유지에서 기인합니다.
  - **소스 성능**: 소스 모델과 비교했을 때 소스 성능이 약간 저하되지만 (Office-Home 2.1%p, VisDA 9.2%p), 기존 SFDA 방법보다 훨씬 잘 유지됩니다.
  - **도메인 불가지론(Domain-agnostic) 설정**: 도메인 분류기를 통해 도메인 ID를 추정하는 설정에서도 도메인 인지(domain-aware) 설정과 유사한 결과를 얻으며, 여전히 SHOT보다 우수한 $\mathrm{H}$ 값을 보고합니다.
- **어블레이션 스터디 (Ablation Study)**:
  - **SDA의 효과**: SDA를 제거하면 소스 성능이 크게 저하되고, VisDA에서는 타겟 성능도 10.4%p 감소하여 SDA가 타겟 적응에도 도움이 됨을 보여줍니다.
  - **LSC의 $K$ 값**: 최근접 이웃의 수 $K$에 대해 비교적 강건하지만, $K=1$일 때는 성능이 약간 낮아집니다.
  - **도메인 분류기**: 매우 적은 수의 저장된 이미지(예: Office-Home 클래스당 1개, VisDA 도메인당 64개)로도 잘 작동함을 확인했습니다.
- **t-SNE 시각화**: 적응 후 타겟 특징이 더 구조화되고, 소스 특징 클러스터가 잘 유지됨을 보여줍니다. 도메인 공유 채널의 특징은 함께 클러스터링되지만, 도메인 특정 채널의 특징은 도메인별로 완전히 분리됩니다.
- **지속적 SFDA**: 순차적인 타겟 도메인 적응에서도 모든 도메인에서 잘 작동하며, 이전에 보지 못한 타겟 도메인에서도 성능 향상이 관찰되기도 합니다.

## 🧠 Insights & Discussion

- **실용적 가치**: G-SFDA는 소스 도메인 데이터를 다시 사용할 수 없는 상황에서 모델이 기존 지식(소스 도메인 성능)을 잊지 않고 새로운 도메인에 적응할 수 있게 하여 실제 애플리케이션에 대한 중요한 진전을 이룹니다.
- **LSC의 효율성**: 소스 데이터 없이도 타겟 도메인의 로컬 구조 정보를 활용하여 성공적으로 모델을 적응시킵니다.
- **SDA의 이중 역할**: SDA는 소스 도메인 지식을 보존하는 동시에, 타겟 도메인에 대한 적응 과정 자체를 개선하는 데 기여합니다. 이는 소스 정보를 유지하는 것이 타겟 적응을 위한 더 나은 "시작점"을 제공할 수 있음을 시사합니다.
- **한계점**: 소스 성능이 원본 소스 모델 대비 약간 저하되는 현상은 여전히 존재하며, 이는 주로 특징 추출기 내부 레이어의 망각과 BN 레이어의 통계치 변화에서 비롯됩니다. 이는 향후 연구를 위한 방향을 제시합니다.
- **확장성**: 지속적 SFDA로의 확장 가능성을 보여주며, 여러 도메인에 걸쳐 일반화된 적응력을 갖는 모델의 잠재력을 시사합니다. 하지만 더 많은 도메인에 적응할수록 기울기 정규화가 증가하여 잠재적으로 모델의 용량이 제한될 수 있습니다.

## 📌 TL;DR

**문제**: 기존 소스 없는 도메인 적응(SFDA)은 타겟 도메인에 적응하면서 소스 도메인 성능을 잊어버립니다. 이 논문은 소스 데이터 없이 **타겟 도메인에 적응하면서 소스 성능을 유지**하는 **일반화된 소스 없는 도메인 적응(G-SFDA)**이라는 새로운 패러다임을 제안합니다.

**방법**: G-SFDA는 타겟 특징 이웃 간의 일관된 예측을 장려하여 타겟에 적응하는 **Local Structure Clustering (LSC)**과, 도메인별 특징 채널 마스크 및 기울기 정규화를 통해 소스 지식을 보존하는 **Sparse Domain Attention (SDA)**을 결합합니다.

**결과**: 제안된 방법은 VisDA에서 SOTA 타겟 성능을 달성했으며, 기존 SFDA 방법 대비 소스 성능 유지에서 크게 우수하여 망각 문제를 효과적으로 해결합니다.
