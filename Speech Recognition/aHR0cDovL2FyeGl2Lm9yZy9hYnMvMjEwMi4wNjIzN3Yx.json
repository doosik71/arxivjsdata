{
  "title": "An Investigation of End-to-End Models for Robust Speech Recognition",
  "authors": "Archiki Prasad, Preethi Jyothi, Rajbabu Velmurugan",
  "year": 2021,
  "url": "http://arxiv.org/abs/2102.06237v1",
  "abstract": "End-to-end models for robust automatic speech recognition (ASR) have not been\nsufficiently well-explored in prior work. With end-to-end models, one could\nchoose to preprocess the input speech using speech enhancement techniques and\ntrain the model using enhanced speech. Another alternative is to pass the noisy\nspeech as input and modify the model architecture to adapt to noisy speech. A\nsystematic comparison of these two approaches for end-to-end robust ASR has not\nbeen attempted before. We address this gap and present a detailed comparison of\nspeech enhancement-based techniques and three different model-based adaptation\ntechniques covering data augmentation, multi-task learning, and adversarial\nlearning for robust ASR. While adversarial learning is the best-performing\ntechnique on certain noise types, it comes at the cost of degrading clean\nspeech WER. On other relatively stationary noise types, a new speech\nenhancement technique outperformed all the model-based adaptation techniques.\nThis suggests that knowledge of the underlying noise type can meaningfully\ninform the choice of adaptation technique.",
  "citation": 34
}