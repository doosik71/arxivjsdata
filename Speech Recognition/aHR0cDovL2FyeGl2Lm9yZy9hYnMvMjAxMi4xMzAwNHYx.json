{
  "url": "http://arxiv.org/abs/2012.13004v1",
  "title": "Speech Synthesis as Augmentation for Low-Resource ASR",
  "authors": "Deblin Bagchi, Shannon Wotherspoon, Zhuolin Jiang, Prasanna Muthukumar",
  "year": 2020,
  "abstract": "Speech synthesis might hold the key to low-resource speech recognition. Data\naugmentation techniques have become an essential part of modern speech\nrecognition training. Yet, they are simple, naive, and rarely reflect\nreal-world conditions. Meanwhile, speech synthesis techniques have been rapidly\ngetting closer to the goal of achieving human-like speech. In this paper, we\ninvestigate the possibility of using synthesized speech as a form of data\naugmentation to lower the resources necessary to build a speech recognizer. We\nexperiment with three different kinds of synthesizers: statistical parametric,\nneural, and adversarial. Our findings are interesting and point to new research\ndirections for the future."
}