# UNSUPERVISED SPEECH ENHANCEMENT WITH SPEECH RECOGNITION EMBEDDING AND DISENTANGLEMENT LOSSES
Viet Anh Trinh, Sebastian Braun

## 🧩 Problem to Solve
음성 향상(Speech Enhancement, SE)은 다양한 딥러닝 기법으로 큰 발전을 이루었지만, 대부분의 기존 시스템은 다음 두 가지 문제에 직면해 있습니다:
1.  **합성 훈련 데이터와 실제 데이터 간의 도메인 불일치**: 대부분의 SE 훈련 데이터셋은 깨끗한 음성과 잡음 코퍼스를 혼합하여 합성되므로, 실제 잡음 음성 녹음과의 도메인 불일치가 발생합니다. 또한, 스튜디오 품질의 훈련 데이터 수집은 비용이 많이 듭니다.
2.  **음성 향상 성능과 자동 음성 인식(ASR) 성능 저하 간의 상충 관계**: SE 시스템은 잡음을 제거하지만, 음성 신호를 왜곡할 수도 있어 후속 ASR 시스템의 성능을 저하시킬 수 있습니다.
이 논문은 이 두 가지 문제를 해결하기 위한 비지도 학습 손실 함수를 제안합니다.

## ✨ Key Contributions
*   **새로운 비지도 손실 함수 제안**: MixIT 손실 함수를 음성 인식(ASR) 임베딩 손실 및 분리(disentanglement) 손실로 확장하여 풍부한 실제 잡음 코퍼스를 활용한 음성 향상 성능 개선을 가능하게 했습니다.
*   **ASR 성능 저하 완화**: ASR 임베딩 손실과 분리 항을 통합하여 음성 향상과 ASR 성능 간의 상충 관계를 해결하고, MixIT 출력에서 음성과 잡음을 효과적으로 분리하도록 돕습니다.
*   **준지도 학습 방식 도입**: 지도 학습 및 비지도 학습 손실을 결합하여 깨끗한 음성 데이터와 잡음이 포함된 음성 데이터를 동시에 활용하는 방식을 제안합니다.

## 📎 Related Works
*   **MixIT [7]**: 비지도 음원 분리(source separation)를 위해 설계된 특수 손실 함수로, 순열 손실, 재구성 손실 및 음성 향상 손실의 조합입니다. 음원 분리에는 효과적이나, 음성 향상 작업에서는 성능이 좋지 않습니다.
*   **[8]**: 훈련 음성 샘플에 인위적인 잡음을 추가하는 잡음 증강(noise augmentation) 방식을 통해 MixIT의 음성 향상 성능을 개선하고자 했습니다.
*   **Wav2vec 2.0 [14]**: 사전 훈련된 ASR 시스템으로, 본 연구에서는 음성 임베딩 추출에 사용되었습니다.
*   기존의 지도 학습 기반 딥러닝 음성 향상 시스템들 [1-6].
*   다른 비지도 음성 향상 방법들 [9, 10].

## 🛠️ Methodology
본 연구는 Convolutional Recurrent U-net for Speech Enhancement (CRUSE) [12] 아키텍처를 기반으로 하며, 다음과 같은 방법론을 제안합니다.

1.  **지도 학습 음성 향상 (Supervised Baseline)**:
    *   입력 신호의 단시간 푸리에 변환(STFT) $Y$를 사용하며, 입력 특징은 $|Y|^{c}\frac{Y}{|Y|}$ ($c=0.3$) 형태의 복소수 압축 스펙트럼입니다.
    *   네트워크 출력은 복소수 필터(마스크) $G(k, n)$이며, 출력 신호 스펙트럼 $\hat{S}(k, n)$은 $G(k, n)$와 입력 스펙트럼 $Y(k, n)$의 복소수 곱으로 얻어집니다.
    *   손실 함수는 타겟 음성 $S(k, n)$과 예측된 깨끗한 음성 $\hat{S}(k, n)$ 간의 복소수 압축 스펙트럼 손실 $L_{\text{SE}}(S, \hat{S})$ (Eq. 1)을 최소화합니다:
        $$L_{\text{SE}}(S, \hat{S}) =(1-\lambda) \sum_{k,n} \left| |S|^{c} - |\hat{S}|^{c} \right|^{2} + \lambda \sum_{k,n} \left| \frac{|S|^{c} S}{|S|} - \frac{|\hat{S}|^{c} \hat{S}}{|\hat{S}|} \right|^{2}$$
        여기서 $\lambda$는 복소수 손실과 크기 기반 손실 간의 가중치입니다.

2.  **비지도 학습 음성 향상 (Proposed Unsupervised)**:
    *   CRUSE 아키텍처에 두 개의 추가 디코더 브랜치를 추가하여 두 개의 잡음 출력 $N_1$, $N_2$를 생성합니다.
    *   **MixIT 손실 ($L_{\text{MixIT-SE}}$)** (Eq. 2)을 기본으로 사용합니다:
        $$L_{\text{MixIT-SE}} = \min \left[ L_{\text{SE}}(\hat{S}+N_1, X) + L_{\text{SE}}(N_2, N), L_{\text{SE}}(\hat{S}+N_2, X) + L_{\text{SE}}(N_1, N) \right]$$
        여기서 $X$는 잡음이 포함된 녹음, $N$은 추가된 잡음입니다. 네트워크는 예측된 음성 $\hat{S}$와 두 개의 잡음 $N_1$, $N_2$를 출력합니다.
    *   **ASR 임베딩 손실 ($L_{\text{emb}}$)** (Eq. 3) 추가:
        *   사전 훈련된 Wav2vec 2.0 모델을 사용하여 잡음이 포함된 입력 $X$와 향상된 출력 $\hat{S}$로부터 임베딩 $X_{\text{emb}}$와 $\hat{S}_{\text{emb}}$를 추출합니다.
        *   두 임베딩을 유사하게 강제합니다: $L_{\text{emb}} = L_{\text{MSE}}(\hat{S}_{\text{emb}}, X_{\text{emb}})$
    *   **분리 손실 ($L_{\text{dis}}$)** (Eq. 4) 추가:
        *   예측된 음성 $\hat{S}_{\text{emb}}$의 ASR 임베딩이 잡음 임베딩 $N_{\text{1-emb}}$ 및 $N_{\text{2-emb}}$와 직교하도록 강제하여 음성-잡음 간의 누설을 최소화합니다:
            $$L_{\text{dis}} = \left< \hat{S}_{\text{emb}}, N_{\text{1-emb}} \right> + \left< \hat{S}_{\text{emb}}, N_{\text{2-emb}} \right>$$
            여기서 $<>$는 내적(dot product) 연산을 의미합니다.
    *   **총 제안된 비지도 손실 ($L$)**:
        $$L = L_{\text{MixIT-SE}} + \alpha_{e} L_{\text{emb}} + \alpha_{d} L_{\text{dis}}$$
        여기서 $\alpha_{e}$와 $\alpha_{d}$는 각각 임베딩 및 분리 손실에 대한 가중치입니다.

3.  **준지도 학습 음성 향상 (Semi-supervised)**:
    *   지도 학습 손실 (1)과 제안된 비지도 학습 손실 (5)을 결합합니다.
    *   $L_{\text{semi}} = L_{\text{supervised}} + L_{\text{unsupervised}}$
    *   깨끗한 데이터셋과 잡음 데이터셋 모두를 사용하여 훈련합니다.

## 📊 Results
DNS 챌린지 테스트 셋에서 음성 향상 및 ASR 성능을 평가한 결과는 다음과 같습니다.

*   **기존 MixIT (Exp. 4)**: 원본 MixIT 손실은 음성 향상 성능(nOVL 3.16)이 비향상 잡음 음성(3.11)과 유사하며, ASR WER도 높게 나타나 성능이 매우 좋지 않았습니다.
*   **제안된 비지도 학습 방식 (MixIT + Emb + Dis, Exp. 7)**:
    *   잡음이 있는 음성으로 지도 학습된 베이스라인(Exp. 1)과 비교하여 유사한 nOVL 점수(3.29 vs 3.31)를 보였고, ASR WER에서 더 나은 성능(low SNR 33.58% vs 35.51%)을 달성했습니다.
    *   하지만, 깨끗한 잔향 음성으로 지도 학습된 강한 베이스라인(Exp. 3)을 능가하지는 못했습니다.
*   **제안된 비지도 손실 항의 기여 (Ablation Study, Exp. 5, 6)**: ASR 임베딩 손실이나 분리 손실 중 하나를 제거하면 음성 향상 성능(nOVL)이 저하되어, 이 두 항이 시스템에 유용한 제약 조건임을 입증했습니다.
*   **준지도 학습 방식 (Exp. 8, 9)**:
    *   가장 강력한 지도 학습 베이스라인(Exp. 2, 깨끗한 비잔향 음성으로 훈련)과 유사한 음성 품질(nOVL 3.49 vs 3.52)을 달성했습니다.
    *   특히, ASR WER에서는 Exp. 2보다 **더 나은** 성능을 보였습니다(low SNR 30.94% vs 32.59%).
    *   이는 준지도 학습 방식이 지도 학습의 상한선을 MOS(평균 의견 점수) 측면에서 완전히 넘어서지는 못했지만, WER 측면에서는 더 우수하며, 강한 잔향 베이스라인(Exp. 3)을 능가함을 보여줍니다.

## 🧠 Insights & Discussion
*   순수 MixIT 손실만으로는 음성 향상, 특히 잡음 억제에는 불충분합니다.
*   ASR 임베딩 손실과 분리 손실은 비지도 음성 향상 성능을 개선하고 ASR 성능 저하를 완화하는 데 핵심적인 역할을 합니다.
*   완전히 비지도 학습 방식만으로는 깨끗한 데이터로 강하게 지도 학습된 시스템의 성능을 뛰어넘기 어렵습니다.
*   준지도 학습 방식은 매우 효과적입니다. 이는 가장 좋은 지도 학습 방식과 유사한 음성 품질을 달성하면서도, ASR 성능에서는 오히려 더 우수함을 보여주어, 풍부한 잡음이 포함된 실제 데이터를 활용하고 음성 향상-ASR 상충 관계를 완화하는 성공적인 균형점을 제시합니다.
*   한계점으로는, 준지도 학습이 가장 강력한 지도 학습 상한선(잔향 제거까지 수행하는 모델)을 MOS 측면에서 완전히 능가하지 못했는데, 이는 비지도 학습 샘플이 잔향 제거를 명시적으로 유도하지 않기 때문일 수 있습니다.
*   향후 연구에서는 제안된 손실 함수에 다른 임베딩 관련 손실을 추가하거나, ASR을 위한 중요한 음성 단서를 유지하면서 음성 향상과 음성 인식 간의 상충 관계를 최소화하는 방안이 모색될 수 있습니다.

## 📌 TL;DR
*   **문제**: 기존 지도 학습 기반 음성 향상(SE)은 합성 데이터의 도메인 불일치와 SE-ASR 성능 상충이라는 난제를 겪습니다.
*   **제안 방법**: 이 논문은 기존 MixIT 손실을 ASR 임베딩 손실과 분리(disentanglement) 손실로 확장한 새로운 비지도 손실 함수를 제안합니다. 또한, 이를 지도 학습과 결합한 준지도 학습 방식을 도입하여 깨끗한 음성과 잡음이 포함된 실제 음성 데이터를 함께 활용합니다.
*   **핵심 결과**: 제안된 비지도 방식은 기존 MixIT 및 잡음이 포함된 음성으로 훈련된 지도 학습 베이스라인보다 우수한 성능을 보였습니다. 특히, 준지도 학습 방식은 최고의 지도 학습 시스템과 동등한 음성 품질을 달성하면서도 ASR 성능은 **향상**시켜, 풍부한 실제 잡음 데이터를 효과적으로 활용하고 SE와 ASR 성능 간의 균형을 성공적으로 맞추었음을 입증했습니다.