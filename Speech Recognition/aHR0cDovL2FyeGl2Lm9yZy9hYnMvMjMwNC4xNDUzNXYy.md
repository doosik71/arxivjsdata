# Deep Transfer Learning for Automatic Speech Recognition: Towards Better Generalization

Hamza Kheddar, Yassine Himeur, Somaya Al-Maadeed, Abbes Amira and Faycal Bensaali

## 🧩 Problem to Solve

자동 음성 인식(ASR)에서 딥러닝(DL) 기법은 대규모 훈련 데이터셋과 높은 계산 및 저장 자원을 요구하며, 훈련 및 테스트 데이터가 동일한 도메인에서 동일한 입력 특징 공간과 데이터 분포 특성을 가진다는 가정을 전제로 합니다. 그러나 이러한 가정은 현실 세계의 많은 인공지능(AI) 애플리케이션에서 적용하기 어렵습니다. 특히, 실제 데이터를 수집하기 어렵거나, 비용이 많이 들거나, 드물게 발생하는 상황에서는 DL 모델의 데이터 요구 사항을 충족하기 어렵습니다. 이로 인해 소규모 데이터셋을 사용하거나 훈련 및 테스트 데이터 간에 불일치(domain discrepancy)가 있을 경우 DL 모델의 성능이 저하됩니다. 딥 전이 학습(DTL)은 이러한 문제들을 해결하고, 작거나 다소 다르지만 관련된 데이터셋을 사용하여 고성능 모델을 개발하는 것을 목표로 합니다.

## ✨ Key Contributions

- 2015년부터 2023년까지 발표된 DTL 기반 ASR 프레임워크에 대한 포괄적인 최신 조사 연구를 제공합니다.
- 전이된 지식의 성격, 소스/타겟 도메인 레이블의 가용성, 채택된 전략에 기반한 DTL-ASR 방법론의 상세한 분류법(taxonomy)을 제시합니다.
- 각 프레임워크의 한계와 장점에 대한 비판적 분석을 수행하고, 성능을 비교합니다.
- 적대적 DTL 기반 ASR 방법론을 최초로 조사하고, ASR 애플리케이션에 사용되는 도메인 적응(DA) 기술을 요약합니다.
- DTL 기반 ASR과 음성 번역(ST), 음성 평가, 의료 진단 등 다른 응용 분야 간의 관계를 설명합니다.
- 부정적 전이(NT), 지식 획득 측정, DTL 통합 등 DTL 기반 ASR의 주요 도전 과제 및 격차를 식별합니다.
- DTL 기반 ASR 솔루션의 성능을 더욱 향상시키기 위한 미래 연구 방향을 제시하고, 가까운 미래의 DTL 개발을 예측합니다.

## 📎 Related Works

기존의 전이 학습(TL) 관련 조사 연구들은 DTL의 일반적인 응용 분야를 다루는 데 초점을 맞추었으나, 대부분 ASR 작업에 대한 최신 DTL 발전 사항을 깊이 있게 다루지 못했습니다([34, 35, 22, 36, 37, 38, 39, 40, 41] 등). 특히, ASR과 DTL을 동시에 활용하는 연구를 통합적으로 분석하거나, DTL 기반 ASR 솔루션의 정량적 분석, 의료 진단 적용, 공격 및 보안 측면, 그리고 부정적 전이(NT), 지식 획득 측정, DTL 통합과 같은 현재 당면 과제들을 종합적으로 다루지 못했습니다. 본 논문은 이러한 기존 TL 조사 연구의 한계점을 보완하여, ASR에 특화된 DTL 기술의 포괄적인 분석과 미래 방향을 제시합니다.

## 🛠️ Methodology

본 논문은 2015년부터 2023년까지 DTL 기반 ASR 프레임워크에 대한 포괄적인 **조사 연구**입니다.

### 1. 문헌 검색 및 선정

- **검색 전략**: Scopus, Web of Science, Elsevier, IEEE, ACM Digital Library, Wiley, IET Digital Library 등 주요 학술 데이터베이스에서 다음 키워드 쿼리를 사용하여 관련 연구를 식별했습니다: "Transfer learning" OR "Knowledge transfer" OR "Model adaptation" OR "domain adaptation" "Model combination" OR "Fine-tuning" AND ("Automatic speech recognition" OR "Speech processing" OR "Natural language processing" OR "Spoken language" OR "Applications").
- **선정 기준**: 키워드 일치, 연구의 혁신성과 영향력(ASR 기반 혁신, 연구 품질, 기여 및 결과), 출판 유형(저널, 학회 논문, 도서 챕터), 그리고 2015-2023년 기간 내 출판 여부를 기준으로 연구를 선별했습니다. 반복적이거나 영어 외 언어로 작성된 논문은 제외했습니다.

### 2. DTL 및 ASR 개념적 배경

- **도메인($\mathcal{D}$)**: 특징 공간 $\mathcal{X}$와 주변 확률 분포 $P(\mathcal{X})$로 정의됩니다($ \mathcal{D} = \{\mathcal{X}, P(\mathcal{X})\} $). 초기 지식이 있는 소스 도메인($\mathcal{D}_{S}$)과 학습할 지식이 있는 타겟 도메인($\mathcal{D}_{T}$)으로 구분됩니다.
- **작업($\mathcal{T}$)**: 특징 공간 $\mathcal{X}$와 레이블 공간 $\mathcal{Y}$에 대한 학습 목표 예측 함수 $F(\mathcal{X})$ 또는 조건부 분포 $P(\mathcal{Y}|\mathcal{X})$로 정의됩니다($ \mathcal{T} = \{\mathcal{Y}, F(\mathcal{X})\} $). 소스 작업($\mathcal{T}_{S}$)과 타겟 작업($\mathcal{T}_{T}$)으로 구분됩니다.
- **DTL**: $\mathcal{D}_{S} \ne \mathcal{D}_{T}$ 또는 $\mathcal{T}_{S} \ne \mathcal{T}_{T}$일 때, $\mathcal{D}_{S}$와 $\mathcal{T}_{S}$에서 얻은 지식을 활용하여 $\mathcal{D}_{T}$와 $\mathcal{T}_{T}$에 대한 대상 예측 함수 $\mathcal{F}_{T}$의 성능을 향상시키는 것을 목표로 합니다.
- **ASR 시스템 구조**: 음성 신호를 텍스트로 변환하는 시스템으로, 음향 전처리(MFCC 등 특징 추출), 음향 모델(AM), 어휘집, 언어 모델(LM), 디코더로 구성됩니다.
  - **AM**: 음성 신호의 음향적 특성을 모델링하며, HMM, DNN-HMM, End-to-End 모델(CTC, Seq2Seq) 등이 사용됩니다.
  - **LM**: 언어의 문법적, 의미론적 제약을 모델링하며, N-gram, NNLM, BERT, LSTM 등이 사용됩니다.
- **ASR 평가 기준**: WER(Word Error Rate), CER(Character Error Rate), PER(Phoneme Error Rate), 정확도, 재현율, 정밀도, F1-score, EER(Equal Error Rate), UAR(Unweighted Average Recall), MOS(Mean Opinion Score), PESQ(Perceptual Evaluation of Speech Quality), RTF(Real-time Factor), APT(Average Processing Time) 등이 사용됩니다.

### 3. DTL 기법 분류 및 ASR 적용

본 연구는 DTL 기법을 **귀납적 DTL(Inductive DTL)**, **전이적 DTL(Transductive DTL)**, **적대적 DTL(Adversarial DTL)**로 분류하고, 각 유형에 속하는 미세 조정(Fine-tuning), 어댑터 모듈(Adapter modules), 특징 기반(Feature-based), 제로 샷(Zero-shot), 도메인 적응(DA), 교차-모달리티 DTL(Cross-modality DTL), 비지도 DTL(Unsupervised DTL) 등의 세부 기법들을 ASR의 음향 모델(AM) 및 언어 모델(LM)에 어떻게 적용하는지 분석합니다.

## 📊 Results

본 논문은 DTL 기반 ASR의 다양한 적용 분야와 그 성능을 상세히 분석했습니다.

### 1. 음향 모델(AM)을 위한 DTL

- **특징 정규화 기반 DTL**: 선형 변환을 통해 음성 특징을 정규화하며, 기존 네트워크에 변환 네트워크를 추가하여 파라미터를 조정합니다. SAT(Speaker Adaptive Training), DNN-HMM 결합, 비선형 적응 계층 등이 활용되어 WER 및 PER 감소에 기여합니다.
- **보수적 훈련을 위한 DTL**: 제한된 데이터로 모델 성능을 적응시키는 방법으로, KL-발산(KLD) 정규화가 널리 사용됩니다. 이는 과적합을 방지하고 소스 및 타겟 모델 분포를 유사하게 만듭니다. Seq2Seq 모델의 화자 적응 등에서 WER을 크게 줄입니다.
- **부분 공간 기반 DTL**: PCA, SVD, NMF와 같은 비지도 차원 축소 기법을 활용하여 각 모델 파라미터 또는 변환의 부분 공간을 식별합니다. NMF의 변형인 CNMF는 다국어 및 다중 작업 학습을 통해 PER을 3.90%까지 감소시키는 등 높은 성능을 보입니다.

### 2. 언어 모델(LM)을 위한 DTL

- **BERT 기반 DTL**: 사전 훈련된 BERT 모델의 지식을 활용하여 ASR 시스템의 LM 적응 및 N-best 목록 재점수화(L2RS) 성능을 향상시킵니다.
- **LDA 기반 DTL**: 잠재 디리클레 할당(LDA)과 같은 생성적 확률 모델을 사용하여 단어 간의 연결을 포착하고 LM을 구축합니다.
- **NNLM 기반 DTL**: 신경망 LM(NN-LM)은 N-best 재점수화에서 WER을 낮추며, 특징 기반 또는 모델 기반 적응을 통해 새로운 도메인에 효과적으로 적응합니다. RNN-LM은 WER을 16.0%까지 감소시켰습니다.
- **LSTM 기반 DTL**: 가변 길이 시퀀스에 적합하여 장거리 의존성을 활용하며, n-gram 근사 없이 LM 성능을 향상시킵니다.
- **Sequence-to-sequence 모델 기반 DTL**: CTC 및 인코더-디코더 모델과 같은 종단 간 아키텍처는 음향 모델과 언어 모델을 결합하여 전반적인 ASR 성능을 향상시킵니다.

### 3. 교차-도메인 ASR

- **감정 인식용 DTL**: 언어 정보와 음향 데이터 결합을 통해 SER(Speech Emotion Recognition) 정확도를 향상시키며, ASR 시스템에서 학습된 특징을 감정 추정에 전이합니다.
- **교차-언어 DTL**: 고자원 언어 모델을 소자원 언어 ASR에 적응시키는 일반적인 방법으로, 음소 특징 공유 가정을 기반으로 합니다. Fine-tuning, Prognets, DNN, TDNNF 등이 활용되어 WER을 38.6%까지 감소시켰습니다.
- **교차-코퍼스 SER (CC-SER)**: 훈련 및 테스트 데이터 간의 환경/장치 불일치 문제를 해결하기 위해 TLSL(Transfer Linear Subspace Learning), DoSL(Domain-adaptive Subspace Learning) 등 다양한 DTL 모델이 제안되었습니다.

### 4. 적대적 TL 기반 ASR

- **적대적 공격**: 미세한 교란(노이즈)을 통해 ASR 시스템을 오분류하거나 성능을 향상시킬 수 있습니다. DTL은 이러한 적대적 예제의 전이 가능성을 활용합니다.
- **유형**: 화이트 박스/블랙 박스 공격, 비타겟/타겟 공격으로 분류되며, 적대적 훈련을 통해 ASR 시스템의 견고성을 높이거나(WER 23% 감소) 공격 성공률(100%)을 달성합니다.

### 5. 의료 진단을 위한 DTL 기반 ASR

- **심장 소리 분류**: DTL PANNs-기반 모델이 심장 소리 분류에 활용되어 UAR(Unweighted Average Recall) 89.7%를 달성합니다.
- **파킨슨병 진단**: DTL 기반 ASR은 파킨슨병 자동 진단에 효과적이며, SqueezeNet, ResNet, DenseNet 등의 모델 미세 조정을 통해 91.17%의 정확도를 달성합니다.
- **기타 의료 진단**: 우울증 예측, 조음 장애 화자를 위한 음성 인식, 건강 상태 분류 등 다양한 분야에서 DTL 기반 ASR이 활용됩니다.

### 6. 기타 응용

오디오 태깅, 음향 이벤트 감지, 음성 향상, 웨어러블 장치 기반 사회적 음성 평가, 음성 번역(ST), 화자 확인(SV), 해양 포유류 소리 분류, 다국어 TTS 등 폭넓은 분야에서 DTL 기반 ASR 기술이 성능 향상에 기여하고 있습니다.

## 🧠 Insights & Discussion

본 연구는 DTL 기반 ASR 방법론이 계산 효율성 및 기존 ML 알고리즘을 능가하는 능력 덕분에 다양한 응용 시나리오에서 효과적임을 확인했습니다. 특히 훈련 데이터와 대상 도메인 데이터 간에 상당한 불일치가 있을 때 DTL의 이점이 두드러집니다. 그러나 DTL 기반 ASR 시스템의 성능과 일반화를 더욱 향상시키기 위해서는 다음과 같은 주요 도전 과제들이 해결되어야 합니다.

### 1. 부정적 전이 (Negative Transfer, NT) 문제

NT는 소스 도메인에서 대상 도메인으로 지식이 전이될 때 학습 성능이 저하되는 현상을 의미합니다. 이는 소스 및 대상 도메인 간의 불충분한 유사성이나 "귀납적 편향"으로 인해 발생할 수 있으며, DTL의 이점을 제한하거나 오히려 해를 끼칠 수 있습니다. NTG(Negative Transfer Gap)와 같은 개념이 도입되어 NT 발생을 정량화하고 있지만, 이를 완화하기 위한 더 많은 연구가 필요합니다.

### 2. 과적합 (Overfitting) 문제

DTL은 다른 ML/DL 모델보다 과적합 문제를 더 잘 관리할 수 있지만, 소스 도메인의 노이즈를 학습하여 출력에 부정적인 영향을 미칠 수 있습니다. 특히, DL 모델의 특정 레이어를 제거하는 것이 어려워 모델 구조를 변경하기 어렵고, 적절한 레이어 수를 분석하는 데 계산 비용이 많이 듭니다. 드롭아웃, LASSO 정규화, 교차 검증, 데이터 증강 등의 방법으로 과적합을 부분적으로 해결할 수 있지만, DTL 맥락에서 이 문제에 대한 심층적인 연구가 더 필요합니다.

### 3. DTL 기반 ASR 결과의 재현성 문제

DTL 기반 ASR 솔루션의 재현성은 다음과 같은 요인으로 인해 여전히 도전 과제로 남아 있습니다:

- **비공개 데이터셋**: 많은 연구가 공개되지 않은 맞춤형 데이터셋으로 테스트되어 일반화 가능성 평가가 어렵습니다.
- **온라인 플랫폼 부재**: 기존 알고리즘과 데이터셋을 통합하는 온라인 플랫폼이 부족합니다.
- **평가 지표의 다양성**: 성능 측정 및 도메인 간 거리 정량화에 사용되는 평가 지표와 파라미터가 다양하여 공정한 비교가 복잡합니다.

### 4. 지식 획득 측정 문제

DTL 모델을 특정 ASR 작업에 적용할 때 얻는 지식의 양을 정량적으로 측정하는 것은 매우 중요하지만, 아직 충분히 탐구되지 않은 문제입니다. 전이 비율, 전이 손실, 전이 오류, 인-도메인 비율과 같은 지표가 제안되었지만, 다른 DTL 기법에서의 행동 예측은 여전히 어렵습니다. 정확도, MSE, F1 점수, WER 등과 같은 일반적인 평가 지표가 주로 사용되지만, 도메인 간 유사성을 측정하는 보편적이고 도메인 독립적인 방법론에 대한 연구가 더 필요합니다.

### 5. DTL의 통합 문제

DTL 기반 ASR 전략 개발은 DTL의 기본 원리를 설명하는 데 사용되는 광범위한 수학적 공식 때문에 방해를 받습니다. 다양한 용어와 그 변형의 사용은 혼란을 야기할 수 있으므로, DTL 정의 및 배경 공식을 표준화하기 위한 노력이 필요합니다. 패트리샤 외([235])가 DTL 공식화 및 정의를 통합하려는 시도를 했지만, 이 방향으로의 추가적인 노력이 절실합니다.

### 6. 기타 도전 과제

- **음성 기반 DTL의 복잡성**: 이미지 기반 DTL보다 더 복잡하며, 언어, 화자 변이, 연령대, 민족, 음향 환경 등 소스 및 대상 데이터베이스 간의 광범위한 불일치 때문입니다.
- **CTC의 한계**: CTC(Connectionist Temporal Classification)는 종단 간 음성 인식에서 잠재력이 크지만, 한 프레임의 출력이 다음 프레임 출력에 영향을 미치지 않는다는 프레임 독립성 가정에 의해 제한됩니다.
- **교차-언어 DTL의 과제**: 다국어 공유 지식은 여러 소스에서 다양한 수준의 언어 특성을 캡슐화해야 하며, 모든 지식 계층 수준에서 언어적 변이를 고려한 통합이 필요합니다.
- **계산 부하**: DTL의 심층 도메인 적응 프로세스는 상당한 계산 비용을 발생시키며, DTL 기법이 의존하는 심층 아키텍처 자체가 추가적인 계산 부담을 야기합니다.

## 📌 TL;DR

본 논문은 대규모 데이터 및 계산 자원 요구와 도메인 불일치로 인한 딥러닝 기반 ASR의 한계를 해결하기 위한 **심층 전이 학습(DTL)**의 포괄적인 조사 연구입니다. DTL-ASR 방법론을 **음향 모델(AM), 언어 모델(LM), 교차 도메인 ASR(예: 감정 인식, 교차 언어, 교차 코퍼스)**로 분류하고, **의료 진단, 적대적 공격 및 보안**을 포함한 다양한 응용 분야에서의 활용 사례를 분석합니다. 주요 기여는 DTL 기반 ASR 기법의 상세한 분류, 각 프레임워크의 장단점 비교, **부정적 전이, 과적합, 재현성, 지식 획득 측정, DTL 통합**과 같은 주요 도전 과제 식별, 그리고 **프라이버시 보존, DTL 모델 해석 가능성, 온라인 DTL, DTL 기반 대규모 언어 모델(LLM) 활용**과 같은 미래 연구 방향 제시입니다. 이 연구는 ASR 분야의 연구자와 실무자가 DTL 기술의 현재 상태와 잠재력을 이해하고, 향후 연구 및 개발 노력을 위한 통찰력을 제공하는 것을 목표로 합니다.
