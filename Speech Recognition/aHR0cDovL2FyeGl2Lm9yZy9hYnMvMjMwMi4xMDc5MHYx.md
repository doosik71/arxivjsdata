# FEDERATED LEARNING FOR ASR BASED ON WAV2VEC 2.0

Tuan Nguyen, Salima Mdhaffar, Natalia Tomashenko, Jean-Franc ̧ois Bonastre, Yannick Est
`
eve

## 🧩 Problem to Solve

본 연구는 자가 지도 학습(self-supervised learning, SSL)을 통해 사전 학습된 wav2vec 2.0 모델을 기반으로 자동 음성 인식(ASR) 모델을 연합 학습(Federated Learning, FL) 방식으로 훈련하는 방법에 대한 연구입니다. 특히, 사용자 데이터 공유 없이 ASR 모델의 성능을 향상시키고, 스피커별 FL 참여가 ASR 성능에 미치는 영향을 분석하며, 교환된 모델을 통해 스피커 정체성이 얼마나 보호되는지 측정하는 데 중점을 둡니다.

## ✨ Key Contributions

- 자가 지도 학습으로 사전 학습된 wav2vec 2.0 모델을 ASR을 위해 연합 학습에 활용한 최초의 연구입니다.
- 언어 모델 없이도 TED-LIUM 3 테스트 세트에서 10.92%의 낮은 단어 오류율(WER)을 달성하여, 사용자 데이터 공유 없이도 효과적인 ASR 모델 학습이 가능함을 입증했습니다.
- 스피커의 연합 학습 참여 정도와 상관없이 전역 모델(global model)이 스피커 관련 정보를 잘 유지하며, 스피커 참여 횟수에 따른 편향이 없음을 분석했습니다.
- 신경망 흔적(neural network footprint) 분석을 통해 교환된 모델에 포함된 스피커 정체성 정보 유출 정도를 측정하고, wav2vec 2.0 기반 모델의 특정 계층(layer)에서 스피커 정체성 정보가 드러날 수 있음을 계층별로 분석했습니다.

## 📎 Related Works

- **연합 학습(FL):** 이미지 및 자연어 처리 분야에서 성공적으로 탐색되었으며 [1], 데이터 공유 없이 분산된 환경에서 기계 학습 모델을 협력적으로 훈련하는 패러다임입니다 [1, 2].
- **음성 관련 FL 적용:** ASR [3, 4, 5, 6, 7, 8], 키워드 스포팅 [9, 10, 11], 화자 인식 [12, 13], 음성 감정 인식 [14], 음성 표현의 자가 지도 학습 [15] 등 다양한 음성 관련 애플리케이션에 적용되었습니다.
- **ASR FL의 도전 과제:** 통신 병목 현상, 컴퓨팅 능력 및 에너지 상태, 학습된 모델의 성능 및 정확도, 프라이버시 및 보안 고려 사항 등이 있습니다 [16].
- **wav2vec 2.0:** 자가 지도 학습을 통해 사전 학습된 모델로, 여러 음성 처리 작업에서 좋은 성능을 달성했습니다 [17, 18, 19].
- **FL에서의 프라이버시 공격:** 연합 학습은 다양한 유형의 공격에 취약할 수 있으며 [20, 4], 특히 [4]에서는 교환된 모델에 포함된 정보를 분석하는 접근 방식을 제안했습니다.

## 🛠️ Methodology

1. **연합 학습 설정:**
   - **패러다임:** 여러 클라이언트가 로컬 모델을 훈련하고, 서버가 이 업데이트를 집계하여 전역 모델을 생성하는 반복적인 라운드 방식.
   - **집계(Aggregation):** FedAvg (Federated Averaging) [2] 알고리즘을 사용하며, 이는 각 클라이언트 $k$의 데이터셋 크기 $n_k$에 비례하여 모델 매개변수 $F_k(w)$를 가중 평균합니다:
     $$f(w) = \sum_{k=1}^{m} \frac{n_k}{n} F_k(w)$$
     여기서 $m$은 선택된 클라이언트 수, $n$은 주어진 라운드에서 사용된 총 데이터 크기입니다.
   - **클라이언트:** TED-LIUM 3 훈련 세트의 각 스피커(총 1943명)가 클라이언트로 설정됩니다.
   - **데이터 분할:** 스피커 데이터가 10분 초과인 경우, 5분은 `analysis` 데이터셋으로, 나머지는 `train` 데이터셋으로 사용됩니다. 10분 미만인 경우, 전체 데이터가 로컬 `train` 데이터셋으로 사용됩니다.
   - **참여 클라이언트 수:** 각 라운드에서 20개의 클라이언트가 집계 프로세스에 참여하도록 무작위로 선택됩니다.
   - **도구:** 연합 학습 프레임워크로는 Flower [24]를, ASR 툴킷으로는 SpeechBrain [25]을 사용했습니다.
2. **ASR 모델 아키텍처:**
   - **CRDNN 기반 ASR (비교군):** 어텐션 기반 인코더-디코더 신경망을 사용합니다. 인코더는 CRDNN 블록(컨볼루션, 순환, 심층 신경망)과 LSTM 및 dense 레이어로 구성됩니다. CommonVoice 데이터셋으로 사전 학습된 모델로 가중치를 초기화합니다.
   - **wav2vec 2.0 기반 ASR:** 대규모 영어 사전 학습 wav2vec 2.0 모델(LS960-LV60)에 선형 레이어와 소프트맥스 출력 레이어를 추가한 종단 간(end-to-end) 접근 방식을 사용합니다. CTC(Connectionist Temporal Classification) 손실 함수 [29]를 사용하며, 서버 모델의 가중치는 무작위로 초기화됩니다 (wav2vec 2.0은 ASR 특화 사전 학습이 아닌, 음성 표현 학습에 중점을 둡니다).
3. **실험 데이터:** TED-LIUM 3 코퍼스 [26] (452시간 분량의 영어 음성 데이터)를 사용했습니다. `train`, `analysis`, `dev`, `test`, `indicator` 데이터셋으로 구성되며, `test`, `dev`, `train`, `indicator` 데이터셋의 스피커는 서로 겹치지 않습니다.
4. **학습 세부 사항:** 서버 모델은 100 라운드 동안 훈련되었으며, 각 클라이언트 모델은 로컬 데이터셋에서 20 에포크(epochs) 동안 미세 조정되었습니다.
5. **프라이버시 평가:**
   - **공격 모델:** [4]에서 제안된 것과 유사한 공격 모델을 사용합니다. 공격자는 특정 라운드 $r$의 전역 모델 $G_r$과 개인화된 모델 $M$ (알 수 없는 스피커의 모델), 그리고 알려진 스피커의 음성 데이터 $u_1, ..., u_T$를 이용해 $M$이 $u_1, ..., u_T$와 동일한 스피커에 해당하는지 확인하는 ASV (Automatic Speaker Verification) 작업을 수행합니다.
   - **정보 추출:** $G_r$과 $M$ (또는 $M_e$) 간의 활성화 값(activation values) 차이를 `indicator` 데이터셋에 대해 계산하고, 이를 통해 스피커 정체성 정보를 포착합니다.
   - **유사성 점수:** 스피커 $e$의 개인화된 모델 $M_e$와 테스트 모델 $M$ 간의 코사인 유사도를 사용합니다.
   - **평가 지표:** 동일 오류율(Equal Error Rate, EER)을 사용합니다. EER은 오경보율(false alarm rate, $P_{fa}(\theta)$)과 누락률(miss rate, $P_{miss}(\theta)$)이 같아지는 임계값 $\theta_{EER}$에서의 오류율이며 ($EER = P_{fa}(\theta_{EER}) = P_{miss}(\theta_{EER})$), EER 값이 높을수록 프라이버시 보호가 우수함을 의미합니다.

## 📊 Results

- **ASR 성능 (WER):**
  - wav2vec 2.0 기반 모델이 CRDNN 기반 모델보다 현저히 우수한 성능을 보였습니다.
  - wav2vec 2.0은 85번째 라운드에서 10.92%의 WER을 달성했으며, 초기 4라운드 이내에 CRDNN을 추월하고 지속적으로 성능을 향상시켰습니다.
  - CRDNN은 초기 WER이 37.04%로 더 나은 시작점이었으나, 수렴에 어려움을 겪고 35% 수준에 머물렀습니다.
  - 전체 스피커의 62%(1209명)만이 100 라운드 동안 wav2vec 2.0 모델의 최고 성능 달성에 기여했습니다.
- **스피커별 종단 간 ASR 성능:**
  - 전역 모델 $G_r$의 `analysis` 데이터셋에 대한 성능은 초기 라운드(5~22 라운드)에서 크게 향상되었고, 이후 안정화되었습니다.
  - 스피커의 참여 횟수에 따른 성능 편향은 관찰되지 않았으며, $G_r$은 모든 스피커에 대한 관련 정보를 잘 포함했습니다.
  - 로컬 스피커 모델(자체 데이터로 미세 조정됨)은 로컬 성능이 향상되었지만, 전역 모델(10.92%)이 테스트 세트에서 로컬 모델의 평균 WER(13.04%)보다 우수하여, 전역 모델이 학습에 참여한 스피커뿐만 아니라 새로운 스피커에게도 잘 일반화됨을 보여주었습니다.
- **스피커 정체성 보호 (EER):**
  - EER(프라이버시)은 계산 라운드 수가 증가할수록 일반적으로 증가하여, 후기 라운드에서는 공격자가 스피커 정보를 검색하기 더 어려워졌습니다.
  - 하위 은닉 계층(예: #2~#6)은 평균적으로 더 낮은 EER을 보였으며(5%에서 20%까지), 이는 상위 계층보다 더 많은 스피커 정체성 정보가 유출될 수 있음을 시사합니다.

## 🧠 Insights & Discussion

- **FL ASR에서 wav2vec 2.0의 효과:** wav2vec 2.0과 같은 자가 지도 학습으로 사전 학습된 모델은 로컬 클라이언트 데이터가 적고 비동질적(non-IID)인 연합 학습 환경에서 ASR에 매우 효과적임을 입증했습니다. 이는 CRDNN과 같은 모델이 겪는 한계를 극복합니다.
- **전역 모델의 일반화 능력:** 연합 학습을 통해 훈련된 전역 모델은 학습에 참여한 스피커뿐만 아니라 새로운, 이전에 본 적 없는 스피커에게도 잘 일반화됩니다.
- **프라이버시 시사점:** 연합 학습이 프라이버시를 목표로 함에도 불구하고, 교환된 모델, 특히 하위 계층 및 초기 학습 라운드에서 스피커 정체성 정보가 여전히 검색될 수 있음을 보여줍니다. 이는 자가 지도 학습 모델에서도 FL에서 프라이버시를 강화하기 위한 추가적인 기술의 필요성을 강조합니다.
- **한계 및 향후 연구:** 본 연구는 어떤 계층에서 정보가 유출되는지를 보여주었지만, 공유된 로컬 스피커 모델이 얼마나 많은 언어 정보를 전달하는지에 대한 조사는 향후 연구로 남겨져 있습니다. 또한, 종단 간 ASR에서 FL 훈련을 처음부터 시작하는 것이 거의 불가능하다는 점을 인지하며, 사전 학습 모델의 중요성을 강조합니다.

## 📌 TL;DR

- **문제:** 데이터 프라이버시를 보호하면서 wav2vec 2.0 기반 ASR 모델을 연합 학습(FL)으로 효율적으로 훈련하고, 모델 교환 시 스피커 정체성 유출을 분석하는 것이 목표였습니다.
- **방법:** 자가 지도 학습으로 사전 학습된 wav2vec 2.0 모델에 FedAvg 기반 FL을 적용하여 TED-LIUM 3 데이터셋에서 ASR 모델을 미세 조정했습니다. 교환된 모델의 프라이버시 침해 가능성을 평가하기 위해 신경망 흔적 분석을 통해 계층별 스피커 정체성 정보 유출을 측정했습니다.
- **주요 발견:** wav2vec 2.0 기반 FL ASR 모델은 언어 모델 없이도 10.92%의 낮은 WER을 달성하며 뛰어난 성능과 일반화 능력을 보였습니다. 그러나, FL임에도 불구하고 교환된 모델의 하위 계층과 초기 학습 라운드에서 스피커 정체성 정보가 유출될 수 있음을 확인했습니다.
