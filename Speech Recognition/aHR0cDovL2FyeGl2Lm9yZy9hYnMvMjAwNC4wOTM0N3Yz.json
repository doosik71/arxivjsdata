{
  "url": "http://arxiv.org/abs/2004.09347v3",
  "title": "End-to-End Whisper to Natural Speech Conversion using Modified\n  Transformer Network",
  "authors": "Abhishek Niranjan, Mukesh Sharma, Sai Bharath Chandra Gutha, M Ali Basha Shaik",
  "year": 2020,
  "abstract": "Machine recognition of an atypical speech like whispered speech, is a\nchallenging task. We introduce whisper-to-natural-speech conversion using\nsequence-to-sequence approach by proposing enhanced transformer architecture,\nwhich uses both parallel and non-parallel data. We investigate different\nfeatures like Mel frequency cepstral coefficients and smoothed spectral\nfeatures. The proposed networks are trained end-to-end using supervised\napproach for feature-to-feature transformation. Further, we also investigate\nthe effectiveness of embedded auxillary decoder used after N encoder\nsub-layers, trained with the frame-level objective function for identifying\nsource phoneme labels. We show results on opensource wTIMIT and CHAINS datasets\nby measuring word error rate using end-to-end ASR and also BLEU scores for the\ngenerated speech. Alternatively, we also propose a novel method to measure\nspectral shape of it by measuring formant distributions w.r.t. reference\nspeech, as formant divergence metric. We have found whisper-to-natural\nconverted speech formants probability distribution is similar to the\ngroundtruth distribution. To the authors' best knowledge, this is the first\ntime enhanced transformer has been proposed, both with and without auxiliary\ndecoder for whisper-to-natural-speech conversion and vice versa."
}