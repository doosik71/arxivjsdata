# SPEECHAIN: 대규모 기계 음성 사슬을 위한 음성 툴킷
Heli Qi, Sashi Novitasari, Andros Tjandra, Sakriani Sakti, Satoshi Nakamura

## 🧩 Problem to Solve
자동 음성 인식(ASR)과 음성 합성(TTS) 모델은 밀접한 관계를 가짐에도 불구하고 개별적으로 개발되어 왔다. 기계 음성 사슬(Machine Speech Chain, MSC) 개념이 도입되어 ASR과 TTS를 연결하지만, 특히 ASR 성능 향상을 위해 TTS가 생성한 합성 음성으로 훈련하는 대규모 TTS→ASR 체인을 위한 효율적인 파이프라인 구축에 어려움이 있다. 기존의 오픈소스 툴킷들은 ASR과 TTS 구성 요소를 독립적으로 개발하여 두 분야 간의 연계가 부족하다.

## ✨ Key Contributions
*   대규모 기계 음성 사슬 개발을 위한 오픈소스 PyTorch 기반 툴킷인 SpeeChain을 소개한다.
*   특히 TTS 데이터 증강을 통한 ASR 성능 향상을 위한 효율적인 TTS→ASR 체인 파이프라인을 제공한다.
*   다중 GPU를 활용한 배치(batch) 수준 모델 추론을 구현하여 대규모 데이터 처리를 가속화한다.
*   여러 데이터 로더를 사용하여 실제(real) 및 합성(synthetic) 데이터의 고정된 비율로 배치를 생성함으로써 ASR 모델 훈련의 안정성을 높인다.
*   훈련 중 동적인 데이터 필터링 및 선택 기능을 제공한다.
*   반지도 학습 환경에서 LibriSpeech 데이터셋에 대한 실험을 통해 TTS→ASR 체인이 ASR의 단어 오류율(WER)을 크게 개선함을 입증한다.

## 📎 Related Works
*   종단간(End-to-End) 자동 음성 인식(ASR) [1-4] 및 음성 합성(TTS) [5-7] 분야의 발전.
*   ASR과 TTS를 연결하는 기계 음성 사슬(Machine Speech Chain) 개념 [8, 9] 및 이의 핵심 응용인 TTS→ASR 체인 연구 [10, 11].
*   합성 음성으로 ASR 모델을 학습시키는 TTS→ASR 체인의 초기 성공적인 실험 [8, 12] 및 다중 화자 TTS, 비라벨링된 외부 도메인 텍스트 활용 연구 [13-19].
*   ASR 자기 학습(self-training) 기법 [27, 28].
*   다양한 오픈소스 ASR 및 TTS 툴킷 [20-25]이 존재하지만, ASR과 TTS 구성 요소 간의 연계가 부족하다는 점을 지적한다.

## 🛠️ Methodology
제안하는 TTS→ASR 체인은 세 단계로 구성된다.
1.  **기본 ASR 및 TTS 학습:** 동일한 레이블링된 데이터셋으로 기본 ASR 및 TTS 모델을 학습시킨다. 제한된 데이터로 인해 다중 화자 TTS 학습이 어렵다는 점을 고려한다.
2.  **음성 합성 및 필터링:** 기본 TTS 모델 $\theta_{\text{base}}^{\text{TTS}}$이 비라벨링된 텍스트 $y_{u_i}$로부터 합성 음성 $\tilde{x}_{i}$을 생성하여 의사(pseudo) 레이블링된 데이터셋 $D_u = \{(\tilde{x}_{1}, y_{u_1}), \dots, (\tilde{x}_{|D_u|}, y_{u_{|D_u|}})\}$를 구성한다. 이후 기본 ASR 모델 $\theta_{\text{base}}^{\text{ASR}}$의 WER $W_{\text{base}}$을 기준으로 합성 음성의 품질을 평가하고 필터링한다. WER은 $W_{\text{base}_{i}} = \frac{\text{edit distance}(\tilde{y}_{i},y_{u_i})}{|y_{u_i}|}$으로 계산된다.
3.  **타겟 ASR 학습:** 필터링된 $D_u$와 실제 레이블링된 데이터 $D_l$를 결합한 $D=D_l \cup D_u$를 사용하여 타겟 ASR 모델 $\theta_{\text{target}}^{\text{ASR}}$을 학습시킨다. 학습 시, 배치(batch) $B$는 실제 데이터 $B_l$와 의사 데이터 $B_u$를 고정된 비율로 조합하여 구성되며, 손실 함수 $L = (1-\lambda)L_{l} + \lambda L_{u}$를 통해 최적화된다.

SpeeChain 툴킷은 다음과 같은 효율적인 기능들을 제공한다.
*   **빠른 모델 추론 및 균일한 데이터 구조:** `torch.nn.parallel.DistributedDataParallel`을 활용하여 다중 GPU 기반의 배치 수준 모델 추론을 지원하며, 실제 데이터와 의사 데이터 간의 균일한 데이터 구조를 통해 실험 설정을 간소화한다.
*   **다중 데이터 로더를 통한 배치 생성:** 여러 `torch.utils.data.DataLoader`를 사용하여 실제 데이터와 의사 데이터로부터 음성-텍스트 쌍을 독립적으로 가져와, 고정된 실제-합성 데이터 비율로 배치를 생성함으로써 학습 안정성을 확보한다.
*   **실시간(on-the-fly) 데이터 선택:** 배치 생성과 데이터셋 접근을 분리하여, 메타데이터(예: WER 분포)를 기반으로 학습 중 접근 가능한 음성-텍스트 쌍을 쉽게 변경할 수 있도록 한다.

## 📊 Results
*   LibriSpeech-`trainclean460` 데이터셋에서 TTS→ASR 체인을 통한 반지도 학습은 ASR의 단어 오류율(WER)을 크게 개선함을 보여주었다.
*   기본 ASR 모델의 WER을 이용한 합성 음성 필터링은 오히려 ASR 성능 향상을 저해하는 것으로 나타났다. 이는 실제 음성과 합성 음성 간의 불일치로 인해 기본 WER이 합성 음성의 품질을 정확히 평가하지 못하며, 합성 음성 내 일부 오류가 데이터 증강의 역할을 할 수 있음을 시사한다.
*   `test_other` 데이터셋에 대한 TTS→ASR 체인의 개선 효과는 ASR 자기 학습보다 작았는데, 이는 TTS 모델이 `clean` 데이터로만 학습되어 `clean` 및 `other` 데이터셋 간의 음향 불일치가 발생하기 때문으로 추정된다.
*   합성 음성이 훈련 세트에 포함될 경우, 각 배치(batch)에 일정량의 실제 음성을 포함하여 기울기 방향을 정규화하는 고정된 실제-합성(R2S) 데이터 비율이 중요함을 확인했다. 반면, 두 개의 실제 데이터셋을 사용하여 최상위 성능(topline) 모델을 훈련할 때는 배치 생성의 무작위성을 높이기 위해 동적으로 데이터를 혼합하는 것이 더 효과적이었다.

## 🧠 Insights & Discussion
*   합성 음성 내 일부 오류가 데이터 증강(data augmentation) 역할을 하여 ASR 모델 학습에 긍정적인 영향을 줄 수 있다(예: 침묵이 ASR이 누락된 부분을 예측하도록 강제하는 역할).
*   실제 음성과 합성 음성 간의 음향적 불일치로 인해 기본 WER 필터링이 합성 음성 품질 평가에 한계가 있을 수 있다. TTS 모델 학습 시 다양한 음향 특성을 반영하는 데이터 활용의 중요성을 시사한다.
*   반지도 학습 시 합성 데이터를 사용할 경우, 각 학습 배치(batch)에 고정된 비율의 실제 데이터를 포함하는 것이 기울기 방향을 안정화하고 성능을 향상시키는 데 필수적이다.
*   SpeeChain 툴킷은 대규모 기계 음성 사슬 개발을 용이하게 하여, 반지도 ASR 연구 및 ASR-TTS 공동 최적화 연구에 기여할 잠재력이 크다.
*   향후 연구에서는 더욱 발전된 ASR 및 TTS 모델 구현, 반지도 TTS를 위한 ASR→TTS 체인 개발, ASR-TTS 공동 최적화를 위한 온라인 음성 사슬 학습 등을 포함할 예정이다.

## 📌 TL;DR
대규모 반지도 ASR을 위한 효율적인 TTS→ASR 체인 구축을 목표로 한다. SpeeChain은 다중 GPU 추론, 다중 데이터 로더를 통한 고정 비율 배치 생성, 동적 데이터 필터링 기능을 제공하는 툴킷이다. 실험 결과, 합성 음성을 활용한 반지도 ASR이 WER을 크게 개선하며, 합성 음성의 오류도 데이터 증강 효과를 낼 수 있음을 보여준다. 학습 안정성을 위해 실제-합성 데이터의 고정 비율 유지가 중요하다.