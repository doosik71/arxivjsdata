# Transformers in Speech Processing: A Survey

Siddique Latif, Aun Zaidi, Heriberto Cuayahuitl, Fahad Shamshad, Moazzam Shoukat, Muhammad Usama, and Junaid Qadir

## 🧩 Problem to Solve

자연어 처리(NLP) 분야에서 트랜스포머(Transformers)의 놀라운 성공은 음성 시퀀스 내의 장거리 의존성 모델링 잠재력을 탐색하며 음성 처리 커뮤니티의 관심을 불러일으켰습니다. 자동 음성 인식(ASR), 음성 합성(TTS), 음성 번역(ST) 등 다양한 음성 관련 도메인에서 트랜스포머가 부상하고 있지만, 이처럼 이질적인 하위 분야의 연구들을 연결하고 트랜스포머의 도전 과제와 잠재적 해결책에 대한 포괄적인 이해를 제공하는 자원이 부족합니다. 기존 연구들은 주로 컴퓨터 비전(CV)이나 NLP에 초점을 맞추거나, 음성 처리 내 딥러닝 기술을 다루지만 트랜스포머를 구체적으로 다루지 않는 경우가 많아 이러한 격차를 해소할 필요가 있습니다.

## ✨ Key Contributions

- 음성 처리 분야에서 트랜스포머 모델 적용에 대한 최초의 포괄적인 설문 조사를 제시하며, 100편 이상의 최신 논문을 다룹니다.
- 자동 음성 인식, 신경망 음성 합성, 음성 번역, 음성 파라언어학, 음성 향상, 멀티모달 애플리케이션, 음성 대화 시스템을 포함한 다양한 응용 분야별로 논문을 분류하여 빠르게 발전하는 분야를 심층적으로 다룹니다.
- 철저한 분석을 바탕으로 다양한 도전 과제를 식별하고, 이러한 문제들을 해결하기 위한 잠재적 솔루션과 미래 연구 방향에 대한 통찰력을 제공합니다.

## 📎 Related Works

이 논문은 트랜스포머 및 음성 처리 관련 최신 설문조사들과 비교하여 본 연구의 차별점을 강조합니다. 대부분의 트랜스포머 관련 설문조사는 컴퓨터 비전(CV) 및 자연어 처리(NLP)에 중점을 두었으며, 음성 처리만을 다루는 논문들은 트랜스포머를 깊이 있게 다루지 않았습니다. 예를 들어, 2016년 Deng 외 논문은 음성 처리의 자기 지도 표현 학습을 검토했고, 2019년 Khalil 외 논문은 음성 기반 감정 인식 딥러닝 기술을, 2019년 Nassif 외 논문은 음성 관련 애플리케이션의 딥러닝 사용을 리뷰했습니다. 반면, 2021년 Liu 외 논문은 CV의 트랜스포머를, 2021년 Acheampong 외 논문은 NLP의 감정 감지 트랜스포머를 다루는 등 특정 도메인에 초점을 맞췄습니다. 본 연구는 이러한 간극을 메워 트랜스포머를 활용한 음성 기술의 최신 발전에 집중합니다.

## 🛠️ Methodology

이 설문 논문은 음성 처리 도메인에서 트랜스포머 모델의 응용에 대한 포괄적인 문헌 검토를 수행합니다.

**1. 트랜스포머 아키텍처 배경:**

- **순환 신경망(RNN)의 한계:** 음성 데이터의 순차적 특성 모델링에 적합하지만, 긴 시퀀스 처리, 기울기 소실/폭발 문제, 병렬 컴퓨팅 활용의 어려움이 있습니다.
- **트랜스포머 개요:** Vaswani 외(2017)의 "Attention Is All You Need"에서 처음 소개되었습니다.
  - **셀프-어텐션 계층 (Self-Attention Layer):** 전체 입력 시퀀스에서 전역 정보를 통합하여 내부 상관관계를 포착합니다. 입력 $X \in \mathbb{R}^{N \times D}$를 Query ($Q$), Key ($K$), Value ($V$) 행렬로 변환합니다.
  - **스케일드 닷-프로덕트 어텐션 (Scaled Dot-Product Attention):** 어텐션 행렬 $A = \text{softmax} \left( \frac{QK^T}{\sqrt{D_k}} \right)$를 계산하고, 출력 $Z = AV$를 생성합니다.
  - **마스킹된 셀프-어텐션 (Masked Self-Attention):** 디코더에서 미래 엔티티에 대한 어텐션을 방지하기 위해 마스크 $M \in \mathbb{R}^{N \times N}$를 사용하여 $Z = \text{softmax} \left( \frac{QK^T}{\sqrt{d_k}} \circ M \right) V$와 같이 계산합니다.
  - **멀티-헤드 어텐션 (Multi-Head Attention, MHSA):** 여러 개의 셀프-어텐션 블록으로 구성되어 채널별로 연결되어 병렬화를 가능하게 하고, 입력 시퀀스의 다른 요소들 간의 의존성을 모델링합니다.
  - **위치 인코딩 (Positional Encoding):** 셀프-어텐션의 순서 불변성을 보완하기 위해 입력 시퀀스의 각 위치에 대한 정보를 제공합니다.

**2. 음성 처리를 위한 인기 트랜스포머 모델:**

- **wav2vec, w2v-BERT, XLS-R:** 전사나 분할 없이 음성 표현을 학습하는 자기 지도 훈련(대조 예측 코딩, 마스크 언어 모델링) 프레임워크입니다.
- **data2vec:** 음성, 이미지, 텍스트 등 멀티모달 데이터에서 표현을 학습하는 자기 지도 프레임워크입니다.
- **Whisper:** 잡음이 많거나 저자원 환경에서 음성 인식, 음성 번역, 언어 식별을 수행하는 범용 모델입니다.
- **Tacotron, Tacotron 2, Transformer TTS, FastSpeech, VALL-E, VALL-E X:** 텍스트 입력에서 고품질 음성을 생성하기 위한 음성 합성 모델들입니다.
- **Conformer:** 컨볼루션 및 트랜스포머 계층을 결합하여 지역 및 전역 컨텍스트 정보를 모두 캡처합니다.
- **UniSpeech, UniSpeech-SAT:** 저자원 및 교차 언어 음성 작업을 처리하기 위한 통합 사전 훈련 방법론을 제안합니다.
- **SpeechFormer, SpeechFormer++:** 음성 신호의 고유한 특성을 트랜스포머 모델에 통합하는 계층적 프레임워크입니다.
- **WavLM:** 마스킹된 음성 예측과 잡음 제거를 공동으로 학습하는 대규모 자기 지도 사전 훈련 모델입니다.

**3. 분야별 적용 분석:**

- 자동 음성 인식(ASR), 신경망 음성 합성(TTS), 음성 번역(ST), 음성 파라언어학, 음성 향상 및 분리, 음성 대화 시스템, 멀티모달 애플리케이션 등 다양한 음성 처리 하위 분야에서 트랜스포머의 적용 사례를 검토하고, 각 분야에서 트랜스포머가 달성한 성능 향상, 사용된 아키텍처 및 기법을 분석합니다.

## 📊 Results

트랜스포머는 음성 처리 분야의 다양한 작업에서 RNN 기반 모델 대비 상당한 성능 향상을 보였습니다.

- **자동 음성 인식 (ASR):**

  - RNN 대비 향상된 WER (Word Error Rate)을 달성했으며, 특히 Karita 외(2019)는 트랜스포머가 RNN 대비 훈련 및 성능 면에서 다양한 이점을 가짐을 보였습니다.
  - Li 외(2020)는 대규모 데이터셋(65,000시간)에서 트랜스포머 기반 어텐션 인코더-디코더 아키텍처가 최상의 정확도를 달성했음을 보고했습니다.
  - 스트리밍 ASR을 위한 증강 메모리 셀프-어텐션 트랜스포머(Wu 외, 2020)는 LC-BLSTM 대비 15% 오류 감소를 달성했습니다.
  - Conformer는 LibriSpeech 및 AISHELL-1 벤치마크에서 최첨단 성능을 달성했습니다.

- **신경망 음성 합성 (TTS):**

  - Li 외(2019)의 트랜스포머 TTS는 Tacotron 2 대비 4.25배 빠른 훈련 속도를 보이며 유사한 MOS(Mean Opinion Score) 성능을 달성했습니다.
  - FastSpeech 및 FastSpeech 2 (Ren 외, 2019, 2020)는 멜-스펙트로그램 생성을 병렬화하여 추론 속도를 크게 향상시켰습니다.
  - VALL-E (Chen 외, 2022)는 언어 모델링 접근 방식을 사용하여 제로샷(zero-shot) TTS에서 SOTA 성능을 달성했고, VALL-E X (Zhang 외, 2023)는 교차 언어 음성 합성으로 확장했습니다.

- **음성 번역 (ST):**

  - Vila 외(2018)는 스페인어-영어 번역에서 트랜스포머 기반 종단간 아키텍처가 연결된(cascaded) 시스템을 능가함을 보였습니다.
  - Zhang 외(2019)의 Lattice Transformer는 기존 SOTA를 개선했습니다.

- **음성 파라언어학 (Speech Paralinguistics):**

  - WavLM (Chen 외, 2022)은 자기 지도 사전 훈련을 통해 SUPERB 벤치마크에서 SOTA 결과를 달성했으며, SER, SV, SD, SS 등 여러 파라언어학적 작업에서 성능을 향상시켰습니다.
  - SpeechFormer 및 SpeechFormer++ (Chen 외, 2022, 2023)는 다양한 파라언어학적 작업에서 경쟁력 있는 결과를 보였습니다.

- **음성 향상 및 분리 (Speech Enhancement and Separation):**

  - SepFormer (Subakan 외, 2021)와 MSTG (Zhao 외, 2021)는 트랜스포머의 병렬 계산 능력과 멀티스케일 융합을 활용하여 음성 향상 및 분리에서 높은 SDR(Signal-to-Distortion Ratio) 및 SI-SNR(Source-to-Interference Ratio)을 달성했습니다.

- **음성 대화 시스템 (Spoken Dialogue Systems):**

  - BERT 및 GPT-2 기반 모델은 언어 이해(의도 인식, 의미 태깅), 턴 예측, 대화 생성 등에서 기존 RNN/CNN 기반 모델을 능가했습니다.
  - GODEL, InstructGPT (ChatGPT의 신경망 아키텍처)와 같은 대규모 모델은 대화 생성에서 SOTA 성능을 보였습니다.

- **멀티모달 애플리케이션 (Multi-Modal Applications):**
  - MulT (Tsai 외, 2019)와 UNITER (Chen 외, 2020)와 같은 멀티모달 트랜스포머는 여러 양식(음성, 비전, 텍스트)의 정보 통합에서 우수성을 입증하며 분류, 분할, 교차 모달 검색 등의 성능을 향상시켰습니다.

## 🧠 Insights & Discussion

트랜스포머는 음성 처리 분야에서 혁신적인 발전을 가져왔지만, 여전히 여러 도전 과제를 안고 있습니다.

**주요 도전 과제:**

- **훈련 복잡성:** 음성 프레임은 어휘 단위처럼 명확한 의미를 전달하지 않으므로 셀프-어텐션이 적절한 가중치를 계산하기 어렵습니다. 음성 시퀀스는 텍스트 데이터에 비해 정보 밀도가 낮아 긴 시퀀스에 대한 트랜스포머의 훈련은 비용이 많이 들고 복잡합니다.
- **계산 비용 및 효율성:** 트랜스포머의 셀프-어텐션 메커니즘은 시퀀스 길이에 대해 이차적인(quadratic) 계산 복잡성을 가지며, 이는 긴 시퀀스에 대한 확장성을 제한하고 높은 메모리 소비와 추론 시간을 야기합니다.
- **대규모 데이터 요구 사항:** 트랜스포머 기반 음성 모델은 효과적인 훈련을 위해 엄청난 양의 데이터가 필요하며, 이는 텍스트 데이터에 비해 음성 데이터의 가용성이 더 제한적이라는 점에서 문제가 됩니다.
- **일반화 및 전이 가능성:** 순수 트랜스포머는 귀납적 편향(inductive bias)이 부족하여 대규모 훈련 데이터에 크게 의존하며, 훈련 데이터 품질이 나쁘거나 새로운 도메인/시나리오에 대한 일반화 능력이 떨어질 수 있습니다. 도메인 간 격차로 인해 멀티모달 및 다국어 환경에서 전이 학습에 어려움이 있습니다.
- **멀티모달 훈련:** 여러 양식 간의 정보 융합(초기, 중간, 후기 융합)과 본질적인 동기화 문제(예: 오디오-시각적 일치)를 효과적으로 다루는 것이 여전히 어렵습니다.
- **견고성:** 트랜스포머는 도메인 변화와 음성 데이터의 노이즈에 민감하며, 단일 언어 데이터로 훈련 시 다른 언어에 잘 일반화되지 않을 수 있습니다. 명시적인 운율(prosody) 정보 부족도 성능 저하를 야기합니다.

**잠재적 해결책 및 미래 연구 방향:**

- **훈련 개선:** 컨볼루션과 같은 전처리 메커니즘을 사용하여 의미 있는 음성 프레임 청크를 형성하거나, 시간 제한 셀프-어텐션, 다운샘플링, 서브샘플링, 풀링 등의 기법으로 긴 시퀀스 문제를 해결합니다. 향상된 위치 인코딩 방법론을 탐구합니다.
- **효율성 증대:** 희소 어텐션 패턴, 저랭크 분해, 지식 증류, 모델 압축 및 가지치기 등의 기법을 통해 계산 복잡성을 줄이고 모델 효율성을 향상시킵니다.
- **데이터 제약 완화:** 대규모 다국어 및 멀티태스크 오디오 데이터셋 수집, 피치 쉬프팅, 시간 스트레칭, SpecAugment와 같은 데이터 증강 기술 활용, 자기 지도 사전 훈련 모델을 통한 전이 학습, 멀티태스크 학습을 통한 효율성 개선이 중요합니다.
- **일반화 및 전이 가능성 강화:** 베이지안 프레임워크(예: BTLM), 압축 기법, Parallel Scheduled Sampling (PSS), Relative Positional Embedding (RPE) 등을 사용하여 새로운 도메인에 대한 일반화 능력을 향상시킵니다. 대조 학습, 자기 훈련, 준지도 학습을 통해 견고하고 다국어적인 음성 표현을 학습하고, 오디오-비주얼 ASR과 같은 멀티모달 접근 방식을 활용합니다.
- **멀티모달 훈련 심화:** 양식 간 상호작용 및 융합에 대한 추가 탐색, 웹 데이터와 대조 학습을 활용한 정렬 모델 개발, 지역 수준 정렬 등을 통해 멀티모달 트랜스포머의 성능을 향상시킵니다.
- **견고성 증대:** 자기 지도 대조 학습을 통해 견고하고 다국어적인 음성 표현을 학습하고, 다국어 음운 어휘를 활용하여 언어 간 전이 학습을 가능하게 합니다. 오디오-비주얼 ASR 및 다중 작업 학습(화자 인식 및 ASR 동시 학습)을 통해 노이즈 및 화자 변동성에 대한 견고성을 향상시킵니다.
- **윤리적 고려:** 프라이버시, 편향, 공정성과 같은 윤리적 문제들을 트랜스포머 기반 음성 처리 시스템 개발 및 배포 시 반드시 고려해야 합니다.
- **벤치마크 개선:** 음성 대화 시스템에서 더 명확한 SOTA 이해를 위해 NLP의 GLUE와 같은 비교 벤치마크가 필요합니다.

## 📌 TL;DR

음성 처리 분야에서 트랜스포머의 채택이 급증하고 있지만, 이 기술의 포괄적인 개요와 도전 과제, 해결책에 대한 통일된 이해가 부족했습니다. 이 설문 논문은 ASR, TTS, ST, 음성 파라언어학, SE&S, SDS, 멀티모달 애플리케이션 등 다양한 음성 관련 하위 분야에서 트랜스포머 모델의 적용 사례를 처음으로 심층적으로 분석합니다. 주요 발견으로는 트랜스포머가 긴 시퀀스 의존성 처리 및 병렬화 능력 덕분에 RNN 기반 모델을 능가하는 경쟁력 있는 성능을 제공한다는 점입니다. wav2vec, Whisper, VALL-E, Conformer와 같은 모델들은 해당 분야에서 SOTA 결과를 달성했습니다. 그러나 긴 시퀀스 훈련의 복잡성, 높은 계산 비용, 대규모 데이터 요구 사항, 새로운 도메인 및 언어에 대한 일반화 및 전이 능력 부족, 멀티모달 훈련의 어려움, 노이즈에 대한 견고성 부족 등 중요한 과제들이 남아있습니다. 미래 연구는 희소 어텐션, 지식 증류, 데이터 증강, 자기 지도 사전 훈련 및 멀티모달 학습과 같은 기술을 통해 이러한 한계를 해결하는 데 집중해야 합니다.
