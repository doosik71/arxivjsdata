# Very Deep Self-Attention Networks for End-to-End Speech Recognition

Ngoc-Quan Pham, Thai-Son Nguyen, Jan Niehues, Markus Müller, Sebastian Stüker, Alex Waibel

## 🧩 Problem to Solve

기존의 종단 간(end-to-end) 음성 인식(ASR) 모델은 장단기 기억 신경망(LSTM)이나 시간 지연 신경망(TDNN)과 같은 순환 또는 컨볼루션 아키텍처를 주로 사용했습니다. 자기 주의(self-attention) 기반의 Transformer 모델이 자연어 처리(NLP) 분야에서 뛰어난 성능을 보였지만, ASR에 적용했을 때는 만족스러운 결과를 얻지 못했습니다. 이 연구는 Transformer 아키텍처를 ASR에 효과적으로 적용하여 기존 종단 간 방식의 성능을 뛰어넘고 전통적인 하이브리드 시스템과 경쟁할 수 있는 수준에 도달하는 것을 목표로 합니다. 특히, 깊은 네트워크가 ASR 성능 향상에 중요한 역할을 할 수 있는지 탐구합니다.

## ✨ Key Contributions

- **깊이의 중요성 입증:** Transformer 기반 종단 간 ASR 모델에서 깊이가 경쟁력 있는 성능을 달성하는 데 중요한 요소임을 보여주었습니다.
- **확률적 잔차 연결(Stochastic Residual Connections) 제안:** 매우 깊은 Transformer 네트워크의 훈련을 용이하게 하고 일반화 성능을 크게 향상시키기 위해 확률적 잔차 연결(Stochastic Depth) 변형을 도입했습니다.
- **최고 성능 달성:** 제안된 방법론(최대 48개 Transformer 레이어 사용)을 통해 Switchboard 벤치마크에서 기존 모든 종단 간 ASR 접근 방식 중 최고 성능을 달성했습니다.
- **하이브리드 시스템과의 경쟁력:** 앙상블 모델이 특정 하이브리드 시스템보다 뛰어난 성능을 보여, 복잡한 구조와 훈련 절차 없이도 Transformer가 경쟁력을 가질 수 있음을 입증했습니다.
- **인코더 깊이의 효과:** 디코더보다 인코더의 깊이가 ASR 성능에 더 중요한 요소임을 발견했습니다.

## 📎 Related Works

- **전통적인 하이브리드 ASR 시스템:** 음향 모델과 언어 모델을 분리하여 훈련한 후 디코딩 시 결합하는 방식.
- **이전 종단 간 S2S ASR 모델:** LSTM [1, 2] 또는 TDNN [4] 기반으로 시퀀스 수준 표현을 학습했습니다.
- **Transformer 및 자기 주의:** NLP 분야에서 뛰어난 성능을 보인 Vaswani et al. [7]의 "Attention Is All You Need" 논문에서 제안된 모델로, 이미지 [5] 및 음향 신호 [6]에도 적용되었습니다.
- **ASR 분야의 자기 주의 초기 탐색:** Sperber et al. [6]은 인코더에 자기 주의를 사용했지만 LSTM과 결합했을 때만 미미한 개선을 보였고, Dong et al. [9]은 Transformer를 사용했음에도 눈에 띄는 성능 향상을 발견하지 못했습니다.
- **확률적 깊이 네트워크:** Huang et al. [10]이 이미지 분류를 위해 제안한 Stochastic Residual Network에서 영감을 받아 Transformer에 적용되었습니다.
- **데이터 증강 기법:** 음성 인식 성능 향상을 위해 Ko et al. [18] 등에서 사용된 오디오 증강(예: Speed Perturbation) 기법이 참조되었습니다.

## 🛠️ Methodology

이 연구는 인코더와 디코더 모두에 순환 또는 컨볼루션 계층 없이 자기 주의 메커니즘만을 사용하는 Transformer 아키텍처를 제안합니다.

1. **모델 아키텍처:**

   - **인코더-디코더:** Transformer의 표준 인코더-디코더 구조를 따르며, 각 계층은 자기 주의 서브 계층과 피드포워드 신경망으로 구성됩니다.
   - **입력 처리:** 긴 음성 발화에 적응하기 위해 연속적인 프레임을 하나의 단계로 그룹화하고, 이를 사인파 위치 인코딩(sinusoidal positional encoding) [7]과 결합합니다. 이때, 음향 특성과 위치 인코딩을 직접 더하는 대신, 결합된 특성을 더 높은 차원(512)으로 투영한 후 더합니다.
   - **잔차 연결 및 계층 정규화:** 모든 서브 모듈 앞에 잔차 연결(residual connections)을 포함하고, 각 잔차 연결 뒤에 계층 정규화(layer normalization) [13]를 적용합니다.
   - **디코더:** 오토회귀(auto-regressive) 특성을 유지하기 위해 디코더의 자기 주의 계층은 마스킹되어 과거 상태에만 접근할 수 있습니다. 또한, 자기 주의 계층과 피드포워드 계층 사이에 인코더 출력을 활용하는 추가 어텐션 계층이 포함됩니다.

2. **확률적 계층(Stochastic Layers):**

   - 매우 깊은 네트워크의 과적합 및 훈련 어려움을 해결하기 위해 확률적 잔차 연결을 도입합니다.
   - 훈련 중에는 각 잔차 계층의 내부 함수 $F$가 마스크 $M$에 의해 무작위로 활성화되거나 건너뛰어집니다.
   - $$R(x) = \text{LayerNorm}(M \ast F(x) \ast \frac{1}{1-p_l} + x)$$
     - $M$은 Bernoulli 분포에서 샘플링되며, 0 또는 1 값을 가집니다.
     - $p_l$은 계층 드롭 확률로, 계층 깊이 $l$에 따라 선형적으로 스케일링됩니다: $p_l = \frac{l}{L}(1-p)$. 여기서 $L$은 전체 계층 수, $p$는 전역 드롭 파라미터입니다. 낮은 계층일수록 $p_l$이 낮아져 드롭될 확률이 적습니다.
     - 훈련 시 계층이 건너뛰지 않을 때, 출력은 $\frac{1}{1-p_l}$로 스케일링되어 테스트 시 전체 네트워크가 사용될 때의 출력과 일관성을 유지합니다.

3. **실험 설정:**
   - **데이터:** Switchboard-1 Release 2 (300시간) 및 Hub5'00 (테스트셋), TED-LIUM 3.
   - **특징:** 40 log mel filter-bank 특징, 4개 연속 프레임 스태킹으로 입력 시퀀스 길이 4배 감소.
   - **훈련:** Adam 옵티마이저 [20]와 적응형 학습률 스케줄링 (Equation 6), 초기 학습률 2, 웜업 8000 스텝. 드롭아웃(0.2), 문자 드롭아웃(p=0.1), 레이블 스무딩($\epsilon=0.1$) 적용.

## 📊 Results

- **깊이의 효과:** 계층 수가 4개에서 24개로 증가함에 따라 WER이 20.8%에서 12.1%로 크게 감소했습니다. 12개에서 24개 사이에서는 성능 향상이 덜했지만, 이는 과적합의 징후로 해석되었습니다.
- **확률적 계층의 효과:** 24개 계층 설정에서 확률적 계층을 추가했을 때 WER이 SWB 테스트셋에서 12.1%에서 11.7%로, CallHome(CH) 테스트셋에서 23.0%에서 21.5%로 크게 향상되어 일반화 능력이 개선됨을 확인했습니다.
- **인코더-디코더 깊이 분할:** 인코더를 더 깊게 (예: 36개 인코더, 12개 디코더 레이어) 구성했을 때 더 좋은 성능을 보였습니다. 36Enc-12Dec 모델(확률적 계층 및 스피드 섭동 포함)은 SWB에서 10.4%, CH에서 18.6% WER을 달성했습니다.
- **최고 성능 (앙상블):** 여러 모델의 앙상블은 SWB에서 9.9% WER, CH에서 17.7% WER을 달성하여, 기존 하이브리드 시스템과 경쟁하거나 일부를 능가하는 수준을 보여주었습니다.
- **TED-LIUM 데이터셋:** TED-LIUM 3 데이터셋에서도 36Enc-12Dec 모델이 강력한 베이스라인(외부 언어 모델 및 스피드 섭동 사용)을 능가하는 10.6% WER을 달성했습니다.

## 🧠 Insights & Discussion

- **Transformer의 ASR 적용 가능성:** 이 연구는 자기 주의만을 사용하는 Transformer 아키텍처가 적절한 깊이와 정규화 기법(확률적 계층)을 통해 ASR 작업에서 매우 효과적일 수 있음을 최초로 입증했습니다.
- **깊이의 중요성:** 이전 연구들과 달리, Transformer에서 깊이가 ASR 성능을 결정하는 핵심 요소임을 명확히 보여주었습니다. 이는 모델이 더 복잡한 음향 표현을 학습할 수 있게 하기 때문입니다.
- **확률적 깊이의 역할:** 확률적 잔차 연결은 과적합을 방지하고 깊은 네트워크의 일반화 능력을 향상시키는 데 결정적인 역할을 했습니다.
- **인코더의 중요성:** 음향 특징을 학습하는 인코더가 문자 시퀀스 생성을 담당하는 디코더보다 더 깊은 네트워크를 요구한다는 점은 모달리티(음성 vs. 텍스트)의 차이를 반영하며, 음향 모델링의 복잡성을 시사합니다.
- **하이브리드 시스템과의 경쟁력:** 복잡한 구조와 훈련 절차가 필요한 하이브리드 시스템에 비해, 종단 간 Transformer 모델이 더 단순한 방식으로도 경쟁력 있는 성능을 달성할 수 있음을 보여주었습니다.
- **한계 및 향후 연구:** 현재 모델은 실시간 인식, 지연 시간, 스트리밍과 같은 더 현실적이고 도전적인 조건에서 최적화되지 않았으므로, 이러한 측면에서의 프레임워크 개발이 향후 연구 과제입니다.

## 📌 TL;DR

이 논문은 종단 간 음성 인식(ASR)을 위해 순환 또는 컨볼루션 계층 없이 자기 주의(self-attention) 기반의 매우 깊은 Transformer 네트워크를 제안합니다. 깊이가 ASR 성능에 중요함을 입증하고, 과적합 방지 및 일반화 능력 향상을 위해 확률적 잔차 연결(stochastic residual connections)을 도입했습니다. 결과적으로, 이 모델은 Switchboard 벤치마크에서 기존 종단 간 ASR 모델 중 최고 성능을 달성했으며, 복잡한 하이브리드 시스템과도 경쟁할 수 있는 수준의 WER(9.9%)을 보였습니다. 특히, 인코더를 더 깊게 구성하는 것이 효과적임이 밝혀져, 자기 주의만을 사용하는 ASR 모델의 잠재력을 입증했습니다.
