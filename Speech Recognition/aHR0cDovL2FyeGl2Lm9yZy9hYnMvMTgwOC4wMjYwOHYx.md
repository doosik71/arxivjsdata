# END-TO-END SPEECH RECOGNITION WITH WORD-BASED RNN LANGUAGE MODELS

Takaaki Hori, Jaejin Cho, Shinji Watanabe

## 🧩 Problem to Solve

기존의 종단간(end-to-end) 자동 음성 인식(ASR) 시스템에서 문자 기반(character-based) 및 단어 기반(word-based) 순환 신경망 언어 모델(RNN-LM)을 결합한 다단계(multi-level) LM은 인식 정확도 향상에 큰 기여를 했습니다. 그러나 이 방식은 두 개의 다른 LM을 학습하고 디코딩에 사용해야 하므로, 훈련 및 디코딩 과정에서 상당한 계산 비용과 메모리 사용량 증가를 초래합니다. 본 논문은 이러한 오버헤드를 줄이면서도 인식 성능을 유지하거나 개선하는 방법을 모색합니다. 특히 영어와 같이 음소 문자 체계를 사용하는 언어에서는 문자 기반 LM이 단어 기반 LM에 비해 성능이 떨어지는 경향이 있습니다.

## ✨ Key Contributions

- 종단간 ASR을 위한 **새로운 단어 기반 RNN-LM**을 제안하며, 예측에 "look-ahead" 메커니즘을 포함합니다.
- **단일 단어 기반 LM만으로 디코딩**할 수 있도록 하여, 별도의 문자 기반 LM이 필요 없어 시스템 복잡성, 학습 시간, 디코딩 시 계산 비용 및 메모리 사용량을 절감합니다.
- 다단계 LM에 비해 **경쟁력 있는(또는 더 높은) 정확도**를 달성하면서도 더 적은 계산 비용을 요구합니다.
- WSJ(Wall Street Journal) 외에 **더 큰 코퍼스인 LibriSpeech에서도 제안된 방법의 효과**를 입증했습니다.
- WSJ Eval'92 테스트 세트에서 어휘 크기를 늘렸을 때 **5.1%의 WER(Word Error Rate)을 달성**하여, 해당 벤치마크에서 종단간 ASR 시스템 중 당시 **최고 성능**을 기록했습니다.
- 단어 기반 RNN-LM을 사용하여 종단간 ASR에서 **look-ahead 확률을 동적으로 효율적으로 계산하는 방법**을 제공합니다.

## 📎 Related Works

- **저자들의 이전 연구 (다단계 LM):** 문자 및 단어 수준 LM을 결합하여 개방형 어휘(open-vocabulary) 종단간 ASR의 정확도를 향상시켰습니다 [11]. 본 논문은 이 연구의 한계점(높은 계산 비용)을 해결하고자 합니다.
- **일반적인 종단간 ASR 아키텍처:** CTC (Connectionist Temporal Classification) [3], RNN 트랜스듀서 [4], 어텐션 기반 인코더-디코더 [5] 및 이들의 하이브리드 모델 [6, 7].
- **외부 LM 통합 (Shallow Fusion):** 디코딩 시 로그 확률 도메인에서 외부 LM과 디코더 네트워크를 결합하여 정확도를 향상시키는 접근 방식 [9, 10].
- **Acoustic-to-Word CTC:** 음향 특징 시퀀스를 단어 시퀀스로 직접 매핑하는 방식 [20, 21, 22]. 이는 대량의 음향-텍스트 병렬 데이터가 필요하며, 본 논문의 접근 방식은 병렬 데이터가 제한적인 저자원 언어에 더 적합합니다.
- **Subword 단위:** 바이트-페어 인코딩(BPE) 등으로 자동 추출된 서브워드 단위를 사용하는 방식 [23, 24]. 본 논문의 접근 방식은 문자 및 단어 단위를 기본으로 하지만, 서브워드 기반 LM과의 결합 가능성도 언급합니다.
- **기존 ASR의 LM Look-ahead:** 접두사 트리 검색에 LM look-ahead 메커니즘을 포함하는 전통적인 ASR 시스템 [12, 13]과 유사한 개념을 사용하지만, RNN-LM에 대한 동적 look-ahead 확률 계산 방식이 다릅니다.

## 🛠️ Methodology

1. **기반 ASR 아키텍처:**
   - **하이브리드 CTC/어텐션 네트워크** [6, 7]를 사용합니다.
   - **인코더:** VGG net 아키텍처 [14] 기반의 딥 CNN 층과 BLSTM (Bidirectional Long Short-Term Memory) 층으로 구성됩니다. 입력 음성 특징 $X = x_1, ..., x_T$를 받아 은닉 벡터 $H = h_1, ..., h_{T'}$를 출력합니다.
   - **디코더:** CTC 네트워크, 어텐션 디코더 네트워크, RNN-LM이 결합되어 다음 레이블 $c_l$을 예측합니다. 출력 레이블은 기본적으로 문자 단위입니다.
   - **공동 학습:** CTC와 어텐션 모델의 목적 함수를 로그 선형 결합하여 최대화합니다:
     $$L_{MTL} = \lambda \log p_{ctc}(C|X) + (1-\lambda) \log p_{att}(C|X)$$
     여기서 $\lambda$는 조절 가능한 파라미터입니다.
2. **외부 LM을 사용한 디코딩:**
   - 빔 탐색(beam search)을 통해 가장 확률 높은 문자 시퀀스 $\hat{C}$를 찾습니다. LM 확률 $p_{lm}(C)$는 스케일링 인자 $\gamma$와 함께 CTC/어텐션 확률에 추가됩니다:
     $$\hat{C} = \arg \max_{C \in U^*} \{\lambda \log p_{ctc}(C|X) + (1-\lambda) \log p_{att}(C|X) + \gamma \log p_{lm}(C)\}$$
   - 부분 가설 $h$의 점수 $\alpha(h)$는 다음과 같이 계산됩니다: $\alpha(h) = \lambda\alpha_{ctc}(h) + (1-\lambda)\alpha_{att}(h) + \gamma\alpha_{lm}(h)$.
3. **단어 기반 LM 통합 (기본 접근 방식):**
   - 문자 기반 시스템이 단어 사이의 공백(space) 문자를 예측하도록 하여, 문자 시퀀스를 단어 시퀀스로 결정론적으로 매핑할 수 있게 합니다.
   - 디코더가 공백 문자를 가설로 세울 때만 단어 수준 RNN-LM을 사용하여 마지막 단어의 확률을 계산하고 가설 점수에 누적합니다.
4. **다단계 RNN-LM (비교 대상, 이전 연구):**
   - 문자 수준 LM과 단어 수준 LM을 포함합니다.
   - 조건부 문자 확률 $p_{lm}(c|g)$는 다음 조건에 따라 결정됩니다:
     - 단어의 끝($c \in S$)이고 단어가 어휘에 있는 경우($w_g \in V$): $p_{wlm}(w_g|\psi_g) / p_{clm}(w_g|\psi_g)$. 분모 $p_{clm}(w_g|\psi_g)$는 $w_g$에 대해 누적된 문자 수준 LM 확률을 상쇄합니다.
     - 단어의 끝($c \in S$)이고 단어가 OOV($w_g \notin V$)인 경우: $p_{wlm}(<UNK>|\psi_g) \tilde{\beta}$.
     - 그 외 (단어 내): $p_{clm}(c|g)$.
   - 두 개의 서로 다른 LM을 학습하고 사용해야 합니다.
5. **제안된 Look-ahead 단어 기반 RNN-LM:**
   - **오직 단일 단어 기반 RNN-LM**만을 사용합니다.
   - **접두사 트리 (Prefix Tree):** 어휘를 접두사 트리로 표현하여 look-ahead 확률을 효율적으로 계산합니다.
   - **Look-ahead 확률 $p_{la}(n|\psi)$:** 특정 노드 $n$에서 가능한 모든 예상 단어들의 확률 합계로, 단어 수준 컨텍스트 $\psi$가 주어졌을 때 계산됩니다:
     $$p_{la}(n|\psi) = \sum_{w \in wset(n)} p_{wlm}(w|\psi)$$
   - **Look-ahead를 사용한 문자 LM 확률:** $p_{lm}(c|g)$는 $p_{la}$를 이용하여 다음과 같이 계산됩니다:
     - 단어 끝 노드($n_g \in F$)이고 $c \in S$인 경우: $p_{wlm}(w_g|\psi_g) / p_{la}(n_g|\psi_g)$.
     - 트리 내에서 전이($n_g \neq null, c \in \xi(n_g)$)하는 경우: $p_{la}(n_{g \cdot c}|\psi_g) / p_{la}(n_g|\psi_g)$.
     - 문자 $c$가 허용되지 않아 OOV로 가는 경우($n_g \neq null, c \notin \xi(n_g)$): $p_{wlm}(<UNK>|\psi_g)\eta$.
     - 그 외 (트리에서 벗어난 경우): 1.
   - **효율적인 Look-ahead 계산:** 어휘 내 단어 ID가 알파벳순으로 부여되어 누적 합계 배열 $s_{\psi}[\cdot]$을 사용하여 $p_{la}(n|\psi) = s_{\psi}[\text{maxid}(n)] - s_{\psi}[\text{minid}(n)-1]$로 빠르게 계산합니다.

## 📊 Results

- **WSJ (Wall Street Journal) 태스크:**
  - **WER:** eval92 테스트 세트에서 no LM (13.4%), character LM (7.7%), multi-level LM (20K 어휘, 5.6%)에 비해, 제안된 look-ahead LM은 어휘 크기가 65K로 증가했을 때 **5.1%의 WER**을 달성하며 다단계 LM을 능가했습니다. 이는 당시 종단간 ASR 시스템 중 최고 성능입니다. 초기 20K 어휘에서는 OOV 단어로 인해 6.1%로 약간 높은 WER을 보였습니다.
  - **디코딩 시간:** Look-ahead LM(65K)은 LM이 없는 경우의 55%의 디코딩 시간만을 필요로 했으며, 이는 다단계 LM(20K)의 65%보다 빨랐습니다. 제안된 방법이 더 빠르고 효율적임을 보여줍니다.
- **LibriSpeech 태스크 (대규모 코퍼스):**
  - WSJ 결과와 일관되게, look-ahead LM(65K)은 다단계 LM(65K)과 경쟁력 있는 WER을 보여주었습니다 (예: `dev clean`에서 모두 5.4%).
  - 대규모 코퍼스에서도 속도 이점과 문자 LM 학습 제외 이점을 유지했습니다.

## 🧠 Insights & Discussion

- 초기 20K 어휘에서 look-ahead LM의 성능 저하는 OOV(Out-Of-Vocabulary) 단어 처리의 중요성을 보여주며, 어휘 크기 증가를 통해 이러한 문제가 성공적으로 완화되었습니다.
- 더 큰 어휘와 결합된 look-ahead 메커니즘은 단어 LM 확률과 일관된 더 나은 문자 수준 LM 점수를 제공하여 빔 탐색 과정에 도움을 줍니다.
- 본 연구는 단일 단어 기반 LM만을 요구함으로써 시스템의 **복잡성을 크게 줄이고**, LM 학습 및 디코딩 과정에서의 **계산 비용과 메모리 사용량을 절감**하는 데 성공했습니다.
- WSJ 벤치마크에서 종단간 ASR의 새로운 최고 WER을 달성함으로써 제안된 접근 방식의 효과성과 잠재력을 입증했습니다.
- 문자 또는 서브워드 기반 인코더-디코더와 외부 RNN-LM을 사용하는 설계는 병렬 음향-텍스트 데이터가 제한적이지만 대규모 텍스트 데이터는 풍부한 **저자원 언어**에 특히 적합합니다.
- 제안된 look-ahead 확률의 효율적인 계산은 어휘의 특정 구조(알파벳순 ID 할당)에 의존한다는 제한이 있습니다.

## 📌 TL;DR

- **문제:** 종단간 음성 인식(ASR)에서 문자 및 단어 기반 RNN 언어 모델(LM)을 결합한 기존 다단계 LM은 정확도 향상에 기여하지만, 두 개의 LM 학습 및 디코딩으로 인한 높은 계산 비용과 메모리 사용량 문제가 있었습니다.
- **방법:** 이 문제를 해결하기 위해, 단일 단어 기반 RNN-LM만을 사용하여 디코딩하는 새로운 "look-ahead" 메커니즘을 제안합니다. 이는 접두사 트리(prefix tree)를 활용하여 다음 문자를 예측할 때 미리 단어 확률을 계산함으로써 문자 기반 LM을 대체합니다.
- **결과:** 제안된 방법은 Wall Street Journal (WSJ) 및 LibriSpeech 데이터셋에서 다단계 LM과 동등하거나 더 나은 WER을 달성했으며, 특히 WSJ Eval'92에서는 5.1% WER로 당시 종단간 ASR 시스템 중 최고 성능을 기록했습니다. 또한 디코딩 시간을 단축하고 문자 기반 LM 학습 과정을 완전히 제거하여 시스템의 효율성과 간결성을 크게 향상시켰습니다.
