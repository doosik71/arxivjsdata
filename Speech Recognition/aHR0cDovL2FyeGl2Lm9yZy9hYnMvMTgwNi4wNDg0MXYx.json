{
  "url": "http://arxiv.org/abs/1806.04841v1",
  "title": "A Study of Enhancement, Augmentation, and Autoencoder Methods for Domain\n  Adaptation in Distant Speech Recognition",
  "authors": "Hao Tang, Wei-Ning Hsu, Francois Grondin, James Glass",
  "year": 2018,
  "abstract": "Speech recognizers trained on close-talking speech do not generalize to\ndistant speech and the word error rate degradation can be as large as 40%\nabsolute. Most studies focus on tackling distant speech recognition as a\nseparate problem, leaving little effort to adapting close-talking speech\nrecognizers to distant speech. In this work, we review several approaches from\na domain adaptation perspective. These approaches, including speech\nenhancement, multi-condition training, data augmentation, and autoencoders, all\ninvolve a transformation of the data between domains. We conduct experiments on\nthe AMI data set, where these approaches can be realized under the same\ncontrolled setting. These approaches lead to different amounts of improvement\nunder their respective assumptions. The purpose of this paper is to quantify\nand characterize the performance gap between the two domains, setting up the\nbasis for studying adaptation of speech recognizers from close-talking speech\nto distant speech. Our results also have implications for improving distant\nspeech recognition."
}