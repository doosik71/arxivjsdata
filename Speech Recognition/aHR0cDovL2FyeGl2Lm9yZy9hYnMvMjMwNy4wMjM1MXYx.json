{
  "title": "Online Hybrid CTC/Attention End-to-End Automatic Speech Recognition\n  Architecture",
  "authors": "Haoran Miao, Gaofeng Cheng, Pengyuan Zhang, Yonghong Yan",
  "year": 2023,
  "url": "http://arxiv.org/abs/2307.02351v1",
  "abstract": "Recently, there has been increasing progress in end-to-end automatic speech\nrecognition (ASR) architecture, which transcribes speech to text without any\npre-trained alignments. One popular end-to-end approach is the hybrid\nConnectionist Temporal Classification (CTC) and attention (CTC/attention) based\nASR architecture. However, how to deploy hybrid CTC/attention systems for\nonline speech recognition is still a non-trivial problem. This article\ndescribes our proposed online hybrid CTC/attention end-to-end ASR architecture,\nwhich replaces all the offline components of conventional CTC/attention ASR\narchitecture with their corresponding streaming components. Firstly, we propose\nstable monotonic chunk-wise attention (sMoChA) to stream the conventional\nglobal attention, and further propose monotonic truncated attention (MTA) to\nsimplify sMoChA and solve the training-and-decoding mismatch problem of sMoChA.\nSecondly, we propose truncated CTC (T-CTC) prefix score to stream CTC prefix\nscore calculation. Thirdly, we design dynamic waiting joint decoding (DWJD)\nalgorithm to dynamically collect the predictions of CTC and attention in an\nonline manner. Finally, we use latency-controlled bidirectional long short-term\nmemory (LC-BLSTM) to stream the widely-used offline bidirectional encoder\nnetwork. Experiments with LibriSpeech English and HKUST Mandarin tasks\ndemonstrate that, compared with the offline CTC/attention model, our proposed\nonline CTC/attention model improves the real time factor in human-computer\ninteraction services and maintains its performance with moderate degradation.\nTo the best of our knowledge, this is the first work to provide the full-stack\nonline solution for CTC/attention end-to-end ASR architecture.",
  "citation": 65
}