# JOINT CTC-ATTENTION BASED END-TO-END SPEECH RECOGNITION USING MULTI-TASK LEARNING

Suyoun Kim, Takaaki Hori, and Shinji Watanabe

## 🧩 Problem to Solve

기존의 종단 간 (end-to-end) 음성 인식 모델인 Connectionist Temporal Classification (CTC)과 어텐션 기반 (attention-based) 인코더-디코더 모델은 각각의 한계를 가지고 있습니다.

- **CTC**: 타겟 레이블 간의 조건부 독립성을 가정하여, 음성 시퀀스의 각 프레임에 대해 레이블을 예측합니다. 이는 문자 수준의 언어 정보를 모델링하는 데 제약이 있습니다.
- **어텐션 기반 모델**: 조건부 독립성 가정을 사용하지 않아 CTC보다 문자 오류율(CER)이 개선되는 경우가 많지만, 잡음이 많은 환경에서 성능이 저하되며, 긴 입력 시퀀스에서는 초기 학습 단계에서 정렬(alignment)을 학습하기 어렵습니다. 이는 CTC와 같은 왼쪽-오른쪽 제약(left-to-right constraint)이 부족하여 어텐션 모델이 너무 유연해지기 때문입니다. 이로 인해 수동으로 윈도잉(windowing) 기법을 사용하여 어텐션 범위를 제한해야 하는 문제가 있습니다.

본 연구는 이러한 어텐션 모델의 정렬 문제를 해결하고, 강건성(robustness)을 개선하며, 학습 속도를 높이는 새로운 종단 간 음성 인식 방법을 제안하는 것을 목표로 합니다.

## ✨ Key Contributions

- **다중 작업 학습(Multi-task Learning) 프레임워크 내에서 조인트 CTC-어텐션 모델 제안**: CTC 손실 함수를 보조 작업으로 사용하여 어텐션 모델의 인코더를 학습시키는 새로운 방법을 제시합니다.
- **정렬 문제 해결 및 강건성 향상**: CTC의 단조로운 정렬(monotonic alignment) 특성을 활용하여 어텐션 모델의 정렬 문제를 완화하고, 잡음 조건에서의 성능을 개선합니다.
- **빠른 수렴 및 학습 속도 달성**: CTC가 보조 작업으로 포함되어 인코더가 적절한 정렬을 더 빠르게 학습할 수 있도록 유도함으로써, 초기 학습 단계에서의 수렴 속도를 크게 향상시킵니다. 이로 인해 수동으로 정렬 범위를 제한하는 윈도잉 기법의 필요성을 줄입니다.
- **최첨단 성능 달성**: WSJ (깨끗한 음성) 및 CHiME-4 (잡음이 많은 음성) 태스크에서 기존 CTC 및 어텐션 기반 모델보다 5.4-14.6%의 상대적인 문자 오류율(CER) 개선을 보여주었습니다.

## 📎 Related Works

- **Connectionist Temporal Classification (CTC)**: 비분할(unsegmented) 시퀀스 데이터에 레이블을 부여하기 위한 RNN 기반 방법 [12].
- **Attention-based Encoder-Decoder**: 가변 길이 입력 및 출력 시퀀스 매핑을 학습하는 모델로, 특히 신경망 기계 번역에서 처음 제안되었으며 [13], 이후 음성 인식에 적용됨 [4, 5, 6, 7].
- **Traditional Hybrid Approaches (DNN-HMM)**: 음향 모델, 발음 모델, 언어 모델 등을 개별적으로 학습하는 기존의 음성 인식 시스템 [10, 11].

## 🛠️ Methodology

본 논문은 다중 작업 학습(Multi-task Learning, MTL) 프레임워크 내에서 CTC 손실 함수를 보조 작업으로 활용하여 어텐션 모델의 인코더를 훈련하는 **조인트 CTC-어텐션 모델**을 제안합니다.

1. **공유 인코더 (Shared Encoder)**:

   - 입력 음성 시퀀스 $x$를 고수준 특징 표현 $h = (h_1, \dots, h_L)$로 변환합니다.
   - 인코더는 4계층 Bidirectional Long Short-Term Memory (BLSTM) 네트워크로 구성되며, 각 계층 및 방향당 320개의 셀을 가집니다.
   - 인코더의 상위 두 계층은 아래 계층의 매 두 번째 은닉 상태를 읽어 발화 길이를 4배 줄입니다 ($L=T/4$).

2. **어텐션 디코더 (Attention Decoder)**:

   - 공유 인코더에서 생성된 특징 $h$와 이전에 생성된 문자 시퀀스 $y_{1:u-1}$에 따라 각 출력 문자 $y_u$의 확률 분포를 생성합니다.
   - 디코더는 1계층 LSTM (320개 셀)으로 구성됩니다.
   - 어텐션 메커니즘은 '위치 기반(location-based)' 어텐션을 사용하며, 이전 어텐션 $a_{u-1}$에서 컨볼루션 특징 $f_{u,l}$을 추출합니다 (10개의 중심 컨볼루션 필터, 폭 100).
   - 샤프닝 팩터(sharpening factor) $\gamma=2$를 사용합니다.

3. **다중 작업 학습 목적 함수 (Multi-task Learning Objective Function)**:

   - CTC 손실($L_{CTC}$)과 어텐션 손실($L_{Attention}$)을 동시에 최소화하도록 모델을 훈련합니다.
   - 최종 목적 함수는 다음과 같습니다:
     $$L_{MTL} = \lambda L_{CTC} + (1-\lambda)L_{Attention}$$
     여기서 $\lambda$는 0과 1 사이의 튜닝 가능한 가중치 파라미터입니다.
   - $L_{CTC}$는 CTC의 순방향-역방향 알고리즘을 사용하여 단조로운 정렬 제약을 제공함으로써, 공유 인코더가 적절한 정렬을 학습하도록 돕습니다.
   - $L_{Attention}$은 어텐션 모델의 표준 교차 엔트로피 손실입니다.

4. **훈련 및 디코딩**:
   - 최적화에는 AdaDelta 알고리즘과 그레디언트 클리핑(gradient clipping)을 사용합니다.
   - 어텐션 및 MTL 모델의 디코딩은 빔 서치(beam search, 빔 크기 20)와 길이 페널티(length penalty)를 사용합니다.
   - CTC 모델의 디코딩은 가장 가능성 있는 출력 시퀀스를 취합니다.
   - 어떤 실험에서도 외부 언어 모델이나 어휘 정보를 사용하지 않았습니다.

## 📊 Results

- **문자 오류율 (CER) 개선**: 제안된 MTL 모델은 WSJ (깨끗한 음성) 및 CHiME-4 (잡음이 많은 음성) 두 가지 태스크 모두에서 CTC 및 어텐션 기반 모델보다 우수한 성능을 보였습니다.

  - 검증(validation) 세트에서 6.0-8.4%, 평가(evaluation) 세트에서 5.4-14.6%의 상대적 CER 개선을 달성했습니다.
  - 특히, 잡음이 많은 CHiME-4 태스크에서 MTL($\lambda=0.2$)은 CTC와 어텐션 모델을 크게 능가했습니다 (예: CHiME-4 평가 세트에서 CTC 48.79%, Attention(location-based) 47.58% 대비 MTL($\lambda=0.2$) 44.99%).
  - 깨끗한 WSJ 태스크에서도 MTL 모델은 CTC와 어텐션 모델보다 더 나은 결과를 보여주었습니다.
  - 최적의 성능은 $\lambda=0.2$일 때 관찰되었습니다.

- **학습 속도 및 수렴 개선**: MTL 프레임워크는 원하는 정렬을 학습하는 속도를 현저히 가속화했습니다.
  - CTC 손실에 더 큰 가중치($\lambda$ 값 증가)를 부여할수록 네트워크가 더 빠르게 학습하고 조기에 수렴하는 경향을 보였습니다.
  - 정렬 시각화 결과 (그림 3)에 따르면, MTL 모델은 학습 5번째 에포크에서 이미 적절한 정렬을 학습한 반면, 어텐션 모델은 9번째 에포크에서도 적절한 정렬을 학습하지 못했습니다. 이는 CTC 손실이 MTL 접근 방식에서 정렬이 단조롭게 이루어지도록 유도했음을 나타냅니다.

## 🧠 Insights & Discussion

- **CTC의 정렬 유도 역할**: CTC 손실 함수는 어텐션 모델의 인코더가 음성 및 레이블 시퀀스 간의 단조로운 정렬을 학습하도록 효과적으로 안내합니다. 이는 잡음이 많은 환경에서의 강건성을 향상시키고, 긴 시퀀스에 대한 학습 어려움을 완화하는 데 중요한 역할을 합니다.
- **학습 효율성 증가**: MTL 접근 방식은 수동으로 입력 범위를 제한하는 윈도잉 기법 없이도 원하는 정렬을 빠르게 학습하게 하여, 모델 학습의 수렴 속도를 크게 높입니다.
- **예상치 못한 일반화 개선**: 깨끗한 음성 데이터셋(WSJ)에서도 MTL 모델이 성능 개선을 보인 점은 흥미로운 발견입니다. 이는 CTC가 명시적인 문자 간 의존성을 사용하지 않는 훈련 절차 덕분에 일반화 성능을 향상시킬 가능성을 시사합니다. 이 부분은 향후 추가 실험을 통해 검증이 필요합니다.
- **범용성**: 제안된 다중 작업 학습 방식은 음성 인식뿐만 아니라 다른 시퀀스-투-시퀀스 학습 태스크에도 잠재적으로 적용될 수 있습니다.

## 📌 TL;DR

**문제**: 어텐션 기반 종단 간 음성 인식 모델은 잡음 환경이나 긴 시퀀스에서 정렬 문제로 인해 성능이 저하되고 학습이 어렵습니다. 기존 CTC는 문자 간 의존성을 모델링하기 어렵습니다.
**방법**: CTC 손실을 보조 작업으로 활용하는 다중 작업 학습(MTL) 프레임워크 내에서 조인트 CTC-어텐션 모델을 제안합니다. 이는 공유 인코더가 CTC의 단조로운 정렬 제약을 통해 어텐션 모델의 정렬 문제를 완화하도록 돕습니다.
**결과**: 제안된 MTL 모델은 깨끗한 (WSJ) 및 잡음이 많은 (CHiME-4) 환경 모두에서 기존 CTC 및 어텐션 모델 대비 5.4-14.6%의 상대적 CER 개선을 달성했습니다. 또한, 정렬 학습 및 모델 수렴 속도를 현저히 가속화하여 초기 학습 단계에서 빠르고 정확한 정렬을 가능하게 했습니다.
