# SELF-TRAINING FOR END-TO-END SPEECH RECOGNITION

Jacob Kahn, Ann Lee, Awni Hannun

## 🧩 Problem to Solve

자동 음성 인식(ASR) 시스템, 특히 엔드-투-엔드(end-to-end) 모델은 고성능을 달성하기 위해 방대한 양의 전사(transcribed)된 음성 데이터가 필요합니다. 하지만 대량의 오디오를 전사하는 것은 비용이 많이 들고 시간이 소모되는 작업입니다. 이는 데이터가 부족할 때 모델 성능 저하로 이어지며, 기존 하이브리드 모델보다 엔드-투-엔드 모델에서 이러한 성능 저하가 더욱 두드러집니다. 따라서 풍부한 미학습 오디오 및 텍스트 데이터를 활용할 수 있는 효과적인 준지도 학습(semi-supervised learning) 방법이 필요하며, 특히 시퀀스-투-시퀀스(sequence-to-sequence) 모델을 위한 자기 훈련(self-training) 기법에 대한 심층적인 연구가 부족했습니다.

## ✨ Key Contributions

- **자기 훈련의 효과 입증**: 레이블이 없는 대규모 데이터셋을 활용하여 강력한 기준 모델 대비 엔드-투-엔드 ASR 시스템의 정확도를 크게 향상시킬 수 있음을 입증했습니다.
  - 잡음이 있는 음성 환경에서 기준 모델 대비 WER(Word Error Rate)을 33.9% 상대적으로 개선했습니다.
  - 깨끗한 음성 환경에서 기준 모델과 오라클 모델 사이의 성능 격차를 59.3% 회복했습니다. 이는 이전 접근 방식보다 최소 93.8% 더 높은 상대적 개선입니다.
- **오류 맞춤형 필터링 메커니즘**: 시퀀스-투-시퀀스 모델에서 흔히 발생하는 오류(예: 루핑(looping) 및 조기 종료(early stopping))에 맞춰진 휴리스틱(heuristic) 필터링과 신뢰도 기반 필터링 기법을 제안하고 그 효과를 입증했습니다.
- **새로운 앙상블 접근 방식**: 의사 레이블(pseudo-label)의 다양성을 높이고 모델이 잡음이 많은 의사 레이블에 과도하게 확신하지 않도록 하는 새로운 _샘플 앙상블(sample ensemble)_ 방법을 제안했습니다.
- **재현 가능한 벤치마크 제공**: LibriSpeech 코퍼스에 대한 실험을 통해 향후 준지도 학습 ASR 접근 방식을 평가할 수 있는 강력하고 재현 가능한 기준점을 제시했습니다.
- **강력한 베이스라인 및 LM 활용의 중요성**: 고품질 의사 레이블 생성을 위해 강력한 음향 모델(AM)과 대규모 외부 언어 모델(LM)을 사용하는 것이 중요함을 강조했습니다.

## 📎 Related Works

- **ASR 분야의 자기 훈련**: 과거 하이브리드 시스템에서 음향 모델의 준지도 학습에 자기 훈련이 탐구되었으며, 주로 신뢰도 기반 필터링 [4, 5] 및 합의 기반(agreement-based) 선택 [20] 등 의사 레이블 품질 향상을 위한 데이터 필터링 방법에 중점을 두었습니다.
- **엔드-투-엔드 ASR을 위한 최신 준지도 학습**: 텍스트-투-스피치(TTS) 모듈을 사용하여 미학습 텍스트로부터 합성 데이터를 생성하거나 [22], ASR+TTS 파이프라인의 입력과 출력 사이의 순환 일관성 손실(cycle-consistency loss)을 도입하는 방식 [9, 10] 등이 제안되었습니다.
- **시퀀스-투-시퀀스 모델의 디코딩 문제**: 루핑 및 조기 종료와 같은 문제가 잘 알려져 있습니다 [14].
- **사용된 베이스라인 모델**: 시간-깊이 분리(Time-Depth Separable, TDS) 컨볼루션 블록을 사용하는 인코더-디코더 아키텍처 [3]를 기반으로 하여 강력한 베이스라인 성능을 보장했습니다.

## 🛠️ Methodology

1. **베이스라인 모델 훈련**: 작은 양의 레이블링된 데이터 $D = \{(X_1, Y_1), \dots, (X_n, Y_n)\}$를 사용하여 강력한 음향 모델(AM)을 훈련합니다. 이 AM은 어텐션(attention) 메커니즘을 갖춘 인코더-디코더 구조이며, 인코더는 TDS 블록을 활용합니다. 동시에 대규모 텍스트 코퍼스를 사용하여 외부 언어 모델(LM)을 훈련합니다.
2. **의사 레이블 생성**:
   - 미학습 오디오 데이터 $\mathcal{X}$의 각 발화 $X_i$에 대해, 훈련된 AM과 LM을 결합하여 빔 서치(beam search) 디코딩을 수행하여 의사 레이블 $\bar{Y}_i$를 생성합니다. 디코딩 식은 다음과 같습니다.
     $$ \bar{Y} = \underset{Y}{\operatorname{argmax}} \log P*{AM}(Y|X) + \alpha \log P*{LM}(Y) + \beta |Y| $$
   - 조기 종료를 방지하기 위해 EOS(end-of-sentence) 토큰 확률 임계값과 같은 안정적인 디코딩 기술 [3]이 적용됩니다.
3. **의사 레이블 필터링**:
   - **시퀀스-투-시퀀스 모델 특정 휴리스틱 필터**:
     - $c$번 이상 반복되는 $n$-그램을 포함하는 의사 레이블을 제거하여 루핑 오류를 방지합니다.
     - 빔 서치가 완전한 가설을 찾지 못하고 종료되는 예제를 필터링하여 조기 종료 오류를 방지합니다.
   - **신뢰도 기반 필터링**: 각 의사 레이블 $\bar{Y}_i$에 대해 음향 모델의 길이 정규화된 로그 가능도를 신뢰도 점수로 계산합니다:
     $$ \text{ConfidenceScore}(\bar{Y}_i) = \frac{\log P_{AM}(\bar{Y}\_i|X_i)}{|\bar{Y}\_i|} $$
     이후 신뢰도 임계값보다 낮은 의사 레이블을 제거합니다.
4. **앙상블 자기 훈련 (샘플 앙상블)**:
   - $M$개의 부트스트랩된(bootstrapped) AM을 각각 다른 무작위 초기값으로 $D$에서 훈련합니다.
   - 각 모델 $m$은 자체적으로 의사 레이블 데이터셋 $\bar{D}_m$을 생성합니다.
   - 모든 $M$개의 의사 레이블 세트를 균등하게 결합합니다.
   - 훈련 중에는 매 에포크(epoch)마다 $M$개 모델 중 하나에서 의사 레이블을 균등하게 샘플링하여 타겟으로 사용합니다. 학습 목표는 다음과 같습니다:
     $$ \sum*{(X,Y) \in D} \log P(Y|X) + \frac{1}{M} \sum*{m=1}^{M} \sum\_{(X,\bar{Y}) \in \bar{D}\_m} \log P(\bar{Y}|X) $$
5. **최종 모델 훈련**: 레이블링된 데이터 $D$와 필터링된 의사 레이블 데이터셋 $\bar{D}$ (또는 앙상블의 경우 $\bigcup_{m=1}^M \bar{D}_m$)를 결합하여 새로운 음향 모델을 훈련합니다. 이때 모델은 무작위 초기화부터 시작합니다.

## 📊 Results

- **필터링의 중요성**:
  - 필터링은 의사 레이블의 WER을 낮춰 품질을 향상시킵니다.
  - 깨끗한 환경에서는 휴리스틱 필터가 1.8%의 데이터를 제거하며, 여기에 상위 10% 신뢰도 기반 필터링을 추가하면 개발 세트 WER에서 5.2%의 상대적 개선을 가져옵니다.
  - 잡음이 있는 환경에서는 가장 낮은 신뢰도의 10% 의사 레이블을 제거하는 것이 WER을 크게 감소시키며, 60%의 레이블을 필터링했을 때 최적 성능(개발 세트에서 필터링 없음 대비 22.7% 상대적 WER 감소)을 보였습니다.
- **모델 앙상블의 효과**:
  - 앙상블에 포함되는 모델 수가 증가함에 따라(최대 6개) 성능이 향상되며, 특히 잡음이 있는 환경에서 더욱 두드러집니다.
  - 잡음 환경에서 6개의 모델과 휴리스틱 필터링을 사용했을 때 13.7%의 상대적 개선을 달성했습니다.
  - 두 가지 필터링 기법(휴리스틱 + 신뢰도 기반)과 앙상블을 함께 사용했을 때, 잡음 환경에서 필터링 없는 단일 모델 대비 27.0%의 상대적 WER 개선을 보였습니다.
- **전반적인 성능 (LM 디코딩 포함)**:
  - **깨끗한 음성 (100시간 레이블 + 360시간 미학습 깨끗한 데이터)**: 테스트 세트에서 5.79%의 WER을 달성하며, 오라클 모델과의 격차를 59.3% 회복했습니다(WRR).
  - **잡음 음성 (100시간 레이블 + 500시간 미학습 잡음 데이터)**: 테스트 세트에서 20.11%의 WER을 달성하며, 오라클 모델과의 격차를 53.9% 회복했습니다(WRR).
  - **선행 연구와의 비교**: 유사한 데이터 설정에서 이전 최고 결과 대비 WER이 최소 65.1% 상대적으로 낮으며, WRR은 다른 방법들보다 최소 93.8% 상대적으로 높습니다.
- **LM의 중요성**: 의사 레이블 생성에 사용되는 LM의 perplexity가 낮을수록(즉, LM 성능이 좋을수록) 최종 모델의 WER이 더 낮아지는 경향을 보였습니다. LM을 전혀 사용하지 않는 것보다 성능이 낮은 LM이라도 사용하는 것이 자기 훈련의 효과를 크게 향상시킵니다.
- **안정적인 빔 서치(stable beam search)의 중요성**: 의사 레이블 생성 시 EOS 임계값과 같은 안정적인 빔 서치 기법을 사용하는 것이 단순 빔 서치나 탐욕적(greedy) AM 디코딩보다 의사 레이블 품질과 후속 모델 성능을 크게 향상시켰습니다.

## 🧠 Insights & Discussion

- 이 연구는 자기 훈련이 엔드-투-엔드 ASR 시스템에 있어 강력한 베이스라인 모델을 넘어 상당한 성능 향상을 가져올 수 있는 단순하면서도 효과적인 준지도 학습 방법임을 입증했습니다.
- 의사 레이블의 품질은 자기 훈련 성공의 핵심 요소입니다. 이는 강력한 베이스라인 음향 모델, 강력한 외부 언어 모델, 그리고 안정적인 빔 서치와 같은 견고한 디코딩 전략을 통해 향상될 수 있습니다.
- 시퀀스-투-시퀀스 모델의 특유한 오류를 해결하기 위한 필터링 메커니즘(휴리스틱 및 신뢰도 기반)은 특히 잡음이 있는 데이터 환경에서 신뢰할 수 없는 의사 레이블을 제거하는 데 중요합니다. 최적의 필터링 수준은 데이터의 깨끗함 정도에 따라 달라집니다.
- 제안된 *샘플 앙상블*은 필터링과 상호 보완적으로 작용하여 의사 레이블 다양성을 높이고, 모델이 잡음이 있는 레이블에 과도하게 의존하는 것을 방지합니다.
- 이러한 성공의 주요 원인 중 하나는 TDS 기반 인코더를 갖춘 강력한 베이스라인 모델과 현실 세계에서 쉽게 구할 수 있는 대규모 미학습 텍스트 코퍼스를 활용하여 고품질의 의사 레이블을 생성했다는 점입니다.
- 이 연구는 미래의 준지도 학습 ASR 접근 방식이 비교하고 평가할 수 있는 강력하고 재현 가능한 벤치마크를 제공합니다.

## 📌 TL;DR

엔드-투-엔드 ASR은 많은 전사된 데이터가 필요하지만, 이 연구는 강력한 자기 훈련(self-training) 방법을 사용하여 레이블이 없는 대량의 오디오 데이터를 활용합니다. 핵심적으로, 이들은 강력한 음향 모델과 언어 모델로 고품질의 의사 레이블(pseudo-label)을 생성하고, 시퀀스-투-시퀀스 모델의 흔한 오류를 방지하는 필터링 메커니즘을 적용하며, 의사 레이블 다양성을 높이는 새로운 앙상블 접근 방식(_sample ensemble_)을 제안합니다. LibriSpeech 실험 결과, 이 방법은 잡음이 있는 환경에서 baseline 대비 33.9%의 WER 상대적 개선을 달성했으며, 이전 접근 방식보다 93.8% 더 높은 WER 회복률을 보여주며 자기 훈련이 엔드-투-엔드 음성 인식 시스템의 정확도를 크게 향상시킬 수 있음을 입증했습니다.
