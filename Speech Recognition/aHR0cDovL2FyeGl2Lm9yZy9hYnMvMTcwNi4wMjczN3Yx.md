# Advances in Joint CTC-Attention based End-to-End Speech Recognition with a Deep CNN Encoder and RNN-LM

Takaaki Hori, Shinji Watanabe, Yu Zhang, William Chan

## 🧩 Problem to Solve

기존의 자동 음성 인식(ASR) 시스템은 음향 모델, 어휘 모델, 언어 모델 등 여러 모듈로 구성되어 복잡하며, 발음 사전이나 토큰화 같은 언어학적 지식 및 전처리를 요구합니다. 이는 비전문가가 새로운 언어나 응용 분야에 ASR 시스템을 구축하고 개발하기 어렵게 만듭니다.

종단 간(End-to-End) ASR은 이러한 복잡성을 단일 신경망 아키텍처로 단순화하는 것을 목표로 하지만, 기존 종단 간 방식에도 각각의 문제가 있습니다:

- **어텐션 기반 방식**: 입력 음향 프레임과 출력 기호 간의 정렬(alignment)을 학습하지만, 기계 번역과 같이 비순차적인 정렬을 허용하여 음성 인식에서는 정렬이 손상될 수 있습니다.
- **CTC (Connectionist Temporal Classification) 기반 방식**: Markov 가정에 기반하여 효율적이지만, 특정 조건부 독립 가정이 필요합니다.

이 논문은 기존의 CTC-어텐션 결합 종단 간 ASR 프레임워크를 확장하여 견고성과 정확도를 더욱 향상시키는 것을 목표로 합니다.

## ✨ Key Contributions

이 논문은 기존의 CTC-어텐션 결합 종단 간 ASR 모델에 다음 세 가지 핵심적인 확장을 제안합니다:

1. **CTC-어텐션 결합 디코딩**: 학습 과정에서만 CTC 목표 함수를 사용하는 것을 넘어, 디코딩 과정에서도 CTC 예측과 어텐션 기반 디코더 예측을 결합합니다. 이를 위해 재점수 매기기(rescoring) 방식과 원패스(one-pass) 디코딩 방식을 제안합니다.
2. **심층 CNN (VGG 네트워크) 인코더**: 인코더 네트워크에 VGG 네트워크 [14] 기반의 심층 컨볼루션 신경망(CNN)을 통합하여 음향 특징 추출 능력을 강화합니다.
3. **RNN 언어 모델 (RNN-LM) 통합**: 어텐션 디코더와 병렬로 별도로 학습되거나 공동으로 학습될 수 있는 문자 시퀀스 기반의 순환 신경망 언어 모델(RNN-LM)을 결합하여 언어 모델링 성능을 향상시킵니다.

## 📎 Related Works

- **전통적인 하이브리드 ASR 시스템**: HMM(Hidden Markov Model), GMM(Gaussian Mixture Model), DNN(Deep Neural Networks) 등을 기반으로 음향, 어휘, 언어 모델을 분리하여 구성합니다.
- **종단 간 ASR (End-to-End ASR)**:
  - **어텐션 기반 방식**: 어텐션 메커니즘을 사용하여 음향 프레임과 인식된 심볼 간의 정렬을 수행합니다 [5, 6, 7, 8, 9].
  - **CTC 기반 방식**: Markov 가정을 사용하여 동적 프로그래밍으로 순차적 문제를 효율적으로 해결합니다 [10, 11, 12].
- **이전 연구**: CTC 목표 함수를 어텐션 모델 인코더의 정규화 기술로 활용하여 훈련 중 불규칙한 정렬을 줄이고 성능을 개선한 CTC-어텐션 결합 종단 간 ASR [13].
- **심층 CNN 인코더의 효용성**: 종단 간 ASR에서 심층 CNN 인코더의 효과는 이미 다른 연구들에서 입증된 바 있습니다 [15, 16].

## 🛠️ Methodology

본 논문은 기존 CTC-어텐션 결합 프레임워크를 기반으로 확장된 종단 간 ASR 모델을 제안합니다.

1. **다중 작업 학습(Multi-task Learning)을 통한 CTC-어텐션 결합 훈련**:

   - CTC와 어텐션 디코더 네트워크는 동일한 BLSTM 인코더를 공유합니다.
   - 목표 함수는 CTC의 로그 확률과 어텐션 모델의 로그 확률의 가중 선형 조합으로 최대화됩니다:
     $$L_{MTL} = \lambda \log p_{ctc}(C|X) + (1-\lambda) \log p_{att}(C|X)$$
     여기서 $X$는 입력 음성, $C$는 출력 문자열, $\lambda$는 조절 가능한 가중치입니다. CTC는 훈련 중 음성과 레이블 시퀀스 간의 단조로운 정렬을 강제하여 어텐션 모델의 정렬 문제를 보완합니다.

2. **심층 CNN 인코더**:

   - VGG 네트워크 아키텍처 [14]에서 영감을 받은 6개 계층의 CNN (4개의 Convolution2D, 2개의 Maxpool2D 레이어)을 BLSTM 레이어 앞에 통합합니다.
   - 이 CNN은 입력 음성 특징(멜 스케일 필터뱅크, 피치, 델타 및 델타 델타 특징)을 처리하며, 두 개의 Max-pooling 레이어를 통해 시간-주파수 축을 따라 입력을 $1/4 \times 1/4$로 다운샘플링합니다.

3. **결합 디코딩 (Joint Decoding)**:

   - 빔 탐색(beam search) 과정에서 CTC와 어텐션 모델의 확률을 결합하여 최적의 문자열 시퀀스 $\hat{C}$를 찾습니다.
     $$\hat{C}= \arg \max_{C \in U^*} \{\lambda \log p_{ctc}(C|X) +(1-\lambda) \log p_{att}(C|X)\}$$
   - **재점수 매기기 (Rescoring)**: 먼저 어텐션 모델만으로 N-best 가설을 얻은 다음, CTC의 순방향 알고리즘으로 계산된 $p_{ctc}(C|X)$를 사용하여 각 가설의 점수를 재조정합니다.
   - **원패스 디코딩 (One-pass Decoding)**: 빔 탐색 과정에서 각 부분 가설($g_l$)의 점수에 CTC 접두사 확률(CTC prefix probability, $p(g_l,...|X)$)을 직접 통합하여 실시간으로 CTC와 어텐션 모델의 확률을 결합합니다.

4. **RNN-LM (Recurrent Neural Network Language Model) 통합**:
   - 문자 단위로 학습된 RNN-LM 네트워크를 어텐션 디코더와 병렬로 결합합니다.
   - RNN-LM은 단독으로 사전 학습되거나, 인코더 및 디코더 네트워크와 함께 공동으로 학습될 수 있습니다.
   - RNN-LM의 확률은 디코더 네트워크와 함께 최종 출력 레이블을 예측하는 데 사용되며, 소프트맥스(softmax) 이전의 로짓(logits) 레벨에서 결합됩니다.

## 📊 Results

제안된 방법은 일본어(CSJ) 및 중국어(MTS) ASR 벤치마크에서 기존 시스템 대비 상당한 성능 향상을 보였으며, 전통적인 하이브리드 ASR 시스템을 능가하는 결과를 달성했습니다.

- **전반적인 오류 감소**: 자발적 일본어 및 중국어 음성 인식에서 이전 시스템 대비 5-10%의 오류 감소를 달성했습니다.
- **결합 디코딩의 효과**:
  - **CSJ (일본어)**: 다중 작업 학습(MTL)만 사용했을 때 (10.5% CER)보다, 결합 디코딩(원패스) 방식이 10.0% CER로 향상되었습니다.
  - **MTS (중국어)**: MTL (38.7% CER)에서 결합 디코딩(원패스) 방식이 33.9% CER로 크게 향상되었습니다.
- **RNN-LM 통합의 효과**:
  - **CSJ**: MTL-large + 결합 디코딩(원패스) (8.4% CER)에 RNN-LM (별도 학습)을 추가하여 7.9% CER로 개선되었습니다.
  - **MTS**: 결합 디코딩(원패스) (33.9% CER)에 RNN-LM (별도 학습)을 추가하여 33.3% CER, 그리고 RNN-LM을 공동 학습했을 때 32.1% CER로 추가 개선되었습니다.
- **심층 CNN (VGG) 인코더의 효과**:
  - **MTS (속도 교란 데이터 추가)**: 결합 디코딩 (32.1% CER)에 VGG 네트워크를 추가하여 30.0% CER로 개선되었고, RNN-LM (별도 학습)까지 추가 시 28.0% CER를 달성했습니다.
- **하이브리드 시스템과의 비교**:
  - **CSJ**: 제안된 모델 (7.9% CER)은 DNN-하이브리드 시스템 (8.4-9.0% CER)보다 낮은 CER을 기록했습니다.
  - **MTS**: 제안된 모델 (28.0% CER)은 TDNN-하이브리드, lattice-free MMI (28.2% CER)를 포함한 최신 하이브리드 시스템보다 우수한 성능을 보였습니다.
- 이러한 성능 향상은 형태소 분석기나 발음 사전과 같은 어떠한 언어학적 자원도 사용하지 않고 달성되었습니다.

## 🧠 Insights & Discussion

- 이 연구는 언어학적 자원(예: 형태소 분석기, 발음 사전) 없이도 최첨단 종단 간 ASR 성능을 달성하여, 특히 중국어 및 일본어와 같이 언어학적 지식이 필수적인 언어에서 시스템 구축의 복잡성을 크게 줄일 수 있음을 보여줍니다.
- 제안된 CTC-어텐션 결합 디코딩, 심층 CNN 인코더, RNN-LM 통합은 개별적으로도 성능 향상에 기여하며, 모두 결합했을 때 시너지 효과를 내어 기존 종단 간 ASR 모델뿐만 아니라 전통적인 하이브리드 HMM 시스템까지 능가하는 결과를 가져왔습니다.
- RNN-LM은 별도로 사전 학습된 후 통합될 수 있지만, 모델 전체가 하나의 큰 신경망으로 간주될 수 있으며, 공동 훈련 시 추가적인 성능 향상을 기대할 수 있습니다.
- RNN-LM 학습에 사용된 텍스트 데이터는 레이블링된 음성 데이터와 동일한 텍스트 데이터에서 추출되었습니다. 이는 막대한 양의 레이블 없는 텍스트 데이터를 활용하여 RNN-LM을 사전 학습하고 이후 모델과 공동 훈련할 경우, 훨씬 더 큰 성능 개선 가능성이 있음을 시사합니다.
- 이러한 발전은 비전문가도 새로운 응용 분야나 언어에 대한 ASR 시스템을 쉽고 효율적으로 개발할 수 있는 길을 열어줍니다.

## 📌 TL;DR

**문제**: 기존 ASR은 복잡하고 언어학적 자원이 필요하며, 기존 종단 간 ASR(어텐션의 유연성, CTC의 가정)은 한계가 있습니다.

**제안 방법**: 심층 CNN 인코더와 RNN-LM을 통합한 개선된 CTC-어텐션 결합 종단 간 ASR 모델을 제안합니다. 특히 디코딩 과정에 CTC 확률을 활용하는 결합 디코딩(원패스 및 재점수 매기기 방식)을 도입합니다.

**핵심 결과**: 제안된 모델은 일본어 및 중국어 ASR 벤치마크에서 언어학적 자원 없이도 기존 하이브리드 시스템과 이전 종단 간 모델을 뛰어넘는 최첨단 성능을 달성했습니다.
