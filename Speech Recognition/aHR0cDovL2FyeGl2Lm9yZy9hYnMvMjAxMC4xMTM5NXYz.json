{
  "title": "Developing Real-time Streaming Transformer Transducer for Speech\n  Recognition on Large-scale Dataset",
  "authors": "Xie Chen, Yu Wu, Zhenghao Wang, Shujie Liu, Jinyu Li",
  "year": 2020,
  "url": "http://arxiv.org/abs/2010.11395v3",
  "abstract": "Recently, Transformer based end-to-end models have achieved great success in\nmany areas including speech recognition. However, compared to LSTM models, the\nheavy computational cost of the Transformer during inference is a key issue to\nprevent their applications. In this work, we explored the potential of\nTransformer Transducer (T-T) models for the fist pass decoding with low latency\nand fast speed on a large-scale dataset. We combine the idea of Transformer-XL\nand chunk-wise streaming processing to design a streamable Transformer\nTransducer model. We demonstrate that T-T outperforms the hybrid model, RNN\nTransducer (RNN-T), and streamable Transformer attention-based encoder-decoder\nmodel in the streaming scenario. Furthermore, the runtime cost and latency can\nbe optimized with a relatively small look-ahead.",
  "citation": 245
}