{
  "title": "Deep Representation Learning in Speech Processing: Challenges, Recent\n  Advances, and Future Trends",
  "authors": "Siddique Latif, Rajib Rana, Sara Khalifa, Raja Jurdak, Junaid Qadir, Bj√∂rn W. Schuller",
  "year": 2020,
  "url": "http://arxiv.org/abs/2001.00378v2",
  "abstract": "Research on speech processing has traditionally considered the task of\ndesigning hand-engineered acoustic features (feature engineering) as a separate\ndistinct problem from the task of designing efficient machine learning (ML)\nmodels to make prediction and classification decisions. There are two main\ndrawbacks to this approach: firstly, the feature engineering being manual is\ncumbersome and requires human knowledge; and secondly, the designed features\nmight not be best for the objective at hand. This has motivated the adoption of\na recent trend in speech community towards utilisation of representation\nlearning techniques, which can learn an intermediate representation of the\ninput signal automatically that better suits the task at hand and hence lead to\nimproved performance. The significance of representation learning has increased\nwith advances in deep learning (DL), where the representations are more useful\nand less dependent on human knowledge, making it very conducive for tasks like\nclassification, prediction, etc. The main contribution of this paper is to\npresent an up-to-date and comprehensive survey on different techniques of\nspeech representation learning by bringing together the scattered research\nacross three distinct research areas including Automatic Speech Recognition\n(ASR), Speaker Recognition (SR), and Speaker Emotion Recognition (SER). Recent\nreviews in speech have been conducted for ASR, SR, and SER, however, none of\nthese has focused on the representation learning from speech -- a gap that our\nsurvey aims to bridge.",
  "citation": 121
}