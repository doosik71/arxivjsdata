{
  "title": "Automatic Speech Recognition using Advanced Deep Learning Approaches: A\n  survey",
  "authors": "Hamza Kheddar, Mustapha Hemis, Yassine Himeur",
  "year": 2024,
  "url": "http://arxiv.org/abs/2403.01255v2",
  "abstract": "Recent advancements in deep learning (DL) have posed a significant challenge\nfor automatic speech recognition (ASR). ASR relies on extensive training\ndatasets, including confidential ones, and demands substantial computational\nand storage resources. Enabling adaptive systems improves ASR performance in\ndynamic environments. DL techniques assume training and testing data originate\nfrom the same domain, which is not always true. Advanced DL techniques like\ndeep transfer learning (DTL), federated learning (FL), and reinforcement\nlearning (RL) address these issues. DTL allows high-performance models using\nsmall yet related datasets, FL enables training on confidential data without\ndataset possession, and RL optimizes decision-making in dynamic environments,\nreducing computation costs. This survey offers a comprehensive review of DTL,\nFL, and RL-based ASR frameworks, aiming to provide insights into the latest\ndevelopments and aid researchers and professionals in understanding the current\nchallenges. Additionally, transformers, which are advanced DL techniques\nheavily used in proposed ASR frameworks, are considered in this survey for\ntheir ability to capture extensive dependencies in the input ASR sequence. The\npaper starts by presenting the background of DTL, FL, RL, and Transformers and\nthen adopts a well-designed taxonomy to outline the state-of-the-art\napproaches. Subsequently, a critical analysis is conducted to identify the\nstrengths and weaknesses of each framework. Additionally, a comparative study\nis presented to highlight the existing challenges, paving the way for future\nresearch opportunities.",
  "citation": 157
}