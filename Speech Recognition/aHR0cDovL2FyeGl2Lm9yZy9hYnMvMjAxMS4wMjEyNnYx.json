{
  "url": "http://arxiv.org/abs/2011.02126v1",
  "title": "Incremental Machine Speech Chain Towards Enabling Listening while\n  Speaking in Real-time",
  "authors": "Sashi Novitasari, Andros Tjandra, Tomoya Yanagita, Sakriani Sakti, Satoshi Nakamura",
  "year": 2020,
  "abstract": "Inspired by a human speech chain mechanism, a machine speech chain framework\nbased on deep learning was recently proposed for the semi-supervised\ndevelopment of automatic speech recognition (ASR) and text-to-speech synthesis\nTTS) systems. However, the mechanism to listen while speaking can be done only\nafter receiving entire input sequences. Thus, there is a significant delay when\nencountering long utterances. By contrast, humans can listen to what hey speak\nin real-time, and if there is a delay in hearing, they won't be able to\ncontinue speaking. In this work, we propose an incremental machine speech chain\ntowards enabling machine to listen while speaking in real-time. Specifically,\nwe construct incremental ASR (ISR) and incremental TTS (ITTS) by letting both\nsystems improve together through a short-term loop. Our experimental results\nreveal that our proposed framework is able to reduce delays due to long\nutterances while keeping a comparable performance to the non-incremental basic\nmachine speech chain."
}