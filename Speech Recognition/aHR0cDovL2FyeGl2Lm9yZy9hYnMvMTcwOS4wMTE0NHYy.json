{
  "title": "Information Theoretic Analysis of DNN-HMM Acoustic Modeling",
  "authors": "Pranay Dighe, Afsaneh Asaei, Herv√© Bourlard",
  "year": 2017,
  "url": "http://arxiv.org/abs/1709.01144v2",
  "abstract": "We propose an information theoretic framework for quantitative assessment of\nacoustic modeling for hidden Markov model (HMM) based automatic speech\nrecognition (ASR). Acoustic modeling yields the probabilities of HMM sub-word\nstates for a short temporal window of speech acoustic features. We cast ASR as\na communication channel where the input sub-word probabilities convey the\ninformation about the output HMM state sequence. The quality of the acoustic\nmodel is thus quantified in terms of the information transmitted through this\nchannel. The process of inferring the most likely HMM state sequence from the\nsub-word probabilities is known as decoding. HMM based decoding assumes that an\nacoustic model yields accurate state-level probabilities and the data\ndistribution given the underlying hidden state is independent of any other\nstate in the sequence. We quantify 1) the acoustic model accuracy and 2) its\nrobustness to mismatch between data and the HMM conditional independence\nassumption in terms of some mutual information quantities. In this context,\nexploiting deep neural network (DNN) posterior probabilities leads to a simple\nand straightforward analysis framework to assess shortcomings of the acoustic\nmodel for HMM based decoding. This analysis enables us to evaluate the Gaussian\nmixture acoustic model (GMM) and the importance of many hidden layers in DNNs\nwithout any need of explicit speech recognition. In addition, it sheds light on\nthe contribution of low-dimensional models to enhance acoustic modeling for\nbetter compliance with the HMM based decoding requirements.",
  "citation": 0
}