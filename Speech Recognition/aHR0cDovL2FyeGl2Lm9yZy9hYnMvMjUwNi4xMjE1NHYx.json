{
  "url": "http://arxiv.org/abs/2506.12154v1",
  "title": "Adapting Whisper for Streaming Speech Recognition via Two-Pass Decoding",
  "authors": "Haoran Zhou, Xingchen Song, Brendan Fahy, Qiaochu Song, Binbin Zhang, Zhendong Peng, Anshul Wadhawan, Denglin Jiang, Apurv Verma, Vinay Ramesh, Srivas Prasad, Michele M. Franceschini",
  "year": 2025,
  "abstract": "OpenAI Whisper is a family of robust Automatic Speech Recognition (ASR)\nmodels trained on 680,000 hours of audio. However, its encoder-decoder\narchitecture, trained with a sequence-to-sequence objective, lacks native\nsupport for streaming ASR. In this paper, we fine-tune Whisper for streaming\nASR using the WeNet toolkit by adopting a Unified Two-pass (U2) structure. We\nintroduce an additional Connectionist Temporal Classification (CTC) decoder\ntrained with causal attention masks to generate streaming partial transcripts,\nwhile the original Whisper decoder reranks these partial outputs. Our\nexperiments on LibriSpeech and an earnings call dataset demonstrate that, with\nadequate fine-tuning data, Whisper can be adapted into a capable streaming ASR\nmodel. We also introduce a hybrid tokenizer approach, which uses a smaller\ntoken space for the CTC decoder while retaining Whisper's original token space\nfor the attention decoder, resulting in improved data efficiency and\ngeneralization."
}