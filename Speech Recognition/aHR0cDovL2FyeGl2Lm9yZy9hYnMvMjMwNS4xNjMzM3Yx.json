{
  "url": "http://arxiv.org/abs/2305.16333v1",
  "title": "Text Generation with Speech Synthesis for ASR Data Augmentation",
  "authors": "Zhuangqun Huang, Gil Keren, Ziran Jiang, Shashank Jain, David Goss-Grubbs, Nelson Cheng, Farnaz Abtahi, Duc Le, David Zhang, Antony D'Avirro, Ethan Campbell-Taylor, Jessie Salas, Irina-Elena Veliche, Xi Chen",
  "year": 2023,
  "abstract": "Aiming at reducing the reliance on expensive human annotations, data\nsynthesis for Automatic Speech Recognition (ASR) has remained an active area of\nresearch. While prior work mainly focuses on synthetic speech generation for\nASR data augmentation, its combination with text generation methods is\nconsiderably less explored. In this work, we explore text augmentation for ASR\nusing large-scale pre-trained neural networks, and systematically compare those\nto traditional text augmentation methods. The generated synthetic texts are\nthen converted to synthetic speech using a text-to-speech (TTS) system and\nadded to the ASR training data. In experiments conducted on three datasets, we\nfind that neural models achieve 9%-15% relative WER improvement and outperform\ntraditional methods. We conclude that text augmentation, particularly through\nmodern neural approaches, is a viable tool for improving the accuracy of ASR\nsystems.",
  "citation": 5
}