# Text Generation with Speech Synthesis for ASR Data Augmentation

Zhuangqun Huang, Gil Keren, Ziran Jiang, Shashank Jain, David Goss-Grubbs, Nelson Cheng, Farnaz Abtahi, Duc Le, David Zhang, Antony D’Avirro, Ethan Campbell-Taylor, Jessie Salas, Irina-Elena Veliche, Xi Chen

## 🧩 Problem to Solve

자동 음성 인식(ASR) 모델 훈련에는 수천 시간의 전사된 음성 데이터가 필요하지만, 이러한 데이터를 수집하고 주석을 다는 과정은 매우 비용이 많이 듭니다. 기존 연구들은 주로 텍스트 음성 변환(TTS)을 통한 합성 음성 생성에 초점을 맞추었으나, 텍스트 생성 방법과의 결합을 통한 ASR 데이터 증강은 상대적으로 덜 탐구되었습니다. 특히, ASR 정확도 향상을 위한 텍스트 증강(Text Augmentation, TA)의 잠재력(데이터 다양화 및 풍부화, 새로운 도메인 ASR 시스템의 신속한 구축 가능성 등)이 충분히 연구되지 않았으며, 기존 TA 방법들은 비신경망 기반이거나 소규모 데이터셋에 국한되어 있었습니다.

## ✨ Key Contributions

- 대규모 사전 학습 신경망(BART)을 활용한 ASR 데이터 증강을 위한 텍스트 증강 기법을 탐구하고, 이를 전통적인 텍스트 증강 방법과 체계적으로 비교했습니다.
- 신경망 기반 TA(BART)가 규칙 기반 TA(NLX)보다 모든 세 가지 도메인(LibriSpeech, Photo Search, Q&A)에서 ASR WER(단어 오류율) 개선에 우수함을 입증했습니다. 특히 오픈 도메인이나 다양한 발화가 있는 도메인에서 10%-16%의 상대적 WER 개선을 달성했습니다.
- 현대 신경망 기반 TA가 TTS 시스템과 함께 ASR 시스템의 정확도를 향상시키는 중요한 도구임을 제시했습니다.
- 도메인 특화 훈련의 경우, 소규모 인-도메인 텍스트 코퍼스로부터 시작하여 목표 정확도에 도달할 수 있음을 보여주었으며, 현대 TA 기법이 음성 데이터 합성의 표준 관행으로 고려되어야 함을 제안했습니다.
- 텍스트 증강 없이 시드 텍스트 데이터만으로 TTS 데이터 증강을 수행해도 상당한 WER 개선(오픈 도메인 약 5%, 단순 구조 도메인 약 15%)이 있음을 확인했습니다.
- 증강 데이터의 크기가 8배 이상으로 증가해도 모델 개선은 안정적이며, 100배 이상의 증강에서 추가 개선이 발생할 수 있음을 발견했습니다.
- 여러 TA 방법(NLX, BART R.M., BART C.M.)에서 생성된 합성 데이터를 결합하면 WER 개선이 추가적으로 증대됨을 확인했습니다.

## 📎 Related Works

- **ASR 데이터 부족 문제 해결**: 레이블링되거나 레이블링되지 않은 데이터를 사용하는 데이터 증강 기법 [1, 2].
- **음성 데이터 합성**: 최근 도메인 적응 [3], 의약품 이름 인식 [4], 정확한 숫자 시퀀스 전사 [5], 저자원 언어 [6] 등에서 상당한 진전을 보였습니다.
- **주요 연구 분야**: TTS 생성 [7, 8, 9, 10] 및 오디오 증강 [11, 12, 13]과 이러한 기술이 ASR 정확도에 미치는 영향.
- **ASR 정확도 향상을 위한 텍스트 증강(TA)**: 기존 문헌은 제한적이며, Rosenberg et al. [9]은 비신경망 Max-Ent 언어 모델 [14]을 사용하여 작은 WER 개선을 관찰했습니다. Zevallos et al. [6]은 개체(명사 등)를 비어휘화된 형태로 대체한 후 seq2seq 모델을 사용하여 다양한 비어휘화된 패러프레이즈를 생성하고 훈련 데이터에서 값을 채워 넣는 방식으로 합성 발화를 생성했습니다. 본 연구는 이러한 기존 방법들이 대규모 사전 학습 모델의 강력한 기능을 충분히 활용하지 못한다는 점을 개선하고자 합니다.

## 🛠️ Methodology

본 연구의 일반적인 파이프라인은 시드 텍스트 코퍼스에서 시작하여 텍스트 증강 방법을 통해 새로운 증강 텍스트 코퍼스를 생성한 다음, TTS 시스템을 사용하여 이 텍스트들을 합성 음성 발화로 변환하는 것입니다. 이렇게 생성된 합성 음성은 인간이 주석을 단 데이터와 함께 RNN-T(Recurrent Neural Network Transducer) 기반 ASR 모델 훈련에 사용됩니다.

- **ASR 모델**: 저지연 스트리밍 RNN-T 모델을 사용했으며, 이는 20개의 Emformer 레이어로 구성된 오디오 인코더, 3개의 LSTM 레이어로 구성된 RNN 예측기, 그리고 ReLU 활성화 함수와 선형 레이어로 구성된 조이너 모듈로 이루어져 있습니다.
- **텍스트 증강(TA) 방법**:
  - **NLX (규칙 기반)**: 자체 개발된 기능 강화 문맥 자유 규칙 기반 시스템입니다. 언어학 전문가가 시드 데이터를 분석하여 문법 규칙을 만들고, 명명된 개체와 같은 어휘 항목을 채굴하여 발화를 합성합니다.
  - **BART (신경망 기반)**: 대규모 사전 학습 모델인 BART [15]를 활용합니다. 시드 훈련 데이터의 마스킹된 시퀀스에 대해 BART 모델을 미세 조정하여 작업에 적응시킵니다.
    - **Random Masking (BART R.M.)**: 시드 데이터에 무작위로 마스크를 삽입하여 합성 텍스트를 생성합니다.
    - **Custom Masking (BART C.M.)**: 품사(Part of Speech) 태그를 사용하여 명사, 동사 등 마스킹할 후보 단어를 식별하고 하나씩 마스크로 교체합니다.
- **TTS 시스템**: 언어 프런트엔드와 음향 백엔드로 구성됩니다. 프런트엔드는 평문 텍스트를 음소 표현과 운율 정보로 변환하며, 백엔드는 트랜스포머 기반 운율 모델(F0 값, 지속 시간 예측), 트랜스포머 기반 스펙트럼 모델(멜-켑스트럼 계수, F0, 주기성 특성 생성), 그리고 WaveRNN 기반 신경 보코더(최종 파형 예측)로 이루어져 있습니다 [20]. 96명의 영어 화자로부터 얻은 170시간의 고품질 오디오로 훈련되었으며, 3가지 속도와 5가지 피치 변형을 추가하여 증강했습니다.
- **오디오 증강**: 속도 왜곡(0.9, 1.0, 1.1배), 다양한 노이즈(1.72M 노이즈 트랙) 추가를 포함합니다. SNR(신호 대 잡음비)은 $N(12.50, 17.31)$ 분포를 따릅니다.
- **훈련 방식**: 인간 주석 데이터와 합성 TTS 데이터를 특정 혼합 비율로 사용하여 RNN-T 모델을 훈련했습니다. Photo Search 도메인을 제외하고는 모델을 처음부터 훈련했으며, Photo Search의 경우 기존 모델을 미세 조정했습니다.

## 📊 Results

세 가지 데이터셋(LibriSpeech, Photo Search, Q&A)에 대해 실험을 수행했습니다.

- **시드 텍스트만으로 TTS 증강**:
  - Q&A: 2% 미만의 미미한 WER 개선.
  - LibriSpeech: 5.2%-5.4%의 상대적 WER 개선.
  - Photo Search: 14.53%의 상당한 상대적 WER 개선(단 3350개의 발화만으로 WER <4% 달성 가능).
- **텍스트 증강(TA) 방법 비교 (BART vs. NLX)**:
  - **NLX**: LibriSpeech 및 Photo Search 도메인에서는 성능이 오히려 저하되거나 개선이 없었으나, Q&A 도메인에서는 6.1%-8.1%의 유의미한 상대적 개선을 보였습니다.
  - **BART C.M.** (Custom Masking): Photo Search 도메인에서 성능 저하가 없었으며, 다른 두 도메인에서는 개선을 보였습니다.
  - **BART R.M.** (Random Masking): BART C.M.보다 더 큰 개선을 달성했습니다.
  - **종합**: 신경망 기반 BART 방법이 규칙 기반 NLX보다 전반적으로 WER 개선에 더 효과적이었습니다. TA는 크고 다양한 시드 코퍼스를 가진 데이터셋에서 더 효과적인 것으로 나타났습니다.
- **NLX와 BART의 결합**: Q&A 도메인에서 모든 TA 방법(NLX, BART R.M., BART C.M.)이 개별적으로 이득을 보였으며, 이들을 결합했을 때 추가적인 WER 개선을 관찰했습니다. 예를 들어, 베이스라인 대비 11.88%에서 15.68%로 상대적 개선이 이루어졌습니다. 그러나 LibriSpeech와 Photo Search 도메인에서는 NLX의 개별 기여가 미미했기 때문에 결합 효과도 크지 않았습니다.
- **증강 계수의 효과**: LibriSpeech의 경우, 증강 계수가 8배(2.3M)에서 26배(7.3M)로 증가했을 때 WER이 상당히 안정적이었으며, 103배(29M) 증강 시 test-clean 세트에서 WER이 3.11%에서 3.00%로 추가 개선되었습니다. Q&A 도메인에서는 83배 증강에서도 추가적인 이득은 없었으며, 이는 일부 경우 TA 방법이 특정 발화 수 이상에서는 포화될 수 있음을 시사합니다.

## 🧠 Insights & Discussion

- **신경망 기반 TA의 우수성**: 본 연구는 기존 문헌에서 명확히 검증되지 않았던 신경망 기반 텍스트 증강(특히 BART)이 ASR 데이터 증강 목적의 TTS와 결합될 때 규칙 기반 방법보다 월등히 우수하다는 것을 입증했습니다. 이는 ASR 정확도 향상을 위한 중요한 접근 방식임을 의미합니다.
- **TA의 도메인별 효과**: 텍스트 증강은 오픈 도메인(LibriSpeech) 및 다양한 발화 스타일을 가진 도메인(Q&A)에서 ASR 정확도를 크게 향상시킬 수 있음을 보여주었습니다.
- **작은 시드 데이터의 한계 및 잠재력**: Photo Search와 같이 작고 구조화된 시드 데이터에서는 TA의 효과가 제한적일 수 있지만, 단 몇 천 개의 텍스트 발화만으로도 높은 성능의 ASR을 달성할 수 있음이 확인되었습니다.
- **비용 효율적인 ASR 개선**: 비싼 인간 주석 오디오 코퍼스 대신, 인-도메인 텍스트 코퍼스를 활용하여 ASR 시스템을 개선하는 것이 비용 효율적인 대안이 될 수 있습니다.
- **한계 및 향후 연구**:
  - TTS 데이터 크기가 다른 도메인에 미치는 영향에 대한 추가 조사가 필요합니다.
  - 고품질 시드 텍스트 코퍼스 수집의 중요성(비용은 절감되나 노력은 필요).
  - 생성된 텍스트를 외부 언어 모델(LM)에 활용하는 것과 TTS의 효과를 비교하는 연구가 필요합니다.
  - TTS 음성 다양성을 더욱 높이고 개인화된 요소를 추가하여 ASR 개선의 잠재력을 탐색할 필요가 있습니다.

## 📌 TL;DR

- **문제**: ASR 훈련에 필요한 고비용의 주석된 음성 데이터를 대체하기 위해 텍스트 증강(TA)과 음성 합성(TTS)의 시너지가 충분히 탐구되지 않았습니다.
- **제안 방법**: 대규모 사전 학습 BART 모델을 활용한 신경망 기반 텍스트 증강 기법을 제안하고, 이를 통해 생성된 합성 텍스트를 TTS 시스템으로 음성 데이터로 변환하여 ASR 훈련에 사용했습니다. 규칙 기반 TA와 신경망 기반 TA의 효과를 체계적으로 비교했습니다.
- **주요 결과**: 신경망 기반 TA (BART)가 규칙 기반 TA (NLX)보다 ASR WER 개선에 월등히 우수함을 보였습니다(최대 15.68% 상대 개선). 특히 크고 다양한 시드 텍스트 코퍼스를 가진 도메인에서 효과적이었으며, 여러 TA 기법을 혼합하면 추가적인 성능 향상을 얻을 수 있었습니다. 이는 비싼 음성 데이터 대신 비용 효율적인 텍스트 코퍼스를 사용하여 ASR 시스템을 개선할 수 있는 강력한 방법을 제시합니다.
