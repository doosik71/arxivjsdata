{
  "title": "FastEmit: Low-latency Streaming ASR with Sequence-level Emission\n  Regularization",
  "authors": "Jiahui Yu, Chung-Cheng Chiu, Bo Li, Shuo-yiin Chang, Tara N. Sainath, Yanzhang He, Arun Narayanan, Wei Han, Anmol Gulati, Yonghui Wu, Ruoming Pang",
  "year": 2020,
  "url": "http://arxiv.org/abs/2010.11148v2",
  "abstract": "Streaming automatic speech recognition (ASR) aims to emit each hypothesized\nword as quickly and accurately as possible. However, emitting fast without\ndegrading quality, as measured by word error rate (WER), is highly challenging.\nExisting approaches including Early and Late Penalties and Constrained\nAlignments penalize emission delay by manipulating per-token or per-frame\nprobability prediction in sequence transducer models. While being successful in\nreducing delay, these approaches suffer from significant accuracy regression\nand also require additional word alignment information from an existing model.\nIn this work, we propose a sequence-level emission regularization method, named\nFastEmit, that applies latency regularization directly on per-sequence\nprobability in training transducer models, and does not require any alignment.\nWe demonstrate that FastEmit is more suitable to the sequence-level\noptimization of transducer models for streaming ASR by applying it on various\nend-to-end streaming ASR networks including RNN-Transducer,\nTransformer-Transducer, ConvNet-Transducer and Conformer-Transducer. We achieve\n150-300 ms latency reduction with significantly better accuracy over previous\ntechniques on a Voice Search test set. FastEmit also improves streaming ASR\naccuracy from 4.4%/8.9% to 3.1%/7.5% WER, meanwhile reduces 90th percentile\nlatency from 210 ms to only 30 ms on LibriSpeech.",
  "citation": 104
}