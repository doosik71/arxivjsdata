# Automatic Speech Recognition using Advanced Deep Learning Approaches: A survey

Hamza Kheddar, Mustapha Hemis, Yassine Himeur

## 🧩 Problem to Solve

최근 딥러닝(DL)의 발전은 자동 음성 인식(ASR) 분야에 상당한 도전 과제를 제시했습니다. ASR은 종종 기밀 데이터를 포함하는 방대한 훈련 데이터셋과 상당한 컴퓨팅 및 저장 자원을 요구합니다. 또한, 기존 DL 기술은 훈련 및 테스트 데이터가 동일한 도메인에서 유래한다고 가정하지만, 이는 동적 환경에서 항상 사실이 아니므로 적응형 시스템의 필요성이 커지고 있습니다. 데이터 부족, 주석 처리된 데이터의 희소성, 데이터 분포 불일치 등도 모델 성능 저하의 주요 원인입니다.

## ✨ Key Contributions

이 논문은 고급 딥러닝 기반 ASR 프레임워크에 대한 포괄적인 검토를 제공하며, 다음과 같은 핵심 기여를 합니다:

- 심층 전이 학습(DTL), 심층 강화 학습(DRL), 연합 학습(FL) 및 트랜스포머를 포함한 고급 DL 기술의 배경을 제시합니다.
- ASR 접근 방식 검증에 사용되는 평가 지표와 데이터셋을 설명합니다.
- 음향 모델(AM) 및 언어 모델(LM) 도메인을 기반으로 ASR 방법론을 분류하는 체계적인 분류법을 소개합니다.
- 고급 DL 기반 ASR의 과제와 한계를 식별합니다.
- 고급 DL 기반 ASR 솔루션의 성능을 향상시키기 위한 미래 방향을 제시하고 해당 분야의 잠재적 발전을 예측합니다.

## 📎 Related Works

이 논문은 다양한 ASR 모델 측면을 평가하기 위해 발표된 수많은 기존 설문조사 논문을 언급합니다. 여기에는 포르투갈어, 인도어, 튀르키예어, 아랍어와 같은 특정 언어에 초점을 맞춘 연구와 제한된 어휘, 어린이 ASR, 오류 감지 및 수정, 비지도 ASR, 신경망 및 심층 신경망(DNN)에 대한 체계적인 검토가 포함됩니다. 특히, 이전의 DTL 기반 ASR 검토 논문들도 언급됩니다.

본 설문조사는 이전 연구들과 달리 DTL과 다른 고급 DL 접근 방식(DRL, FL, 트랜스포머)을 통합하여 포괄적으로 검토하고, 모든 고려된 접근 방식의 성능 평가 결과, 사용된 지표 및 데이터셋 검토, 지속적인 과제 및 미래 방향을 포함하여 차별점을 둡니다.

## 🛠️ Methodology

이 설문조사는 2016년부터 2023년까지의 기간 동안 고급 딥러닝 기반 ASR 연구를 다룹니다. 검색 전략은 Scopus와 Web of Science 데이터베이스에서 "(ASR || NLP) & (DTL || DRL || FL || Transformers)" 키워드 쿼리를 사용하여 관련 논문을 식별했습니다. 포함 기준은 ASR 분야의 혁신 수준, 연구의 품질, 제시된 기여 및 발견을 기반으로 합니다.

설문조사에서 다루는 주요 고급 DL 방법론은 다음과 같습니다:

- **트랜스포머(Transformers):** NLP, 컴퓨터 비전(CV), 음성 처리 등 다양한 분야에서 사용되는 DL 모델로, 입력 시퀀스의 광범위한 종속성을 포착하기 위해 **자기 주의(self-attention)** 메커니즘에 크게 의존합니다. ASR에서 AM 및 LM 모두에 적용됩니다.
  - 수식: $\text{Attention}(Q, K, V) = \text{softmax} \left( \frac{QK^T}{\sqrt{D_k}} \right) V$
- **심층 전이 학습(DTL):** 한 도메인 또는 작업에서 사전 훈련된 모델(소스 모델)에서 얻은 지식을 활용하여 다른 관련 도메인 또는 작업에서 대상 모델의 성능을 향상시키는 패러다임입니다. **도메인 적응(DA)**, **미세 조정(Fine-tuning)**, **교차 도메인 학습(Cross-domain learning)** 등을 포함합니다.
- **연합 학습(FL):** 민감한 훈련 데이터를 공유할 필요 없이 분산된 에지 장치(예: 모바일 폰)에서 AI 모델을 공동으로 훈련할 수 있게 하는 패러다임입니다.
  - 목적 함수: $\min_{\theta} F(\theta) = \min_{\theta} \sum_{k=1}^{K} \frac{n_k}{N} F_k(\theta)$
  - **수평 연합 학습(HFL)**: 동일한 특징 공간을 공유하지만 샘플 공간이 다른 데이터셋을 사용합니다.
  - **수직 연합 학습(VFL)**: 동일한 샘플 공간을 공유하지만 특징 공간이 다른 데이터셋을 사용합니다.
- **심층 강화 학습(DRL):** 에이전트가 환경과 상호작용하며 보상 또는 페널티 형태의 피드백을 받아 행동을 최적화하는 머신러닝 패러다임입니다. 이는 훈련(크로스 엔트로피, 교사 강요)과 테스트(WER) 간의 불일치를 해결하는 데 사용됩니다.
  - 정책 최적화: $\pi^* = \max_{\pi} \mathbb{E}_{\pi} \left[ \sum_{t=0}^{T} \gamma^t r_t(s_t, \pi(s_t)) \right]$

## 📊 Results

이 설문조사에서 검토된 고급 DL 기술들은 ASR 분야에서 다음과 같은 중요한 개선을 보여주었습니다.

- **트랜스포머:** WER 및 CER 감소, 실시간 요소(RTF) 향상 등 SOTA 성능을 달성하며 다양한 ASR 작업에서 음향 및 언어 모델링 능력을 크게 향상시켰습니다.
- **DTL:** 데이터 부족 문제를 해결하고, 특히 저자원 언어, 어린이 음성, 다중 방언 인식과 같은 영역에서 모델의 일반화 능력을 높여 WER과 CER을 줄였습니다.
- **FL:** 민감한 데이터를 공유하지 않고도 ASR 모델을 훈련할 수 있게 하여 데이터 프라이버시를 보호하고, 비동일 독립 분포(non-IID) 데이터 환경에서도 WER 감소를 시연했습니다.
- **DRL:** ASR 모델의 훈련과 테스트 간의 목표 불일치(예: 교차 엔트로피와 WER)를 해결하며 WER을 줄이고 모델 압축률을 높이는 데 효과적인 것으로 나타났습니다.
  이러한 기술들은 ASR 시스템의 견고성, 유연성 및 동적 환경에서의 성능을 전반적으로 향상시켰습니다.

## 🧠 Insights & Discussion

**주요 통찰력 및 한계:**

- **트랜스포머:** 장문 오디오 시퀀스 처리 시 높은 메모리 및 계산 자원 요구, 음성 변동성(억양, 소음)에 대한 견고성 부족, 저자원 언어의 어려움, 모델 해석 가능성 부족이 과제로 남아 있습니다.
- **DTL 및 DA:** 도메인 이동(distribution shift), 특징 공간 적응, 레이블 분포 이동, 치명적인 망각(catastrophic forgetting), 도메인 불변 특징 학습, 샘플 선택 편향, 하이퍼파라미터 최적화 문제가 있습니다.
- **FL:** 이질적인(non-IID) 데이터 분포, 높은 통신 오버헤드, 모델 업데이트를 통한 사생활 유출 가능성, 개인화와 일반적인 모델 성능의 균형 유지, 대규모 장치 네트워크에서의 확장성 문제가 존재합니다.
- **DRL:** 희소하고 지연된 보상, 탐색-활용(exploration-exploitation) 균형, 대량의 훈련 데이터 요구, 기존 지도 학습 시스템과의 통합, 사용자 프라이버시, 적절한 보상 함수 설계, 다양한 환경 조건에 대한 적응 문제가 있습니다.

**미래 연구 방향:**

- **개인화된 데이터 증강:** 발음 장애가 있거나 노인 사용자를 위한 ASR 시스템의 정확도를 향상시키기 위해 이들의 고유한 음성 패턴을 시뮬레이션하고 훈련 데이터에 통합하는 연구가 필요합니다.
- **멀티태스크 학습(MTL) for ASR:** 여러 관련 학습 작업을 동시에 활용하여 ASR 모델의 일반화 능력과 견고성을 향상시키는 연구가 중요합니다.
- **연합 멀티태스크 학습(FMTL) 및 증류(distillation) for ASR:** 데이터 프라이버스를 유지하면서 ASR 시스템의 개인화 및 보안을 강화하고, 에지 장치를 위한 효율적인 모델 압축 기술을 개발하는 연구가 필요합니다.
- **최신 DRL 기술 for ASR:** 점진적 DRL(incremental DRL) 접근 방식 및 DDQN, Actor-Critic, DDPG 등과 같은 다양한 DRL 서브카테고리를 탐색하여 DTL 방법론을 강화하는 연구가 제안됩니다.
- **온라인 DTL:** 새로운 작업이나 데이터 스트림에 실시간으로 적응할 수 있는 모델을 개발하여 동적 환경에서의 성능을 최적화하는 데 중점을 둡니다.
- **트랜스포머 및 대규모 언어 모델(LLM) 기반 ASR:** 트랜스포머 기반 모델 내에서 AM 및 LM 도메인에 DRL 및 FL과 같은 고급 AI 기술을 통합하고, LLM을 ASR에 활용하는 방법을 더욱 탐구해야 합니다.

## 📌 TL;DR

**문제:** 기존 ASR은 방대한 기밀 데이터와 상당한 컴퓨팅 자원을 필요로 하며, 훈련 및 테스트 데이터의 도메인 불일치로 인해 동적 환경에서 성능이 저하되는 한계가 있습니다.

**해결책 (설문조사 대상):** 이 논문은 이러한 과제를 해결하기 위한 고급 딥러닝 접근 방식인 **트랜스포머(Transformers)** (강력한 시퀀스 모델링), **심층 전이 학습(DTL)** (데이터 희소성 및 도메인 적응), **연합 학습(FL)** (데이터 프라이버시 및 분산 데이터), **심층 강화 학습(DRL)** (동적 의사 결정 최적화)을 포괄적으로 검토합니다.

**핵심 발견:** 이 기술들은 ASR 성능을 크게 향상시키고, 데이터 부족 문제를 해결하며, 프라이버시를 보호하고, 시스템의 적응력을 높이는 데 기여합니다. 그러나 계산 효율성, 데이터 이질성, 보상 함수 설계, 실제 환경에서의 원활한 통합 등 여전히 중요한 과제가 남아있습니다. 미래 연구는 개인화된 데이터 증강, 멀티태스크 학습, 온라인 적응 및 LLM과의 통합에 초점을 맞출 것을 제안합니다.
