# "Help Me Help the AI": Understanding How Explainability Can Support Human-AI Interaction

Sunnie S. Y. Kim, Elizabeth Anne Watkins, Olga Russakovsky, Ruth Fong, Andrés Monroy-Hernández

## 🧩 Problem to Solve

설명 가능한 인공지능(XAI) 방법론이 확산되고 있음에도 불구하고, 최종 사용자의 설명 가능성에 대한 실제 요구사항과 XAI 설명을 둘러싼 행동에 대해서는 거의 알려져 있지 않습니다. 본 연구는 이러한 간극을 해결하고, 설명 가능성이 인간-AI 상호작용을 어떻게 지원할 수 있는지 이해하기 위해 다음 세 가지 연구 질문에 답하고자 합니다:

- RQ1: 실제 AI 애플리케이션에서 최종 사용자의 XAI 요구사항은 무엇인가?
- RQ2: 최종 사용자는 XAI 설명을 어떻게 활용하려고 하는가?
- RQ3: 기존 XAI 접근 방식에 대해 최종 사용자는 어떻게 인식하는가?

## ✨ Key Contributions

- **다양한 XAI 요구사항**: 참가자들은 AI 시스템의 세부 사항에 대해 일반적으로 궁금해했지만, 특히 AI 배경 지식이 높거나 조류 관찰에 대한 관심이 높은 사용자일수록 XAI 요구사항이 더 높았습니다. 그러나 모든 참가자는 AI와의 협업을 개선할 수 있는 실용적인 정보가 필요하다고 입을 모았습니다.
- **XAI 활용 목적의 확장**: 참가자들은 AI 출력물을 이해하는 것을 넘어, AI에 대한 신뢰를 조정하고, 스스로 작업 기술을 향상시키며, AI에 더 나은 입력값을 제공하기 위해 자신의 행동을 변화시키고, 개발자에게 건설적인 피드백을 제공하는 등 다양한 목적으로 XAI 설명을 사용하고자 했습니다.
- **선호하는 XAI 접근 방식**: 기존 XAI 접근 방식 중, 참가자들은 인간의 추론 및 설명 방식과 유사하며 가장 유용하다고 판단한 부분 기반 설명, 즉 개념(Concept) 기반 및 프로토타입(Prototype) 기반 설명을 선호했습니다.

## 📎 Related Works

- **알고리즘 중심 XAI에서 인간 중심 XAI로의 전환**: XAI 연구의 초기 노력은 주로 AI 시스템의 내부 작동과 출력 설명을 제공하는 알고리즘 자체에 집중되었으나, 최근에는 특정 맥락에서 사람들의 요구를 이해하는 "인간 중심 XAI(human-centered XAI)"의 중요성이 강조되고 있습니다.
- **최종 사용자의 XAI 요구 이해**: 기존 연구는 주로 AI 개발자에게 초점을 맞추거나 가상의/프로토타입 AI 애플리케이션에서 최종 사용자의 XAI 요구를 탐색했습니다. 본 연구는 실생활 AI 애플리케이션인 'Merlin'을 통해 실제 최종 사용자의 요구를 심층적으로 탐구합니다.
- **인간-AI 협업에서 XAI의 역할**: XAI는 AI 지원 의사결정에서 신뢰 조정과 같은 특정 용도로 주로 연구되어 왔습니다. 본 연구는 XAI가 단순한 의사결정 지원을 넘어, 사용자가 AI와 더 효과적으로 협력하여 공동의 목표를 달성하는 매개체가 될 수 있음을 보여줍니다.
- **컴퓨터 비전을 위한 XAI 방법론**: Heatmap, Example, Concept, Prototype 기반 설명과 같은 다양한 컴퓨터 비전 XAI 방법론들이 존재하며, 본 연구는 이러한 방법론들을 Merlin 앱에 적용하여 사용자의 인식을 평가했습니다.

## 🛠️ Methodology

- **연구 대상 및 모집**: 실제 AI 애플리케이션인 'Merlin' 조류 식별 앱의 최종 사용자 $20$명을 대상으로 혼합 방법론 연구를 수행했습니다. 참가자는 조류 관찰 및 AI 배경 지식 수준(낮음-중간-높음)에 따라 다양하게 선정되었습니다.
- **데이터 수집**:
  - **맥락**: 참가자의 앱 사용 배경, 목적, AI에 대한 지식 및 인식에 대한 질문으로 인터뷰 시작.
  - **XAI 요구사항**: Liao et al.의 XAI 질문 은행($10$개 카테고리)을 기반으로 개발된 설문조사와 개방형 질문을 통해 참가자들이 AI 시스템에 대해 알고 싶어 하는 것과 궁금해하는 것을 파악.
  - **XAI 사용 및 인식**: Merlin Photo ID의 실제 식별 예시 ($3$개: 정확한 식별, 사람도 실수할 법한 오인식, 사람이 하지 않을 법한 오인식)를 활용하여 다음 네 가지 XAI 접근 방식의 목업을 순차적으로 무작위 순서로 제시:
    - **Heatmap 기반 설명**: AI 모델이 출력에 중요하다고 판단한 이미지 영역을 강조.
    - **Example 기반 설명**: AI 모델이 입력 사진과 가장 유사하다고 판단한 학습 데이터 내의 예시 사진들을 제시.
    - **Concept 기반 설명**: AI 모델이 특정 출력에 대해 긍정적/부정적 증거로 간주한 텍스트 기반 개념들을 제시.
    - **Prototype 기반 설명**: AI 모델이 입력 사진의 특정 영역을 이전에 본 새 사진의 프로토타입(시각적 부분)과 유사하다고 판단한 것을 박스로 표시하여 제시.
- **데이터 분석**: 인터뷰 녹취록을 전사한 후, 서술적 코딩과 개념적 테마 식별을 통해 참가자들의 XAI 요구, 사용 의도, 각 접근 방식에 대한 인식을 분석했습니다.

## 📊 Results

- **XAI 요구사항**:
  - 참가자들은 AI 시스템 세부 사항에 대한 일반적인 호기심을 보였으나, 실제로 정보를 찾아 나설 의지는 AI 배경 지식과 조류 관찰 관심도에 따라 달랐습니다.
  - 모든 참가자는 AI의 능력과 한계에 대한 이해, AI의 신뢰도(예: 퍼센트 기반 신뢰 점수) 표시, 그리고 AI의 판단을 검증하는 데 도움이 되는 상세한 출력(예: 특정 조류 소리가 발생한 시간대 강조)과 같이 AI와의 협업을 개선할 수 있는 실용적인 정보를 원했습니다.
- **XAI 활용 의도**: 참가자들은 XAI 설명을 다음 네 가지 목적으로 사용하고자 했습니다.
  - **AI 신뢰 조정**: 히트맵이 "올바른 것"을 보거나 예시가 입력과 유사하면 신뢰 증가, 중요하지 않은 부분이 강조되거나 개념 인식 오류가 있을 때 신뢰 감소.
  - **스스로 작업 능력 향상**: AI를 '교사'로 인식하고, AI가 보는 특징을 학습하여 스스로 조류를 식별하는 기술을 향상시키고자 함.
  - **더 나은 AI 협력자 되기**: AI에 더 나은 입력값을 제공하기 위해 설명으로부터 자신의 행동에 대한 피드백을 얻고자 함 ("AI를 돕기 위해 나는 무엇을 해야 하는가?").
  - **개발자에게 피드백 제공**: 특히 AI 배경 지식이 높은 참가자들은 설명을 통해 AI의 출력 과정에 대한 정보를 얻어, 개발자에게 더 상세한 피드백을 제공하고 AI 개선에 기여할 의사를 밝혔습니다.
- **XAI 접근 방식에 대한 인식**:
  - **Heatmap 기반 설명**: 가장 의견이 엇갈렸습니다. 직관적이고 시각적으로 매력적이라는 평도 있었으나, 너무 거칠고 정보가 부족하다("그냥 새를 강조할 뿐이다"), "왜" 특정 부분이 중요한지 설명하지 못하며, 실행 가능한 정보가 없다는 비판이 많았습니다.
  - **Example 기반 설명**: 매우 이해하기 쉽다고 평가되었으나, AI가 입력과 무엇을 유사하다고 판단하는지 구체적인 정보가 부족하여 "정보성이 떨어진다"는 의견이 많았습니다.
  - **Concept 기반 설명**: 전반적으로 긍정적인 평가를 받았습니다. 인간의 추론 방식과 유사하게 개념 단위로 정보를 제공한다는 점, 조류 식별 교육 방식과 유사하다는 점에서 호평을 받았습니다. 하지만 제시된 개념들이 너무 일반적이며($P_1, P_4, P_5, P_{10}$), 수치($1.7$이 좋은 수치인지 등)가 혼란스러울 수 있다는 지적도 있었습니다. 일부는 숫자가 많아 압도당하는 느낌을 받았습니다($P_5, P_{13}, P_{16}, P_{20}$).
  - **Prototype 기반 설명**: 가장 선호되었습니다($P_2, P_3, P_4, P_6, P_7, P_9, P_{10}, P_{12}, P_{13}, P_{15}, P_{16}, P_{17}, P_{19}, P_{20}$). 시각적 특성과 부분 기반 형태가 인간의 사고방식 및 조류 식별 교육 방식과 유사하다는 점이 장점으로 꼽혔습니다. 학습, AI 이해, 오류 발견, 더 나은 입력 제공 등 다양한 용도에 유용하다고 평가되었습니다. "클러터(cluttered)"하거나 일부 프로토타입이 모호하고 흥미롭지 않다는($P_1, P_{13}, P_{18}$, 예: 새의 발) 단점도 지적되었습니다.

## 🧠 Insights & Discussion

- **인간-AI 협업 개선을 위한 XAI**: 참가자들은 XAI 설명을 통해 AI 시스템과의 협업을 개선하고 싶어 했습니다. 이는 단순히 AI의 출력을 이해하는 것을 넘어, 사용자가 AI에 더 나은 입력값을 제공하고 개발자에게 건설적인 피드백을 주어 궁극적으로 더 나은 결과를 함께 달성하는 것을 의미합니다. XAI는 기술적 투명성을 넘어, 사용자에게 **실행 가능한 피드백(actionable feedback)**을 제공하여 인간-AI 상호작용을 풍부하게 만드는 매개체가 되어야 합니다.
- **Merlin을 위한 XAI 디자인 제안**: 참가자들의 선호도와 피드백을 바탕으로, 프로토타입 기반 설명과 개념 기반 설명을 결합하는 디자인을 제안합니다. 사용자의 입력 사진에 프로토타입 매칭 영역을 박스로 표시하고, 각 박스를 탭하면 해당 프로토타입에 대한 짧은 개념 설명(예: "접힌 날개에 흰색 줄무늬")을 제공하는 방식입니다. 불필요하거나 흥미롭지 않은 프로토타입은 전문가 및 사용자와 협력하여 선별하고, 상세 수치는 선택 사항으로 제공하여 정보 과부하를 피하는 것이 중요합니다.
- **미래 XAI 연구에 대한 시사점**:
  1. **최종 사용자와 함께 설계**: XAI 연구의 '창작자-소비자' 간극을 줄이기 위해, 설명 디자인 과정에 최종 사용자를 참여시키는 참여형 접근 방식이 필요합니다.
  2. **"무엇을" 넘어 "왜"에 답하는 설명**: AI가 어떤 특징을 사용하는지($What$)를 넘어, "왜" 특정 특징이 중요한지에 대한 인과적 관계를 설명하는 XAI 연구가 필요합니다.
  3. **다중 형태 및 모달리티 활용**: 정보 전달력을 높이기 위해 여러 XAI 접근 방식(예: 프로토타입 + 개념)을 결합하고, 인간 조류 관찰자처럼 다중 모달 정보(사진, 소리, 위치)를 활용하는 설명 디자인을 고려해야 합니다.
  4. **엄격한 평가**: XAI 설명이 AI에 대한 과도한 신뢰나 오해와 같은 의도치 않은 부정적인 영향을 미칠 수 있으므로, 개발 과정 전반에 걸쳐 방법론적 목표와 사용 사례 목표를 모두 고려한 엄격한 평가가 필수적입니다.

## 📌 TL;DR

본 연구는 AI 최종 사용자의 XAI 요구사항과 활용 방식을 탐구하기 위해 Merlin 조류 식별 앱 사용자 $20$명을 대상으로 심층 연구를 수행했습니다. 결과적으로, 사용자들은 AI 시스템 세부 사항에 대한 호기심을 넘어, AI와의 협업을 개선하고 더 나은 결과를 얻기 위한 **실용적이고 실행 가능한 정보**를 XAI 설명을 통해 얻고자 했습니다. 특히 **인간의 추론 방식과 유사한 시각적 부분 기반 설명(프로토타입 및 개념 기반 설명)**을 가장 선호했으며, XAI가 신뢰 조정, 학습, AI에 대한 더 나은 입력 제공, 개발자 피드백과 같은 다양한 목적으로 활용될 수 있음을 밝혔습니다. 이는 XAI 연구가 알고리즘 중심에서 벗어나 사용자 중심의 협력 증진 도구로 발전해야 함을 시사합니다.
