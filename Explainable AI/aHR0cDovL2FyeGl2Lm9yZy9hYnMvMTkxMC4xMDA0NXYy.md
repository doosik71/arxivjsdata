# Explainable Artificial Intelligence (XAI): Concepts, Taxonomies, Opportunities and Challenges toward Responsible AI

Alejandro Barredo Arrieta, Natalia Díaz-Rodríguez, Javier Del Ser, Adrien Bennetot, Siham Tabik, Alberto Barbado, Salvador Garcia, Sergio Gil-Lopez, Daniel Molina, Richard Benjamins, Raja Chatila, and Francisco Herrera

## 🧩 Problem to Solve

최근 인공지능(AI)은 딥러닝(Deep Learning, DL)과 같은 비심볼릭(sub-symbolic) 기술의 발전으로 뛰어난 성능을 보이지만, 그 작동 방식이 '블랙박스(black-box)'처럼 불투명하여 의사결정 과정을 이해하고 신뢰하기 어렵다는 본질적인 문제가 있습니다. 이는 의료, 법률, 금융 등 사람의 삶에 중요한 영향을 미치는 분야에서 AI 모델의 실질적인 배포와 책임 있는 사용을 가로막는 주요 장벽이 됩니다. 이러한 불투명성은 공정성, 개인 정보 보호, 책임성 등 윤리적 문제를 야기하며, 인간이 AI 시스템을 적절히 신뢰하고 효과적으로 관리하는 데 어려움을 줍니다.

## ✨ Key Contributions

- **새로운 설명 가능성(explainability) 정의 제안**: 특정 '청중(audience)'을 핵심 요소로 고려하여 ML 모델의 작동 방식을 명확하고 이해하기 쉽게 만드는 상세 정보 및 이유를 의미합니다. 신뢰성, 인과성, 전이성, 정보성, 공정성, 개인 정보 보호 등 다양한 목적을 포괄합니다.
- **ML 모델의 투명성(transparency) 수준 및 사후 설명(post-hoc explainability) 분석**: 모델이 본질적으로 이해 가능한 정도를 나타내는 투명성 수준(시뮬레이션 가능성, 분해 가능성, 알고리즘적 투명성)과, 불투명한 모델을 설명하기 위한 사후 접근 방식(텍스트, 시각화, 국소 설명, 예시 기반, 단순화, 특징 중요도)에 대한 정의와 심층 분석을 제공합니다.
- **XAI 문헌에 대한 포괄적 분류 체계(taxonomy) 구축**: 약 400여 편의 기존 XAI 문헌을 분석하여 ML 모델(투명 모델, 얕은 학습, 딥러닝) 및 딥러닝 모델에 특화된 두 가지 분류 체계를 구축하고 상세히 검토합니다.
- **XAI 분야의 도전 과제 제시**: 설명 가능성 평가를 위한 개념 및 지표의 부족, 딥러닝 모델의 이해도 향상 방안, 데이터 융합(data fusion) 맥락에서의 기밀성, 적대적 설정에서의 견고성, 데이터 다양성 등 XAI가 직면한 다양한 연구 과제를 식별합니다.
- **'책임 있는 AI(Responsible Artificial Intelligence)' 개념 제안**: 모델 설명 가능성을 넘어, 공정성(fairness), 책임성(accountability), 개인 정보 보호(privacy)를 핵심으로 하는 통합적인 AI 윤리 원칙을 제안하고 이를 실질적으로 구현하기 위한 방법론을 탐구합니다.
- **데이터 융합 환경에서의 XAI 영향 분석**: 데이터 융합 패러다임 하에서 XAI 기법이 개인 정보 보호 및 보안에 미치는 잠재적 영향(위협 및 기회)에 대해 심층적으로 성찰합니다.

## 📎 Related Works

- **D. Gunning의 XAI 정의 [7]**: "XAI는 인간 사용자가 새로 등장하는 인공지능 파트너를 이해하고, 적절히 신뢰하며, 효과적으로 관리할 수 있도록 하는 머신러닝 기술들을 창조할 것이다."
- **Z. C. Lipton의 모델 해석 가능성 신화 [5]**: 모델 해석 가능성의 개념과 복잡성에 대한 비판적 시각을 제공하며, 투명성과 해석 가능성 사이의 미묘한 차이를 강조합니다.
- **T. Miller의 사회 과학에서 얻은 설명에 대한 통찰 [12]**: 인간이 설명을 어떻게 이해하고 받아들이는지에 대한 사회 과학적 관점을 XAI에 통합할 필요성을 강조합니다.
- **R. Guidotti 외의 블랙박스 모델 설명 방법론 조사 [17]**: 투명한 모델 설계와 블랙박스 모델 설명 문제 해결 방법을 구분하여 XAI 기법을 분류합니다.
- **M. T. Ribeiro 외의 LIME [32]**: 모델에 구애받지 않는(model-agnostic) 지역 해석 가능한 설명(local interpretable explanations)을 제공하는 대표적인 사후 설명 기법으로 널리 인용됩니다.

## 🛠️ Methodology

이 논문은 XAI 분야에 대한 종합적인 문헌 검토 및 개념 분석을 통해 다음 단계를 수행했습니다.

1. **용어 및 개념 명확화**: 설명 가능성(explainability), 해석 가능성(interpretability), 이해 가능성(understandability), 투명성(transparency) 등 XAI 관련 핵심 용어들을 명확히 구분하고 정의를 재정립합니다. 특히 '청중(audience)' 중심의 새로운 설명 가능성 정의를 제안합니다.
2. **XAI 목표 분석**: 설명 가능한 AI 모델을 추구하는 다양한 목표(신뢰성, 인과성, 전이성, 정보성, 공정성, 개인 정보 보호 등)를 식별하고 분류합니다.
3. **ML 모델 투명성 수준 분류**: ML 모델을 투명성 정도에 따라 시뮬레이션 가능($Simulatability$), 분해 가능($Decomposability$), 알고리즘적 투명($Algorithmic\ Transparency$)한 세 가지 수준으로 나눕니다.
4. **XAI 기술 분류 및 문헌 검토**:
   - **일반 ML 모델을 위한 XAI 분류**: 본질적으로 투명한 ML 모델(선형/로지스틱 회귀, 의사결정 트리, K-최근접 이웃, 규칙 기반 학습기, 일반화 가법 모델, 베이즈 모델)과 사후 설명 기술(텍스트 설명, 시각적 설명, 국소 설명, 예시 기반 설명, 단순화 기반 설명, 특징 중요도 설명)로 나눕니다.
   - **딥러닝 모델을 위한 XAI 분류**: 심층 신경망(MLNN), 컨볼루션 신경망(CNN), 순환 신경망(RNN)에 특화된 사후 설명 기법을 심층적으로 검토하고, 계층별 설명, 표현 벡터, 어텐션 메커니즘 등 딥러닝 고유의 분류 기준을 포함하는 두 번째 분류 체계를 제시합니다.
   - **하이브리드 접근 방식 분석**: 투명 모델과 블랙박스 모델을 결합하거나 지식 기반(KB)을 활용하는 하이브리드 XAI 모델을 탐구합니다.
5. **기회, 도전 과제 및 미래 연구 방향 식별**: 해석 가능성과 성능 간의 트레이드오프, XAI 개념 및 지표의 필요성, 딥러닝 설명 가능성의 도전 과제, AI 보안, 출력 신뢰도, 비판적 데이터 연구, 이론 기반 데이터 과학과의 연계성, 해석 가능한 AI 모델을 위한 가이드라인 등을 논의합니다.
6. **'책임 있는 AI' 프레임워크 제안**: 설명 가능성을 포함하여 공정성, 개인 정보 보호, 책임성 등 AI 윤리 원칙을 포괄하는 '책임 있는 AI'의 개념을 제시하고, 데이터 융합 환경에서의 XAI 역할과 의미를 탐구합니다.

## 📊 Results

- **설명 가능성의 새로운 정의**: 특정 **청중(audience)** 에 초점을 맞춰 모델의 작동 방식을 명확하고 쉽게 이해할 수 있도록 제공하는 **세부 정보 및 이유**로 정의되었습니다.
- **ML 모델의 투명성 수준**:
  - **시뮬레이션 가능성($Simulatability$)**: 인간이 직접 모델의 전체 작동을 시뮬레이션하고 추론할 수 있는 능력.
  - **분해 가능성($Decomposability$)**: 모델의 각 부분(입력, 파라미터, 계산)이 독립적으로 이해될 수 있는 능력.
  - **알고리즘적 투명성($Algorithmic\ Transparency$)**: 모델이 입력에서 출력을 생성하는 과정이 수학적 분석을 통해 완전히 탐색될 수 있는 능력.
- **주요 ML 모델의 설명 가능성 특성 분류**:
  - **투명한 모델**: 선형/로지스틱 회귀, 의사결정 트리, K-최근접 이웃, 규칙 기반 학습기, 일반화 가법 모델(GAM), 베이즈 모델 등은 본질적으로 높은 수준의 투명성을 가집니다.
  - **블랙박스 모델 (사후 설명 필요)**: 트리 앙상블, 서포트 벡터 머신(SVM), 다층 신경망(MLNN), 컨볼루션 신경망(CNN), 순환 신경망(RNN) 등은 본질적으로 불투명하여 사후 설명 기법이 필수적입니다.
- **사후 설명 기법의 범주**:
  - **모델-불가지론적(Model-agnostic)**: 모델 단순화(예: LIME, G-REX), 특징 중요도(예: SHAP), 시각화(예: ICE 플롯)
  - **모델-특정적(Model-specific)**: 앙상블, SVM, MLNN, CNN, RNN에 특화된 단순화, 특징 중요도, 국소 설명, 예시 기반 설명, 텍스트 설명, 시각화, 아키텍처 수정 기법 등이 제시됩니다. 특히 딥러닝에서는 활성화 매핑, 주의 메커니즘, 계층별 분석 등이 활용됩니다.
- **딥러닝 설명 가능성을 위한 대체 분류 체계**: 네트워크 처리 설명, 네트워크 표현 설명, 설명 생성 시스템, 하이브리드 투명/블랙박스 방법으로 세분화됩니다.
- **XAI의 도전 과제 및 기회**: 해석 가능성과 성능 간의 균형점 탐색, XAI 개념 및 평가 지표 표준화의 필요성, 딥러닝 설명에서의 용어 통일 및 객관적 평가, AI 보안 및 적대적 ML, 모델 출력 신뢰도, 비판적 데이터 연구, 이론 기반 데이터 과학과의 시너지 등을 제시합니다.
- **책임 있는 AI (Responsible AI) 프레임워크**: 설명 가능성뿐만 아니라 공정성, 개인 정보 보호 및 보안, 책임성 등을 포함하는 포괄적인 AI 윤리 원칙들을 통합한 방법론을 제안합니다. 데이터 융합 맥락에서 XAI가 개인 정보 보호에 미칠 수 있는 잠재적 위협과 기회를 강조합니다.

## 🧠 Insights & Discussion

- **해석 가능성과 성능 간의 트레이드오프 완화**: XAI의 발전은 모델 성능 저하 없이 해석 가능성을 향상시킬 수 있는 잠재력을 보여주며, 이 균형점을 찾는 것이 중요합니다.
- **XAI 개념 및 평가 지표의 표준화 필요성**: XAI 분야의 성장을 위해 설명 가능성에 대한 통일된 개념 정의와 객관적인 평가 지표 개발이 시급하며, 이는 사회 과학적 통찰을 통해 인간의 이해 방식을 반영해야 합니다.
- **딥러닝 설명 가능성의 고유한 도전 과제**: 용어 불일치, 주관적 평가 문제, 확률적 결과를 인과적 연결이 포함된 질적 개념으로 전환하는 어려움 등이 있습니다. 신경-심볼릭 시스템의 통합이 유망한 해결책으로 제시됩니다.
- **XAI와 AI 보안 및 개인 정보 보호의 교차점**: XAI 기술은 모델의 내부 지식을 드러내어 적대적 공격에 악용될 수 있는 동시에, 개인 정보 노출을 방지하는 데도 사용될 수 있습니다. 특히 데이터 융합 환경에서는 민감한 정보가 유추될 위험이 커지므로, XAI 활용 시 개인 정보 보호에 대한 신중한 접근이 필요합니다.
- **책임 있는 AI (Responsible AI)의 중요성**: XAI는 공정성, 개인 정보 보호, 책임성 등 광범위한 AI 윤리 원칙의 핵심 구성 요소입니다. AI 시스템의 윤리적이고 실질적인 구현을 위해서는 기술 개발 초기부터 이러한 원칙들을 통합적으로 고려하는 '책임 있는 AI' 방법론이 필수적입니다.
- **XAI와 새로운 데이터 과학 패러다임의 시너지**: XAI는 이론 기반 데이터 과학(Theory-guided Data Science)과 비판적 데이터 연구(Critical Data Studies)와 같은 새로운 패러다임과 시너지를 낼 수 있으며, 모델이 학습한 지식이 사전 지식 및 이론적 원칙과 일치하는지 평가하고 다양한 이해관계자에게 AI 모델의 의사결정 과정을 효과적으로 설명하는 데 기여합니다.

## 📌 TL;DR

이 논문은 현대 AI, 특히 딥러닝의 **블랙박스 문제**를 해결하기 위한 **설명 가능한 AI (XAI)의 개념, 분류, 기회 및 도전 과제**를 포괄적으로 분석합니다. **청중 중심의 설명 가능성 정의**를 제시하고, ML 모델의 **투명성 수준과 사후 설명 기법**에 대한 상세한 분류 체계를 제안합니다. 주요 내용은 **XAI 문헌에 대한 두 가지 포괄적인 분류** (일반 ML 모델, 딥러닝 모델)와 함께, **XAI가 직면한 개념적/평가적 도전 과제, AI 보안, 데이터 융합과의 상호작용** 등을 깊이 있게 다룹니다. 궁극적으로 **공정성, 개인 정보 보호, 책임성**을 XAI와 통합한 **'책임 있는 AI' 프레임워크**를 제시하며, AI의 윤리적이고 실질적인 구현을 위한 필수 원칙들을 강조합니다.
