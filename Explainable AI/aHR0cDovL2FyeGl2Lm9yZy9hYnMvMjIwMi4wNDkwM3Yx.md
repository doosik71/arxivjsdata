# Investigating Explainability of Generative AI for Code through Scenario-based Design

Jiao Sun, Q. Vera Liao, Michael Muller, Mayank Agarwal, Stephanie Houde, Kartik Talamadupula, and Justin D. Weisz

## 🧩 Problem to Solve

최근 생성형 AI(GenAI) 기술이 소프트웨어 엔지니어링 분야에 적용되며 빠르게 발전하고 있지만, 의사결정(decision)이 아닌 산출물(artifacts)을 생성하는 모델에 대한 설명 가능성(explainability) 연구는 부족한 실정입니다. 이 연구는 코드 생성을 위한 생성형 AI 모델에 대한 사용자 설명 가능성 요구사항이 무엇인지, 그리고 사용자가 AI 시스템을 효과적으로 이해하고 목표를 달성하기 위해 어떤 정보를 필요로 하는지에 대한 근본적인 이해를 구축하는 것을 목표로 합니다.

## ✨ Key Contributions

- 코드 생성형 AI(GenAI for Code) 환경에서 소프트웨어 엔지니어의 설명 가능성 요구사항 11가지 범주를 식별하고 정의 및 예시를 제시했습니다. 특히, 판별형 ML(Discriminative ML) 모델과 차별화되는 GenAI 및 코드 생성 사용 사례에 고유한 요구사항들을 강조했습니다.
- 선행 연구를 바탕으로 코드 생성형 AI 사용자를 지원하기 위한 4가지 XAI(Explainable AI) 기능 유형(AI 문서화, 모델 불확실성 지표, 모델 어텐션 시각화, 사회적 투명성)을 제안하고, 참가자들의 피드백을 통해 이를 구체적으로 구현하기 위한 설계 권장사항을 도출했습니다.
- 시나리오 기반 설계, 참여형 디자인 워크숍, 질문 중심 접근 방식을 결합하여 설명 가능성 요구사항을 도출하는 방법론적 기여를 했습니다. 이를 통해 새로운 영역에서 GenAI 탐색에 대한 향후 연구에 중요한 통찰을 제공합니다.

## 📎 Related Works

- **코드 생성형 AI (GenAI for Code)**: 자연어 가설(naturalness hypothesis)을 기반으로 NLP 기술을 프로그래밍 언어에 적용한 연구들(예: TransCoder, GitHub Copilot, Codex)을 참조하여, 코드 자동 완성, 코드 번역, 자연어-코드 변환 등의 사용 사례를 정의했습니다.
- **설명 가능한 AI (Explainable AI, XAI)**: 판별형 ML 모델을 위한 다양한 XAI 기술(직접 해석 가능한 모델, 사후 설명)과 더불어, 생성 모델의 해석 가능성을 높이는 연구(예: 잠재 공간의 의미 부여, 어텐션 메커니즘 시각화, 인간 중심 XAI)를 배경으로 삼았습니다.
- **인간 중심 AI (Human-centered approaches to AI)**: AI 시스템이 인간의 필요에 부응하고 가치에 부합하도록 설계하는 접근 방식(예: 참여형 머신러닝, 시나리오 기반 설계)을 방법론적 토대로 활용했습니다.

## 🛠️ Methodology

이 연구는 9개의 워크숍을 통해 43명의 소프트웨어 엔지니어와 함께 진행되었으며, 원격 화상 회의 도구와 가상 협업 도구 Mural을 활용했습니다.

1. **사용 사례 및 시나리오**:

   - **코드 번역 (Code Translation)**: 한 언어(예: Java)의 소스 코드를 다른 언어(예: Python)로 번역.
   - **코드 자동 완성 (Code Autocompletion)**: 주석 및 소스 코드를 입력받아 코드 생성.
   - **자연어-코드 변환 (Natural Language to Code)**: 자연어 설명을 코드로 변환.
   - 각 사용 사례별로 "Alex"라는 가상 인물과 실제 GenAI 모델(TransCoder, Copilot)이 생성한 코드 예시가 포함된 현실적인 프로그래밍 작업 시나리오를 구성했습니다.

2. **워크숍 진행**:

   - **1단계: 질문 도출 연습**: 시나리오를 제시한 후, 참가자들에게 Alex의 입장에서 GenAI 모델에 대해 알고 싶은 질문들을 자유롭게 작성하도록 했습니다. 이후 유사한 질문들을 클러스터링하고, 가장 중요하다고 생각하는 질문에 투표한 후 토론했습니다.
   - **2단계: XAI 기능에 대한 아이디어 도출**: 다음 4가지 XAI 기능 유형에 대한 디자인 프로브(저수준 UI 목업)를 제시하고, 참가자들의 피드백과 설계 아이디어를 수집했습니다.
     - **AI 문서화 (AI Documentation)**: 모델의 목적, 성능, 안전성, 출처 등에 대한 정보를 제공.
     - **불확실성 지표 (Uncertainty Indicator)**: AI가 생성한 코드 라인별 불확실성 수준을 물결선 등으로 시각화.
     - **어텐션 시각화 (Attention Visualization)**: 특정 출력 부분에 영향을 미친 입력(또는 이전 출력) 부분을 강조하여 시각화.
     - **사회적 투명성 (Social Transparency)**: 다른 팀원의 AI 사용 경험 및 상호작용 정보를 공유.

3. **데이터 분석**:
   - 워크숍 기록(Mural 내용, 녹음된 대화록)을 바탕으로 내용 분석을 수행했습니다.
   - 질문 도출 결과는 기존 XAI 연구의 질문 범주(Liao et al. [48], Lim and Dey [53])를 참조하여 코딩하고, GenAI for Code에 특유한 새로운 범주를 식별했습니다.
   - XAI 기능에 대한 피드백은 구체적인 설계 권장사항으로 변환될 수 있도록 분석했습니다.

## 📊 Results

- **설명 가능성 요구사항 11가지 범주**: 참가자들의 질문 분석을 통해 다음 범주들을 식별했습니다 (빈도 순):

  - **Input**: 모델이 받아들일 수 있는 입력 유형 및 최적화 방법.
  - **Output**: AI가 생성할 수 있는 결과물의 특성, 범위, 시스템 기능.
  - **How (global)**: 모델이 코드를 생성하는 전반적인 방식 및 논리.
  - **Performance**: AI가 생성한 코드의 품질, 모델의 런타임 성능.
  - **How to**: 더 나은 결과를 얻기 위해 입력을 변경하거나 개선하는 방법.
  - **Control**: 모델의 작동 방식에 대한 사용자 정의 또는 선호도 지정 옵션.
  - **Why/Why NOT (local)**: 특정 출력이 생성된 이유 또는 원하는 출력이 생성되지 않은 이유.
  - **Data**: 모델 학습에 사용된 데이터의 특성 및 출처.
  - **System Requirements & Impact**($\dagger$): 시스템 사용을 위한 요구사항 또는 사용 조건에 대한 영향.
  - **Limitations**($\dagger$): 모델의 기능적 한계 또는 다루지 못하는 시나리오.
  - **What if**: 입력이 변경되거나 가상 상황에서 출력이 어떻게 될지.
    ($\dagger$는 GenAI for Code 맥락에서 새롭게 부각된 범주를 나타냅니다.)

- **XAI 기능에 대한 설계 권장사항**:
  - **AI 문서화**: 예시 및 튜토리얼, 소프트웨어 엔지니어링 기능, 출력 코드 품질 및 유용성, 지원 언어 및 프레임워크, 제어, 배포 요구사항 및 플랫폼 등 GenAI for Code에 특화된 정보 포함.
  - **불확실성 지표**: 불확실한 코드에 대한 대안 출력 제안, 불확실성 원인 설명, 더 세분화된 불확실성(예: 정확성, 시간 복잡도), 인간 입력(확인, 명확화, 선호도 지정)을 통한 불확실성 해결, 대화형 테스트 지원.
  - **어텐션 시각화**: span 레벨보다 라인 레벨 해석, 의심스러운 부분 즉시 수정 기능, 구문 트리 기반 선택, 시각화에 자연어 설명 추가, 사용자 수정사항을 모델 개선 신호로 활용.
  - **사회적 투명성**: 소프트웨어 개발 수명 주기(요구사항 분석, 설계, 구현, 테스트, 배포 및 유지보수)의 각 단계에서 팀 정보, 다른 사람들의 AI 경험, 유사 작업 및 요청, 코드의 저작자 정보, AI의 인간에 대한 영향, 모델 사용자 정의 및 피드백 수집 등 다양한 정보를 공유.

## 🧠 Insights & Discussion

- **GenAI를 위한 XAI 접근 방식**: GenAI의 풍부하고 복잡한 입출력은 사용자들이 입력 및 출력 공간의 범위, 특성, 한계, 그리고 모델이 입력을 통해 출력을 생성하는 방식에 대한 명확한 개념 모델을 형성하는 것을 중요하게 만듭니다. 이는 기존 XAI가 표현 학습 및 시각화에 집중했던 것과 달리, GenAI 사용자의 요구사항(입력, 출력, 전역 설명)과 기술적 커뮤니티의 초점 사이에 불일치가 있음을 시사합니다.
- **코드 특성 및 실용적/문화적 맥락의 중요성**: GenAI를 위한 XAI는 생성된 산출물(코드)의 특성과 이 산출물을 사용하는 실용적/문화적 맥락(소프트웨어 엔지니어링 도메인)에 따라 맞춤화되어야 합니다. 예를 들어, 참가자들은 지원 언어, 프레임워크, 데이터 구조와 같은 입력/출력 공간에 대한 정보와 기술적 정확성 외에 코드 특성 및 인간 생산성에 미치는 영향을 반영하는 지표에 관심을 보였습니다.
- **실행 가능하고 유용성 지향적인 이해**: 참가자들은 코드 생성 및 프로그래밍 생산성을 최적화하는 최종 목표를 지원하기 위한 '실행 가능한' 또는 '유용성 지향적인' 이해를 원했습니다. 이는 투명한 정보를 본 후 목표 달성을 위한 후속 조치를 가능하게 하는 방식으로 지원될 수 있습니다.
- **설계 함의**: 자연어 설명 및 대화형 인터페이스가 코드 AI 비서에 적합할 수 있으며, 프로그래밍 기술 수준이 낮은 사용자에게는 보다 적극적인 설명이나 교육 세션이 필요할 수 있습니다. GenAI 기술의 완성도와 잠재적 위험에 대한 근본적인 질문도 제기됩니다.
- **인간 중심, 참여형, 질문 중심 접근 방식의 가치**: 시나리오, 페르소나, 실제 AI 모델의 출력을 활용한 저수준 프로토타입이 참가자들의 풍부한 질문 도출에 효과적이었으며, 질문들을 취합-클러스터링-투표하는 과정이 그룹 토론과 아이디어 구축에 생산적이었습니다. 프로브 디자인의 구체성과 개방성 사이의 균형을 찾는 것이 중요합니다.

## 📌 TL;DR

이 연구는 소프트웨어 엔지니어를 위한 코드 생성형 AI의 설명 가능성 요구사항을 탐구했습니다. 코드 번역, 자동 완성, 자연어-코드 변환 세 가지 시나리오에서 43명의 소프트웨어 엔지니어와 9번의 워크숍을 통해, 사용자가 AI 시스템을 효과적으로 활용하기 위해 '입력', '출력', '전반적인 작동 방식', '성능', '제어' 등 11가지 설명 요구사항 범주를 가짐을 발견했습니다. 또한 AI 문서화, 불확실성 지표, 어텐션 시각화, 사회적 투명성 등 4가지 XAI 기능에 대한 설계 권장사항을 제시하며, 인간 중심 접근 방식이 GenAI를 위한 XAI 개발에 중요함을 강조했습니다.
