# NATURAL TTS SYNTHESIS BY CONDITIONING WAVENET ON MEL SPECTROGRAM PREDICTIONS

Jonathan Shen, Ruoming Pang, Ron J. Weiss, Mike Schuster, Navdeep Jaitly, Zongheng Yang, Zhifeng Chen, Yu Zhang, Yuxuan Wang, RJ Skerry-Ryan, Rif A. Saurous, Yannis Agiomyrgiannakis, and Yonghui Wu

## 🧩 Problem to Solve

텍스트로부터 사람의 음성과 구별하기 어려울 정도로 자연스러운 음성을 직접 합성하는 것은 텍스트-음성 변환(Text-to-Speech, TTS) 분야에서 오랜 난제였습니다. 기존의 연결 합성(concatenative synthesis) 방식은 이음새 아티팩트가 발생하고, 통계적 파라메트릭 합성(statistical parametric synthesis) 방식은 음질이 탁하고 부자연스러웠습니다. WaveNet과 같은 신경망 기반 보코더는 높은 음질을 제공했지만, 입력 특징(언어학적 특징, F$_0$ 예측, 음소 지속 시간 등)을 생성하는 데 복잡한 텍스트 분석 시스템과 전문 지식이 필요했습니다. Tacotron은 복잡한 특징 엔지니어링 없이 스펙트로그램을 생성했지만, Griffin-Lim과 같은 비신경망 기반 보코더를 사용하여 음질에 한계가 있었습니다. 이 논문은 이러한 단점들을 극복하고, 복잡한 중간 특징 없이 텍스트에서 직접 고품질의 자연스러운 음성을 합성하는 통합된 신경망 아키텍처를 제안합니다.

## ✨ Key Contributions

- **신경망 기반 종단 간 TTS 시스템 제안:** 텍스트에서 멜 스펙트로그램을 예측하는 Tacotron 스타일의 특징 예측 네트워크와, 예측된 멜 스펙트로그램으로부터 파형을 합성하는 수정된 WaveNet 보코더를 결합한 Tacotron 2를 제안합니다.
- **인간 음성 수준의 자연스러운 음성 합성:** 제안된 모델은 평균 청취 품질 점수(Mean Opinion Score, MOS) 4.53을 달성하여, 전문가가 녹음한 실제 음성(MOS 4.58)과 거의 구별할 수 없는 수준의 높은 자연도를 보여줍니다.
- **멜 스펙트로그램의 효과적인 활용:** 멜 스펙트로그램을 중간 음향 표현으로 사용하여 TTS 파이프라인을 단순화하고, WaveNet 보코더의 크기를 크게 줄일 수 있음을 입증했습니다. 이는 복잡한 언어학적 특징 대신 낮은 수준의 음향 특징을 사용함으로써 가능했습니다.
- **다양한 설계 선택에 대한 심층적인 연구:** 시스템의 핵심 구성 요소에 대한 제거 연구(ablation studies)를 통해 멜 스펙트로그램 사용의 효과, 후처리 네트워크의 중요성, WaveNet 아키텍처 간소화 가능성 등을 검증했습니다.

## 📎 Related Works

- **연결 합성 (Concatenative Synthesis)** [2,3]: 사전 녹음된 작은 단위의 파형을 이어 붙여 음성을 합성하는 방식.
- **통계적 파라메트릭 음성 합성 (Statistical Parametric Speech Synthesis)** [4,5,6,7]: 음성 특징의 부드러운 궤적을 직접 생성하고 보코더로 합성하는 방식.
- **WaveNet** [8]: 시간 도메인 파형을 위한 생성 모델로, 높은 음질을 달성했지만 복잡한 언어학적/음향학적 특징을 필요로 함. 기존 WaveNet 기반 TTS 시스템 [9,10,11].
- **Tacotron** [12]: 문자 시퀀스에서 크기 스펙트로그램을 생성하는 시퀀스-투-시퀀스 아키텍처로, Griffin-Lim 알고리즘 [14]을 사용하여 파형을 합성.
- **Deep Voice 3** [11]: 유사한 종단 간 접근 방식을 사용하지만, 본 시스템만큼 자연도가 높지는 않음.
- **Char2Wav** [16]: 신경망 보코더를 사용한 또 다른 종단 간 TTS 방식이지만, 다른 중간 표현과 아키텍처를 사용함.

## 🛠️ Methodology

제안된 Tacotron 2 시스템은 두 가지 주요 구성 요소로 이루어져 있습니다:

1. **특징 예측 네트워크 (Feature Prediction Network):**

   - **목표:** 입력 문자 시퀀스에서 멜 스펙트로그램 프레임 시퀀스를 예측합니다.
   - **입력:** 학습된 512차원 문자 임베딩.
   - **인코더 (Encoder):**
     - 3개의 컨볼루션 레이어 스택: 각 레이어는 $5 \times 1$ 필터 512개, 배치 정규화 [18], ReLU 활성화 함수를 사용합니다. 이는 입력 문자 시퀀스에서 장기적인 문맥을 모델링합니다.
     - 단일 양방향 LSTM [19,20] 레이어: 512 유닛 (각 방향 256)으로 인코딩된 특징을 생성합니다.
   - **어텐션 (Attention):** 이전 디코더 타임스텝의 누적 어텐션 가중치를 추가 특징으로 사용하는 위치-감지 어텐션 [21]을 사용하여 모델이 입력 시퀀스를 일관되게 진행하도록 돕습니다.
   - **디코더 (Decoder):**
     - 자동회귀 순환 신경망으로, 인코딩된 입력 시퀀스로부터 한 번에 하나의 멜 스펙트로그램 프레임을 예측합니다.
     - **Pre-net:** 이전 타임스텝의 예측값을 2개의 완전 연결 레이어 (256 ReLU 유닛)를 거쳐 통과시킵니다. 이는 어텐션 학습에 필수적인 정보 병목 역할을 합니다.
     - **LSTM 스택:** pre-net 출력과 어텐션 문맥 벡터를 연결하여 2개의 단방향 LSTM 레이어 (1024 유닛)를 통과시킵니다.
     - **선형 투영:** LSTM 출력과 어텐션 문맥 벡터의 연결을 통해 타겟 스펙트로그램 프레임을 예측합니다.
     - **Post-net:** 예측된 멜 스펙트로그램을 5개 레이어의 컨볼루션 네트워크 (512 필터, $5 \times 1$ 모양, 배치 정규화, tanh 활성화)를 통과시켜 잔차를 예측하고 전체 재구성을 개선합니다.
   - **손실 함수:** post-net 전후의 평균 제곱 오차(MSE) 합을 최소화합니다.
   - **종료 토큰 예측 (Stop Token Prediction):** 디코더 LSTM 출력과 어텐션 문맥을 스칼라로 투영하고 시그모이드 활성화를 통해 출력 시퀀스 완료 확률을 예측합니다. 추론 시 모델이 동적으로 생성을 종료하도록 합니다.
   - **정규화:** 컨볼루션 레이어에 Dropout (0.5), LSTM 레이어에 Zoneout (0.1)을 적용합니다. 추론 시 출력 변형을 위해 자동회귀 디코더의 pre-net에만 Dropout (0.5)을 적용합니다.

2. **수정된 WaveNet 보코더 (Modified WaveNet Vocoder):**
   - **목표:** 예측된 멜 스펙트로그램 특징 표현을 시간 도메인 파형 샘플로 변환합니다.
   - **아키텍처:** 30개의 팽창 컨볼루션(dilated convolution) 레이어로 구성되며, 3개의 팽창 주기(dilation cycle)로 그룹화됩니다 (레이어 $k$의 팽창률은 $2^{k(\text{mod } 10)}$).
   - **업샘플링:** 스펙트로그램 프레임의 12.5 ms 프레임 홉에 맞춰 2개의 업샘플링 레이어만 사용됩니다.
   - **출력:** PixelCNN++ [27] 및 Parallel WaveNet [28]을 따라 소프트맥스 레이어 대신 10개 구성 요소의 로지스틱 분포 혼합(Mixture of Logistic distributions, MoL)을 사용하여 24 kHz의 16비트 샘플을 생성합니다. WaveNet 스택 출력은 ReLU 활성화 후 선형 투영을 거쳐 각 혼합 구성 요소의 파라미터(평균, 로그 스케일, 혼합 가중치)를 예측합니다.
   - **손실 함수:** 실제 샘플의 음의 로그 우도(negative log-likelihood)로 계산됩니다.

**학습 설정 (Training Setup):**

- **특징 예측 네트워크:** 교사 강요(teacher-forcing) 방식으로 Adam 최적화 [29]를 사용하여 학습됩니다. 배치 크기 64, 학습률 $10^{-3}$에서 $10^{-5}$로 지수적으로 감소.
- **WaveNet:** 특징 예측 네트워크의 'ground truth-aligned' 예측을 사용하여 독립적으로 학습됩니다. 배치 크기 128 (32개 GPU 분산), Adam 최적화, 고정 학습률 $10^{-4}$, 지수 가중 이동 평균(exponentially-weighted moving average)을 사용하여 모델 가중치를 유지합니다.
- **데이터셋:** 단일 전문 여성 화자의 24.6시간 분량 미국 영어 데이터셋을 사용하며, 모든 텍스트는 정규화(예: "16"을 "sixteen"으로 변환)되어 학습됩니다.

## 📊 Results

- **MOS 평가:**
  - Tacotron 2 (본 논문): $4.526 \pm 0.066$
  - Ground truth (실제 음성): $4.582 \pm 0.053$
  - WaveNet (언어학적 특징): $4.341 \pm 0.051$
  - Tacotron (Griffin-Lim): $4.001 \pm 0.087$
  - 연결 합성: $4.166 \pm 0.091$
  - 파라메트릭 합성: $3.492 \pm 0.096$
  - 결과: Tacotron 2는 다른 TTS 시스템들을 크게 능가하며, 실제 음성과 거의 동등한 MOS를 달성했습니다.
- **병렬 평가 (Side-by-side evaluation):** 합성 음성과 실제 음성 간의 선호도 평가에서, 평가자들은 실제 음성에 대해 약간의 통계적으로 유의미한 선호도($-0.270 \pm 0.155$)를 보였습니다. 이는 주로 시스템의 가끔 발생하는 오발음 때문이었습니다.
- **도메인 외 텍스트에 대한 일반화 능력:** 37개의 뉴스 헤드라인에 대한 평가에서 MOS는 $4.148 \pm 0.124$로, 언어학적 특징에 기반한 WaveNet($4.137 \pm 0.128$)과 거의 동등한 결과를 보였습니다. 합성 음성은 더 자연스럽게 들렸지만, 이름 처리 등에서 발음 오류가 발생하는 경향이 있었습니다.
- **제거 연구 (Ablation Studies):**
  - **예측 특징 대 Ground Truth:** WaveNet을 예측된 멜 스펙트로그램으로 학습시키는 것이 추론 시 예측된 특징으로 합성할 때 더 좋은 성능을 보였습니다(MOS 4.526 vs 4.449). Ground truth 멜 스펙트로그램으로 학습한 WaveNet이 예측된 스펙트로그램으로 합성할 경우 성능이 저하되었는데(MOS 4.362), 이는 예측된 스펙트로그램이 더 과도하게 부드러워지고 세부 정보가 부족하기 때문입니다.
  - **선형 대 멜 스펙트로그램:** WaveNet에 선형 스펙트로그램을 조건으로 주는 경우(MOS 4.510)와 멜 스펙트로그램을 조건으로 주는 경우(MOS 4.526) 사이에 큰 차이는 없었습니다. 그러나 멜 스펙트로그램이 더 압축된 표현이므로 더 나은 선택으로 판단됩니다.
  - **후처리 네트워크 (Post-net):** 후처리 네트워크가 없을 경우 MOS가 $4.429 \pm 0.071$로 감소하여, 후처리 네트워크가 시스템 설계에서 여전히 중요한 부분임을 확인했습니다.
  - **WaveNet 간소화:** 멜 스펙트로그램이 파형에 더 가까운 표현이므로 WaveNet의 복잡도를 줄일 수 있는지 실험했습니다. Baseline WaveNet (30 레이어, 256 ms 수용 필드)과 유사한 음질을 유지하면서 레이어 수를 12개 (10.5 ms 수용 필드, MOS 4.481)까지 줄일 수 있었습니다. 그러나 팽창 컨볼루션을 완전히 제거하면 음질이 크게 저하되었습니다(MOS 3.930), 이는 고품질 음성 합성을 위해 파형 샘플 시간 스케일에서 충분한 문맥이 필요함을 시사합니다.

## 🧠 Insights & Discussion

Tacotron 2는 텍스트로부터 직접 인간 음성 수준의 자연스러운 음성을 합성하는 데 있어 중요한 진전을 이루었습니다. 이 연구의 핵심 통찰은 두 단계의 신경망 접근 방식, 즉 특징 예측 네트워크와 신경망 보코더의 효과적인 결합입니다. 특히, 중간 표현으로 멜 스펙트로그램을 사용하는 것은 파이프라인을 간소화하고, 각 구성 요소를 독립적으로 훈련할 수 있게 하며, WaveNet 보코더의 복잡도를 줄이는 데 기여했습니다.

모델은 대부분의 경우 매우 자연스러운 음성을 생성하지만, 가끔 발생하는 오발음이나 부자연스러운 운율, 그리고 학습 데이터셋에 없는 도메인 외의 이름과 같은 텍스트에 대해서는 발음 오류를 보이는 한계가 있습니다. 이는 종단 간 접근 방식이 의도된 사용 시나리오를 포괄하는 광범위한 학습 데이터를 필요로 함을 시사합니다.

향후 연구에서는 멜 주파수 빈의 개수와 오디오 품질 간의 트레이드오프를 탐색하여 멜 스펙트로그램 표현의 효율성을 더욱 최적화할 수 있을 것으로 보입니다. 전반적으로 Tacotron 2는 TTS 분야에서 새로운 최첨단 성능을 확립하며, 사람과 기계 음성 간의 격차를 더욱 좁혔습니다.

## 📌 TL;DR

Tacotron 2는 텍스트-음성 변환(TTS)의 주요 난제인 고품질 음성 합성을 위해, 문자 임베딩으로부터 멜 스펙트로그램을 예측하는 Tacotron 스타일의 신경망과, 이 멜 스펙트로그램을 기반으로 파형을 생성하는 수정된 WaveNet 보코더를 결합한 완전히 신경망 기반의 종단 간 시스템입니다. 이 모델은 복잡한 특징 엔지니어링 없이 학습 가능하며, 평균 청취 품질 점수(MOS) 4.53을 달성하여 실제 인간 음성(MOS 4.58)과 거의 구별할 수 없는 수준의 자연도를 보여줍니다. 멜 스펙트로그램을 중간 표현으로 사용하여 파이프라인을 단순화하고 WaveNet의 복잡성을 줄인 것이 핵심 성과이며, 이는 TTS 기술의 최첨단 성능을 확립했습니다.
