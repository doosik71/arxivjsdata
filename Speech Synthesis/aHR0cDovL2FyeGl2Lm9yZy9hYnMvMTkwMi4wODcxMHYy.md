# GANSYNTH: ADVERSARIAL NEURAL AUDIO SYNTHESIS

Jesse Engel, Kumar Krishna Agrawal, Shuo Chen, Ishaan Gulrajani, Chris Donahue, & Adam Roberts

## 🧩 Problem to Solve

인간의 지각은 전역적인 구조와 미세한 파형 일관성 모두에 민감하기 때문에 효율적인 오디오 합성은 본질적으로 어려운 기계 학습 문제입니다. 기존의 자기회귀 모델(예: WaveNet)은 지역적인 구조를 모델링하지만, 샘플링 속도가 느리고 전역적인 잠재 구조(global latent structure)가 부족합니다. 반대로 GAN(Generative Adversarial Network)은 전역적인 잠재 컨디셔닝과 효율적인 병렬 샘플링이 가능하지만, 지역적으로 일관된 오디오 파형을 생성하는 데 어려움을 겪습니다. 이 연구는 GAN이 어떻게 고품질 및 지역적으로 일관된 오디오를 생성할 수 있는지 그 방법을 제시하고자 합니다.

## ✨ Key Contributions

- GAN이 스펙트럼 영역에서 로그-크기(log-magnitude) 스펙트로그램과 위상(phase)을 직접 생성함으로써, 스트라이드 컨볼루션을 사용하여 파형을 직접 생성하는 것보다 더 일관된 파형을 생성할 수 있음을 입증했습니다.
- 순간 주파수(Instantaneous Frequency, IF) 스펙트럼을 추정하는 것이 위상을 추정하는 것보다 더 일관된 오디오를 생성합니다.
- 고조파(harmonics)가 겹치지 않도록 유지하는 것이 중요하며, STFT 프레임 크기를 늘리고 멜(mel) 주파수 스케일을 사용하면 낮은 고조파 주파수 간의 분리를 증가시켜 성능을 향상시킵니다.
- NSynth 데이터셋에서 GAN이 자동 및 인간 평가 지표에서 강력한 WaveNet 베이스라인을 능가하며, 자기회귀 모델보다 약 $54,000$배 더 빠르게 오디오를 생성할 수 있음을 보여주었습니다.
- 잠재 벡터 및 피치 벡터에 대한 전역적 컨디셔닝은 GAN이 지각적으로 부드러운 음색(timbre) 보간(interpolation)과 피치 전반에 걸쳐 일관된 음색 정체성(timbral identity)을 생성하도록 합니다.

## 📎 Related Works

- **자기회귀 모델 (Autoregressive Models):** WaveNet (van den Oord et al., 2016)은 높은 충실도의 오디오를 생성했지만, 느린 샘플링 속도 문제가 있었습니다. 이후 빠른 생성을 위한 연구 (van den Oord et al., 2018; Paine et al., 2016)가 진행되었습니다.
- **GAN (Generative Adversarial Networks):** 이미지 생성 분야에서 큰 성공을 거두었습니다 (Radford et al., 2016; Arjovsky et al., 2017; Karras et al., 2018a). GAN 학습 안정화 및 품질 향상 기법 (Gulrajani et al., 2017; Karras et al., 2018a)이 활용되었습니다.
- **이전 오디오 GAN 시도:** 이미지를 위한 GAN 아키텍처를 오디오 파형에 직접 적용하려는 시도는 지각적 충실도 면에서 실패했습니다 (Donahue et al., 2019).
- **NSynth 데이터셋 (Engel et al., 2017):** 이미지 분야의 CelebA처럼 오디오에 특화된 데이터셋으로, 악기 음색 및 충실도 모델링에 중점을 둡니다.
- **다른 오디오 생성 모델:** 프레임 기반 회귀 모델 (Defossez et al., 2018), 역산란 네트워크 (Andreux & Mallat, 2018), 지각적 사전(perceptual priors)을 이용한 VAE (Esling et al., 2018) 등이 NSynth 데이터셋에서 탐구되었습니다.
- **순간 주파수 개념:** 위상 보코더(phase vocoder) (Dolson, 1986) 및 순간 주파수(IF) (Boashash, 1992) 개념에서 영감을 받았습니다.

## 🛠️ Methodology

1. **데이터셋:** NSynth 데이터셋의 어쿠스틱 악기 음원 (MIDI 24-84) 서브셋을 사용했습니다. 각 샘플은 4초 길이, 16kHz 샘플링 레이트($64,000$ 차원)를 가집니다.
2. **아키텍처:** Karras et al. (2018a)의 Progressive GAN 훈련 방식을 오디오 스펙트럼 생성에 맞게 변형했습니다.
   - **생성자(Generator):** 구형 가우시안에서 무작위 벡터 $z$를 샘플링하고, 전치 컨볼루션(transposed convolutions) 스택을 통해 업샘플링하여 스펙트럼 데이터 $x = G(z)$를 생성합니다.
   - **판별자(Discriminator):** 생성자의 아키텍처를 미러링하는 다운샘플링 컨볼루션 네트워크로, 실제 분포와 생성된 분포 간의 발산 측정값을 추정합니다. Lipschitz 연속성을 촉진하기 위해 기울기 페널티(gradient penalty) (Gulrajani et al., 2017)와 픽셀 정규화(pixel normalization)를 사용합니다.
   - **조건부 생성:** 잠재 벡터에 음악적 피치(one-hot representation)를 추가하여 피치와 음색을 독립적으로 제어할 수 있도록 합니다. 판별자에는 피치 레이블을 예측하는 보조 분류(auxiliary classification) 손실 (Odena et al., 2017)을 추가하여 생성자가 피치 정보를 사용하도록 유도합니다.
3. **오디오 표현 (핵심):** TensorFlow의 내장 STFT 구현을 사용하여 스펙트럼 표현을 계산합니다.
   - **기본 STFT 설정:** 256 스트라이드, 1024 프레임 크기를 사용하여 75% 프레임 중첩과 513 주파수 빈을 얻습니다. Nyquist 주파수를 잘라내고 시간적으로 패딩하여 $(256, 512, 2)$ 크기의 "이미지"를 얻습니다. 두 채널은 크기(magnitude)와 위상(phase)에 해당합니다.
   - **로그 크기:** 크기에 로그를 취한 후 $[-1, 1]$ 범위로 스케일링합니다.
   - **위상 (Phase) 모델:** 위상 각도 또한 $[-1, 1]$ 범위로 스케일링합니다.
   - **순간 주파수 (Instantaneous Frequency, IF) 모델:** 위상 각도를 언랩(unwrap)하고 시간 미분에 해당하는 유한 차분(finite difference)을 취합니다. 이는 프레임 스트라이드와 신호 주기성 간의 각도 차이와 같은 의미를 가집니다.
   - **고주파 해상도 (+ H):** STFT 프레임 크기와 스트라이드를 두 배로 늘려 $(128, 1024, 2)$ 크기의 스펙트럼 이미지를 생성하여 낮은 주파수 대역의 고조파 분리 능력을 향상시킵니다.
   - **IF-Mel 모델:** 로그 크기와 순간 주파수 모두를 멜 주파수 스케일 (1024 빈)로 변환하여 낮은 주파수 분리를 더욱 강화합니다.
4. **베이스라인:** WaveGAN (Donahue et al., 2019)에 피치 컨디셔닝을 추가하여 재훈련하고, WaveNet (van den Oord et al., 2016)에 동일한 원-핫 피치 컨디셔닝 신호를 적용하여 강력한 베이스라인을 구축했습니다 (8비트 $\mu$-law 모델이 더 안정적이고 우수한 성능을 보임).
5. **평가 지표:** 인간 평가 (Amazon Mechanical Turk), 통계적으로 다른 빈의 수 (Number of Statistically-Different Bins, NDB), 피치 분류기 기반의 Inception Score (IS), Pitch Accuracy (PA) 및 Pitch Entropy (PE), Fréchet Inception Distance (FID)를 사용했습니다.

## 📊 Results

- **인간 평가:** 오디오 품질은 IF-Mel > IF > Phase > Waveform 순으로 뚜렷한 경향을 보였습니다. IF-Mel + H 모델은 실제 데이터와 비슷하거나 약간 낮은 품질로 평가되었습니다. WaveNet 베이스라인은 IF GAN과 비슷한 점수를 얻었습니다.
- **다양성 (NDB):** NDB 점수는 인간 평가와 유사한 경향을 보였습니다. 고주파 해상도는 NDB 점수를 향상시켰으며, WaveNet은 가장 낮은 NDB 점수를 기록하여 샘플 다양성 부족을 나타냈습니다.
- **FID:** 고주파 해상도를 가진 IF 모델에서 FID 점수가 현저히 낮게 나타났습니다. 멜 스케일은 인간 평가만큼 FID에 큰 영향을 주지 않았습니다.
- **분류기 지표 (IS, PA, PE):** 대부분의 모델은 명시적인 피치 컨디셔닝 덕분에 IS, PA, PE에서 좋은 성능을 보였습니다. 고해상도 모델은 실제 데이터와 유사한 분류 정확도를 보였습니다.
- **생성 속도:** IF-Mel GAN은 4초 오디오 샘플 생성에 20밀리초(ms)가 소요되어, WaveNet 베이스라인 (1077.53초)보다 약 $53,880$배 빨랐습니다.
- **위상 일관성:** IF 모델은 WaveGAN 및 PhaseGAN보다 주기-대-주기 일관성이 높은 파형을 생성했으며, 이는 Rainbowgrams 시각화에서 강하고 일관된 색상으로 나타났습니다.
- **보간:** GAN의 전역적 컨디셔닝 덕분에 잠재 공간에서 부드러운 음색 보간이 가능했으며, 중간 지점에서도 고품질 오디오를 유지했습니다. 반면 WaveNet 오토인코더는 보간 시 종종 비현실적인 소리를 생성했습니다.
- **피치 간 음색 일관성:** 고정된 잠재 벡터에 대해 GAN은 다양한 피치에 걸쳐 일관된 악기 음색 정체성을 유지했습니다.

## 🧠 Insights & Discussion

이 연구는 GAN이 스펙트럼 영역에서 로그-크기와 순간 주파수를 모델링함으로써, 고품질 및 지역적으로 일관된 오디오를 성공적으로 생성할 수 있음을 증명했습니다. 이는 기존 오디오 GAN의 한계를 극복하는 데 있어 오디오 표현 방식의 중요성을 강조합니다. 특히, 순간 주파수 (IF)와 멜 스케일(Mel-scale)을 활용한 표현은 파형의 위상 일관성을 유지하는 데 결정적인 역할을 했습니다.

GAN의 병렬 샘플링 능력은 WaveNet과 같은 자기회귀 모델에 비해 수만 배 빠른 생성 속도를 제공하며, 이는 실시간 신경망 오디오 합성의 가능성을 열어줍니다. 또한, GAN의 전역적 잠재 컨디셔닝은 음색의 부드러운 보간과 피치 전반에 걸친 일관된 음색 정체성 유지 등 음악적 응용에서 중요한 이점을 제공합니다.

제한점으로는 본 연구가 통제된 NSynth 데이터셋에 중점을 두었다는 점이 있습니다. 향후 음성 및 다른 유형의 자연음과 같은 더 광범위한 신호에 대한 유효성 검증 및 확장이 필요합니다. GAN의 일반적인 문제인 모드 붕괴(mode collapse) 및 다양성(diversity) 문제는 오디오에서도 존재하며, 데이터 분포를 더 잘 포착하기 위해 인코더 또는 직접적인 회귀 손실과 적대적 손실을 결합하는 추가 연구가 필요할 것입니다.

## 📌 TL;DR

GAN은 효율적인 샘플링에도 불구하고 지역적으로 일관된 고품질 오디오를 생성하는 데 어려움이 있었습니다. 이 논문은 로그-크기 및 순간 주파수(IF) 스펙트로그램을 멜(Mel) 스케일에서 모델링하여 스펙트럼 영역에서 오디오를 생성하는 GANsynth를 제안합니다. 이 방법은 NSynth 데이터셋에서 WaveNet 베이스라인을 인간 및 자동 평가 지표에서 능가하는 최고 수준의 오디오 품질을 달성했으며, 생성 속도는 약 $54,000$배 더 빨랐습니다. 특히 IF 및 멜 스케일 표현은 파형의 위상 일관성과 충실도에 결정적이며, GAN의 전역적 잠재 컨디셔닝은 부드러운 음색 보간과 피치 전반에 걸친 일관된 음색을 가능하게 합니다.
