# WAVEGLOW: A FLOW-BASED GENERATIVE NETWORK FOR SPEECH SYNTHESIS

Ryan Prenger, Rafael Valle, Bryan Catanzaro

## 🧩 Problem to Solve

고품질 음성을 효율적으로 합성하는 것은 기계와의 음성 상호작용이 중요해지면서 더욱 중요해지고 있습니다. 특히, 텍스트-음성 변환(TTS) 시스템의 두 번째 단계인 멜-스펙트로그램과 같은 시간 정렬 특징으로부터 실제 오디오 샘플을 생성하는 보코더(vocoder)는 계산적으로 매우 어렵고 음성 품질에 큰 영향을 미칩니다.

기존의 고품질 음성 합성 모델(예: WaveNet)은 대개 **오토회귀(auto-regressive)** 방식이어서, 미래의 오디오 샘플이 이전 샘플에 조건화되기 때문에 본질적으로 순차적이며 GPU와 같은 병렬 처리 장치를 완전히 활용하기 어렵습니다. 이로 인해 추론(inference) 속도가 실시간 요구사항을 충족하기 어렵습니다. 비오토회귀(non-auto-regressive) 모델도 존재하지만, 복잡한 다중 손실 함수나 두 개의 네트워크(교사-학생 네트워크)를 필요로 하여 훈련이 어렵고 수렴 문제가 발생할 수 있습니다.

## ✨ Key Contributions

- **비오토회귀 방식의 고품질 음성 합성:** 멜-스펙트로그램으로부터 고품질 음성을 생성하는 새로운 플로우 기반 네트워크인 WaveGlow를 제안합니다.
- **단일 네트워크 및 손실 함수:** 오직 단일 네트워크와 훈련 데이터의 가능도(likelihood)를 최대화하는 단일 손실 함수만을 사용하여 훈련 절차를 간단하고 안정적으로 만듭니다.
- **높은 추론 속도:** NVIDIA V100 GPU에서 500 kHz 이상의 속도로 오디오 샘플을 생성하여, 실시간보다 25배 이상 빠릅니다. 이는 기존 비오토회귀 모델 중 가장 빠른 속도 중 하나입니다.
- **WaveNet 수준의 오디오 품질:** 평균 의견 점수(Mean Opinion Score, MOS) 테스트 결과, 공개적으로 사용 가능한 최고의 WaveNet 구현만큼 우수한 오디오 품질을 제공합니다.
- **Glow와 WaveNet 아이디어 결합:** Glow[1]의 플로우 기반 네트워크 아이디어와 WaveNet[2]의 아키텍처(확장 컨볼루션 등) 통찰력을 결합하여 효율적이고 고품질의 합성 모델을 만듭니다.

## 📎 Related Works

- **WaveNet [2]:** 고품질 음성 합성을 가능하게 한 오토회귀 신경망 모델입니다. 하지만 추론 속도가 느리다는 단점이 있습니다.
- **Parallel WaveNet [9], ClariNet [7]:** 비오토회귀 방식의 음성 합성 모델로, Inverse Auto-regressive Flows (IAF)를 사용합니다. 빠른 추론이 가능하지만, 두 개의 네트워크(교사-학생)와 복합 손실 함수를 사용하여 훈련이 복잡하고 수렴에 어려움이 있을 수 있습니다.
- **Glow [1]:** 역변환 가능한 1x1 컨볼루션을 포함한 플로우 기반 생성 모델로, WaveGlow의 핵심 아키텍처 중 하나인 1x1 컨볼루션과 아핀 커플링 레이어 아이디어를 제공합니다.
- **NICE [11], Real NVP [12]:** 커플링 레이어를 사용하여 역변환 가능한 신경망을 구축하는 플로우 기반 모델의 초기 연구들입니다.
- **Griffin-Lim [16]:** 스펙트로그램으로부터 위상 정보를 반복적으로 추정하여 오디오를 생성하는 전통적인 알고리즘입니다.

## 🛠️ Methodology

WaveGlow는 간단한 분포(0 평균 구형 가우시안)에서 샘플링한 $z$ 값을 일련의 역변환 가능한 레이어를 통해 원하는 오디오 샘플 $x$ 분포로 변환하는 **플로우 기반 생성 모델**입니다.

1. **확률 분포 변환:**
   $$ z \sim N(z; 0, I) $$
    $$ x = f*0 \circ f_1 \circ \dots \circ f_k(z) $$
    모델은 데이터의 음의 로그-가능도를 직접 최소화하여 훈련됩니다. 네트워크의 각 레이어가 전단사(bijective)이므로, 변수 변환(change of variables) 공식을 사용하여 가능도를 직접 계산할 수 있습니다.
    $$ \log p*{\theta}(x) = \log p*{\theta}(z) + \sum*{i=1}^k \log|\det(J(f^{-1}\_i(x)))| $$

2. **Squeeze 연산:**
   네트워크의 순방향 패스에서 8개의 오디오 샘플을 벡터로 묶는 "squeeze" 연산을 수행합니다.

3. **Flow Step:**
   각 "flow step"은 다음 두 가지 역변환 가능한 레이어로 구성됩니다.

   - **역변환 가능한 1x1 컨볼루션:**
     채널 간 정보를 혼합하기 위해 각 아핀 커플링 레이어 전에 사용됩니다. 이 컨볼루션의 가중치 $W$는 직교(orthonormal)로 초기화되어 역변환 가능성을 보장하며, 훈련 중에도 손실 함수에 야코비안의 로그-행렬식 항이 포함되어 역변환 가능성을 유지합니다.
     $$ f^{-1}_{\text{conv}} = Wx $$
        $$ \log|\det(J(f^{-1}_{\text{conv}}(x)))| = \log|\det W| $$
   - **아핀 커플링 레이어:**
     입력 채널을 절반으로 분할하여 한 절반($x_a$)을 입력으로 사용하여 다른 절반($x_b$)에 적용할 곱셈($s$) 및 덧셈($t$) 항을 생성합니다. $s$와 $t$는 WaveNet과 유사한 팽창 컨볼루션(dilated convolutions) 기반의 WN() 네트워크에 의해 $x_a$와 멜-스펙트로그램을 조건으로 생성됩니다. 멜-스펙트로그램은 각 레이어의 `gated-tanh` 비선형성 이전에 추가되어 음성 합성을 조건화합니다.
     $$ x*a, x_b = \text{split}(x) $$
        $$ (s, t) = \text{WN}(x_a, \text{mel-spectrogram}) $$
        $$ x_b' = s \cdot x_b + t $$
        $$ f^{-1}*{\text{coupling}}(x) = \text{concat}(x_a, x_b') $$
        이 레이어는 WN()이 역변환 가능하지 않아도 전체 네트워크의 역변환 가능성을 유지합니다. 야코비안의 로그-행렬식은 $\log|s|$로 단순화됩니다.

4. **Early Outputs:**
   모든 채널이 모든 레이어를 통과하는 대신, 4개의 커플링 레이어마다 2개의 채널을 손실 함수로 출력합니다. 이는 네트워크가 여러 시간 스케일에서 정보를 추가하는 것을 용이하게 하고, 이전 레이어로 기울기가 잘 전파되도록 돕습니다.

5. **추론 (Inference):**
   훈련된 네트워크는 가우시안 분포에서 $z$ 값을 무작위로 샘플링하여 역방향으로 네트워크를 통과시켜 오디오 $x$를 생성합니다. 훈련 시 사용한 표준편차($\sigma=\sqrt{0.5}$)보다 낮은 표준편차($0.6$)의 가우시안에서 $z$를 샘플링하면 약간 더 높은 품질의 오디오를 얻을 수 있습니다.

## 📊 Results

- **오디오 품질 (MOS):**

  - Griffin-Lim: $3.823 \pm 0.1349$
  - WaveNet: $3.885 \pm 0.1238$
  - WaveGlow: $3.961 \pm 0.1343$
  - Ground Truth: $4.274 \pm 0.1340$
    WaveGlow는 모든 방법 중 가장 높은 MOS를 기록했지만, WaveNet과 비교했을 때 통계적으로 유의미한 큰 차이는 없었습니다. 이는 주관적인 청취 평가와도 일치합니다. 모든 합성 방법은 실제 오디오에는 미치지 못했습니다.

- **추론 속도:**
  - Griffin-Lim: 507 kHz (60 반복 기준)
  - WaveNet (공개 구현): 0.11 kHz (실시간보다 훨씬 느림)
  - WaveGlow (PyTorch 구현): NVIDIA V100 GPU에서 약 520 kHz
    WaveGlow는 WaveNet보다 훨씬 빠르며, 실시간 요구사항을 크게 뛰어넘는 속도를 보여주었습니다. 이는 Parallel WaveNet이 보고한 500kHz보다 약간 빠른 수준입니다. 최적화된 구현 시 2,000 kHz까지 가능할 것으로 추정됩니다.

## 🧠 Insights & Discussion

- **간단한 훈련 및 배포:** WaveGlow는 단일 네트워크와 단일 가능도 손실 함수를 사용하므로 훈련 절차가 매우 간단하고 안정적입니다. 이는 두 개 이상의 네트워크와 복합 손실 함수를 필요로 하는 기존의 비오토회귀 모델(Parallel WaveNet, ClariNet)에 비해 큰 장점입니다. 이러한 단순성은 고품질 오디오 합성의 배포를 용이하게 합니다.
- **성능의 균형:** WaveGlow는 WaveNet 수준의 오디오 품질을 유지하면서도 극도로 빠른 추론 속도를 달성합니다. 이는 오토회귀 모델의 고질적인 문제인 느린 추론 속도를 해결하는 동시에, 기존 비오토회귀 모델의 복잡한 훈련 문제를 회피합니다.
- **플로우 기반 모델의 잠재력:** WaveGlow는 오토회귀 방식 없이도 강한 장기 종속성을 효과적으로 모델링할 수 있음을 보여주었습니다. 역변환 가능성과 가우시안 분포로의 변환을 통해 가능도를 직접 계산할 수 있는 플로우 기반 모델의 특성이 고품질 음성 합성에서 효과적임을 입증합니다.
- **한계:** MOS 점수에서 볼 수 있듯이, WaveGlow를 포함한 모든 합성 모델은 아직 실제 오디오의 품질에는 미치지 못합니다. 또한, WaveGlow는 멜-스펙트로그램과 같은 중간 특징을 입력으로 받으며, 텍스트-멜-스펙트로그램 변환 단계는 이 연구의 범위 밖입니다.

## 📌 TL;DR

WaveGlow는 멜-스펙트로그램으로부터 고품질 음성을 빠르게 합성하기 위한 **비오토회귀 플로우 기반 생성 네트워크**입니다. 기존 WaveNet의 고품질 오디오 합성 능력과 Glow의 역변환 가능한 네트워크 구조를 결합하여, **단일 네트워크와 단일 가능도 손실 함수**만으로 간단하고 안정적인 훈련이 가능합니다. 이 모델은 NVIDIA V100 GPU에서 **500 kHz 이상의 초고속 추론**을 달성하면서도 **WaveNet에 버금가는 고품질**의 음성을 생성합니다. 이는 복잡한 훈련 과정 없이 실시간 음성 합성을 가능하게 하는 효율적이고 강력한 솔루션을 제공합니다.
