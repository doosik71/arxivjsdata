# From Forks to Forceps: A New Framework for Instance Segmentation of Surgical Instruments

Britty Baby, Daksh Thapar, Mustafa Chasmai, Tamajit Banerjee, Kunal Dargan, Ashish Suri, Subhashis Banerjee, Chetan Arora

## 🧩 Problem to Solve

최소 침습 수술(MIS)에서는 수술 도구의 인스턴스 수준 분류 및 세분화가 필수적입니다. 그러나 자연 영상으로 훈련된 최첨단(SOTA) 인스턴스 세분화 모델을 수술 도구에 미세 조정할 경우 다음과 같은 문제에 직면합니다:

* **낮은 분류 정확도:** 바운딩 박스와 세분화 마스크는 정확하지만, 도구의 모양이 유사하여 분류 헤드가 종종 잘못된 클래스 레이블을 할당합니다.
* **배경 간섭:** 수술 도구는 길고 가늘며 비스듬하게 사용되는 경향이 있어, 바운딩 박스 안에 도구 외에 방해되는 배경 영역이 많이 포함되어 분류를 복잡하게 만듭니다.
* **클래스 간 낮은 시각적 분산:** 수술 도구 간의 시각적 유사성이 높아 일반적인 교차 엔트로피 손실로는 미세한 분류가 어렵습니다.
* **데이터 희소성:** 의료 영상 데이터셋은 규모가 작아 강건한 특징 학습이 어렵습니다.

## ✨ Key Contributions

* **오분류 원인 규명 및 해결:** SOTA 알고리즘의 낮은 성능이 주로 도구의 오분류 때문임을 밝히고, 기존 인스턴스 세분화 모델에 새로운 단계로 특화된 분류 모듈을 추가하여 분류 문제를 해결했습니다. 이 모듈은 바운딩 박스 및 마스크 예측과 분류를 분리합니다.
* **마스크 기반 어텐션 도입:** 도구의 독특한 형태와 기울어진 사용으로 인해 바운딩 박스에 포함되는 방해되는 배경 문제를 해결하기 위해, 제안하는 분류 모듈에 마스크 기반 어텐션(mask-based attention)을 통합하여 도구 영역에만 집중하도록 했습니다.
* **메트릭 학습 활용:** 수술 도구의 낮은 클래스 간 시각적 유사성을 효과적으로 처리하고 작은 데이터셋에서도 강건한 특징을 학습하기 위해, arc loss를 사용한 메트릭 학습(metric learning)으로 분류 모듈을 훈련한 후 교차 엔트로피로 미세 조정하는 방식을 제안했습니다.
* **SOTA 성능 달성:** EndoVis2017 및 EndoVis2018 벤치마크 데이터셋에서 기존 18개 이상의 SOTA 방법보다 우수한 성능을 보였으며, 특히 EndoVis2017 챌린지에서 SOTA 성능을 최소 12점(20%) 이상 향상시키고 효과적으로 일반화했습니다.

## 📎 Related Works

* **의료 영상에서의 객체 감지 및 세분화:** 부인과, 안과, 신경외과 등 다양한 수술 분야에서 적용되고 있으며, EndoVis와 같은 챌린지 데이터셋이 연구를 주도하고 있습니다.
* **세분화 접근 방식:**
  * **의미론적 세분화 (Semantic Segmentation):** TernausNet (U-Net 기반), U-NetPlus, PAANet, MF-TAPNet 등. 주로 픽셀별 클래스 분류에 초점을 맞추며, 때때로 오버 세분화 문제를 겪습니다.
  * **인스턴스 세분화 (Instance Segmentation):** MaskRCNN (Kong et al., ISINet), TraSeTR (Transformer 기반), AP-MTL, Mask-then-classify 등. 자연 영상에서 사전 훈련된 모델을 미세 조정하거나, 특정 작업을 위해 맞춤 설계된 모델을 사용합니다.
* **감독 방식:** 감독 학습, 준감독 학습, 비감독 학습 방법이 있으며, 본 연구는 감독 학습 기반의 인스턴스 세분화에 중점을 둡니다.

## 🛠️ Methodology

본 논문은 기존의 2단계 인스턴스 세분화 모델(예: MaskRCNN)에 새로운 3단계 분류 모듈을 추가한 **S3Net(Three Stage Deep Neural Network)** 프레임워크를 제안합니다.

1. **Stage 1 (Box Proposal):**
    * Region Proposal Network (RPN)를 사용하여 초기 바운딩 박스 제안을 생성합니다.
    * MaskRCNN의 초기 두 단계와 유사하게 구현됩니다.

2. **Stage 2 (Mask Prediction):**
    * Stage 1에서 생성된 바운딩 박스 제안을 기반으로 각 도구에 대한 마스크 $P_{i,j,\hat{c}}$를 예측합니다.
    * 기존 MaskRCNN과 유사하지만, 중복되는 바운딩 박스들을 클래스 간 비최대 억제(NMS)를 적용하여 제거하는 사후 처리 단계를 추가하여 위양성(false-positive) 예측을 줄입니다.

3. **Stage 3 (Multi-Scale Mask Attended Classifier, MSMA):**
    * 이것이 본 논문의 핵심 기여로, Stage 2에서 예측된 마스크 $P_{i,j,\hat{c}}$와 원본 이미지 $I_i$를 입력받아 클래스 레이블 $\hat{c}$를 더 정확한 $c$로 개선합니다.
    * **다중 스케일 특징 추출:** ResNet 백본을 사용하여 $I_i$로부터 다중 스케일 특징을 추출합니다.
    * **마스크 어텐션 (Mask Attention):** 예측된 마스크 $P_{i,j,\hat{c}}$를 각 다중 스케일 특징 맵에 곱하여 도구 영역에만 집중하고 방해되는 배경 특징을 마스킹합니다.
    * **특징 통합:** 마스킹된 특징들을 $1 \times 1$ 컨볼루션을 통해 병합하여 각 인스턴스에 대한 단일 특징 맵을 생성합니다.
    * **임베딩 학습:** 마스킹된 특징 맵 위에 임베딩 레이어를 학습하여 각 도구 인스턴스에 대한 임베딩 $E_{i,j}$를 출력합니다.
    * **메트릭 학습 기반 분류:**
        * **Arc Loss:** 클래스 간의 낮은 시각적 유사성을 해결하기 위해 arc loss [16]를 사용하여 분류 헤드를 훈련합니다.
        $$L = -\frac{1}{C}\sum_{c=1}^{C} \log\frac{e^{\cos(\theta_c+m)}}{e^{\cos(\theta_c+m)} + \sum_{j=1, j\neq c}^{C} e^{\cos\theta_j}}$$
        여기서 $C$는 클래스 수, $m$은 각도 마진을 나타냅니다. Arc loss는 특징 간의 거리를 최대화하여 클래스 불균형과 낮은 클래스 간 분산을 효과적으로 처리합니다.
        * **미세 조정:** arc loss로 훈련한 후, 최종적으로 범주형 교차 엔트로피 손실로 분류 레이어를 미세 조정합니다.

## 📊 Results

* **성능 우위:** EndoVis2017 및 EndoVis2018 벤치마크 데이터셋에서 18개 이상의 SOTA 인스턴스 세분화 방법을 능가했습니다.
* **EndoVis2017:**
  * MaskRCNN 기반 S3Net은 ChallengeIoU(Ch$_{IoU}$)에서 72.54를 기록하며, ISINet 대비 Ch$_{IoU}$ 30%, mean class IoU(mc$_{IoU}$) 60% 향상을 달성했습니다.
  * TraSeTR (Transformer 기반)보다 Ch$_{IoU}$에서 20%, mc$_{IoU}$에서 26% 더 높은 성능을 보였습니다.
* **EndoVis2018:**
  * ISINet 대비 Ch$_{IoU}$ 3.8%, mc$_{IoU}$ 5.8% 향상을 달성했습니다. TraSeTR보다는 약간 낮은 성능을 보였는데, 이는 이 데이터셋에서 시간적 정보가 분류 외에 다른 결정 요인으로 작용할 수 있음을 시사합니다.
* **오분류 검증:** MaskRCNN의 예측 레이블을 실제(ground truth) 레이블로 대체했을 때 마스크 AP50 점수가 0.65에서 0.90으로 크게 향상되어, 기존 모델의 분류 부정확성이 성능 병목임을 입증했습니다.
* **마스크 어텐션 효과:** EndoVis2017의 초음파 프로브(Ultrasound Probe)에 대한 실험에서, 길쭉한 바운딩 박스(종횡비 > 3)가 도구를 잘 감쌀 때 84%의 높은 예측 정확도를 보여, 마스크 기반 어텐션의 필요성을 뒷받침했습니다.
* **메트릭 학습 효과:** 제거 연구(ablation study)에서 Stage 3를 교차 엔트로피로 훈련했을 때(Ch$_{IoU}$ 63.63)보다 arc loss로 훈련했을 때(Ch$_{IoU}$ 72.54) 성능이 현저히 높아, 유사한 도구 분류에 메트릭 학습이 중요함을 확인했습니다.

## 🧠 Insights & Discussion

* **의료 영상 특화 설계의 중요성:** 자연 영상 모델을 미세 조정하는 것을 넘어, 수술 도구 세분화와 같은 미세 분류 작업에는 의료 영상의 고유한 특성(유사한 외형, 비스듬한 배치, 작은 데이터셋)을 고려한 아키텍처 혁신, 특히 특화된 분류 단계가 필수적임을 보여주었습니다.
* **분류 헤드의 병목 현상:** 기존 SOTA 인스턴스 세분화 모델의 주된 한계는 세분화 마스크 자체보다는 분류 헤드의 약점이라는 점을 명확히 했습니다.
* **마스크 어텐션의 효과:** 도구의 모양과 사용 방식 때문에 발생하는 방해되는 배경 문제를 마스크 기반 어텐션으로 효과적으로 완화하여 분류 정확도를 높였습니다.
* **메트릭 학습의 역할:** 시각적으로 매우 유사한 클래스들을 구분해야 하는 과제에서 arc loss와 같은 메트릭 학습이 일반적인 교차 엔트로피보다 훨씬 우수하며, 클래스 간 분리도를 높이는 데 결정적인 역할을 함을 입증했습니다.
* **향후 연구 방향:** 본 연구는 분류 정확도 향상에 초점을 맞추었으나, 향후에는 시간적(temporal) 정보를 통합하여 마스크 품질과 인스턴스 레이블을 더욱 개선할 수 있습니다.
* **실용적 함의:** 제안된 프레임워크는 수술 도구 식별 및 세분화에 의존하는 다양한 다운스트림 애플리케이션에 활용될 수 있습니다.

## 📌 TL;DR

이 논문은 수술 도구 인스턴스 세분화에서 **기존 SOTA 모델의 낮은 분류 정확도** 문제를 해결하기 위해 **S3Net**이라는 새로운 3단계 딥러닝 프레임워크를 제안합니다. S3Net은 **Multi-Scale Mask Attended (MSMA) 분류 모듈**을 세 번째 단계로 도입하여, **마스크 기반 어텐션**으로 도구 영역에만 집중하고, 유사한 도구 간 구분을 강화하기 위해 **arc loss를 활용한 메트릭 학습**으로 훈련합니다. EndoVis2017 및 EndoVis2018 데이터셋에서 S3Net은 기존 SOTA 성능을 **최소 12점(20%) 이상 향상**시키며, 의료 영상의 미세 분류에 특화된 아키텍처와 학습 전략의 중요성을 입증했습니다.
