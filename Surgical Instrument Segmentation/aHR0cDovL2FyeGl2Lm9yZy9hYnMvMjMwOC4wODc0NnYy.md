# SurgicalSAM: Efficient Class Promptable Surgical Instrument Segmentation

Wenxi Yue, Jing Zhang, Kun Hu, Yong Xia, Jiebo Luo, Zhiyong Wang

## 🧩 Problem to Solve

기존의 수술 도구 분할(Surgical Instrument Segmentation, SIS) 모델들은 전체 모델 매개변수를 훈련해야 하므로 비효율적이며, 데이터셋 규모가 작아 일반화 성능이 저조하다는 문제가 있습니다. Segment Anything Model (SAM)은 이미지 분할 분야에서 강력한 기초 모델이지만, 수술 도구에 적용할 때 두 가지 주요 문제에 직면합니다:

1. **도메인 격차:** 일반 객체와 수술 도구 사이의 상당한 도메인 격차로 인해 SAM의 직접적인 제로샷(zero-shot) 일반화 성능이 떨어집니다.
2. **정확한 프롬프트 의존성:** SAM은 정확한 분할을 위해 정밀한 점 또는 경계 상자(bounding box) 프롬프트에 의존합니다. 이는 광범위한 수동 가이드 또는 고성능 전문 탐지기를 필요로 하여 복잡한 다단계 파이프라인으로 이어지며, 프롬프트의 미세한 흔들림(jitter)에도 민감하게 반응하여 분할 정확도를 저하시킵니다.
3. **낮은 클래스 간 분산:** 수술 도구 카테고리 간의 외형 유사성이 높아 클래스 구별이 어렵습니다.

이러한 문제들을 해결하고, 효율적이며 일반화 성능이 뛰어난 수술 도구 분할 방법을 제공하는 것이 이 연구의 목표입니다.

## ✨ Key Contributions

이 논문의 주요 기여는 다음과 같습니다:

* **SurgicalSAM 제안:** 수술 도구 지식을 SAM의 사전 훈련된 지식과 효율적으로 통합하여 클래스 프롬프트 기반의 수술 도구 분할을 가능하게 합니다. 이는 전문 모델 및 복잡한 다단계 솔루션보다 뛰어난 성능을 보입니다.
* **프로토타입 기반 클래스 프롬프트 인코더 개발:** 명시적인 프롬프트(점 또는 경계 상자)를 사용하지 않고, 클래스 프롬프트로부터 잠재 프롬프트 임베딩을 직접 학습하여 엔드투엔드 파이프라인을 구축합니다. 또한, 미세한 수술 도구 카테고리의 프로토타입 판별력을 향상시키기 위해 **대조 프로토타입 학습(contrastive prototype learning)**을 제안합니다.
* **광범위한 실험 및 SOTA 달성:** EndoVis2018 및 EndoVis2017 데이터셋에 대한 광범위한 실험을 통해 최첨단(SOTA) 성능을 달성하면서 훈련 효율성을 크게 개선합니다.

## 📎 Related Works

* **기존 수술 도구 분할(SIS) 연구:** TernausNet과 같은 U-Net 기반 인코더-디코더 네트워크를 사용하는 픽셀 분류 방식이 초기 연구의 주류였습니다. 이후 Mask-RCNN을 활용한 ISINet, 트래킹 단서를 통합한 TraSeTR, 시간적 일관성을 포함한 MATIS 등 마스크 분류(mask classification) 패러다임이 등장하여 공간적 클래스 불일치 문제를 줄였습니다. 하지만 이들은 주로 전문 모델 설계와 전체 매개변수 훈련에 의존하여 비효율적이고 작은 데이터셋에서 일반화 성능이 낮습니다.
* **Segment Anything Model (SAM) 활용 연구:** SAM은 제로샷 일반화 능력으로 주목받지만, 의료 영상 분할에서는 도메인 격차와 정확한 프롬프트 의존성 때문에 어려움을 겪습니다. 많은 연구에서 SAM의 제로샷 의료 영상 분할 성능이 저조하다고 보고되었습니다. SAM을 특정 도메인에 맞추려는 연구들도 있지만, 여전히 정확한 점/경계 상자 프롬프트가 필요하거나, 미세한 클래스 구별 능력이 부족한 문제가 있었습니다.

## 🛠️ Methodology

SurgicalSAM은 클래스 프롬프트 기반의 수술 도구 분할을 위해 SAM을 효율적으로 튜닝하는 엔드투엔드(end-to-end) 접근 방식을 제안합니다.

1. **전체 구조:**
    * **이미지 인코더($E_I$):** 입력 이미지를 임베딩($F_I$)으로 변환하며, SAM의 사전 훈련된 Vision Transformer (ViT-H)를 **고정(frozen)**하여 사용합니다.
    * **프로토타입 기반 클래스 프롬프트 인코더($E_{CP}$):** 클래스 프롬프트($c$)를 기반으로 프롬프트 임베딩을 생성합니다.
    * **마스크 디코더($D_M$):** 이미지 임베딩과 프롬프트 임베딩을 사용하여 최종 마스크를 예측하며, SAM의 마스크 디코더를 **튜닝(tuning)**합니다.

2. **프로토타입 기반 클래스 프롬프트 인코더($E_{CP}$):**
    * **클래스 프로토타입 뱅크($B$):** 각 클래스에 대한 대표 프로토타입($B^{(k)}$)으로 구성됩니다.
    * **유사도 행렬($S$):** 이미지 임베딩($F_I$)과 각 클래스 프로토타입의 내적을 계산하여 이미지 내의 공간별 유사도를 나타냅니다.
    * **클래스 활성화 특징($F^{(k)}_I$):** 유사도 행렬($S^{(k)}$)을 공간적 어텐션으로 사용하여 클래스별 영역을 활성화하고 이미지 임베딩에 더해 특징을 생성합니다.
    * **프롬프트 임베딩 생성:**
        * **Dense Prompt Embeddings ($T^{(c)}_D$):** 프롬프트된 클래스($c$)의 클래스 활성화 특징($F^{(c)}_I$)을 2계층 MLP에 통과시켜 생성합니다. 이는 SAM의 포어그라운드 마스크와 유사하게 긍정적(positive) 단서를 제공합니다.
        * **Sparse Prompt Embeddings ($T^{(c)}_S$):** 모든 클래스의 클래스 활성화 특징($F^C_I$)을 2계층 MLP에 통과시켜 'positivity-agnostic' 스파스 프롬프트 임베딩을 얻습니다. 여기에 긍정(λ$^+$) 및 부정(λ$^-$) 임베딩을 추가하여 'positivity-aware' 스파스 프롬프트 임베딩을 생성합니다. 이는 SAM의 점 프롬프트처럼 긍정 및 부정 단서를 모두 통합합니다.

3. **대조 프로토타입 학습(Contrastive Prototype Learning):**
    * 수술 도구의 높은 유사성 문제를 해결하기 위해, 프로토타입의 판별력을 높입니다.
    * 이미지 임베딩($F_I$)과 ground-truth 마스크($G^{(c)}$)를 사용하여 SAM 기반 클래스 임베딩($v^{(c)}$)을 추출합니다.
    * **프로토타입 대조 손실($L_{PCL}$):** infoNCE 손실에서 영감을 받아, 클래스 프로토타입을 앵커로, SAM 기반 클래스 임베딩을 샘플로 간주하여 $L_{PCL}$를 계산합니다. 이는 앵커 프로토타입과 해당 클래스 샘플 간의 유사도를 높이고, 다른 클래스 샘플과의 유사도를 낮춥니다.

4. **효율적인 튜닝:**
    * 이미지 인코더는 고정하고, 프로토타입 기반 프롬프트 인코더와 마스크 디코더의 매개변수만 업데이트합니다.
    * 손실 함수는 분할을 위한 Dice Loss($L_{DICE}$)와 프로토타입 학습을 위한 프로토타입 대조 손실($L_{PCL}$)로 구성됩니다: $L = L_{DICE} + L_{PCL}$.

## 📊 Results

* **EndoVis2018 및 EndoVis2017 데이터셋 성능:** SurgicalSAM은 기존 SAM 기반 제로샷 모델(MaskTrack-RCNN + SAM, Track Anything, PerSAM)을 모두 능가하며, SOTA 전문 모델과 동등하거나 더 우수한 성능을 달성했습니다. 특히 mean class IoU(mc IoU)에서 상당한 개선을 보였습니다.
* **효율성:**
  * **조정 가능한 매개변수:** SurgicalSAM은 4.65M개의 매개변수만 조정하여 MATIS Frame (68.72M)이나 MaskTrack-RCNN + SAM (57.67M)에 비해 훨씬 적은 매개변수로 작동합니다.
  * **훈련 속도 및 GPU 사용량:** MATIS Frame 대비 10배 이상 빠르고, GPU 메모리 사용량은 1/6 미만으로 매우 효율적입니다.
  * **추론 속도:** 엔드투엔드 파이프라인 덕분에 복잡한 다단계 SAM 기반 모델보다 빠른 추론 속도를 보입니다.
* **Oracle 시나리오 대비:** ground-truth centroid 또는 bounding box를 SAM의 프롬프트로 사용한 oracle 시나리오보다 SurgicalSAM이 ground-truth centroid 대비 Challenge IoU에서 EndoVis2018에서 20.07%, EndoVis2017에서 25.52% 개선된 성능을 보였습니다.
* **Ablation Study:** 대조 프로토타입 학습이 없을 경우 성능이 크게 저하되어, 미세한 수술 도구 카테고리 간의 판별력 향상에 핵심적인 역할을 함을 확인했습니다. Dense 및 Sparse 프롬프트 임베딩, 긍정/부정 임베딩 또한 각각 중요한 기여를 함을 입증했습니다.
* **교차 데이터셋 일반화:** EndoVis2018에서 훈련하고 EndoVis2017에서 평가했을 때 SOTA 전문 모델인 MATIS Frame보다 평균 IoU에서 11.43% 더 높은 성능을 보여, 새로운 데이터 분포에 대한 뛰어난 일반화 능력을 입증했습니다.

## 🧠 Insights & Discussion

* **도메인 격차 해소 및 효율적인 튜닝:** SurgicalSAM은 SAM의 강력한 사전 훈련 지식과 수술 도구 관련 도메인 특화 지식을 효율적인 튜닝을 통해 통합함으로써, 자연 객체와 수술 도구 간의 도메인 격차를 성공적으로 메웠습니다. 이는 특히 의료 영상 분야에서 SAM의 활용 가능성을 크게 확장합니다.
* **간소화된 엔드투엔드 파이프라인:** 명시적인 점이나 경계 상자 프롬프트 대신 클래스 프로토타입으로부터 직접 프롬프트 임베딩을 생성하는 접근 방식은 기존 SAM 기반 솔루션의 복잡한 다단계 파이프라인을 제거하고, 수동 개입이나 고성능 탐지기의 필요성을 없애면서 프롬프트 강건성(robustness)을 향상시켰습니다.
* **미세한 클래스 구별 능력 강화:** 대조 프로토타입 학습은 외형이 매우 유사한 수술 도구 카테고리 간의 판별력을 높이는 데 결정적인 역할을 했습니다. 이는 수술 환경에서 필수적인 정확한 도구 식별에 기여합니다.
* **임상적 중요성:** 클래스 프롬프트 기반의 분할 파이프라인은 수술 훈련, 계획, 내비게이션 및 수술 후 분석과 같은 다양한 임상 상황에서 외과의사의 컴퓨터 상호 작용을 크게 향상시킬 수 있습니다. 사용자가 도구 카테고리 ID만으로 관심 영역을 지정할 수 있어 직관적이고 효율적인 시스템을 구축할 수 있습니다.
* **한계 및 미래 방향:** 현재 연구는 클래스 프롬프트 기반 분할에 중점을 둡니다. 향후 연구에서는 여러 도구 인스턴스를 동시에 분할하거나, 특정 도구의 특정 부분(예: 끝부분)을 분할하는 등 더 세분화된 요구 사항을 다룰 수 있습니다.

## 📌 TL;DR

SurgicalSAM은 수술 도구 분할을 위해 SAM을 효율적으로 튜닝하는 새로운 방법을 제안합니다. 이 모델은 SAM의 도메인 격차 문제와 정밀한 프롬프트 의존성 문제를 해결하기 위해 **프로토타입 기반 클래스 프롬프트 인코더**를 도입하여 명시적 프롬프트 없이 클래스 정보만으로 분할이 가능하게 합니다. 또한, **대조 프로토타입 학습**을 통해 유사한 수술 도구들 간의 판별력을 강화합니다. 결과적으로 SurgicalSAM은 EndoVis2018 및 EndoVis2017 데이터셋에서 최첨단 성능을 달성하며, 훨씬 적은 수의 매개변수로 뛰어난 훈련 및 추론 효율성을 보여주었습니다.
