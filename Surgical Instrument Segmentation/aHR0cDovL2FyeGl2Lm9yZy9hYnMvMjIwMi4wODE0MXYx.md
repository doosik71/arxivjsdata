# FUN-SIS: a Fully UNsupervised approach for Surgical Instrument Segmentation

Luca Sestini, Benoit Rosa, Elena De Momi, Giancarlo Ferrigno, Nicolas Padoy

## 🧩 Problem to Solve

최소 침습 수술(MIS)에서 내시경 이미지의 자동 수술 도구 분할은 컴퓨터 지원 애플리케이션의 핵심 요소입니다. 그러나 현재 최첨단 접근 방식들은 수동으로 주석을 달아 얻는 지상 진실(ground-truth) 감독 신호에 전적으로 의존하며, 이는 대규모로 수집하기에 비용이 많이 듭니다. 또한, 기존의 비지도 비디오 객체 분할(VOS) 방법은 전경(도구)과 배경(조직)의 움직임이 강하게 상호작용하여 상관성이 높거나, 도구가 장시간 정지해 있는 수술 환경에서는 성능이 저하되는 한계가 있습니다.

## ✨ Key Contributions

* **새로운 비지도 광학 흐름 수술 도구 분할 접근 방식**: 현실적인 도구 `shape-priors` (반드시 동일한 데이터셋/도메인에서 오지 않아도 됨)를 활용하여 광학 흐름 이미지의 수술 도구 분할을 위한 새로운 생성적 적대적(generative-adversarial) 접근 방식을 제안합니다. 이는 '비일관성 배경 움직임' 가설을 완화하여 수술 도메인 특성에 적응합니다.
* **의사 라벨 노이즈 특성 심층 분석**: 제안된 광학 흐름 분할에서 생성된 의사 라벨($y_{T_{t}}$)의 '예측 불가능성(unpredictability)' 및 '양극화(polarization)'라는 두 가지 고유한 노이즈 특성을 식별하고 철저히 분석하여, 이들이 분할 결과 개선에 활용될 수 있음을 보여줍니다.
* **새로운 노이즈 라벨 학습 전략 제안**: 확장된 `Teacher-Student` 접근 방식을 기반으로, 앞서 언급된 노이즈 특성을 활용하여 '아마도 잘 라벨링된 영역'만을 선택적으로 학습하는 새로운 `learning-from-noisy-labels` 전략을 개발합니다. 이는 클린 라벨 없이 완전 비지도 방식으로 효율적인 영역 선택을 가능하게 합니다.
* **최첨단 성능 달성**: 세 가지 수술 데이터셋(MICCAI 2017 EndoVis Robotic Instrument Segmentation Challenge 데이터셋 포함)에서 완전 비지도 수술 도구 분할 결과가 완전 지도 학습 최첨단 접근 방식과 거의 동등한 수준임을 입증했습니다.

## 📎 Related Works

* **수술 도구 분할 (Surgical Tool Segmentation)**:
  * 초기에는 수작업 특징, Support Vector Machine, Random Forests, 템플릿 매칭 등 전통적인 방법을 사용했습니다.
  * 현재는 딥러닝 기반 완전 지도 학습 방법(예: TernausNet-16, MF-TAPNet)이 주로 사용되며, 높은 성능을 보이지만 수동 주석의 필요성으로 확장성이 제한됩니다.
  * 주석 문제를 완화하기 위해 크라우드소싱, 반합성 데이터 생성, 키네마틱스 정보 활용, Cycle-GAN 기반 도메인 적응 등이 연구되었습니다.
  * 비지도 접근으로는 수작업 단서(예: 색상 분포)를 사용해 의사 라벨을 생성하는 AGSD (Liu et al. (2020a))가 있습니다. 본 논문은 키네마틱 정보나 도메인 특정 수작업 단서 없이 접근합니다.
* **비디오 객체 분할 (Video Object Segmentation, VOS)**:
  * 움직임 정보는 VOS에서 핵심적인 단서로 활용됩니다.
  * **준지도 VOS**: 첫 프레임의 마스크를 추적하여 대상을 분할합니다.
  * **비지도 VOS**: 초기 마스크 없이 전경 객체를 배경으로부터 분리합니다 (예: CIS (Yang et al. (2019a)), Yang et al. (2021)의 오토인코더 접근). 수술 환경에서는 도구의 잦은 교체와 움직임 패턴의 특수성(정지, 배경과의 강한 상호작용)으로 인해 기존 비지도 VOS 방법이 실패하는 경우가 많습니다.
* **노이즈 라벨 학습 (Learning from Noisy Labels)**:
  * 대규모 데이터셋 구축 시 발생하는 노이즈 라벨 문제를 해결하기 위한 연구로, 크게 강건한 아키텍처, 강건한 정규화, 강건한 손실 함수 설계(예: 일반화 교차 엔트로피 GCE, 대칭 교차 엔트로피 SCE), 샘플 선택(예: MentorNet, Coteaching) 등으로 분류됩니다.
  * 의료 영상 분야에서는 몬테카를로 드롭아웃 기반 신뢰도 추정 (Yu et al. (2019)), 판별자를 이용한 픽셀 단위 신뢰도 점수 (Nie et al. (2018)) 등 준지도 학습이 제안되었지만, 본 논문은 클린 라벨 없이 노이즈 라벨의 고유한 특성만으로 지역 선택을 수행합니다.

## 🛠️ Methodology

FUN-SIS는 수술 도구 분할을 위한 3단계 완전 비지도 학습 접근 방식입니다.

1. **1단계: `Teacher` 모델 학습 (비지도 광학 흐름 분할)**
    * **목표**: `shape-priors` (대상 객체의 이진 분할 마스크, 반드시 비디오와 동일한 도메인일 필요는 없음)를 활용하여 광학 흐름 이미지에서 수술 도구를 분할하는 `Teacher` 모델 ($S_{\text{OF}}$)을 학습합니다.
    * **접근 방식**: `Cycle-GAN` 아키텍처에서 영감을 받은 생성적 적대적 학습(Generative-Adversarial Training)을 사용합니다.
        * **`complexity-imbalance` 해결**: `shape-priors`는 광학 흐름에 비해 복잡성이 낮기 때문에 발생하는 정보 불균형 문제를 해결하기 위해 다음을 적용합니다.
            * **단일 `cycle-consistency loss`**: `shape-priors` 도메인에만 $L_{\text{cycle}}$을 적용하여 정보 숨김(`steganography`)을 방지합니다.
            * **노이즈 벡터 연결**: `shape-priors` 마스크 $m$에 임의의 노이즈 벡터 $n$을 연결하여 생성자 ($G$)가 동일한 $m$으로부터 다양한 합성 광학 흐름 이미지 ($m_{\text{OF}}$)를 생성하게 함으로써 도구 실루엣과 움직임을 분리합니다.
            * **실시간(on-the-fly) 증강**: 광학 흐름 회전($AugmFlow$)을 포함한 강력한 실시간 이미지 증강을 활용하여 광학 흐름의 다양성을 높입니다.
    * **손실 함수**: 재구성 손실($L_{\text{cycle}}$), 생성자 적대적 손실($L_{G}^{\text{adv}}$), 판별자 적대적 손실($L_{D}^{\text{adv}}$)을 포함합니다.
    * **출력**: 각 프레임 $x_t$에 대해 광학 흐름 $y_{\text{OF}_{t}}$에서 `Teacher` 모델이 생성한 의사 라벨 마스크 $y_{T_{t}}$를 얻습니다.

2. **2단계: `Proxy` 모델 학습 (개별 프레임 분할)**
    * **목표**: `Teacher` 모델이 생성한 노이즈 의사 라벨 $y_{T_{t}}$을 직접 감독 신호로 사용하여 개별 프레임에서 도구 분할을 수행하는 `Proxy` 모델을 학습합니다.
    * **노이즈 특성 활용**: 의사 라벨의 **'예측 불가능성(unpredictability)'** 특성(노이즈가 개별 입력 이미지 $x_t$로부터 예측될 수 없음)을 활용하여, `Proxy` 모델이 노이즈를 외우기보다는 훈련 예시 전반에 걸친 '가장 쉬운 호환 패턴' (도구와 조직 분리)을 학습하도록 유도합니다.
    * **네트워크 구조**: 이 효과를 장려하기 위해 상대적으로 용량이 작은 네트워크(`Unet11`)를 사용합니다.
    * **손실 함수**: 이진 교차 엔트로피 손실($L_{P}^{\text{CE}}$)과 로그 Intersection-over-Union (IoU) 손실($L_{P}^{\text{IoU}}$)의 가중합($L_P = \alpha_P L_{P}^{\text{IoU}} + (1-\alpha_P) L_{P}^{\text{CE}}$)을 최소화합니다.

3. **3단계: `Student` 모델 학습 (향상된 개별 프레임 분할)**
    * **목표**: `Proxy` 모델과 `Teacher` 모델의 예측 간의 일치도를 기반으로 `Teacher`가 생성한 의사 라벨 $y_{T_{t}}$에서 '아마도 잘 라벨링된 영역'만을 선택하여 최종 `Student` 모델을 학습합니다.
    * **노이즈 특성 활용**: 의사 라벨의 **'양극화(polarization)'** 특성(개별 도구가 거의 완벽하게 분할되거나 완전히 잘못 라벨링되는 경향)을 활용합니다. 이는 `local IoU`를 통해 '잘 라벨링된 영역'을 효과적으로 식별할 수 있음을 의미합니다.
    * **`localIoU` 마스킹**: `Proxy` 예측 $y_{P_{t}}$와 `Teacher` 의사 라벨 $y_{T_{t}}$ 간의 지역 IoU ($IoU_{\text{loc}}(w,h)$)를 계산하고, 임계값 $\Theta_{\text{IoU}}$로 이진화하여 손실 전파를 마스킹합니다. 이진화된 $IoU_{\text{loc}}(w,h)$는 손실이 '아마도 잘못 라벨링된 영역'을 통해 전파되는 것을 방지합니다.
    * **손실 함수**: $IoU_{\text{loc}}(w,h)$로 마스킹된 이진 교차 엔트로피 손실($L_{S}^{\text{CE}}$)과 마스킹된 로그 IoU 손실($L_{S}^{\text{IoU}}$)의 가중합($L_S = \alpha_S L_{S}^{\text{IoU}} + (1-\alpha_S) L_{S}^{\text{CE}}$)을 최소화합니다.

* **학습 전략**: 1단계와 2단계는 동시에 수행될 수 있는 2단계 학습 전략이 3단계 순차 학습보다 효율적이고 비교 가능한 결과를 제공합니다.

## 📊 Results

* **광학 흐름 분할 (Teacher 모델)**:
  * `EndoVis2017VOS` 데이터셋에서 기존 최첨단 비지도 VOS 방법인 CIS (Yang et al. (2019a)) 대비 **+16.32%p** 향상된 40.08%의 평균 IoU를 달성했습니다.
  * 일반 객체 분할 데이터셋 `DAVIS2016`에서도 CIS (60.89%)를 능가하는 63.40%의 성능을 보였습니다. 이는 '비일관성 배경 움직임' 가설에 대한 독립성이 수술 시나리오에서 중요함을 시사합니다.
* **개별 프레임 수술 도구 분할 (Proxy & Student 모델)**:
  * `EndoVis2017VOS`에서 `Proxy` 모델은 `Teacher`의 의사 라벨(40.08% IoU) 대비 **+34.70%p** 향상된 74.78% IoU를 달성하며 `unpredictability` 노이즈 특성의 효과를 입증했습니다.
  * `Student` 모델은 `Proxy` 대비 **+8.99%p** 향상된 83.77% IoU를 달성했습니다. 이는 비지도 AGSD (Liu et al. (2020a))의 71.47%보다 **+12.30%p** 높고, 완전 지도 학습 최첨단 모델인 `MF-TAPNet` (89.61%)에 근접하는 성능입니다.
  * 도전적인 `STRAS` 데이터셋에서는 낮은 품질의 의사 라벨(29.93% IoU)에도 불구하고 `Student`가 66.37% IoU를 달성하며 방법론의 강건함을 보여주었습니다.
  * 2단계 학습 전략이 3단계 학습과 유사한 결과를 내면서 더 효율적임이 확인되었습니다.
* **노이즈 특성 (Unpredictability & Polarization) 분석**:
  * **`Unpredictability`**: 노이즈가 예측 불가능할 때 `Proxy` 모델은 노이즈 패턴을 학습하지 않고 일반 패턴을 학습하여 의사 라벨 대비 크게 개선된 성능을 보였습니다.
  * **`Polarization`**: 노이즈가 '양극화'될 때(`Tool-Drop` 노이즈) `Student` 모델의 `localIoU` 기반 영역 선택이 `Proxy` 대비 **+6.73%p**의 상당한 개선을 가져왔습니다. 이는 의사 라벨의 노이즈 특성을 효과적으로 활용했음을 의미합니다.
* **`Shape-Priors` 영향**:
  * `shape-priors`의 출처(`RoboTool` vs. `GrScreenTool`)가 다르거나 양이 극히 적어도(전체 `RoboTool shape-priors`의 10%인 51개 마스크만 사용) 성능 저하가 미미하여, 제안된 방법이 `shape-priors`의 품질 및 양에 매우 강건함을 입증했습니다.
* **랜덤 비라벨 데이터셋 (`RandSurg`) 적용**:
  * 최소한의 전처리만 거친 `RandSurg` 데이터로 훈련했을 때 `EndoVis2017VOS`에서 `Student`가 79.65% IoU를 달성했으며, 비라벨 데이터의 양이 증가함에 따라 성능이 향상됨을 보여주었습니다.
* **다른 도메인 적용 가능성 (`Cholec80`)**:
  * 로봇 수술과 다른 수동 복강경 수술 데이터셋인 `Cholec80`에서도 `RoboTool shape-priors`를 사용하여 효과적인 분할이 가능함을 정성적으로 입증했습니다.

## 🧠 Insights & Discussion

* **강점**: FUN-SIS는 `EndoVis2017`(로봇 수술), `STRAS`(유연 내시경 수술), `Cholec80`(수동 복강경 수술) 등 다양한 수술 데이터셋에서 이진 수술 도구 분할을 효과적으로 수행하는 강력한 완전 비지도 접근 방식을 제공합니다. 특히 `EndoVis2017VOS`에서 `Student` 네트워크는 83.77% IoU를 달성하여 기존 비지도 AGSD보다 **12.30%p** 높고, 완전 지도 SOTA인 MF-TAPNet보다 **5.84%p**만 낮은 뛰어난 성능을 보였습니다. 제안된 비지도 광학 흐름 도구 분할 접근 방식도 SOTA를 크게 능가했습니다. `shape-priors`는 다양한 방식으로 획득 가능하며(예: 녹색 스크린 촬영 도구, 다른 데이터셋의 재활용 주석) 그 품질과 양에 대해 매우 강건합니다. 노이즈 라벨의 고유한 특성(`unpredictability`, `polarization`)에 대한 분석과 이를 활용한 `learning-from-noisy-labels` 전략은 향후 연구의 중요한 기반이 될 수 있습니다.
* **한계 및 향후 개선 방향**:
  * **데이터 활용**: `local IoU`를 통한 영역 선택 시 상당량의 '불확실하게 라벨링된 픽셀' (약 49.52% in `EndoVis2017VOS`)이 버려집니다. 이들을 준지도 학습과 유사한 전략으로 활용하여 `Student` 학습에 기여할 수 있습니다.
  * **`local IoU` 유연성**: `local IoU` 계산에 사용되는 윈도우($w \times h$) 크기와 스트라이드가 고정되어 있습니다. 변화하는 도구 크기와 위치에 적응하는 유연한 접근 방식이 필요합니다.
  * **`Proxy` 네트워크 안정성**: `Proxy` 네트워크는 노이즈 의사 라벨로 인해 강한 경사에 노출되어 성능 진동이 발생할 수 있습니다. `self-ensembling` (Nguyen et al. (2020))과 같은 접근 방식으로 학습을 정규화하여 완화할 수 있습니다.
  * **광학 흐름 품질 의존성**: FUN-SIS 성능은 광학 흐름 이미지의 품질에 영향을 받으며, 이는 내시경 카메라 해상도 및 광학 흐름 추정기에 따라 달라집니다. 내시경 이미지에 특화된 광학 흐름 모델 및 고해상도 카메라 사용이 성능을 더욱 향상시킬 수 있습니다.
  * **다중 클래스 분할**: FUN-SIS는 도구 움직임에 전적으로 의존하므로 `instrument` 클래스 내에서 의미론적 차별화(예: 특정 도구 식별)를 수행할 수 없습니다. 움직임 패턴 분석 및 제한적인 외부 의미론적 감독을 통해 다중 클래스 분할로 확장하는 방법을 탐색할 수 있습니다.

## 📌 TL;DR

이 논문은 비라벨 내시경 비디오에서 수술 도구를 분할하는 **완전 비지도 학습 접근 방식인 FUN-SIS**를 제안합니다. 기존 방법의 **수동 주석 데이터 의존성이라는 문제**를 해결하기 위해, FUN-SIS는 1) `shape-priors`와 생성적 적대적 학습을 통해 **광학 흐름 이미지에서 의사 라벨($y_{T_{t}}$)을 생성**하고, 2) 이 **노이즈 의사 라벨의 독특한 특성(예측 불가능성, 양극화)을 활용**하는 새로운 `Teacher-Proxy-Student` 아키텍처를 통해 **개별 프레임 분할 모델을 훈련**합니다. `EndoVis2017` 등 다양한 수술 데이터셋에서 **완전 지도 학습 최첨단 모델에 거의 필적하는 성능**을 달성하며, 대량의 비라벨 수술 데이터를 활용할 엄청난 잠재력을 보여줍니다.
