# Automatic Instrument Segmentation in Robot-Assisted Surgery Using Deep Learning

Alexey A. Shvets, Alexander Rakhlin, Alexandr A. Kalinin, and Vladimir I. Iglovikov

## 🧩 Problem to Solve

로봇 보조 수술에서 수술 기구의 정확한 의미론적 분할(semantic segmentation)은 기구 추적 및 자세 추정(pose estimation)에 필수적인 중요한 문제입니다. 수술 장면은 그림자, 거울 반사, 혈액 및 카메라 렌즈 김서림과 같은 시각적 가림, 그리고 배경 조직의 복잡하고 역동적인 특성으로 인해 기구를 정확하게 픽셀 단위로 분할하기 어렵습니다. 신뢰할 수 있는 기구 추적 시스템을 위한 입력 데이터를 제공하기 위해 이러한 복잡한 환경에서 수술 기구를 정확하고 견고하게 분할하는 컴퓨터 비전 방법이 필요합니다.

## ✨ Key Contributions

* **최첨단 성능 달성:** 이 논문은 이진(binary) 및 다중 클래스(multi-class) 로봇 기구 분할 문제 모두에서 최첨단(state-of-the-art) 결과를 달성하는 심층 학습 기반 접근 방식을 제시합니다.
* **새로운 딥러닝 아키텍처 활용:** U-Net 모델을 기반으로 TernausNet(VGG11/16 인코더 사용) 및 수정된 LinkNet(ResNet18 인코더 사용)을 포함한 여러 새로운 심층 신경망 아키텍처를 도입하여 성능을 향상시켰습니다.
* **MICCAI 2017 챌린지 우수 성과:** MICCAI 2017 Endoscopic Vision SubChallenge: Robotic Instrument Segmentation에서 상위권에 랭크되었습니다.
* **오픈 소스 공개:** 개발된 솔루션의 소스 코드를 공개하여 연구 커뮤니티에 기여했습니다.

## 📎 Related Works

* **고전적인 기계 학습 방법:** 이전에는 색상 및/또는 텍스처 특징을 사용하여 기구-배경 분할을 이진 또는 인스턴스 분할 문제로 다루는 고전적인 기계 학습 알고리즘이 적용되었습니다.
* **의미론적 분할 접근 방식:** 이후 기구 또는 기구의 다른 부분을 구별하는 것을 목표로 하는 의미론적 분할 방법이 연구되었습니다.
* **심층 학습의 부상:** 최근 심층 학습 기반 접근 방식은 생체 의학 분야의 여러 문제(예: 유방암 조직학 이미지 분석, 뼈 질환 예측 및 연령 평가)에서 기존 기계 학습 방법보다 뛰어난 성능을 보였습니다.
* **기존 딥러닝 기반 기구 분할:** 이전에 심층 학습 기반 기법이 로봇 기구의 이진 분할에서 경쟁력 있는 성능을, 다중 클래스 분할에서 유망한 결과를 보여주었습니다.
* **U-Net 모델:** 본 논문의 접근 방식은 의료 영상 분할에서 성공적으로 사용된 U-Net 모델의 변형을 기반으로 합니다.

## 🛠️ Methodology

### 1. 데이터셋

* **수술 영상:** da Vinci Xi 수술 시스템에서 획득한 8개의 225프레임 시퀀스로 구성된 고해상도 스테레오 카메라 이미지(돼지 시술).
* **해상도 및 채널:** RGB 형식의 1920x1080 픽셀 해상도에서 1280x1024 픽셀 이미지로 잘라내어 사용했습니다.
* **그라운드 트루스:** 왼쪽 채널 이미지에 대해서만 수동으로 라벨링된 그라운드 트루스가 제공되었습니다.
* **다중 클래스 라벨:** 기구의 관절 부분(강체 샤프트, 관절 손목, 집게) 및 기구 유형(왼쪽/오른쪽 프로그라스프 겸자, 단극 곡선 가위, 큰 바늘 드라이버 등)에 대한 라벨이 포함됩니다.

### 2. 네트워크 아키텍처

* **U-Net:** 콘텍스트를 캡처하는 수축 경로(contracting path)와 정확한 위치를 가능하게 하는 대칭적인 확장 경로(expanding path)로 구성된 인코더-디코더 구조. 스킵 연결(skip-connection)을 사용하여 고해상도 특징을 전달합니다.
* **TernausNet:** ImageNet으로 사전 학습된 VGG11 또는 VGG16 네트워크를 인코더로 사용하는 U-Net과 유사한 아키텍처.
* **LinkNet:** 사전 학습된 ResNet18 아키텍처를 기반으로 하는 인코더를 사용합니다. 인코더에서 디코더 블록으로 정보가 추가되는 방식으로 스킵 연결이 이루어집니다. LinkNet은 경량 인코더 덕분에 추론 시간이 빠릅니다.

### 3. 훈련

* **평가 지표:** 자카드 지수(Jaccard index, IoU - Intersection Over Union)를 사용했습니다.
    $$
    J(A, B) = \frac{|A \cap B|}{|A \cup B|} = \frac{|A \cap B|}{|A| + |B| - |A \cap B|}
    $$
    픽셀 단위로 적용 시:
    $$
    J = \frac{1}{n} \sum_{i=1}^{n} \left( \frac{y_i \hat{y}_i}{y_i + \hat{y}_i - y_i \hat{y}_i} \right)
    $$
    여기서 $y_i$는 실제 이진 라벨, $\hat{y_i}$는 예측 확률입니다.
* **손실 함수:** 픽셀 분류 문제로 간주하여, 교차 엔트로피(H)와 자카드 지수(J)를 결합한 일반화된 손실 함수를 사용했습니다.
    $$
    L = H - \log J
    $$
    이진 분할에는 이진 교차 엔트로피를, 다중 클래스 분할에는 범주형 교차 엔트로피를 사용했습니다.
* **출력 및 임계값:** 모델의 출력은 각 픽셀이 관심 영역 또는 특정 클래스에 속할 확률을 나타내는 이미지입니다. 이진 분할의 경우 0.3의 임계값을 사용하여 픽셀 확률을 이진화했습니다.

## 📊 Results

* **이진 분할 (Instrument vs. Background):**
  * TernausNet-16이 IoU=0.836, Dice=0.901로 가장 우수한 성능을 보였으며, 이는 당시 문헌에서 보고된 최상의 결과였습니다.
* **다중 클래스 분할 (기구 부위별 - rigid shaft, articulated wrist, claspers):**
  * TernausNet-16이 IoU=0.655, Dice=0.760로 가장 우수한 성능을 보였습니다.
* **다중 클래스 분할 (기구 유형별):**
  * TernausNet-11이 IoU=0.346, Dice=0.459로 가장 우수했습니다. 이 결과는 데이터셋 크기가 상대적으로 작고 일부 클래스가 훈련 데이터셋에 적게 나타난다는 점으로 인해 다른 문제에 비해 성능이 낮았습니다.
* **추론 시간:**
  * LinkNet-18은 경량 인코더 덕분에 가장 빨랐으며, 1280x1024 픽셀 이미지에 대해 약 7ms의 추론 시간을 기록하여 TernausNet보다 두 배 이상 빨랐습니다.

## 🧠 Insights & Discussion

* **실시간 적용 가능성:** 개발된 종단 간(end-to-end) 파이프라인은 전체 이미지 해상도에서 효율적인 분석을 수행하여 실시간 수술 기구 위치 감지 문제에 좋은 기반을 제공할 수 있습니다. 이는 다시 수술 장면 근처에서 기구 추적 및 자세 추정에 활용될 수 있습니다.
* **데이터셋 크기의 중요성:** 다중 클래스 기구 유형 분할의 경우 낮은 성능이 상대적으로 작은 데이터셋 크기(특히 일부 클래스의 부족한 출현)와 관련이 있음이 밝혀졌습니다. 이는 데이터셋 크기를 늘림으로써 성능을 개선할 수 있음을 시사합니다.
* **성능과 속도의 균형:** TernausNet-16은 최고의 분할 정확도를 제공했지만, LinkNet-18은 더 빠른 추론 시간으로 실시간 시스템에 더 적합할 수 있음을 보여주어 정확도와 속도 간의 트레이드오프를 고려해야 함을 시사합니다.

## 📌 TL;DR

이 논문은 로봇 보조 수술에서 수술 기구의 자동 의미론적 분할 문제를 해결하기 위해 심층 학습 기반의 최첨단 접근 방식을 제안합니다. U-Net을 기반으로 VGG 인코더를 사용한 TernausNet과 ResNet 인코더를 사용한 LinkNet을 포함한 다양한 신경망 아키텍처를 탐색했습니다. 이진 및 다중 클래스 분할 모두에서 최첨단 성능을 달성했으며, 특히 TernausNet-16은 높은 정확도를, LinkNet-18은 빠른 추론 속도를 보였습니다. 이 방법은 실시간 수술 기구 추적 및 자세 추정의 견고한 기반을 제공할 잠재력을 가지고 있습니다.
