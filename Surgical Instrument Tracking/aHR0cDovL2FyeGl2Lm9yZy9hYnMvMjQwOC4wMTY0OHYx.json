{
  "title": "Zero-Shot Surgical Tool Segmentation in Monocular Video Using Segment\n  Anything Model 2",
  "authors": "Ange Lou, Yamin Li, Yike Zhang, Robert F. Labadie, Jack Noble",
  "year": 2024,
  "url": "http://arxiv.org/abs/2408.01648v1",
  "abstract": "The Segment Anything Model 2 (SAM 2) is the latest generation foundation\nmodel for image and video segmentation. Trained on the expansive Segment\nAnything Video (SA-V) dataset, which comprises 35.5 million masks across 50.9K\nvideos, SAM 2 advances its predecessor's capabilities by supporting zero-shot\nsegmentation through various prompts (e.g., points, boxes, and masks). Its\nrobust zero-shot performance and efficient memory usage make SAM 2 particularly\nappealing for surgical tool segmentation in videos, especially given the\nscarcity of labeled data and the diversity of surgical procedures. In this\nstudy, we evaluate the zero-shot video segmentation performance of the SAM 2\nmodel across different types of surgeries, including endoscopy and microscopy.\nWe also assess its performance on videos featuring single and multiple tools of\nvarying lengths to demonstrate SAM 2's applicability and effectiveness in the\nsurgical domain. We found that: 1) SAM 2 demonstrates a strong capability for\nsegmenting various surgical videos; 2) When new tools enter the scene,\nadditional prompts are necessary to maintain segmentation accuracy; and 3)\nSpecific challenges inherent to surgical videos can impact the robustness of\nSAM 2.",
  "citation": 13
}