# CL-MAE: Curriculum-Learned Masked Autoencoders

Neelu Madan, Nicolae-Cătălin Ristea, Kamal Nasrollahi, Thomas B. Moeslund, Radu Tudor Ionescu

## 🧩 Problem to Solve

기존 Masked Autoencoders (MAE)를 포함한 마스크드 이미지 모델링(Masked Image Modeling, MIM) 기법은 일반적으로 고정된 무작위 마스킹 전략을 사용합니다. 본 논문은 이러한 고정된 마스킹 전략이 모델의 학습 진행에 따라 작업의 난이도를 조절하지 못하여, 더 정교하고 전이 가능한 표현을 학습할 기회를 놓칠 수 있다는 문제점을 제기합니다. 점진적으로 작업 복잡성을 증가시키는 커리큘럼 학습(Curriculum Learning)을 통해 모델이 더 우수하고 전이 가능한 표현을 학습할 수 있을 것이라는 가설을 검증하고자 합니다.

## ✨ Key Contributions

- 강건한 표현 학습을 위해 Masked Autoencoders (MAE) 프레임워크에 커리큘럼 학습 개념을 도입했습니다.
- 원하는 복잡도 수준에 따라 적응형 마스크를 생성할 수 있는 새로운 학습 가능한 마스킹 모듈(Learnable Masking Module)을 제안했습니다.
- ImageNet 및 5가지 다운스트림 태스크에서 CL-MAE가 기존 MAE 대비 현저히 우수한 성능을 보임을 종합적인 실험 결과로 입증했습니다.

## 📎 Related Works

- **자기지도 표현 학습 (Self-supervised Representation Learning):**
  - 대비 학습(Contrastive Learning) 방법론(예: SimCLR, MoCo, BYOL)과 마스크드 이미지 모델링(MIM)이 주요 연구 분야입니다. 특히 MAE는 75%의 높은 마스킹 비율을 사용하여 데이터 증강 없이도 강건한 표현을 학습할 수 있음을 보여주었습니다.
- **마스크드 이미지 모델링 (Masked Image Modeling):**
  - BERT에서 영감을 받아 시각 토큰(visual tokens) 또는 특징(features) 재구성에 초점을 맞춥니다. 초기에는 외부 토크나이저나 시각 코드북(예: BEiT, PeCo, iBOT)을 사용했으나, 최근에는 픽셀 값을 직접 재구성하는 방식이 주류를 이룹니다. 기존 마스킹 전략은 의미론적 객체 부분 기반 또는 균일 샘플링 기반이었습니다.
- **커리큘럼 학습 (Curriculum Learning):**
  - Bengio et al.에 의해 소개된 전략으로, 쉬운 것부터 어려운 순서로 데이터를 제시하여 학습 결과와 일반화 능력을 향상시킵니다. 외부 복잡도 측정 또는 자기 주도 학습(self-paced learning) 기법을 사용하며, 이산적(discrete) 또는 연속적(continuous) 스케줄러가 있습니다. 본 연구는 모델의 재구성 오류를 난이도 척도로 활용하는 '쉬운-어려운' 연속 스케줄러를 마스킹 모듈에 통합합니다.

## 🛠️ Methodology

CL-MAE는 학습 가능한 마스킹 모듈과 MAE 백본을 포함하며, 다음 단계들을 통해 '쉬운-어려운' 커리큘럼을 생성합니다.

1. **학습 가능한 마스킹 모듈 (Learnable Masking Module):**
   - 입력 이미지 $I \in R^{h \times w \times c}$를 $n = (h \cdot w) / p^2$개의 겹치지 않는 패치로 분할하고, 이를 선형 레이어를 통해 토큰으로 변환합니다. 학습 가능한 `[CLS]` 토큰 $C \in R^d$를 연결하여 입력 토큰 $T \in R^{(n+1) \times d}$를 구성합니다.
   - Vision Transformer (ViT) 블록 기반 아키텍처를 사용하여 이 토큰들을 처리합니다.
   - `[CLS]` 토큰의 출력 $C_{out} \in R^d$는 Multi-Layer Perceptron (MLP)과 시그모이드($\sigma$) 활성화 함수를 거쳐 소프트 마스킹 확률 벡터 $Z \in [0,1]^n$를 생성합니다. $Z$의 각 요소 $z_i$는 $i$-번째 입력 토큰을 가시 상태로 유지할 확률을 나타냅니다.
   - MAE 학습 시에는 $Z$를 0.5를 기준으로 이진 마스크 $Z^* \in \{0,1\}^n$로 변환하여 사용합니다. 마스킹 모듈 자체 학습 시에는 $Z$를 직접 사용하여 기울기 전파를 허용합니다.
2. **공동 학습 절차 (Joint Training Procedure):**
   - 마스킹 확률의 이진화 과정에서 기울기 전파가 불가능하므로, 생성적 적대 신경망(GAN)과 유사하게 MAE와 마스킹 모듈을 독립적으로 업데이트하는 두 단계의 교대 학습을 사용합니다.
     - **1단계 (MAE 학습):** 마스킹 모듈을 고정하고, 마스킹 모듈에서 생성된 이진 마스크 $Z^*$를 사용하여 MAE 백본을 학습합니다.
     - **2단계 (마스킹 모듈 학습):** MAE 백본을 고정하고, 마스킹 모듈에서 생성된 소프트 마스킹 확률 $Z$를 입력 토큰에 직접 곱하여 마스킹 모듈을 학습합니다. 이를 통해 MAE의 재구성 손실에 대한 기울기가 마스킹 모듈로 전달되도록 합니다.
3. **제안된 손실 함수 (Proposed Loss Functions):**
   마스킹 모듈의 최적화를 위해 네 가지 손실 함수를 공동으로 최소화합니다.
   - **커리큘럼 손실 ($L_{CL}$):**
     $$L_{CL}(\hat{I}, I) = \lambda^{(t)}_{CL} \cdot (\hat{I}-I)^2$$
     $\lambda^{(t)}_{CL}$는 학습 스텝 $t$에 따라 선형적으로 양수($1$)에서 음수(예: $-0.1$)로 감소합니다. $\lambda^{(t)}_{CL} > 0$일 때는 마스킹 모듈이 MAE의 재구성 작업을 단순화하기 위해 쉬운 토큰을 마스킹(협력자 역할)하고, $\lambda^{(t)}_{CL} < 0$일 때는 MAE의 재구성 작업을 어렵게 하기 위해 어려운 토큰을 마스킹(적대자 역할)합니다.
   - **가우시안 손실 ($L_{Gauss}$):**
     $$L_{Gauss} = \frac{1}{\sigma\sqrt{2\pi}} \exp \left( -\frac{(Z-\mu)^2}{2\sigma^2} \right)$$
     마스킹 확률 $Z$가 0.5에서 멀어져 0 또는 1에 가깝도록 유도하여 마스킹 결정의 명확성을 강화합니다($\mu=0.5$, $\sigma=0.12$).
   - **쿨백-라이블러 손실 ($L_{KL}$):**
     $$L_{KL} = m \cdot \log \left( \frac{\hat{m}}{m} \right) + v \cdot \log \left( \frac{\hat{v}}{v} \right)$$
     마스킹 모듈이 모든 패치를 마스킹하거나 전혀 마스킹하지 않는 지름길을 택하는 것을 방지하고, 미리 정의된 마스킹 비율(즉, 원하는 마스킹 토큰 수 $m$ 및 보이는 토큰 수 $v$)을 유지하도록 강제합니다.
   - **다양성 손실 ($L_{div}$):**
     $$L_{div} = \frac{1}{p \cdot (p-1)} \sum_{i=1}^{p} \sum_{j=i+1}^{p} \exp \left( -\|Z_i - Z_j\|^2 \right)$$
     미니 배치 내의 각 이미지 샘플에 대해 다양한 마스크 구성을 생성하도록 장려하여, 마스킹 모듈이 단일 마스크에 수렴하는 '모드 붕괴(mode collapse)' 현상을 방지합니다.
   - **총 손실 ($L_{total}$):**
     $$L_{total} = L_{CL} + \lambda_{Gauss} \cdot L_{Gauss} + \lambda_{KL} \cdot L_{KL} + \lambda_{div} \cdot L_{div}$$
     각 손실 항의 기여도를 조절하는 하이퍼파라미터 $\lambda_{Gauss}, \lambda_{KL}, \lambda_{div}$는 모두 양수 값입니다.

## 📊 Results

- **ImageNet (사전 학습):** ViT-B, ViT-L, ViT-H를 포함한 모든 백본에서 Nearest Neighbor 평가 시 CL-MAE가 기존 MAE보다 일관되게 우수한 성능을 보였습니다. 특히 ViT-B와 ViT-H에서 상당한 성능 향상을 보였으며, 모든 개선은 통계적으로 유의미했습니다($p$-value 0.001).
- **다운스트림 태스크 (Nearest Neighbor & Linear Probing):** Aerial Images, Airbus Wind Turbines, Architectural Heritage Elements, Sea Animals, Sport Balls 등 5가지 벤치마크 데이터셋에서 Nearest Neighbor 및 Linear Probing 평가 결과, 총 60가지 경우 중 57가지 경우에서 CL-MAE가 MAE를 능가했으며, 최대 +4.0%p의 절대 정확도 향상을 보였습니다. 모든 개선은 통계적으로 유의미했습니다.
- **Few-shot Linear Probing:** 1-shot 및 2-shot 시나리오에서 특히 높은 성능 향상을 보였습니다. 총 150가지 경우 중 138가지 경우에서 MAE를 능가했으며, 최대 +13.5%p의 절대 정확도 향상을 달성했습니다.
- **어블레이션 연구 (Ablation Study):** 제안된 각 손실 함수($L_{Gauss}, L_{KL}, L_{div}, L_{CL}$)가 모델 성능 향상에 긍정적으로 기여함을 확인했습니다. 특히 다양성 손실($L_{div}$)과 커리큘럼 손실($L_{CL}$)이 CL-MAE의 성능 향상에 중요한 역할을 했습니다.

## 🧠 Insights & Discussion

- **커리큘럼 학습의 유효성:** 정성적 분석 결과(Figure 2)는 학습 가능한 마스킹 모듈이 학습 초기에는 재구성이 쉬운 비주요 영역이나 평평한 텍스처 부분을 마스킹하여 MAE를 '돕고', 학습 후반에는 재구성이 어려운 경계선, 객체 윤곽선, 주요 영역을 마스킹하여 MAE에 '도전적인' 과제를 제시함을 보여줍니다. 이러한 '쉬운-어려운' 커리큘럼이 MAE가 더욱 강건하고 전이 가능한 표현을 학습하는 데 기여했습니다.
- **손실 함수들의 중요성:**
  - 가우시안 손실($L_{Gauss}$)은 마스크 결정의 명확성을 높여 소프트 마스크 확률을 0 또는 1에 가깝게 만듭니다.
  - 쿨백-라이블러 손실($L_{KL}$)은 마스킹 모듈이 모든 패치를 마스킹하거나 전혀 마스킹하지 않는 '지름길'을 택하는 것을 방지하고, 항상 원하는 마스킹 비율을 유지하도록 강제합니다.
  - 다양성 손실($L_{div}$)은 마스킹 모듈이 입력에 관계없이 동일한 마스크를 생성하는 '모드 붕괴(mode collapse)' 현상을 해결하고, 다양한 마스크 생성을 유도하여 모델의 과적합을 방지하는 데 필수적입니다.
- **향후 연구 방향:** 본 연구는 MAE에 커리큘럼 학습을 통합하는 데 성공적인 결과를 보였습니다. 향후 연구에서는 비디오(video) 및 오디오-비디오(audio-video) 등 MAE가 성공적으로 적용된 다른 도메인으로 분석을 확장할 계획입니다.

## 📌 TL;DR

CL-MAE는 기존 Masked Autoencoders (MAE)의 고정된 무작위 마스킹 전략을 개선하기 위해 **커리큘럼 학습**을 도입한 새로운 자기지도 학습 프레임워크입니다. 핵심은 **학습 가능한 마스킹 모듈**에 있으며, 이 모듈은 학습이 진행됨에 따라 재구성 작업의 난이도를 '쉬움'에서 '어려움'으로 점진적으로 증가시키는 마스크를 생성합니다. 이는 마스킹 모듈이 학습 초기에는 MAE의 '협력자' 역할(재구성이 쉬운 토큰 마스킹)을 하다가 점차 '적대자' 역할(재구성이 어려운 토큰 마스킹)로 전환하며 이루어집니다. 마스킹 모듈은 가우시안, 쿨백-라이블러, 다양성 손실과 함께 커리큘럼 손실을 사용하여 훈련되며, MAE와 마스킹 모듈은 GAN처럼 번갈아 학습됩니다. ImageNet 및 5가지 다운스트림 태스크에서 CL-MAE는 MAE보다 일관되게 우수한 표현 학습 능력을 보였으며, 특히 Few-shot 시나리오에서 큰 폭의 성능 향상을 입증했습니다. 이는 점진적으로 난이도를 높이는 마스킹 전략이 모델의 강건한 표현 학습 및 전이 학습 능력 향상에 매우 효과적임을 시사합니다.
