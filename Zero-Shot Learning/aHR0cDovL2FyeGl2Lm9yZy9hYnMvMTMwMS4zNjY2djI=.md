# Zero-Shot Learning Through Cross-Modal Transfer

Richard Socher, Milind Ganjoo, Hamsa Sridhar, Osbert Bastani, Christopher D. Manning, Andrew Y. Ng

## 🧩 Problem to Solve

이 논문은 훈련 데이터가 전혀 없는 객체도 이미지에서 인식할 수 있는 모델을 개발하는 것을 목표로 합니다. 기존 제로샷 학습(Zero-shot learning) 모델의 대부분은 미학습 클래스(unseen classes) 간의 차이를 구별하는 데 그쳤으며, 훈련 데이터가 있는 클래스(seen classes)와 없는 클래스를 동시에 분류할 수 없다는 한계가 있었습니다. 본 연구는 자연어에 담긴 시각 세계에 대한 방대한 지식을 활용하여 이러한 미학습 객체를 분류하는 방법을 모색합니다.

## ✨ Key Contributions

- **훈련 데이터 없는 객체 인식:** 훈련 데이터가 없는 객체도 이미지에서 인식할 수 있는 새로운 모델을 소개합니다.
- **교차-모달 지식 전이:** 비지도 학습된 대규모 텍스트 코퍼스에서 얻은 언어의 분포 정보를 의미론적 기반으로 활용하여 미학습 범주에 대한 지식을 전이합니다.
- **통합된 분류 성능:** 수천 장의 훈련 이미지가 있는 클래스에서 최첨단 성능을 달성하는 동시에, 미학습 클래스에서도 합리적인 성능을 보여 두 가지를 하나의 프레임워크로 통합합니다.
- **수동 속성 불필요:** 단어나 이미지에 대해 수동으로 정의된 의미론적 특성을 요구하지 않습니다.
- **이상치 감지 기반 프레임워크:** 의미 공간에서 이상치 감지(outlier detection)를 사용하여 이미지가 알려진 범주에 속하는지 여부를 먼저 판단한 후, 두 가지 별도의 인식 모델을 적용합니다.

## 📎 Related Works

- **제로샷 학습 (Zero-Shot Learning):** Palatucci et al. [26]의 fMRI 스캔을 수동 특성 공간에 매핑하는 작업과 유사하지만, 본 연구는 미학습 클래스뿐만 아니라 학습된 클래스까지 동시에 분류할 수 있도록 확장했습니다. Larochelle et al. [21]은 '정형화된' 예시나 수동으로 레이블링된 속성으로 미학습 클래스를 설명했습니다.
- **원샷 학습 (One-Shot Learning):** Fei-Fei et al. [17], Salakhutdinov et al. [28] 등은 매우 적은 훈련 예시로 시각 객체 클래스를 학습하는 데 중점을 두었습니다. 본 연구는 아예 훈련 데이터가 없는 범주를 분류합니다.
- **지식 및 시각 속성 전이 (Knowledge and Visual Attribute Transfer):** Lambert et al. [19]과 Farhadi et al. [10]은 잘 설계된 시각 속성을 사용하여 미학습 클래스를 분류했습니다. 본 연구는 비지도 학습된, 정렬되지 않은 코퍼스에서 얻은 분포적 특성만을 사용합니다.
- **도메인 적응 (Domain Adaptation):** Blitzer et al. [4]의 감성 분석과 같이, 도메인 간에 특성이 다를 수 있지만 각 클래스에 대한 데이터가 있는 경우에 적용됩니다. 이는 일부 클래스에 데이터가 전혀 없는 제로샷 학습과는 다릅니다.
- **다중 모달 임베딩 (Multimodal Embeddings):** Socher et al. [30]은 KCCA를 사용하여 단어와 이미지 영역을 공통 공간에 투영했으나, 각 클래스에 소량의 훈련 데이터가 필요했습니다. Srivastava and Salakhutdinov [31]의 다중 모달 딥 볼츠만 머신(Deep Boltzmann Machines)처럼, 본 연구도 딥러닝 기술을 사용하여 이미지와 단어를 표현합니다.

## 🛠️ Methodology

1. **단어 및 이미지 표현 학습:**
   - **단어 벡터:** Huang et al. [15]의 비지도 모델에서 사전 훈련된 50차원 단어 벡터를 사용합니다. 이 벡터는 대규모 텍스트 코퍼스에서 단어의 분포적 유사성을 포착합니다.
   - **이미지 특징:** Coates et al. [6]의 비지도 방법을 사용하여 원본 픽셀에서 $F$차원 이미지 특징 벡터 $x \in \mathbb{R}^F$를 추출합니다.
2. **이미지를 의미론적 단어 공간으로 투영:**
   - 훈련 데이터가 있는 클래스 $y \in Y_s$의 모든 훈련 이미지 $x^{(i)}$를 해당 클래스 이름의 단어 벡터 $w_y$로 매핑합니다.
   - 이 매핑은 다음 목적 함수를 최소화하여 학습됩니다 (여기서 $\theta \in \mathbb{R}^{50 \times F}$는 학습 매핑 행렬):
     $$J(\theta) = \sum_{y \in Y_s} \sum_{x^{(i)} \in X_y} \|w_y - \theta x^{(i)}\|^2$$
   - 이를 통해 단어 의미에 시각적 접지(visual grounding)를 부여합니다.
3. **제로샷 학습 모델 (확률론적 프레임워크):**
   - 새로운 이미지 $x$에 대해, 알려진 클래스 $Y_s$와 미학습 클래스 $Y_u$를 포함한 모든 클래스 $y$에 대한 조건부 확률 $p(y|x)$를 예측합니다.
   - 이미지가 알려진 클래스에 속하는지 ($V=s$) 또는 미학습 클래스에 속하는지 ($V=u$)를 나타내는 이진 변수 $V$를 도입합니다.
   - 최종 예측은 다음과 같이 계산됩니다:
     $$p(y|x, X_s, W, \theta) = \sum_{V \in \{s,u\}} P(y|V,x,X_s,W,\theta)P(V|x,X_s,W,\theta)$$
   - **이상치 감지 ($P(V=u|x,X_s,W,\theta)$):**
     - 이미지가 미학습 클래스일 확률을 결정합니다. 이는 매핑된 훈련 이미지 매니폴드(manifold)에서 이상치 감지 점수를 임계값 처리하여 계산됩니다.
     - 이상치 점수는 알려진 클래스들의 가우시안 혼합 모델(mixture of Gaussians)에서 해당 이미지의 주변 확률 $P(x|X_s,W_s,\theta)$을 사용하여 계산됩니다.
     - $P(x|X_s,W_s,\theta) = \sum_{y \in Y_s} \mathcal{N}(\theta x|w_y, \Sigma_y)P(y)$
     - $\mathcal{N}(\theta x|w_y, \Sigma_y)$는 $\theta x$가 평균 $w_y$와 공분산 $\Sigma_y$ (해당 레이블의 매핑된 훈련 포인트에서 추정)를 갖는 가우시안 분포를 따를 확률입니다.
     - 만약 $P(x|X_s,W_s,\theta) < T$ (임계값 $T$)이면, 이미지는 미학습 클래스일 가능성이 높다고 판단합니다.
   - **분류 모델:**
     - **알려진 클래스 ($V=s$)일 경우:** 원본 $F$차원 특징에 대한 표준 소프트맥스(softmax) 분류기를 사용합니다.
     - **미학습 클래스 ($V=u$)일 경우:** 각 제로샷 의미론적 단어 벡터 주변에 등방성(isometric) 가우시안 분포를 가정하여 분류합니다.

## 📊 Results

- **데이터셋:** CIFAR10 데이터셋 (10개 클래스, 각 5000개의 32x32x3 RGB 이미지)을 사용했으며, Coates and Ng [6]의 방법을 통해 12,800차원 특징 벡터를 추출했습니다.
- **실험 설정:** 2개 클래스를 제로샷 클래스로 제외하고 실험을 진행했습니다.
- **제로샷 클래스만 분류:**
  - 미학습 클래스가 알려진 클래스와 의미론적으로 유사한 경우 성능이 크게 향상됩니다. 예를 들어, 'cat'과 'truck'을 미학습 클래스로 두면, 'cat'은 'dog'으로부터, 'truck'은 'car'로부터 지식을 전이받아 80% 이상의 정확도로 두 클래스를 구별할 수 있었습니다.
  - 반면, 'cat'과 'dog'을 미학습 클래스로 두면, 나머지 8개 클래스 중 충분히 유사한 클래스가 없어 성능이 저조했습니다.
- **제로샷 및 알려진 클래스 통합 분류:**
  - 이상치 감지 임계값에 따라, 알려진 클래스에 대한 정확도는 약 80%를 달성할 수 있었습니다.
  - 알려진 클래스에 대해 70%의 정확도를 유지하면서, 미학습 클래스는 15%에서 30% 사이의 정확도로 분류되었습니다 (10개 클래스 중 무작위 추측은 10%입니다). 이는 훈련 데이터가 전혀 없다는 점을 고려할 때 합리적인 성능입니다.

## 🧠 Insights & Discussion

- **비지도 의미론적 단어 벡터의 효과:** 비지도 방식으로 학습된 의미론적 단어 벡터가 범주 간 지식 전이(knowledge transfer)에 매우 효과적임을 입증했습니다. 이는 객체가 어떻게 생겼는지에 대한 '의미론적 기반'을 제공합니다.
- **이상치 감지의 중요성:** 이미지가 알려진 클래스에 속하는지, 미학습 클래스에 속하는지를 먼저 판별하는 베이즈(Bayesian) 프레임워크 내의 이상치 감지 메커니즘이 핵심적인 역할을 합니다. 이를 통해 제로샷 분류와 일반 분류를 하나의 통합된 프레임워크에서 수행할 수 있게 됩니다.
- **기존 한계 극복:** 본 모델은 이전 제로샷 학습 모델들이 미학습 클래스 간의 차이만 구별할 수 있었던 한계를 뛰어넘어, 알려진 클래스와 미학습 클래스를 동시에 분류하는 능력을 제공합니다.
- **수동 작업 감소:** 수동으로 정의해야 했던 의미론적 또는 시각적 속성이 필요 없어, 모델의 적용 가능성과 일반성을 높입니다.

## 📌 TL;DR

- **문제:** 이미지에서 훈련 데이터가 없는 객체를 인식하는 제로샷 학습의 한계를 극복하고, 알려진/미학습 클래스를 통합 분류하는 것이 목표입니다.
- **방법:** 비지도 학습된 단어 벡터로 이미지 특징을 의미 공간에 매핑하고, 이 공간에서 이상치 감지를 통해 이미지가 알려진 클래스인지 미학습 클래스인지 먼저 판별합니다. 이후, 알려진 클래스에는 표준 분류기를, 미학습 클래스에는 의미론적 단어 벡터 기반의 분류를 적용하는 확률론적 모델을 제안합니다.
- **성과:** 이 모델은 훈련 데이터가 있는 클래스에서 최고 수준의 성능을 유지하면서, 훈련 데이터가 없는 클래스에서도 15-30%의 합리적인 정확도를 달성하여 제로샷 학습과 표준 분류를 성공적으로 통합했습니다. 특히, 수동 속성 정의 없이 비지도 언어 지식을 활용하여 교차-모달 지식 전이의 효율성을 입증했습니다.
