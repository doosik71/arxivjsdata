# Zero-Shot Learning - The Good, the Bad and the Ugly

Yongqin Xian, Bernt Schiele, Zeynep Akata

## 🧩 Problem to Solve

이 논문은 급성장하는 제로샷 학습(Zero-Shot Learning, ZSL) 분야의 세 가지 주요 문제를 다룹니다:

1. **비교 불가능한 벤치마크**: ZSL 연구에서 통일된 벤치마크 및 평가 프로토콜이 부재하여, 발표된 결과들이 종종 비교하기 어렵거나 심지어 테스트 클래스를 훈련에 사용하는 등 잘못된 평가 방식이 사용되는 경우도 존재합니다.
2. **방법론 분석 부족**: 새로운 ZSL 방법론들이 꾸준히 제안되고 있지만, 기존의 SOTA(State-of-the-Art) 방법론들에 대한 심층적이고 체계적인 비교 분석이 부족합니다.
3. **현실성 부족**: 훈련 시 보지 못한 클래스를 인식하는 고전적인 ZSL 설정이 실제 애플리케이션 시나리오(본 클래스와 보지 못한 클래스가 동시에 존재하는 경우)를 충분히 반영하지 못합니다.

## ✨ Key Contributions

- **새로운 ZSL 벤치마크 정의**: 평가 프로토콜과 데이터 분할을 통일하여 새로운 ZSL 벤치마크를 정의했습니다. 이는 기존 벤치마크의 문제점(예: 특징 추출을 위한 사전 훈련 모델에 테스트 클래스 포함)을 해결합니다.
- **SOTA ZSL 방법론 심층 분석**: 고전적인 ZSL 및 보다 현실적인 일반화된 ZSL(Generalized Zero-Shot Learning, GZSL) 설정에서 주요 SOTA 방법론들을 깊이 있게 비교하고 분석했습니다.
- **분야의 한계점 논의**: 현재 ZSL 분야의 한계점을 논의하고, 이를 발전시키기 위한 향후 연구 방향에 대한 기반을 제시했습니다.

## 📎 Related Works

- **제로샷 학습 (ZSL)**: 훈련 세트와 테스트 세트의 클래스가 서로 다른 [17, 21, 22, 29, 40] 환경에서 미분류 데이터를 인식하는 문제. 중간 속성 분류기 학습 [21], 혼합 비율 학습 [42, 43, 25, 7], 호환성 학습 프레임워크 [3, 4, 11, 15, 26, 31, 33, 39] 등 다양한 접근법이 존재합니다. 본 연구에서는 DAP [21], CONSE [25], SSE [42], SJE [4], ALE [3], DEVISE [11], ESZSL [31], LATEM [39], CMT [33], SYNC [7] 등 대표적인 방법론들을 평가합니다.
- **일반화된 제로샷 학습 (GZSL)**: 테스트 시점에 이미 본 클래스와 보지 못한 클래스 모두가 포함되는 [32] 보다 현실적인 ZSL 설정. [11]은 레이블 임베딩을, [41]은 결합 선형 회귀를 제안했으며, [5]는 알려지지 않은 클래스일 확률을 추정하는 모델 레이어를 도입했습니다.
- **기존 ZSL 평가**: [29]와 [8] 같은 이전 평가 연구들이 존재하지만, 본 연구는 더 많은 방법론과 데이터셋, 통일된 프로토콜을 사용하여 더 광범위하고 심층적인 평가를 수행합니다.

## 🛠️ Methodology

본 논문은 ZSL 및 GZSL 작업을 체계적으로 평가하기 위한 통일된 프레임워크를 제시합니다.

- **ZSL 작업 공식화**:

  - 훈련 세트 $S = \{(x_n, y_n), n=1...N\}$와 훈련 클래스 $y_n \in Y_{tr}$가 주어졌을 때, 정규화된 경험적 위험을 최소화하는 함수 $f: X \to Y$를 학습합니다.
    $$ \frac{1}{N} \sum\_{n=1}^{N} L(y_n, f(x_n;W)) + \Omega(W) \quad (1) $$
  - 여기서 $f(x;W)$는 입력과 출력 임베딩 간의 매핑을 정의하며, 가장 높은 호환성 점수를 가진 클래스를 예측합니다.
    $$ f(x;W) = \text{argmax}\_{y \in Y} F(x,y;W) \quad (2) $$
  - ZSL은 테스트 이미지를 보지 못한 클래스 $Y_{ts} \subset Y$에 할당하고, GZSL은 테스트 이미지를 본 클래스 또는 보지 못한 클래스 $Y_{tr+ts} \subset Y$에 할당합니다.

- **평가 방법론 분류**:

  1. **선형 호환성 학습**: ALE [3], DEVISE [11], SJE [4]는 이선형 호환성 함수 $F(x,y;W) = \theta(x)^T W \phi(y)$를 사용하며, ESZSL [31]은 여기에 정규화 항을 추가합니다.
  2. **비선형 호환성 학습**: LATEM [39]은 조각별 선형 호환성을, CMT [33]는 신경망과 이상치 탐지 메커니즘을 통해 비선형 매핑을 학습합니다.
  3. **중간 속성 분류기 학습**: DAP [21]은 확률적 속성 분류기를 학습하여 클래스를 예측합니다.
  4. **하이브리드 모델**: SSE [42], CONSE [25], SYNC [7]는 이미지와 클래스 임베딩을 본 클래스 비율의 혼합으로 표현합니다.

- **데이터셋 및 평가 프로토콜**:
  - **데이터셋**: aPY, AWA, CUB, SUN (속성 데이터셋) 및 대규모 ImageNet을 사용합니다.
  - **이미지 및 클래스 임베딩**: 이미지 특징은 ResNet-101의 2048차원 최상위 풀링 유닛에서 추출(ImageNet 1K 사전 훈련). 클래스 임베딩은 속성 데이터셋의 경우 클래스별 속성을, ImageNet의 경우 Word2Vec [24]을 사용합니다.
  - **새로운 데이터셋 분할 (Proposed Splits, PS)**: 기존 표준 분할 (Standard Splits, SS)의 데이터 유출 문제(테스트 클래스가 ResNet 사전 훈련에 사용된 ImageNet 1K에 포함됨)를 해결하기 위해, 테스트 클래스가 ImageNet 1K에 포함되지 않는 새로운 분할을 제안합니다. 또한, PS는 GZSL 평가를 위해 테스트 시 훈련 클래스 이미지도 포함합니다.
  - **평가 기준**:
    - **ZSL**: 클래스별 평균 Top-1 정확도(average per-class top-1 accuracy)를 측정하여 불균형 데이터셋에서의 희소 클래스 성능을 중요하게 평가합니다.
    - **GZSL**: 훈련 클래스($acc_{Y_{tr}}$)와 테스트 클래스($acc_{Y_{ts}}$) 정확도를 모두 고려하는 조화 평균(Harmonic Mean, H)을 사용합니다.
      $$ H = 2 \cdot (acc*{Y*{tr}} \cdot acc*{Y*{ts}}) / (acc*{Y*{tr}} + acc*{Y*{ts}}) \quad (16) $$

## 📊 Results

- **ZSL 속성 데이터셋 결과**:

  - 새로운 제안 분할(PS)을 적용했을 때, 많은 테스트 클래스가 ImageNet 1K에 포함되었던 AWA 데이터셋의 정확도가 표준 분할(SS)에 비해 크게 감소했습니다. 이는 데이터 유출 방지의 중요성을 입증합니다.
  - PS 설정에서 ALE, DEVISE, SJE와 같은 최대 마진 호환성 학습(max-margin compatibility learning) 방법론들이 다른 방법론들(DAP, CMT, CONSE 등)보다 일관되게 우수한 성능을 보였습니다.
  - 파라미터 튜닝 강건성 평가에서, SUN 및 CUB 같은 세분화된 데이터셋은 안정적인 결과를 보였지만, AWA 및 aPY 같은 작고 거친 데이터셋은 검증 분할에 따라 결과가 불안정했습니다.

- **ZSL ImageNet 결과**:

  - 대규모 ImageNet 데이터셋에서 SYNC [7]가 가장 좋은 성능을 보였으며, 이는 대규모 설정에서의 강점 또는 Word2Vec 사용의 이점으로 해석될 수 있습니다.
  - 이미지 수가 많은 클래스에서의 성능이 적은 클래스보다 높았고, 전체 20K 클래스에서는 모든 방법론의 성능이 낮아 개선의 여지가 많음을 시사했습니다.

- **일반화된 ZSL (GZSL) 결과**:
  - GZSL 설정에서는 훈련 클래스가 검색 공간에 포함되므로, ZSL 결과보다 전반적으로 정확도가 현저히 낮아졌습니다.
  - 호환성 학습 프레임워크(ALE, DEVISE, SJE)는 테스트 클래스에서 강점을 보인 반면, 속성 분류기 학습 방법론(DAP, CONSE)은 훈련 클래스에서 강점을 보였습니다.
  - 조화 평균 (H) 기준으로 평가했을 때, ALE가 SUN, CUB, AWA에서 최고의 성능을 보였으며, 이상치 탐지 기능이 통합된 CMT*가 aPY에서 가장 우수했습니다. CMT*가 CMT보다 모든 경우에서 개선된 성능을 보여, 간단한 이상치 탐지 기법이 유용함을 나타냈습니다.

## 🧠 Insights & Discussion

- **호환성 학습의 우위**: 본 연구의 광범위한 평가를 통해, 최대 마진 호환성 학습 프레임워크(예: ALE, DEVISE, SJE)가 ZSL 작업에서 독립적인 객체/속성 분류기를 학습하거나 하이브리드 모델보다 더 일관되고 우수한 성능을 제공함을 확인했습니다.
- **평가 프로토콜의 중요성**: 기존 ZSL 벤치마크의 치명적인 문제점(예: 특징 추출 단계에서의 데이터 유출)을 명확히 밝히고, 이를 해결하기 위한 새로운 데이터 분할(Proposed Splits)의 중요성을 강조합니다. 이는 ZSL 방법론의 공정하고 정확한 평가를 위해 필수적입니다.
- **GZSL의 실용적 가치**: 실제 시나리오에서 GZSL이 ZSL보다 훨씬 실용적임을 강조하며, 훈련 클래스 정확도와 테스트 클래스 정확도를 균형 있게 고려하는 조화 평균이 GZSL 방법론의 성능을 평가하는 핵심 지표임을 보여줍니다.
- **미래 연구 방향**: GZSL 설정은 ZSL 방법론의 일반화 능력을 심층적으로 탐구할 수 있는 흥미로운 연구 분야입니다. 향후 연구는 훈련 클래스와 테스트 클래스 모두에서 강력한 성능을 발휘할 수 있는 방법론 설계에 초점을 맞춰야 합니다.

## 📌 TL;DR

이 논문은 제로샷 학습(ZSL) 분야의 혼란스러운 벤치마크와 평가 방식을 개선하기 위해, 데이터 유출을 방지하고 일반화된 시나리오(GZSL)를 포함하는 새로운 통일된 벤치마크 및 평가 프로토콜을 제안합니다. 주요 SOTA ZSL 방법론 10가지를 심층적으로 분석한 결과, 최대 마진 호환성 학습 프레임워크(예: ALE, DEVISE, SJE)가 다른 방법론들보다 우수한 성능을 보였습니다. 또한, 실제 적용을 위해 GZSL에서 훈련 및 테스트 클래스 정확도의 조화 평균이 중요한 평가 지표임을 강조하며, 공정한 평가 프로토콜의 필요성을 역설했습니다.
