# An Empirical Study and Analysis of Generalized Zero-Shot Learning for Object Recognition in the Wild

Wei-Lun Chao, Soravit Changpinyo, Boqing Gong, and Fei Sha

## 🧩 Problem to Solve

기존 Zero-Shot Learning (ZSL)은 테스트 데이터가 오직 **미학습(unseen) 클래스**에서만 나온다고 가정하는 비현실적인 환경에서 연구되어 왔습니다. 그러나 실제 환경에서는 **학습(seen) 클래스**와 미학습 클래스 모두에서 객체 인식이 이루어져야 합니다. 이 논문은 이러한 현실적인 시나리오, 즉 테스트 데이터의 클래스 멤버십이 제한되지 않는 **Generalized Zero-Shot Learning (GZSL)** 문제를 다룹니다.

저자들은 기존 ZSL 방법론으로 구축된 분류기를 GZSL 환경에 단순히 적용할 경우, 미학습 클래스 데이터가 거의 항상 학습 클래스로 오분류되는 심각한 성능 저하가 발생함을 경험적으로 보여줍니다. 이는 학습 클래스에 대한 레이블링된 데이터가 있기 때문에, 학습 클래스의 스코어링 함수가 미학습 클래스의 스코어링 함수보다 지배적이기 때문입니다. 따라서 GZSL 환경에서 학습 및 미학습 클래스 간의 인식 균형을 맞추는 것이 핵심 과제입니다.

## ✨ Key Contributions

- **GZSL 문제의 중요성 제기:** 기존 ZSL의 비현실적인 가정(테스트 시 미학습 클래스만 존재)을 비판하고, 학습 및 미학습 클래스가 함께 존재하는 GZSL의 필요성과 중요성을 강조했습니다.
- **"Calibrated Stacking" 방법 제안:** 학습 클래스와 미학습 클래스 간의 상충되는 인식 균형을 맞추기 위해 간단하지만 효과적인 보정(calibration) 방법인 "Calibrated Stacking"을 제안했습니다. 이 방법은 학습 클래스의 분류기 스코어에 보정 계수($\gamma$)를 적용하여 편향을 줄입니다.
- **"Area Under Seen-Unseen accuracy Curve (AUSUC)" 성능 지표 도입:** GZSL 접근 방식의 성능을 평가하기 위해, 학습 클래스 정확도($A_{S \to T}$)와 미학습 클래스 정확도($A_{U \to T}$) 간의 트레이드오프를 포괄적으로 측정하는 새로운 지표인 AUSUC를 개발했습니다.
- **광범위한 경험적 분석:** 여러 기존 ZSL 방법론(DAP, IAP, ConSE, SynC)을 GZSL 설정에서 AwA, CUB, ImageNet과 같은 벤치마크 데이터셋을 사용하여 광범위하게 평가하고, 제안된 보정 방법의 효과를 입증했습니다.
- **이상적인 의미론적 임베딩을 통한 성능 상한선 확립:** "이상적인 의미론적 임베딩" (클래스 대표 시각 특징인 'G-attr')을 사용하여 GZSL 성능의 이론적 상한선을 설정하고, 기존 방법과 이 상한선 간의 큰 격차를 분석하여 의미론적 임베딩의 개선이 GZSL 성능 향상에 결정적임을 밝혔습니다.

## 📎 Related Works

- **제한적인 GZSL 연구:** GZSL에 대한 이전 연구는 매우 적다고 언급됩니다.
- **학습 클래스를 포함하지만 미학습 클래스만 테스트한 연구:** [8, 17, 30, 31] 등은 분류기 레이블 공간에 학습 클래스를 포함시키지만, 실제 테스트는 미학습 클래스 데이터에 대해서만 수행했습니다.
- **2단계 접근 방식:** Socher et al. [9]은 이미지가 학습 클래스인지 미학습 클래스인지 먼저 예측한 다음 해당 분류기를 적용하는 2단계 접근 방식을 제안했지만, 2~6개의 미학습 클래스에 대해서만 실험을 수행했습니다.
- **액션 인식 GZSL:** [32]는 최대 3개의 학습 클래스만으로 일반화된 환경을 조사했습니다.
- **이진 분류기 중심 연구:** [33, 34]는 각 미학습 클래스에 대한 이진 분류기 훈련에 중점을 두어, 여러 미학습 클래스를 구별하는 방법은 명확하지 않았습니다.
- **Open Set Recognition:** [35, 36, 37]은 학습 및 미학습 클래스 모두에서 테스트를 고려하지만, 미학습 클래스를 단일 아웃라이어 클래스로 취급합니다.

## 🛠️ Methodology

1. **기존 ZSL의 GZSL 적용 문제:**

   - 각 클래스 $c \in T$에 대한 판별 스코어링 함수 $f_c(x)$가 주어질 때, 가장 직접적인 분류 규칙인 "direct stacking"은 $\hat{y} = \arg \max_{c \in T} f_c(x)$ 입니다.
   - 경험적 분석 결과, 이 방식은 미학습 클래스 데이터가 높은 확률로 학습 클래스로 오분류되어 $A_{U \to T}$가 크게 저하되는 문제를 보였습니다. 이는 학습 시 학습 클래스에 레이블된 데이터만 제공되므로 학습 클래스 분류기가 미학습 클래스 분류기보다 점수가 높게 나오는 경향이 있기 때문입니다.

2. **"Calibrated Stacking" 제안:**

   - **목표:** 학습 클래스와 미학습 클래스 간의 스코어 불균형을 해결합니다.
   - **규칙:** $\hat{y} = \arg \max_{c \in T} f_c(x) - \gamma I[c \in S]$
     - 여기서 $I[c \in S]$는 $c$가 학습 클래스일 경우 1, 아닐 경우 0인 지시 함수입니다.
     - $\gamma$는 보정 계수로, 학습 클래스의 스코어를 감소시켜 미학습 클래스가 더 높은 점수를 받을 수 있도록 합니다.
   - **해석:** $\gamma$는 미학습 클래스에서 데이터가 나올 사전 확률로 해석될 수 있으며, 이를 조절하여 학습-미학습 인식 간의 트레이드오프를 제어합니다. $\gamma=0$일 때 direct stacking과 동일하며, $\gamma \to +\infty$일 경우 오직 미학습 클래스만 고려하고, $\gamma \to -\infty$일 경우 오직 학습 클래스만 고려합니다.

3. **"Area Under Seen-Unseen accuracy Curve (AUSUC)" 성능 지표:**

   - $\gamma$ 값을 변화시키면서 얻어지는 일련의 ($A_{U \to T}$, $A_{S \to T}$) 정확도 쌍을 플롯하여 "Seen-Unseen accuracy Curve (SUC)"를 생성합니다.
   - AUSUC는 이 SUC 아래 영역을 계산한 값으로, GZSL 알고리즘이 두 가지 정확도($A_{U \to T}$와 $A_{S \to T}$) 사이의 균형을 얼마나 잘 맞추는지를 단일 숫자로 요약합니다. 이 지표는 모델 선택 및 하이퍼파라미터 튜닝에 사용됩니다.

4. **대안 접근 방식 비교 (Novelty Detection):**

   - Socher et al. [9]의 2단계 접근 방식인 Novelty Detection을 비교했습니다. 이 방식은 먼저 이미지의 'novelty score' $N(x)$를 통해 학습 클래스인지 미학습 클래스인지 예측한 후, 해당 분류기를 적용합니다.
   - **Gaussian 모델:** 학습 클래스 데이터를 Gaussian mixture model로 모델링하고, $N(x)$를 음의 로그 확률 값으로 정의합니다.
   - **LoOP 모델:** Local Outlier Probabilities (LoOP)를 사용하여 $N(x)$를 계산합니다.
   - **Calibrated Stacking과의 관계:** 특정 조건 하에서는 Calibrated Stacking과 유사한 예측 규칙을 가질 수 있음을 보였습니다.

5. **성능 상한선 및 이상적인 의미론적 임베딩 분석:**
   - ZSL 성능의 상한선을 파악하기 위해, 각 클래스의 이미지에서 평균 시각 특징을 추출한 "이상적인 의미론적 임베딩" (G-attr)을 사용했습니다.
   - 이 G-attr를 사용하여 분류기를 구성하고 GZSL 성능을 평가함으로써, 기존 의미론적 임베딩(word2vec, 속성)과의 격차를 분석하고, 소수의 레이블된 이미지를 사용하여 G-attr를 생성하는 "few-shot learning" 시나리오를 탐구했습니다.

## 📊 Results

- **"Direct Stacking"의 실패:** AwA, CUB 데이터셋에서 DAP, IAP, ConSE, SynC 등 기존 ZSL 방법론의 분류기를 GZSL에 단순히 적용할 경우, 미학습 클래스에 대한 정확도($A_{U \to T}$)는 0%대에 머무는 등 심각한 성능 저하를 보였습니다. 이는 미학습 클래스 데이터가 거의 항상 학습 클래스로 잘못 분류되기 때문입니다.
- **"Calibrated Stacking"의 우수성:**
  - 제안된 "Calibrated Stacking"은 AwA, CUB, ImageNet의 대규모 데이터셋에서 모든 기존 ZSL 방법론(DAP, IAP, ConSE, SynC, ESZSL)에 대해 novelty detection 기반의 대안 방식(Gaussian, LoOP)보다 일관적으로 높은 AUSUC 성능을 달성했습니다.
  - 특히 SynC (SynC$_{o-v-o}$ 및 SynC$_{struct}$) 방법은 Calibrated Stacking과 결합될 때 다른 ZSL 방법론보다 GZSL에서 훨씬 우수한 AUSUC 점수를 기록했습니다.
- **AUSUC의 유용성:** AUSUC를 사용하여 하이퍼파라미터를 튜닝할 경우, 학습 및 미학습 정확도를 개별적으로 최적화하는 것보다 더 나은 GZSL 모델을 얻을 수 있음을 보여주었습니다.
- **이상적인 성능과의 큰 격차:**
  - 실제 레이블 데이터를 사용하여 학습된 멀티클래스 분류기(GZSL 성능의 상한선)와 기존 ZSL 방법론(word2vec, 속성 기반 의미론적 임베딩 사용) 간에는 상당한 성능 격차가 존재합니다.
  - 이 격차는 특히 미학습 클래스 정확도($A_{U \to T}$)에서 두드러졌습니다.
- **이상적인 의미론적 임베딩('G-attr')의 효과:**
  - 클래스 대표 시각 특징인 'G-attr'를 의미론적 임베딩으로 사용할 경우, 기존 ZSL 방법론과 멀티클래스 분류기 간의 성능 격차가 크게 줄어들었습니다. 특히 CUB 데이터셋에서는 거의 멀티클래스 분류기 수준의 성능을 달성했습니다.
  - 이는 현재의 의미론적 임베딩(word2vec, 수동 정의 속성)이 GZSL 성능의 주요 병목임을 시사합니다.
- **Few-Shot G-attr의 강력함:** ImageNet-2K와 같은 대규모 데이터셋에서도, 각 미학습 클래스당 적은 수의 레이블된 이미지(예: 100개)로 G-attr를 생성하여 GZSL에 활용할 경우, word2vec 기반 임베딩보다 Flat hit@1에서 10배 이상 향상되는 등 멀티클래스 분류 성능에 빠르게 접근할 수 있음을 보여주었습니다.

## 🧠 Insights & Discussion

- **GZSL의 현실적 중요성 강조:** 이 연구는 ZSL 분야가 현실 세계의 객체 인식 문제에 더 잘 적용되기 위해서는 GZSL 설정에 대한 심층적인 연구가 필수적임을 성공적으로 입증했습니다. 기존 ZSL의 비현실적인 가정을 깨고 학습 및 미학습 클래스를 동시에 처리하는 능력의 중요성을 부각시켰습니다.
- **보정(Calibration)의 핵심 역할:** "Calibrated Stacking"의 간단함에도 불구하고 그 효과는 상당했습니다. 이는 GZSL에서 학습 클래스와 미학습 클래스 간의 스코어 불균형을 해소하고 적절한 균형점을 찾는 것이 매우 중요함을 시사합니다. 보정 계수 $\gamma$는 이 균형을 조절하는 강력한 도구로 작용합니다.
- **의미론적 임베딩의 품질이 병목:** 이상적인 시각 특징(G-attr)을 의미론적 임베딩으로 사용했을 때 성능이 크게 향상되는 결과는, 현재 사용되는 의미론적 임베딩(word2vec, 속성)의 품질이 GZSL 성능의 가장 큰 병목임을 명확히 보여줍니다. 이는 미래 연구가 시각적으로 더 유사한 클래스를 잘 나타내는 의미론적 임베딩을 개발하는 데 집중해야 함을 의미합니다.
- **Few-Shot 학습과의 연관성:** 소수의 레이블된 예제로도 G-attr가 GZSL 성능을 극적으로 향상시킬 수 있다는 발견은, 미학습 클래스에서 최소한의 레이블링 노력을 통해도 GZSL 시스템을 크게 개선할 수 있는 잠재력을 제시합니다. 이는 ZSL과 few-shot learning 간의 연결 고리를 강화하며, 하이브리드 접근 방식의 가능성을 열어줍니다.
- **향후 연구 방향:** 이 연구는 의미론적 임베딩의 개선이 GZSL 발전에 핵심적이라는 강력한 증거를 제공하며, 시각-의미론적 특징 간의 간극을 줄이고, 더욱 견고하고 표현력 있는 의미론적 임베딩을 학습하는 방법을 탐색하는 것이 중요함을 시사합니다.

## 📌 TL;DR

- **문제:** 기존 Zero-Shot Learning (ZSL)은 테스트 데이터가 오직 '미학습(unseen)' 클래스에서만 나온다고 가정하여 현실성이 부족합니다. '학습(seen)' 클래스와 미학습 클래스 모두에서 테스트 데이터가 나올 수 있는 Generalized Zero-Shot Learning (GZSL)이 필요하지만, 기존 ZSL 분류기를 GZSL에 단순히 적용하면 미학습 클래스 데이터가 학습 클래스로 잘못 분류되는 문제가 발생합니다.
- **방법:** 저자들은 GZSL을 위한 간단하지만 효과적인 'Calibrated Stacking' 방법을 제안합니다. 이 방법은 학습 및 미학습 클래스 분류기의 점수에 보정 계수($\gamma$)를 적용하여, 두 클래스 간의 인식 균형을 맞춥니다. 또한, 학습-미학습 정확도 간의 트레이드오프를 평가하기 위한 새로운 성능 지표인 Area Under Seen-Unseen accuracy Curve (AUSUC)를 도입했습니다.
- **결과:** Calibrated Stacking은 기존 novelty detection 기반 방법론에 비해 GZSL 환경에서 더 우수한 성능을 보였으며, 특히 'SynC' 방법과 결합 시 최고 성능을 달성했습니다. 나아가, 이상적인 의미론적 임베딩('G-attr', 즉 클래스 대표 시각 특징)을 사용했을 때 GZSL 성능이 크게 향상되는 것을 분석하여, 현재의 의미론적 임베딩(word2vec, 속성)의 품질이 GZSL 성능 개선의 핵심 병목임을 밝혀냈습니다. 이는 의미론적 임베딩 개선이 GZSL 발전에 매우 중요함을 시사합니다.
