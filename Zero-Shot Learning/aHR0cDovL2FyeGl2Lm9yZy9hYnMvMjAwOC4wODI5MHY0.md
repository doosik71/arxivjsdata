# Attribute Prototype Network for Zero-Shot Learning

Wenjia Xu, Yongqin Xian, Jiuniu Wang, Bernt Schiele, Zeynep Akata

## 🧩 Problem to Solve

기존 Zero-Shot Learning (ZSL) 방법들은 주로 사전 학습된 이미지 표현을 활용하고, 이미지 표현과 속성 간의 호환성 함수 학습에 초점을 맞춥니다. 그러나 이러한 접근 방식은 이미지 표현의 "지역성(locality)", 즉 이미지의 특정 영역을 시각적 속성과 연관시켜 해당 영역을 정확히 찾아내는 능력이 부족합니다. 이는 훈련 데이터의 속성 간 우연한 상관관계로 인해 네트워크가 새로운 클래스에서 발생하는 보지 못했던 속성 조합을 인식하지 못하고, 훈련 클래스에 편향될 수 있는 문제로 이어집니다. 이 논문은 ZSL의 핵심 과제로, 이러한 이미지 표현의 지역성 부족 문제를 해결하고 개선하는 것을 목표로 합니다.

## ✨ Key Contributions

* **속성 프로토타입 네트워크(Attribute Prototype Network, APN) 제안:** ZSL을 위한 이미지 표현의 지역성을 향상시키기 위해 새로운 End-to-End 프레임워크인 APN을 개발했습니다. APN은 중간 레이어 피처에서 속성을 동시에 회귀(regress)하고 탈상관(decorrelate)시켜 시맨틱 시각 속성을 인코딩하는 지역 피처를 학습합니다.
* **최첨단 성능 달성:** CUB, AWA2, SUN 등 세 가지 주요 벤치마크 데이터셋에서 Zero-Shot Learning (ZSL) 및 일반화된 Zero-Shot Learning (GZSL) 설정 모두에서 기존 최첨단 방법론 대비 일관된 성능 향상을 시연했습니다.
* **정확한 속성 지역화 능력:** 훈련 중 추가적인 부분(part) 주석을 사용하지 않고도 APN 모델이 속성 프로토타입의 어텐션 맵만으로 새의 부위를 정확하게 지역화할 수 있음을 정성적으로 보여주었으며, 이는 최신 약지도(weakly supervised) 지역화 방법보다 훨씬 더 뛰어난 부분 감지 결과를 달성했습니다.

## 📎 Related Works

* **Zero-shot learning (ZSL):** 훈련 시 관찰되지 않은 클래스를 분류하는 것이 목표이며, 클래스 임베딩을 통해 지식을 전이합니다. 많은 고전적 접근 방식은 이미지와 클래스 임베딩 공간 간의 호환성 함수를 학습하며, 최근에는 시각-시맨틱 임베딩 학습 또는 피처를 합성하는 생성 모델에 중점을 둡니다. 이들은 이미지 표현 학습 측면에서는 상대적으로 덜 탐구되었습니다.
* **Prototype learning:** 소프트맥스 기반 CNN과 달리, 프로토타입 네트워크는 테스트 이미지를 각 클래스의 프로토타입과의 거리 계산을 통해 분류하는 메트릭 공간을 학습합니다. 개방형 인식, 분포 외(Out-of-Distribution) 샘플, Few-Shot Learning에 강건한 것으로 알려져 있습니다. 본 연구는 샘플 기반이나 부분 기반 프로토타입과 달리, 입력 이미지 패치와 관련된 공간 피처를 활용하여 속성 프로토타입을 학습하는 점에서 차별화됩니다.
* **Locality and representation learning:** 지역 피처는 표현 학습, 사람 재식별, 이미지 캡셔닝, 세분화된 분류 등 다양한 분야에서 광범위하게 연구되었습니다. CNN은 고유하게 지역 정보를 활용하지만, 본 연구는 피처 채널이 아닌 이미지 피처의 공간적 구성을 개선하여 지역성을 명시적으로 강화합니다.

## 🛠️ Methodology

본 논문은 이미지 표현의 속성 지역화 능력(locality)을 개선하기 위해 End-to-End 학습되는 Attribute Prototype Network (APN)를 제안합니다. APN은 크게 세 가지 모듈로 구성됩니다:

1. **Image Encoder:** ResNet101과 같은 CNN 백본으로, 입력 이미지 $x$를 피처 표현 $f(x) \in \mathbb{R}^{H \times W \times C}$로 변환합니다. 여기서 $H, W, C$는 각각 높이, 너비, 채널을 나타냅니다.

2. **Base Module (BaseMod):**
    * $f(x)$에 대해 글로벌 평균 풀링(Global Average Pooling)을 적용하여 글로벌 식별 피처 $g(x) \in \mathbb{R}^{C}$를 학습합니다.
    * **시각-시맨틱 임베딩 레이어:** $g(x)$를 선형 레이어 $V \in \mathbb{R}^{C \times K}$를 통해 클래스 임베딩(예: 속성) 공간에 매핑합니다. 예측된 피처와 모든 훈련 클래스의 속성 벡터 $\phi(\hat{y})$의 내적을 계산하여 클래스 로짓을 생성하고, 교차 엔트로피 손실 $L_{CLS}$를 사용하여 최적화합니다. 이 손실은 이미지가 해당 속성 벡터와 가장 높은 호환성 점수를 가지도록 유도합니다.
    $$L_{CLS} = -\log \frac{\exp(g(x)^T V \phi(y))}{\sum_{\hat{y} \in Y_s} \exp(g(x)^T V \phi(\hat{y}))}$$

3. **Prototype Module (ProtoMod):** 이미지 표현의 지역성을 개선하고, 지역 피처 $f_{i,j}(x)$가 시맨틱 시각 속성을 인코딩하도록 강제합니다.
    * **속성 프로토타입 학습:** $K$개의 시각 속성에 해당하는 $K$개의 속성 프로토타입 $P = \{p_k \in \mathbb{R}^{C}\}_{k=1}^K$를 학습합니다. $p_k$는 $k$번째 속성의 프로토타입입니다.
    * **유사성 맵 생성:** 각 속성 $k$에 대해, 해당 속성 프로토타입 $p_k$와 각 공간 위치 $(i,j)$의 지역 피처 $f_{i,j}(x)$ 간의 내적을 계산하여 유사성 맵 $M_k \in \mathbb{R}^{H \times W}$를 생성합니다: $M_{k_{i,j}} = \langle p_k, f_{i,j}(x) \rangle$.
    * **속성 예측:** $k$번째 속성 $\hat{a}_k$는 해당 유사성 맵 $M_k$의 최댓값으로 예측됩니다: $\hat{a}_k = \max_{i,j} M_{k_{i,j}}$.
    * **속성 회귀 손실 ($L_{Reg}$):** 실제 클래스 $y$의 속성 벡터 $\phi(y)$와 예측된 속성 $\hat{a}$ 간의 평균 제곱 오차(MSE)를 최소화하여 지역 피처가 시맨틱 속성을 인코딩하도록 합니다.
    $$L_{Reg} = ||\hat{a} - \phi(y)||_2^2$$
    * **속성 탈상관화 손실 ($L_{AD}$):** 속성 간의 우연한 상관관계를 완화하기 위해 속성 프로토타입에 제약을 가합니다. $K$개의 속성을 $L$개의 서로 다른 그룹 $S_1, ..., S_L$으로 나누고, 각 그룹 $S_l$의 프로토타입 행렬 $P_{S_l} \in \mathbb{R}^{C \times |S_l|}$의 $c$번째 행 $P_{S_l_c}$에 대한 L2 norm을 최소화합니다. 이는 동일 그룹 내 속성 프로토타입 간의 피처 공유를, 다른 그룹 간에는 피처 경쟁을 유도합니다.
    $$L_{AD} = \sum_{c=1}^{C} \sum_{l=1}^{L} \|P_{S_l_c}\|_2$$
    * **유사성 맵 압축 손실 ($L_{CPT}$):** 유사성 맵 $M_k$가 최댓값을 가지는 영역에 집중하도록 유도하는 정규화항입니다. 이는 속성 프로토타입이 소수의 지역 피처만 닮도록 하여 압축된 유사성 맵을 생성합니다.
    $$L_{CPT} = \sum_{k=1}^{K} \sum_{i=1}^{H} \sum_{j=1}^{W} M_{k_{i,j}} [ (i-\tilde{i})^2 + (j-\tilde{j})^2 ]$$
    여기서 $(\tilde{i}, \tilde{j})$는 $M_k$에서 최댓값을 가지는 공간 좌표입니다.

4. **전체 모델 학습:** Image Encoder, BaseMod, ProtoMod를 다음 목적 함수로 동시에 최적화합니다:
    $$L_{APN} = L_{CLS} + \lambda_1 L_{Reg} + \lambda_2 L_{AD} + \lambda_3 L_{CPT}$$
    여기서 $\lambda_1, \lambda_2, \lambda_3$는 하이퍼파라미터입니다.

5. **Zero-shot 추론 및 속성 지역화:**
    * **ZSL 추론:** 학습된 BaseMod의 시각-시맨틱 임베딩 레이어를 직접 사용합니다. GZSL의 경우, 보지 못한 클래스에 대한 예측 편향을 줄이기 위해 Calibrated Stacking (CS)을 적용합니다.
    * **속성 지역화:** ProtoMod에서 생성된 유사성 맵 $M_k$를 입력 이미지 크기로 업샘플링하여 이미지 내에서 $k$번째 속성이 해당하는 영역을 시각적으로 나타냅니다.

## 📊 Results

* **ZSL 및 GZSL 성능:**
  * APN은 CUB, AWA2, SUN 데이터셋에서 ZSL 정확도를 Baseline (BaseMod만 사용) 대비 일관되게 향상시켰습니다 (각각 2.0%, 3.5%, 1.6% 개선). 특히 속성 회귀 손실 $L_{Reg}$과 속성 탈상관화 손실 $L_{AD}$가 주요 정확도 향상에 기여했습니다.
  * GZSL의 조화 평균(Harmonic Mean, H)에서도 최첨단 비생성 모델 대비 뛰어난 성능을 보였습니다 (CUB에서 67.2%, SUN에서 37.6%, AWA2에서 65.5%).
* **생성 모델 성능 부스트:** APN으로 추출된 피처 $g(x)$를 ABP 및 f-VAEGAN-D2와 같은 생성 모델의 입력으로 사용할 경우, 미세 조정된 ResNet 피처를 사용했을 때보다 상당한 성능 향상을 달성했습니다 (예: ZSL에서 ABP* 대비 APN+ABP가 CUB 2.6%, AWA 5.3% 향상). 이는 APN 피처가 보지 못한 클래스로의 지식 전이를 더 효과적으로 수행함을 나타냅니다.
* **부분 및 속성 지역화 평가 (CUB 데이터셋):**
  * **정량적 평가:** APN은 부분 지역화 정확도 지표인 PCP(Percentage of Correctly Localized Parts)를 BaseMod (30.7%) 대비 평균 22.1% 향상된 52.8%로 개선했습니다. 특히 가슴, 머리, 날개, 다리 부위에서 큰 개선을 보였습니다. 또한, 약지도 지역화 모델인 SGMA (61.5%) 대비 APN은 79.2%의 훨씬 높은 지역화 정확도를 달성했습니다.
  * **정성적 평가:** APN은 BaseMod에 비해 더 집중되고 다양한 어텐션 맵을 생성하여, 새의 특정 몸통 부위를 더 정확하게 지역화함을 시각적으로 입증했습니다. 또한, 바운딩 박스 주석 없이도 속성 수준의 지역화가 가능함을 보여주었습니다.
* **이진 vs. 연속 속성:** APN은 이진 속성과 연속 속성 모두에서 유사한 속성 예측 및 부분 지역화 정확도를 보여주었으며, 이는 비싼 연속 속성 주석에 의존하지 않고도 이진 속성에도 잘 일반화될 수 있음을 시사합니다.

## 🧠 Insights & Discussion

* **향상된 지역성의 중요성:** 이 연구는 ZSL에서 이미지 표현의 지역성을 강화하는 것이 보지 못한 클래스로의 지식 전이와 일반화 능력을 크게 향상시키는 데 결정적임을 입증했습니다. 이는 속성 기반 지식 전이의 효과를 극대화하는 중요한 방향성을 제시합니다.
* **속성 탈상관화의 효과:** $L_{AD}$ 손실은 속성 간의 우연한 상관관계를 줄여 네트워크가 훈련 데이터의 특정 패턴에만 의존하지 않고, 새로운 속성 조합을 더 유연하게 처리하도록 돕는 중요한 역할을 합니다.
* **모델 해석 가능성 증진:** APN의 속성 지역화 능력은 모델의 추론 과정에 대한 시각적 증거를 제공하여 해석 가능성을 높입니다. 이는 사용자가 모델의 학습 과정을 이해하고, 예측 오류의 원인을 파악하는 데 유용한 정보를 제공합니다.
* **한계점 및 향후 연구:**
  * 속성 간의 복잡한 상관관계 문제는 여전히 완전히 해결되지 않은 도전 과제로 남아 있습니다 (예: '흰색 배'와 '흰색 가슴'을 혼동하는 사례). 이는 향후 연구에서 더 깊이 탐구되어야 할 부분입니다.
  * ZSL의 예측 정확도는 여전히 보거나 보지 못한 클래스 모두로 훈련된 완전 지도 학습 모델보다는 낮습니다. 따라서 높은 정확도와 신뢰성이 요구되는 특정 응용 분야(예: 자율주행)에는 제한적으로 적용될 수 있습니다.
  * 모델의 일반화 능력은 클래스 간 유사성을 설명하는 보조 정보(속성)의 품질에 크게 의존합니다. 편향되거나 불완전한 보조 정보는 ZSL 모델의 일반화 능력에 부정적인 영향을 미칠 수 있습니다.

## 📌 TL;DR

이 논문은 Zero-Shot Learning (ZSL)에서 이미지 표현의 지역성 부족 문제를 해결하기 위해 **Attribute Prototype Network (APN)**를 제안합니다. APN은 글로벌 및 지역 피처를 동시에 학습하며, 중간 피처에서 속성을 회귀하고 속성 프로토타입을 탈상관화함으로써 이미지 표현의 속성 지역화 능력을 크게 개선합니다. APN은 ZSL 및 일반화된 ZSL 벤치마크에서 최첨단 성능을 달성했으며, 훈련 시 부분 주석 없이도 이미지 내에서 속성을 정확하게 지역화할 수 있음을 입증하여 모델의 해석 가능성을 높였습니다.
