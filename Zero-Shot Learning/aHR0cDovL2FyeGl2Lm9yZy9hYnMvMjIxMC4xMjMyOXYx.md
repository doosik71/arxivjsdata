# PROGEN: Progressive Zero-shot Dataset Generation via In-context Feedback

Jiacheng Ye, Jiahui Gao, Jiangtao Feng, Zhiyong Wu, Tao Yu, Lingpeng Kong

## 🧩 해결하고자 하는 문제

기존의 제로샷 데이터셋 생성 방법은 대규모 사전 학습 언어 모델(PLM)을 사용하여 태스크별 모델을 위한 합성 데이터셋을 생성합니다. 이 접근 방식은 적은 수의 파라미터로도 PLM과 유사하거나 더 나은 성능을 달성할 수 있지만, 생성된 합성 데이터셋은 정보성이 낮고 중복성이 많아 품질이 떨어진다는 고질적인 문제가 있습니다. 이는 대규모 합성 데이터가 인간이 레이블링한 데이터에서 기대할 수 있는 성능 향상으로 이어지지 않는 주된 원인입니다. 본 연구는 이처럼 품질이 낮은 합성 데이터셋 문제를 해결하고, 더 고품질의 데이터를 생성하는 것을 목표로 합니다.

## ✨ 주요 기여

* 더 고품질의 데이터셋을 생성하기 위한 `PROGEN`이라는 점진적 제로샷 데이터셋 생성 프레임워크를 제안합니다.
* 인간 주석 없이 각 샘플의 품질을 추정하기 위해 노이즈에 강한 영향 함수(noise-resistant influence function)와 인컨텍스트 피드백(in-context feedback)을 통한 학습 없는 제어 가능한 생성 방법론을 제안합니다.
* 다수의 텍스트 분류 데이터셋에서 제안된 프레임워크가 다양한 프롬프트 기반 방법론 대비 우수한 성능을 달성하며, 인컨텍스트 피드백이 없는 방법론과 비교하여 단 1%의 합성 데이터셋 크기로도 동등하거나 더 나은 제로샷 성능을 보여줍니다.

## 📎 관련 연구

* **PLM을 활용한 데이터셋 생성**: 대규모 인간 주석 데이터의 필요성을 줄이기 위해 PLM의 생성 능력을 활용하여 합성 데이터셋을 생성하는 연구가 활발히 진행되고 있습니다 (Anaby-Tavor et al., 2020; Puri et al., 2020; Kumar et al., 2020). 특히 제로샷 데이터셋 생성 분야에서는 프롬프트 기반 방법을 통해 인간 주석 없이 데이터를 생성합니다 (Schick and Schütze, 2021; Meng et al., 2022; Ye et al., 2022). 이전 연구들은 대부분 전체 데이터셋을 한 번에 생성하지만, 본 연구는 생성 과정 중에 데이터셋 품질을 개선합니다.
* **인컨텍스트 학습 (In-context Learning)**: Brown et al. (2020)이 제시한 바와 같이, 대규모 PLM은 몇 가지 입출력 데모 쌍을 조건으로 태스크를 학습할 수 있습니다. 이는 PLM의 파라미터 업데이트 없이 모델 성능을 향상시키는 매력적인 패러다임입니다. 인컨텍스트 예제 선택 방법 (Liu et al., 2022b; Lu et al., 2022), 학습 목표 (Min et al., 2022a), 그리고 이론적/실험적 분석 (Xie et al., 2021; Min et al., 2022b) 등 다양한 연구가 이루어졌습니다. 본 연구는 이러한 인컨텍스트 학습을 제로샷 데이터셋 생성 환경에 적용합니다.

## 🛠️ 방법론

PROGEN은 태스크별 모델(TAM)의 피드백을 활용하여 합성 데이터셋의 품질을 점진적으로 향상시키는 프레임워크입니다.

1. **초기 데이터셋 생성**: PLM과 초기 프롬프트를 사용하여 소량의 합성 훈련 데이터셋 ($D_{train}$) 및 검증 데이터셋 ($D_{val}$)을 생성합니다.
2. **TAM 훈련**: 현재까지 생성된 $D_{train}$과 $D_{val}$을 사용하여 태스크별 모델(TAM)을 훈련합니다.
3. **주석 없는 품질 추정 (Annotation-free Quality Estimation)**:
    * **노이즈에 강한 영향 함수**: 훈련된 TAM을 기반으로 각 샘플의 품질을 추정하기 위해 영향 함수(Influence Function, IF)를 사용합니다. 제로샷 설정에서는 깨끗한 인간 주석 검증 세트를 사용할 수 없으므로, 합성 검증 세트의 잠재적 노이즈를 처리하기 위해 노이즈에 강한 목적 함수를 통합합니다.
    * **Reverse Cross-Entropy (RCE) Loss**: 특히, 검증 세트에 대해 Reverse Cross-Entropy (RCE) 손실 ($L'$)을 사용하여 영향 함수를 계산합니다.
        $$ I_{up,loss}(z,D_{val}) = -\nabla_{\theta}L'(D_{val},\hat{\theta})^{T} H_{\hat{\theta}}^{-1} \nabla_{\theta}L(z,\hat{\theta}) $$
        여기서 $z$는 훈련 데이터 포인트, $D_{val}$은 합성 검증 세트, $\hat{\theta}$는 훈련된 TAM의 파라미터, $H_{\hat{\theta}}$는 헤세 행렬입니다. RCE 손실은 노이즈에 더 강한 특성을 가집니다.
    * **도움이 되는 샘플 식별**: 계산된 영향 점수를 오름차순으로 정렬하여, 가장 가치 있는 상위 $M$개의 샘플($D_{helpful}$)을 선택합니다 (음수 값이 작을수록 더 가치 있음).
4. **인컨텍스트 학습을 통한 피드백 (Feedback via In-context Learning)**:
    * 식별된 $D_{helpful}$의 샘플들을 인컨텍스트 예제(in-context examples)로 활용하여 PLM의 생성 분포를 조절합니다.
    * PLM은 이제 일반적인 프롬프트 $T(y)$ 외에, $D_{helpful}$에서 무작위로 선택된 인컨텍스트 예제들을 포함한 프롬프트로 새로운 $x$를 생성합니다.
        $$ x \sim P(\cdot | T(y_1, x_1), \dots, T(y_k, x_k), T(y)) $$
        이를 통해 PLM은 도움이 되는 샘플들의 전반적인 분포로부터 학습하여 더 높은 품질의 샘플을 생성하도록 유도됩니다.
5. **점진적 반복**: 위의 2~4단계를 여러 번 반복하여 합성 데이터셋 $D_{train}$을 점진적으로 확장하고 TAM의 성능을 향상시킵니다.

## 📊 결과

* **성능 우위**: PROGEN은 IMDb, SST-2, Rotten Tomatoes, Elec, Yelp 등 5개의 텍스트 분류 데이터셋에서 ZEROGEN, PROMPTING, PROMPTING$^{*}$를 포함한 다양한 제로샷 학습 베이스라인 대비 일관되게 우수한 평균 정확도와 낮은 성능 분산을 달성했습니다.
* **데이터 효율성**: PROGEN은 베이스라인 방법(ZEROGEN)과 비교하여 단 1%의 합성 데이터셋 크기(100k vs. 1k)로도 동등하거나 더 나은 성능을 달성하여 뛰어난 데이터 효율성을 보여주었습니다. 이는 PLM 접근이 제한적인 실제 환경에서 특히 유용합니다.
* **노이즈 내성 영향 함수 효과**: Reverse Cross-Entropy (RCE) 손실을 사용한 영향 함수가 일반 Cross-Entropy (CE) 손실을 사용한 경우보다 노이즈가 많은 합성 검증 세트에서 더 정확하게 중요한 예제를 식별했습니다.
* **인컨텍스트 예제의 영향**:
  * 적당한 수의 인컨텍스트 예제(예: 8개 이하)가 성능을 일관되게 향상시켰습니다.
  * 인컨텍스트 예제의 레이블 정보를 마스킹(예: "The movie review is: '\<X\>'")하는 것이 성능을 일관되게 향상시켰습니다.
* **프롬프트 민감도 감소**: PROGEN은 "나쁜 프롬프트"에서도 "좋은 프롬프트"에 필적하는 결과를 달성하여, 프롬프트 선택의 중요도를 낮추는 효과를 보였습니다.
* **데이터셋 품질 분석**: PROGEN은 ZEROGEN보다 낮은 다양성(Self-BLEU 점수 증가)을 보였으나, 텍스트 분포와 레이블 정확도(MAUVE 및 TAM 정확도) 측면에서 지상 진실 분포에 더 가깝게 이동했습니다.

## 🧠 통찰 및 논의

* **피드백 메커니즘의 중요성**: 본 연구는 태스크별 모델로부터의 피드백을 통해 생성 과정을 안내하는 것이 합성 데이터셋의 품질을 크게 향상시킬 수 있음을 보여줍니다. 특히, RCE 기반의 영향 함수가 노이즈가 있는 데이터셋 환경에서 중요한 샘플을 더 정확하게 식별하는 데 효과적임을 입증했습니다.
* **인컨텍스트 학습의 강력한 활용**: PLM의 인컨텍스트 학습 능력을 활용하여 생성 분포를 조절하는 것이 효율적이며, PLM 파라미터 수정 없이 최소한의 방해로 이루어진다는 장점이 있습니다.
* **데이터 효율성**: PROGEN은 훨씬 적은 양의 합성 데이터로도 경쟁력 있는 성능을 달성함으로써, 컴퓨팅 자원이나 PLM 접근이 제한적인 환경에서 실용적인 가치를 제공합니다.
* **제한 사항**:
  * PROGEN은 PLM이 초기 프롬프트만으로도 상대적으로 고품질의 데이터를 생성하고 인컨텍스트 예제로부터 학습할 수 있는 능력에 의존합니다. 만약 초기 데이터 품질이 극도로 낮거나 PLM이 관련 지식이 부족하면 프레임워크가 실패할 수 있습니다.
  * 노이즈가 많은 검증 데이터는 TAM이 잘못 레이블링된 예제를 신뢰하게 하여 생성 품질을 저하시킬 수 있습니다.
  * 영향 함수 계산은 여전히 계산 비용이 많이 들며, 전체 데이터셋 대신 샘플링된 부분집합을 사용하는 것은 최적의 품질 추정이 아닐 수 있습니다.

## 📌 요약 (TL;DR)

PROGEN은 제로샷 데이터셋 생성 시 발생하는 낮은 품질 문제를 해결하기 위한 점진적 프레임워크입니다. 이 방법은 태스크별 모델의 피드백을 활용하여, 노이즈에 강한 영향 함수로 가치 있는 합성 데이터를 식별하고 이를 PLM의 인컨텍스트 예제로 사용하여 고품질 데이터를 생성합니다. 결과적으로 PROGEN은 기존 방법 대비 적은 양의 합성 데이터로도 더 높은 정확도를 달성하며, 프롬프트 선택에 대한 민감도를 줄입니다.
