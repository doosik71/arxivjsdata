# A Unified approach for Conventional Zero-shot, Generalized Zero-shot and Few-shot Learning

Shafin Rahman, Salman H. Khan and Fatih Porikli

## 🧩 Problem to Solve

이 논문은 레이블링된 훈련 데이터가 부족하거나 존재하지 않는 클래스 시나리오에서 기존 시각 객체 분류 방법의 여러 한계를 해결하고자 한다. 주요 문제점은 다음과 같다:

- **레이블 데이터 의존성:** 전통적인 지도 학습은 대규모의 주석(annotation)된 데이터셋에 크게 의존한다. 새로운, 특이하거나 복합적인 클래스의 경우, 충분한 레이블을 얻는 것은 비실용적이거나 전문가의 지식을 필요로 한다.
- **새로운 클래스 출현:** 기존 방법들은 초기 학습 단계 이후에 대표 이미지가 없는 새로운 클래스가 계속 추가되는 상황에 잘 대처하지 못한다.
- **일반화 능력 부족 (직관 부족):** 지도 학습은 종종 사람이 설명만으로 새로운 객체를 식별하고, 이전에 학습된 개념과의 유사성을 활용하는 능력을 간과한다.
- **기존 ZSL의 일반화 한계:** 대부분의 Zero-Shot Learning (ZSL) 기술은 특정 문제에 특화되어 있으며, Generalized Zero-Shot Learning (GZSL) (테스트 시 알려진 클래스와 보지 못한 클래스가 모두 나타남) 또는 Few-Shot Learning (FSL) (보지 못한 클래스에 대해 소수의 레이블링된 예제가 제공됨)과 같은 보다 현실적인 시나리오에 잘 일반화되지 않는다. 기존 ZSL 방법은 GZSL에서 보지 못한 클래스에 대한 강한 편향을 보이며 FSL 설정에 효과적으로 확장되지 못한다.

## ✨ Key Contributions

본 논문의 주요 기여는 다음과 같다:

- 클래스 적응형 주성분 방향(Class Adapting Principal Directions, CAPD) 개념을 도입하여 효율적이고 판별적인 미관측 클래스 이미지의 임베딩을 시맨틱 공간에서 가능하게 함으로써 ZSL, GZSL 및 F/OSL 문제에 대한 **통합적인 해결책**을 제시한다.
- 학습된 거리 측정(distance measure)에 기반하여 관측 클래스(seen classes)와 미관측 클래스(unseen classes) 간의 임베딩을 연결하는 **시맨틱 변환(semantic transformation)**을 제안한다.
- 각 미관측 클래스를 설명하는 데 가장 관련성이 높은 관측 클래스의 수를 **자동으로 선택**하여 성능 향상을 가져오는 방법을 제공한다.
- 관측 CAPD를 일반화하여 관측-미관측 다양성(seen-unseen diversity)에 맞춰 자동으로 조정함으로써 **일반화된 Zero-Shot Learning(GZSL) 설정에 적응**할 수 있다.
- 새롭게 사용 가능한 데이터를 통해 미관측 CAPD를 업데이트함으로써 **Few/One-Shot Learning(F/OSL) 설정으로 쉽게 확장**할 수 있다.

## 📎 Related Works

본 논문은 Zero-Shot Learning(ZSL) 분야의 여러 연구 흐름과 관련이 있으며, 특히 다음 주요 분야의 선행 연구들을 참조한다:

- **클래스 레이블 설명:**
  - 수동으로 생성된 속성(attributes) 기반의 지도 학습([11], [21], [31], [42])은 노동 집약적이다.
  - Word2vec([27], [26])이나 GloVe([32])와 같은 대규모 텍스트 코퍼스에서 파생된 비지도 단어 임베딩([50], [44])은 확장성과 유연성을 제공한다.
  - 본 논문은 두 가지 유형의 특징을 모두 사용하여 접근 방식의 강점을 보여준다.
- **임베딩 공간:**
  - **속성/단어 벡터 예측:** 이미지에서 레이블 임베딩을 근사화하고 유사성 기반으로 분류하는 방법([30], [43], [22], [49], [25]). 노이즈나 편향된 속성 주석에 취약하다.
  - **호환성 함수 학습:** 이미지와 레이블 임베딩 간의 호환성 점수를 반환하는 함수를 학습하는 방법([2], [35], [33], [44]). 본 논문의 방법도 CAPD와 내적(inner product) 기반의 호환성 함수를 사용한다.
- **유사성 매칭:** 각 관측 클래스에 대한 분류기를 구축하고, 클래스별 유사성 측정치를 기반으로 미관측 클래스와 관련시키는 방법([7], [10], [15], [25], [34]). 본 논문의 방법은 분류기 대신 CAPD를 학습된 시맨틱 임베딩 공간의 거리 측정에 기반하여 관련시킨다.
- **Few/One-shot Learning (FSL/OSL):** 훈련 중에 미관측 클래스의 소수(하나 또는 몇 개) 인스턴스를 레이블링된 데이터로 사용하는 시나리오([36], [12]). 기존 ZSL 방법은 FSL 설정에서 잘 평가되지 않았다.
- **Generalized Zero-shot Learning (GZSL):** 테스트 단계에서 관측 클래스와 미관측 클래스가 모두 나타나는 보다 현실적인 설정([45], [9], [8]). 대부분의 ZSL 방법은 관측 클래스에 대한 강한 편향 때문에 GZSL에서 성능이 저하된다.

## 🛠️ Methodology

본 논문은 클래스 적응형 주성분 방향(Class Adapting Principal Direction, CAPD) 개념을 중심으로 ZSL, GZSL, FSL에 대한 통합적인 접근 방식을 제시한다.

**문제 공식화:**

- 모든 클래스 레이블 집합은 관측(seen) 클래스 `$y_S$`와 미관측(unseen) 클래스 `$y_U$`로 구성된 `$y = y_S \cup y_U$`이다.
- 각 클래스에는 시맨틱 클래스 임베딩 `$e_s \in R^d$`와 `$e_u \in R^d$`가 할당된다.
- 관측 클래스 `$s$`의 이미지 특징은 `$X_s = [x_1^s, ..., x_{n_s}^s]$`로 표현된다.

### A. 클래스 적응형 주성분 방향(CAPD)

1. **관측 클래스 CAPD 학습($p_s$)**:

   - 주어진 이미지 특징 `$x_s$`에 대해, CAPD `$p_s$`는 선형 매핑 `$p_s = W_s^T x_s$`로 정의되며, `$W_s$`는 클래스별 가중치 행렬이다.
   - `$W_s$`는 다음 목적 함수를 최소화하여 학습된다 (Eq. 2):
     $$ \min*{W_s} \frac{1}{\kappa} \sum*{c=1}^{S} \sum\_{m=1}^{n_c} \log \left( 1 + \exp \left\{ L(x_m^c;W_s) \right\} \right) + \frac{\lambda_s}{2} \|W_s\|\_2^2 $$
        여기서 `$L$`은 비용 함수로, 올바른 시맨틱 임베딩 `$e_s$`에 대한 `$p_s$`의 투영(`$\langle p_s, e_s \rangle$`)을 최대화하고, 잘못된 임베딩에 대한 투영을 최소화하도록 설계되었다.
   - SGD를 사용하여 최적화되며, 각 관측 클래스에 대한 `$W_s$` 학습은 병렬로 독립적으로 수행될 수 있다.

2. **미관측 클래스 CAPD 학습($p_u$)**:
   - 미관측 클래스는 훈련 시 이미지가 관측되지 않으므로, `$p_u$`는 관측 클래스 CAPD의 선형 조합으로 근사된다:
     `$p_u = \sum_{s=1}^S \theta_{s,u} p_s = P_S \theta_u$` (Eq. 3).
   - **CAPD에 대한 거리 학습**: 시맨틱 임베딩 공간에서 마할라노비스(Mahalanobis) 거리 측정 `$M$`을 학습하여 유사한 CAPD는 가깝게, dissimilar CAPD는 멀리 떨어뜨린다 (Eq. 4).
     $$ \max*M \min*{(i,j) \in \bar{A}} d*M^2(p_i, p_j) \quad \text{s.t.} \sum*{(i,j) \in A} d_M^2(p_i, p_j) \leq 1 $$
   - 미관측 시맨틱 임베딩 `$e_u$`는 관측 시맨틱 임베딩 `$e_s$`의 선형 조합으로 근사화된다:
     `$\hat{e}_u = \sum_{s=1}^S \alpha_{s,u} e_s = E_S \alpha_u$` (Eq. 5).
   - `$M$`을 활용하여 `$(\hat{e}_u - e_u)^T M (\hat{e}_u - e_u) + \frac{\lambda_u}{2} \|\alpha_u\|_2^2$`를 최소화하여 `$\alpha_u$`를 찾는다 (Eq. 6).
   - `$\theta_u \approx \alpha_u$` 가정을 통해 `$p_u \approx P_S \alpha_u$`로 미관측 CAPD를 계산한다 (Eq. 7).
   - **ZSL 예측**: 주어진 이미지 특징 `$x$`에 대해 `$p_u$`와 `$e_u$`의 내적(`$\langle p_u, e_u \rangle$`)이 최대인 클래스로 할당한다: `$\hat{y} = \arg \max_u \langle p_u, e_u \rangle$` (Eq. 8).

### B. 미관측 클래스의 축소된 설명 집합

- 모든 관측 클래스를 사용하는 대신, 마할라노비스 거리를 사용하여 `$N < S$`개의 가장 가까운 관측 클래스만으로 `$\hat{e}_u$`를 재구성한다: `$\hat{e}_u = \sum_{i=1}^N \beta_{i,u} e_i$` (Eq. 9).
- **자동 `$N$` 선택**: 각 미관측 클래스에 대해 가장 유용한 관측 클래스의 수를 자동으로 선택하기 위해 커널 밀도 추정(kernel density estimation)을 사용하여 정규화된 마할라노비스 거리 분포에서 최고 확률 점수를 가진 클래스 수를 `$N$`으로 할당한다.

### C. 일반화된 Zero-shot Learning (GZSL)

- 문제: 기존 ZSL 방법은 훈련 시 관측 클래스에만 의존하므로 GZSL 테스트 시 관측 클래스에 편향되는 경향이 있다.
- **관측 클래스를 위한 일반화된 CAPD($p_g_s$)**: 각 관측 클래스 `$s$`에 대해 `$p_g_s = P_S \gamma_s$`와 같이 일반화된 CAPD를 개발한다 (Eq. 10).
- 목적 함수(Eq. 11)는 평균 일반화된 관측 손실(mean generalized seen loss)과 평균 미관측 재구성 손실(mean unseen reconstruction loss) 간의 제곱 차이를 최소화한다. 이는 시맨틱 레이블 임베딩 영역에서만 `$\gamma_s$`를 계산하여 관측-미관측 다양성을 균형 있게 조정한다.
  $$ \min*\gamma \left\| \frac{1}{S} \sum*{s=1}^S (E*S \gamma_s - e_s)^2 - \frac{1}{U} \sum*{u=1}^U (E*S \alpha_u - e_u)^2 \right\|\_2^2 + \frac{\lambda*\gamma}{2} \sum\_{s=1}^S \|\gamma_s\|\_2^2 $$
- **GZSL 예측**: 관측 클래스의 일반화된 CAPD `$p_g_s$`와 미관측 클래스의 CAPD `$p_u$`를 모두 사용하여 예측한다: `$\hat{y} = \arg \max_{l \in y} \langle p_l, v_l \rangle$`, 여기서 `$p_l \in p_u \cup p_g_s$`이고 `$v_l \in e_S \cup e_U$`.

### D. Few-shot Learning (FSL)

- 훈련 시 미관측 클래스의 소수 레이블링된 인스턴스가 사용 가능한 시나리오.
- **미관측 클래스를 위한 업데이트된 CAPD($p_f_u$)**:
  - 미관측 클래스에 대해 새로운 분류기 `$W_u$`를 학습하고 `$p'_u = W_u^T x$`를 계산한다.
  - ZSL에서 파생된 `$p_u$`와 FSL에서 파생된 `$p'_u$`를 융합하여 업데이트된 CAPD를 생성한다:
    `$p_f_u = \delta_u p_u + \delta'_u p'_u$`, 단, `$\delta_u + \delta'_u = 1$` (Eq. 12).
  - 가중치 `$\delta_u$`와 `$\delta'_u$`는 훈련 이미지에 대한 CAPD와 해당 시맨틱 벡터 간의 최대 투영 반응의 합을 정규화하여 계산되며, 이는 각 CAPD의 신뢰도를 반영한다.

## 📊 Results

본 논문은 aPY, AwA, SUN, CUB의 4가지 표준 데이터셋을 사용하여 광범위한 실험을 수행했다. 이미지 특징으로는 GoogLeNet, VGG-verydeep-19, ResNet을 사용했으며, 시맨틱 임베딩으로는 지도 학습된 속성(attributes)과 비지도 학습된 word2vec(w2v) 및 GloVe(glo) 단어 벡터를 활용했다. 평가 지표로는 Top-1 정확도, 평균 평균 정밀도(mAP)를 사용했으며, GZSL의 경우 관측(seen) 클래스와 미관측(unseen) 클래스 정확도(`$acc_s$`, `$acc_u$`)의 조화 평균(Harmonic Mean, HM)을 사용했다.

- **축소된 설명 집합 효과**:
  - 가장 가까운(nearest) 관측 클래스(마할라노비스 거리 기반)를 사용하여 미관측 클래스를 설명하는 것이 가장 좋은 성능을 보였다 (그림 3).
  - 각 미관측 클래스에 대해 자동화된 `$N$` 선택 방식은 일반적으로 전체 관측 클래스의 약 50% 정도만을 활용하며, 이는 성능 유지 및 복잡성 감소에 기여한다 (표 II).
- **ZSL (지도 속성 사용)**:
  - 제안된 방법(특히 `[reduced-auto]` 버전)은 대부분의 설정에서 최신 ZSL 접근 방식들보다 Top-1 정확도(표 III, IV)와 mAP(표 V)에서 우수한 성능을 일관되게 달성했다.
  - 혼동 행렬(confusion matrix) 비교에서도 기존 방법보다 더 나은 전체 및 클래스별 성능을 보였다 (그림 5).
- **ZSL (비지도 시맨틱스 사용)**:
  - word2vec 및 GloVe와 같은 비지도 시맨틱 임베딩을 사용하는 경우에도 제안된 방법은 AwA 및 CUB 데이터셋에서 일관되게 뛰어난 Top-1 정확도를 기록하며 다른 최신 방법들을 능가했다 (표 VI).
  - 평균 정밀도-재현율(Precision-Recall) 곡선에서도 기존 방법들보다 현저히 우수했다 (그림 6).
- **GZSL**:
  - Xian et al. [45]의 설정(ResNet 특징, 속성 시맨틱스)에서 제안된 GZSL 방법은 HM에서 다른 방법들을 큰 폭으로 능가하며, 관측/미관측 클래스 다양성의 균형을 효과적으로 맞추고 최고의 미관측 클래스 정확도(`$acc_u$`)를 달성했다 (표 VII).
  - Chao et al. [9]의 설정(GoogLeNet 특징, 속성 시맨틱스)에서도 경쟁 방법보다 HM에서 우수한 성능을 보였다 (표 VIII).
  - DMaP [23]와 비교했을 때도 Mean Top1 정확도에서 우수한 결과를 보였다 (표 IX).
- **FSL (Few/One-Shot Learning)**:
  - 미관측 클래스당 3개의 인스턴스를 사용하는 FSL 설정에서 제안된 방법은 AwA 및 CUB 데이터셋에서 DeViSE [13] 및 CMT [38]를 대부분 능가하는 Top-1 정확도 및 mAP를 달성했다 (표 X).
  - FSL에서는 지도 속성과 비지도 시맨틱스(word2vec, GloVe) 간의 성능 격차가 ZSL에 비해 크게 줄어들었는데, 이는 소수의 레이블링된 예제가 비지도 시맨틱스의 내재된 노이즈를 보완하는 데 도움이 됨을 시사한다.
  - 업데이트된 미관측 CAPD 구성에서 Few-Shot 분류기의 기여(`$\delta'_u$`)가 Zero-Shot 기여(`$\delta_u$`)보다 일반적으로 더 높았으며, FSL에서 OSL보다 더 큰 기여를 했다 (그림 7). 지도 속성은 w2v/GloVe보다 `$\delta_u$`에서 더 높은 기여도를 보였다.
- **모든 결과 요약**: OSL, FSL, ZSL, GZSL에 대한 종합적인 결과(표 XI, XII, XIII, XIV)는 FSL이 OSL보다 성능이 좋고, OSL/FSL에서 비지도 시맨틱스의 성능이 ZSL에 비해 크게 향상됨을 보여준다.

## 🧠 Insights & Discussion

본 논문의 실험 및 분석을 통해 다음과 같은 주요 통찰과 논의점을 도출할 수 있다:

- **CAPD의 이점**: CAPD는 판별적인 임베딩을 제공하며, 각 클래스에 특화된 적응을 가능하게 하여 미묘한 클래스 간 차이를 효과적으로 포착한다. 이는 하나의 전역 주성분 방향을 사용하는 기존 방법들과 차별화된다.
- **가장 가까운 관측 클래스의 이점**: 새로운 객체를 설명할 때 유사한 알려진 객체를 예로 드는 인간의 직관과 마찬가지로, 가장 가까운 관측 클래스(유사한 CAPD)를 사용하여 미관측 CAPD를 재구성하는 것이 예측 성능을 향상시킨다.
- **자동 `$N$` 선택**: 각 미관측 클래스에 대해 유용한 관측 클래스의 수를 적응적으로 선택하는 제안된 자동화 솔루션은 간단하면서도 효과적이며, 성능 향상에 기여한다.
- **GZSL 확장**: 제안된 GZSL 방법은 기존 ZSL 방법의 고유한 문제였던 관측 클래스 편향을 효과적으로 해결한다. 이미지 데이터에 대한 추가적인 지도 없이, 오직 시맨틱 정보만을 사용하여 알고리즘 수준에서 관측-미관측 클래스 다양성을 조정함으로써, 관측/미관측 클래스 성능의 균형을 맞추고 전반적인 인식률을 향상시킨다. 이는 후처리 방식과는 대조적이다.
- **FSL 확장**: CAPD 기반 ZSL 접근 방식은 FSL 설정에 쉽게 적용될 수 있다. 이 방법은 Zero-Shot 설정에서 파생된 CAPD와 Few-Shot 설정에서 새롭게 학습된 CAPD를 결합하며, 예측 반응 품질에 기반한 자동 가중치 부여 체계를 사용한다. 이를 통해 미관측 CAPD를 미세 조정하고 분류 성능을 향상시킨다.
- **전반적인 일관성**: 제안된 통합 접근 방식은 ZSL, GZSL, F/OSL 설정 전반에 걸쳐 일관되게 우수한 성능을 보이며, 특히 비지도 ZSL에서 탁월한 성과를 달성한다. 이는 시맨틱 공간에서의 신뢰할 수 있는 일반화 및 노이즈 억제와 같은 여러 이점을 제공한다.
- **제한 및 향후 연구**: 현재 접근 방식은 귀납적(inductive) 설정에 초점을 맞추고 있으며, 향후 연구에서는 전도 학습(transductive learning) 및 도메인 적응(domain adaptation) 설정으로 확장할 계획이다.

## 📌 TL;DR

기존 Zero-Shot Learning(ZSL) 방법은 Generalized Zero-Shot Learning(GZSL) 및 Few-Shot Learning(FSL) 시나리오에 잘 일반화되지 않고, 관측 클래스(seen classes)에 대한 편향 및 통합된 해결책의 부재 문제를 겪는다. 본 논문은 **클래스 적응형 주성분 방향(CAPD)**이라는 새로운 개념을 도입하여 ZSL, GZSL, FSL 문제에 대한 **통합적인 접근 방식**을 제시한다.

CAPD는 이미지 특징을 시맨틱 공간으로 매핑하는 클래스별 주성분 방향을 학습한다. 미관측 클래스(unseen classes)의 CAPD는 학습된 거리 측정과 시맨틱 관계를 통해 관측 클래스의 CAPD를 조합하여 근사화된다. GZSL의 경우, 시맨틱 정보만을 사용하여 관측 CAPD를 일반화하여 관측-미관측 클래스 다양성의 균형을 맞추고 관측 클래스에 대한 편향을 해소한다. FSL에서는 소수의 레이블링된 미관측 예제를 활용하여 Zero-Shot 설정에서 파생된 CAPD와 Few-Shot 설정에서 새롭게 학습된 CAPD를 적응형 가중치로 융합하여 미관측 CAPD를 업데이트한다. 또한, 각 미관측 클래스를 설명하는 데 가장 유용한 관측 클래스 집합을 자동으로 선택하는 기능도 포함한다.

실험 결과, 제안된 CAPD 기반 접근 방식은 지도 및 비지도 시맨틱스를 사용하는 ZSL, 관측/미관측 정확도의 균형을 크게 향상시키는 GZSL, 그리고 F/OSL을 포함한 모든 설정에서 여러 벤치마크 데이터셋에 걸쳐 일관되게 **우수한 성능**을 달성하며, 이 세 가지 주요 학습 문제에 대한 강력하고 통합된 해결책을 제공한다.
