# Generative Multi-Label Zero-Shot Learning
Akshita Gupta, Sanath Narayan, Salman Khan, Fahad Shahbaz Khan, Ling Shao, Joost van de Weijer

## 🧩 Problem to Solve
기존의 다중 레이블 분류 접근 방식은 훈련 중에 시각적 예시가 주어지지 않은 "미확인(unseen)" 클래스를 포함하는 이미지의 다중 레이블을 분류하는 다중 레이블 제로샷 학습(Multi-Label Zero-Shot Learning, MLZSL) 문제를 해결하지 못합니다. 단일 레이블 제로샷 학습(Single-Label Zero-Shot Learning, SLZSL) 분야에서는 생성 모델, 특히 GAN(Generative Adversarial Network)을 사용하여 미확인 클래스의 특징을 합성하는 접근 방식이 우세하지만, 다중 레이블 특징을 합성하는 것은 아직 미개척 분야입니다. 특히, 단일 이미지에 여러 객체가 동시에 나타날 때, 여러 클래스 정보를 효과적으로 융합하는 방법이 중요한 과제로 남아 있습니다.

## ✨ Key Contributions
*   (일반화된) 제로샷 설정에서 다중 레이블 특징 합성 문제를 다룬 최초의 연구입니다.
*   다중 레이블 특징 합성을 위한 세 가지 새로운 융합 접근 방식인 **속성 수준 융합(Attribute-Level Fusion, ALF)**, **특징 수준 융합(Feature-Level Fusion, FLF)**, 그리고 **교차 수준 특징 융합(Cross-Level Feature Fusion, CLF)**을 제안합니다.
*   CLF는 ALF의 레이블 의존성 포착 능력과 FLF의 클래스별 식별성 보존 능력의 장점을 효과적으로 결합합니다.
*   제안된 융합 접근 방식을 대표적인 생성 아키텍처인 f-CLSWGAN과 f-VAEGAN에 통합합니다.
*   NUS-WIDE, Open Images, MS COCO 세 가지 제로샷 벤치마크에서 기존 최첨단 방법들을 뛰어넘는 성능을 달성합니다.
*   MS COCO 데이터셋에서 제로샷 객체 탐지(Zero-Shot Object Detection) 작업에서도 제안된 융합 접근 방식의 일반화 가능성을 입증하여 기존 방법들보다 우수한 성능을 보입니다.

## 📎 Related Works
*   **기존 다중 레이블 분류:** 어텐션 메커니즘, 순환 신경망(RNN), 그래프 CNN, 레이블 상관관계를 활용하지만, 제로샷 설정을 다루지 않습니다.
*   **기존 다중 레이블 (G)ZSL:** 전역 이미지 표현, 구조화된 지식 그래프, 어텐션 기반 메커니즘을 사용합니다.
*   **기존 단일 레이블 (G)ZSL:** GAN [32] 및 VAE [33]와 같은 생성 모델을 활용하여 미확인 클래스 특징을 합성하는 생성적 접근 방식이 주를 이룹니다 (예: f-CLSWGAN [25], f-VAEGAN [26]). 이러한 방법들은 단일 레이블 특징만 합성합니다.
*   **제로샷 객체 탐지 (ZSD):** SUZOD [41]와 같은 연구는 클래스 임베딩에 기반한 특징 합성을 Faster R-CNN [54] 프레임워크에 통합하여 단일 레이블 RoI(Region of Interest) 특징을 생성합니다.

## 🛠️ Methodology
본 논문은 다중 레이블 특징 합성을 위한 세 가지 융합 접근 방식을 제안하고, 이를 f-CLSWGAN 및 f-VAEGAN과 같은 생성 아키텍처에 통합합니다.

1.  **속성 수준 융합 (Attribute-Level Fusion, ALF):**
    *   이미지 내의 여러 레이블에 해당하는 클래스별 임베딩 벡터 ($e(y_j)$) 세트로부터 전역 이미지 수준 임베딩 ($e_{\mu}$)을 얻습니다.
    *   $e_{\mu} = \frac{1}{n} \sum_{j:y[j]=1} e(y_j)$
    *   이 $e_{\mu}$를 노이즈 $z$와 함께 생성자 $G_a$에 입력하여 다중 레이블 특징 $\tilde{x}_a$를 합성합니다: $\tilde{x}_a = G_a(z, e_{\mu})$.
    *   **장점:** 이미지 내 레이블 간의 상관관계(의존성)를 잘 포착합니다.
    *   **단점:** 전역 임베딩으로부터의 생성으로 인해 클래스별 식별성이 낮습니다.

2.  **특징 수준 융합 (Feature-Level Fusion, FLF):**
    *   각 클래스별 임베딩 ($e(y_j)$)으로부터 개별적으로 특징을 합성합니다.
    *   생성자 $G_f$는 각 $e(y_j)$로부터 클래스별 잠재 특징 $\tilde{x}_j$를 생성합니다: $\tilde{x}_j = G_f(z, e(y_j))$.
    *   이 개별 특징들을 평균화하여 최종 합성 특징 $\tilde{x}_f$를 얻습니다: $\tilde{x}_f = \frac{1}{n} \sum_{j:y[j]=1} \tilde{x}_j$.
    *   **장점:** 합성된 특징에서 클래스별 식별 정보를 더 잘 보존합니다.
    *   **단점:** 개별적으로 특징을 합성하므로 이미지 내 레이블 의존성을 명시적으로 인코딩하지 못합니다.

3.  **교차 수준 특징 융합 (Cross-Level Feature Fusion, CLF):**
    *   ALF의 레이블 의존성 장점과 FLF의 클래스별 식별성 장점을 결합하는 것을 목표로 합니다.
    *   ALF에서 생성된 $\tilde{x}_a$와 FLF에서 생성된 $\tilde{x}_f$를 특징 융합 블록에 전달합니다.
    *   이 융합 블록은 multi-headed self-attention [39]에서 영감을 받아 각 특징을 다른 브랜치의 안내를 받아 풍부하게 만듭니다.
    *   $\tilde{x}_f$와 $\tilde{x}_a$를 스태킹하여 행렬 $\tilde{x} \in \mathbb{R}^{2 \times d}$를 생성합니다.
    *   이 특징들을 $H$개의 프로젝션 헤드를 사용하여 쿼리-키-값 ($q_h, k_h, v_h$) 삼중항으로 저차원 공간으로 선형 투영합니다.
    *   각 쿼리 벡터는 두 특징에서 파생된 '키'와 상관관계를 찾아 정규화된 관계 점수 $r_h = \sigma(\frac{q_h k_h^\top}{\sqrt{d'}})$를 생성합니다.
    *   이 점수를 해당 값 벡터에 재가중하여 어텐션 특징 $\alpha_h$를 얻습니다: $\alpha_h = r_h v_h$.
    *   모든 헤드의 저차원 어텐션 특징을 연결하고 출력 레이어 $W_O$를 통해 원래 $d$차원 출력 $o = [\alpha_1; ...; \alpha_H] W_O$를 생성합니다.
    *   잔차 분기 (residual branch)와 소형 잔차 하위 네트워크 $f(\cdot)$를 추가하여 지역적 정보를 먼저 고려하고 점진적으로 다른 수준 특징에 주의를 기울이도록 합니다: $\tilde{o} = f(\tilde{x}+o) + (\tilde{x}+o)$.
    *   마지막으로, 행 차원을 따라 $\tilde{o}$를 평균 풀링하여 단일 교차 수준 융합 특징 $\tilde{x}_c \in \mathbb{R}^d$를 얻습니다: $\tilde{x}_c = \frac{1}{2} \sum_{j \in \{1,2\}} \tilde{o}_{j,k}$.
    *   **결과:** 이미지 내 레이블 간의 상관관계와 클래스별 식별 정보를 모두 명시적으로 인코딩하는 특징을 생성합니다.

4.  **다중 레이블 제로샷 분류 통합:**
    *   CLF를 f-CLSWGAN [25] 및 f-VAEGAN [26]에 통합합니다.
    *   f-CLSWGAN의 표준 생성자를 다중 레이블 특징 생성기 (CLF)로 대체하여 다중 레이블 특징 $\tilde{x}_c$를 합성합니다. WGAN 손실과 BGE 손실(이진 교차 엔트로피 손실)을 최적화합니다.
    *   f-VAEGAN은 조건부 VAE와 조건부 WGAN을 공유 생성기로 결합한 모델이며, 여기서도 단일 레이블 공유 생성자를 CLF로 대체합니다.
    *   학습된 생성기로 미확인 클래스에 대한 다중 레이블 특징을 합성하고, 이 합성 특징과 실제 확인 클래스 특징을 사용하여 최종 분류기를 훈련합니다.

## 📊 Results
*   **ABLATION 연구 (NUS-WIDE):** CLF는 ALF 및 FLF에 비해 ZSL 및 GZSL 작업 모두에서 F1 점수와 mAP 측면에서 일관된 성능 향상을 보였습니다. 특히, CLF를 f-VAEGAN에 통합했을 때 가장 좋은 결과가 나왔습니다.
*   **다중 레이블 조합 변화:** 무작위 다중 레이블 조합을 사용하는 것보다, 훈련 세트에서 가장 가까운 미확인 클래스로 대체하여 얻은 다중 레이블 조합이 ZSL 및 GZSL 성능을 크게 향상시켰습니다.
*   **융합 방식 변화:** CLF는 ALF와 FLF의 평균(AVG) 또는 연결(CONCAT)보다 ZSL 및 GZSL 작업 모두에서 F1 및 mAP에서 상당한 이득을 달성했습니다.
*   **백본 변화:** DINO ResNet-50 [45]과 같은 더 강력한 백본을 사용하면 ZSL 및 GZSL 성능이 향상되었습니다. (예: mAP 1.4% 및 1.5% 향상).
*   **최첨단 비교:**
    *   **NUS-WIDE:** CLF는 ZSL mAP에서 LESA [16] 대비 6.3%, GZSL mAP에서 3.3%의 절대 이득을 보이며 새로운 최첨단 성능을 달성했습니다.
    *   **Open Images:** CLF는 대규모 Open Images 데이터셋에서 ZSL F1 (K=10)에서 2.5%, GZSL F1 (K=10)에서 33.6%의 높은 F1 점수를 기록하며 LESA 대비 크게 향상되었습니다.
    *   **MS COCO:** CLF는 Fast0Tag [14] 대비 ZSL mAP에서 8.9%, GZSL mAP에서 5.3%의 상당한 이득을 보이며 기존 방법들보다 우수했습니다.
*   **판별적 접근 방식과의 결합 효과:** LESA [16] 및 BiAM [50]과 같은 판별적 ZSL 접근 방식 위에 CLF를 적용했을 때 ZSL 및 GZSL 분류 성능이 향상되었으며, t-SNE 플롯을 통해 미확인 클래스 특징의 식별성 향상을 시각적으로 확인했습니다.
*   **제안된 분할에 대한 최첨단 비교:** ImageNet과의 클래스 중복을 제거한 새로운 NUS-WIDE 및 Open Images 분할에서도 CLF는 기존 방법들보다 지속적으로 우수한 성능을 보였습니다.
*   **표준 다중 레이블 분류:** NUS-WIDE 및 Open Images 데이터셋에서 표준 다중 레이블 분류 작업에서도 CLF는 기존 최첨단 방법들을 크게 능가하는 mAP 및 F1 점수를 달성했습니다.
*   **제로샷 객체 탐지 (ZSD) 확장:** MS COCO 데이터셋에서 ZSD 및 GZSD 작업에서 SUZOD [41] 대비 mAP에서 1.3%, recall에서 3.7%의 이득을 보이며 우수한 성능을 입증했습니다.

## 🧠 Insights & Discussion
본 연구는 생성 모델 기반의 다중 레이블 제로샷 학습에 대한 첫 탐색이며, 특히 복잡한 다중 레이블 시나리오에서 특징 합성이 중요하다는 것을 보여줍니다. 제안된 CLF(Cross-Level Feature Fusion)는 전역적인 레이블 의존성(ALF의 장점)과 개별적인 클래스 식별성(FLF의 장점)을 동시에 포착함으로써 강력한 합성 특징을 생성하는 핵심적인 통찰력을 제공합니다.

CLF의 성능 우위는 단순히 새로운 아키텍처를 제시하는 것을 넘어, 다중 레이블 특징 합성에 있어 각 레이블의 개별적 특징과 전체 이미지 맥락 간의 상호 작용을 모델링하는 것이 중요함을 시사합니다. 이러한 접근 방식은 (일반화된) 제로샷 분류뿐만 아니라 제로샷 객체 탐지 및 표준 다중 레이블 분류와 같은 다양한 작업에서 효과적임을 보여, 방법론의 높은 일반화 가능성과 효용성을 입증했습니다.

제안된 방법은 이미지넷으로 사전 학습된 백본과 미확인 클래스 간의 중복 문제를 해결하기 위한 새로운 데이터 분할을 제안하여, ZSL 패러다임의 엄격한 정의를 준수하려는 노력을 보여줍니다. 이는 향후 연구를 위한 견고한 벤치마크 및 베이스라인을 제공합니다. 다만, 현재는 VGG 백본을 사용하여 기존 연구와의 공정한 비교를 했지만, DINO ResNet-50과 같은 더 강력한 백본 사용 시 성능이 추가적으로 향상될 여지가 있음을 언급했습니다.

## 📌 TL;DR
본 논문은 (일반화된) 다중 레이블 제로샷 학습에서 미확인 클래스의 시각적 특징을 합성하는 문제를 해결합니다. 핵심적으로, 레이블 의존성을 포착하는 '속성 수준 융합(ALF)'과 클래스별 식별성을 유지하는 '특징 수준 융합(FLF)'의 장점을 결합한 '교차 수준 특징 융합(CLF)'을 제안합니다. CLF는 f-CLSWGAN 및 f-VAEGAN과 같은 생성 아키텍처에 통합되어 NUS-WIDE, Open Images, MS COCO 벤치마크에서 기존 최첨단 방법들을 뛰어넘는 성능을 달성했습니다. 또한, 제로샷 객체 탐지 및 표준 다중 레이블 분류에서도 우수한 성능을 보이며, 생성적 다중 레이블 제로샷 학습 분야의 견고한 베이스라인을 제시합니다.