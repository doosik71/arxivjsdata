# Zero-Shot Instance Segmentation

Ye Zheng, Jiahong Wu, Yongqiang Qin, Faen Zhang, Li Cui

## 🧩 Problem to Solve

심층 학습 기반의 인스턴스 세그멘테이션은 풍부한 레이블 데이터가 있을 때 높은 정확도를 보이지만, 의료 및 제조와 같이 레이블링된 데이터를 충분히 수집하기 어렵고 전문적인 기술을 요구하는 분야에서는 적용하기 어렵습니다. 특히 훈련 단계에서 보지 못한(unseen) 클래스에 대한 인스턴스를 정확하게 분할하는 것은 큰 과제입니다.

본 논문은 이러한 동기에서 **제로샷 인스턴스 세그멘테이션(Zero-Shot Instance Segmentation, ZSI)**이라는 새로운 태스크를 제안하며, 다음의 두 가지 주요 난제를 해결하고자 합니다:

1. **보지 못한 클래스에 대한 인스턴스 세그멘테이션 방법**: 보지 못한 클래스 데이터 없이 딥러닝 모델이 인스턴스를 분할하도록 하는 방법.
2. **배경과 보지 못한 클래스 간의 혼동 감소**: 훈련 중에 보지 못한 데이터를 관찰하지 못하므로, 모델이 보지 못한 객체를 배경으로 잘못 식별할 가능성을 줄이는 방법. 특히 기존의 고정된 배경 단어 벡터로는 복잡하고 동적으로 변하는 배경을 효과적으로 표현하기 어렵습니다.

## ✨ Key Contributions

* **제로샷 인스턴스 세그멘테이션(ZSI) 문제 정의**: 실세계 설정에서 보지 못한 인스턴스를 픽셀 수준으로 분할하는 새로운 문제를 제시하고 평가 프로토콜과 벤치마크를 제공했습니다.
* **배경 인지(background-aware) 검출-세그멘테이션 방식의 새로운 방법론 제안**: ZSI 문제를 해결하기 위한 종단 간(end-to-end) 신경망 프레임워크를 제안합니다. 주요 구성 요소는 다음과 같습니다:
  * **Zero-shot Detector (제로샷 검출기)**: 시각-의미론적 매핑 관계를 학습하여 보지 못한 객체를 검출합니다.
  * **Semantic Mask Head (의미론적 마스크 헤드)**: 시각-의미론적 매핑을 활용하여 보지 못한 인스턴스의 마스크를 생성합니다.
  * **Background Aware RPN (BA-RPN)**: 이미지로부터 배경 클래스를 위한 보다 합리적인 단어 벡터($v_b$)를 학습합니다.
  * **Synchronized Background Strategy (Sync-bg)**: BA-RPN에서 학습된 동적인 배경 단어 벡터를 Zero-shot Detector 및 Semantic Mask Head에 일관되게 동기화하여 활용합니다.
* **새로운 ZSI 벤치마크 제시**: MS-COCO 데이터셋을 기반으로 ZSI 성능 평가를 위한 새로운 실험 벤치마크(48/17 및 65/15 분할)를 구축했습니다.
* **광범위한 실험 및 Ablation 연구**: 제안된 방법이 최신 제로샷 객체 검출(ZSD) 모델의 성능을 능가하며, ZSI에서 유망한 성능을 달성함을 입증했습니다.

## 📎 Related Works

* **일반 인스턴스 세그멘테이션**: Mask R-CNN [1], FCIS [2] 등과 같은 딥러닝 기반 방법들은 레이블링된 대규모 데이터에 크게 의존하며, 훈련 샘플이 없는 새로운 카테고리로 확장하기 어렵습니다.
* **제로샷 학습 (Zero-shot Learning, ZSL)**: 보지 못한 클래스에 대해 추론하기 위해 보았던(seen) 클래스 데이터를 활용합니다. 대부분의 초기 연구는 제로샷 분류(ZSC)에 초점을 맞추었으나, 이는 입력 이미지 내 단일 도메인 객체 인식에 한정되어 실세계 시나리오에 부적합했습니다.
* **제로샷 객체 검출 (Zero-shot Object Detection, ZSD)** [23, 24]: 보지 못한 객체를 동시에 지역화하고 인식하는 것을 목표로 합니다. 이전 ZSD 연구들은 배경 클래스 표현에 대해 고정된 단어 벡터 [23, 26]를 사용하거나 다단계 훈련 프로세스 [23, 32]를 통해 학습하는 방식의 한계를 보였습니다.
* **제로샷 의미론적 세그멘테이션 (Zero-shot Semantic Segmentation, ZSS)** [25]: 전체 이미지에 대한 의미론적 분할을 수행하며, 개별 인스턴스 분할을 목표로 하는 본 연구와는 다릅니다.
본 연구는 기존 ZSD 방법의 배경 표현 한계를 개선하고, 개별 인스턴스 수준의 미세한 분할 결과를 제공하는 ZSI 문제를 다룹니다.

## 🛠️ Methodology

본 논문은 시각-의미론적 매핑 관계를 활용하여 보지 못한 인스턴스를 검출하고 분할하는 종단 간(end-to-end) 네트워크를 제안합니다. 전체 아키텍처는 Faster R-CNN을 기반으로 하며, Zero-shot Detector, Semantic Mask Head, 그리고 배경 표현을 위한 BA-RPN 및 Synchronized Background Strategy로 구성됩니다.

### 1. 문제 정의 ($3.1$)

주어진 이미지와 단어 벡터는 보았던 클래스 $C_s$와 보지 못한 클래스 $C_u$의 서로 겹치지 않는 두 세트에서 나옵니다.

* **훈련 단계**: $D_{train}$은 $C_s$의 이미지 $x_s$와 단어 벡터 $w_s$로 구성되며, 모델은 $\theta = \arg \max_{\theta} \sum_{D_{train}}^{i=1} \log p(y_{si} \in C_s | x_{si}, w_s, \theta)$를 통해 훈련됩니다.
* **추론 단계**: 목표는 $\arg \max_{\theta} \sum_{D_{test}}^{i=1} \log p(y_{si} \in C_s, y_{ui} \in C_u | x_i, w, \theta)$로, 훈련된 네트워크 $\theta$를 사용하여 $C_s$와 $C_u$ 모두에 대해 정확한 인스턴스 세그멘테이션 결과를 얻는 것입니다.

### 2. Zero-Shot Detector ($3.2.1$)

Faster R-CNN의 분류 브랜치를 새로운 의미론적 분류 브랜치로 대체합니다.

* **구조**: 인코더-디코더 구조로, 인코더 $T_e$는 입력 RoI의 시각적 특징을 의미론적 특징으로 인코딩하고, 디코더 $T_d$는 의미론적 특징을 다시 시각적 특징으로 디코딩합니다.
* **훈련**: 재구성 손실 $L_R$을 사용하여 시각적 특징과 재구성된 시각적 특징 간의 차이를 최소화하여 판별적인 시각-의미론적 정렬을 학습합니다.
* **추론**: $T_d$는 제거되며, 의미론적 특징과 보았던/보지 못한 클래스 단어 벡터($W_s$, $W_u$)의 행렬 곱셈을 통해 점수를 얻습니다.

### 3. Semantic Mask Head (SMH) ($3.2.2$)

보지 못한 인스턴스에 대한 인스턴스 세그멘테이션을 수행하기 위해 시각-의미론적 매핑 관계를 학습하고 이를 보지 못한 클래스에 전이합니다.

* **구조**: 인코더-디코더 구조. 인코더 $E$는 $1 \times 1$ 컨볼루션 레이어로 시각적 특징을 의미론적 공간으로 인코딩합니다 (채널 차원 300). 디코더 $D$는 의미론적 단어 벡터를 다시 시각적 특징으로 디코딩하며, $L_R$을 사용하여 매핑 품질을 개선합니다.
* **마스크 생성**: 300차원 의미론적 특징 텐서에서, 각 요소의 단어 벡터와 모든 보았던/보지 못한 클래스 단어 벡터 간의 유사성을 계산하여 픽셀별 분류 점수를 얻습니다. 이를 위해 $W_s$-Conv 및 $W_u$-Conv라는 고정된 $1 \times 1$ 컨볼루션 레이어를 사용합니다.

### 4. BA-RPN 및 Synchronized Background Strategy (Sync-bg) ($3.2.3$)

배경 클래스에 대한 기존 고정 단어 벡터의 한계를 극복하기 위해 동적으로 적응하는 배경 단어 벡터를 학습하고 활용합니다.

* **BA-RPN**: 시각-의미론적 학습 과정을 RPN에 도입하여 이미지로부터 더 합리적인 배경 클래스 단어 벡터 $v_b$를 학습합니다. FC 레이어 $T$가 시각적 특징을 의미론적 특징으로 변환하고, $W_{bf}$ (300x2 차원)가 전경-배경 이진 분류 점수를 얻습니다. $W_{bf}$의 가중치는 훈련 중 최적화되어 새로운 $v_b$를 학습합니다.
* **Synchronized Background Strategy (Sync-bg)**: 훈련 및 추론 과정에서 BA-RPN으로부터 얻은 $v_b$를 Zero-shot Detector의 $W_s, W_u$와 SMH의 $W_s$-Conv, $W_u$-Conv에 동기화하여 업데이트합니다 (Algorithm 1 참조). 이는 종단 간 공동 훈련을 통해 더 합리적인 $v_b$를 학습하고, 동적으로 적응하는 배경 단어 벡터가 전체 프레임워크에 일관되게 적용되도록 하여 성능을 크게 향상시킵니다.

### 5. 손실 함수 ($4$)

전체 손실 함수 $L_{ZSI}$는 세 가지 구성 요소로 이루어집니다:
$$L_{ZSI} = L_{BA} + L_{ZSD} + L_{SMH}$$

* $L_{BA}$: BA-RPN의 전경-배경 분류를 위한 크로스 엔트로피 손실($CE$)과 회귀를 위한 smooth $L_1$ 손실로 구성됩니다.
    $$L_{BA} = \mathcal{L}_1(r, \hat{r}) + CE(c, \hat{c})$$
* $L_{ZSD}$: Zero-shot Detector의 분류를 위한 크로스 엔트로피 손실($CE$), 회귀를 위한 smooth $L_1$ 손실, 그리고 시각적 특징 재구성 손실($L_R$)로 구성됩니다.
    $$L_{ZSD} = \mathcal{L}_1(r, \hat{r}) + CE(c, \hat{c}) + \lambda_{ZSD}L_R(O,R)$$
* $L_{SMH}$: Semantic Mask Head의 픽셀별 이진 분류를 위한 이진 크로스 엔트로피 손실($BCE$)과 재구성 손실($L_R$)로 구성됩니다.
    $$L_{SMH} = BCE(c, \hat{c}) + \lambda_{SMH}L_R(O,R)$$
    여기서 $L_R$은 원본 시각적 특징 $O$와 재구성된 시각적 특징 $R$ 간의 평균 제곱 오차를 측정합니다 (Eq. 1). $\lambda_{ZSD}$와 $\lambda_{SMH}$는 하이퍼파라미터입니다.

## 📊 Results

* **데이터셋**: MS-COCO 2014 데이터셋을 기반으로 48/17 및 65/15 클래스 분할(seen/unseen)을 사용하여 벤치마크를 구축했습니다. 훈련 세트에는 보지 못한 객체가 포함된 이미지는 제외되었습니다.
* **평가 지표**: Recall@100 (IoU 0.4, 0.5, 0.6) 및 mAP (IoU 0.5)를 사용합니다. ZSI 설정(보지 못한 인스턴스만 예측)과 일반화된 제로샷 인스턴스 세그멘테이션(GZSI) 설정(보았던/보지 못한 인스턴스 모두 예측)에서 평가되었습니다.
* **구성 요소별 분석 (Table 1)**: 각 구성 요소(ZSD, SMH 인코더/디코더, Det Decoder, BA-RPN & Sync-bg)의 추가가 전체 성능을 점진적으로 향상시킴을 보여줍니다. 특히 BA-RPN과 Sync-bg는 ZSI Recall@100에서 48/17 분할에서 6.4%, 65/15 분할에서 7.4%의 상당한 개선을 가져왔습니다.
* **기존 ZSD 방법과의 비교 (Table 2)**: 제안된 방법은 48/17 및 65/15 분할 모두에서 기존 최신 ZSD(Zero-Shot Detection) 방법들(SB, DSES, PL, BLC 등)을 Recall@100 및 mAP 면에서 크게 능가했습니다 (예: 48/17 분할에서 Recall@100 최대 36.99%, mAP 11.08% 개선).
* **일반화된 제로샷 객체 검출(GZSD) 및 인스턴스 세그멘테이션(GZSI) 성능 (Table 3, 4)**: GZSD 및 GZSI 설정에서도 보았던/보지 못한 클래스 모두에서 조화 평균(HM) 성능이 크게 향상되었음을 보였습니다. 특히 GZSI에서 조화 평균 mAP에서 최대 5.61%, Recall@100에서 11.72% 개선을 달성했습니다.
* **BA-RPN 및 Sync-bg의 Ablation 연구 (Table 5)**: BA-RPN 단독으로는 성능이 저하될 수 있지만, Sync-bg 전략을 ZSD 및 SMH 전체 프레임워크에 일관되게 적용했을 때 가장 좋은 성능을 얻었습니다. 이는 배경 단어 벡터의 일관된 동기화가 중요함을 시사합니다.
* **의미론적 정보의 효과 (Table 6)**: Word2vec과 같은 사전 지식을 포함하는 의미론적 단어 벡터가 무작위 또는 원-핫 벡터에 비해 훨씬 우수한 성능을 보이며, 의미론적 정보의 중요성을 강조합니다.
* **정성적 결과 (Figure 6)**: "컵", "소파", "스노보드"와 같이 복잡하고 밀집된 배경에서도 보지 못한 인스턴스를 정확하게 검출하고 분할하는 능력을 시각적으로 보여줍니다.

## 🧠 Insights & Discussion

* **ZSI 태스크의 개척**: 본 연구는 실세계 시나리오에 더욱 적합한 제로샷 인스턴스 세그멘테이션(ZSI)이라는 새로운 태스크를 도입하고 이를 위한 견고한 벤치마크와 평가 프로토콜을 제공함으로써 해당 분야의 미래 연구를 위한 기반을 마련했습니다.
* **동적 배경 표현의 중요성**: 기존 ZSD 방법의 주요 한계점이었던 배경 클래스의 표현 문제를 해결하기 위해 BA-RPN과 Sync-bg 전략을 도입하여, 시각적 정보로부터 동적으로 적응하는 배경 단어 벡터를 학습하고 이를 네트워크 전체에 일관되게 적용하는 것이 성능 향상에 결정적인 역할을 함을 입증했습니다. 이는 특히 배경과 보지 못한 객체 간의 혼동을 줄이는 데 효과적이었습니다.
* **시각-의미론적 매핑의 정교화**: Zero-shot Detector와 Semantic Mask Head에 인코더-디코더 구조와 재구성 손실을 적용하여 시각적 특징과 의미론적 단어 벡터 간의 매핑 관계를 더욱 판별적이고 견고하게 학습할 수 있었습니다.
* **높은 실용성**: 보지 못한 객체에 대한 픽셀 수준의 정확한 분할을 가능하게 함으로써, 의료 영상 분석이나 로봇 공학 등 레이블 데이터가 희소한 분야에서 인스턴스 세그멘테이션의 적용 가능성을 크게 확장했습니다.
* **향후 연구 방향 제시**: 본 연구는 ZSI를 위한 강력한 기준 모델을 제공하며, 이를 바탕으로 더 정교한 시각-의미론적 매핑, 효율적인 배경 학습, 그리고 더 넓은 범위의 제로샷/퓨샷(Few-shot) 세그멘테이션 문제로 연구를 확장할 수 있는 길을 열었습니다.

## 📌 TL;DR

본 논문은 레이블 데이터가 없는 보지 못한 클래스에 대한 인스턴스 분할을 목표로 하는 **제로샷 인스턴스 세그멘테이션(ZSI)**이라는 새로운 컴퓨터 비전 태스크를 제안합니다. 이를 위해 제로샷 검출기, 의미론적 마스크 헤드, 배경 인지 RPN(BA-RPN), 그리고 동기화된 배경 전략(Sync-bg)으로 구성된 종단 간(end-to-end) 프레임워크를 제시합니다. 이 방법론은 시각-의미론적 매핑 관계를 활용하고, 이미지로부터 동적으로 적응하는 배경 단어 벡터를 학습하며 이를 검출 및 분할 모듈에 일관되게 동기화합니다. MS-COCO 기반 벤치마크에서 이 방법은 최신 제로샷 객체 검출(ZSD) 성능을 능가하고, ZSI에서 유망한 결과를 달성하며, 해당 분야의 향후 연구를 위한 견고한 기준선을 제공합니다.
