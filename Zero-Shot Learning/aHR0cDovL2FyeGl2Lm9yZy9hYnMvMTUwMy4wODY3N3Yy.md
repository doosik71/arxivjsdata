# Label-Embedding for Image Classification

Zeynep Akata, Florent Perronnin, Zaid Harchaoui, and Cordelia Schmid

## 🧩 Problem to Solve

본 논문은 이미지 분류, 특히 **레이블된 학습 데이터가 없는 새로운 클래스를 인식해야 하는 제로샷 학습(Zero-Shot Learning, ZSL) 문제**를 다룹니다. 기존의 속성 기반(attribute-based) 접근 방식인 **직접 속성 예측(Direct Attribute Prediction, DAP)** 모델은 다음과 같은 한계점을 가집니다:

- **두 단계 학습**: 속성 분류기와 클래스 예측이 독립적으로 수행되어 최종 목표(클래스 분류)에 최적화되지 않습니다.
- **점진적 학습의 어려움**: 제로샷 학습에서 소량의 레이블이 있는 클래스(few-shot)로 확장하기 어렵습니다.
- **사이드 정보 통합의 한계**: 속성 외에 클래스 계층이나 텍스트 설명 같은 다른 유용한 사이드 정보를 효율적으로 통합하기 어렵습니다.

## ✨ Key Contributions

- **속성 기반 이미지 분류를 레이블 임베딩(Label-Embedding) 문제로 재정의**하여 기존 DAP 모델의 한계를 극복했습니다.
- 이미지 $x$와 레이블 $y$ 간의 호환성($F(x,y;W)$)을 측정하는 함수를 도입하고, 올바른 클래스의 순위가 잘못된 클래스보다 높도록 파라미터를 학습하는 프레임워크를 제안했습니다.
- 제안된 **속성 레이블 임베딩(Attribute Label Embedding, ALE)**이 제로샷 학습 시나리오에서 표준 DAP 기준선보다 우수한 성능을 보임을 입증했습니다.
- ALE 프레임워크는 속성 외에 **클래스 계층(class hierarchies) 또는 텍스트 설명(textual descriptions)과 같은 다양한 사이드 정보**를 유연하게 활용할 수 있음을 보여주었습니다.
- 제로샷 학습부터 다수의 레이블된 예시가 있는 일반 학습까지 **다양한 학습 설정을 아우를 수 있는** 확장성을 갖습니다.
- **연속형 속성 임베딩(continuous attribute embeddings)**이 이진 속성 임베딩보다 우수한 성능을 보임을 실험적으로 확인했습니다.
- 클래스 간 속성 상관관계로 인해 출력 공간 차원을 크게 줄여도 성능 손실이 미미하거나 오히려 향상될 수 있음을 보였습니다.

## 📎 Related Works

- **속성(Attributes)**: 이미지 설명, 캡션 생성, 얼굴 인식, 객체 분류 등 다양한 컴퓨터 비전 작업에 활용됩니다. Lampert et al.의 DAP 모델은 속성 독립성을 가정하며, 이를 개선하기 위한 여러 시도(속성 간/클래스 간 상관관계 고려 등)가 있었으나 고유한 한계가 있었습니다.
- **제로샷 학습(Zero-shot Learning)**: 훈련 데이터가 없는 클래스로 지식을 전달하는 문제입니다. 속성, 의미론적 클래스 분류 체계, 클래스 간 유사도, 텍스트 특징 등 다양한 사전 정보 소스가 사용됩니다. 인식 모델로는 DAP와 더불어 이미지와 클래스 임베딩 간 거리를 측정하는 방식들이 연구되었습니다.
- **레이블 임베딩(Label Embedding)**: 이미지 표현(input embedding)에 비해 덜 연구된 분야로, 클래스 레이블을 유클리드 공간에 임베딩하는 방식입니다.
  - **데이터 독립적 임베딩(Data-Independent Embeddings)**: 커널 의존성 추정, 랜덤 투영(random projections), 오류 수정 출력 코드(Error Correcting Output Codes, ECOC) 등이 있습니다.
  - **데이터 학습 임베딩(Learned Embeddings)**: CCA(Canonical Correlation Analysis), WSABIE(Web-Scale Annotation By Image Embedding)와 같이 입력과 출력을 공동으로 중간 공간에 임베딩하는 방식이 있습니다.
  - **사이드 정보 기반 임베딩(Embeddings Derived From Side Information)**: 속성, 텍스트 설명, 클래스 분류 체계 등을 활용합니다. Frome et al.의 Word2Vec 기반 임베딩(DeViSE)이 본 연구와 유사한 방향입니다.

## 🛠️ Methodology

본 논문은 구조적 예측(structured prediction) 프레임워크에서 영감을 받아, 이미지 임베딩 $\theta(x)$와 레이블 임베딩 $\phi(y)$의 텐서곱으로 구성된 결합 특징 임베딩 $\psi(x,y) = \theta(x) \otimes \phi(y)$에 대해 선형 호환성 함수를 정의합니다.

$$F(x,y;W) = \theta(x)'W\phi(y)$$

여기서 $W$는 학습 가능한 파라미터 행렬입니다.

1. **속성 레이블 임베딩 (Attribute Label Embedding, ALE)**:

   - 각 클래스 $y$는 $E$차원 속성 벡터 공간에 임베딩됩니다: $\phi_A(y) = [\rho_{y,1}, ..., \rho_{y,E}]$. $\rho_{y,i}$는 클래스 $y$와 속성 $a_i$ 간의 이진 또는 연속형 연관성 측정값입니다.
   - **출력 인코딩 및 정규화**:
     - 연속형(continuous), 이진 $\{0,1\}$, 이진 $\{-1,+1\}$ 인코딩을 비교합니다.
     - 평균 중심화(mean-centering) 및 $L_2$-정규화(normalization) 효과를 분석합니다.

2. **학습 알고리즘**:

   - **WSABIE 목표 함수**: 이미지 분류 정확도를 직접 최적화하기 위해 Weston et al.의 WSABIE 알고리즘에서 제안된 랭킹 기반 목적 함수를 사용합니다. 이 함수는 올바른 레이블이 높은 순위를 갖도록 하며, 스토캐스틱 경사 하강법(Stochastic Gradient Descent, SGD)으로 효율적으로 최적화됩니다.
   - **ALE: 제로샷 학습**: 레이블 임베딩 $\Phi$는 속성 정보 $\Phi_A$로 고정하고, $W$만 최적화합니다. 이는 (비정규화된) 구조적 SVM(Structured SVM, SSVM) 목적 함수와 밀접한 관련이 있습니다.
   - **ALE: 퓨샷 학습 (Few-Shots Learning)**: 레이블된 데이터와 사이드 정보가 모두 있는 경우, $\Phi$를 $\Phi_A$에 가깝게 유지하는 정규화 항($\frac{\mu}{2}||\Phi - \Phi_A||^2$)을 추가하여 $W$와 $\Phi$를 공동으로 최적화합니다. (스토캐스틱 교대 최적화 사용).

3. **속성 외 레이블 임베딩**:
   - **계층적 레이블 임베딩 (Hierarchical Label Embedding, HLE)**: WordNet과 같은 클래스 계층 구조를 활용하여 각 클래스의 조상을 나타내는 이진 벡터로 임베딩합니다.
   - **Word2Vec 레이블 임베딩 (Word2Vec Label Embedding, WLE)**: Wikipedia와 같은 텍스트 코퍼스에서 클래스 이름의 Word2Vec 임베딩을 학습하여 클래스 간 관계를 인코딩합니다.

## 📊 Results

- **데이터셋**: Animals With Attributes (AWA), Caltech-UCSD-Birds (CUB).
- **입력 임베딩**: SIFT 및 색상 디스크립터의 Fisher Vector (FV) (4K 또는 64K 차원).

- **출력 인코딩 비교 (ALE)**:

  - **연속형 임베딩**이 이진 임베딩($\{0,1\}$ 또는 $\{-1,+1\}$)보다 일관적으로 높은 정확도를 보였습니다. (예: AWA 64K FV에서 연속형 48.5% vs. $\{-1,+1\}$ 41.8%). 이는 연속형 임베딩이 클래스-속성 연관성의 강도를 더 많이 인코딩하기 때문입니다.
  - **$L_2$-정규화**는 성능을 크게 향상시켰으나, 평균 중심화는 영향이 미미했습니다. 기본적으로 연속형 $L_2$-정규화 임베딩을 사용합니다.

- **학습 알고리즘 비교**:

  - 랭킹 기반 목적 함수(RNK)와 다중 클래스 SSVM(MUL)은 능선 회귀(Ridge Regression, RR)보다 우수한 성능을 보였습니다. 이는 RNK/MUL이 분류 목표에 더 직접적으로 최적화되기 때문입니다.

- **ALE와 DAP 비교 (제로샷 학습)**:

  - **객체 분류 정확도**: ALE는 DAP를 크게 능가했습니다 (AWA: ALE 48.5% vs. DAP 41.0%; CUB: ALE 26.9% vs. DAP 12.3%).
  - **속성 예측 정확도**: DAP가 속성 예측 정확도(AUC)에서는 ALE보다 높거나 유사했지만, ALE의 AUC도 합리적인 수준이었습니다 (AWA: DAP 72.7%, ALE 72.7%; CUB: DAP 64.8%, ALE 59.4%).

- **속성 상관관계**:

  - SVD를 이용한 차원 축소는 속성 간 높은 상관관계를 보여주며, 출력 차원을 크게 줄여도 분류 정확도 손실이 적거나 심지어 향상될 수 있음을 확인했습니다.

- **ALE, HLE, WLE 비교 (제로샷 학습)**:

  - **ALE(속성)**가 가장 좋은 성능을 보였고, 다음으로 **HLE(계층)**, 그리고 **WLE(Word2Vec)** 순이었습니다. (예: AWA: ALE 48.5%, HLE 40.4%, WLE 32.5%). 이는 ALE과 HLE가 전문가의 강한 감독을 받는 반면, WLE는 비감독 방식으로 학습되기 때문으로 분석됩니다.
  - ALE와 HLE의 조합(AHLE late fusion)은 ALE 단독보다 약간의 성능 향상을 가져왔습니다 (AWA: +0.9%, CUB: +0.4%).
  - AWA 데이터셋에서 AHLE(49.4%)는 기존 제로샷 최고 성능(48.3%)을 뛰어넘었습니다.

- **퓨샷 학습 (Few-Shots Learning)**:

  - 매우 적은 수의 훈련 샘플(2-5개/클래스)에서는 사전 정보를 활용하는 **ALE 변형들(ALE(W), ALE($\Phi$), ALE(W$\Phi$))**이 WSABIE, OVR, GLE와 같은 다른 방법들보다 우수한 성능을 보였습니다. 이는 데이터가 부족할 때 사전 정보의 중요성을 시사합니다.
  - 훈련 샘플 수가 증가함에 따라 모든 알고리즘의 정확도가 유사하게 수렴했습니다.

- **전체 데이터셋 학습 (Full Dataset Learning)**:
  - 훈련 데이터가 풍부할 때는 모든 방법론이 유사한 성능을 보였으며, OVR, GLE와 같은 단순한 기준선도 경쟁력 있는 성능을 나타냈습니다. 이는 훈련 데이터가 많을수록 임베딩 품질의 중요성이 감소함을 의미합니다.

## 🧠 Insights & Discussion

- ALE 프레임워크는 속성 기반 분류를 레이블 임베딩 문제로 성공적으로 전환하여, 기존 DAP 모델의 구조적, 확장적 한계를 체계적으로 해결했습니다.
- 연속형 속성 임베딩의 사용은 제로샷 분류 정확도를 크게 향상시키며, 이는 속성 정보의 세부적인 강도를 포착하는 것이 중요함을 보여줍니다.
- 학습된 속성 분류기의 해석 가능성을 유지하면서도 분류 정확도를 높일 수 있어, "인간-개입(human-in-the-loop)" 시스템에서도 유용하게 활용될 수 있습니다.
- 레이블 임베딩 프레임워크는 다양한 형태의 사이드 정보를 쉽게 통합할 수 있는 유연성을 제공하며, 제로샷, 퓨샷, 전체 데이터 학습 등 광범위한 시나리오에 걸쳐 적용 가능합니다.
- 이는 입력 결합에 대한 연구에 비해 상대적으로 덜 탐구된 "출력 결합(combining outputs)"이라는 연구 경로의 가치를 강조합니다.

## 📌 TL;DR

본 논문은 제로샷 학습에 초점을 맞춘 이미지 분류를 위한 **속성 레이블 임베딩(ALE)** 프레임워크를 제안합니다. 이는 속성 기반 분류를 레이블 임베딩 문제로 재구성하여, 이미지-레이블 호환성 함수를 학습하고 랭킹 목적 함수를 직접 최적화합니다. ALE는 기존 DAP 모델의 한계(비효율적 두 단계 학습, 사이드 정보 통합의 어려움)를 극복하며, 특히 연속형 속성 임베딩을 통해 AWA 및 CUB 데이터셋에서 제로샷 학습 성능을 크게 향상시킵니다. 또한 클래스 계층 및 텍스트 정보와 같은 다양한 사이드 정보를 활용할 수 있으며, 데이터가 부족한 퓨샷 학습 환경에서도 우수한 성능을 보였습니다.
