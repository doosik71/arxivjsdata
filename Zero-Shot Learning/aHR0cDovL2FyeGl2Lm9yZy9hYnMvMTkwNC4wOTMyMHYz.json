{
  "title": "Context-Aware Zero-Shot Recognition",
  "authors": "Ruotian Luo, Ning Zhang, Bohyung Han, Linjie Yang",
  "year": 2019,
  "url": "http://arxiv.org/abs/1904.09320v3",
  "abstract": "We present a novel problem setting in zero-shot learning, zero-shot object\nrecognition and detection in the context. Contrary to the traditional zero-shot\nlearning methods, which simply infers unseen categories by transferring\nknowledge from the objects belonging to semantically similar seen categories,\nwe aim to understand the identity of the novel objects in an image surrounded\nby the known objects using the inter-object relation prior. Specifically, we\nleverage the visual context and the geometric relationships between all pairs\nof objects in a single image, and capture the information useful to infer\nunseen categories. We integrate our context-aware zero-shot learning framework\ninto the traditional zero-shot learning techniques seamlessly using a\nConditional Random Field (CRF). The proposed algorithm is evaluated on both\nzero-shot region classification and zero-shot detection tasks. The results on\nVisual Genome (VG) dataset show that our model significantly boosts performance\nwith the additional visual context compared to traditional methods.",
  "citation": 33
}