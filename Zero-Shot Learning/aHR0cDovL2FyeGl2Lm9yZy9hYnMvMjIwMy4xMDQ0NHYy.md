# VGSE: Visually-Grounded Semantic Embeddings for Zero-Shot Learning

Wenjia Xu, Yongqin Xian, Jiuniu Wang, Bernt Schiele, Zeynep Akata

## 🧩 해결하려는 문제점

제로샷 학습(ZSL)에서 의미론적 임베딩은 클래스 간 지식 전이를 촉진하는 중요한 역할을 합니다. 기존 접근 방식에는 두 가지 주요 문제점이 있습니다.

* **수동 주석 속성의 한계:** 사람이 직접 주석을 단 속성(human-annotated attributes)은 강력한 의미론적 임베딩이지만, 전문가의 감독과 많은 노동력을 필요로 하여 확장성이 떨어집니다.
* **비지도 단어 임베딩의 한계:** 단어 임베딩(word embeddings)과 같은 비지도 의미론적 임베딩은 주석 없이 지식 전이를 가능하게 하지만, 시각적 유사성을 항상 반영하지 못하여 ZSL 성능이 저하되는 원인이 됩니다. 예를 들어, 텍스트에서는 "양(sheep)"과 "개(dog)"가 가깝지만, 시각적으로는 "양"이 "사슴(deer)"과 더 유사합니다.

이 논문은 인간의 주석 없이도 식별 가능한 시각적 속성(discriminative visual properties)을 포함하는 의미론적 임베딩을 발견하여, 시각적 유사성과 의미론적 관련성 사이의 격차를 해소하는 것을 목표로 합니다.

## ✨ 주요 기여

* **시각 기반 의미론적 임베딩(VGSE) 네트워크 제안:** 학습된 클래스(seen classes)의 이미지에서 시각적 클러스터를 학습하고, 비지도 외부 지식(예: word2vec)을 활용하여 각 카테고리에 대한 의미론적 임베딩을 자동으로 예측하는 VGSE 네트워크를 제안합니다.
* **ZSL 성능의 상당한 개선:** AWA2, CUB, SUN 세 가지 ZSL 벤치마크에서 제안된 VGSE 의미론적 임베딩이 5가지 최신(SOTA) ZSL 모델 전반에 걸쳐 기존 단어 임베딩보다 일관되게 성능을 크게 향상시킴을 입증했습니다.
* **풍부하고 이해하기 쉬운 시각 정보 포함:** 정성적 평가 및 사용자 연구를 통해 VGSE 임베딩이 세분화된(fine-grained) 속성과 같은 풍부한 시각 정보를 포함하며, 인간이 이해할 수 있는 의미론을 전달하여 클래스 간 지식 전이를 촉진함을 보여주었습니다.

## 📎 관련 연구

* **제로샷 학습 (ZSL):** 훈련 시 보지 못한 새로운 클래스의 이미지를 분류하는 것을 목표로 하며, 시각 공간과 의미 공간을 연결하는 호환성 함수(compatibility function) 학습 또는 생성 모델(generative model)을 통한 특징 합성 방식이 주로 사용됩니다.
* **의미론적 임베딩 (Semantic Embeddings):** 객체의 특성(색상, 모양 등)을 나타내는 인간 주석 속성이 가장 널리 사용되지만, 수집에 많은 비용과 전문가 지식이 필요합니다. 대안으로 텍스트 코퍼스에서 학습된 단어 임베딩, 지식 그래프, 온라인 백과사전 기사 등이 있으나, 이러한 임베딩이 항상 시각적 유사성을 반영하지는 못하는 한계가 있습니다.
* **이미지 패치에서 시각적 속성 학습:** 중간 레벨 표현을 발견하려는 이전 시도들은 이미지 전체 임베딩이나 명명 가능한 지역화된 속성을 탐색했습니다. Visual Transformer나 BagNets는 이미지 패치가 강력한 시각적 단어 역할을 함을 보였습니다. 본 연구는 이미지 패치를 클러스터링하여 시각적 속성을 학습하며, 기존 Bag of Visual Words(BOVW) 모델과 달리 딥러닝을 통해 종단간(end-to-end) 방식으로 클러스터링을 학습하고, 규칙적인 그리드 대신 세그멘테이션 기반 영역 제안(segmentation-based region proposals)을 사용하여 의미론적 이미지 영역을 얻습니다.

## 🛠️ 방법론

제안하는 시각 기반 의미론적 임베딩(VGSE) 네트워크는 두 가지 주요 모듈로 구성됩니다.

1. **패치 클러스터링 (Patch Clustering, PC) 모듈:** 학습 데이터셋의 이미지 패치를 $D_v$개의 시각 클러스터로 군집화합니다.
    * **패치 이미지 생성:** 비지도 압축 분수령 분할(unsupervised compact watershed segmentation) 알고리즘을 사용하여 각 이미지를 $N_t$개의 의미론적 패치로 분할합니다.
    * **패치 클러스터링:** ResNet으로 사전 훈련된 딥 뉴럴 네트워크를 사용하여 패치 특징 $\theta(x_{nt}) \in \mathbb{R}^{D_f}$를 추출하고, 클러스터링 레이어 $H: \mathbb{R}^{D_f} \to \mathbb{R}^{D_v}$를 통해 클러스터 확률 $a_{nt}$를 예측합니다.
        * **클러스터링 손실($L_{clu}$):** 패치 $x_{nt}$와 그 이웃이 동일한 클러스터에 할당되도록 합니다: $L_{clu} = - \sum_{x_{nt} \in X_{sp}} \sum_{x_i \in X_{sp}^{nb}} \log(a_{nt}^T a_i)$.
        * **엔트로피 페널티($L_{pel}$):** 이미지가 모든 클러스터에 균등하게 분포되도록 합니다: $L_{pel} = \sum_{k=1}^{D_v} \bar{a}_k^{nt} \log \bar{a}_k^{nt}$.
    * **클래스 판별($L_{cls}$):** 클러스터-클래스 레이어 $Q: \mathbb{R}^{D_v} \to \mathbb{R}^{|Y_s|}$를 사용하여 학습된 클러스터에 클래스 판별 정보를 부여하고, 교차 엔트로피 손실로 훈련합니다.
    * **의미론적 관련성($L_{sem}$):** 클러스터-의미론적 레이어 $S: \mathbb{R}^{D_v} \to \mathbb{R}^{D_w}$를 통해 학습된 클러스터를 word2vec 임베딩 $\phi_w(y_n)$에 회귀시켜 클래스 간 전이 가능성을 높입니다: $L_{sem} = \|S \circ a_{nt} - \phi_w(y_n)\|^2$.
    * **전체 목적 함수:** $L = L_{clu} + \lambda L_{pel} + \beta L_{cls} + \gamma L_{sem}$.
    * **학습된 클래스(Seen Class) 의미론적 임베딩 예측:** 각 이미지의 패치 임베딩을 평균하여 이미지 임베딩 $a_n$을 얻고, 다시 클래스에 속하는 모든 이미지 임베딩을 평균하여 클래스 임베딩 $\phi_{VGSE}(y_n)$를 계산합니다.

2. **클래스 관계 (Class Relation, CR) 모듈:** 비지도 단어 임베딩(예: word2vec)을 활용하여 학습되지 않은 클래스(unseen classes)의 의미론적 임베딩을 추론합니다.
    * **가중 평균 (Weighted Average, VGSE-WAvg):** 학습되지 않은 클래스 $y_m$의 임베딩을 word2vec 공간에서 가장 가까운 이웃 학습된 클래스 $\tilde{y}$들의 의미론적 임베딩 $\phi_{VGSE}(\tilde{y})$의 가중 평균으로 계산합니다. 이때 가중치는 word2vec 유사도 $\text{sim}(y_m, \tilde{y}) = \exp(-\eta\|\phi_w(y_m) - \phi_w(\tilde{y})\|^2)$에 비례합니다.
    * **유사도 행렬 최적화 (Similarity Matrix Optimization, VGSE-SMO):** 학습되지 않은 클래스 $y_m$와 모든 학습된 클래스 $Y_s$ 간의 유사도 매핑 $r \in \mathbb{R}^{|Y_s|}$을 학습하여 $y_m$의 word2vec 임베딩 $\phi_w(y_m)$을 학습된 클래스들의 word2vec 임베딩 $\phi_w(Y_s)$로부터 재구성합니다. 학습된 $r$을 사용하여 $\phi_{VGSE}(y_m) = r^T \phi_{VGSE}(Y_s)$를 예측합니다.

## 📊 결과

* **단어 임베딩 대비 우수성:** VGSE-SMO는 AWA2, CUB, SUN 세 가지 벤치마크 데이터셋과 SJE, APN, GEM-ZSL, CADA-VAE, f-VAEGAN-D2와 같은 5가지 최신 ZSL 모델 모두에서 word2vec 임베딩보다 훨씬 뛰어난 성능을 보였습니다. 특히, 미세 분류(fine-grained classification) 태스크에서 큰 성능 향상을 달성했습니다.
  * 예시: AWA2 데이터셋에서 GEM-ZSL과 결합 시, word2vec의 ZSL 성능 50.2%를 VGSE-SMO가 58.0%로 향상시켰습니다.
  * 일반화된 제로샷 학습(GZSL)의 조화 평균(harmonic mean)에서도 크게 개선되었습니다.
* **약한 감독 학습 방식 대비 우수성:** VGSE는 외부 지식으로 오직 word2vec만을 사용했음에도 불구하고, 텍스트 기사를 활용하는 ZSLNS, GAZSL, Auto-Dis, CAAP 등 다른 약한 감독(weakly supervised) ZSL 의미론적 임베딩 학습 방법들보다 뛰어난 성능을 보였습니다.
* **패치 클러스터링 (PC) 모듈의 효과:**
  * 클래스 판별 및 의미론적 관련성 손실($L_{cls}, L_{sem}$)을 추가함으로써 ZSL 성능이 크게 향상됨을 확인했습니다.
  * PC 모듈을 통해 학습된 시각 클러스터 임베딩은 ResNet 특징을 직접 사용하거나 K-평균(k-means) 클러스터링을 사용한 임베딩보다 우수했습니다.
* **클러스터 수($D_v$) 및 패치 수($N_t$)의 영향:** 적절한 클러스터 수(예: 150~200)가 성능에 중요하며, 이미지 패치를 사용하는 것이 전체 이미지를 사용하는 것보다 우수했습니다. 특히, 무작위 그리드 패치 대신 분수령 분할 기반의 의미론적 이미지 영역 패치를 사용하는 것이 성능을 크게 향상시켰습니다.
* **외부 지식의 일반화:** VGSE-SMO는 word2vec, GloVe, FastText 등 다양한 외부 단어 임베딩을 사용하더라도 일관된 성능 향상을 보였습니다. 심지어 인간 주석 속성(human-annotated attributes)을 외부 지식으로 활용했을 때에도, VGSE-SMO(Attribute)가 순수 인간 속성보다 높은 성능(AWA2 ZSL에서 62.8% 대비 66.7%)을 달성하여 인간 지식을 보완하고 강화할 수 있음을 입증했습니다.
* **정성적 결과:** t-SNE 시각화를 통해 VGSE가 학습한 시각 클러스터들이 서로 다른 클래스에서 온 패치임에도 불구하고 일관된 시각적 속성(예: 토끼, 북극곰, 여우의 '흰 털'; 호랑이, 얼룩말, 보브캣의 '줄무늬 털')을 공유함을 보여주었습니다. 또한, 인간 주석 속성이 놓칠 수 있는 '우리(cage)', '흑백 털(양)'과 같은 세분화된 시각적 속성도 발견했습니다.
* **인간 평가:** 사용자 연구에서 VGSE 클러스터의 88.5%가 일관된 시각적 속성을, 87.0%가 일관된 의미론적 정보를 전달한다고 평가받았으며, 이는 K-평균 클러스터보다 훨씬 높은 수치로 VGSE 임베딩의 시각적 및 의미론적 일관성을 뒷받침합니다.

## 🧠 통찰 및 논의

* **시각적 접지 임베딩의 중요성:** 이 연구는 ZSL에서 시각적으로 접지된(visually-grounded) 의미론적 임베딩의 중요성을 강조합니다. 단순히 텍스트 기반의 의미론적 유사성뿐만 아니라, 실제 이미지에서 추출된 시각적 특성을 반영하는 임베딩이 클래스 간 지식 전이에 훨씬 효과적임을 보여줍니다.
* **자동화된 세분화된 속성 발견:** 이미지 패치 클러스터링 접근 방식은 노동 집약적인 인간 주석 없이도, 인간이 간과할 수 있는 세분화된(fine-grained) 시각적 속성을 자동으로 발견하는 능력을 가지고 있습니다. 이는 의미론적 공간을 풍부하게 하고 ZSL 성능을 향상시키는 데 기여합니다.
* **다양한 ZSL 모델에 대한 일반화:** VGSE가 기존의 다양한 ZSL 모델(생성 및 비생성 모델 모두)의 성능을 향상시킨다는 결과는 제안된 의미론적 임베딩이 특정 ZSL 모델에 종속되지 않고 광범위하게 적용될 수 있는 일반화 능력을 가지고 있음을 시사합니다.
* **비용 효율성:** 인간 주석 없이 기존의 이미지 분류 레이블과 비지도 텍스트 임베딩만을 사용하여 강력한 의미론적 임베딩을 생성함으로써, ZSL의 적용 가능성을 크게 확장하고 비용 문제를 해결할 수 있습니다.

## 📌 TL;DR

**문제점:** 제로샷 학습(ZSL)에서 의미론적 임베딩은 필수적이지만, 인간 주석은 비싸고 기존 단어 임베딩은 시각적 유사성을 반영하지 못해 ZSL 성능이 낮습니다.
**제안 방법:** VGSE(Visually-Grounded Semantic Embedding)는 두 가지 모듈로 구성됩니다. 첫째, **패치 클러스터링(PC) 모듈**은 학습된 클래스 이미지의 패치에서 시각적으로 구별되고 의미론적으로 관련된 클러스터를 학습합니다. 둘째, **클래스 관계(CR) 모듈**은 외부 지식(예: word2vec)을 사용하여 학습된 클래스와 학습되지 않은 클래스 간의 관계를 모델링하여 학습되지 않은 클래스의 임베딩을 추론합니다.
**핵심 결과:** VGSE 임베딩은 여러 ZSL 모델과 데이터셋에서 단어 임베딩 및 다른 약한 감독 방식보다 훨씬 뛰어난 성능을 달성합니다. VGSE는 풍부하고 인간이 이해할 수 있는 시각적 속성을 포착하여 ZSL 및 GZSL 모두에서 지식 전이를 효과적으로 개선합니다.
