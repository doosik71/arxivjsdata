# Feature Generating Networks for Zero-Shot Learning

Yongqin Xian, Tobias Lorenz, Bernt Schiele, Zeynep Akata

## 🧩 Problem to Solve

제로샷 학습(ZSL) 및 일반화된 제로샷 학습(GZSL)에서 **본 클래스(seen classes)와 미본 클래스(unseen classes) 간의 극심한 훈련 데이터 불균형**이 핵심 문제입니다. 대부분의 기존 최첨단 접근 방식은 GZSL과 같이 미본 클래스에 대한 레이블이 지정된 예제가 전혀 없는 상황에서 만족스러운 결과를 얻지 못하고 있습니다. 딥러닝은 많은 훈련 데이터를 필요로 하지만, 현실 세계에서는 모든 개념에 대해 충분한 양의 레이블이 지정된 데이터를 확보하기 어렵습니다. 특히, 미본 클래스의 경우 훈련 예제가 전혀 없습니다. 기존 이미지 생성 GAN은 사실적인 이미지를 생성할 수 있지만, 이러한 이미지를 사용하여 딥러닝 분류기를 훈련할 만큼 충분한 품질을 제공하지 못합니다.

## ✨ Key Contributions

- **새로운 조건부 생성 모델 `f-CLSWGAN` 제안**: Wasserstein 거리와 분류 손실(classification loss)로 정규화하여 미본 클래스의 CNN 특징을 합성하는 모델을 제안합니다. 이는 클래스 수준의 의미론적 정보(예: 속성, 문장 임베딩)에 기반하여 미본 클래스의 구별 가능한 시각적 특징 분포를 직접 생성합니다.
- **최첨단 성능 향상**: 5가지 챌린지 데이터셋(CUB, FLO, SUN, AWA, ImageNet)에서 ZSL 및 GZSL 설정 모두에서 최첨단 정확도를 크게 향상시켰습니다.
- **생성 모델 평가를 위한 GZSL 활용**: 생성 모델의 성능을 평가하는 보조 작업으로 GZSL을 제안하여, 생성된 데이터의 구별 능력을 정량적으로 측정할 수 있도록 합니다.
- **모델의 일반화 능력 입증**: 제안된 모델이 GoogleNet, ResNet과 같은 다양한 딥 CNN 특징 추출기와 속성(attribute), 문장 임베딩(sentence embedding), Word2Vec과 같은 다양한 클래스 수준 보조 정보에 일반화될 수 있음을 보여줍니다.

## 📎 Related Works

- **생성적 적대 신경망(GAN)**:
  - 원래 GAN [18]은 임의의 데이터 분포를 학습합니다.
  - DCGAN [34]은 GAN에 딥 컨볼루션 네트워크를 활용하여 훈련 방식을 개선했습니다.
  - InfoGAN [12]은 해석 가능한 잠재 변수와 생성자 분포 간의 상호 정보를 최대화하여 GAN을 확장했습니다.
  - 조건부 GAN [29]은 클래스 레이블이나 문장 설명을 조건 변수로 사용하여 GAN을 확장했습니다.
  - WGAN [5] 및 개선된 WGAN (WGAN-GP) [19]은 Wasserstein 거리를 최적화하여 GAN 훈련의 불안정성 문제를 해결했습니다.
  - 본 논문은 이러한 GAN들이 주로 이미지를 생성하는 데 사용되었으며, 이미지 특징 생성에 적용되지 않았다는 점을 지적합니다.
- **제로샷 학습(ZSL) 및 일반화된 제로샷 학습(GZSL)**:
  - ZSL은 훈련 시 미본 클래스의 레이블 데이터를 사용하지 않습니다 [22, 24, 25, 39, 47].
  - 기존 ZSL 접근 방식은 본 클래스의 비율 혼합으로 미본 클래스를 학습하거나 [50, 31, 8], 이미지와 클래스 간의 호환성을 학습합니다 [2, 3, 14, 42, 45, 40, 16, 33, 1, 6, 17, 23].
  - 전이 학습 설정에서 미본 클래스의 비레이블 데이터를 활용하는 연구도 있습니다 [15, 38, 26].
  - GZSL은 테스트 시 본 클래스와 미본 클래스 모두가 등장하는 더 현실적인 시나리오이며, 이에 대한 연구는 상대적으로 적습니다 [42, 9].
  - [20]은 특징 벡터만으로 예제를 생성하지만, 본 연구는 의미론적 정보를 조건으로 활용하여 미본 클래스에 일반화됩니다. [7]은 GMMN [27]을 통해 특징을 생성하며, 본 논문은 이와 직접 비교됩니다.

## 🛠️ Methodology

이 논문은 미본 클래스에 대한 합성 CNN 특징을 생성하여 ZSL 및 GZSL 문제를 해결하는 `f-CLSWGAN` 모델을 제안합니다.

1. **문제 정의**:

   - **본 클래스 훈련 데이터 $S$**: $\{(x, y, c(y))\}$로 구성되며, $x \in \mathbb{R}^{d_x}$는 CNN 특징, $y \in Y_s$는 본 클래스 레이블, $c(y) \in \mathbb{R}^{d_c}$는 클래스 $y$의 의미론적 임베딩(예: 속성)입니다.
   - **미본 클래스 집합 $U$**: $\{(u, c(u))\}$로 구성되며, $u \in Y_u$는 미본 클래스 레이블, $c(u)$는 해당 클래스의 의미론적 임베딩입니다. 미본 클래스에 대한 이미지 특징은 없습니다.
   - **목표**: ZSL의 경우 $f_{zsl}: X \to Y_u$를 학습하고, GZSL의 경우 $f_{gzsl}: X \to Y_s \cup Y_u$를 학습합니다.

2. **특징 생성 (Feature Generation)**:

   - **`f-GAN`**: 조건부 GAN으로, 생성자 $G: Z \times C \to X$는 무작위 가우시안 노이즈 $z$와 클래스 임베딩 $c(y)$를 입력받아 CNN 이미지 특징 $\tilde{x}$를 출력합니다. 판별자 $D: X \times C \to [0,1]$은 실제 이미지 특징과 생성된 특징을 구별합니다.
     $$ \min*G \max_D L*{GAN} = E[\log D(x, c(y))] + E[\log (1 - D(\tilde{x}, c(y)))] $$
   - **`f-WGAN`**: 개선된 WGAN [19]을 조건부 설정으로 확장합니다. 판별자 $D: X \times C \to \mathbb{R}$는 시그모이드 레이어를 제거하고 실수 값을 출력합니다. Wasserstein 거리 근사를 최적화하며, 기울기 페널티(gradient penalty)를 통해 1-Lipschitz 제약 조건을 적용합니다.
     $$ L*{WGAN} = E[D(x, c(y))] - E[D(\tilde{x}, c(y))] - \lambda E[(||\nabla*{\hat{x}} D(\hat{x}, c(y))||\_2 - 1)^2] $$
        여기서 $\tilde{x} = G(z, c(y))$, $\hat{x} = \alpha x + (1-\alpha)\tilde{x}$ ($\alpha \sim U(0,1)$).
   - **`f-CLSWGAN` (제안 모델)**: `f-WGAN`에 분류 손실 ($L_{CLS}$)을 추가하여 생성된 특징이 분류에 적합하도록 만듭니다. $L_{CLS}$는 생성된 특징에 대한 음의 로그 가능도이며, 미리 훈련된 선형 Softmax 분류기를 사용하여 계산됩니다. 이 분류 손실은 생성자가 구별 가능한 특징을 생성하도록 강제하는 정규화 역할을 합니다.
     $$ L*{CLS} = -E*{\tilde{x} \sim p*{\tilde{x}}}[\log P(y | \tilde{x}; \theta)] $$
        최종 목적 함수는 다음과 같습니다.
        $$ \min_G \max_D L*{WGAN} + \beta L\_{CLS} $$
        여기서 $\beta$는 분류 손실의 가중치를 조절하는 하이퍼파라미터입니다.

3. **분류 (Classification)**:
   - 생성 모델이 훈련된 후, 각 미본 클래스 $u \in Y_u$에 대해 $c(u)$를 조건으로 무작위 노이즈 $z$를 샘플링하여 원하는 만큼의 합성 CNN 특징 $\tilde{x}$를 생성합니다.
   - 이렇게 생성된 미본 클래스 특징으로 합성 훈련 세트 $\tilde{U} = \{(\tilde{x}, u, c(u))\}$를 구성합니다.
   - **멀티모달 임베딩 (Multimodal Embedding)**: ALE [2], DEVISE [14] 등 기존 ZSL 방법을 본 클래스 데이터 $S$와 합성 미본 클래스 데이터 $\tilde{U}$의 조합으로 훈련하여 더 강력한 분류기를 학습합니다.
     $$ f(x) = \operatorname{argmax}\_y F(x, c(y); W) $$
   - **Softmax**: 표준 Softmax 분류기는 $T=\tilde{U}$ (ZSL) 또는 $T=S \cup \tilde{U}$ (GZSL)에 대해 음의 로그 가능도 손실을 최소화하여 훈련됩니다.
     $$ \min*\theta -\frac{1}{|T|} \sum*{(x,y) \in T} \log P(y|x; \theta) $$

## 📊 Results

- **ZSL 및 GZSL 성능 대폭 향상**: `f-CLSWGAN`은 모든 데이터셋(CUB, FLO, SUN, AWA, ImageNet)에서 ZSL 및 GZSL의 정확도를 기존 최첨단 모델 대비 크게 향상시켰습니다.
  - **ZSL (Top-1 정확도)**: CUB에서 54.9% $\to$ 61.5%, FLO에서 53.4% $\to$ 71.2%, SUN에서 58.1% $\to$ 62.1%, AWA에서 65.6% $\to$ 69.9%로 향상되었습니다.
  - **GZSL (조화 평균 H)**: CUB에서 34.4% $\to$ 49.7%, FLO에서 21.9% $\to$ 65.6%, SUN에서 26.3% $\to$ 39.4%, AWA에서 27.5% $\to$ 59.6%로 향상되었습니다.
- **간단한 Softmax 분류기의 효과**: `f-CLSWGAN`이 생성한 특징을 사용하면 간단한 Softmax 분류기도 기존의 복잡한 멀티모달 임베딩 모델들을 능가하는 성능을 보이며 GZSL에 적용 가능해졌습니다.
- **생성 모델 버전 비교**: `f-CLSWGAN`은 `f-GAN`, `f-WGAN`, 그리고 경쟁 모델인 `f-GMMN`보다 일관되게 우수한 성능을 보였습니다. 이는 분류 손실의 효과를 입증합니다.
- **안정성과 일반화**:
  - `f-CLSWGAN`은 훈련 중 안정적인 정확도 향상을 보이며, 본 클래스에 대한 분류 성능이 실제 데이터의 상한에 거의 도달합니다.
  - 생성된 미본 클래스 특징의 수를 늘릴수록 (예: 클래스당 1개 $\to$ 100개) 미본 클래스 정확도가 크게 향상되어, 생성자의 뛰어난 일반화 능력을 보여줍니다.
- **CNN 아키텍처의 영향**: GoogLeNet과 ResNet-101 모두에서 `f-CLSWGAN`이 "none" (특징 생성 없음)보다 크게 우수한 성능을 보이며, 모델이 특정 CNN 특징 분포에 국한되지 않음을 입증했습니다.
- **클래스 임베딩의 영향**:
  - 문장 임베딩(stc)을 조건으로 사용했을 때 속성(att)보다 더 높은 H-측정치와 균형 잡힌 `u` 및 `s` 정확도를 달성했습니다. 이는 고품질의 조건 신호가 더 우수한 CNN 특징을 생성하는 데 도움이 됨을 보여줍니다.
- **대규모 ImageNet 실험**: Word2Vec 임베딩과 함께 `f-CLSWGAN`을 사용했을 때 ImageNet 스케일의 데이터셋에서도 ALE [2] 및 SYNC [8]를 능가하는 최첨단 ZSL 및 GZSL 성능을 달성했습니다.
- **특징 생성 vs. 이미지 생성**: StackGAN [48]을 이용한 이미지 생성과 비교했을 때, CNN 특징 생성이 분류 작업을 위해 훨씬 우수한 성능을 보였습니다. 이미지 생성은 여전히 판별에 필요한 세부 사항을 놓치기 쉽다는 것을 보여줍니다.

## 🧠 Insights & Discussion

- **구별 가능한 특징 생성의 중요성**: 제안된 `f-CLSWGAN`의 핵심 통찰력은 단순히 사실적인 시각적 데이터를 생성하는 것을 넘어, **분류에 유용한 구별 가능한(discriminative) CNN 특징**을 생성하는 데 초점을 맞춘다는 것입니다. 이는 생성자 목적 함수에 분류 손실을 추가함으로써 달성됩니다.
- **데이터 불균형 해결의 효과적인 방법**: 미본 클래스에 대한 합성 특징 생성을 통해 ZSL 및 GZSL에서 본/미본 클래스 간의 데이터 불균형 문제를 효과적으로 해결합니다. 이로 인해 미본 클래스 정확도가 크게 향상되면서 본 클래스 정확도도 유지되어 GZSL의 조화 평균을 극대화합니다.
- **모델의 강력한 일반화 능력**: `f-CLSWGAN`은 다양한 CNN 특징(GoogLeNet, ResNet), 다양한 분류기(ALE, SJE, Softmax 등), 다양한 클래스 임베딩(속성, 문장, Word2Vec) 및 대규모 데이터셋(ImageNet)에 걸쳐 뛰어난 일반화 능력을 보여줍니다. 특히, 단순한 Softmax 분류기가 GZSL에서 효과적으로 작동할 수 있도록 만든 점은 특징 생성의 잠재력을 강조합니다.
- **GZSL을 통한 생성 모델 평가**: 이 논문은 GZSL 작업이 생성 모델의 표현력(expressive power)을 정량적으로 평가하는 강력한 보조 방법으로 활용될 수 있음을 제시합니다. 이는 생성된 이미지의 수동 검사보다 더 객관적이고 효율적인 평가 방식입니다.

## 📌 TL;DR

데이터가 부족한 **제로샷 학습(ZSL) 및 일반화된 제로샷 학습(GZSL)** 문제 해결을 위해, 이 논문은 **`f-CLSWGAN`이라는 새로운 조건부 생성 적대 신경망**을 제안합니다. 이 모델은 **클래스 수준의 의미론적 정보를 조건으로 미본 클래스의 구별 가능한 CNN 특징을 합성**합니다. `f-CLSWGAN`은 Wasserstein GAN에 분류 손실을 추가하여 생성된 특징이 분류에 최적화되도록 강제합니다. 결과적으로, CUB, FLO, SUN, AWA, ImageNet 등 5개 데이터셋에서 ZSL 및 GZSL의 최첨단 성능을 크게 능가하며, **단순한 Softmax 분류기로도 GZSL에서 뛰어난 결과를 달성**할 수 있게 합니다. 또한, **이미지 생성보다 특징 생성이 분류 작업에 훨씬 효과적**임을 입증하고, GZSL을 생성 모델 평가를 위한 프록시 작업으로 활용할 것을 제안합니다.
