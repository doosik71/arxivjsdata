{
  "title": "A Simple and Efficient Baseline for Zero-Shot Generative Classification",
  "authors": "Zipeng Qi, Buhua Liu, Shiyan Zhang, Bao Li, Zhiqiang Xu, Haoyi Xiong, Zeke Xie",
  "year": 2024,
  "url": "http://arxiv.org/abs/2412.12594v1",
  "abstract": "Large diffusion models have become mainstream generative models in both\nacademic studies and industrial AIGC applications. Recently, a number of works\nfurther explored how to employ the power of large diffusion models as zero-shot\nclassifiers. While recent zero-shot diffusion-based classifiers have made\nperformance advancement on benchmark datasets, they still suffered badly from\nextremely slow classification speed (e.g., ~1000 seconds per classifying single\nimage on ImageNet). The extremely slow classification speed strongly prohibits\nexisting zero-shot diffusion-based classifiers from practical applications. In\nthis paper, we propose an embarrassingly simple and efficient zero-shot\nGaussian Diffusion Classifiers (GDC) via pretrained text-to-image diffusion\nmodels and DINOv2. The proposed GDC can not only significantly surpass previous\nzero-shot diffusion-based classifiers by over 10 points (61.40% - 71.44%) on\nImageNet, but also accelerate more than 30000 times (1000 - 0.03 seconds)\nclassifying a single image on ImageNet. Additionally, it provides probability\ninterpretation of the results. Our extensive experiments further demonstrate\nthat GDC can achieve highly competitive zero-shot classification performance\nover various datasets and can promisingly self-improve with stronger diffusion\nmodels. To the best of our knowledge, the proposed GDC is the first zero-shot\ndiffusionbased classifier that exhibits both competitive accuracy and practical\nefficiency.",
  "citation": 2
}