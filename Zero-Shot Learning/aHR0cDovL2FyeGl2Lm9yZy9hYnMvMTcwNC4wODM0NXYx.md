# Semantic Autoencoder for Zero-Shot Learning

Elyor Kodirov, Tao Xiang, Shaogang Gong

## 🧩 Problem to Solve

기존 Zero-Shot Learning(ZSL) 모델은 시각적 특징 공간에서 의미론적 임베딩 공간으로의 투영 함수를 학습하지만, 이 함수는 학습 시 사용된 "보이는 클래스(seen classes)"에 편향되어 "보이지 않는 클래스(unseen classes)"에 적용될 때 "투영 도메인 시프트(projection domain shift)" 문제로 인해 성능 저하를 겪는다. 이는 보이지 않는 클래스의 시각적 특징이 의미론적 공간에서 올바른 위치에 투영되지 못하게 하여 정확한 분류를 어렵게 한다.

## ✨ Key Contributions

- Zero-Shot Learning을 위한 새로운 선형 대칭 시맨틱 오토인코더(Semantic AutoEncoder, SAE) 모델을 제안한다.
- SAE는 원본 시각적 특징을 충실하게 재구성할 수 있는 저차원 의미론적 표현을 학습한다.
- SAE의 효율적인 학습 알고리즘을 개발했으며, 이 알고리즘의 계산 복잡도는 훈련 데이터의 크기와 무관하다($O(d^3)$).
- 재구성 제약 조건이 Zero-Shot Learning의 주요 문제인 투영 도메인 시프트(projection domain shift)를 효과적으로 완화함을 입증했다.
- SAE가 지도 학습 클러스터링(supervised clustering)과 같은 다른 문제에도 성공적으로 적용될 수 있음을 보여주었다.
- 6개의 벤치마크 ZSL 데이터셋에서 기존 최신 모델보다 뛰어난 성능을 달성했으며, 동시에 낮은 계산 비용을 유지한다.

## 📎 Related Works

- **의미론적 공간:** 속성(attribute) 공간, 워드 벡터(word vector) 공간(word2vec), 위키피디아 문서와 같은 텍스트 설명 등 다양한 의미론적 공간이 ZSL에 활용되어 왔다.
- **시각 $\to$ 의미 투영:** 기존 ZSL 모델의 대부분은 시각적 특징 공간에서 의미론적 공간으로의 투영 함수를 학습한다. 본 논문의 인코더가 이에 해당한다.
- **의미 $\to$ 시각 투영:** 일부 모델은 허브니스(hubness) 문제를 완화하기 위해 의미론적 공간에서 시각적 특징 공간으로 역투영한다. 본 논문의 디코더가 이에 해당한다.
- **투영 도메인 시프트 완화:** 기존 연구들은 대부분 전이 학습(transductive learning) 접근 방식을 사용했으나, 이는 모든 테스트 데이터에 대한 사전 접근을 필요로 한다. 본 연구는 재구성 제약 조건을 통해 귀납적 학습(inductive learning)으로 도메인 시프트를 해결한다.
- **오토인코더:** 기존 오토인코더는 대부분 비지도 학습 방식으로 특징을 학습하며, 입력 신호 재구성 능력에 초점을 맞춘다. 본 SAE는 지도 학습 방식이며, 저차원 의미론적 공간을 학습한다.
- **지도 학습 클러스터링:** 레이블이 지정된 훈련 데이터셋을 활용하여 투영 행렬을 학습하는 방식으로, 주로 메트릭 학습(metric learning) 또는 회귀 기반(regression-based) 접근 방식을 사용한다.

## 🛠️ Methodology

1. **선형 오토인코더 기반:** 입력 데이터 $X \in \mathbb{R}^{d \times N}$ (N개의 $d$차원 특징 벡터)를 저차원 잠재 공간 $S \in \mathbb{R}^{k \times N}$으로 투영하는 인코더 $W \in \mathbb{R}^{k \times d}$와 $S$를 다시 $X$로 재구성하는 디코더 $W^* \in \mathbb{R}^{d \times k}$를 정의한다. 목표는 재구성 오차 $ \min\_{W, W^*} \|X - W^*WX\|\_F^2 $를 최소화하는 것이다.
2. **의미론적 제약 조건 추가:** 잠재 공간 $S$가 데이터의 의미론적 표현(예: 속성 벡터)이 되도록 $WX = S$라는 강한 제약 조건을 추가한다.
3. **가중치 공유(Tied Weights):** 모델을 단순화하기 위해 디코더 투영 행렬 $W^*$를 인코더 투영 행렬 $W$의 전치 $W^T$로 설정한다. 이로써 추정해야 할 행렬이 $W$ 하나로 줄어든다.
4. **최종 목적 함수 및 최적화:** 강한 제약 조건 $WX = S$를 부드러운 제약 조건으로 완화하여 다음과 같은 목적 함수를 사용한다:
   $$ \min_W \|X - W^TS\|\_F^2 + \lambda \|WX - S\|\_F^2 $$
    여기서 $ \lambda $는 인코더와 디코더의 손실 중요도를 조절하는 가중치 계수이다. 이 함수는 $W$에 대해 볼록(convex)하며, $W$에 대한 미분값을 0으로 설정하여 얻을 수 있는 다음 실베스터 방정식(Sylvester equation)을 통해 최적해를 찾는다:
    $$ AW + WB = C $$
    여기서 $A = SS^T$, $B = \lambda XX^T$, $C = (1+\lambda)SX^T$ 이다.
   이 방정식은 Bartels-Stewart 알고리즘을 통해 효율적으로 해결할 수 있으며, 계산 복잡도는 특징 차원 $d$에만 의존($O(d^3)$)하고 데이터 샘플 수 $N$에는 의존하지 않아 대규모 데이터셋에 매우 적합하다.
5. **ZSL 및 지도 학습 클러스터링 적용:**
   - **ZSL:** 학습된 인코더 $W$를 사용하여 테스트 이미지의 시각적 특징을 의미론적 공간으로 투영($ \hat{s}\_i = Wx_i $)하거나, 디코더 $W^T$를 사용하여 의미론적 프로토타입을 시각적 특징 공간으로 투영($ \hat{x}\_i = W^T s_i $)한 후, 가장 가까운 이웃 탐색(Nearest Neighbor search)을 통해 클래스를 분류한다.
   - **지도 학습 클러스터링:** 의미론적 공간 $S$를 원-핫(one-hot) 클래스 레이블 벡터로 설정하고, 학습된 $W$를 사용하여 데이터를 레이블 공간으로 투영한 후 k-평균 클러스터링을 수행한다.

## 📊 Results

- **Zero-Shot Learning (ZSL):**
  - Animals with Attributes (AwA), CUB-200-2011 Birds (CUB), aPascal&Yahoo (aP&Y), SUN Attribute (SUN) 등 4개의 소규모 데이터셋과 ILSVRC2010 (ImNet-1), ILSVRC2012/ILSVRC2010 (ImNet-2) 등 2개의 대규모 데이터셋을 포함한 총 6개 벤치마크에서 기존 14개(소규모), 7개(대규모) ZSL 모델들을 모두 능가하는 최고의 성능을 달성했다.
  - 소규모 데이터셋에서는 가장 강력한 경쟁 모델 대비 3.5%에서 6.5%의 성능 향상을 보였으며, 최대 규모인 ImNet-2에서는 기존 최신 모델 대비 8.8% 향상되었다.
  - 재구성 제약 조건의 중요성을 입증하는 분석(ablation study)을 통해, 재구성 제약이 없는 단순 회귀 모델 대비 압도적인 성능 향상을 보였다.
  - 일반화된 ZSL 설정(Generalized ZSL)에서도 CUB 데이터셋에서 경쟁 모델을 크게 앞섰다.
  - 훈련 및 테스트 단계 모두에서 기존의 효율적인 선형 ZSL 모델들보다 훨씬 빠른(훈련 시 최소 10배) 계산 속도를 제공한다.
- **지도 학습 클러스터링 (Supervised Clustering):**
  - 합성 데이터셋(클러스터 크기 동일/상이, 노이즈 포함)과 실제 Oxford Flowers-17 데이터셋에서 모든 비교 모델보다 우수한 클러스터링 정확도를 달성했다.
  - MLCA보다 훈련 시간이 길지만, 다른 모든 경쟁 모델보다 훨씬 효율적인 훈련 시간을 보여주었다.

## 🧠 Insights & Discussion

- **재구성 제약의 효과:** 제안된 SAE 모델의 핵심은 시각적 특징의 재구성 제약 조건이다. 이 제약은 학습된 투영 함수가 원본 시각적 특징에 포함된 모든 정보를 보존하도록 강제하며, 이는 도메인 시프트 문제에 덜 민감하게 반응하여 보이지 않는 클래스로의 일반화 성능을 크게 향상시킨다.
- **단순성과 효율성의 시너지:** 선형적이고 대칭적인 인코더-디코더 구조는 단순함에도 불구하고 재구성 제약 덕분에 놀라운 효과를 발휘한다. 이 설계는 계산 효율성을 극대화하여 대규모 데이터셋에도 쉽게 적용될 수 있다.
- **암묵적 정규화:** 재구성 제약은 투영 행렬의 노름(norm)에 대한 명시적인 정규화 항 없이도 과적합을 방지하는 암묵적인 정규화 효과를 제공한다.
- **다목적성:** ZSL뿐만 아니라 지도 학습 클러스터링 문제에서도 재구성 제약이 학습된 표현의 의미를 풍부하게 하여 우수한 성능을 달성함으로써 모델의 일반적인 적용 가능성을 입증한다.
- **한계 및 의의:** 모델이 선형 투영 함수를 사용한다는 점은 잠재적으로 비선형 모델보다 표현력이 떨어질 수 있다는 한계가 있지만, 재구성 제약을 통해 이를 극복하고 다양한 최신 비선형 모델을 능가하는 뛰어난 성능을 보여주었다. 이는 ZSL에서 모델의 복잡성보다는 핵심적인 문제(도메인 시프트)를 해결하는 제약 조건이 더 중요할 수 있음을 시사한다.

## 📌 TL;DR

Zero-Shot Learning(ZSL)의 투영 도메인 시프트 문제를 해결하기 위해, 시각적 특징을 의미론적 공간으로 투영하는 인코더와 원본 특징을 재구성하는 디코더로 구성된 새로운 선형 대칭 시맨틱 오토인코더(SAE)를 제안한다. SAE는 재구성 제약 조건을 통해 모델의 일반화 능력을 크게 향상시키며, 6개 ZSL 벤치마크 및 지도 학습 클러스터링 문제에서 최신 기술 대비 뛰어난 성능과 낮은 계산 비용을 달성했다.
