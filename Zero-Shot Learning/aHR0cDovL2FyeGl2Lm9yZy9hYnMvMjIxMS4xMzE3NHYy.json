{
  "title": "Evolutionary Generalized Zero-Shot Learning",
  "authors": "Dubing Chen, Chenyi Jiang, Haofeng Zhang",
  "year": 2022,
  "url": "http://arxiv.org/abs/2211.13174v2",
  "abstract": "Attribute-based Zero-Shot Learning (ZSL) has revolutionized the ability of\nmodels to recognize new classes not seen during training. However, with the\nadvancement of large-scale models, the expectations have risen. Beyond merely\nachieving zero-shot generalization, there is a growing demand for universal\nmodels that can continually evolve in expert domains using unlabeled data. To\naddress this, we introduce a scaled-down instantiation of this challenge:\nEvolutionary Generalized Zero-Shot Learning (EGZSL). This setting allows a\nlow-performing zero-shot model to adapt to the test data stream and evolve\nonline. We elaborate on three challenges of this special task, \\ie,\ncatastrophic forgetting, initial prediction bias, and evolutionary data class\nbias. Moreover, we propose targeted solutions for each challenge, resulting in\na generic method capable of continuous evolution from a given initial IGZSL\nmodel. Experiments on three popular GZSL benchmark datasets demonstrate that\nour model can learn from the test data stream while other baselines fail. Codes\nare available at \\url{https://github.com/cdb342/EGZSL}.",
  "citation": 1
}