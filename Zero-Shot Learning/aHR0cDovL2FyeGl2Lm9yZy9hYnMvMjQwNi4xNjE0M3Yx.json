{
  "title": "Review of Zero-Shot and Few-Shot AI Algorithms in The Medical Domain",
  "authors": "Maged Badawi, Mohammedyahia Abushanab, Sheethal Bhat, Andreas Maier",
  "year": 2024,
  "url": "http://arxiv.org/abs/2406.16143v1",
  "abstract": "In this paper, different techniques of few-shot, zero-shot, and regular\nobject detection have been investigated. The need for few-shot learning and\nzero-shot learning techniques is crucial and arises from the limitations and\nchallenges in traditional machine learning, deep learning, and computer vision\nmethods where they require large amounts of data, plus the poor generalization\nof those traditional methods.\n  Those techniques can give us prominent results by using only a few training\nsets reducing the required amounts of data and improving the generalization.\n  This survey will highlight the recent papers of the last three years that\nintroduce the usage of few-shot learning and zero-shot learning techniques in\naddressing the challenges mentioned earlier. In this paper we reviewed the\nZero-shot, few-shot and regular object detection methods and categorized them\nin an understandable manner. Based on the comparison made within each category.\nIt been found that the approaches are quite impressive.\n  This integrated review of diverse papers on few-shot, zero-shot, and regular\nobject detection reveals a shared focus on advancing the field through novel\nframeworks and techniques. A noteworthy observation is the scarcity of detailed\ndiscussions regarding the difficulties encountered during the development\nphase. Contributions include the introduction of innovative models, such as\nZSD-YOLO and GTNet, often showcasing improvements with various metrics such as\nmean average precision (mAP),Recall@100 (RE@100), the area under the receiver\noperating characteristic curve (AUROC) and precision. These findings underscore\na collective move towards leveraging vision-language models for versatile\napplications, with potential areas for future research including a more\nthorough exploration of limitations and domain-specific adaptations.",
  "citation": 3
}