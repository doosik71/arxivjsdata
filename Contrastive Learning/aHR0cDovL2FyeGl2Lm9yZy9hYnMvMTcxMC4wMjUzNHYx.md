# Contrastive Learning for Image Captioning
Bo Dai, Dahua Lin

## 해결하고자 하는 문제
기존 이미지 캡션 생성 모델들은 주로 최대 우도 추정(**MLE**)을 통해 학습되어, 생성된 캡션이 **경직되고** (**rigid**) **제한적**(**restrictive**)이며, 종종 다른 이미지, 특히 유사한 객체를 포함하는 이미지에 대해 매우 **유사한** 캡션을 생성하는 경향이 있습니다. 이는 자연어 설명에서 중요한 속성인 **고유성**(**distinctiveness**)이 간과되기 때문입니다. 논문은 자체 검색 연구(**self-retrieval study**)를 통해 캡션의 고유성 부족이 품질 저하로 이어진다는 것을 보여줍니다.

## 주요 기여
*   이미지 캡션 생성을 위한 새로운 학습 방법인 **대조 학습**(**Contrastive Learning**, **CL**)을 제안합니다.
*   **CL**은 참조 모델(**reference model**) 위에 두 가지 제약 조건을 정립하여, 생성된 캡션의 전반적인 품질을 유지하면서 **고유성**을 명시적으로 장려합니다.
*   두 가지 도전적인 데이터셋(**MSCOCO**, **InstaPIC-1.1M**)에서 기존 베이스라인 모델 대비 **상당한 성능 향상**을 달성했습니다.
*   제안된 방법이 **다양한 구조의 모델에 적용 가능**한 범용적인 방법임을 입증했습니다.

## 방법론
**CL**은 대상 이미지 캡션 모델 $p_m(\cdot;\theta)$을 참조 모델 $p_n(\cdot;\phi)$과 비교하여 학습합니다.
*   **데이터셋 구성**:
    *   **긍정 쌍**(**positive pairs**, `X`): 실제 이미지-캡션 쌍 $(I, c)$.
    *   **부정 쌍**(**negative pairs**, `Y`): 불일치 이미지-캡션 쌍 $(I, c')$. 여기서 $c'$는 다른 이미지에 대한 캡션이며, 이는 동적으로 샘플링됩니다.
*   **학습 목표**:
    *   긍정 쌍 $(I, c)$에 대해 대상 모델 $p_m(c|I,\theta)$의 확률이 참조 모델 $p_n(c|I,\phi)$보다 높아야 합니다.
    *   부정 쌍 $(I, c')$에 대해 $p_m(c'|I,\theta)$의 확률이 $p_n(c'|I,\phi)$보다 낮아야 합니다.
*   **목적 함수**:
    *   `Noise Contrastive Estimation`(**NCE**)에서 영감을 받아, 대상 모델과 참조 모델의 조건부 확률 로그-비율 함수 $G((c,I);\theta,\phi) = \ln p_m(c|I,\theta) - \ln p_n(c|I,\phi)$를 사용합니다.
    *   이 $G$ 값에 로지스틱 함수 $r_{\nu}(z) = \frac{1}{1 + \nu \exp(-z)}$를 적용하여 $h((c,I);\theta,\phi) = r_{\nu}(G((c,I);\theta,\phi))$를 계산합니다. 이는 쉬운 샘플의 영향을 포화시키기 위함입니다.
    *   최종 손실 함수는 다음과 같습니다:
        $$L(\theta; X, Y, \phi) = \sum_{t=1}^{T_m} \ln[h((c_t,I_t);\theta,\phi)] + \sum_{t=1}^{T_n} \ln[1-h((c'_t,I_t);\theta,\phi)]$$
    *   긍정 및 부정 쌍의 균형 잡힌 영향을 위해 $\nu = T_n/T_m = 1$로 설정합니다.
    *   더 다양한 부정 쌍을 포함하고 과적합을 방지하기 위해 긍정 데이터 `X`를 $K$번 복사하고 각각 다른 부정 쌍 `Y`를 샘플링하여 최종 목적 함수 $J(\theta)$를 정의합니다 (실험에서는 $K=5$ 사용).
    $$J(\theta) = \frac{1}{K} \frac{1}{T_m} \sum_{k=1}^K L(\theta; X, Y_k, \phi)$$
*   이 학습 과정은 부정 쌍에 대한 확률을 억제하여 **고유성**을 장려하고, 긍정 쌍에 대한 확률 값을 극대화하여 전반적인 성능을 유지합니다.
*   **참조 모델**: 참조 모델은 일반적으로 학습 과정 내내 고정되지만, 주기적으로 최신 대상 모델로 교체하여 추가 성능 향상을 꾀할 수도 있습니다.

## 결과
*   **전반적인 성능**:
    *   **MSCOCO** 데이터셋에서 **CL**은 **MLE**로 학습된 `AdaptiveAttention` 모델의 모든 지표에서 **상당한 성능 향상**을 이끌어냈습니다. 특히 `Cider` 점수는 1.003에서 1.029로 향상되어 C40에서 **단일 모델 중 최고 성능**을 달성했습니다.
    *   **InstaPIC-1.1M** 데이터셋에서는 `AdaptiveAttention`의 `Cider` 점수를 14% 향상시켜 **최고 성능**을 기록했습니다.
*   **질적 결과**: **CL**로 생성된 캡션은 `AdaptiveAttention` 모델이 **MLE**로 생성한 캡션보다 더 **고유하고 구체적**임을 보여주었습니다.
*   **다른 학습 방법과의 비교**:
    *   **CL**은 **Introspective Learning**(**IL**) 및 **GAN** 기반 방법보다 베이스라인 모델의 성능을 더 크게 향상시켰습니다. **IL**과 **GAN**은 때때로 성능을 저하시키는 경향을 보였습니다.
    *   **CL**의 긍정 제약 조건(**CL(P)**) 또는 부정 제약 조건(**CL(N)**)만 단독으로 사용하는 것보다, 이 둘을 모두 포함하는 **CL(Full)**이 모든 지표에서 가장 큰 개선을 가져왔습니다.
*   **모델 선택 및 일반화 능력**:
    *   **CL**은 `AdaptiveAttention`뿐만 아니라 `Neuraltalk2`와 같은 다른 이미지 캡션 모델에서도 성능 향상을 보여 **일반화 능력**이 뛰어남을 입증했습니다.
    *   더 강력한 모델(`AdaptiveAttention`)을 참조 모델로 사용했을 때, 대상 모델(`Neuraltalk2`)의 성능이 더욱 향상되어, 더 강력한 참조 모델이 학습에 더 강한 제약 조건을 제공함을 시사합니다.
*   **참조 모델 주기적 교체**: 충분히 강력한 참조 모델을 사용하면 첫 번째 학습 실행에서 이미 성능 개선이 충분히 이루어지며, 참조 모델을 여러 번 교체하는 것은 전반적인 성능 측면에서 추가적인 이점이 크지 않다는 것을 확인했습니다.