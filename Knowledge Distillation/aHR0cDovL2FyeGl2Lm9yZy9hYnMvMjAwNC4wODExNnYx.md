# Triplet Loss for Knowledge Distillation
Hideki Oki, Motoshi Abe, Jyunichi Miyao and Takio Kurita

## 🧩 Problem to Solve
최근 딥러닝 모델은 깊고 커지면서 막대한 계산 비용을 수반하게 되었습니다. 이러한 문제를 해결하기 위한 모델 압축 기술 중 하나가 지식 증류(Knowledge Distillation, KD)입니다. 기존의 지식 증류 방법들은 주로 교사 모델의 출력(로짓 또는 소프트맥스 확률)을 학생 모델이 모방하도록 학습시키는 데 중점을 두었습니다. 하지만 이는 교사 모델의 미묘한 지식, 특히 다른 클래스 간의 차이를 명확히 구분하는 능력을 학생 모델에 효과적으로 전달하지 못할 수 있습니다. 따라서 이 연구는 교사 모델의 지식을 더 효과적으로 전달하여 학생 모델의 성능을 향상시키는 새로운 지식 증류 접근법을 모색합니다.

## ✨ Key Contributions
*   **메트릭 학습 개념 도입**: 지식 증류에 메트릭 학습(Metric Learning)의 개념, 특히 트라이플렛 손실(Triplet Loss)을 도입하여 교사 모델의 지식을 더욱 효과적으로 학생 모델에 전달하는 새로운 방법을 제안했습니다.
*   **"모방하지 않아야 할 지식" 전달**: 제안된 트라이플렛 손실은 학생 모델이 동일 샘플에 대한 교사 모델의 출력을 모방하는 동시에, 다른 클래스에 속하는 샘플에 대해서는 교사 모델의 출력과 멀어지도록 학습시켜 "모방하지 않아야 할 지식"까지 전달합니다.
*   **성능 향상 입증**: CIFAR-10 및 Tiny ImageNet 데이터셋에 대한 실험을 통해 제안된 `Ours KD` 방법이 기존의 지식 증류 방법들(Ba의 KD, Hinton의 KD, Park의 RKD-DA)보다 학생 모델의 분류 정확도를 크게 향상시킴을 입증했습니다.
*   **다른 KD 방법과의 시너지**: Hinton의 KD (HKD) 및 Park의 RKD-DA와 같은 다른 지식 증류 손실들과 결합했을 때, 특히 Tiny ImageNet 데이터셋에서 추가적인 성능 향상을 보여 제안된 방법이 기존 방법들과 상호 보완적임을 확인했습니다.

## 📎 Related Works
*   **심층 컨볼루션 신경망 (Deep CNN)**: AlexNet, VGG, ResNet과 같이 대규모 이미지 분류 및 객체 인식에서 뛰어난 성능을 보인 모델들.
*   **메트릭 학습 (Metric Learning)**: 유사한 샘플의 출력 거리를 줄이고, dissimilar 샘플의 출력 거리를 늘려 임베딩을 학습하는 방법.
    *   **Siamese Network**: 두 개의 동일한 네트워크를 사용하여 샘플 쌍 간의 거리를 학습. (수식 $E = \frac{1}{2|\chi_2|} \sum_{(i,j) \in \chi_2} l_{ij}(D_{ij})^2 + (1-l_{ij})\max(m-D_{ij},0)^2$)
    *   **Triplet Network**: "앵커", "긍정", "부정"으로 구성된 세 개의 샘플을 사용하여 앵커-긍정 거리는 줄이고 앵커-부정 거리는 늘리도록 학습. (트라이플렛 손실 수식: $E = \sum_{(a,p,n) \in \Theta} \max(0, m+||f(x_a)-f(x_p)||^2_2 - ||f(x_a)-f(x_n)||^2_2)$)
*   **지식 증류 (Knowledge Distillation)**: 파라미터가 많은 큰 교사 모델의 지식을 작고 얕은 학생 모델에 전달하는 기술.
    *   **Ba et al. [4] (BKD)**: 교사 및 학생 모델의 로짓(logits) 간의 평균 제곱 오차를 손실로 사용. (수식 $E_{\text{BKD}} = \frac{1}{2} \sum_{i \in \chi} ||t(x_i) - s(x_i)||^2_2$)
    *   **Hinton et al. [5] (HKD)**: 교사 및 학생 모델의 소프트맥스 출력(확률) 간의 KL-divergence를 손실로 사용. 온도(temperature) 파라미터 $T$ 도입. (수식 $E_{\text{HKD}} = \sum_{i \in \chi} \text{KL}(\text{softmax}(\frac{t(x_i)}{T}),\text{softmax}(\frac{s(x_i)}{T}))$)
    *   **Park et al. [13] (RKD-D, RKD-A, RKD-DA)**: 교사 모델 출력 간의 관계적 지식을 전달.
        *   **RKD-D**: 출력 쌍 간의 유클리드 거리를 사용.
        *   **RKD-A**: 출력 트리플렛이 형성하는 각도의 코사인 값을 사용.
        *   **RKD-DA**: RKD-D와 RKD-A 손실을 결합.
*   **결합 손실**: 일반적으로 단단한 타겟(hard target) 손실과 부드러운 타겟(soft target) 손실을 결합하여 사용. ($E_{\text{KD}} = E_{\text{hard}} + \lambda_{\text{soft}} E_{\text{soft}}$)

## 🛠️ Methodology
제안하는 방법은 메트릭 학습의 핵심 아이디어인 트라이플렛 손실을 지식 증류에 적용합니다.

*   **제안된 트라이플렛 손실 ($E_{\text{ourKD}}$)**:
    $$ E_{\text{ourKD}} = \sum_{(a,n) \in \Omega} \max(0, m + ||t(x_a) - s(x_a)||^2_2 - ||t(x_a) - s(x_n)||^2_2) $$
    *   $t(x_a)$: 앵커 샘플 $x_a$에 대한 교사 모델의 출력.
    *   $s(x_a)$: 앵커 샘플 $x_a$에 대한 학생 모델의 출력. 이는 트라이플렛의 "긍정"으로 간주됩니다.
    *   $s(x_n)$: 앵커 샘플 $x_a$와 다른 클래스에 속하는 샘플 $x_n$에 대한 학생 모델의 출력. 이는 트라이플렛의 "부정"으로 간주됩니다.
    *   $m$: 마진 파라미터.
    *   $\Omega$: 해당 샘플 쌍의 인덱스 집합.
    *   **목표**: $t(x_a)$와 $s(x_a)$ 사이의 거리를 최소화하는 동시에, $t(x_a)$와 $s(x_n)$ 사이의 거리를 마진 $m$ 이상으로 최대화합니다. 교사 모델의 가중치는 학습 과정에서 고정됩니다.
*   **전체 손실 함수**: 제안된 $E_{\text{ourKD}}$는 일반적인 단단한 타겟 손실(소프트맥스와 교차 엔트로피)과 결합되어 학생 모델을 학습시킵니다.
*   **실험 설정**:
    *   **데이터셋**: CIFAR-10 및 Tiny ImageNet.
    *   **모델 아키텍처**:
        *   CIFAR-10: 교사 모델 (8-layer CNN), 학생 모델 (5-layer CNN).
        *   Tiny ImageNet: 교사 모델 (VGG19), 학생 모델 (VGG11).
    *   **학습**: 모멘텀을 사용한 SGD, ReLU 활성화 함수, 가중치 감쇠, 특정 학습률 스케줄. Tiny ImageNet에는 Mixup을 적용.
    *   **하이퍼파라미터**: Hinton의 KD를 위한 온도 $T=4$, 트라이플렛 손실의 마진 $m=5$. 각 KD 손실에 대한 가중치 $\lambda$를 설정.
    *   **비교 대상**: Ba의 KD (BKD), Hinton의 KD (HKD), Park의 RKD-DA.
    *   **조합 실험**: HKD 및 RKD-DA와 제안된 방법을 결합한 경우의 성능도 평가했습니다.

## 📊 Results
*   **단독 성능 비교 (표 II, III)**:
    *   **CIFAR-10**: 제안된 `Ours KD`는 81.14%의 정확도로, 단독 학생 모델(74.66%)과 BKD (80.40%), HKD (79.16%), RKD-DA (79.21%)를 포함한 모든 기존 KD 방법보다 우수한 성능을 보였습니다. (교사 모델: 83.42%)
    *   **Tiny ImageNet**: 제안된 `Ours KD`는 60.00%의 정확도로, 다른 기존 KD 방법들(BKD 59.80%, HKD 59.80%, RKD-DA 59.73%)에 비해 소폭 우수했습니다. (교사 모델: 63.17%)
*   **결합 손실 성능 비교 (표 IV, V)**:
    *   **HKD와의 결합 (표 IV)**: Tiny ImageNet 데이터셋에서는 모든 KD 방법이 HKD와 결합했을 때 성능이 향상되었으며, `Ours KD + HKD`가 60.62%로 가장 높은 정확도를 달성했습니다. CIFAR-10에서는 `Ours KD + HKD`가 단독 `Ours KD`보다 약간 낮았지만, 여전히 결합 모델 중 가장 높은 성능을 유지했습니다.
    *   **RKD-DA와의 결합 (표 V)**: Tiny ImageNet 데이터셋에서는 `Ours KD`가 RKD-DA (60.32%) 및 HKD + RKD-DA (60.65%)와 결합했을 때 추가적인 성능 향상을 보였습니다. 특히 `Ours KD + HKD + RKD-DA` 조합이 가장 높은 60.65%의 정확도를 기록했습니다. CIFAR-10에서는 RKD-DA와의 결합이 단독 `Ours KD`보다 성능 향상을 가져오지 못했습니다.

## 🧠 Insights & Discussion
*   **메트릭 학습의 지식 증류 기여**: 제안된 트라이플렛 손실을 통해 교사 모델의 "모방해야 할 지식"뿐만 아니라 "모방하지 않아야 할 지식(다른 클래스 간의 차이)"까지 학생 모델에 효과적으로 전달할 수 있음을 확인했습니다. 이는 학생 모델이 더 명확한 클래스 경계를 학습하는 데 기여하여 성능 향상으로 이어집니다.
*   **성능 우위**: 제안된 방법은 다양한 데이터셋에서 기존 지식 증류 방법들을 능가하는 학생 모델 성능을 달성하여, 메트릭 학습 개념의 유효성을 입증했습니다.
*   **시너지 효과**: 특히 Tiny ImageNet에서 나타난 것처럼, 제안된 방법이 Hinton의 KD나 Park의 RKD-DA와 같은 다른 KD 손실들과 결합했을 때 시너지 효과를 보인다는 점은, 각 손실이 지식의 다른 측면을 포착하여 통합적인 지식 전달이 더욱 효과적임을 시사합니다.
*   **한계점 및 향후 연구**: 트라이플렛 손실은 '하드 샘플링(hard sampling)'이라는 문제점을 내포하고 있습니다. 일관된 학습 결과를 얻기 위해서는 학습하기 어려운 샘플을 의도적으로 선택해야 하는데, 이는 구현의 복잡성을 증가시킵니다. 향후 연구에서는 Hermans et al. [18]과 같은 방법을 통해 이 하드 샘플링 문제를 해결하는 방안을 모색할 필요가 있습니다.

## 📌 TL;DR
*   **문제**: 기존 지식 증류는 교사 모델의 지식을 모방하는 데 초점을 맞추었으나, 다른 클래스 간의 구별 능력 전달에는 한계가 있었습니다.
*   **제안 방법**: 메트릭 학습의 핵심인 트라이플렛 손실을 지식 증류에 도입했습니다. 이 손실은 학생 모델이 동일 샘플에 대한 교사 모델의 출력을 가깝게 모방하는 동시에, 교사 모델의 출력과 다른 클래스 샘플에 대한 학생 모델의 출력을 멀리 떨어뜨리도록 학습시킵니다.
*   **주요 발견**: 이 새로운 접근법은 CIFAR-10 및 Tiny ImageNet에서 기존의 지식 증류 방법들보다 학생 모델의 분류 정확도를 크게 향상시켰습니다. 또한, 다른 SOTA KD 손실들과 결합했을 때 시너지 효과를 보여 추가적인 성능 향상을 달성했습니다. 이는 메트릭 학습이 '모방해야 할 지식'뿐만 아니라 '모방하지 말아야 할 지식'까지 효과적으로 전달하여 학생 모델의 성능을 개선함을 입증합니다.