{
  "title": "Improving Defensive Distillation using Teacher Assistant",
  "authors": "Maniratnam Mandal, Suna Gao",
  "year": 2023,
  "url": "http://arxiv.org/abs/2305.08076v1",
  "abstract": "Adversarial attacks pose a significant threat to the security and safety of\ndeep neural networks being applied to modern applications. More specifically,\nin computer vision-based tasks, experts can use the knowledge of model\narchitecture to create adversarial samples imperceptible to the human eye.\nThese attacks can lead to security problems in popular applications such as\nself-driving cars, face recognition, etc. Hence, building networks which are\nrobust to such attacks is highly desirable and essential. Among the various\nmethods present in literature, defensive distillation has shown promise in\nrecent years. Using knowledge distillation, researchers have been able to\ncreate models robust against some of those attacks. However, more attacks have\nbeen developed exposing weakness in defensive distillation. In this project, we\nderive inspiration from teacher assistant knowledge distillation and propose\nthat introducing an assistant network can improve the robustness of the\ndistilled model. Through a series of experiments, we evaluate the distilled\nmodels for different distillation temperatures in terms of accuracy,\nsensitivity, and robustness. Our experiments demonstrate that the proposed\nhypothesis can improve robustness in most cases. Additionally, we show that\nmulti-step distillation can further improve robustness with very little impact\non model accuracy."
}