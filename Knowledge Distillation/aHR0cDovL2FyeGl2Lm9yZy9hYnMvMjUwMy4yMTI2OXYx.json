{
  "title": "Delving Deep into Semantic Relation Distillation",
  "authors": "Zhaoyi Yan, Kangjun Liu, Qixiang Ye",
  "year": 2025,
  "url": "http://arxiv.org/abs/2503.21269v1",
  "abstract": "Knowledge distillation has become a cornerstone technique in deep learning,\nfacilitating the transfer of knowledge from complex models to lightweight\ncounterparts. Traditional distillation approaches focus on transferring\nknowledge at the instance level, but fail to capture nuanced semantic\nrelationships within the data. In response, this paper introduces a novel\nmethodology, Semantics-based Relation Knowledge Distillation (SeRKD), which\nreimagines knowledge distillation through a semantics-relation lens among each\nsample. By leveraging semantic components, \\ie, superpixels, SeRKD enables a\nmore comprehensive and context-aware transfer of knowledge, which skillfully\nintegrates superpixel-based semantic extraction with relation-based knowledge\ndistillation for a sophisticated model compression and distillation.\nParticularly, the proposed method is naturally relevant in the domain of Vision\nTransformers (ViTs), where visual tokens serve as fundamental units of\nrepresentation. Experimental evaluations on benchmark datasets demonstrate the\nsuperiority of SeRKD over existing methods, underscoring its efficacy in\nenhancing model performance and generalization capabilities."
}