{
  "url": "http://arxiv.org/abs/1905.08663v2",
  "title": "RASNet: Segmentation for Tracking Surgical Instruments in Surgical\n  Videos Using Refined Attention Segmentation Network",
  "authors": "Zhen-Liang Ni, Gui-Bin Bian, Xiao-Liang Xie, Zeng-Guang Hou, Xiao-Hu Zhou, Yan-Jie Zhou",
  "year": 2019,
  "abstract": "Segmentation for tracking surgical instruments plays an important role in\nrobot-assisted surgery. Segmentation of surgical instruments contributes to\ncapturing accurate spatial information for tracking. In this paper, a novel\nnetwork, Refined Attention Segmentation Network, is proposed to simultaneously\nsegment surgical instruments and identify their categories. The U-shape network\nwhich is popular in segmentation is used. Different from previous work, an\nattention module is adopted to help the network focus on key regions, which can\nimprove the segmentation accuracy. To solve the class imbalance problem, the\nweighted sum of the cross entropy loss and the logarithm of the Jaccard index\nis used as loss function. Furthermore, transfer learning is adopted in our\nnetwork. The encoder is pre-trained on ImageNet. The dataset from the MICCAI\nEndoVis Challenge 2017 is used to evaluate our network. Based on this dataset,\nour network achieves state-of-the-art performance 94.65% mean Dice and 90.33%\nmean IOU."
}