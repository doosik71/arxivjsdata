{
  "title": "WeakSurg: Weakly supervised surgical instrument segmentation using\n  temporal equivariance and semantic continuity",
  "authors": "Qiyuan Wang, Yanzhe Liu, Shang Zhao, Rong Liu, S. Kevin Zhou",
  "year": 2024,
  "url": "http://arxiv.org/abs/2403.09551v2",
  "abstract": "For robotic surgical videos, instrument presence annotations are typically\nrecorded with video streams, which offering the potential to reduce the\nmanually annotated costs for segmentation. However, weakly supervised surgical\ninstrument segmentation with only instrument presence labels has been rarely\nexplored in surgical domain due to the highly under-constrained challenges.\nTemporal properties can enhance representation learning by capturing sequential\ndependencies and patterns over time even in incomplete supervision situations.\nFrom this, we take the inherent temporal attributes of surgical video into\naccount and extend a two-stage weakly supervised segmentation paradigm from\ndifferent perspectives. Firstly, we make temporal equivariance constraint to\nenhance pixel-wise temporal consistency between adjacent features. Secondly, we\nconstrain class-aware semantic continuity between global and local regions\nacross temporal dimension. Finally, we generate temporal-enhanced pseudo masks\nfrom consecutive frames to suppress irrelevant regions. Extensive experiments\nare validated on two surgical video datasets, including one cholecystectomy\nsurgery benchmark and one real robotic left lateral segment liver surgery\ndataset. We annotate instance-wise instrument labels with fixed time-steps\nwhich are double checked by a clinician with 3-years experience to evaluate\nsegmentation results. Experimental results demonstrate the promising\nperformances of our method, which consistently achieves comparable or favorable\nresults with previous state-of-the-art approaches.",
  "citation": 1
}