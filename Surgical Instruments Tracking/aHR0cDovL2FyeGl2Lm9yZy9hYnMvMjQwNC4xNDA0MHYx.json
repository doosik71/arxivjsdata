{
  "title": "Surgical-DeSAM: Decoupling SAM for Instrument Segmentation in Robotic\n  Surgery",
  "authors": "Yuyang Sheng, Sophia Bano, Matthew J. Clarkson, Mobarakol Islam",
  "year": 2024,
  "url": "http://arxiv.org/abs/2404.14040v1",
  "abstract": "Purpose: The recent Segment Anything Model (SAM) has demonstrated impressive\nperformance with point, text or bounding box prompts, in various applications.\nHowever, in safety-critical surgical tasks, prompting is not possible due to\n(i) the lack of per-frame prompts for supervised learning, (ii) it is\nunrealistic to prompt frame-by-frame in a real-time tracking application, and\n(iii) it is expensive to annotate prompts for offline applications.\n  Methods: We develop Surgical-DeSAM to generate automatic bounding box prompts\nfor decoupling SAM to obtain instrument segmentation in real-time robotic\nsurgery. We utilise a commonly used detection architecture, DETR, and\nfine-tuned it to obtain bounding box prompt for the instruments. We then\nempolyed decoupling SAM (DeSAM) by replacing the image encoder with DETR\nencoder and fine-tune prompt encoder and mask decoder to obtain instance\nsegmentation for the surgical instruments. To improve detection performance, we\nadopted the Swin-transformer to better feature representation.\n  Results: The proposed method has been validated on two publicly available\ndatasets from the MICCAI surgical instruments segmentation challenge EndoVis\n2017 and 2018. The performance of our method is also compared with SOTA\ninstrument segmentation methods and demonstrated significant improvements with\ndice metrics of 89.62 and 90.70 for the EndoVis 2017 and 2018.\n  Conclusion: Our extensive experiments and validations demonstrate that\nSurgical-DeSAM enables real-time instrument segmentation without any additional\nprompting and outperforms other SOTA segmentation methods."
}