{
  "title": "Surgical Scene Understanding in the Era of Foundation AI Models: A\n  Comprehensive Review",
  "authors": "Ufaq Khan, Umair Nawaz, Adnan Qayyum, Shazad Ashraf, Muhammad Bilal, Junaid Qadir",
  "year": 2025,
  "url": "http://arxiv.org/abs/2502.14886v1",
  "abstract": "Recent advancements in machine learning (ML) and deep learning (DL),\nparticularly through the introduction of foundational models (FMs), have\nsignificantly enhanced surgical scene understanding within minimally invasive\nsurgery (MIS). This paper surveys the integration of state-of-the-art ML and DL\ntechnologies, including Convolutional Neural Networks (CNNs), Vision\nTransformers (ViTs), and foundational models like the Segment Anything Model\n(SAM), into surgical workflows. These technologies improve segmentation\naccuracy, instrument tracking, and phase recognition in surgical endoscopic\nvideo analysis. The paper explores the challenges these technologies face, such\nas data variability and computational demands, and discusses ethical\nconsiderations and integration hurdles in clinical settings. Highlighting the\nroles of FMs, we bridge the technological capabilities with clinical needs and\noutline future research directions to enhance the adaptability, efficiency, and\nethical alignment of AI applications in surgery. Our findings suggest that\nsubstantial progress has been made; however, more focused efforts are required\nto achieve seamless integration of these technologies into clinical workflows,\nensuring they complement surgical practice by enhancing precision, reducing\nrisks, and optimizing patient outcomes."
}