{
  "title": "Surgical SAM 2: Real-time Segment Anything in Surgical Video by\n  Efficient Frame Pruning",
  "authors": "Haofeng Liu, Erli Zhang, Junde Wu, Mingxuan Hong, Yueming Jin",
  "year": 2024,
  "url": "http://arxiv.org/abs/2408.07931v2",
  "abstract": "Surgical video segmentation is a critical task in computer-assisted surgery\nand is vital for enhancing surgical quality and patient outcomes. Recently, the\nSegment Anything Model 2 (SAM2) framework has shown superior advancements in\nimage and video segmentation. However, SAM2 struggles with efficiency due to\nthe high computational demands of processing high-resolution images and complex\nand long-range temporal dynamics in surgical videos. To address these\nchallenges, we introduce Surgical SAM 2 (SurgSAM2), an advanced model to\nutilize SAM2 with an Efficient Frame Pruning (EFP) mechanism, to facilitate\nreal-time surgical video segmentation. The EFP mechanism dynamically manages\nthe memory bank by selectively retaining only the most informative frames,\nreducing memory usage and computational cost while maintaining high\nsegmentation accuracy. Our extensive experiments demonstrate that SurgSAM2\nsignificantly improves both efficiency and segmentation accuracy compared to\nthe vanilla SAM2. Remarkably, SurgSAM2 achieves a 3$\\times$ FPS compared with\nSAM2, while also delivering state-of-the-art performance after fine-tuning with\nlower-resolution data. These advancements establish SurgSAM2 as a leading model\nfor surgical video analysis, making real-time surgical video segmentation in\nresource-constrained environments a reality. Our source code is available at\nhttps://github.com/jinlab-imvr/Surgical-SAM-2."
}