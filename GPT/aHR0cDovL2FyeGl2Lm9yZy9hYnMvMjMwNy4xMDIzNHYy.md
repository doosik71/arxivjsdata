# SentimentGPT: Exploiting GPT for Advanced Sentiment Analysis and its Departure from Current Machine Learning

Kiana Kheiri, Hamid Karimi

## 🧩 해결하고자 하는 문제

- 디지털 시대의 방대한 사용자 생성 콘텐츠는 다양한 분야에서 귀중한 행동 통찰력을 제공하지만, 인간의 한계로 인해 수동 처리는 어렵습니다.
- 자연어 처리(NLP) 분야의 감성 분석은 사람들의 의견, 감정, 태도를 자동으로 분석하는 해결책으로 부상했습니다.
- 그럼에도 불구하고, 감성 분석은 인간 언어의 복잡성(예: 맥락 이해, 비꼬는 표현 및 아이러니 감지, 언어적 뉘앙스 해독, 이모지 또는 약어와 같은 언어 구조 처리)으로 인해 어려움을 겪습니다. 특히 소셜 미디어 콘텐츠는 짧고 노이즈가 많아 이러한 문제가 더욱 두드러집니다.
- 본 연구는 대규모 언어 모델(LLM), 특히 GPT가 이러한 문제들을 극복하고 정확한 감성 예측 모델을 달성할 수 있는지 탐구하고자 합니다.
- 주요 연구 질문은 다음과 같습니다:
  - RQ1: GPT 관련 모델이 기존 기계 학습 솔루션과 비교하여 소셜 미디어 게시물(트윗)의 감성 분석에서 어떤 성능을 보이는가?
  - RQ2: 각기 다른 GPT 제품(프롬프트 기반, 미세 조정, 임베딩)들이 감성 분석 작업에서 어떤 성능을 보이는가?
  - RQ3: GPT 모델이 텍스트 내의 복잡하지만 중요한 언어적 감성 관련 뉘앙스(예: 감정, 이모지, 복합 감성)를 효과적으로 다룰 수 있는가?

## ✨ 주요 기여

- 감성 분석 작업 맥락에서 GPT 모델의 혁신적인 적용을 최초로 소개했습니다.
- GPT 모델과 현재 사용되는 감성 분석 방법론 간의 철저한 비교를 수행했습니다.
- 다양한 GPT 모델(프롬프트 기반, 미세 조정, 임베딩) 간의 비교 및 대조를 진행했습니다.
- 트윗의 감성 관련 언어적 뉘앙스를 해독하고 처리하는 GPT의 능력을 심층적으로 조사했습니다.

## 📎 관련 연구

- **감성 분석의 발전:**
  - **어휘 기반(Lexicon-based) 시대:** 미리 정의된 감성 점수 어휘를 사용하며, 해석은 쉽지만 맥락 이해와 언어 변화에 대한 적응력이 부족했습니다.
  - **기계 학습(ML) 시대:** 나이브 베이즈, 서포트 벡터 머신, 랜덤 포레스트 등 감독 학습 기법을 활용하여 맥락적 뉘앙스 학습에 더 나은 성능을 보였습니다.
  - **트랜스포머 모델 시대:** BERT, GPT-3 등과 같은 모델이 등장하여 사전 학습-미세 조정 패러다임을 통해 부정어, 강조어, 암시적 감성 등 복잡한 요소를 탁월하게 처리합니다.
- **대규모 언어 모델 (LLM):**
  - **GPT-3:** OpenAI의 1,750억 개 파라미터를 가진 최첨단 자동 회귀 언어 모델로, 광범위한 인터넷 텍스트 코퍼스에서 학습되었습니다.
  - **GPT-3.5:** GPT-3에서 진화하여 코드 사전 학습(Codex) 및 강화 학습 기반 미세 조정을 통해 능력이 더욱 향상되었습니다.
  - **프롬프팅 (Prompting):** LLM이 특정 작업을 정확하게 수행하도록 텍스트 작업 설명 또는 프롬프트를 사용하는 새로운 NLP 연구 동향입니다.
- **기준 모델 (SemEval-2017 Task 4):**
  - Baziotis et al. [88]: 어텐션 메커니즘이 있는 양방향 LSTM (BiLSTM) 모델.
  - Deshmane et al. [89]: CNN, GRNN 및 감성 어휘 통합 딥러닝 아키텍처 앙상블.
  - Cliche et al. [90]: CNN 및 LSTM 네트워크 앙상블.
  - Hao et al. [91]: Word2Vec 및 3계층 CNN, SSWE를 사용한 분석.
  - Gonzalez et al. [93]: 컨볼루션 및 순환 신경망, 일반/특정 단어 임베딩 및 극성 어휘 조합.
  - Nguyen et al. [94] (RoBERTa): RoBERTa 사전 학습 절차를 사용한 BERTweet.

## 🛠️ 방법론

제안하는 프레임워크인 **SentimentGPT**는 세 가지 주요 구성 요소를 활용합니다.

- **프롬프트 기반 GPT (GPT-3.5 Turbo 활용):**
  - **프롬프트 엔지니어링:** GPT가 감성 분석을 수행하도록 "사회 과학자로서 트윗의 감성을 0(부정)에서 2(긍정)까지 점수를 매겨라"와 같이 명확하고 구체적인 프롬프트를 설계합니다. 또한, 분류 결정에 대한 설명을 추출하기 위한 프롬프트도 사용합니다.
  - **언어적 뉘앙스 조사:** 이모지, 속어, 해시태그, 부정어 및 비꼬는 표현, 복합 감성, 문화적 맥락, 현대 약어 등 7가지 유형의 언어적 뉘앙스를 식별하고, GPT-3.5가 이를 얼마나 잘 해석하는지 평가합니다.
  - **성능 평가:** 정확도, 재현율, F1-스코어와 같은 지표를 사용하여 평가합니다. GPT는 미리 정의된 세 가지 클래스 외에 "혼합(Mixed)" 감성을 반환할 수 있습니다.

- **미세 조정 GPT 모델:**
  - **모델 선택:** OpenAI API의 Ada, Babbage, Curie 모델을 평가합니다.
  - **절차:** SemEval 2017 훈련 세트의 레이블이 지정된 데이터로 사전 학습된 GPT 모델을 미세 조정합니다.
  - **성능 평가:** 미세 조정된 모델의 성능을 정확도, 재현율, F1-스코어를 사용하여 평가하며, 예측은 미리 정의된 세 가지 감성 클래스(긍정, 부정, 중립)로 제한합니다.

- **임베딩 GPT (davinci-002) + 전통 ML:**
  - **임베딩 획득:** `text-embedding-ada-002` 모델을 사용하여 훈련 및 평가 데이터셋에서 텍스트 임베딩을 추출합니다.
  - **차원 축소:** 과적합 위험을 줄이기 위해 주성분 분석(PCA)을 사용하여 임베딩 차원을 400에서 150으로 줄입니다.
  - **ML 모델 훈련:** 차원 축소된 훈련 세트 임베딩을 입력으로 사용하여 XGboost 및 Random Forest와 같은 전통적인 기계 학습 모델을 훈련합니다.
  - **성능 평가:** 훈련된 ML 모델을 평가 세트 임베딩에 적용하고 성능을 평가합니다.

- **데이터셋:** SemEval-2017 Task 4 데이터셋(영문 트윗, 3점 척도: 긍정, 중립, 부정)을 사용합니다. 데이터셋은 감성 극성의 분포가 불균형합니다.
- **실험 설정:** Python, OpenAI API, GPT CLI를 사용합니다. 온도를 $0$으로 설정하여 높은 정밀도와 결정론적 출력을 보장합니다. GPT 모델의 모든 예측은 3회 실행 중 가장 자주 예측된 출력을 선택하는 'best of 3' 설정으로 실행됩니다. PyCaret을 사용하여 XGBoost 및 Random Forest 모델의 하이퍼파라미터를 최적화합니다.

## 📊 결과

- **전반적인 성능:** GPT 관련 모델은 기존 기계 학습 솔루션을 크게 능가했으며, F1-스코어에서 최신 RoBERTa 대비 22% 이상 높은 성능을 보였습니다.
- **GPT 변형 모델 비교:**
  - **GPT 3.5 Turbo:** 가장 높은 정확도(0.9732)를 달성했습니다.
  - **Ada:** 가장 높은 F1-스코어(0.9473)를 기록했습니다.
  - **Babbage:** 가장 높은 재현율(0.9653)을 달성했습니다.
  - Curie와 Davinci는 위 모델들보다는 낮은 성능을 보였지만, 기존 방법론보다는 훨씬 우수했습니다.
  - GPT 임베딩 + XGBoost/Random Forest도 준수한 성능을 보였지만, 단독 GPT 모델보다는 약간 낮았습니다.
- **언어적 뉘앙스 처리 (GPT-3.5 vs. RoBERTa):** GPT-3.5는 모든 7가지 범주에서 뛰어난 능력을 입증했습니다.
  - **이모지:** 긍정적인 이모지가 있어도 부정적인 텍스트의 감성을 정확히 해석했습니다 (RoBERTa는 4건 모두 실패).
  - **속어:** 속어가 사용된 경우에도 감성을 일관되게 정확히 식별했습니다 (RoBERTa는 절반 실패).
  - **해시태그:** '#NotMyPresident'와 같은 해시태그에 내포된 비꼬는 표현을 정확히 해석했습니다 (RoBERTa는 4건 모두 실패).
  - **부정어 및 비꼬는 표현:** 비꼬는 어조와 부정어를 성공적으로 감지했으며, 일부 인간이 중립으로 분류한 경우에도 정확히 부정적인 감성을 식별했습니다 (RoBERTa는 실패).
  - **복합 감성:** 모든 경우에서 복합 감성을 일관되게 식별했으며, GPT-3.5가 제공하는 추론은 논리적이었습니다 (RoBERTa는 모든 경우에서 어려움).
  - **문화적 맥락:** 'sick' 또는 'flock like sheep'과 같은 문화적 표현에서 감성을 정확히 식별했습니다 (RoBERTa는 3건 모두 오해석).
  - **현대 약어:** 모든 경우에서 감성을 정확하게 식별했습니다 (RoBERTa는 지속적으로 오해석).
- **임베딩 시각화 (t-SNE):** t-SNE 시각화는 GPT 임베딩이 서로 다른 감성 클래스를 뚜렷하게 분리하여 나타냄을 보여주었으며, 이는 GPT가 시끄럽고 짧은 트윗에서도 중요한 텍스트 표현을 학습하는 능력을 증명합니다.

## 🧠 통찰 및 논의

- **함의:**
  - GPT 모델은 복잡한 언어적 뉘앙스를 처리하는 데 있어 감성 분석에 상당한 발전을 제공합니다.
  - 이러한 모델의 트랜스포머 아키텍처, 대규모 학습, 맥락 이해 능력은 탁월한 성능의 핵심입니다.
  - 다양한 GPT 변형이 서로 다른 지표(예: GPT 3.5 Turbo는 정확도, Ada는 F1, Babbage는 재현율)에서 뛰어난 성능을 보이며, 이는 특정 사용 사례에 대한 잠재력을 시사합니다.
  - 예측에 대한 추론을 제공하는 능력은 모델의 해석 가능성을 높이며, 이는 복잡한 AI 모델에서 중요한 측면입니다.
  - GPT 모델은 비꼬는 표현, 복합 감성, 문화적 맥락과 같이 오랫동안 감성 분석을 방해했던 문제들을 효과적으로 해결할 수 있습니다.
- **GPT의 한계:**
  - **프라이버시:** 예측 및 결정을 위해 방대한 데이터 세트에 접근해야 하므로 데이터 기밀성 및 오용에 대한 우려가 있습니다.
  - **사회적 편향:** 학습 데이터에 내재된 편향이 모델 예측에 스며들어 불공정하거나 편향된 결과를 초래할 수 있습니다. 공정성, 포괄성, 비편향적 의사결정을 보장하기 위한 노력이 필요합니다.
  - **비용:** 방대한 처리 시간, 데이터 저장 공간, 전력 소비로 인해 계산 비용이 많이 듭니다. 성능과 비용 간의 균형을 찾는 것이 과제입니다.
- **향후 연구:**
  - 위기 대응, 전자상거래 리뷰, 정치적 담론 등 특정 맥락에서의 감성 분석 성능 탐색.
  - 영어 외 다른 언어에서의 감성 분석 성능 조사 및 각 언어의 고유한 문제점 해결.
  - 감정 인식(예: 기쁨, 분노, 슬픔 등 미세한 감성 구분) 연구 확장.
  - 비꼬는 표현 및 아이러니 감지 개선을 위한 전문 모듈 또는 전략 개발.
  - 다양한 인구 통계학적 그룹에 걸친 GPT 모델의 공정성 및 잠재적 편향 완화 연구.
  - 헬스케어, 금융, 유통 등 다양한 산업 분야에서의 실제 적용 평가.
  - 감성 분석에서 GPT 모델 예측의 해석 가능성 및 설명 가능성을 높이는 기술 개발에 중점.

## 📌 TL;DR

- **문제:** 기존 감성 분석은 소셜 미디어의 복잡한 언어적 뉘앙스(예: 비꼬는 표현, 맥락, 속어) 처리에서 어려움을 겪습니다.
- **방법:** SentimentGPT는 SemEval 2017 트위터 데이터셋에 대해 프롬프트 기반 GPT(GPT-3.5 Turbo), 미세 조정 GPT(Ada, Babbage, Curie), 임베딩 + ML(XGBoost, RF)의 세 가지 GPT 기반 전략을 탐구합니다.
- **핵심 발견:** GPT 모델은 기존 최신 기술(RoBERTa)을 F1-스코어에서 22% 이상 뛰어넘는 월등한 성능을 보입니다. 특히 GPT-3.5 Turbo는 최고 정확도를, Ada는 최고 F1-스코어를, Babbage는 최고 재현율을 달성했습니다. GPT-3.5는 이모지, 속어, 비꼬는 표현, 복합 감성, 문화적 맥락, 약어 등 복잡한 언어적 뉘앙스를 강력한 추론과 함께 해독하는 데 탁월하며, 이는 기존 ML의 한계에서 크게 벗어나는 진보를 보여줍니다.
