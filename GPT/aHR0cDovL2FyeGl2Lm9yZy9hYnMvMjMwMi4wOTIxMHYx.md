# How Good Are GPT Models at Machine Translation? A Comprehensive Evaluation
Amr Hendy, Mohamed Abdelrehim, Amr Sharaf, Vikas Raunak, Mohamed Gabr, Hitokazu Matsushita, Young Jin Kim, Mohamed Afify, Hany Hassan Awadalla

## 🧩 Problem to Solve
최신 GPT 모델들이 자연어 생성에서 놀라운 성능을 보였지만, 기계 번역(MT)에서의 성능은 아직 철저히 조사되지 않았습니다. 이 연구는 GPT 모델의 기계 번역 능력을 종합적으로 평가하여, 기존의 연구 및 상용 시스템과 비교하고, 다양한 조건(프롬프트 전략, 도메인 변화, 문서 수준 번역 등)에서의 강점과 한계를 파악하는 것을 목표로 합니다.

## ✨ Key Contributions
*   **GPT 모델의 포괄적인 번역 성능 평가**: ChatGPT, GPT-3.5(text-davinci-003), text-davinci-002 세 가지 GPT 모델의 번역 품질을 18개 언어 쌍(고자원/저자원, 영어 중심/비영어 중심)에 걸쳐 종합적으로 평가했습니다.
*   **경쟁력 있는 성능 입증**: 고자원 언어 번역에서 GPT 모델이 기존의 최첨단 NMT 시스템 및 상용 시스템과 매우 경쟁력 있는 품질을 달성함을 보여주었습니다. 저자원 언어에서는 제한적인 능력을 보였습니다.
*   **프롬프트 전략의 영향 분석**: 제로샷(zero-shot) 및 퓨샷(few-shot) 프롬프트 전략(무작위, 품질 기반, 관련성 기반)이 GPT 모델의 번역 성능에 미치는 영향을 탐색했습니다. 특히 영어에서 다른 언어로의 번역에서 퓨샷 학습이 꾸준히 성능을 향상시켰습니다.
*   **문서 수준 번역 및 도메인 강건성 평가**: GPT 모델의 문서 수준 번역 능력과 도메인 변화(대화, 뉴스, 전자상거래, 소셜)에 대한 강건성을 평가했습니다. 문서 수준 번역에서 컨텍스트 길이가 길어질수록 성능이 향상되고 효율성이 증대됨을 확인했습니다.
*   **하이브리드 접근법 제안**: GPT 모델과 기존 NMT 시스템을 결합한 하이브리드 접근법이 번역 품질을 더욱 향상시킬 수 있음을 입증했습니다.
*   **번역 특성 심층 분석**: 인간 평가 및 정량적 분석(언어 모델링 편향, 병렬 데이터 편향 등)을 통해 GPT 번역의 고유한 특성(유창성, 비단조성, 구두점 삽입 경향, 정렬되지 않은 단어)을 밝혀냈습니다.
*   **번역 외 다국어 추론 능력 탐색**: MGSM 벤치마크를 사용하여 GPT 모델의 번역 능력과 다국어 추론 능력 간의 연관성을 조사했습니다.

## 📎 Related Works
*   **대규모 언어 모델(LLMs) 및 기계 번역**: Brown et al. (2020), Chowdhery et al. (2022) 등.
*   **Transformer 아키텍처**: Vaswani et al. (2017).
*   **인컨텍스트 학습 및 퓨샷 학습**: Ouyang et al. (2022), Goyal et al. (2022), Wei et al. (2022) 등.
*   **기계 번역 프롬프트 선택**: Zhang et al. (2023), Vilar et al. (2022), Agrawal et al. (2022) 등.
*   **문서 수준 NMT**: Sun et al. (2020), Liu et al. (2020) 등.
*   **MT 평가 메트릭**: Freitag et al. (2022), Rei et al. (2022a, 2022b) (COMET), Popović (2015) (ChrF), Akhbardeh et al. (2021) (Human Eval).
*   **다국어 추론 벤치마크**: Shi et al. (2022) (MGSM).

## 🛠️ Methodology
1.  **GPT 시스템**: text-davinci-002, text-davinci-003(GPT3.5), ChatGPT 세 가지 OpenAI GPT 모델을 Microsoft Azure OpenAI Service API를 통해 접근.
2.  **비교 시스템**: WMT 최고 성능 시스템(WMT-Best)과 Microsoft Translator (상용 시스템)를 벤치마크로 사용.
3.  **데이터셋**: 18개 언어 쌍(영어-독일어, 영어-일본어, 영어-중국어, 아이슬란드어-영어, 하우사어-영어 등)에 걸쳐 WMT22 및 WMT21 공개 테스트셋 사용.
4.  **프롬프트 전략**:
    *   **제로샷(Zero-shot)**: 추가 예시 없이 번역 지시만 제공.
    *   **퓨샷(Few-shot)**: 0, 1, 5개의 학습 예시(샷)를 제공.
        *   **RR (Random)**: WMT 학습 데이터에서 무작위 샷 선택.
        *   **QR (Quality Random)**: LaBSE (Feng et al., 2020)로 점수 매긴 고품질 샷 중 무작위 선택.
        *   **QS (Quality Selected)**: LaBSE 임베딩 코사인 거리를 기반으로 입력 문장과 유사한 고품질 샷 선택.
5.  **평가 메트릭**:
    *   **문장 수준**: COMET-22 (참조 기반), COMETkiwi (참조 불필요), SacreBLEU, ChrF.
    *   **문서 수준**: Doc-COMETkiwi (슬라이딩 윈도우 방식으로 COMETkiwi를 개조), Doc-BLEU.
    *   **인간 평가**: Contrastive DA+SQM (source-based sentence-level), 전문 번역가 5명 참여.
6.  **문서 수준 번역**: 슬라이딩 윈도우 방식을 사용하여 컨텍스트 길이에 따른 성능 및 API 호출 수 변화를 실험.
7.  **도메인 변화 강건성**: WMT22의 4개 도메인(대화, 뉴스, 전자상거래, 소셜) 데이터셋으로 평가.
8.  **하이브리드 접근법**:
    *   **Max-Routing**: MS-Translator와 GPT 중 COMETkiwi 점수가 높은 번역을 선택.
    *   **Threshold-Routing**: MS-Translator의 COMETkiwi 점수가 특정 임계값(중앙값) 이하일 때만 GPT를 사용.
9.  **번역 특성 분석**:
    *   **Translation Non-Monotonicity (NM)**: 번역이 원문의 단어 순서를 얼마나 잘 따르는지 측정.
    *   **Translation Fluency (TF)**: 'gpt2-large' 언어 모델을 사용하여 번역문의 유창성 측정 (X-E 방향에 한정).
    *   **Punctuation Insertion (PI)**: 원문에 없는 문장 종료 부호가 번역문에 삽입된 비율.
    *   **Unaligned Source Words (USW)**: 원문과 번역문 간 단어 정렬에서 정렬되지 않은 원문 단어 수.
    *   **Unaligned Translation Words (UTW)**: 원문과 번역문 간 단어 정렬에서 정렬되지 않은 번역문 단어 수.
10. **다국어 추론 능력**: MGSM (Multilingual Grade School Math) 벤치마크 사용. Native-CoT, Translate-EN, Translate-EN+ 세 가지 설정으로 GPT 모델의 추론 능력 평가.

## 📊 Results
*   **GPT 모델 비교**: text-davinci-003이 다른 두 GPT 모델(text-davinci-002, ChatGPT)보다 전반적으로 우수한 번역 성능을 보였습니다.
*   **고자원 언어 번역**: DE-EN, JA-EN, ZH-EN과 같은 고자원 언어 쌍에서 GPT 모델은 제로샷 설정에서도 WMT-Best 및 MS-Translator 시스템을 능가하거나 거의 동등한 COMET 점수를 달성했습니다. 영어에서 다른 언어로 번역(EN-JA, EN-ZH)할 때는 퓨샷 학습이 성능 향상에 큰 기여를 했습니다.
*   **저자원 및 비영어 중심 언어 번역**: 아이슬란드어(IS)와 하우사어(HA) 같은 저자원 언어에서는 WMT-Best 시스템에 미치지 못했지만, 퓨샷 학습을 통해 완만한 성능 향상을 보였습니다. 비영어 중심 언어 쌍(FR-DE, DE-FR)에서는 제로샷으로도 경쟁력 있는 성능을 보였고, 퓨샷을 통해 상당한 개선을 이루었습니다.
*   **문서 수준 번역**: 컨텍스트 창 크기(1~32 문장)를 늘릴수록 모든 메트릭에서 번역 품질이 향상되었으며, API 요청 수가 현저히 줄어들어 효율성도 증대되었습니다. 문서 수준 번역은 문장 수준 번역보다 우수했지만, 퓨샷 학습의 이점은 문장 수준 번역만큼 크지 않았습니다.
*   **도메인 강건성**: GPT는 대화 도메인에서 특히 뛰어난 성능을 보였습니다. 뉴스, 전자상거래, 소셜 도메인에서도 견고한 번역 능력을 입증했습니다. COMET 메트릭은 도메인 전반에서 일관된 성능을 보인 반면, BLEU/ChrF 같은 어휘 메트릭은 일부 도메인에서 일관성 없는 하락을 보였습니다.
*   **하이브리드 접근법**: "Hybrid Max-Routing"은 모든 언어 쌍에서 개별 시스템보다 일관되게 가장 높은 COMET-22 점수를 달성했습니다. "Hybrid Threshold"도 상한선에 근접하는 결과를 보였으며, GPT 사용률을 50%로 제한하여 효율성을 높였습니다.
*   **인간 평가**: COMETkiwi 결과와 매우 일치하게, GPT는 CS-EN, ZH-EN, EN-ZH, DE-FR에서 WMT-Best 시스템을 능가하거나 고자원 언어에서 비슷한 성능을 보였습니다. 저자원 언어에서는 여전히 뒤쳐졌습니다.
*   **정성적 분석**: GPT는 오타가 있거나 짧고 구어체적인 원문 문장 처리에서 WMT보다 우수했지만, 비정형적이거나 복잡한 표현에서 부자연스러운 번역을 생성하는 경향이 있으며, 때때로 원문에 없는 내용을 "환각"(hallucination)하기도 했습니다.
*   **번역 특성 분석 (언어 모델링 편향)**:
    *   **X-E 번역**: GPT는 더 유창하고(낮은 perplexity), 더 비단조적이며, 더 많은 구두점 삽입을 보였습니다. 또한, 정렬되지 않은 원문 단어 수가 약간 더 많았지만, 정렬되지 않은 번역 단어 수는 비슷하여 충실도와 비례하여 비단조성이 나타남을 시사했습니다.
    *   **E-X 번역**: X-E와 유사하게 구두점 삽입이 더 많았지만 그 차이는 적었습니다. 정렬되지 않은 원문 단어 수가 많고 비단조성이 더 크지만, 정렬되지 않은 번역 단어 수도 약간 더 많아 때로는 '덜 적절한' 번역을 생성할 수 있음을 시사했습니다.
*   **번역 특성 분석 (병렬 데이터 편향)**: GPT는 특히 E-ZH, E-JA, E-RU와 같이 병렬 데이터 구축이 어려운 언어 쌍에서 입력 perplexity가 가장 높은(즉, 품질이 낮은/노이즈가 많은) 버킷의 번역에서 MS-Translator보다 더 높은 성능 향상을 보였습니다.

## 🧠 Insights & Discussion
*   **GPT의 강점**: GPT 모델은 고자원 언어에서 강력한 경쟁력을 가지며, 제로샷 학습만으로도 뛰어난 유창성과 품질을 보여줍니다. 특히 대화 도메인이나 노이즈가 많거나 형식화되지 않은 입력에서 강점을 발휘합니다. 이는 GPT가 방대한 단일 언어 데이터로 학습되어 병렬 데이터의 노이즈 편향으로부터 보호받기 때문으로 분석됩니다.
*   **퓨샷 학습의 역할**: 퓨샷 학습은 영어에서 다른 언어로의 번역과 같은 특정 방향에서 성능을 꾸준히 향상시키는 데 중요합니다. 이는 퓨샷 예시가 출력 공간에 대한 명시적인 지침을 제공하는 역할을 하기 때문입니다.
*   **하이브리드 시스템의 잠재력**: NMT와 GPT의 강점을 결합하는 하이브리드 접근법은 현재 가장 높은 번역 품질을 달성할 수 있는 유망한 방향입니다. 특히 GPT는 기존 NMT 시스템의 품질이 만족스럽지 않을 때의 대체 시스템으로 활용될 수 있습니다.
*   **평가 메트릭의 한계**: BLEU, ChrF와 같은 어휘 기반 메트릭은 GPT 모델의 번역 품질을 정확히 포착하지 못하고 오해의 소지가 있는 신호를 제공할 수 있습니다. COMET과 같은 신경망 기반 메트릭과 인간 평가가 GPT 번역 품질을 평가하는 데 더 적합하고 신뢰할 수 있음을 확인했습니다.
*   **GPT 번역의 특성**: GPT 번역은 더 유창하고 때로는 더 의역적이며(non-monotonicity), 원문에 없는 구두점을 삽입하는 경향이 있습니다. 이러한 언어 모델링 편향은 특정 도메인(예: 매우 직역적이고 충실한 번역이 필요한 경우)에서는 단점이 될 수 있습니다.
*   **다국어 능력의 불균형**: 번역 능력과 다국어 추론 능력 사이에 불균형이 존재합니다. RU, ZH, JA와 같이 번역 성능이 높은 언어에서도 MGSM 벤치마크에서의 추론 성능은 보통 수준에 그쳤습니다. 이는 GPT 모델이 프로그래밍 언어 데이터에 편향되어 학습된 언어의 추론 능력에 더 의존하기 때문일 수 있습니다.
*   **한계점**: 이 연구의 결론은 평가된 18개 언어 쌍에 국한되며, 다른 언어에 대한 일반화는 추가 평가가 필요합니다. 또한, 현재의 자동 평가 메트릭이 GPT 출력의 품질을 완전히 포착하지 못하는 한계가 있습니다.
*   **윤리적 고려사항**: GPT 모델은 언어별 편향을 가질 수 있으며, 고정관념을 영구화하거나 오역(예: 성별 편향) 및 환각(misinformation)을 생성할 수 있습니다. 특히 저자원 언어에서의 성능 격차는 공정성 문제를 야기할 수 있습니다.

## 📌 TL;DR
이 논문은 ChatGPT, GPT-3.5 등 최신 GPT 모델의 기계 번역 능력을 18개 언어 쌍에 걸쳐 종합적으로 평가했습니다. GPT 모델은 고자원 언어 번역에서 기존 SOTA NMT 시스템과 경쟁력 있는 성능을 보였으나, 저자원 언어에서는 한계를 드러냈습니다. 퓨샷 학습은 영어에서 다른 언어로의 번역 성능을 향상시켰고, 문서 수준 번역은 효율성과 품질을 높였습니다. NMT와 GPT를 결합한 하이브리드 접근법은 가장 높은 번역 품질을 달성했습니다. 인간 평가와 COMET 메트릭은 GPT의 강점을 잘 포착한 반면, BLEU/ChrF는 부족했습니다. 분석 결과, GPT 번역은 유창하고 의역적이며 특정 언어 모델링 및 병렬 데이터 편향을 보였습니다. 또한, 번역 능력과 다국어 추론 능력 사이에 불균형이 존재함을 확인했습니다.