# Large Language Models (GPT) for automating feedback on programming assignments

Maciej PANKIEWICZ, Ryan S. BAKER

## 🧩 Problem to Solve

프로그래밍 과제에 대한 맞춤형 피드백을 생성하는 것은 코드 구문의 복잡성, 다양한 올바른 해결 방법, 그리고 평가의 어려움 때문에 상당한 시간과 노력이 필요한 일입니다. 이 연구는 이러한 문제를 해결하기 위해 대규모 언어 모델(LLM)을 활용하여 자동화되고 개인화된 피드백 제공 시스템을 개발하는 것을 목표로 합니다.

## ✨ Key Contributions

* $GPT-3.5$ 모델을 사용하여 프로그래밍 과제에 대한 학생 맞춤형 힌트 생성을 자동화하는 시스템을 구축했습니다.
* 실험군 학생들이 $GPT$가 생성한 힌트의 유용성을 긍정적으로 평가했음을 확인했습니다.
* $GPT$ 힌트가 제공된 실험군은 일반 플랫폼 피드백에 대한 의존도가 감소했음에도 불구하고, 연속 제출 시 과제 성공률이 더 높았습니다.
* $GPT$ 힌트가 제공되지 않은 더 어려운 후속 과제에서 실험군은 대조군보다 과제 해결에 유의미하게 적은 시간을 소요하여, 이전 힌트를 통한 학습 전이 효과를 보였습니다.
* $GPT$ 힌트가 비활성화된 과제에서 실험군은 초기 시도에서 성공률이 낮아지는 경향을 보였으나, 빠르게 적응하여 7번째 시도 후에는 대조군과 유사한 성공률을 달성하며 $GPT$ 피드백에 대한 초기 과도한 의존 가능성과 빠른 적응력을 시사했습니다.
* $GPT$ 힌트의 제공 유무가 학생들의 '집중', '불안', '지루함', '혼란', '좌절감' 등 정서적 상태에 유의미한 영향을 미치지 않았습니다.

## 📎 Related Works

* **대규모 언어 모델(LLM)**: $GPT$ 시리즈 (Radford et al., 2019; Brown et al., 2020)는 복잡한 언어 구조를 처리하고 인간과 유사한 텍스트를 생성하는 능력으로 자연어 처리 분야에서 주목받고 있으며, 교육 환경에서 개인화된 피드백을 제공하는 데 유망합니다 (Carlini et al., 2021; Finnie-Ansley et al., 2022; Dai et al., 2023; Pardos & Bhandari, 2023).
* **컴퓨터 과학 교육의 자동화된 평가 도구**: 프로그래밍 교육 분야에서는 이미 다양한 자동화 평가 도구들이 학생들의 자기 주도 학습을 지원하고 있습니다 (Deeva et al., 2021; Edwards & Murali, 2017; Brusilovsky et al., 2018; Stanger, 2018; Paiva et al., 2022).
* **개인화된 피드백**: 학습 효과를 높이기 위해 개인화된 피드백의 중요성이 여러 연구에서 강조되어 왔습니다 (Jackson & Graesser, 2007; Hull & du Boulay, 2015; Maier & Klotz, 2022).
* **학생의 정서 상태**: 학습 과정에서 학생들의 정서적 상태가 학습 결과와 어떤 관련이 있는지에 대한 연구도 활발히 진행되어 왔습니다 (Karumbaiah et al., 2022).

## 🛠️ Methodology

* **참가자**: 폴란드 바르샤바 생명과학대학교 컴퓨터 과학과 2학년 학생 132명 (C# 객체 지향 프로그래밍 과정)을 대상으로 했습니다. 이들은 무작위로 대조군 ($N=66$)과 실험군 ($N=66$)으로 배정되었으며, 93명의 학생이 연구 기간 동안 최소 한 번의 코드 제출을 했습니다.
* **플랫폼**: 학생들이 프로그래밍 코드를 제출하고 자동 평가를 받는 'RunCode' 온라인 애플리케이션을 사용했습니다.
* **과제**: 객체 지향 프로그래밍 개념(클래스, 객체, 필드, 메서드, 생성자, 캡슐화, 상속, 다형성)을 다루는 46개의 프로그래밍 과제를 제공했습니다. 총 809개의 단위 테스트가 각 과제의 세부 요건을 평가하도록 설계되었습니다.
* **실험 조건**:
  * **대조군**: 일반적인 플랫폼 피드백(컴파일 오류, 런타임 오류, 단위 테스트 결과)만 받았습니다.
  * **실험군**: 46개 과제 중 38개 과제에 대해 일반 피드백 외에 $GPT-3.5$ $API$를 통해 생성된 추가 힌트를 받았습니다. 나머지 8개 과제(더 어렵고 이전 개념을 통합한 과제)에는 일반 피드백만 제공되었습니다.
* **$GPT$ 힌트 생성**:
  * 학생 코드가 컴파일 오류, 런타임 오류를 일으키거나 최소 하나의 단위 테스트에 실패할 때 $GPT$ 힌트를 요청했습니다.
  * 프롬프트는 과제 텍스트(폴란드어), 학생 코드, 그리고 테스트 결과(컴파일러 메시지, 예외 유형, 실패한 단위 테스트 세부 정보 등)를 포함했습니다.
  * 힌트는 코드 솔루션을 직접 제공하지 않고, 코드 개선 제안, 컴파일러 오류 설명, 디버깅 힌트를 제공하며 폴란드어로 자동 생성되었습니다.
  * $GPT$ $API$의 토큰 제한(4,000 토큰)을 준수하도록 과제가 설계되었습니다.
* **데이터 수집 및 분석**:
  * $GPT$ 힌트의 유용성을 평가하기 위해 실험군 학생들에게 5점 리커트 척도로 힌트 평점을 매기도록 했습니다.
  * 학생들의 정서적 상태('집중', '불안', '지루함', '혼란', '좌절감')는 제출 후 무작위로 (1/3 확률) 설문 조사를 통해 수집했습니다.
  * 초기 지식 수준의 동등성을 확인하기 위해 사전 테스트를 실시했습니다.
  * 데이터 분석에는 비모수적 Mann-Whitney U 테스트, 다중 비교를 위한 Benjamini-Hochberg 알파 보정, 선형 혼합 효과 모델, 순위 기반 회귀 모델이 사용되었습니다.

## 📊 Results

* **사전 테스트**: 대조군 ($Mdn=0$)과 실험군 ($Mdn=1$) 간 사전 테스트 점수에 유의미한 차이가 없었습니다 ($W=1791, p=0.249$).
* **$GPT$ 힌트 유용성**: 실험군에서 수집된 1,442개 응답 중 대다수($46\%$는 중앙값 4 또는 5)가 $GPT$ 힌트를 유용하다고 평가했습니다.
* **일반 플랫폼 피드백 사용량**:
  * $GPT$ 힌트가 활성화된 과제에서는 실험군 ($Mdn=0.321$)이 대조군 ($Mdn=0.710$)보다 일반 피드백 사용량이 유의미하게 적었습니다 ($W=282, p<0.001$).
  * $GPT$ 힌트가 비활성화된 과제에서는 두 그룹 간 일반 피드백 사용량에 유의미한 차이가 없었습니다 ($W=341, p=0.269$).
* **플랫폼 내 성과 ($GPT$ 힌트 활성화 과제)**: 실험군이 대조군보다 연속 제출 시 성공률이 약간 더 높았지만, 시도 횟수에 따른 기울기 차이는 유의미하지 않았습니다 ($t(13)=-0.172, p=0.866$). 그러나 그룹과 시도의 주 효과는 유의미하여 (그룹: $t(13)=5.38, p<0.001$; 시도: $t(13)=-7.38, p<0.001$), 평균적으로 실험군이 대조군보다 더 높은 점수를 얻었음을 나타냅니다.
* **플랫폼 내 성과 ($GPT$ 힌트 비활성화 과제)**: 초기 6번의 시도에서는 대조군이 더 나은 성과를 보였으나, 7번째 시도부터는 두 그룹의 정확도 비율이 비슷해졌습니다. 그룹과 시도 간의 유의미한 상호작용 효과가 있었습니다 ($t(13)=7.13, p<0.001$).
* **과제 완료 시간**:
  * $GPT$ 힌트가 제공된 과제에서는 그룹이 과제 해결 시간에 유의미한 영향을 미치지 않았습니다 ($t(89)=-0.24, p=0.811$).
  * $GPT$ 힌트가 제공되지 않은 과제에서는 실험군이 대조군보다 평균 375초 (6.25분) 더 적은 시간으로 과제를 해결했습니다 ($t(48)=-2.25, p=0.029$).
* **정서적 상태**: '집중', '좌절감', '불안', '혼란', '지루함' 등 모든 정서적 상태에서 두 그룹 간 유의미한 차이가 발견되지 않았습니다 (모든 $p$ 값 $ > 0.05$).

## 🧠 Insights & Discussion

* **$GPT$ 힌트의 효과성**: $GPT-3.5$가 생성한 개인화된 힌트는 학생들에게 전반적으로 유용하다고 평가받았으며, 학생들이 일반 피드백에 덜 의존하고도 더 나은 학습 성과를 달성할 수 있도록 도왔습니다. 이는 $GPT$ 모델이 프로그래밍 교육에서 효과적인 학습 지원 도구가 될 수 있음을 보여줍니다.
* **학습 전이 및 효율성 증대**: $GPT$ 힌트를 통해 개념을 학습한 실험군 학생들은 힌트가 없는 더 어려운 과제에서도 해결 시간을 단축했습니다. 이는 $GPT$ 힌트가 단기적인 문제 해결을 넘어, 학생들의 프로그래밍 개념 이해도를 높여 장기적인 학습 효율성으로 이어질 수 있음을 시사합니다.
* **과도한 의존성과 적응**: $GPT$ 힌트가 비활성화된 과제에서 실험군이 초기에 어려움을 겪은 것은 $GPT$ 피드백에 대한 일시적인 과도한 의존 가능성을 나타냅니다. 그러나 학생들이 빠르게 적응하여 대조군과 동등한 성과를 보인 점은 학습자가 새로운 학습 환경에 유연하게 대처할 수 있음을 보여줍니다.
* **정서적 영향 부재**: $GPT$ 힌트의 유무가 학생들의 스트레스나 집중도 등 정서적 상태에 큰 변화를 주지 않았다는 점은 $GPT$ 기반 시스템이 학생들에게 불필요한 부담을 주지 않으면서 학습을 지원할 수 있음을 의미합니다.
* **제한 사항**: 본 연구는 9주라는 비교적 짧은 기간 동안 진행되었고, 폴란드어 환경 및 단일 프로그래밍 언어($C#$)에 국한되었으며, 참여 학생 수도 제한적이었습니다.
* **향후 연구**: 장기적인 효과, 다양한 언어 및 프로그래밍 언어, 더 많은 참가자를 포함하는 연구가 필요합니다. 또한 프롬프트 엔지니어링 및 $GPT$ 모델의 미세 조정을 통해 힌트의 품질을 더욱 향상시키는 방안을 모색해야 할 것입니다.
* **결론**: 본 연구는 $GPT$ 기반 피드백이 컴퓨터 프로그래밍 교육에서 학생들의 성과를 긍정적으로 향상시키고 전반적인 학습 결과에 기여할 잠재력이 크다는 것을 보여줍니다.

## 📌 TL;DR

이 연구는 $GPT-3.5$ 모델을 활용하여 프로그래밍 과제에 대한 자동화된 개인 맞춤형 피드백(힌트) 시스템을 구축하고 그 효과를 평가했습니다. 학생들은 $GPT$ 힌트를 유용하다고 평가했으며, $GPT$ 힌트를 받은 실험군은 일반 피드백 의존도가 낮았음에도 불구하고 과제 성공률이 향상되었습니다. 또한, 힌트 없이 진행된 후속 과제에서는 실험군이 과제 해결 시간을 단축하여 힌트를 통한 학습 전이 효과를 보였습니다. 초기에는 $GPT$ 힌트 부재 시 과도한 의존 경향이 나타났지만, 학생들은 빠르게 적응했으며 정서적 상태에는 유의미한 영향이 없었습니다. 이는 $GPT$ 기반 피드백이 프로그래밍 교육의 학습 성과를 향상시킬 잠재력이 크다는 것을 시사합니다.
