# Table-GPT: Table-tuned GPT for Diverse Table Tasks

Peng Li, Yeye He, Dror Yashar, Weiwei Cui, Song Ge, Haidong Zhang, Danielle Rifinski Fainman, Dongmei Zhang, Surajit Chaudhuri

## 🧩 Problem to Solve

오늘날의 대규모 언어 모델(LLM), 예를 들어 GPT-3나 ChatGPT는 다양한 자연어 명령을 따르고 광범위한 작업을 수행하는 데 탁월한 능력을 보여줍니다. 하지만 테이블 관련 작업, 특히 기본적인 테이블 이해 작업에 있어서는 최적의 성능을 보여주지 못합니다. 이는 LLM이 주로 일차원적인 자연어 텍스트로 사전 학습된 반면, 관계형 테이블은 이차원적인 객체이기 때문입니다. 구체적으로, 기존 LLM은 다음과 같은 문제점을 보입니다:

* 테이블 내 누락된 셀 식별(`T-1: Missing-value identification`) 및 특정 값에 대한 컬럼명 찾기(`T-2: Column-finding`)와 같은 간단한 작업에서 빈번히 실패합니다 (정확도 26% 수준).
* 테이블의 수직적(상하) 읽기 능력, 즉 동일한 컬럼 내 값들의 관계를 이해하는 능력이 부족합니다. 이는 데이터 보간, 오류 감지, 테이블 QA 등 많은 테이블 작업에 필수적입니다.
* 자연어 텍스트와 달리 행 또는 열의 순서를 바꿔도 의미가 변하지 않는 테이블의 "순열 불변성(permutation-invariance)"에 둔감하여, 컬럼 순서 변경에 따라 예측이 달라지는 불안정한 동작을 보입니다.

## ✨ Key Contributions

이 연구는 테이블 이해 및 관련 작업 수행 능력을 향상시키기 위한 새로운 "테이블 튜닝(table-tuning)" 패러다임을 제안합니다. 주요 기여는 다음과 같습니다:

* **테이블 튜닝 패러다임 제안:** GPT-3.5 및 ChatGPT와 같은 기존 LLM을 다양한 실제 테이블에서 합성된 테이블 작업 데이터로 지속적으로 훈련/미세 조정하는 "테이블 튜닝" 접근 방식을 제안합니다.
* **향상된 테이블 이해 능력:** 결과적으로 개발된 Table-GPT 모델은 기존 GPT-3.5 및 ChatGPT보다 더 뛰어난 테이블 이해 능력을 보여주며, 광범위한 테이블 작업(새롭고 학습되지 않은 작업 포함)에서 일관되게 우수한 성능을 달성합니다.
* **강력한 일반화 능력:** Table-GPT는 GPT-3.5 및 ChatGPT와 유사하게 새롭고 보지 못한 테이블 작업에 대한 다양한 인간 명령에 잘 반응하는 강력한 일반화 능력을 입증합니다.
* **데이터 증강 기법 개발:** 과적합 방지 및 Table-GPT의 일반성을 보장하기 위해 작업 수준, 테이블 수준, 명령어 수준 및 완료 수준의 데이터 증강 기법을 개발합니다.
* **테이블 파운데이션 모델로서의 역할:** Table-GPT는 제로샷 및 퓨샷 환경에서 뛰어날 뿐만 아니라, 하위 단일 작업 최적화(예: 작업별 미세 조정 및 프롬프트 엔지니어링)를 위한 바닐라 GPT보다 더 나은 시작점, 즉 "테이블 파운데이션 모델" 역할을 할 수 있음을 보여줍니다.

## 📎 Related Works

* **프롬프트 엔지니어링 (Prompt Engineering):** [20, 29, 39, 43] 등의 선구적인 연구들은 특정 작업에 대한 최적의 명령어와 퓨샷 예제를 신중하게 선택하는 "프롬프트 엔지니어링"을 통해 LLM이 테이블 작업에서 좋은 성능을 보이도록 유도했습니다. 본 연구는 프롬프트를 수정하는 대신 모델의 가중치를 수정하는 직교적인 접근 방식인 "테이블 튜닝"을 제안합니다.
* **자연어 처리(NLP) 분야의 명령어 튜닝 (Instruction-tuning):** [40, 47, 57-59] 등에서 개발된 "명령어 튜닝" 기술은 GPT-3와 같은 모델을 ChatGPT와 같이 고수준의 인간 명령을 따를 수 있도록 훈련하는 데 성공했습니다. 본 연구의 "테이블 튜닝"은 이러한 명령어 튜닝에 영감을 받았습니다.
* **테이블 작업을 위한 인코더-스타일 LLM:** TURL [16], TaBERT [64], Ditto [32], Doduo [48] 등은 인코더-스타일 BERT 유사 모델을 기반으로 훈련되어 다양한 테이블 작업에서 좋은 성능을 보입니다. 하지만 새로운 데이터셋이나 작업에 일반화하기 위해선 작업별 레이블된 데이터로 미세 조정이 필요합니다.
* **테이블 작업을 위한 디코더-스타일 LLM:** GPT-3 및 ChatGPT와 같은 디코더 전용 모델의 성공과 함께, 데이터베이스 분야에서는 이러한 모델을 테이블 관련 작업에 활용하기 위한 프롬프트 엔지니어링 기법 [29, 39, 43]이 개발되었습니다.

## 🛠️ Methodology

본 연구는 테이블 이해 능력을 향상시키기 위해 "명령어 튜닝"에서 영감을 받은 "테이블 튜닝" 패러다임을 제안하며, 이는 `(instruction, table, completion)`($I_{ns}$, $T$, $C$) 형태의 다양한 훈련 데이터를 활용합니다. 전체 접근 방식은 "합성-후-증강(Synthesis-then-Augment)"으로 요약할 수 있습니다.

1. **다양한 테이블 작업 합성 (Synthesize Diverse Table-Tasks):**
    * 대규모 실제 테이블($C_{wt}$: 웹 테이블, $C_{db}$: 데이터베이스 테이블) 코퍼스에서 테이블 $T$와 테이블 작업 유형 $S$를 샘플링하여 테이블 작업 인스턴스 $(I_{ns}, T, C)$를 합성합니다.
    * **작업 다양성을 위한 새로운 테이블 작업 합성:**
        * `T-13: Table summarization (TS)`: 테이블 내용을 요약하는 제목을 생성합니다.
        * `T-14: Column augmentation (CA)`: 주어진 컬럼에 이어 새로운 컬럼을 생성합니다.
        * `T-15: Row augmentation (RA)`: 주어진 행에 이어 새로운 행을 생성합니다.
        * `T-16: Row/column swapping (RS/CS)`: 테이블의 행 또는 열을 교환합니다.
        * `T-17: Row/column filtering (RCF)`: 특정 행 또는 열을 기준으로 테이블을 필터링합니다.
        * `T-18: Row/column sorting (RCS)`: 특정 행 또는 열을 기준으로 테이블을 정렬합니다.
        * `T-11: Head-value matching (HVM)`: 헤더가 없는 테이블에 올바른 컬럼 헤더를 채웁니다.
    * **데이터 다양성을 위한 기존 테이블 작업의 새로운 테스트 케이스 합성:**
        * `T-5: Row-to-row Data Transformation (R2R)`: 행 간 변환 패턴을 유추하여 누락된 값을 채웁니다.
        * `T-7: Schema Matching (SM)`: 두 테이블 간의 일치하는 컬럼을 찾습니다.
        * `T-8: Data Imputation (DI)`: 테이블 컨텍스트를 기반으로 누락된 값을 예측합니다.
        * `T-9: Error Detection (ED)`: 테이블 내에서 오타 등의 오류를 감지합니다.
        * `T-10: List extraction (LE)`: 명시적인 컬럼 구분자가 없는 목록 데이터에서 테이블을 추출합니다.

2. **합성된 테이블 작업 증강 (Augment Synthesized Table-Tasks):**
    합성된 테이블 작업 인스턴스 $(I_{ns}, T, C)$를 여러 수준에서 추가로 증강하여 작업/데이터 다양성을 높이고 과적합을 방지합니다.
    * **명령어 수준 증강 (Instruction-level augmentations):** GPT와 같은 생성 모델을 사용하여 표준 인간 작성 명령어를 다양한 변형으로 의역하여 과적합을 방지합니다.
    * **테이블 수준 증강 (Table-level augmentations):** 컬럼 순열, 행 순열, 컬럼 샘플링, 행 샘플링과 같은 의미 보존 작업을 수행하여 테이블 다양성을 높이고 모델이 "의미 보존 테이블 작업"에 덜 민감하게 만듭니다.
    * **완료 수준 증강 (Completion-level augmentations):** 원래 완료 $C$에 추론 단계(Chain-of-Thought와 유사)를 추가하여 모델이 복잡한 테이블 작업에서 단계별 추론을 수행하도록 유도합니다.
        * LLM 지원 완료 증강: GPT가 복잡한 작업(예: 개체 매칭)에 대한 추론 단계를 생성하도록 합니다.
        * 정답(ground-truth) 지원 완료 증강: 정답을 사용하여 추론 단계를 포함하는 증강된 완료를 생성하여 모델 예측의 신뢰성을 높이고 오탐(false-positives)을 줄입니다 (예: 오류 감지에서 올바른 철자를 제공).

3. **모델 훈련:**
    합성 및 증강된 `(instruction, table, completion)` 쌍을 사용하여 GPT 및 ChatGPT와 같은 디코더-스타일 언어 모델을 계속 훈련합니다. 이때, 직렬화된 `($I_{ns}$, $T$)`를 "프롬프트"로 사용하고 $C$를 "완료"로 사용하여 프롬프트가 주어졌을 때 완료의 언어 모델링 손실을 최소화합니다.

## 📊 Results

광범위한 실험을 통해 Table-GPT가 다양한 테이블 작업에서 강력한 성능 향상을 입증했습니다.

* **전반적인 성능 향상:**
  * Table-GPT 모델은 바닐라 GPT-3.5 및 ChatGPT를 모든 설정(제로샷, 퓨샷)에서 일관되게 능가했습니다.
  * 총 104개 테스트 중 98개에서 Table-tuned 모델이 바닐라 모델보다 우수했습니다 (3개는 동점, 3개는 Table-tuned 모델이 성능이 낮은 경우).
  * 특히, Table-tuning의 이점은 GPT-3.5와 ChatGPT 모두에서 관찰되어 제안된 접근 방식의 일반성을 보여줍니다.

* **일반화 능력 입증:**
  * 테이블 튜닝 중 완전히 보지 못한 4가지 unseen task (T-1, T-2, T-3, T-4)에서도 강력한 성능을 보여주어, 새로운 작업과 데이터셋에 대한 일반화 능력을 입증했습니다.

* **테이블 파운데이션 모델로서의 이점:**
  * **단일 작업 프롬프트 엔지니어링:** Column-type-annotation(CTA) 작업에서 프롬프트 엔지니어링을 수행했을 때, Table-GPT-3.5가 GPT-3.5보다 일관되게 뛰어난 성능을 보였습니다.
  * **단일 작업 미세 조정:** CTA 및 Table Question-Answering(TQA) 작업에서 동일한 양의 학습 데이터를 사용하여 미세 조정했을 때, Table-GPT-3.5가 GPT-3.5를 지속적으로 능가했습니다. 이는 Table-GPT-3.5가 동일한 성능을 달성하기 위해 더 적은 양의 레이블된 데이터를 필요로 함을 의미합니다.

* **민감도 분석 (Sensitivity Analysis):**
  * **학습 작업 수:** 더 많은 학습 작업을 사용할수록 성능이 일관되게 향상되었습니다. (단일 작업 튜닝은 다른 작업의 성능을 해칠 수 있음).
  * **학습 데이터 양:** 학습 데이터 양이 많아질수록 성능이 향상되며, 일정 수준 이상에서는 포화 상태에 도달했습니다.
  * **기반 모델 크기:** Table-tuning의 이점은 Ada(350M) 또는 Babbage(3B)와 같은 작은 모델에서는 미미했지만, GPT-3.5(175B)와 ChatGPT와 같은 대규모 모델에서는 크게 나타났습니다. 이는 대규모 모델에서 나타나는 새로운 능력과 일치합니다.
  * **프롬프트 템플릿:** Table-GPT는 다양한 프롬프트 템플릿에 대해 견고한 성능을 보였으며, 모든 템플릿에서 GPT-3.5를 10%p 이상 지속적으로 능가했습니다.
  * **테이블 형식:** Markdown 형식이 다른 형식(CSV, JSON)보다 평균적으로 약간 더 나은 성능을 보였습니다.

* **제거 연구 (Ablation Studies):**
  * **합성된 작업 제거 (NoSyn):** 학습 데이터에서 합성된 작업을 제거하자 성능이 크게 하락하여, 합성된 다양한 테이블 작업의 중요성을 보여주었습니다.
  * **컬럼 순열 제거 (NoColPer):** 테이블 수준 증강(컬럼 순열)을 제거하자 성능이 저하되었습니다.
  * **명령어 변형 제거 (NoPromptVar):** 명령어 수준 증강(프롬프트 의역)을 제거하자 성능이 약간 하락했습니다.
  * **Chain-of-Thought 제거 (NoCOT):** 완료 수준 증강(Chain-of-Thought)을 제거하자 학습된 작업의 성능이 낮아졌습니다.

## 🧠 Insights & Discussion

본 연구는 "테이블 튜닝"이라는 새로운 패러다임을 통해 대규모 언어 모델이 테이블을 더 잘 이해하고 다양한 테이블 작업을 수행할 수 있음을 성공적으로 입증했습니다. 주요 시사점은 다음과 같습니다.

* **테이블 이해 능력의 근본적 개선:** 기존 LLM이 1차원 텍스트 중심의 사전 학습으로 인해 테이블 이해에 한계를 가졌던 문제를, 2차원 테이블 구조를 명시적으로 학습시키는 테이블 튜닝을 통해 효과적으로 극복했습니다. 이는 LLM이 단순히 텍스트를 처리하는 것을 넘어 데이터의 구조적 특성을 학습할 수 있음을 보여줍니다.
* **"테이블 파운데이션 모델"로서의 가능성:** Table-GPT는 제로샷 및 퓨샷 상황에서 뛰어난 성능을 보일 뿐만 아니라, 프롬프트 엔지니어링이나 작업별 미세 조정과 같은 다운스트림 최적화 작업에서도 기존 LLM보다 더 좋은 시작점(foundation model) 역할을 할 수 있습니다. 이는 테이블 관련 애플리케이션 개발에 있어 효율성과 성능 향상의 기반이 될 수 있습니다.
* **대규모 모델의 시너지 효과:** 테이블 튜닝의 효과가 소규모 모델에서는 미미했지만, 대규모 모델에서 급격히 증가하는 현상은 LLM의 스케일업과 새로운 능력의 발현이 테이블 도메인에서도 유효함을 시사합니다.
* **데이터 증강의 중요성:** "합성-후-증강" 접근 방식과 다양한 수준의 데이터 증강 기법(명령어, 테이블, 완료 수준)은 Table-GPT의 일반화 능력과 견고성을 확보하는 데 결정적인 역할을 했습니다. 특히, 추론 단계를 포함한 완료 증강(Chain-of-Thought)은 복잡한 작업에서 모델의 정확도와 설명 가능성을 높이는 데 기여했습니다.

**한계 및 향후 연구:**

* 제안된 합성 테이블 작업 목록은 포괄적이지 않으며, 더 많은 창의적인 합성 작업이 테이블 튜닝 프로세스를 더욱 개선할 수 있습니다. NLP 커뮤니티가 명령어 튜닝을 위해 1,000개 이상의 작업을 축적한 것처럼, 테이블 도메인에서도 유사한 커뮤니티 노력이 필요합니다.
* 다양한 테이블 형식(CSV, JSON 등)에 대한 성능이 Markdown만큼 높지는 않았으므로, 다양한 형식에 대한 더 깊은 이해를 위한 연구가 필요합니다.
* 모델의 추론 과정에 대한 보다 심층적인 분석을 통해, Table-GPT가 실제로 테이블의 2차원적 구조와 순열 불변성을 어떻게 학습하고 활용하는지 탐구하는 것도 흥미로운 방향입니다.

## 📌 TL;DR

기존 대규모 언어 모델(LLM)은 텍스트 중심의 사전 학습으로 인해 2차원 테이블 이해 및 작업에 취약했습니다. 본 연구는 다양한 합성 테이블 작업 데이터와 다단계 증강 기법을 활용하여 LLM을 지속적으로 훈련하는 새로운 "테이블 튜닝" 패러다임을 제안합니다. 그 결과인 Table-GPT는 바닐라 GPT 및 ChatGPT를 능가하는 탁월한 테이블 이해 능력과 높은 일반화 성능을 보여주며, 하위 작업 최적화를 위한 강력한 "테이블 파운데이션 모델"로서의 가능성을 제시합니다.
