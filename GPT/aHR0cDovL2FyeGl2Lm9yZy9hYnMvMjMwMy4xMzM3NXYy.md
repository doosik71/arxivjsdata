# Capabilities of GPT-4 on Medical Challenge Problems

Harsha Nori, Nicholas King, Scott Mayer McKinney, Dean Carignan, and Eric Horvitz

## 🧩 Problem to Solve

이 논문은 전문적인 의료 지식으로 훈련되거나 특정 임상 작업을 위해 설계되지 않은 일반 목적 대규모 언어 모델(LLM)인 GPT-4가 의료 역량 시험 및 벤치마크 데이터셋에서 어떤 성능을 보이는지 종합적으로 평가하는 것을 목표로 합니다. 특히, 최첨단 LLM이 복잡한 의료 추론 문제들을 '추가적인 전문화 없이' 얼마나 잘 해결할 수 있는지 탐구합니다.

## ✨ Key Contributions

* **USMLE 합격 점수 초과 및 SOTA 달성:** GPT-4는 미국 의사 면허 시험(USMLE)에서 합격 점수를 20점 이상 초과 달성했으며, 이전 모델인 GPT-3.5 및 의료 지식으로 미세 조정된 Med-PaLM, Flan-PaLM 540B를 능가하는 성능을 보였습니다.
* **향상된 확률 보정(Calibration):** GPT-3.5에 비해 GPT-4는 답변의 정확성 확률을 훨씬 더 잘 예측하는 등 보정 능력이 크게 향상되었습니다. 이는 의료와 같은 고위험 애플리케이션에서 매우 중요합니다.
* **텍스트-전용 모델의 시각 정보 처리 능력:** 텍스트-전용 GPT-4 모델임에도 불구하고, 이미지나 그래프를 참조하는 시험 문제에서도 논리적 추론과 시험 전략을 활용하여 70-80%의 정확도를 달성했습니다.
* **의료 추론 및 교육 지원 가능성:** GPT-4가 의료 추론 과정을 설명하고, 학생들에게 맞춤형 설명을 제공하며, 가상 시나리오를 대화식으로 구성하는 능력에 대한 질적 사례 연구를 제시했습니다.

## 📎 Related Works

* **Transformer 기반 LLM:** [VSP$^{+}$17], [RNS$^{+}$18], [DCLT18] 등 트랜스포머 아키텍처와 자가 지도 학습을 기반으로 하는 LLM의 발전.
* **LLM 규모와 성능 관계:** 모델 및 데이터셋 크기, 훈련 계산량 증가에 따른 벤치마크 점수 개선 ([KMH$^{+}$20], [LBL$^{+}$22]).
* **미세 조정 및 행동 조작:** 특정 도메인에 대한 미세 조정(fine-tuning)과 사람 피드백을 통한 강화 학습(RLHF) ([CLB$^{+}$17], [BJN$^{+}$22])을 통한 모델 행동 조작 연구.
* **의료 분야 AI 연구 역사:** Ledley와 Lusted의 고전 연구 [LL59]부터 확률적 및 의사결정 이론적 방법 ([GB68], [HHN92]), 규칙 기반 시스템 ([Sho77], [BS84]), 의미 그래프 ([PSS81]), 의료 정보 데이터베이스를 통한 지도 학습 ([WGH16], [HHPS15], [ELS$^{+}$20], [CLG$^{+}$15]), 딥 신경망 모델 ([EKN$^{+}$17], [SHJ$^{+}$17], [RIZ$^{+}$17], [MSG$^{+}$20])까지 다양한 컴퓨팅 방법론 탐색.
* **기존 의료 LLM 벤치마크:** MultiMedQA [SAT$^{+}$22] 및 ChatGPT [KCM$^{+}$23], InstructGPT, Flan-PaLM 540B, Med-PaLM 등 다른 LLM의 성능 비교.

## 🛠️ Methodology

1. **모델:** OpenAI의 텍스트-전용 GPT-4 (비전 기능 없음) 및 GPT-3.5를 주로 평가하며, Flan-PaLM 540B 및 Med-PaLM의 발표된 결과와 비교합니다.
2. **데이터셋:**
    * **공식 USMLE 자료:** 미국 의사 면허 시험(USMLE)의 Step 1, 2, 3에 대한 NBME(National Board of Medical Examiners) 공식 연습 자료인 USMLE Self Assessment와 USMLE Sample Exam.
    * **공개 벤치마크:** MultiMedQA 스위트의 구성 요소인 MedQA, PubMedQA, MedMCQA, MMLU의 의료 관련 부분.
3. **프롬프트 방식:**
    * 최대한 단순한 "out-of-the-box" 성능을 측정하기 위해 제로-샷(zero-shot) 및 5-샷(5-shot) 프롬프트 템플릿을 사용했습니다.
    * 복잡한 연쇄 사고(chain-of-thought) 프롬프트 [WWS$^{+}$22b], 검색 증강 생성 [NHB$^{+}$21], 앙상블 전략 [WWS$^{+}$22a] 등은 사용하지 않았습니다.
    * OpenAI API의 `logit_bias` 파라미터를 사용하여 모델이 유효한 답변만 생성하도록 유도했습니다.
4. **추가 평가:**
    * 텍스트-전용 모델이 시각적 요소(이미지, 그래프)를 포함하는 질문에서 어떻게 작동하는지 분석했습니다.
    * 답변 확률의 보정(calibration)을 평가하여 모델의 신뢰도를 측정했습니다.
    * 훈련 데이터에 시험 내용이 포함되어 모델이 암기했을 가능성(memorization)을 Levenshtein 거리 기반의 MELD(Memorization effects Levenshtein Detector) 알고리즘으로 조사했습니다.

## 📊 Results

* **USMLE 성능:**
  * GPT-4는 USMLE Self Assessment에서 86.65%, USMLE Sample Exam에서 86.7%의 평균 점수를 기록하여 합격 기준(약 60%)을 크게 초과했습니다.
  * GPT-3.5의 점수(Self Assessment 53.61%, Sample Exam 58.78%)보다 30% 이상 높은 놀라운 개선을 보였습니다.
* **시각적 요소 질문 처리:**
  * 텍스트-전용 GPT-4는 시각적 참조가 있는 질문에서도 70-80%의 높은 정확도를 유지했습니다. 모델이 이미지를 볼 수 없음에도 불구하고 논리적 추론을 통해 답변을 도출할 수 있음을 입증했습니다.
* **정렬(Alignment) 및 안전 튜닝 영향:**
  * 안전 및 지시 준수(safety and instruction-following)를 위한 RLHF 미세 조정이 적용되지 않은 GPT-4-base 모델은 공개 버전 GPT-4보다 3-5% 높은 원시 성능을 보였습니다. 이는 안전성과 정확성 간의 균형점을 시사합니다.
* **MultiMedQA 벤치마크:**
  * GPT-4는 MedQA, MedMCQA, MMLU의 의료 관련 하위 구성 요소에서 GPT-3.5와 Flan-PaLM 540B를 모두 능가했습니다.
  * 다만, PubMedQA 데이터셋에서는 Flan-PaLM 540B가 GPT-4보다 약간 높은 성능을 보였습니다.
* **보정(Calibration):**
  * GPT-4는 GPT-3.5에 비해 현저히 우수한 보정 능력을 보였습니다. 예를 들어, GPT-4가 0.96의 평균 확률을 할당한 데이터 포인트는 93%의 정확도를 보인 반면, GPT-3.5는 55%에 불과했습니다.

## 🧠 Insights & Discussion

* **의료 교육 및 임상 적용 잠재력:** GPT-4는 의료 지식 평가를 넘어, 의료 추론 설명, 학생 맞춤형 교육, 가상 시나리오 생성 등의 질적 능력을 보여 의료 교육 및 임상 의사 결정 지원에 큰 잠재력을 가집니다. 특히 USMLE Step 3에서의 역량은 의료진의 임상 추론 및 일상 업무에 기여할 수 있음을 시사합니다.
* **정확성과 안전성 과제:** LLM의 생성물은 환자 진료에 심각한 결과를 초래할 수 있는 부정확하거나 불완전한 정보, 즉 '환각(hallucinations)'을 포함할 수 있으므로 극도의 주의가 필요합니다. 신뢰성 평가와 전문가 검토의 필요성이 강조됩니다.
* **편향(Bias) 위험:** LLM 훈련 데이터에 내재된 편향이 의료 권고 사항에 반영되어 건강 불균형을 심화할 위험이 있습니다. 인종, 사회경제적 배경, 성별 등 다양한 요인에 대한 편향 연구와 완화 노력이 필요합니다.
* **전문 직업에 미치는 영향:** LLM의 성능 향상은 의학 외에도 법률, 금융, 공학 등 지식 집약적인 전문 직업의 역할과 가치에 근본적인 변화를 가져올 수 있습니다. 이는 사회적 합의 및 경력 선택에도 영향을 미칠 수 있습니다.
* **현재의 한계:** 이 연구는 주로 객관식 문제에 초점을 맞추었으며, USMLE Step 3의 컴퓨터 기반 사례 시뮬레이션(CCS)과 같은 동적이고 상호작용적인 과제에 대한 정량적 평가는 부족합니다. 또한, '체인-오브-스루트' 같은 고급 프롬프트 기법이 GPT-4에 미치는 영향은 추가 연구가 필요합니다.

## 📌 TL;DR

이 논문은 일반 목적 LLM인 GPT-4가 의료 전문성을 평가하는 USMLE 시험에서 합격 점수를 크게 넘어서고, 기존 모델들을 능가하는 성능을 보임을 입증합니다. GPT-4는 텍스트-전용 모델임에도 시각적 요소를 포함하는 질문에도 잘 답변하며, GPT-3.5보다 훨씬 정확한 답변 확률 보정 능력을 가집니다. 또한, 의료 추론 설명 및 대화형 시나리오 구성 등 질적 역량도 뛰어납니다. 이러한 결과는 GPT-4가 의료 교육 및 임상 실습에 혁신적인 영향을 미칠 잠재력을 시사하지만, 오류 및 편향 위험을 완화하기 위한 신중한 접근과 추가 연구가 필수적임을 강조합니다.
