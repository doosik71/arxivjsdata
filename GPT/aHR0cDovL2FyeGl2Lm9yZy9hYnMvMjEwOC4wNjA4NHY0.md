# The Stability-Efficiency Dilemma: Investigating Sequence Length Warmup for Training GPT Models

Conglong Li, Minjia Zhang, Yuxiong He

## 🧩 Problem to Solve

최근 대규모 GPT 모델의 사전 학습은 방대한 GPU를 활용하여 큰 성공을 거두었으나, 훈련 시간을 단축하기 위해 배치 크기(batch size)와 학습률(learning rate)을 높이는 일반적인 방법은 '안정성-효율성 딜레마'를 야기합니다. 즉, 배치 크기와 학습률을 높이면 훈련 효율성은 향상되지만, 훈련 불안정성(training instability)이 발생하여 모델의 일반화 정확도가 저하되거나 훈련이 실패할 수 있습니다. 본 연구는 이러한 현상을 깊이 있게 분석하고, 특히 훈련 초기에 긴 시퀀스 길이의 샘플이 극단적인 기울기 분산(gradient variance) 값의 주요 원인이 되어 훈련 불안정성을 초래함을 밝혀냅니다.

## ✨ Key Contributions

* GPT-2 사전 학습 작업에 대한 광범위한 연구를 통해 훈련 안정성-효율성 딜레마, 불안정성과 기울기 분산 이상치(outliers) 간의 상관관계, 시퀀스 길이의 중요성에 대한 상세한 통찰을 제공했습니다.
* 분석을 기반으로 GPT-스타일 모델(일반적으로 자기회귀 모델)을 위한 간단하면서도 효과적인 시퀀스 길이 웜업(Sequence Length Warmup, SLW) 메서드를 제안하여, 훈련 효율성을 높이면서도 안정적인 훈련을 가능하게 했습니다. 또한, 값비싼 전체 훈련의 일부만을 사용하여 유망한 하이퍼파라미터를 식별하는 경량 튜닝 전략을 제시했습니다.
* 대규모 실험(GPT-2 117M 및 1.5B, GPT-3 125M 및 1.3B)을 수행하여 제안된 방법이 뛰어난 훈련 안정성과 효율성을 동시에 제공함을 입증했습니다. 이 방법은 DeepSpeed 딥러닝 최적화 라이브러리에 오픈 소스로 공개되었습니다.

## 📎 Related Works

* **언어 모델 사전 학습:** GPT-3와 같은 대규모 트랜스포머 기반 언어 모델의 성공과 이로 인한 기하급수적인 훈련 비용 및 훈련 난이도 문제를 다룹니다. 통신 병목 현상을 완화하기 위해 대규모 배치 훈련(예: LAMB, 1-bit Adam)이 사용되지만, 이는 종종 수렴 지연, 훈련 불안정성, 모델 발산 등의 문제를 초래합니다.
* **커리큘럼 학습 (Curriculum Learning, CL):** 쉬운/간단한 예제를 먼저 제시하고 점차 난이도를 높이는 학습 패러다임 [2, 12, 39]. 기존 CL 연구는 주로 수렴 속도 개선에 초점을 맞추었으나, 본 연구는 안정성-효율성 딜레마를 해결하고 더 공격적인 하이퍼파라미터 설정에서도 안정적인 훈련을 가능하게 하여 이중적인 이점을 제공함을 보여줍니다.
* **Shortformer [30]:** 짧은 시퀀스 길이로 첫 번째 훈련 단계를 추가하여 언어 모델의 훈련 효율성을 개선하는 방법을 제안합니다. 그러나 본 연구는 Shortformer의 2단계 접근 방식이 대규모 모델의 훈련 불안정성 문제를 완전히 해결하지 못하며, 주로 소규모 모델에 평가되었다는 한계를 지적합니다.
* **Batch Size Warmup [6]:** GPT-3 훈련에서 사용된 배치 크기 웜업 기법으로, 훈련 초기에 작은 배치 크기로 시작하여 점진적으로 증가시킵니다. 본 연구의 평가에서는 배치 크기 웜업이 훈련 불안정성을 완화하는 데 효과적이지 않음을 발견했습니다.

## 🛠️ Methodology

1. **안정성-효율성 딜레마 분석:**
    * GPT-2 (117M 및 1.5B) 모델을 사용하여 대규모 사전 훈련 실험을 수행했습니다.
    * 훈련 불안정성(손실값 급증)과 Adam 옵티마이저의 분산 상태($\sqrt{v_t}$)의 $L_1$ 노름 및 최대 요소(max element) 이상치 간에 강한 양의 상관관계가 있음을 발견했습니다.
    * 특히, 훈련 초기 단계에서 긴 시퀀스 길이가 불안정성의 주요 원인임을 식별했습니다.

2. **시퀀스 길이 웜업 (Sequence Length Warmup, SLW) 방법론 제안:**
    * **개념:** 모델이 짧은 시퀀스 길이로 훈련을 시작하여 안정성을 확보한 후, 훈련이 안정화되면 점진적으로 시퀀스 길이를 늘려 긴 컨텍스트 정보를 학습하도록 합니다.
    * **가변 시퀀스 길이 구현:** 데이터로더는 전체 시퀀스 길이로 텍스트를 인덱싱하고, 각 훈련 단계에서 페이싱 함수에 따라 현재 시퀀스 길이를 결정한 후 전체 길이 시퀀스를 해당 길이로 잘라(truncation-based) 미니 배치로 사용합니다. 이 방식은 데이터 로딩 오버헤드를 최소화합니다.
    * **페이싱 함수(Pacing Function):** 단계별 선형 함수를 사용합니다. 시작 시퀀스 길이 $seqlen_s$, 종료 시퀀스 길이 $seqlen_e$, 총 웜업 기간 $T$ (단계 수)가 주어지면, $t$ 단계에서 사용되는 시퀀스 길이는 다음과 같이 결정됩니다:
        $$seqlen_t = seqlen_s + (seqlen_e - seqlen_s) \times \min\left(\frac{t}{T}, 1\right)$$
        다른 페이싱 함수(2단계 이산, 단계별 제곱근, 적응형)도 탐색했으나 선형 함수가 가장 효과적이거나 유사한 성능을 보였습니다.

3. **경량 튜닝 전략:**
    * 시작 시퀀스 길이 $seqlen_s$는 일반적으로 가능한 작게 (예: 8) 설정하여 안정성 및 수렴 속도 이점을 극대화합니다. 초기 유효성 검사 퍼플렉시티가 크게 변동하면 $seqlen_s$를 늘립니다.
    * 웜업 기간 $T$는 학습률 웜업 단계의 몇 배로 시작하여, 훈련 초기 (예: 첫 10K 단계) 동안 유효성 검사 퍼플렉시티에 큰 변동(이전 최저 퍼플렉시티의 1.3배 이상)이 없는 가장 긴 $T$를 이진 탐색으로 찾습니다. 이 전략은 전체 훈련을 완료할 필요 없이 하이퍼파라미터 튜닝 비용을 크게 절감합니다.

## 📊 Results

* **GPT-2 (117M 및 1.5B) 실험:**
  * SLW는 8배 큰 배치 크기와 4배 큰 학습률에서도 안정적인 훈련을 가능하게 했으며, 기존 방법은 동일 설정에서 심각한 불안정성을 겪었습니다.
  * 동일하거나 더 나은 zero-shot 평가 결과를 얻기 위해, SLW는 필요한 훈련 토큰 수를 최대 2.2배, 벽시계 시간(wall clock time)을 최대 3.7배 단축했습니다.
  * Shortformer 및 Batch Size Warmup과 비교하여, SLW는 더 빠른 수렴 속도를 제공하고 훈련 불안정성 문제를 효과적으로 해결했습니다. 특히 Shortformer는 시퀀스 길이 전환 시 불안정성을 보였습니다.
  * SLW는 Adam의 분산 노름 및 최대 요소 급증을 방지하여 훈련 안정성에 기여함을 입증했습니다.

* **GPT-3 (125M) 실험 (제한된 데이터 시나리오):**
  * 오리지널 GPT-3 훈련 레시피보다 8배 큰 배치 크기와 40배 큰 학습률을 사용하여 훈련 시, SLW는 안정성을 유지하며 11개 태스크에서 zero-shot 정확도의 99%를 유지했습니다.
  * 기존 GPT-3 훈련 대비 10배 적은 데이터와 17배 적은 시간을 사용했습니다.
  * 동일 설정에서 기존 방법은 발산(divergence)하거나, 학습률을 30배로 낮춰야 95%의 정확도만 유지할 수 있었습니다.

* **GPT-3 (1.3B) 추가 실험:**
  * 동일한 300B 훈련 토큰 하에서, SLW는 baseline보다 zero-shot (41.6% $\to$ 41.9%) 및 few-shot (44.8% $\to$ 45.3%) 평가에서 더 나은 평균 정확도를 제공했습니다. 이는 SLW가 안정성 및 효율성 이점 외에도 모델의 최종 정확도를 향상시킬 수 있음을 시사합니다.

## 🧠 Insights & Discussion

* **안정성-효율성 딜레마 해결:** 본 연구는 대규모 언어 모델 사전 학습에서 효율성 향상(큰 배치, 높은 학습률)과 훈련 안정성 유지 사이의 근본적인 딜레마를 SLW라는 간단하지만 효과적인 방법으로 해결할 수 있음을 입증했습니다.
* **기울기 분산 제어:** 훈련 불안정성과 기울기 분산 이상치 사이의 강한 상관관계를 발견했으며, SLW가 이러한 분산 이상치를 효과적으로 억제하여 훈련을 안정화함을 보여주었습니다. 이는 대규모 모델 훈련의 주요 불안정성 요인을 직접적으로 해결합니다.
* **데이터 효율성 개선:** SLW는 단순히 훈련 효율성을 높이는 것을 넘어, GPT-3 125M 실험에서 10배 적은 데이터와 17배 적은 시간으로도 높은 성능을 유지하여, 데이터 효율성을 통한 새로운 차원의 훈련 비용 절감 가능성을 제시했습니다.
* **한계 및 미래 연구:** 긴 시퀀스 길이가 훈련 불안정성을 유발하는 근본적인 원인에 대한 깊이 있는 이론적 설명은 아직 부족합니다. 기울기 분산과의 상관관계가 인과관계를 완전히 증명하는 것은 아니며, 훈련 불안정성이 다른 요인에 의해 발생할 수도 있습니다. 본 연구는 대규모 모델 훈련의 불안정성 연구에 대한 초기 시도로, 향후 이론 및 실제 분야에서 이 중요한 문제에 대한 추가 연구를 장려합니다.

## 📌 TL;DR

대규모 GPT 모델 사전 학습 시 효율성을 높이기 위한 큰 배치 크기와 학습률이 훈련 불안정성을 야기하는 '안정성-효율성 딜레마'를 해결하고자, 본 연구는 **시퀀스 길이 웜업(Sequence Length Warmup, SLW)** 방법을 제안합니다. SLW는 훈련 초기에 짧은 시퀀스 길이로 시작하여 점진적으로 길이를 늘림으로써, 훈련 불안정성의 주요 원인인 극단적인 기울기 분산 이상치 발생을 효과적으로 방지합니다. 실험 결과, SLW는 GPT-2 및 GPT-3 모델에서 기존 대비 8배 큰 배치 크기와 최대 40배 큰 학습률에서도 안정적인 훈련을 가능하게 했으며, 동일하거나 더 나은 성능을 달성하면서도 훈련 시간(최대 17배)과 데이터 사용량(최대 10배)을 획기적으로 줄였습니다. 이는 대규모 언어 모델의 효율적이고 안정적인 사전 훈련을 위한 실용적인 솔루션임을 입증합니다.
