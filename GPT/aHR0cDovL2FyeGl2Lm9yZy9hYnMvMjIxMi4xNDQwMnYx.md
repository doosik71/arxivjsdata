# GPT Takes the Bar Exam

Michael Bommarito II, Daniel Martin Katz

## 🧩 Problem to Solve

본 연구는 법률 전문가 자격 시험인 "변호사 시험(Bar Exam)" 중 다지선다형(Multistate Multiple Choice, MBE) 섹션에서 최신 대규모 언어 모델(LLM)인 OpenAI의 `text-davinci-003`(GPT-3.5)의 성능을 평가하는 것을 목표로 합니다. 법률 시스템은 고도로 복잡하고, 법률 언어는 전문적인 지식과 미묘한 의미 차이를 요구하여 기존 NLP 모델이 어려움을 겪는 영역입니다. 이러한 복잡한 법률 과제에 대해 최신 AI 모델이 얼마나 깊이 있는 지식을 보여줄 수 있는지, 특히 제로샷(zero-shot) 환경에서 성공할 수 있을지에 대한 의문이 제기됩니다.

## ✨ Key Contributions

* GPT-3.5가 MBE 시험에서 무작위 추측(25%)을 크게 상회하는 50.3%의 정답률을 기록하며 높은 성능을 보였습니다.
* GPT-3.5는 미세 조정(fine-tuning) 없이 제로샷 성능만으로 증거법(Evidence)과 불법행위법(Torts) 두 과목에서 인간의 평균 합격률 수준에 도달했습니다.
* 하이퍼파라미터 최적화와 프롬프트 엔지니어링이 GPT-3.5의 제로샷 성능에 긍정적인 영향을 미쳤음을 확인했습니다. 특히, 상위 세 가지 선택지를 순위별로 나열하도록 요구하는 프롬프트가 가장 효과적이었습니다.
* GPT-3.5가 제시한 상위 두 가지 선택지는 71%, 상위 세 가지 선택지는 88%의 확률로 정답을 포함하여, 모델의 답변 순위와 정답 간에 강력한 상관관계를 보여주었습니다. 이는 모델이 법률 도메인에 대한 일반적인 이해도가 높다는 것을 시사합니다.

## 📎 Related Works

* **법률 시스템의 복잡성 및 AI의 필요성**: 법률 시스템의 복잡성 증가([1], [2], [3])와 법률 서비스의 질 및 접근성을 향상하기 위한 AI 및 프로세스 엔지니어링의 필요성이 오랫동안 논의되어 왔습니다([4], [5]).
* **법률 AI 활용 사례**: 검색, 일반인 대상 법률 지원, 자동화된 논증 또는 소송 서류 작성, 계약 프로세스, 실사 및 전자 증거 개시, 사법 분석 등 다양한 법률 분야에서 AI 활용 사례가 연구되었습니다([6], [7], [8]).
* **법률 언어의 특성**: 법률은 언어에 크게 의존하는 분야이며([9]), 방대한 양의 텍스트 데이터([10])를 생성합니다. 법률 언어는 문법적 복잡성 및 "법률 용어(legalese)"와 같은 독특한 관습, 그리고 "estoppel"과 같은 특정 용어들로 인해 복잡성이 높습니다.
* **NLP 및 LLM의 발전**: 최근 몇 년간 신경망 연구([11], [12]), 임베딩([14], [15]) 및 트랜스포머 기반 대규모 언어 모델(LLM)의 발전([16], [17], [18], [19], [20])이 NLP 분야에 혁명을 가져왔습니다. 특히 [25]에서 소개된 트랜스포머 아키텍처는 GPT와 같은 모델의 기반이 됩니다.
* **GPT 모델**: OpenAI의 GPT 모델([17])은 1,750억 개의 파라미터를 가진 자기회귀 언어 모델로, `InstructGPT-3` 및 `Codex 12B`와 같은 파생 모델들이 "GPT-3.5"로 통칭됩니다. 본 연구에서는 `text-davinci-003` 모델을 사용했습니다.
* **기존 변호사 시험 AI 시도**: 전 세계 변호사 시험을 통과하기 위한 시스템 개발 시도들은 시험별로 상당한 훈련이 필요했음에도 불구하고 혼합된 결과를 보였습니다([21], [22], [23]).

## 🛠️ Methodology

본 연구는 OpenAI의 `text-davinci-003` (GPT-3.5) 모델을 활용하여 다지선다형 변호사 시험(MBE)의 제로샷 성능을 평가했습니다.

1. **데이터**: National Conference of Bar Examiners (NCBE)에서 제공하는 MBE 실전 시험 자료(200개 문항)를 사용했습니다. 각 문항은 지문과 네 가지 다지선다형 옵션으로 구성되었으며, 정답은 별도로 저장되었습니다.
2. **프롬프트 엔지니어링**: LLM의 성능이 프롬프트에 민감하다는 점을 고려하여 다양한 프롬프트 유형을 실험했습니다:
    1. 단일 선택: 모델에 하나의 정답만 요구.
    2. 단일 선택 및 설명: 정답과 그 이유를 요구.
    3. 상위 두 가지 선택: 최적의 답변과 차선의 답변을 요구.
    4. 상위 두 가지 선택 및 설명: 상위 두 가지 답변과 그 이유를 요구.
    5. 상위 두 가지 선택 및 재프롬프트: 상위 두 가지 답변 중 하나를 선택하도록 재프롬프트.
    6. 모든 선택지 순위 지정: 네 가지 선택지를 모두 순위별로 나열하도록 요구.
    7. **상위 세 가지 선택지 순위 지정**: 이 방식이 모델 정확도를 가장 크게 향상시켰습니다. 모델은 "First Choice: \<LETTER\>", "Second Choice: \<LETTER\>", "Third Choice: \<LETTER\>" 형식으로 답변하도록 요청받았습니다.
3. **하이퍼파라미터 최적화**: 모델의 성능에 영향을 미치는 다양한 하이퍼파라미터를 평가했습니다.
    * `temperature`: {0.0, 0.25, 0.5, 0.75, 1.0} 범위에서 테스트 (0.0은 결정론적, 높은 값은 더 "무작위적").
    * `top_p`: {0.75, 1.0} 범위에서 핵 샘플링 확률 테스트.
    * `best_of`: {1, 2, 4} 범위에서 여러 완성 결과를 생성하고 가장 확률이 높은 것을 반환.
    * `max_tokens`: {16, 32} (설명 없는 프롬프트) 및 {128, 256, 1024} (설명 있는 프롬프트) 범위에서 생성할 최대 토큰 수.
4. **미세 조정 시도**: 200개의 미공개 MBE 문제와 정답/오답 설명을 사용하여 `text-davinci-003`을 미세 조정하려는 시도가 있었으나, 모든 경우에 미세 조정된 모델이 원본 모델보다 성능이 현저히 떨어져 더 이상 추구하지 않았습니다.

## 📊 Results

GPT-3.5는 총 107개의 샘플 시험에서 다양한 프롬프트와 파라미터 조합을 통해 평가되었으며, 특히 상위 세 가지 선택지를 순위별로 나열하는 프롬프트(#7)가 가장 좋은 성능을 보였습니다.

* **전반적인 성능**:
  * GPT-3.5는 NCBE MBE 실전 시험에서 **50.3%**의 정답률을 기록했습니다. 이는 무작위 추측률 25%를 크게 상회하는 수치입니다.
  * 인간 응시자의 평균 정답률 68%에는 미치지 못하지만, 합격 기준선(jurisdiction에 따라 다르나 대략 60% 전후)에 근접하거나 일부 과목에서는 도달했습니다.
* **과목별 합격률**:
  * **증거법(Evidence)**: 63% (인간 평균: 65%) - 인간 평균과 거의 동등한 수준에 도달했습니다.
  * **불법행위법(Torts)**: 62% (인간 평균: 71%) - 합격률 수준에 도달했습니다.
  * 민사소송법(Civil Procedure): 52% (인간 평균: 59%)
  * 헌법(Constitutional Law): 49% (인간 평균: 72%)
  * 부동산법(Real Property): 45% (인간 평균: 65%)
  * 계약법(Contracts): 45% (인간 평균: 70%)
  * 형법 및 형사소송법(Criminal Law & Procedure): 35% (인간 평균: 71%) - 가장 큰 성능 격차를 보였습니다.
* **순위별 정답률**:
  * **상위 2개 선택지**에 정답이 포함될 확률: **71%**. 모든 과목에서 50%의 무작위 추측률을 초과했으며, 7개 과목 중 5개에서 NCBE 보고 평균을 초과했습니다.
  * **상위 3개 선택지**에 정답이 포함될 확률: **88%**. 민사소송법을 제외하고는 모든 과목에서 무작위 추측률을 훨씬 상회했습니다.

## 🧠 Insights & Discussion

* **기대 이상의 성능**: GPT-3.5는 복잡한 법률 도메인에서 제로샷 환경에서 예상보다 훨씬 뛰어난 능력을 보여주었습니다. 이는 법률 AI 분야에서 LLM의 잠재력을 강력하게 시사합니다.
* **성능 격차의 원인**: 일부 과목(특히 형법)에서 인간 응시자와 큰 성능 격차가 발생하는 두 가지 가능성이 제기됩니다. 첫째, 해당 법률 지식이 모델의 훈련 데이터에 없었거나 후속 모델 압축/미세 조정 과정에서 제거되었을 수 있습니다. 둘째, 시험 출제자가 의도적으로 복잡하거나 혼란스러운 언어를 사용하여 모델의 성능을 저해했을 수 있습니다.
* **랭킹 상관관계의 중요성**: GPT-3.5가 제시한 답변의 순위와 정답 간의 높은 상관관계는 모델이 단순히 추측하는 것이 아니라, 법률 도메인에 대한 일반적인 이해를 바탕으로 오답을 효과적으로 배제하고 있음을 나타냅니다. 이는 문제 설계의 '함정'이 모델 성능에 영향을 미칠 수 있다는 인간 응시자들의 상식과도 일맥상통합니다.
* **LLM의 미래**: 현재의 제한적인 LLM 이해와 GPT의 독점적인 특성에도 불구하고, 본 연구 결과는 LLM이 가까운 미래에 MBE 시험을 통과할 것이라는 강력한 증거를 제시합니다. GPT-4와 같은 후속 모델들은 0\~18개월 이내에 이를 달성할 가능성이 높다고 저자들은 예측합니다.
* **향후 연구 방향**: OpenAI와의 협업 또는 EleutherAI, BigScience, LAION과 같은 대안적인 오픈소스 모델을 활용하여 실험 설계를 재현하고 미세 조정을 계속할 계획입니다. 또한, MBE 외에 에세이(MEE) 및 상황 기반 수행(MPT) 섹션에 대해서도 GPT-3.5 및 다른 모델들을 평가할 예정입니다.

## 📌 TL;DR

본 연구는 GPT-3.5(`text-davinci-003`)가 변호사 시험(Bar Exam)의 다지선다형 섹션(MBE)에서 제로샷으로 높은 성능을 보임을 입증했습니다. 모델은 미세 조정 없이 50.3%의 정답률을 기록하며 무작위 추측률을 크게 상회했으며, 특히 증거법과 불법행위법에서는 인간의 합격률 수준에 도달했습니다. 프롬프트 엔지니어링과 하이퍼파라미터 최적화가 성능 향상에 기여했으며, 모델의 답변 순위와 정답 간의 강력한 상관관계는 법률 도메인에 대한 모델의 깊은 이해를 시사합니다. 이 결과는 LLM이 가까운 미래에 변호사 시험을 통과할 것이라는 강력한 증거를 제공합니다.
