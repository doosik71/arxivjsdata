# The Emergence of Economic Rationality of GPT

Yiting Chen, Tracy Xiao Liu, You Shan, and Songfa Zhong

## 🧩 Problem to Solve

이 연구는 GPT와 같은 거대 언어 모델(LLM)의 언어 처리 능력을 넘어선 의사결정 능력을 평가하는 것을 목표로 합니다. 특히, 경제학의 근본적인 가정인 GPT의 **경제적 합리성**을 현시선호 이론(revealed preference theory)에 기반하여 측정하고, 그 결과가 인간의 행동과 어떻게 다른지, 그리고 다양한 조건에 어떻게 반응하는지를 탐구합니다.

## ✨ Key Contributions

* **GPT의 높은 합리성 입증**: GPT는 위험, 시간, 사회적, 음식 선호 등 네 가지 영역에서 높은 수준의 경제적 합리성(CCEI 점수)을 보였습니다.
* **인간을 능가하는 합리성**: GPT의 합리성 점수는 동일한 실험에 참여한 인간 피실험자 및 기존 문헌의 인간 데이터보다 일관되게 높았습니다.
* **선호 파라미터의 동질성**: GPT의 추정된 선호 파라미터는 인간과 약간의 차이가 있었으며, 인간보다 훨씬 낮은 이질성(homogeneity)을 나타냈습니다.
* **무작위성 및 인구통계학적 요인에 대한 강건성**: GPT의 합리성 점수는 모델의 무작위성 정도(온도)나 나이, 성별과 같은 인구통계학적 설정에는 영향을 받지 않았습니다.
* **언어 프레이밍 및 선택 형식에 대한 민감성**: 가격 정보의 언어 프레임(제시 방식)이 바뀌거나 연속적인 선택이 이산적인 선택으로 변경될 경우, GPT의 합리성 수준이 크게 감소하는 것을 발견했습니다.

## 📎 Related Works

* **LLM의 다양한 능력**: GPT와 같은 LLM이 컴퓨터 코드 생성(Chen et al., 2021), 대화(Lin et al., 2020), 수학 문제 해결(Drori et al., 2022), 마음 이론(theory of mind) 발현(Kosinski, 2023), 인간과 유사한 심리적 특성(Binz and Schulz, 2023; Park et al., 2023), 고수준 추론 작업(Webb et al., 2023) 등 광범위한 영역에서 인상적인 능력을 보여주었습니다.
* **현시선호 분석 및 합리성 측정**: Afriat(1967, 1972), Samuelson(1938), Varian(1982, 1990) 등의 고전적인 현시선호 이론을 바탕으로 의사결정자의 효용 극대화 정도를 측정합니다. 이전 연구들은 위험, 시간, 사회적 의사결정 및 가계 지출 데이터에서 인간의 합리성을 측정했습니다(Andreoni and Miller, 2002; Choi et al., 2007, 2014; Blundell et al., 2003, 2008 등).
* **AI 기반 의사결정 지원 도구**: AI를 보석 결정(Kleinberg et al., 2018), 임상 진단(Mullainathan and Obermeyer, 2022), 주가 예측(Lopez-Lira and Tang, 2023) 등 다양한 의사결정 분야에 활용하는 연구들이 증가하고 있습니다.

## 🛠️ Methodology

1. **GPT 모델**: OpenAI의 공개 API를 통해 GPT-3.5-Turbo 모델을 사용했습니다. API를 사용하여 파라미터를 조정하고 대규모 실험을 효율적으로 수행했습니다.
2. **의사결정 과제**:
    * **기본 프레임워크**: 각 의사결정자는 100점을 두 가지 상품에 할당하는 25개의 예산 결정 과제를 수행합니다.
    * **합리성 측정**: 25개 결정의 집합이 효용 극대화와 얼마나 일관되는지 **일반현시선호 공리(GARP)**를 통해 측정하고, **한계비용 효율성 지수(CCEI)**를 합리성 점수로 사용합니다. CCEI가 1이면 완벽한 합리성을 나타냅니다.
    * **네 가지 선호 영역**:
        * **위험 선호**: 두 가지 우발적 증권(contingent securities) 간의 투자.
        * **시간 선호**: 오늘과 한 달 후의 보상 간의 투자.
        * **사회적 선호**: 자신과 다른 무작위로 매칭된 대상 간의 지급액 분배.
        * **음식 선호**: 햄 고기와 토마토의 소비량 선택.
    * **반복 실험**: 각 환경에서 100번의 시뮬레이션을 수행하여 총 10,000개의 GPT 과제 데이터를 생성했습니다.
3. **변형 조건**:
    * **온도(Temperature) 변화**: GPT 응답의 무작위성/창의성을 조절하는 'temperature' 파라미터를 0(기본), 0.5, 1로 변경하여 실험했습니다.
    * **의사결정 과제 프레이밍 변화**:
        * **가격 프레이밍**: "1점 = X단위의 상품" 방식(기본)에서 "Y점 = 1단위의 상품" 방식으로 가격 제시 방식을 변경했습니다.
        * **이산 선택**: 연속적인 예산 제약 대신, 11개의 미리 정의된 이산적인 선택지 중에서 선택하도록 했습니다.
    * **인구통계학적 정보 삽입**: GPT 프롬프트에 성별, 나이, 교육 수준, 소수 민족 등 인구통계학적 정보를 포함시켜 응답의 변화를 관찰했습니다.
4. **인간 실험**: 대표적인 미국 표본에서 347명의 인간 피실험자를 대상으로 GPT와 동일한 의사결정 과제를 수행했습니다.
5. **구조적 선호 추정**: CCEI 점수 외에도, 효용 함수($U(x_1, x_2)$) 가정을 통해 위험(risk), 시간(time), 사회적(social), 음식(food) 선호에 대한 선호 파라미터($\alpha$, $\rho$)를 추정했습니다.

## 📊 Results

* **높은 합리성 및 우하향 수요**:
  * GPT의 평균 CCEI는 위험 0.998, 시간 0.997, 사회적 0.997, 음식 0.999로 매우 높았습니다.
  * 인간 피실험자의 평균 CCEI는 위험 0.980, 시간 0.985, 사회적 0.967, 음식 0.963으로 GPT보다 낮았습니다 ($p < 0.01$).
  * GPT는 가격 변화에 대한 우하향 수요 법칙을 인간보다 더 강력하게 따랐습니다. 스피어만 상관계수(relative quantity rate와 relative price rate의 로그 값)는 GPT의 경우 -0.951 ~ -0.992, 인간의 경우 -0.673 ~ -0.826였습니다 ($p < 0.01$).
* **선호 파라미터**:
  * GPT는 인간보다 기대 효용 극대화에 가깝고(위험: 인간 $\alpha_{r}=0.618$ vs. GPT $\alpha_{r}=0.508$), 사회적 선호에서 이타적(사회적: 인간 $\alpha_{s}=0.735$ vs. GPT $\alpha_{s}=0.512$)이며, 음식 선호에서 고기를 덜 선호하는(음식: 인간 $\alpha_{f}=0.583$ vs. GPT $\alpha_{f}=0.501$) 경향을 보였습니다.
  * GPT는 인간보다 선호 파라미터의 이질성이 훨씬 낮았습니다.
* **강건성**:
  * 온도(무작위성)가 0.5, 1.0으로 증가해도 GPT의 합리성 수준은 기본 조건과 유사했습니다. 다만, 일부 파라미터의 표준편차는 증가하여 행동의 이질성이 커질 수 있음을 시사했습니다.
  * 인구통계학적 정보(성별, 나이, 교육, 민족)를 프롬프트에 삽입해도 CCEI 값, 스피어만 상관계수, 추정된 선호 파라미터에 유의미한 변화는 없었습니다. 이는 인간 피실험자 결과와 대조됩니다.
* **민감성**:
  * **가격 프레이밍**: 가격 제시 방식을 변경하자 GPT의 합리성이 크게 감소했습니다 (예: 위험 선호 CCEI 0.998 $\rightarrow$ 0.901). 우하향 수요 속성도 손상되었습니다. 이러한 감소는 인간보다 GPT에서 더 크게 나타났습니다.
  * **이산 선택**: 11개의 이산 선택지를 제공하자 GPT의 합리성이 감소했습니다 (예: 위험 선호 CCEI 0.998 $\rightarrow$ 0.843). 이 또한 인간보다 GPT에서 더 큰 영향을 미쳤습니다.

## 🧠 Insights & Discussion

* **LLM의 의사결정 잠재력**: GPT는 경제적 합리성 측면에서 인간을 능가하는 인상적인 의사결정 능력을 보여주며, 일반적인 AI 기반 의사결정 지원 도구로서의 잠재력을 시사합니다.
* **제한점 및 편향**:
  * **맥락 및 프레임에 대한 민감성**: GPT의 의사결정은 가격 제시 방식이나 선택 형식과 같은 맥락에 매우 민감하게 반응하여 합리성이 저하됩니다. 이는 기존 데이터에 내재된 편향(Schramowski et al., 2022), 대체 맥락에 대한 불충분한 학습(Chen et al., 2021), 또는 유사하지 않은 작업에서 통계적 불규칙성을 이용하는 경향(McCoy et al., 2019) 때문일 수 있습니다. 특히, "50대 50 분할" 또는 "전부 아니면 전무"와 같은 코퍼스 기반 휴리스틱이 "낯선" 프레이밍 조건에서 중간값 또는 극단적인 선택을 유도할 수 있습니다.
  * **인구통계학적 정보에 대한 둔감성**: GPT가 인구통계학적 요인에 반응하지 않는 것은 '초정확성 왜곡(hyper-accuracy distortion)'과 일치할 수 있으며, 이는 LLM이 인간의 윤리적 기준에 맞춰 문제적 출력을 줄이기 위해 인구통계학적 정보를 검열하려는 광범위한 노력의 결과일 수 있습니다.
* **미래 연구 방향**: 본 연구는 GPT의 의사결정 행동 이면에 있는 메커니즘을 탐구하지 않았으며, 향후 연구는 이러한 "블랙박스"를 열고 그 작동 방식을 이해해야 합니다. 또한, 더 광범위한 합리성 정의와 슈퍼마켓 쇼핑, 포트폴리오 선택과 같은 더 현실적인 의사결정 환경에서 LLM의 합리성을 탐구해야 합니다.

## 📌 TL;DR

이 연구는 GPT의 **경제적 합리성**을 현시선호 이론 기반으로 평가했습니다. GPT는 **인간보다 높은 합리성**과 우하향 수요를 보였으며, 선호 파라미터에서 높은 동질성을 나타냈습니다. 무작위성이나 인구통계학적 정보에는 강건했지만, **가격 제시 프레임이나 이산 선택으로 조건이 변경될 경우 합리성이 크게 저하**되는 민감성을 보였습니다. 이는 LLM이 유망한 의사결정 도구지만, 그 잠재적 편향과 작동 메커니즘에 대한 더 깊은 이해가 필요함을 시사합니다.
