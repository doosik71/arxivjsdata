{
  "title": "On the Compressive Power of Deep Rectifier Networks for High Resolution\n  Representation of Class Boundaries",
  "authors": "Senjian An, Mohammed Bennamoun, Farid Boussaid",
  "year": 2017,
  "url": "http://arxiv.org/abs/1708.07244v1",
  "abstract": "This paper provides a theoretical justification of the superior\nclassification performance of deep rectifier networks over shallow rectifier\nnetworks from the geometrical perspective of piecewise linear (PWL) classifier\nboundaries. We show that, for a given threshold on the approximation error, the\nrequired number of boundary facets to approximate a general smooth boundary\ngrows exponentially with the dimension of the data, and thus the number of\nboundary facets, referred to as boundary resolution, of a PWL classifier is an\nimportant quality measure that can be used to estimate a lower bound on the\nclassification errors. However, learning naively an exponentially large number\nof boundary facets requires the determination of an exponentially large number\nof parameters and also requires an exponentially large number of training\npatterns. To overcome this issue of \"curse of dimensionality\", compressive\nrepresentations of high resolution classifier boundaries are required. To show\nthe superior compressive power of deep rectifier networks over shallow\nrectifier networks, we prove that the maximum boundary resolution of a single\nhidden layer rectifier network classifier grows exponentially with the number\nof units when this number is smaller than the dimension of the patterns. When\nthe number of units is larger than the dimension of the patterns, the growth\nrate is reduced to a polynomial order. Consequently, the capacity of generating\na high resolution boundary will increase if the same large number of units are\narranged in multiple layers instead of a single hidden layer. Taking high\ndimensional spherical boundaries as examples, we show how deep rectifier\nnetworks can utilize geometric symmetries to approximate a boundary with the\nsame accuracy but with a significantly fewer number of parameters than single\nhidden layer nets.",
  "citation": 5
}