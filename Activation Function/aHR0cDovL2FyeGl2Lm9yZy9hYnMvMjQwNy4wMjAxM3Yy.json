{
  "title": "DiGRAF: Diffeomorphic Graph-Adaptive Activation Function",
  "authors": "Krishna Sri Ipsit Mantri, Xinzhi Wang, Carola-Bibiane Sch√∂nlieb, Bruno Ribeiro, Beatrice Bevilacqua, Moshe Eliasof",
  "year": 2024,
  "url": "http://arxiv.org/abs/2407.02013v2",
  "abstract": "In this paper, we propose a novel activation function tailored specifically\nfor graph data in Graph Neural Networks (GNNs). Motivated by the need for\ngraph-adaptive and flexible activation functions, we introduce DiGRAF,\nleveraging Continuous Piecewise-Affine Based (CPAB) transformations, which we\naugment with an additional GNN to learn a graph-adaptive diffeomorphic\nactivation function in an end-to-end manner. In addition to its\ngraph-adaptivity and flexibility, DiGRAF also possesses properties that are\nwidely recognized as desirable for activation functions, such as\ndifferentiability, boundness within the domain, and computational efficiency.\nWe conduct an extensive set of experiments across diverse datasets and tasks,\ndemonstrating a consistent and superior performance of DiGRAF compared to\ntraditional and graph-specific activation functions, highlighting its\neffectiveness as an activation function for GNNs. Our code is available at\nhttps://github.com/ipsitmantri/DiGRAF.",
  "citation": 9
}