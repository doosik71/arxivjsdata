# On the Generalization of Diffusion Model

Mingyang Yi, Jiacheng Sun, Zhenguo Li

## 🧩 Problem to Solve

확산 확률 생성 모델(Diffusion Probabilistic Generative Models)은 훈련 데이터셋에 없는 고품질 데이터를 생성하는 능력을 보여주지만, 이러한 **일반화(generalization) 능력의 근본적인 이유**는 아직 명확히 탐구되지 않았습니다. 특히, 본 논문은 **경험적 최적(empirical optimal) 확산 모델**이 결정론적 샘플러(deterministic sampler)를 사용할 경우 생성된 데이터가 훈련 데이터셋과 강하게 연관되어 **일반화 능력이 떨어진다**는 이론적 결과와, 실제 학습된 확산 모델이 **훈련 세트에 없는 데이터를 생성하는 외삽 능력(extrapolation ability)**을 보인다는 관찰 사이의 모순을 해결하고자 합니다.

## ✨ Key Contributions

- **생성 모델의 일반화 정의**: 생성된 데이터와 훈련 데이터셋 간의 상호 정보(mutual information)로 측정되는 생성 모델의 일반화를 공식적으로 정의했습니다. 이는 생성된 데이터가 훈련 데이터셋과 덜 상관될수록 일반화 능력이 우수하다는 직관에서 비롯됩니다.
- **경험적 최적 DDPM의 일반화 문제점 입증**: 경험적 최적 확산 모델(DDPM)의 경우, 결정론적 샘플러에 의해 생성된 데이터가 훈련 데이터셋과 매우 밀접하게 관련되어 일반화가 떨어진다는 것을 이론적으로 입증했습니다.
- **최적화 편향(Optimization Bias)의 역할 규명**: 충분히 학습된 확산 모델과 이론적인 경험적 최적 모델 사이의 미묘한 차이(최적화 과정에서 발생하는 편향)가 확산 모델의 일반화 능력에 중요하게 작용한다는 것을 실증적으로 확인했습니다. 즉, 최적화 편향이 모델을 정규화(regularize)하여 일반화 문제를 피하게 합니다.
- **새로운 훈련 목적 함수 제안**: 잠재적인 일반화 문제가 없는 경험적 최적 해를 갖는 새로운 훈련 목적 함수를 제안했습니다. 이 목적 함수는 $E[x_{t-1}|x_t]$를 추정하는 것을 목표로 합니다.
- **제안된 목적 함수의 유효성 검증**: 제안된 목적 함수로 학습된 모델이 기존 목적 함수로 학습된 모델과 유사한 출력을 생성함을 경험적으로 보여, 학습된 확산 모델의 일반화 능력을 다시 한번 확인했습니다.

## 📎 Related Works

- **생성 모델의 일반화**: 기존의 예측 모델 일반화 이론은 훈련/테스트 성능 격차를 측정하지만, 생성 모델에는 직접 적용하기 어렵습니다. GAN의 일반화를 탐구한 Arora et al. (2017)는 생성 분포와 실제 분포 간의 거리 차이를 측정하지만, 이는 모델이 훈련 데이터에 없는 데이터를 생성하는 직관과 일치하지 않습니다. 본 논문은 정보 이론적 일반화 경계(Xu and Raginsky, 2017)에서 영감을 받아 생성 데이터와 훈련 데이터 간의 상관관계를 통해 일반화를 측정합니다.
- **Denoising Diffusion Probabilistic Model (DDPM)**: Sohl-Dickstein et al. (2015)이 일반적인 프레임워크를 제시한 후, Song et al. (2020) 및 Ho et al. (2020)이 고품질 데이터 생성 능력을 크게 향상시켰습니다. 최근 Somepalli et al. (2022) 및 Carlini et al. (2023)은 확산 모델이 훈련 데이터와 유사한 샘플을 생성하여 프라이버시 문제를 야기할 수 있다고 지적했으나, 본 논문의 결과는 확산 모델이 훈련 데이터를 "암기"하는 것을 피할 수 있음을 보여줍니다.
- **DDPM 훈련 목적 함수**: 기존 DDPM은 주로 노이즈 예측(Ho et al., 2020) 또는 데이터 예측(Cao et al., 2022) 문제를 최소화하여 학습됩니다. 본 논문은 "이전 포인트(previous points)"를 예측하는 새로운 훈련 목적 함수를 제안하여 잠재적인 일반화 문제를 해결합니다.

## 🛠️ Methodology

1. **생성 모델의 초과 위험(Excess Risk) 정의**: 생성 모델의 성능을 평가하기 위해 초과 위험 $d_{\mathcal{F}}(Q_{\theta_S}, P_0)$을 정의합니다 (식 1).
   - 초과 위험은 **최적화 오류(optimization error)**와 **일반화 오류(generalization error)**로 분해됩니다 (식 4).
   - **최적화 오류**는 생성된 데이터 분포 $Q_{\theta_S}$와 목표 분포 $P_0$ 사이의 거리(예: KL-divergence, Wasserstein distance)를 측정하여 생성 데이터의 품질을 평가합니다.
   - **일반화 오류**는 생성된 데이터 $z_{\theta_S}$와 훈련 데이터셋 $S$ 간의 상관관계를 측정하며, 이는 직관적으로 모델의 외삽 능력(일반화 능력)을 나타냅니다. 특히, 일반화 오류는 $I(z_{\theta_S}, S)$와 관련이 있습니다 (Proposition 1).
2. **DDPM의 경험적 최적 해 분석**:
   - DDPM은 노이즈 예측 문제 (식 12)를 최소화하여 학습됩니다. 충분한 함수적 용량(functional capacity)을 가진 모델 $\epsilon_\theta$에 대해, 이 문제의 **경험적 최적 해 $\epsilon^*_{\theta_S}(x,t)$**는 훈련 데이터셋 $S$의 각 샘플 $x^0_i$에 대한 가우시안 커널의 가중 평균 형태로 표현됩니다 (식 13):
     $$\epsilon^*_{\theta_S}(x,t) = \frac{x}{\sqrt{1-\bar{\alpha}_t}} - \left( \frac{\sqrt{\bar{\alpha}_t}}{\sqrt{1-\bar{\alpha}_t}} \right) \frac{\sum_{i=1}^n \exp\left( -\frac{\|x-\sqrt{\bar{\alpha}_t}x^0_i\|^2}{2(1-\bar{\alpha}_t)} \right) x^0_i}{\sum_{i=1}^n \exp\left( -\frac{\|x-\sqrt{\bar{\alpha}_t}x^0_i\|^2}{2(1-\bar{\alpha}_t)} \right)}$$
   - 이 형태는 $\epsilon^*_{\theta_S}(x,t)$가 $x$와 훈련 데이터셋 사이의 차이의 선형 결합임을 나타냅니다.
   - **결정론적 샘플링의 문제점**: 만약 확산 모델의 전이 규칙이 $\epsilon^*_{\theta_S}(x,t)$를 사용하는 결정론적 형태($x_{t-1} = f(\epsilon^*_{\theta_S}, x_t, t)$)를 취한다면, 생성된 데이터 $x_0$는 훈련 데이터셋 $S$에 강하게 의존하게 되어 일반화 오류가 무한대가 됩니다 (Proposition 3). 이는 이론적으로 DDIM과 같은 결정론적 샘플러의 일반화 문제를 시사합니다.
3. **최적화 편향의 일반화 기여 실증 분석**:
   - 훈련된 DDPM (Unet)과 경험적 최적 모델의 차이를 CIFAR10 데이터셋에서 DDIM (50단계 결정론적 역방향 프로세스)을 사용하여 비교했습니다.
   - 시간 단계 $t$가 증가함에 따라 훈련된 모델과 경험적 최적 모델 사이의 $L_2$ 거리 $\|x_t - x^*_t\|^2$가 누적되어 증가함을 확인했습니다. 이는 **최적화 과정에서 발생하는 편향(optimization bias)**이 훈련된 모델이 경험적 최적 해에 완벽히 수렴하는 것을 방해하며, 이러한 편향이 역설적으로 일반화 문제를 완화하는 정규화 역할을 함을 시사합니다.
   - 훈련된 모델은 훈련 세트에 없는 새로운 데이터를 생성(외삽)하는 반면, 경험적 최적 모델은 훈련 세트에 존재하는 데이터를 재현하는 경향이 있음을 확인했습니다.
4. **일반화를 개선하는 새로운 훈련 목적 함수 제안**:
   - 기존 DDPM이 $E[x_0|x_t]$를 추정하는 것과 달리, 새로운 목적 함수는 $E[x_{t-1}|x_t]$ (또는 $E[\xi_{t,t-1}|x_t]$)를 직접 추정하는 것을 목표로 합니다 (Proposition 4).
   - 이를 위해 Tweedie의 공식(Lemma 1)을 활용하여 $E[\xi_{t,s}|x_t]/\sqrt{1-r_{t,s}}$가 $s$에 대해 불변임을 보입니다.
   - 새로운 훈련 목적 함수 (식 21)는 다음과 같습니다:
     $$\inf_{\xi_\theta} \sum_{t=1}^T E_s \left[ \frac{1}{n} \sum_{i=1}^n E_{\xi_{t,s}} \left[ \left\| \frac{\xi_{t,s}}{\sqrt{1-r_{t,s}}} - \xi_\theta\left(\sqrt{r_{t,s}}x^i_s + \sqrt{1-r_{t,s}}\xi_{t,s}, t\right) \right\|^2 \right] \right]$$
   - 이 목적 함수의 경험적 최적 해 $\xi^*_{\theta_S}(x,t)$는 기존 $\epsilon^*_{\theta_S}(x,t)$와 달리, 훈련 데이터 $x^0_i$에 직접적으로 의존하지 않고 다양한 노이즈 데이터 $x^i_s$에 의존하므로 잠재적인 일반화 문제를 피할 수 있습니다 (Proposition 5).

## 📊 Results

- **최적화 편향의 효과**:
  - 훈련된 모델과 경험적 최적 모델 간의 평균 $L_2$ 거리는 시간 단계 $t$가 증가함에 따라 누적적으로 증가하는 경향을 보였습니다 (CIFAR10, Figure 1a).
  - 훈련된 모델은 노이즈가 있는 테스트 세트 데이터($x_{15}$로 시작)로부터 원본 데이터를 성공적으로 복원하는 반면, 경험적 최적 모델은 그러지 못했습니다 (Figure 2b).
  - 훈련된 모델은 훈련 세트 데이터($x_{15}$로 시작)로부터 원본 데이터를 복원할 수 있으나, 충분한 최적화 편향이 축적되면(예: $x_{50}$로 시작) 훈련 데이터를 암기하는 현상이 사라짐을 확인했습니다 (Figure 2a, Appendix E.1).
- **새로운 목적 함수 모델과의 비교**:
  - 새로운 목적 함수 (식 21)로 훈련된 모델($\hat{x}_t$)과 기존 목적 함수 (식 12)로 훈련된 모델($x_t$), 그리고 경험적 최적 모델($x^*_t$)을 비교했을 때, $x_t$와 $\hat{x}_t$는 서로 시각적으로 유사한 출력을 생성했습니다 (Figure 3c).
  - 하지만 $\hat{x}_t$는 $x_t$에 비해 약간 더 노이즈가 많고, FID (Fréchet Inception Distance) 점수는 $x_t$보다 높게 나타났습니다 (CIFAR10: $x_0$ 3.17 vs. $\hat{x}_0$ 11.30; CelebA: $x_0$ 8.91 vs. $\hat{x}_0$ 108.73).

## 🧠 Insights & Discussion

- **일반화의 재정의**: 이 논문은 생성 모델의 성능 평가 지표로서 "초과 위험"을 제안하여, 단순히 생성 데이터의 품질을 넘어 모델의 "외삽 능력"까지 고려하는 새로운 관점을 제시합니다.
- **이론과 실제의 간극 해명**: 경험적 최적 확산 모델은 결정론적 샘플러 사용 시 훈련 데이터에 대한 높은 의존성 때문에 일반화에 문제가 있다는 이론적 예측과 달리, 실제 학습된 신경망 확산 모델은 외삽 능력을 보인다는 관찰 사이의 모순을 "최적화 편향"의 개념으로 설명합니다. 즉, 학습 과정의 불완전성(편향)이 역설적으로 모델의 정규화와 일반화를 돕는다는 의미심장한 통찰을 제공합니다.
- **일반화-최적화의 트레이드오프**: 제안된 새로운 훈련 목적 함수는 이론적으로 일반화 문제를 해결하지만, 기존 모델 대비 FID 점수가 높아지는 현상을 통해 일반화와 최적화 오류 사이의 트레이드오프 관계가 존재함을 시사합니다. 이는 확산 모델 훈련 시 두 가지 요소를 균형 있게 고려해야 함을 강조합니다.
- **데이터 암기 문제에 대한 반박**: 이 연구는 확산 모델이 항상 훈련 데이터를 암기한다는 일부 주장을 재고하게 만듭니다. 충분한 최적화 편향이 축적되면 확산 모델은 훈련 데이터를 재현하지 않고도 일반화 능력을 유지할 수 있음을 보여줍니다.

## 📌 TL;DR

확산 모델의 일반화 원리가 불분명하고, 이론적인 경험적 최적 모델이 결정론적 샘플링 시 훈련 데이터에 과도하게 의존한다는 문제점이 있습니다. 본 논문은 생성 모델의 일반화를 생성 데이터와 훈련 세트 간의 상호 정보로 정의하고, **학습 과정에서 발생하는 최적화 편향(optimization bias)**이 실제 확산 모델의 일반화 능력을 정규화하여 유지시켜준다는 것을 실증적으로 보여줍니다. 또한, 내재적으로 일반화 문제가 없는 새로운 훈련 목적 함수를 제안하여 이 주장을 강화하고, 일반화와 최적화 오류 사이의 트레이드오프를 논의합니다.
