# A Systematic Benchmarking Analysis of Transfer Learning for Medical Image Analysis

Mohammad Reza Hosseinzadeh Taher, Fatemeh Haghighi, Ruibin Feng, Michael B. Gotway, and Jianming Liang

## 🧩 Problem to Solve

의료 영상 분석 분야에서 지도 학습 기반 ImageNet 모델로부터의 전이 학습은 널리 사용되어 왔습니다. 그러나 새로 개발된 사전 학습 기술들의 효능을 체계적으로 평가한 대규모 벤치마킹 연구가 부족하여 다음과 같은 중요한 질문들이 답해지지 않은 상태였습니다.

- 미세 분류(fine-grained) 데이터셋인 iNat2021로 사전 학습된 모델이 지도 학습 ImageNet 모델에 비해 의료 영상 분석에 어떤 이점을 제공하는가?
- 자가 지도 학습(Self-Supervised Learning, SSL) 기반 ImageNet 모델이 지도 학습 ImageNet 모델에 비해 의료 영상에 얼마나 일반화될 수 있는가?
- 적당한 크기의 의료 영상 데이터셋을 사용하여 자연 영상과 의료 영상 간의 도메인 격차를 해소할 수 있는가?

## ✨ Key Contributions

이 연구는 의료 영상 분석을 위한 전이 학습의 다양한 사전 학습 기술에 대한 최초의 체계적이고 포괄적인 벤치마킹 분석을 제공하며, 다음과 같은 핵심 기여를 합니다.

- **미세 분류 데이터의 효과 규명**: 미세 분류 데이터(iNat2021)로 사전 학습된 모델이 의료 영상 분할(segmentation) 작업에 더 적합한 독특한 지역적 표현(local representations)을 학습한다는 것을 밝혀냈습니다.
- **자가 지도 학습의 우수성 입증**: 14가지 최신 자가 지도 학습 ImageNet 모델이 지도 학습 ImageNet 모델보다 전반적으로 더 효과적으로 전체론적 특징(holistic features)을 학습하며, 다양한 의료 작업에서 더 높은 전이 가능성을 보임을 확인했습니다.
- **도메인 적응형(연속) 사전 학습 제안**: 지도 학습 ImageNet 모델을 의료 영상으로 연속적으로 사전 학습(continual pre-training)함으로써 자연 영상과 의료 영상 간의 도메인 격차를 효과적으로 줄일 수 있는 실용적인 접근 방식을 제시했습니다.
- **대규모 개방형 평가**: 7가지 다양한 의료 영상 작업에 대해 iNat2021 및 14가지 최신 자가 지도 학습 ImageNet 모델의 전이 가능성을 광범위하게 평가하여, 미래 연구 방향을 제시하는 중요한 통찰을 제공했습니다. 모든 코드와 사전 학습 모델은 공개되어 있습니다.

## 📎 Related Works

- **ImageNet 전이 학습**: 의료 영상 분야에서 지도 학습 ImageNet 모델의 미세 조정(fine-tuning)은 표준 관행으로 자리 잡았습니다 [18, 35, 34, 44, 17].
- **미세 분류 데이터셋**: ImageNet이 일반 객체 분류용인 반면, iNat2021 [21]은 270만 개의 훈련 이미지와 1만 종의 미세 분류 데이터를 포함하는 최신 대규모 데이터셋입니다.
- **자가 지도 학습**: 최근 많은 자가 지도 학습(SSL) 방법들 [38, 12, 23, 43, 7]이 컴퓨터 비전 태스크에서 지도 학습 ImageNet 모델을 능가하는 성능을 보여주었습니다.
- **의료 도메인 데이터셋**: NIH ChestX-Ray14 [37](112K 이미지), CheXpert [22](224K 이미지)와 같은 중간 규모의 의료 영상 데이터셋이 개발되었습니다.
- **도메인 적응형 사전 학습**: 자연어 처리 분야에서 시작된 개념으로, 대규모 일반 데이터셋으로 먼저 사전 학습한 다음 도메인 특정 데이터셋으로 연속적으로 사전 학습하는 접근 방식입니다 [15].

## 🛠️ Methodology

이 연구는 7가지 다양한 의료 영상 작업(분류 4개, 분할 3개)에 걸쳐 전이 학습의 효과를 평가하기 위해 다음과 같은 체계적인 접근 방식을 사용했습니다.

1. **데이터셋 및 작업**:
   - 7가지 의료 영상 작업: 폐색전증 탐지(ECC), 14가지/5가지 흉부 질환 분류(DXC$_{14}$, DXC$_{5}$), 혈관 분할(VFS), 기흉 분할(PXS), 폐 분할(LXS), 결핵 탐지(TXC).
   - 다양한 질병, 장기, 모달리티(CT, X-ray, 안저경 검사)를 포함합니다.
2. **모델 아키텍처**:
   - 모든 실험에서 ResNet-50 백본을 사용했습니다.
   - 분류 작업에는 ResNet-50 백본 뒤에 작업별 분류 헤드를 추가했습니다.
   - 분할 작업에는 ResNet-50 인코더로 초기화된 U-Net을 사용했습니다.
   - 모든 타겟 모델 파라미터는 미세 조정되었습니다.
3. **평가 지표**:
   - 분류 작업에는 AUC(Area Under the ROC Curve)를 사용했습니다.
   - 분할 작업에는 Dice 계수를 사용했습니다.
   - 10회 실행에 대한 평균 및 표준 편차와 독립 $t$-검정 기반 통계 분석을 보고했습니다.
4. **사전 학습 모델 비교**:
   - **데이터 세분성(Granularity) 분석**: ImageNet과 iNat2021로 사전 학습된 지도 학습 모델의 성능을 비교했습니다. iNat2021 mini 데이터셋을 이용한 어블레이션 연구도 수행했습니다.
   - **자가 지도 학습(SSL) 분석**: 14가지 최신 자가 지도 ImageNet 모델(예: MoCo-v1/v2, SimCLR-v1/v2, BYOL, SwAV, Barlow Twins 등)의 전이 가능성을 지도 학습 ImageNet 모델과 비교했습니다.
   - **도메인 적응형 사전 학습**: ImageNet 모델을 CheXpert 또는 ChestX-ray14와 같은 의료 데이터셋으로 연속적으로 사전 학습(ImageNet $\to$ CheXpert / ImageNet $\to$ ChestX-ray14)하여 성능을 평가했습니다.

## 📊 Results

이 연구의 광범위한 실증적 연구는 다음과 같은 주요 결과를 도출했습니다.

- **데이터 세분성(Granularity)의 영향**:

  - iNat2021로 사전 학습된 모델은 의료 영상 분할 작업(PXS, VFS, LXS)에서 ImageNet 모델을 능가했습니다. 이는 iNat2021의 미세 분류 특성 덕분에 픽셀 수준의 세부 정보를 더 잘 포착하기 때문입니다 (그림 1, 표 4).
  - 반대로 ImageNet으로 사전 학습된 모델은 분류 작업(DXC$_{14}$, DXC$_{5}$, TXC, ECC)에서 iNat2021 모델보다 우세했습니다. 이는 ImageNet이 더 추상적인 고수준 의미 특징을 학습하기 때문입니다 (그림 1, 표 4).
  - iNat2021 mini (ImageNet보다 작은 데이터셋)로 사전 학습된 모델조차 분할 작업에서 ImageNet 모델보다 우수한 성능을 보여, 데이터 크기보다는 미세 분류 특성이 중요함을 입증했습니다 (표 3).

- **자가 지도 학습(SSL)의 성능**:

  - 각 타겟 작업에서 최소 3개 이상의 자가 지도 ImageNet 모델이 지도 학습 ImageNet 모델보다 평균적으로 우수한 성능을 보였습니다 (그림 2, 표 5). 이는 자가 지도 표현 학습의 높은 전이 가능성을 시사합니다.
  - SwAV, Barlow Twins, SeLa-v2, DeepCluster-v2와 같은 상위 자가 지도 모델은 대부분의 작업에서 지도 학습 ImageNet 모델을 꾸준히 능가했습니다.
  - 자가 지도 모델은 지도 학습 모델에 비해 타겟 모델의 훈련 과정을 현저히 가속화했습니다 (표 7).
  - 특히 도메인 차이가 큰 분할 작업에서 더 많은 SSL 방법이 우수한 전이 성능을 보였습니다. 이는 SSL이 이미지 전체에서 더 풍부한 시각 정보를 도출하기 때문입니다.

- **도메인 적응형 사전 학습의 효과**:
  - ChestX-ray14 및 CheXpert로 사전 학습된 도메인 내(in-domain) 모델은 모든 경우에서 ImageNet 모델보다 꾸준히 우수한 성능을 보였습니다 (표 2).
  - ImageNet 모델을 의료 데이터셋으로 연속적으로 사전 학습한 도메인 적응형 모델(ImageNet $\to$ CheXpert, ImageNet $\to$ ChestX-ray14)은 ImageNet 및 해당 도메인 내 모델 모두를 능가하는 경우가 많았습니다 (DXC$_{14}$, LXS, TXC, PXS에서 우세) (표 2).
  - DXC$_{5}$에서는 도메인 내 사전 학습 데이터셋의 이미지 수가 타겟 데이터셋보다 적어 성능이 저하되는 경우가 있었습니다. 이는 도메인 내 사전 학습 데이터가 타겟 데이터보다 커야 함을 시사합니다.
  - 도메인 적응형 모델은 대부분의 경우에 해당 ImageNet 모델에 비해 훈련 과정을 가속화했습니다 (표 8).

## 🧠 Insights & Discussion

- **데이터 세분성의 중요성**: 의료 영상 분석에서는 작업의 성격에 따라 사전 학습 데이터의 세분성이 중요합니다. 분할과 같은 픽셀 수준의 세밀한 작업에는 미세 분류 데이터가, 전반적인 특징을 파악하는 분류 작업에는 일반적인 객체 분류 데이터가 더 효과적입니다.
- **자가 지도 학습의 잠재력**: 자가 지도 학습은 의료 영상 분석을 위한 새로운 전이 학습 표준이 될 수 있습니다. 이는 라벨링 노력 없이도 지도 학습 모델보다 더 높은 전이 가능성과 빠른 수렴을 제공하며, 특히 도메인 격차가 큰 작업에서 유용합니다. 자가 지도 모델이 전체적인 특징을 효과적으로 학습하여 도메인 관련 의미에 편향되지 않은 일반화 가능한 특징을 생성하기 때문입니다.
- **도메인 격차 해소**: 연속적인 사전 학습은 자연 영상과 의료 영상 간의 현저한 도메인 격차를 성공적으로 해소합니다. ImageNet의 일반적인 학습 경험을 활용하고, 이를 도메인 관련 데이터로 더욱 정교화함으로써 더 강력한 사전 학습 모델을 얻을 수 있습니다. 이는 미래의 라벨링 부담을 줄이면서 고성능 의료 영상 모델을 개발하는 데 중요한 방향을 제시합니다.
- **한계**: 모든 작업에서 단일 자가 지도 방법이 지배적이지 않아 보편적인 사전 학습 모델은 아직 미스터리로 남아있습니다. 또한, 본 연구의 자가 지도 모델들은 ResNet50 아키텍처와 ImageNet으로만 사전 학습되었으므로, iNat2021이나 도메인 내 의료 영상 데이터로 다양한 아키텍처에 대한 자가 지도 사전 학습을 탐구하면 더 깊은 통찰을 얻을 수 있을 것입니다.

## 📌 TL;DR

의료 영상 분석을 위한 전이 학습의 최신 사전 학습 기술들에 대한 체계적인 벤치마킹 연구가 부족하다는 문제를 해결하기 위해, 본 연구는 미세 분류 데이터셋 iNat2021, 14가지 자가 지도 ImageNet 모델, 그리고 도메인 적응형 연속 사전 학습을 7가지 다양한 의료 작업에 대해 평가했습니다. 주요 결과는 다음과 같습니다: 1) 미세 분류 데이터로 사전 학습된 모델은 의료 분할 작업에 더 적합한 지역적 표현을 학습하며, 2) 상위 자가 지도 ImageNet 모델은 지도 학습 ImageNet 모델보다 전반적으로 우수하고 훈련 과정을 가속화하며, 3) ImageNet 모델을 의료 영상으로 연속적으로 사전 학습함으로써 자연-의료 도메인 격차를 효과적으로 줄일 수 있습니다. 이 연구는 의료 영상 분야 딥러닝의 미래 연구 방향을 제시합니다.
