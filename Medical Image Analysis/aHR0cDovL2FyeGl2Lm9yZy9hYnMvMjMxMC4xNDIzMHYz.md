# A comprehensive survey on deep active learning in medical image analysis

Haoran Wang, Qiuye Jin, Shiman Li, Siyu Liu, Manning Wang, Zhijian Song

## 🧩 Problem to Solve

의료 영상 분석 분야에서 딥러닝 모델의 성공은 대규모 전문가 주석(annotation) 데이터셋의 확보를 필요로 합니다. 그러나 의료 영상 데이터에 대한 주석 작업은 높은 비용(시간, 노동력, 전문성)이 소요되어 딥러닝 발전의 주요 병목 현상으로 작용합니다. 능동 학습(Active Learning, AL)은 가장 정보 가치가 높은 샘플을 선택하여 주석을 요청함으로써, 적은 수의 레이블된 샘플로도 고성능 모델을 훈련하여 이러한 주석 비용을 효과적으로 줄이는 것을 목표로 합니다.

## ✨ Key Contributions

- 의료 영상 분석에 중점을 둔 AL 연구에 대한 포괄적인 조사와 새로운 분류 체계(taxonomy)를 제시했습니다.
- 이전 연구들이 정보성 평가에 주로 초점을 맞춘 반면, 다양성(diversity) 및 클래스 균형(class-balance) 전략과 같은 딥 능동 학습의 다양한 샘플링 전략을 요약하여 향후 방법론 개선을 위한 참조점을 제공했습니다.
- AL과 다른 레이블 효율적인 기술(예: 준지도 학습, 자기지도 학습, 도메인 적응, 영역 기반 AL, 생성 모델)의 통합에 대한 상세한 검토를 처음으로 제공했습니다.
- 의료 영상 분석에서 다양한 AL 방법의 성능을 비교 분석하는 실험을 수행했으며, 재현성을 위해 코드를 공개했습니다.

## 📎 Related Works

본 논문은 기존의 다양한 능동 학습(AL) 관련 연구를 언급하며 그 한계를 지적합니다:

- **기존 AL 서베이**: Settles (2009)는 초기 기계 학습 시대의 AL에 대한 일반적인 소개를, Ren et al. (2021), Liu et al. (2022), Zhan et al. (2022), Takezoe et al. (2023) 등은 딥러닝 시대의 AL 발전 및 컴퓨터 비전(CV), 자연어 처리(NLP) 분야에서의 응용을 검토했습니다.
- **의료 영상 AL 서베이**: Budd et al. (2021)은 의료 영상 분석에서 딥러닝 개발에 있어 인간의 역할과 AL의 중요성을, Tajbakhsh et al. (2020)은 불완전한 주석으로 고성능 모델을 훈련하기 위한 AL을 언급했습니다. Jin et al. (2023a)은 모델 및 데이터 불확실성 관점에서 AL 방법을 요약했습니다.
- **기존 연구의 한계**: 최신 딥 능동 학습의 발전(특히 다른 레이블 효율 기술과의 통합)을 포괄적으로 다루지 못했으며, 의료 영상 데이터셋에 대한 다양한 AL 방법의 성능 평가가 부족했습니다.

## 🛠️ Methodology

본 논문은 의료 영상 분석을 위한 능동 학습(AL)의 핵심 방법론을 크게 세 가지 축으로 분류하고 검토합니다:

1. **능동 학습의 기본 과정**:

   - **샘플 선택($D_{q_t} = S( \{x \in D_{u_t} | I(x, f_{\theta_{t-1}})\} , b )$)**: $t$번째 주석 라운드에서 정보성 함수 $I$를 사용하여 비레이블 데이터셋 $D_{u_t}$의 각 샘플의 정보성을 평가하고, 샘플링 전략 $S$를 통해 $b$개의 샘플을 선택합니다. 의료 영상에서는 주로 이미지 단위(2D 또는 3D)로 선택하지만, 영역별($\S 4.3$) 또는 슬라이스별($\S 5.2.1$) 주석도 가능합니다.
   - **오라클(전문가)에 의한 주석**: 선택된 $D_{q_t}$를 전문가에게 보내 레이블($y$)을 얻고, 이를 레이블된 데이터셋 $D_{l_t}$에 추가($D_{l_t} = D_{l_{t-1}} \cup \{(x,y) | x \in D_{q_t}\}$)하며, $D_{u_t}$에서 제거합니다.
   - **DL 모델 훈련($\theta_t = \text{arg min}_{\theta} E_{(x,y) \in D_{l_t}} [ L(f_{\theta}(x),y) ]$)**: 새로운 레이블된 데이터 $D_{l_t}$로 딥 모델 $f_{\theta_t}$를 훈련합니다.
   - **반복**: 주석 예산이 소진되거나 목표 성능에 도달할 때까지 1~3단계를 반복합니다. 초기 모델($f_{\theta_0}$)은 무작위로 선택된 초기 레이블 데이터셋 $D_{l_0}$로 훈련됩니다.

2. **능동 학습의 핵심 방법론**:

   - **정보성 평가**:
     - **불확실성(Uncertainty)**: 모델이 현재 예측에 대해 얼마나 불확실한지 측정합니다.
       - **다중 추론 기반**: MC 드롭아웃, 모델 앙상블, 모델 불일치, 데이터 불일치 등을 통해 과신 문제를 완화합니다.
       - **그래디언트 기반**: 그래디언트 노름, 피셔 정보, 영향 함수를 사용하여 샘플이 모델 파라미터 변화에 미치는 영향을 측정합니다.
       - **성능 추정**: 대리 메트릭(surrogate metrics) 또는 학습 가능한 성능 추정 모델(예: 손실 예측)을 통해 예측 오류 수준을 간접적으로 추정합니다.
       - **불확실성 인식 모델**: 증거 딥러닝(EDL), 혼합 밀도 네트워크(MDN)와 같이 내재적으로 불확실성을 포착하는 모델을 사용합니다.
       - **적대적 기반**: 적대적 샘플 또는 적대적 훈련을 통해 결정 경계에 가까운 샘플을 식별합니다.
     - **대표성(Representativeness)**: 데이터셋 전체를 잘 대표할 수 있는 샘플을 선택합니다.
       - **클러스터링 기반**: 특징 공간에서 유사한 이미지를 그룹화하고 각 클러스터의 중심 샘플을 선택합니다.
       - **커버 기반**: 몇 개의 샘플로 전체 데이터셋을 "커버"하는 방식으로, 최대 커버 문제(maximum cover problem)를 해결합니다.
       - **불일치 기반**: 레이블된 세트와 비레이블된 세트 간의 분포 불일치를 최소화하는 샘플을 선택합니다 (예: H-divergence, Wasserstein distance, MMD).
       - **밀도 기반**: 데이터 분포에서 가장 밀도가 높은 영역의 샘플을 선택합니다.
   - **샘플링 전략**:
     - **다양성 샘플링**: 중복성을 줄이고 특징 공간을 더 잘 커버하기 위해 클러스터링, 최원점 우선 탐색(farthest-first traversal), 행렬식 점 과정(Determinantal Point Process, DPP) 등을 사용합니다.
     - **클래스 균형 샘플링**: 불균형한 클래스 분포 문제를 완화하기 위해 소수 클래스 샘플의 주석을 우선시합니다.
     - **하이브리드 샘플링**: 여러 정보성 메트릭을 효과적으로 통합하기 위해 다중 라운드 샘플링 또는 메트릭 융합을 사용합니다.
     - **학습 가능한 샘플링**: 신경망(예: 강화 학습 에이전트)을 직접 사용하여 샘플 선택을 수행합니다.

3. **다른 레이블 효율 기술과의 통합**:
   - **준지도 학습**: 의사 레이블링(pseudo-labeling) 또는 일관성 정규화(consistency regularization)를 통해 대량의 비레이블 데이터를 활용합니다.
   - **자기지도 학습**: 사전 훈련된 모델의 강력한 특징 추출 능력을 활용하여 AL의 콜드 스타트 문제를 해결하거나, pretext task의 손실을 정보성 메트릭으로 사용합니다.
   - **능동 도메인 적응(ADA)**: 소스 도메인에서 타겟 도메인으로 지식을 전달하며, 타겟 도메인의 불확실성 및 도메인 관련성을 고려하여 샘플을 선택합니다. 이미지 단위 또는 영역 단위로 적용됩니다.
   - **영역 기반 능동 학습**: 전체 이미지 대신 패치(patches) 또는 슈퍼픽셀(superpixels)과 같은 작은 영역을 주석 단위로 선택하여 주석 효율성을 높입니다.
   - **생성 모델**: 생성된 합성 샘플을 데이터 증강으로 활용하거나, 생성 모델을 통해 불확실한 영역에서 샘플을 생성하여 주석을 요청하는 생성적 능동 학습(Generative Active Learning)을 수행합니다.

## 📊 Results

본 논문은 다양한 능동 학습(AL) 방법의 성능을 NCT-CRC-HE-100K(다중 클래스 조직 분류), ISIC 2020(이진 피부 병변 분류, 클래스 불균형), ACDC(심장 MRI 분할) 세 가지 의료 영상 데이터셋에서 평가했습니다.

- **병리학적 조직 분류 (NCT-CRC-HE-100K)**:

  - **낮은 예산($b=50$)**: `Margin` 및 `BADGE`가 특히 좋은 성능을 보였습니다. `Margin`은 유사 클래스의 잘못된 예측 정보를 활용하고, `BADGE`는 `k-Means++` 클러스터링을 통한 다양성 향상 덕분입니다.
  - **높은 예산($b=1000$)**: `BADGE`의 성능이 낮아졌는데, 이는 훈련/테스트 세트 간의 분포 편향에 대한 그래디언트 임베딩의 적합성이 낮음을 시사합니다.

- **피부 병변 분류 (ISIC 2020)**:

  - **낮은 예산($b=50$)**: `Core-Set` 및 그 변형들이 불확실성 기반 방법보다 우수한 성능을 보였습니다. 이는 예산이 낮고 태스크가 어려운 경우, 대표성 기반 또는 다양성 개선 방법이 더 효과적임을 나타냅니다. `BADGE`도 클러스터링을 통한 다양성 덕분에 일부 라운드에서 두각을 나타냈습니다.
  - **높은 예산($b=1000$)**: 불확실성 기반 방법들의 성능이 향상되었고, `Core-Set` 변형들도 여전히 경쟁력을 유지했습니다. 이는 예산이 높을수록 불확실성 기반 방법이 더 효과적이며, 낮은 예산에서는 대표성 기반 방법이 유리할 수 있음을 보여줍니다.

- **심장 MRI 분할 (ACDC)**:

  - **낮은 예산($b=10$)**: `BADGE`는 여러 라운드에서 평균 Dice 유사도 계수(DSC)에서 최고 또는 두 번째로 좋은 성능을 달성했습니다. `Core-Set`도 초기 라운드에서 좋은 성능을 보였으며, 두 방법 모두 샘플링 다양성을 어느 정도 개선했습니다.
  - **후반 라운드**: 불확실성 기반 방법들과 무작위 샘플링의 성능이 평균 DSC 및 평균 표면 거리(ASD)에서 향상되었습니다.

- **이미지 간 거리 측정의 효과**:
  - `Core-Set`의 `L2` 거리와 코사인 거리(`Core-Set-Cosine`)를 비교한 결과, NCT-CRC-HE-100K에서는 큰 차이가 없었습니다.
  - ISIC 2020에서는 `L2` 거리가 초기 라운드에서 더 빠르게 모델을 시작하는 데 유리했지만, 예산이 높아질수록 코사인 거리가 `L2` 거리보다 유의미하게 우수했습니다.
  - ACDC 데이터셋에서는 `Core-Set-L2`가 초기 라운드에서 `Core-Set-Cosine`보다 뛰어났으나, 더 많은 샘플을 선택한 후에는 유사한 성능을 보였습니다.
  - 결론적으로, 거리 메트릭의 선택은 대상 태스크와 예산에 따라 신중하게 이루어져야 하며, `L2`는 낮은 예산 시나리오에, 코사인 거리는 높은 예산 시나리오에 더 적합할 수 있습니다.

## 🧠 Insights & Discussion

의료 영상 분석 분야에서 능동 학습(AL)은 주석 비용 절감의 중요한 역할을 하지만, 여전히 해결해야 할 과제와 발전 가능성이 존재합니다.

- **더 나은 불확실성 평가**:
  - 모델의 실수를 직접적으로 파악하고 예측 정확도를 높이기 위해, 학습 가능한 성능 추정(예: SAM 모델의 IoU 예측) 및 확률 보정(probability calibration) 기술을 AL에 통합하는 연구가 필요합니다.
  - 의료 영상 분석 분야에서 아직 제한적으로 활용되는 적대적 기반 불확실성 방법을 연합 학습(federated learning) 시나리오 등에서 탐색하는 것이 유망합니다.
- **더 나은 대표성 평가**:
  - 데이터 분포 간의 거리를 측정하는 더 정교한 메트릭(예: Wasserstein distance, MMD의 개선)을 개발하고, 고차원 공간에서의 밀도 추정 문제(예: 정규화 흐름(normalizing flow) 활용)를 해결하여 대표성 기반 AL의 성능을 향상시켜야 합니다.
- **약한 주석(Weak Annotation) 활용**:
  - 전체 이미지 주석 대신 영역 단위(patches, superpixels), 바운딩 박스, 또는 객체 클래스 레이블과 같은 약한 주석을 AL과 결합하여 주석자의 부담을 줄이고 효율성을 높이는 연구가 중요합니다.
- **더 나은 생성 모델 활용**:
  - Diffusion 모델(Stable Diffusion, ControlNet)과 같은 최신 고품질 생성 모델을 AL에 통합하여, 유연한 데이터 증강 또는 생성적 능동 학습을 통해 주석 없이도 정보성 높은 합성 샘플을 생성하는 잠재력을 탐색해야 합니다.
- **기반 모델(Foundation Models)과의 통합**:
  - CLIP, SAM과 같은 시각 기반 모델 및 GPT-4와 같은 대규모 언어 모델(LLMs)의 등장으로, AL을 매개변수 효율적인 파인튜닝(PEFT) 또는 프롬프트 튜닝(prompt tuning)과 결합하여 필요한 주석 샘플 수를 더욱 줄이는 연구가 필요합니다.
  - 시각적 인-컨텍스트 학습(visual in-context learning)을 위한 최적의 프롬프트를 선택하는 AL 방법 또한 중요한 연구 방향입니다.

## 📌 TL;DR

본 논문은 의료 영상 분석에서 주석 비용 절감의 핵심인 딥 능동 학습(AL)에 대한 포괄적인 서베이입니다. AL의 핵심 방법론(정보성 평가, 샘플링 전략)을 불확실성 및 대표성 관점에서 심층적으로 탐구하고, 준지도 학습, 자기지도 학습, 도메인 적응, 영역 기반 AL, 생성 모델 등 다른 레이블 효율 기술과의 통합 방안을 상세히 검토했습니다. 또한, 다양한 의료 영상 데이터셋에 대한 광범위한 실험을 통해 인기 있는 AL 방법들의 성능을 비교 분석하여 각 방법의 장단점과 특정 시나리오에서의 효과를 제시했습니다. 궁극적으로, 기반 모델, 개선된 불확실성/대표성 측정, 약한 주석 및 새로운 생성 모델과의 통합을 포함한 미래 연구 방향을 제시하며, 의료 영상 AL 분야의 학문적 가치와 임상적 잠재력을 강조합니다.
