# UNet++: 의료 영상 분할을 위한 중첩 U-Net 아키텍처

Zongwei Zhou, Md Mahfuzur Rahman Siddiquee, Nima Tajbakhsh, and Jianming Liang

## 🧩 Problem to Solve

의료 영상 분할은 자연 영상 분할보다 훨씬 높은 정확도를 요구하며, 미미한 분할 오류도 임상 환경에서 심각한 결과를 초래할 수 있습니다. 기존의 U-Net과 같은 인코더-디코더 네트워크는 스킵 연결(skip connections)을 사용하여 세부 정보를 복구하지만, 인코더와 디코더 서브 네트워크 간의 **의미론적으로 유사하지 않은 특징 맵을 직접 융합**하는 경향이 있습니다. 이는 최적화 문제를 어렵게 만들고, 의료 영상에서 요구되는 객체의 미세한 세부 사항을 정확하게 분할하는 데 한계가 있었습니다. 본 논문은 이러한 의미론적 간극(semantic gap)을 줄이고 보다 정확한 의료 영상 분할을 달성하기 위한 새로운 아키텍처를 제안합니다.

## ✨ Key Contributions

- **UNet++ 아키텍처 제안**: 중첩된(nested) 조밀한(dense) 스킵 경로(skip pathways)와 딥 슈퍼비전(deep supervision)을 특징으로 하는 새로운 의료 영상 분할 아키텍처를 제안했습니다.
- **의미론적 간극 감소**: 재설계된 스킵 경로가 인코더와 디코더 서브 네트워크 간의 특징 맵의 의미론적 간극을 줄여, 최적화 문제가 더 쉬워지고 학습 효율성을 높였습니다.
- **성능 향상**: U-Net 및 Wide U-Net 아키텍처 대비 다양한 의료 영상 분할 태스크에서 평균 IoU 점수를 각각 3.9점, 3.4점 향상시키는 우수한 성능을 달성했습니다.
- **딥 슈퍼비전을 통한 모델 가지치기(pruning) 가능**: 딥 슈퍼비전은 모델이 정확도와 추론 속도 사이의 균형을 조절하며 추론 시 가지치기될 수 있는 유연성을 제공합니다.

## 📎 Related Works

- **FCN [8] 및 U-Net [9]**: 이미지 분할을 위한 인코더-디코더 아키텍처의 초기 모델로, 스킵 연결을 도입하여 고해상도 특징 맵과 저해상도 특징 맵을 결합했습니다. U-Net은 특히 의료 영상 분할에서 널리 사용되었으나, 인코더와 디코더 특징 맵 간의 의미론적 간극 문제가 있었습니다.
- **DenseNet [5] 및 관련 연구**: DenseNet에서 영감을 받아 Li et al. [7]은 H-denseunet을 제안했고, Drozdzal et al. [2]은 스킵 연결의 중요성을 체계적으로 연구했습니다. 이들은 스킵 연결을 개선하려 했지만, 여전히 의미론적으로 이질적인 특징 맵을 융합하는 경향이 있었습니다.
- **GridNet [3]**: 그리드 형태로 특징 맵을 연결하는 인코더-디코더 아키텍처로, 여러 고전적인 분할 아키텍처를 일반화하지만, 스킵 연결 사이에 업샘플링 레이어가 없다는 점에서 UNet++와 차이가 있습니다.
- **Mask-RCNN [4]**: 객체 감지, 분류 및 인스턴스 분할을 위한 프레임워크로, UNet++는 Mask-RCNN의 백본 아키텍처로도 활용될 수 있습니다.

## 🛠️ Methodology

UNet++는 인코더-디코더 네트워크를 기반으로 하며, 기존 U-Net과 다음과 같은 주요 차이점을 가집니다.

1. **재설계된 스킵 경로 (Re-designed Skip Pathways)**:

   - U-Net이 인코더의 특징 맵을 디코더로 직접 전달하는 반면, UNet++에서는 이 특징 맵들이 중첩된(nested) 조밀 합성곱 블록(dense convolutional block)을 거치도록 합니다.
   - 이 블록은 피라미드 레벨에 따라 여러 합성곱 레이어로 구성됩니다. 각 합성곱 레이어는 동일한 조밀 블록의 이전 합성곱 레이어 출력과 하위 조밀 블록의 업샘플링된 출력을 연결(concatenation)하여 융합합니다.
   - 이러한 방식으로 인코더 특징 맵의 의미론적 수준을 디코더 특징 맵의 수준에 점진적으로 가깝게 만들어 "의미론적 간극"을 줄입니다. 이는 최적화 문제를 더 쉽게 만듭니다.
   - 노드 $X_{i,j}$의 출력 $x_{i,j}$는 다음과 같이 계산됩니다:
     $$x_{i,j} = \begin{cases} H(x_{i-1,j}), & j=0 \\ H\left(\left[\left[x_{i,k}\right]_{k=0}^{j-1}, U(x_{i+1,j-1})\right]\right), & j > 0 \end{cases}$$
     여기서 $H(\cdot)$는 활성화 함수가 뒤따르는 합성곱 연산, $U(\cdot)$는 업샘플링 레이어, $[\cdot]$는 연결 레이어를 나타냅니다.

2. **딥 슈퍼비전 (Deep Supervision)**:
   - UNet++는 중첩된 스킵 경로 덕분에 여러 의미론적 수준($\{x_{0,j}, j \in \{1,2,3,4\}\}$)에서 완전 해상도 특징 맵을 생성할 수 있습니다.
   - 각 출력 노드(즉, 각 분할 브랜치)에 이진 교차 엔트로피와 다이스 계수(Dice coefficient)의 조합으로 구성된 손실 함수를 적용합니다:
     $$L(Y, \hat{Y}) = -\frac{1}{N} \sum_{b=1}^{N} \left(\frac{1}{2} \cdot Y_b \cdot \log \hat{Y}_b + \frac{2 \cdot Y_b \cdot \hat{Y}_b}{Y_b + \hat{Y}_b}\right)$$
     여기서 $\hat{Y}_b$와 $Y_b$는 각각 $b$번째 이미지의 예측 확률과 실제 레이블(flattened)을 나타냅니다.
   - 이를 통해 모델은 두 가지 모드로 작동할 수 있습니다:
     - **정확 모드 (Accurate mode)**: 모든 분할 브랜치의 출력을 평균하여 최종 분할 맵을 생성하여 가장 높은 정확도를 제공합니다.
     - **고속 모드 (Fast mode)**: 하나의 분할 브랜치(출력 노드)만 선택하여 최종 분할 맵을 생성하며, 이는 모델 가지치기(pruning)를 가능하게 하여 추론 시간과 정확도 간의 유연한 균형을 조절할 수 있습니다.

## 📊 Results

본 논문은 세포 핵, 대장 용종, 간, 폐 결절 등 4가지 의료 영상 데이터셋을 사용하여 UNet++를 평가했습니다.

- **성능 우위**:
  - 딥 슈퍼비전이 적용된 UNet++는 U-Net 대비 평균 IoU에서 3.9점, Wide U-Net 대비 3.4점의 상당한 성능 향상을 달성했습니다.
  - Wide U-Net은 U-Net보다 더 많은 파라미터를 가졌음에도 불구하고, UNet++가 이를 뛰어넘는 성능을 보였습니다.
- **딥 슈퍼비전의 효과**:
  - 딥 슈퍼비전을 사용한 UNet++는 딥 슈퍼비전이 없는 UNet++보다 평균 0.6점의 IoU 향상을 보였습니다.
  - 특히 간 및 폐 결절 분할과 같이 다양한 스케일로 나타나는 객체에 대해 딥 슈퍼비전이 성능을 크게 향상시켰습니다.
- **모델 가지치기**:
  - 딥 슈퍼비전으로 학습된 UNet++는 추론 시 모델 가지치기가 가능하며, UNet++ L3 (가지치기 수준 3)는 IoU를 0.6점만 저하시키면서 추론 시간을 평균 32.2% 단축했습니다.
  - 이는 모델의 복잡성과 속도를 유연하게 조절할 수 있음을 보여주며, 다양한 임상 환경 요구사항에 맞춰 최적화될 수 있습니다.

## 🧠 Insights & Discussion

- **의미론적 간극 해소의 중요성**: 본 연구는 인코더와 디코더 특징 맵 간의 의미론적 간극을 줄이는 것이 최적화 과정을 단순화하고 의료 영상 분할 성능을 크게 향상시킬 수 있음을 입증했습니다. 이는 U-Net과 같은 기존 아키텍처의 한계를 명확히 지적하고 효과적인 해결책을 제시합니다.
- **다중 스케일 학습의 강점**: 딥 슈퍼비전은 특히 크기 변동이 큰 객체(예: 용종, 간)를 분할하는 데 효과적임을 보여주며, 모델이 다양한 스케일의 정보를 활용하여 견고한 예측을 할 수 있도록 돕습니다.
- **실용적인 유연성**: 딥 슈퍼비전을 통해 추론 시 모델 가지치기가 가능해져, 사용자는 특정 애플리케이션의 요구사항에 따라 정확도와 추론 속도 사이의 트레이드오프를 선택할 수 있습니다. 이는 임상 환경에서 모델의 적용 가능성을 높입니다.
- **제한 및 추가 연구**: 본 논문은 UNet++의 성능과 유연성을 명확히 보여주었지만, 각 가지치기 수준에서의 최적의 균형점이나 다른 백본 아키텍처(예: Mask R-CNN)와의 통합 등 추가적인 연구 가능성도 시사합니다.

## 📌 TL;DR

**문제**: 의료 영상 분할은 높은 정확도를 요구하지만, U-Net과 같은 기존 모델은 인코더-디코더 특징 맵 간의 '의미론적 간극'으로 인해 미세한 세부 사항에서 한계가 있었습니다.

**방법**: UNet++는 중첩된 조밀 스킵 경로를 재설계하여 이 간극을 줄이고, 딥 슈퍼비전을 도입하여 다중 스케일 학습 및 추론 시 유연한 모델 가지치기를 가능하게 했습니다.

**결과**: 4가지 의료 영상 데이터셋에서 U-Net 및 Wide U-Net보다 평균 IoU 성능을 각각 3.9점, 3.4점 향상시켰습니다. 딥 슈퍼비전은 특히 다중 스케일 객체 분할에 효과적임을 입증했으며, 추론 속도와 정확도 간의 유연한 조절을 가능하게 했습니다.
