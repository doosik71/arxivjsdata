{
  "title": "ED-SAM: An Efficient Diffusion Sampling Approach to Domain\n  Generalization in Vision-Language Foundation Models",
  "authors": "Thanh-Dat Truong, Xin Li, Bhiksha Raj, Jackson Cothren, Khoa Luu",
  "year": 2024,
  "url": "http://arxiv.org/abs/2406.01432v1",
  "abstract": "The Vision-Language Foundation Model has recently shown outstanding\nperformance in various perception learning tasks. The outstanding performance\nof the vision-language model mainly relies on large-scale pre-training datasets\nand different data augmentation techniques. However, the domain generalization\nproblem of the vision-language foundation model needs to be addressed. This\nproblem has limited the generalizability of the vision-language foundation\nmodel to unknown data distributions. In this paper, we introduce a new simple\nbut efficient Diffusion Sampling approach to Domain Generalization (ED-SAM) to\nimprove the generalizability of the vision-language foundation model. Our\ntheoretical analysis in this work reveals the critical role and relation of the\ndiffusion model to domain generalization in the vision-language foundation\nmodel. Then, based on the insightful analysis, we introduce a new simple yet\neffective Transport Transformation to diffusion sampling method. It can\neffectively generate adversarial samples to improve the generalizability of the\nfoundation model against unknown data distributions. The experimental results\non different scales of vision-language pre-training datasets, including CC3M,\nCC12M, and LAION400M, have consistently shown State-of-the-Art performance and\nscalability of the proposed ED-SAM approach compared to the other recent\nmethods."
}