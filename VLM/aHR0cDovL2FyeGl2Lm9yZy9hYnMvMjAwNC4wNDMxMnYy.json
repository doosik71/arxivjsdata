{
  "url": "http://arxiv.org/abs/2004.04312v2",
  "title": "Learning to Scale Multilingual Representations for Vision-Language Tasks",
  "authors": "Andrea Burns, Donghyun Kim, Derry Wijaya, Kate Saenko, Bryan A. Plummer",
  "year": 2020,
  "abstract": "Current multilingual vision-language models either require a large number of\nadditional parameters for each supported language, or suffer performance\ndegradation as languages are added. In this paper, we propose a Scalable\nMultilingual Aligned Language Representation (SMALR) that supports many\nlanguages with few model parameters without sacrificing downstream task\nperformance. SMALR learns a fixed size language-agnostic representation for\nmost words in a multilingual vocabulary, keeping language-specific features for\njust a few. We use a masked cross-language modeling loss to align features with\ncontext from other languages. Additionally, we propose a cross-lingual\nconsistency module that ensures predictions made for a query and its machine\ntranslation are comparable. The effectiveness of SMALR is demonstrated with ten\ndiverse languages, over twice the number supported in vision-language tasks to\ndate. We evaluate on multilingual image-sentence retrieval and outperform prior\nwork by 3-4% with less than 1/5th the training parameters compared to other\nword embedding methods."
}