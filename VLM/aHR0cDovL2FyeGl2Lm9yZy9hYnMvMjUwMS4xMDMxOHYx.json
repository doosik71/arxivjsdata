{
  "title": "HiMix: Reducing Computational Complexity in Large Vision-Language Models",
  "authors": "Xuange Zhang, Dengjie Li, Bo Liu, Zenghao Bao, Yao Zhou, Baisong Yang, Zhongying Liu, Yujie Zhong, Zheng Zhao, Tongtong Yuan",
  "year": 2025,
  "url": "http://arxiv.org/abs/2501.10318v1",
  "abstract": "Benefiting from recent advancements in large language models and modality\nalignment techniques, existing Large Vision-Language Models(LVLMs) have\nachieved prominent performance across a wide range of scenarios. However, the\nexcessive computational complexity limits the widespread use of these models in\npractical applications. We argue that one main bottleneck in computational\ncomplexity is caused by the involvement of redundant vision sequences in model\ncomputation. This is inspired by a reassessment of the efficiency of vision and\nlanguage information transmission in the language decoder of LVLMs. Then, we\npropose a novel hierarchical vision-language interaction mechanism called\nHierarchical Vision injection for Mixture Attention (HiMix). In HiMix, only the\nlanguage sequence undergoes full forward propagation, while the vision sequence\ninteracts with the language at specific stages within each language decoder\nlayer. It is striking that our approach significantly reduces computational\ncomplexity with minimal performance loss. Specifically, HiMix achieves a 10x\nreduction in the computational cost of the language decoder across multiple\nLVLM models while maintaining comparable performance. This highlights the\nadvantages of our method, and we hope our research brings new perspectives to\nthe field of vision-language understanding. Project Page:\nhttps://xuange923.github.io/HiMix"
}