# Show and Tell: Lessons learned from the 2015 MSCOCO Image Captioning Challenge

Oriol Vinyals, Alexander Toshev, Samy Bengio, and Dumitru Erhan

## 🧩 Problem to Solve

이 논문의 주요 목표는 이미지의 콘텐츠를 자연어 문장으로 자동 설명하는 생성 모델을 개발하는 것입니다. 이는 컴퓨터 비전과 자연어 처리 분야를 연결하는 근본적인 인공지능 문제로, 단순히 이미지 내의 객체를 식별하는 것을 넘어, 객체들 간의 관계, 속성, 그리고 관련된 활동까지 파악하여 유창하고 문법적으로 올바른 문장으로 표현해야 하므로 기존의 이미지 분류나 객체 인식보다 훨씬 어려운 과제입니다.

## ✨ Key Contributions

- **엔드-투-엔드(End-to-End) 신경망 시스템 제시:** 이미지 인코딩을 위한 심층 합성곱 신경망(CNN)과 문장 생성을 위한 순환 신경망(RNN)을 결합한 단일 시스템인 NIC(Neural Image Caption) 모델을 제안합니다. 이 모델은 확률적 경사 하강법을 사용하여 완전히 학습 가능합니다.
- **최첨단 서브 네트워크 결합:** 시각 이해를 위한 사전 학습된 CNN과 언어 모델링을 위한 LSTM(Long Short-Term Memory) RNN을 활용하여 대규모 코퍼스 학습의 이점을 통합합니다.
- **선도적인 성능 달성:** NIC 모델은 기존 최첨단 접근 방식 대비 Pascal(BLEU-1 25에서 59로), Flickr30k(56에서 66으로), SBU(19에서 28로) 등 여러 데이터셋에서 BLEU 점수를 크게 향상시켰습니다.
- **MSCOCO 챌린지 우승 및 개선 사항 분석:** 2015년 MSCOCO 이미지 캡셔닝 챌린지에서 공동 우승을 차지했으며, 챌린지 참가 과정에서 초기 모델에 적용된 다양한 개선 사항들(Batch Normalization 기반 이미지 모델, 이미지 모델 미세 조정, 스케줄드 샘플링, 앙상블, 빔 크기 축소)을 상세히 분석하고 그 효과를 보고합니다.
- **TensorFlow 오픈 소스 구현 제공:** 연구의 재현성을 위해 TensorFlow로 구현된 모델을 오픈 소스로 공개했습니다.

## 📎 Related Works

- **초기 비디오/정지 이미지 캡셔닝:** 전통적으로 시각적 원시 인식기와 구조화된 형식 언어 시스템(예: And-Or 그래프)을 결합하고 규칙 기반 시스템으로 자연어 변환하는 복잡한 수작업 시스템이 주를 이루었습니다.
- **객체 인식 기반 접근 방식:** Farhadi et al. [2], Li et al. [10], Kulkarni et al. [3] 등은 객체 감지 및 속성 인식을 사용하여 장면 요소의 트리플렛(triplet)을 추론하고 이를 템플릿 기반으로 텍스트로 변환했습니다. 이 방법들은 유연성이 떨어지는 한계가 있었습니다.
- **언어 파싱 기반 모델:** Mitchell et al. [11], Aker et al. [12] 등은 더 강력한 언어 모델을 사용하여 캡션을 생성했습니다.
- **설명 랭킹 문제:** Hodosh et al. [16], Gong et al. [17], Ordonez et al. [18] 등은 이미지와 텍스트를 동일한 벡터 공간에 공동으로 임베딩하여 주어진 이미지에 대한 설명을 검색하고 랭킹을 매기는 연구를 수행했습니다. 본 논문은 랭킹 태스크가 설명 생성 태스크를 평가하는 데 만족스럽지 않다고 지적합니다.
- **최근 신경망 기반 생성 모델:** Kiros et al. [26], Mao et al. [27, 28], Donahue et al. [30] 등은 신경망을 사용하여 다음 단어를 예측하거나 이미지-텍스트 공동 임베딩을 구축하는 방식을 제안했습니다. NIC는 강력한 RNN 모델을 사용하고 시각적 입력을 RNN에 직접 제공하여 객체 추적을 가능하게 함으로써 이전 작업 대비 성능을 크게 개선했습니다. 또한, Xu et al. [31], Karpathy et al. [32] 등은 어텐션 메커니즘을 탐구하여 문장 부분과 이미지 영역의 명시적인 시각적 연결을 모델링하는 연구도 진행되었습니다.

## 🛠️ Methodology

NIC 모델은 이미지를 입력으로 받아 해당 이미지를 설명하는 단어 시퀀스 $S = \{S_0, S_1, \dots, S_N\}$을 생성하는 생성 모델입니다. 모델은 주어진 훈련 이미지 $I$에 대해 목표 설명 문장 $S$의 우도(likelihood) $p(S|I;\theta)$를 최대화하도록 훈련됩니다.

1. **확률 공식화:** 목표는 모델 파라미터 $\theta$에 대해 다음을 최대화하는 것입니다:
   $$ \theta^{\*} = \arg \max*{\theta} \sum*{(I,S)} \log p(S|I;\theta) $$
    문장의 길이가 가변적이므로, 조건부 확률의 연쇄 법칙(chain rule)을 사용하여 각 단어 $S_t$의 확률을 이전 단어들과 이미지에 기반하여 모델링합니다:
   $$ \log p(S|I) = \sum*{t=0}^{N} \log p(S_t|I, S_0, \dots, S*{t-1}) $$

2. **아키텍처:**

   - **CNN 인코더 (Vision CNN):** 입력 이미지 $I$를 고정 길이 벡터 표현으로 임베딩합니다. ILSVRC 2014 분류 경쟁에서 최고 성능을 달성한 Batch Normalization [24]을 사용하는 CNN 모델을 활용합니다. 이 CNN은 이미지 분류 태스크로 사전 학습된 후, 마지막 히든 레이어가 RNN의 입력으로 사용됩니다.
   - **LSTM 디코더 (Language Generating RNN):** CNN에서 추출된 이미지 벡터를 초기 상태로 받아 문장을 생성하는 RNN의 일종인 LSTM을 사용합니다. LSTM은 소멸/폭발 기울기(vanishing/exploding gradients) 문제를 잘 처리하며, 입력 게이트($i_t$), 망각 게이트($f_t$), 출력 게이트($o_t$)를 통해 메모리 셀 $c_t$의 상태를 제어하여 장기 의존성을 학습합니다. 각 단어는 워드 임베딩 $W_e$를 통해 표현됩니다.

3. **훈련(Training):**

   - LSTM 모델은 이미지와 모든 선행 단어 $S_0, \dots, S_{t-1}$가 주어진 상황에서 각 단어 $S_t$를 예측하도록 훈련됩니다.
   - 이미지 $I$는 시간 단계 $t=-1$에 한 번만 CNN을 통해 처리되어 $x_{-1} = \text{CNN}(I)$로 LSTM에 입력됩니다. 이후 각 시간 단계 $t \in \{0, \dots, N-1\}$에서는 이전 단어 $S_t$의 워드 임베딩 $x_t = W_e S_t$가 LSTM에 입력되어 다음 단어의 확률 분포 $p_{t+1} = \text{LSTM}(x_t)$를 출력합니다.
   - 손실 함수는 각 단계에서 올바른 단어에 대한 음의 로그 우도(negative log likelihood)의 합입니다: $L(I,S) = -\sum_{t=1}^{N} \log p_t(S_t)$.
   - 훈련 중 과적합을 방지하기 위해 CNN 가중치는 ImageNet으로 사전 학습된 모델로 초기화하며, 드롭아웃(dropout)과 모델 앙상블 기법을 적용합니다.

4. **추론(Inference):**
   - **빔 탐색(Beam Search):** 주어진 이미지에 대해 문장을 생성하기 위해 빔 탐색을 사용합니다. 각 시간 단계에서 상위 $k$개의 가장 좋은 부분 문장 후보들을 유지하고, 이를 확장하여 다음 단어를 생성합니다. 초기 실험에서는 빔 크기 20을 사용했으나, MSCOCO 챌린지에서는 CIDER 점수 기준 최적 빔 크기가 3으로 나타났습니다.
   - **샘플링(Sampling):** 각 단어를 $p_t$에 따라 샘플링하는 방법도 가능하지만, 빔 탐색이 더 나은 성능을 보였습니다.

## 📊 Results

- **정량적 평가:**
  - **BLEU-1 점수:** Pascal (59), Flickr30k (66), Flickr8k (63), SBU (28)에서 기존 최첨단 모델을 크게 능가했습니다. 인간 성능(Human)은 각각 69, 68, 70으로 NIC의 높은 성능을 보여주었습니다.
  - **MSCOCO 개발 세트 (NICv2):** BLEU-4 (32.1), METEOR (25.7), CIDEr (99.8)을 달성하여 인간 성능(BLEU-4 21.7, METEOR 25.2, CIDEr 85.4)을 뛰어넘는 자동 평가 지표를 보였습니다.
- **MSCOCO 챌린지 결과:**
  - **자동 평가:** Google팀(본 논문의 모델)이 CIDER 0.943, BLEU-4 0.309로 1위를 차지했습니다.
  - **인간 평가:** Google팀은 M1(인간 캡션보다 좋거나 같은 캡션 비율), M2(튜링 테스트 통과 비율) 기준으로 Microsoft Research와 함께 공동 1위를 차지했습니다.
- **전이 학습 및 데이터셋 크기:** Flickr30k(Flickr8k보다 약 4배 큼)에서 훈련 시 4 BLEU 포인트 향상 등 데이터셋 크기가 클수록 성능이 향상됨을 확인했습니다. MSCOCO 모델을 Pascal에 전이했을 때도 좋은 성능을 보였습니다.
- **생성 다양성:** 빔 탐색에서 N-best 리스트를 분석한 결과, 모델이 다양하고 고품질의 설명을 생성하며, 훈련 세트에 없는 새로운 문장도 절반 가량 생성함을 확인했습니다.
- **랭킹 태스크:** 이미지 어노테이션 및 이미지 검색 랭킹 태스크에서도 다른 최첨단 모델에 뒤지지 않는 우수한 성능을 보여주었습니다.
- **임베딩 분석:** 학습된 워드 임베딩 공간에서 "car"와 "van", "boy"와 "toddler", "horse"와 "pony"처럼 의미론적으로 유사한 단어들이 서로 가깝게 위치함을 보여주었습니다.

## 🧠 Insights & Discussion

- **데이터 주도 접근 방식의 잠재력:** NIC와 같은 엔드-투-엔드 데이터 주도 접근 방식은 대규모 데이터셋이 있을 때 기존의 수작업 엔지니어링 방식보다 훨씬 뛰어난 성능을 발휘할 수 있음을 입증했습니다.
- **과적합(Overfitting) 관리의 중요성:** 이미지 캡셔닝 데이터셋의 크기가 상대적으로 작기 때문에 과적합이 주요 과제였습니다. 사전 학습된 CNN 가중치 사용, 드롭아웃, 앙상블, 스케줄드 샘플링, 빔 크기 감소 등 다양한 정규화 기법이 성능 향상에 필수적이었습니다.
- **CNN 미세 조정의 효과:** LSTM 훈련 후 CNN 모델을 미세 조정함으로써, ImageNet 클래스에 과적합되어 버려질 수 있는 색상과 같은 미묘한 특징들을 캡셔닝 모델이 더 잘 활용할 수 있게 되어 설명의 질이 향상되었습니다.
- **훈련-추론 불일치 문제 및 해결:** 스케줄드 샘플링은 훈련 시 실제 이전 단어를 사용하고 추론 시 모델이 생성한 단어를 사용하는 훈련-추론 간의 불일치를 완화하여 성능을 개선했습니다.
- **빔 크기 선택의 의미:** 빔 탐색 시 예상과 달리 작은 빔 크기(3)가 최적의 CIDER 점수를 제공했습니다. 이는 모델이 훈련 데이터에 과적합되었거나, 우도(likelihood)를 최대화하는 목적 함수가 인간의 판단과 완벽하게 일치하지 않을 수 있음을 시사합니다. 작은 빔 크기는 생성된 문장의 참신성을 증가시키는 일종의 정규화 효과를 가졌습니다.
- **평가 지표의 한계:** 자동 평가 지표(특히 BLEU)가 인간 평가와 완벽하게 상관관계를 가지지 않음을 시사하며, 더 나은 평가 지표 개발의 필요성을 강조합니다.
- **향후 연구 방향:** 생성된 설명이 이미지의 다양한 해석 중 하나이므로, 특정 이미지 속성이나 위치에 앵커링되거나 사용자 질문에 응답하는 등 더 목표 지향적인 설명을 생성하는 시스템, 그리고 로봇 공학과 같은 응용 분야의 고수준 목표를 통한 평가 연구가 필요하다고 제언합니다.

## 📌 TL;DR

이 논문은 이미지를 자연어 문장으로 자동 설명하는 엔드-투-엔드(end-to-end) 신경망 모델인 NIC를 제안합니다. 이미지 인코딩을 위해 사전 학습된 CNN을, 문장 생성을 위해 LSTM RNN을 결합하여 $p(S|I)$를 최대화하도록 훈련됩니다. NIC는 여러 데이터셋에서 기존 최첨단 모델을 크게 능가하는 성능을 달성했으며, 2015년 MSCOCO 이미지 캡셔닝 챌린지에서 다양한 개선(Batch Normalization 기반 CNN, 미세 조정, 스케줄드 샘플링, 앙상블, 빔 크기 축소)을 통해 자동 및 인간 평가 모두에서 공동 1위를 차지했습니다. 연구는 데이터 주도 방식의 강력한 잠재력과 과적합 방지, 훈련-추론 불일치 해결의 중요성을 강조하며, 향후 더 정확하고 유연한 이미지 설명을 위한 발전 가능성을 제시합니다.
