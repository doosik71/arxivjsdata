{
  "title": "LLaVA-Interactive: An All-in-One Demo for Image Chat, Segmentation,\n  Generation and Editing",
  "authors": "Wei-Ge Chen, Irina Spiridonova, Jianwei Yang, Jianfeng Gao, Chunyuan Li",
  "year": 2023,
  "url": "http://arxiv.org/abs/2311.00571v1",
  "abstract": "LLaVA-Interactive is a research prototype for multimodal human-AI\ninteraction. The system can have multi-turn dialogues with human users by\ntaking multimodal user inputs and generating multimodal responses. Importantly,\nLLaVA-Interactive goes beyond language prompt, where visual prompt is enabled\nto align human intents in the interaction. The development of LLaVA-Interactive\nis extremely cost-efficient as the system combines three multimodal skills of\npre-built AI models without additional model training: visual chat of LLaVA,\nimage segmentation from SEEM, as well as image generation and editing from\nGLIGEN. A diverse set of application scenarios is presented to demonstrate the\npromises of LLaVA-Interactive and to inspire future research in multimodal\ninteractive systems."
}