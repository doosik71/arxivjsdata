# Language Features Matter: Effective Language Representations for Vision-Language Tasks
Andrea Burns, Reuben Tan, Kate Saenko, Stan Sclaroff, Bryan A. Plummer

## 🧩 Problem to Solve
많은 시각-언어(Vision-Language, VL) 태스크 접근 방식들은 언어 구성 요소를 부차적으로 취급하여, 주로 텍스트 데이터로 학습된 고정된 단어 임베딩을 사용하거나 처음부터 학습된 간단한 언어 모델을 활용합니다. 이로 인해 VL 태스크에서 언어 피처의 잠재력이 충분히 발휘되지 못하고, 어떤 단어 임베딩, 언어 모델, 임베딩 증강 단계가 VL 태스크에 가장 효과적인지에 대한 포괄적인 비교 연구가 부족합니다. 본 논문은 언어 피처의 중요성을 강조하고, VL 태스크에 최적화된 언어 표현을 탐색합니다.

## ✨ Key Contributions
*   **포괄적인 실험:** 다섯 가지 일반적인 시각-언어 태스크(이미지-문장 검색, 이미지 캡셔닝, 시각 질의 응답, 구문 접지, 텍스트-클립 검색)에 걸쳐 다양한 단어 표현, 언어 모델, 사전 학습 및 적응 단계를 광범위하게 비교하여 향후 연구를 위한 최적의 관행을 제시합니다.
*   **GrOVLE 임베딩 개발:** WordNet과 Visual Genome의 시각-언어 그래프를 활용하여 Word2Vec을 개조(retrofitting)한 새로운 단어 임베딩인 GrOVLE(Graph Oriented Vision-Language Embedding)를 제안하고 공개적으로 제공합니다. GrOVLE는 시각-언어 태스크에 특화하여 학습됩니다.
*   **다중 태스크 학습을 통한 통찰:** 다섯 가지 시각-언어 태스크 전반에 걸쳐 단어 임베딩의 전이 가능성에 대한 핵심 통찰력을 제공하며, 다중 태스크 학습이 임베딩 성능을 향상시키는 효과를 입증합니다.

## 📎 Related Works
*   **개선된 단어 임베딩:** 기존 연구들은 시각 정보를 사용하여 단어 임베딩을 개선하려는 시도를 했습니다 (예: 시각 피처 연결 [25], 추상적인 장면 집중 [29], 시각-언어 임베딩 간 정렬 유도 [32]). 일부는 학습 과정에 제약 조건을 추가하거나 [64] 후처리 단계로 [14] 임베딩을 개선했습니다. GrOVLE는 이러한 접근 방식과 달리, 다양한 시각-언어 태스크에서 잘 작동하도록 직접 최적화되었습니다.
*   **언어 모델 개선:** 단어 임베딩 대신 언어 모델 자체를 개선하려는 시도도 있었습니다. 여기에는 사전 학습된 단어 임베딩 위에 Fisher 벡터 구축 [27], 단어 순서 제약 [11], 공동 참조 해결 [58] 등이 포함됩니다. 또한, 어텐션 메커니즘 [1, 12, 37, 41]이 성능 향상에 널리 사용되었습니다.

## 🛠️ Methodology
본 논문은 다양한 언어 모델 및 단어 임베딩 조합을 사용하여 다섯 가지 시각-언어 태스크에서 성능을 비교하고, 새로운 임베딩 GrOVLE를 제안합니다.

1.  **비교 대상 언어 모델:**
    *   **Average Embedding (평균 임베딩):** 문장 내 모든 단어 임베딩의 평균 풀링(mean pooling)을 통해 단일 표현을 생성한 후, 완전 연결(FC) 레이어를 통과시킵니다.
    *   **LSTM:** 각 단어 임베딩을 LSTM 셀에 개별적으로 통과시켜 은닉 상태를 생성합니다. 단어 순서 정보를 유지하는 것으로 가정됩니다.
    *   **Self-Attention (셀프-어텐션):** 평균 임베딩과 유사하지만, 단어별 컨텍스트 "점수"를 부여하는 어텐션 메커니즘을 사용하여 단어 임베딩의 가중합(weighted sum)을 생성합니다.
2.  **비교 대상 단어 임베딩:**
    *   **기존 임베딩:** 무작위 초기화(from-scratch), Word2Vec [39], FastText [4], InferSent [8], BERT [10].
    *   **시각-언어 적응 임베딩:** WordNet 개조 Word2Vec [14], Visual Word2Vec [29], HGLMM Fisher Vectors [27].
    *   **제안된 GrOVLE:**
        *   Word2Vec 임베딩을 WordNet [40]과 Visual Genome [31]의 관계 그래프를 사용하여 개조합니다.
        *   Visual Genome 그래프는 이미지 주석에서 단어 쌍의 동시 발생 통계 및 점별 상호 정보량(Pointwise Mutual Information, PMI)을 계산하여 시각적 맥락에서 함께 자주 발생하는 단어들을 연결하여 구축됩니다.
3.  **다중 태스크 학습:**
    *   GrOVLE 임베딩을 실험에 사용된 다섯 가지 VL 태스크(Image-Sentence Retrieval, Phrase Grounding, Text-to-Clip, Image Captioning, Visual Question Answering) 모두에서 미세 조정합니다.
    *   각 태스크 학습 시, 이전 태스크에서 학습된 가장 유익한 $K = D/T$개($D$: 임베딩 차원, $T$: 총 태스크 수) 피처를 고정하여 치명적인 망각(catastrophic forgetting)을 방지합니다.
4.  **평가 태스크:**
    *   **Image-Sentence Retrieval:** 이미지-문장, 문장-이미지 검색. 평가 지표: Recall@K (K=[1,5,10]) 평균.
    *   **Phrase Grounding:** 이미지에서 구문의 위치 찾기. 평가 지표: IOU (Intersection over Union) 0.5 이상 정확도.
    *   **Text-to-Clip:** 비디오에서 질의에 해당하는 시간 영역 찾기. 평가 지표: Recall@K (K=[1,5]) 및 평균 IOU.
    *   **Image Captioning:** 이미지 설명 문장 생성. 평가 지표: BLEU-4 (CIDEr, METEOR는 부록에).
    *   **Visual Question Answering (VQA):** 이미지와 질문에 대한 자연어 답변 생성. 평가 지표: 정확도.

## 📊 Results
*   **언어 모델 비교:** 검색 기반 태스크(이미지-문장 검색, 구문 접지)에서는 평균 임베딩(Average Embedding) 및 셀프-어텐션(Self-Attention) 언어 모델이 LSTM보다 더 나은 성능을 보였습니다. 이들은 파라미터 수가 적고 계산이 더 빠릅니다. 텍스트-클립 태스크에서는 단어 순서가 중요하여 LSTM이 강점을 보였습니다.
*   **미세 조정의 효과:** 시각-언어 태스크에 단어 임베딩을 미세 조정(fine-tuning)하는 것이 성능에 지대한 영향을 미칩니다 (예: 이미지-문장 검색에서 평균 Recall 5-10% 증가).
*   **최신 NLP 임베딩의 한계:** InferSent 및 BERT는 순수 NLP 태스크에서는 최고 성능을 보이지만, 본 연구의 시각-언어 태스크에서는 기존 Word2Vec 모델만큼 좋은 결과를 제공하지 못했습니다.
*   **GrOVLE의 성능:** WordNet과 Visual Genome을 사용하여 Word2Vec을 개조한 GrOVLE는 대부분의 시각-언어 태스크에서 작지만 일관된 성능 향상을 보였습니다. 특히 300-D 임베딩 크기에서 HGLMM보다 좋은 성능을 보였습니다.
*   **다중 태스크 학습의 이점:** 다섯 가지 태스크에 걸쳐 다중 태스크 학습을 적용한 GrOVLE는 단일 태스크로 학습된 버전보다 더 강력한 단어 표현력을 보였으며, 특히 이미지-문장 검색 태스크에서 큰 성능 향상을 달성하며 전반적으로 선두 임베딩 옵션이 되었습니다.

## 🧠 Insights & Discussion
*   **언어 피처의 중요성:** 시각-언어 태스크에서 언어 피처는 시각 피처만큼 중요하게 다루어져야 합니다. 최적의 임베딩, 언어 모델, 학습 방식을 선택함으로써 성능을 크게 향상시킬 수 있습니다.
*   **언어 모델 선택의 재고:** LSTM이 항상 더 나은 선택이라는 일반적인 가정은 시각-언어 태스크에서는 통하지 않습니다. 특히 검색 스타일 태스크에서는 평균 임베딩이나 셀프-어텐션과 같은 더 간단한 모델이 더 효율적이고 효과적일 수 있습니다. LSTM은 특정 태스크에 과적합될 수 있으며, 사전 학습된 임베딩은 이미 충분한 문맥 정보를 포함하고 있을 수 있습니다.
*   **시각적 맥락의 통합:** GrOVLE와 같이 WordNet의 계층적 언어 관계와 Visual Genome의 시각적 맥락을 통합한 임베딩은 시각-언어 태스크를 위해 특별히 학습되어 우수한 성능을 제공합니다.
*   **다중 태스크 학습을 통한 일반화:** 외부 시각-언어 데이터셋과 태스크에서 학습된 단어 임베딩은 다른 애플리케이션으로 잘 일반화됩니다. 다중 태스크 학습은 임베딩에 미묘한 시각 정보를 추가로 통합하여 전이 가능성을 높이고 전반적인 성능을 향상시킵니다.
*   **태스크별 영향:** 언어 피처는 검색 및 접지(grounding) 태스크에서 가장 큰 영향을 미치며, 텍스트-클립 및 생성 태스크에서는 상대적으로 영향이 적었습니다. 이는 생성 태스크 평가의 어려움이나 모델 아키텍처의 차이 때문일 수 있습니다.
*   **한계:** 생성 기반 태스크(이미지 캡셔닝, VQA)의 평가 지표는 언어 모델 개선의 미묘한 부분을 완전히 포착하지 못할 수 있습니다.

## 📌 TL;DR
본 논문은 시각-언어(VL) 태스크에서 언어 피처가 종종 간과되고 있음을 지적하며, 다양한 언어 모델과 단어 임베딩에 대한 포괄적인 비교를 수행했습니다. 연구 결과, 검색 기반 태스크에서는 LSTM보다 더 간단한 평균 임베딩이나 셀프-어텐션 모델이 더 효과적이고 효율적임을 발견했습니다. 또한, WordNet과 Visual Genome 그래프를 활용하여 VL 태스크에 최적화된 새로운 단어 임베딩인 GrOVLE를 제안했습니다. 특히, GrOVLE를 여러 VL 태스크에서 다중 태스크 학습시킨 결과, 단일 태스크 학습보다 뛰어난 일반화 성능과 향상된 결과를 보였습니다. 이는 언어 피처를 신중하게 선택하고 VL 맥락에 맞춰 학습하는 것이 VL 태스크 성능에 결정적인 영향을 미친다는 통찰을 제공합니다.