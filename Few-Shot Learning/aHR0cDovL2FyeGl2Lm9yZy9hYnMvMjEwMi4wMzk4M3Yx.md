# Partial Is Better Than All: Revisiting Fine-tuning Strategy for Few-shot Learning

Zhiqiang Shen, Zechun Liu, Jie Qin, Marios Savvides and Kwang-Ting Cheng

## 🧩 Problem to Solve

Few-shot 학습의 목표는 제한된 수의 레이블이 지정된 지원 데이터(support data)를 사용하여 이전에 본 적 없는 클래스를 인식할 수 있는 분류기를 학습하는 것입니다. 이 task를 위한 일반적인 방법은 먼저 기본 클래스(base classes)로 모델을 훈련시킨 다음, 미세 조정(fine-tuning) 또는 메타 학습(meta-learning)을 통해 새로운 클래스(novel classes)로 지식을 전이하는 것입니다. 그러나 기본 클래스와 새로운 클래스 간에는 겹치는 부분이 없으므로, 기본 모델의 모든 지식을 단순히 전이하는 것은 최적의 해결책이 아닙니다. 기본 모델의 일부 지식은 새로운 클래스에 대해 편향되거나 심지어 해로울 수 있기 때문입니다. 기존 접근 방식은 백본(backbone) 네트워크를 완전히 고정하거나 전체 레이어를 미세 조정하는 경향이 있어, 도메인 불일치(domain discrepancy) 문제나 과적합(overfitting) 문제에 취약합니다.

## ✨ Key Contributions

* **부분 전이(Partial Transfer, P-Transfer) 프레임워크 제안**: Few-shot 분류를 위한 P-Transfer를 제안하여, 유연한 미세 조정을 위해 백본 네트워크의 전이 전략을 탐색할 수 있도록 합니다. 기존의 고정된 전이 방식은 모든 레이어가 고정된 P-Transfer의 특별한 경우로 간주될 수 있습니다.
* **효율적인 진화 탐색 기반 방법 도입**: 어떤 레이어를 고정하고 어떤 레이어를 미세 조정할지, 그리고 미세 조정할 레이어에 어떤 학습률(learning rate)을 할당할지를 동시에 결정하는 효율적인 진화 탐색(evolutionary search) 기반 방법을 개발했습니다. 이는 제한된 탐색 복잡성으로 높은 정확도를 달성합니다.
* **최첨단 성능 달성**: 제안된 P-Transfer 모델은 기존의 완전 전이(complete transfer) 및 수동 설계 전이 전략보다 뛰어난 성능을 보입니다. CUB 및 mini-ImageNet 데이터셋에서 메타 학습 및 비-메타 학습 기반 프레임워크 모두에서 최첨단(state-of-the-art) 성능을 달성했습니다.
* **기존 전이 학습 패러다임으로 확장 가능성 입증**: ImageNet에서 CUB200-2011로의 전통적인 사전 훈련 + 미세 조정(pre-training + fine-tuning) 패러다임에도 적용하여 일관된 성능 향상을 보여주며, 방법론의 효과성과 확장성을 입증했습니다.

## 📎 Related Works

* **메타 학습 기반 Few-shot 학습**: MatchingNet (Vinyals et al. 2016), ProtoNet (Snell, Swersky, and Zemel 2017), MAML (Finn, Abbeel, and Levine 2017) 등 모델 또는 옵티마이저를 학습하여 새로운 task에 빠르게 적응하는 방법들이 있습니다.
* **비-메타 Few-shot 학습**: 코사인 유사도(cosine similarity)를 활용하여 분류기 가중치를 예측하거나 (Gidaris and Komodakis 2018), Baseline++ (Chen et al. 2019)와 같이 클래스 내(intra-class) 변동을 줄이는 방법 등이 있습니다. 이들 방법은 주로 고정된 특징 추출기를 사용합니다.
* **신경망 아키텍처 탐색(NAS) 기반 Few-shot 학습**: 진화 알고리즘(evolutionary algorithm)이 최적의 신경망 아키텍처를 찾는 데 사용되었으며 (Real et al. 2017; Miikkulainen et al. 2019), 일부 연구는 NAS를 메타 학습과 통합하기도 했습니다 (Elsken et al. 2020). 본 논문은 아키텍처가 아닌 미세 조정 스키마 탐색에 중점을 둡니다.
* **다양한 학습률 학습**: Meta-SGD (Li et al. 2017) 및 MAML++ (Antoniou, Edwards, and Storkey 2018)는 각 레이어에 대해 다양한 학습률을 학습할 수 있지만, 주로 MAML-like 메타 학습 시나리오에 특화되어 있습니다. P-Transfer는 학습률을 0으로 설정하여 레이어를 고정할 수 있는 더 일반적인 설계를 제공합니다.

## 🛠️ Methodology

본 논문의 방법론은 세 가지 주요 단계로 구성됩니다:

1. **기본 클래스 사전 훈련 (Base class pre-training)**
    * **비-메타 방법**: 풍부한 기본 클래스 샘플을 사용하여 표준 교차 엔트로피(cross-entropy) 손실을 최소화하여 특징 추출기를 처음부터 훈련시킵니다.
    * **메타 학습 방법**: 메타-사전 훈련(meta-pretraining) 전략에 따라 기본 클래스에서 지원 세트와 쿼리 세트를 샘플링하고, N-way 예측 손실을 최소화하도록 모델 파라미터를 훈련합니다.

2. **진화 탐색 (Evolutionary Search)**
    * **목표**: 기본 클래스에서 새로운 클래스로 지식을 전이하는 최적의 미세 조정 전략 $V^{*}_{lr}$를 찾는 것입니다. $V_{lr} = [v_1, v_2, ..., v_L]$는 각 레이어에 대한 학습률을 정의하며, $L$은 총 레이어 수입니다. 최적의 전략은 다음을 최대화합니다:
        $$V^{*}_{lr} = \arg \max \text{Acc}(W, V_{lr})$$
    * **탐색 공간**: 모델 아키텍처의 레이어 수 ($K$)와 학습률 선택지 수 ($m$)에 따라 $m^{K}$로 정의됩니다. 예를 들어, 학습률 선택지를 $\{0, 0.01, 0.1, 1.0\}$ (여기서 $0$은 레이어 고정을 의미)로 둔다면 $m=4$입니다.
    * **알고리즘**: 진화 알고리즘(Algorithm 1)을 따릅니다.
        1. **초기화**: $R$개의 미세 조정 전략($v$)을 무작위로 샘플링하고, 검증 세트(validation set)에서 정확도를 평가합니다. 상위 $K$개의 전략을 부모 개체군으로 선택합니다.
        2. **반복**: 미리 정해진 반복 횟수($I$) 동안 다음을 수행합니다.
            * **변이(Mutation)**: 부모 개체군에서 변이를 통해 새로운 자손 전략을 생성합니다.
            * **교차(Crossover)**: 두 부모 전략을 교차하여 새로운 자손 전략을 생성합니다.
            * **평가 및 업데이트**: 생성된 자손 전략들을 검증 세트에서 평가하고, 전체 개체군에서 상위 $K$개의 전략을 선택하여 다음 세대를 구성합니다.
        3. **최종 선택**: 반복이 끝나면 가장 높은 검증 정확도를 보인 전략 $v^{*}$를 최종 미세 조정 구성으로 선택합니다.

3. **탐색된 전략을 통한 부분 전이 (Partially transfer via searched strategy)**
    * 최종 단계에서는 진화 탐색을 통해 발견된 최적의 부분 미세 조정 전략을 새로운 클래스의 지원 세트에 적용하여 기본 네트워크를 미세 조정합니다. 이는 기존의 백본 고정 또는 전체 미세 조정 방식과 달리, 제한된 새로운 데이터에 더 잘 적응하고 과적합을 방지하며, 편향되거나 해로운 지식의 전이를 피하는 데 도움을 줍니다.
    * 이 프레임워크는 Baseline++ 및 ProtoNet과 같은 기존 Few-shot 분류 프레임워크에 쉽게 통합될 수 있습니다.

## 📊 Results

* **고정 및 수동 설계 미세 조정과의 비교**: Conv6 및 ResNet-12 구조를 CUB 및 mini-ImageNet에 적용한 결과, 제안된 진화 탐색 전략은 백본을 고정하거나 수동으로 정의된 (예: 마지막 컨볼루션 레이어만 미세 조정하는) 전략보다 일관되게 더 나은 정확도를 달성했습니다 (표 2, 3 참조).
* **교차 도메인 설정에서 정규화 레이어 비교**: 교차 도메인 Few-shot 학습 task (mini-ImageNet에서 CUB로 지식 전이)에서 Batch Normalization (BatchNorm) 대신 Group Normalization (GroupNorm)을 사용했을 때 약 2~8% 더 높은 정확도를 얻었습니다 (표 4 참조). 이는 작은 배치 크기(batch size)로 인해 발생하는 전통적인 BatchNorm의 최적화 문제를 GroupNorm이 극복할 수 있음을 보여줍니다.
* **탐색된 스키마 분석**:
  * 더 깊은 네트워크 (Conv6 vs. ResNet-12)는 Few-shot 학습을 위해 더 많은 레이어를 미세 조정해야 함을 나타냈습니다.
  * 교차 도메인 전이 학습(cross-domain transfer-learning)의 경우, 도메인 차이가 커짐에 따라 대상 도메인에 지식을 적응시키기 위해 더 많은 레이어의 미세 조정이 필요했습니다 (그림 4 참조).
* **최종 결과 및 최첨단 성능**: P-Transfer 방법은 mini-ImageNet 데이터셋에서 1-shot 및 5-shot 설정 모두에서 기존의 최첨단 방법들을 일관되게 능가했습니다 (표 5 참조). DropBlock, 레이블 스무딩(label smoothing)과 같은 추가적인 훈련 기법 없이도 유연한 전이/미세 조정을 통해 상당한 개선을 이루었습니다.
* **전통적인 전이 학습으로의 확장**: ImageNet에서 CUB200-2012로의 Inception V3 네트워크를 사용한 전통적인 전이 학습에서도 부분적으로 가중치를 재초기화하고 미세 조정하는 것이 모든 가중치를 상속하고 미세 조정하는 것보다 더 높은 정확도(83.8% vs 82.9%)를 달성하여 P-Transfer의 효과를 입증했습니다 (표 6 참조).

## 🧠 Insights & Discussion

* **Few-shot 학습에서 전이의 본질적인 역할**: Few-shot 학습 환경에서 사전 훈련된 특징 추출기는 기본 객체에서 새로운 클래스로 공통 지식을 적절히 전이하는 것이 필수적입니다. 그러나 새로운 데이터는 소량이고 특징 추출기에 민감하므로, 기본 클래스에는 불필요하거나 심지어 해로운 정보가 포함될 수 있습니다. 전체 전이 전략은 이러한 문제를 피할 수 없어, 본 방법론이 Few-shot 시나리오에 더 적합한 해결책임을 시사합니다.
* **왜 부분 전이가 전체 전이보다 나은가?**: 일반적으로 기본 클래스와 새로운 클래스는 동일한 도메인에 속하지만, 도메인 차이가 존재하는 경우 (예: 교차 도메인 전이 학습), 대상 도메인에 지식을 적응시키기 위해 더 많은 레이어를 미세 조정해야 합니다. P-Transfer는 다양한 학습률을 사용하여 특정 레이어를 부분적으로 미세 조정함으로써 이러한 어려운 상황에 대처할 수 있습니다. 고정 전이는 본 전략의 특수한 경우이므로, P-Transfer는 Few-shot 학습에서 더 큰 잠재력을 가집니다.
* **향후 연구**: 부분 전이가 Few-shot 문제에 어떻게 기여하는지에 대한 더 많은 분석이 필요합니다. 또한, 본 방법을 탐지(detection), 분할(segmentation)과 같은 다른 Few-shot task에 적용하여 제안된 전이 방법의 한계를 탐구할 수 있습니다.
* **윤리적 영향**:
  * **긍정적 영향**: 의료 영상, 희귀 동물 분류 등 데이터 수집 비용이 높은 분야에서 시스템 구축에 기여하여, 소량의 레이블 데이터만으로도 빠른 일반화가 가능하게 합니다.
  * **부정적 영향**: 시스템의 오분류(misclassification)로 인해 신뢰할 수 없는 결론 (예: 의료 이미지의 잘못된 질병 진단)이 발생할 수 있으므로, 결과의 신뢰성에 주의해야 합니다.

## 📌 TL;DR

Few-shot 학습에서 기존의 지식 전이 전략(백본 고정 또는 전체 미세 조정)은 기본 클래스와 새로운 클래스 간의 도메인 불일치로 인해 편향되거나 해로운 지식을 전이하여 성능이 저하될 수 있습니다. 본 논문은 **부분 전이(P-Transfer)** 방법을 제안하여, 진화 탐색(evolutionary search)을 통해 어떤 레이어를 고정하고 어떤 레이어를 다양한 학습률로 미세 조정할지 자동으로 결정합니다. 이 방법은 백본 네트워크의 유연한 적응을 가능하게 하여, CUB 및 mini-ImageNet 데이터셋에서 메타 학습 및 비-메타 학습 기반 방법 모두에서 **최첨단 성능**을 달성했습니다. 또한, 기존의 전이 학습에도 적용 가능함을 보여주며, 제한된 데이터로 새로운 클래스에 적응하는 데 **부분 전이가 전체 전이보다 우수**하다는 것을 입증했습니다.
