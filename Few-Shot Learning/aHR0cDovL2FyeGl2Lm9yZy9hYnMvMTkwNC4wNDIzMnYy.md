# A CLOSER LOOK AT FEW-SHOT CLASSIFICATION

Wei-Yu Chen, Yen-Cheng Liu, Zsolt Kira, Yu-Chiang Frank Wang, Jia-Bin Huang

## 🧩 Problem to Solve

Few-shot 분류는 훈련 중 보지 못한 클래스를 제한된 수의 레이블된 예시(labeled examples)만으로 인식하는 분류기를 학습하는 것을 목표로 합니다. 그러나 이 분야는 다음과 같은 몇 가지 문제에 직면해 있습니다.

* **공정 비교의 어려움**: 복잡한 네트워크 디자인, 메타 학습(meta-learning) 알고리즘, 그리고 구현 세부 사항의 차이로 인해 다양한 방법론 간의 성능을 공정하게 비교하기 어렵습니다. 특히, 베이스라인(baseline) 방법의 성능이 데이터 증강(data augmentation) 등의 부족으로 과소평가되는 경향이 있었습니다.
* **비현실적인 평가 설정**: 기존 few-shot 분류 평가 시나리오는 대부분 베이스(base) 클래스와 새로운(novel) 클래스가 동일한 데이터셋에서 샘플링되어, 실제 환경에서 발생할 수 있는 상당한 도메인 시프트(domain shift)가 고려되지 않아 현실성이 떨어집니다.

## ✨ Key Contributions

이 논문은 few-shot 분류 문제에 대한 심층적인 경험적 연구를 통해 다음과 같은 핵심 기여를 제시합니다:

* **일관된 비교 분석**: 여러 대표적인 few-shot 분류 알고리즘에 대한 일관된 비교 분석을 제공합니다. 이를 통해 더 깊은 백본(backbone)을 사용할 경우, 제한된 도메인 차이를 가진 데이터셋에서 방법들 간의 성능 격차가 크게 줄어든다는 것을 보여줍니다.
* **수정된 베이스라인(Baseline++) 제안**: 클래스 내 변동(intra-class variation)을 명시적으로 줄이는 거리 기반 분류기(distance-based classifier)를 사용하는 수정된 베이스라인 방법인 Baseline++를 제안합니다. 이 방법은 mini-ImageNet 및 CUB 데이터셋 모두에서 최신 메타 학습 알고리즘과 경쟁적인 성능을 달성합니다.
* **새로운 교차 도메인(Cross-Domain) 평가 설정 도입**: few-shot 분류 알고리즘의 도메인 간 일반화 능력(cross-domain generalization ability)을 평가하기 위한 새로운 실험 설정을 도입합니다. 이 설정에서 기존의 복잡한 few-shot 학습 알고리즘들이 베이스라인보다 낮은 성능을 보인다는 것을 밝혀, 도메인 시프트 적응의 중요성을 강조합니다.
* **백본 깊이와 클래스 내 변동의 관계**: 얕은 백본에서는 클래스 내 변동 감소가 성능에 중요한 요소였으나, 깊은 백본을 사용할 경우 그 중요성이 상대적으로 감소함을 보여줍니다.

## 📎 Related Works

논문은 few-shot 학습 방법론들을 세 가지 주요 범주로 분류하고, 도메인 적응(domain adaptation)과의 관련성을 언급합니다.

* **Initialization based methods**: "미세 조정을 학습하는(learning to fine-tune)" 접근 방식으로, 소수의 경사 업데이트(gradient update)만으로 새로운 클래스 분류기를 학습할 수 있도록 좋은 모델 초기화(예: MAML (Finn et al., 2017))를 배우거나, 옵티마이저(optimizer)를 학습하는 데 중점을 둡니다 (예: Ravi & Larochelle, 2017).
* **Distance metric learning based methods**: "비교를 학습하는(learning to compare)" 접근 방식으로, 이미지 간 유사도를 학습하여 분류합니다. 주요 예시로는 MatchingNet (Vinyals et al., 2016), ProtoNet (Snell et al., 2017), RelationNet (Sung et al., 2018) 등이 있으며, 본 논문의 Baseline++와 유사한 거리 기반 분류기를 사용하는 Gidaris & Komodakis (2018)와 Qi et al. (2018)의 연구도 언급됩니다.
* **Hallucination based methods**: "데이터 증강을 학습하는(learning to augment)" 접근 방식으로, 생성 모델을 사용하여 새로운 클래스 데이터를 가상으로 생성하여 데이터 부족 문제를 해결합니다 (예: Antoniou et al., 2018; Hariharan & Girshick, 2017). (본 연구의 비교 대상에서는 제외됨)
* **Domain adaptation**: 소스 도메인과 타겟 도메인 간의 도메인 시프트를 줄이는 데 목표를 두며 (Pan et al., 2010; Ganin & Lempitsky, 2015), 본 연구는 few-shot 학습의 맥락에서 도메인 차이의 영향을 조사합니다.

## 🛠️ Methodology

이 논문은 표준 전이 학습(transfer learning) 기반의 베이스라인 모델과 메타 학습 알고리즘을 비교 분석합니다.

* **Baseline Model**:
  * **훈련 단계(Training stage)**: 특징 추출기 $f_{\theta}$와 선형 분류기 $C(\cdot|W_{b})$를 다수의 베이스 클래스 데이터 $X_{b}$를 사용하여 표준 교차 엔트로피(cross-entropy) 손실로 처음부터(from scratch) 훈련합니다.
  * **미세 조정 단계(Fine-tuning stage)**: 사전 훈련된 특징 추출기 $f_{\theta}$의 파라미터 $\theta$를 고정하고, 소수의 새로운 클래스 데이터 $X_{n}$ (지원 집합)을 사용하여 새로운 분류기 $C(\cdot|W_{n})$를 훈련합니다.
* **Baseline++ Model**:
  * Baseline과 동일한 훈련 및 미세 조정 절차를 따르지만, 분류기 디자인에서 차이가 있습니다.
  * 선형 분류기 대신 **거리 기반 분류기**를 사용합니다. 입력 특징 $f_{\theta}(x_{i})$와 각 클래스 가중치 벡터 $w_{j}$ 간의 **코사인 유사도** $s_{i,j} = f_{\theta}(x_{i})^{\top} w_{j} / (\lVert f_{\theta}(x_{i}) \rVert \lVert w_{j} \rVert)$를 계산하고, 이를 소프트맥스 함수로 정규화하여 예측합니다.
  * 이 방식은 훈련 중에 클래스 내 변동을 명시적으로 줄이는 효과가 있으며, 학습된 가중치 벡터는 각 클래스의 "프로토타입(prototype)" 역할을 합니다.
* **Meta-Learning Algorithms**:
  * **메타 훈련 단계(Meta-training stage)**: $N$개의 클래스를 무작위로 선택하고, 각 클래스에서 소수의 지원 집합 $S_{b}$와 쿼리 집합 $Q_{b}$를 샘플링합니다. 지원 집합 $S_{b}$에 조건화된 분류 모델 $M$을 훈련하여 쿼리 집합 $Q_{b}$에 대한 $N$-way 예측 손실을 최소화합니다.
  * **메타 테스트 단계(Meta-testing stage)**: 모든 새로운 클래스 데이터 $X_{n}$를 지원 집합 $S_{n}$으로 간주하고, 분류 모델 $M$을 새로운 클래스에 적응시켜 예측합니다.
  * **포함된 방법**: MatchingNet, ProtoNet (거리 기반), RelationNet (학습 가능한 관계 모듈), MAML (초기화 기반)을 비교 대상으로 사용합니다.

## 📊 Results

* **표준 설정에서의 성능**:
  * Conv-4 백본을 사용한 mini-ImageNet 및 CUB 데이터셋 실험에서, 데이터 증강이 적용된 Baseline 모델은 기존에 과소평가되었던 성능을 크게 향상시킵니다.
  * Baseline++는 Baseline보다 훨씬 우수한 성능을 보이며, 두 데이터셋 모두에서 MatchingNet, ProtoNet, MAML, RelationNet과 같은 최신 메타 학습 방법들과 경쟁적입니다. 이는 클래스 내 변동을 줄이는 것이 few-shot 분류에서 중요한 요소임을 입증합니다.
* **네트워크 깊이 증가의 효과**:
  * Conv-4에서 ResNet-34까지 백본의 깊이를 증가시킴에 따라, CUB 데이터셋에서는 다양한 방법들 간의 성능 격차가 크게 줄어들고 전반적인 정확도가 향상됩니다.
  * mini-ImageNet 5-shot 설정에서는 깊은 백본 사용 시 Baseline과 Baseline++가 일부 메타 학습 방법들보다 더 나은 성능을 달성합니다. 깊은 백본은 특징 공간에서 클래스 내 변동을 효과적으로 줄여줍니다.
* **교차 도메인 시나리오(mini-ImageNet → CUB)**:
  * 베이스 클래스(mini-ImageNet)와 새로운 클래스(CUB) 사이에 상당한 도메인 시프트가 존재하는 시나리오에서, **Baseline 모델이 모든 평가된 메타 학습 방법들을 능가**합니다.
  * 이는 메타 학습 방법들이 훈련 시 경험하지 못한 큰 도메인 차이에 효과적으로 적응하지 못함을 시사합니다. Baseline++는 이러한 시나리오에서 Baseline보다 낮은 성능을 보이는데, 이는 클래스 내 변동 감소가 때로는 적응력을 저해할 수 있음을 나타냅니다.
* **추가 적응(Further Adaptation)의 효과**:
  * MatchingNet과 MAML에 Baseline 방식의 추가 적응(예: 특징 고정 후 소프트맥스 분류기 훈련)을 적용했을 때, 특히 교차 도메인 시나리오에서 성능이 크게 향상됩니다. 이는 이들 방법이 적응성 부족으로 Baseline에 뒤처졌을 수 있음을 의미합니다.
  * 그러나 추가 적응이 항상 긍정적인 것은 아니며, ProtoNet의 경우 오히려 성능 저하를 가져올 수도 있습니다. 이는 메타 훈련 단계에서 '적응하는 방법'을 학습하는 것의 중요성을 강조합니다.

## 🧠 Insights & Discussion

* **백본의 중요성**: 이 연구는 특징 추출을 담당하는 백본 네트워크의 깊이가 few-shot 분류 성능에 미치는 지대한 영향을 보여줍니다. 특히, 깊은 백본은 클래스 내 변동을 효과적으로 줄여주며, 이로 인해 다양한 few-shot 학습 방법들 간의 성능 격차가 감소하고, 심지어 단순한 베이스라인 모델조차도 최신 메타 학습 방법과 경쟁하거나 능가할 수 있음을 시사합니다.
* **Baseline++의 잠재력**: 명시적으로 클래스 내 변동을 줄이는 Baseline++는 기존의 복잡한 메타 학습 알고리즘에 필적하는 강력하고 효과적인 베이스라인이 될 수 있음을 입증합니다. 이는 few-shot 학습에서 "어떻게 학습할 것인가"보다 "무엇을 학습할 것인가" (즉, 좋은 특징 표현)가 더 중요할 수 있음을 시사합니다.
* **도메인 시프트의 과제**: 기존 few-shot 분류 알고리즘들이 베이스 클래스와 새로운 클래스 간의 도메인 시프트에 매우 취약하다는 점을 밝혀냈습니다. 실제 세계의 응용에서는 이러한 도메인 차이가 흔하게 발생하므로, 현재 방법론들의 현실 적용에는 한계가 있음을 지적합니다. 단순한 전이 학습 기반의 Baseline 모델이 이러한 시나리오에서 더 잘 작동하는 것은 기존 메타 학습 방법들의 '적응 능력'이 실제 도메인 변화에 충분하지 않음을 시사합니다.
* **미래 연구 방향**: 메타 훈련 단계에서 '적응하는 방법(learning to adapt)' 자체를 학습하는 것이 향후 few-shot 학습 연구의 핵심 방향이 될 것이라고 제안합니다. 특히, 도메인 시프트에 강건하게 적응할 수 있는 메타 학습 알고리즘 개발이 중요합니다.
* **공정한 평가 환경의 필요성**: 기존 few-shot 분류 평가 설정의 한계를 지적하고, 일관된 비교 평가 환경과 소스 코드 공개를 통해 커뮤니티가 더욱 현실적인 문제 해결을 향해 나아갈 수 있도록 기여하고자 합니다.

## 📌 TL;DR

Few-shot 분류의 공정한 비교를 가로막는 요소(구현 차이)와 비현실적인 평가 설정(도메인 시프트 부재) 문제를 다루기 위해, 다양한 few-shot 알고리즘을 일관된 환경에서 비교했습니다. 이 연구는 클래스 내 변동을 줄이는 거리 기반 분류기를 사용하는 **Baseline++**를 제안했으며, 이는 최신 메타 학습 방법들과 경쟁적인 성능을 보였습니다. 특히, 베이스/새로운 클래스 간 **도메인 시프트가 있는 현실적인 시나리오**에서는 단순한 **Baseline 모델**이 모든 평가된 메타 학습 알고리즘보다 **우수한 성능**을 보였습니다. 또한, **깊은 백본**은 다양한 방법들 간의 성능 격차를 줄이며 클래스 내 변동을 효과적으로 줄인다는 것을 밝혔고, 메타 훈련 단계에서 '**적응하는 방법**'을 학습하는 것이 미래 few-shot 연구의 중요한 방향임을 강조했습니다.
