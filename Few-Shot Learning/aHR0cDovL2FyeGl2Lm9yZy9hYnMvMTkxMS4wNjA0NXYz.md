# SELF-SUPERVISED LEARNING FOR FEW-SHOT IMAGE CLASSIFICATION

Da Chen, Yuefeng Chen, Yuhong Li, Feng Mao, Yuan He, Hui Xue

## 🧩 Problem to Solve

소수의 레이블된 샘플만으로 새로운 클래스를 분류해야 하는 퓨샷 이미지 분류(Few-shot Image Classification)는 딥러닝 모델이 대규모 레이블 데이터셋에 의존하는 한계를 드러냅니다. 기존 메타 학습 기반 퓨샷 분류 방법론들은 효율적인 임베딩 네트워크에 크게 의존하지만, 제한된 레이블 데이터로 인해 대규모 임베딩 네트워크를 지도 학습 방식으로 훈련할 경우 과적합(overfitting) 문제로 성능에 병목 현상(bottleneck)이 발생합니다. 본 논문은 이러한 한계를 극복하고, 대규모 임베딩 네트워크가 퓨샷 학습에 효과적으로 사용될 수 있도록 하는 일반화된 임베딩 학습 방법을 제안합니다.

## ✨ Key Contributions

* **자기 지도 학습(Self-supervised Learning, SSL) 기반 임베딩 네트워크 제안**: 레이블이 없는 데이터로부터 강력하고 일반화된 임베딩 표현을 학습하는 새로운 퓨샷 분류 프레임워크를 제안했습니다.
* **대규모 임베딩 네트워크의 효과 입증**: SSL을 통해 기존 지도 학습 방식으로는 어려웠던 대규모 임베딩 네트워크(AmdimNet)를 퓨샷 학습에 성공적으로 적용하여 성능 향상을 이끌었습니다.
* **우수한 성능 달성**: MiniImageNet 및 CUB 데이터셋에서 기존 베이스라인 방법론들을 크게 능가하는 최첨단(state-of-the-art) 분류 정확도를 달성했습니다.
* **도메인 간(Cross-domain) 전이성 입증**: 4개의 크로스-도메인 퓨샷 학습 데이터셋(ChestX, ISIC, EuroSAT, CropDiseases)에서 강력한 전이성(transferability)과 SOTA 결과를 보여, 제안된 모델의 견고함을 증명했습니다.
* **레이블되지 않은 데이터의 활용 가치**: 더 많은 레이블되지 않은 데이터를 활용하여 임베딩 네트워크를 사전 학습할 경우, 퓨샷 분류 성능이 더욱 향상됨을 보였습니다.

## 📎 Related Works

* **메타 학습 (Meta-learning)**: 제한된 학습 데이터로 모델을 빠르게 적응시키는 방법을 학습하는 접근법입니다. Matching Networks [11], MAML [12], Relation Network [13], REPTILE [14], Prototypical Networks [15] 등이 대표적입니다.
* **임베딩 네트워크 개선**: 효율적인 임베딩 네트워크는 퓨샷 학습에서 핵심 요소입니다. ResNet12 [5] 또는 Wide-ResNet [6]과 같은 네트워크가 주로 사용되었으며, 깊은 네트워크(예: ResNet-50)는 과적합 문제로 인해 사용이 제한적이었습니다 [8, 16].
* **자기 지도 학습 (Self-supervised Learning, SSL)**: 레이블 없이 데이터 자체에서 유용한 표현을 학습하는 방법입니다. 다양한 프리텍스트 태스크(pretext tasks)가 연구되었으며 [17], 최근 퓨샷 학습과 SSL을 결합하려는 시도 [18, 19]가 있었습니다. 본 논문은 기존 연구와 달리 SSL을 통해 *대규모* 임베딩 네트워크의 가능성을 탐구합니다.

## 🛠️ Methodology

본 논문은 퓨샷 이미지 분류를 위해 자기 지도 학습(SSL)과 메타 학습(Meta-learning)을 결합한 2단계 프레임워크를 제안합니다.

### Stage A: Self-supervised Image Pre-train (자기 지도 이미지 사전 학습)

1. **목표**: 하류 태스크(downstream tasks)에 일반화되고 견고한 특징 임베딩 네트워크를 학습합니다.
2. **SSL 모델**: Augmented Multiscale Deep InfoMax (AMDIM) [20]를 활용합니다.
3. **프리텍스트 태스크 (Pretext Task)**: 동일한 이미지 $x$에서 데이터 증강(data augmentation)을 통해 생성된 두 가지 뷰 $x_a$와 $x_b$ 간의 특징(feature) 상호 정보량(mutual information, MI)을 최대화하도록 설계됩니다.
    * **상호 정보량($I(X,Y)$)**: 두 확률 변수 $X$와 $Y$ 사이의 공유 정보를 측정하며, 다음과 같이 정의됩니다.
        $$I(X,Y) = D_{KL}(p(x,y)||p(x)p(y)) = \sum\sum p(x,y) \log \frac{p(x|y)}{p(x)}$$
        여기서 $D_{KL}$은 쿨백-라이블러 발산(Kullback–Leibler divergence)입니다.
    * **NCE Loss를 통한 MI 최대화**: 상호 정보량을 직접 추정하기 어렵기 때문에, Noise Contrastive Estimation (NCE) [21] 손실 함수를 최소화하여 상호 정보량의 하한(lower bound)을 최대화합니다.
    * **구체적인 MI 최대화**: $f_g(x_a)$ (첫 번째 뷰 $x_a$의 전역 특징)와 $f_5(x_b)$ (두 번째 뷰 $x_b$의 $5 \times 5$ 지역 특징), $f_g(x_a)$와 $f_7(x_b)$ ($7 \times 7$ 지역 특징), 그리고 $f_5(x_a)$와 $f_5(x_b)$ 간의 상호 정보량을 최대화합니다.
    * **NCE 손실 예시**: $f_g(x_a)$와 $f_5(x_b)$ 간의 NCE 손실은 다음과 같습니다.
        $$L_{ssl}(f_g(x_a), f_5(x_b)) = -\log \frac{\exp\{\varphi(f_g(x_a),f_5(x_b))\}}{\sum_{\tilde{x}_b \in N_x \cup x_b} \exp\{\varphi(f_g(x_a),f_5(\tilde{x}_b))\}}$$
        여기서 $N_x$는 이미지 $x$의 음성 샘플(negative samples)이며, $\varphi$는 거리 측정 함수입니다.
    * **총 SSL 손실**: $x_a$와 $x_b$ 간의 최종 SSL 손실은 다음과 같습니다.
        $$L_{ssl}(x_a,x_b) = L_{ssl}(f_g(x_a),f_5(x_b)) + L_{ssl}(f_g(x_a),f_7(x_b)) + L_{ssl}(f_5(x_a),f_5(x_b))$$
4. **임베딩 네트워크**: AmdimNet(ndf=192, ndepth=8, nrkhs=1536)을 사용하며, 이는 대규모 네트워크입니다.

### Stage B: Meta-learning (메타 학습)

1. **목표**: Stage A에서 사전 학습된 임베딩 네트워크를 에피소드 방식으로 미세 조정(fine-tuning)하여 새로운 클래스에 빠르게 적응하도록 합니다.
2. **퓨샷 태스크**: $K$-way $C$-shot 분류 태스크(예: 5-way 1-shot)로 구성됩니다.
3. **클래스 대표 벡터 (Centroid)**: 각 클래스 $k$에 대해, 서포트 셋(support set) $S_k$에 있는 샘플들의 임베딩 특징 평균을 사용하여 중심점 $c_k$를 계산합니다.
    $$c_k = \frac{1}{|S_k|} \sum_{(x_i,y_i)\in S_k} f(x_i)$$
    여기서 $f(x_i)$는 사전 학습된 임베딩 함수입니다.
4. **쿼리 샘플(Query Sample) 분류**: 쿼리 셋(query set) $Q$의 샘플 $q$가 주어졌을 때, 해당 샘플의 임베딩 $f(q)$와 각 클래스 중심점 $c_k$ 간의 거리(유클리드 거리 사용)를 기반으로 클래스 확률을 예측합니다.
    $$p(y=k|q) = \frac{\exp(-d(f(q),c_k))}{\sum_{k'} \exp(-d(f(q),c_{k'}))}$$
5. **메타 학습 손실**: 쿼리 샘플 $q$의 실제 클래스 $k$와 예측된 클래스 간의 거리를 사용하여 손실 함수를 정의합니다.
    $$L_{meta} = d(f(q),c_k) + \log \sum_{k'} d(f(q),c_{k'})$$

## 📊 Results

* **MiniImageNet 데이터셋**: 제안된 방법은 모든 테스트 태스크에서 베이스라인을 능가했습니다.
  * 1-shot 5-way: 64.03%의 정확도를 달성하여 ProtoNet$^+$ [15] (56.50%) 및 LEO [4] (61.76%) 대비 각각 약 7.5%, 2.3% 향상되었습니다.
  * 5-shot 5-way: 81.15%의 정확도를 달성하여 ProtoNet$^+$ (74.2%) 및 LEO (77.59%) 대비 각각 약 6.9%, 3.5% 향상되었습니다.
  * 더 많은 레이블되지 않은 데이터(ImageNet-1K의 900개 클래스)로 사전 학습 시, 1-shot에서 76.82%, 5-shot에서 90.98%의 정확도를 달성하며 베이스라인 대비 약 15%의 성능 향상을 보였습니다.
* **CUB-200-2011 데이터셋**:
  * 1-shot 5-way: 71.85%의 정확도를 달성하여 ProtoNet [15] (51.31%) 대비 약 20.5%의 큰 향상을 보였습니다.
  * 5-shot 5-way: 84.29%의 정확도를 달성하여 DN4-DA [31] (81.90%) 대비 약 2.4% 향상되었습니다.
  * ImageNet-1K로 사전 학습된 모델은 CUB 데이터셋에서 1-shot 77.09%, 5-shot 89.18%로 더 높은 성능을 기록하며 뛰어난 전이성을 입증했습니다.
* **크로스-도메인 퓨샷 학습 (4개 데이터셋)**: ChestX, ISIC, EuroSAT, CropDiseases 4개 데이터셋에서 5-way 5/20/50-shot 태스크에 대한 평균 테스트 결과, 제안된 방법은 SOTA [9] 대비 약 1.5%의 추가 개선을 보이며 모델의 강력한 견고함과 도메인 전이성을 증명했습니다.
* **Ablation Study (요소 연구)**: SSL 없이 지도 학습 방식으로 대규모 네트워크를 사전 학습한 경우, 제한된 데이터로 인해 과적합되어 오히려 낮은 성능을 보였습니다. 이는 SSL이 대규모 네트워크의 잠재력을 퓨샷 학습에 활용하는 데 필수적임을 보여줍니다. 또한, 메타 학습 단계가 임베딩 네트워크를 효과적으로 미세 조정하여 성능을 크게 향상시킴을 확인했습니다.

## 🧠 Insights & Discussion

* **자기 지도 학습의 중요성**: 본 연구의 핵심은 자기 지도 학습이 퓨샷 학습을 위한 강력하고 일반화된 임베딩 네트워크를 훈련하는 데 매우 효과적이라는 점을 보여주었습니다. 특히, 대규모 네트워크를 사용할 때 레이블된 데이터가 부족하여 발생하는 과적합 문제를 SSL이 해결함으로써, 네트워크 용량의 제약을 극복할 수 있음을 입증했습니다.
* **일반화 및 전이성 향상**: SSL을 통해 사전 학습된 임베딩 네트워크는 데이터 자체의 풍부한 시각적 정보를 학습하여, 새로운 클래스와 도메인에 대한 뛰어난 일반화 및 전이성을 보였습니다. 이는 특히 레이블 데이터가 희소한 실제 시나리오에서 큰 이점을 제공합니다.
* **메타 학습의 역할**: SSL이 강력한 초기 임베딩을 제공하지만, 에피소드 방식의 메타 학습을 통한 미세 조정은 모델이 새로운 태스크에 빠르게 적응하고 분류 성능을 더욱 끌어올리는 데 필수적인 보완적 역할을 합니다.
* **한계 및 향후 연구**: 현재 프레임워크는 2단계로 구성되어 있으며, 향후 두 단계를 통합한 End-to-End 방식의 방법론 개발이 가능합니다. 또한, 퓨샷 객체 탐지(few-shot detection)와 같은 다른 퓨샷 태스크에 대한 제안된 방법의 효과를 탐구하는 것도 유망한 연구 방향입니다.

## 📌 TL;DR

레이블 데이터가 부족한 퓨샷 이미지 분류에서 대규모 임베딩 네트워크의 활용도를 높이기 위해, 본 논문은 자기 지도 학습(SSL)을 통한 사전 학습과 메타 학습 기반의 미세 조정을 결합한 2단계 프레임워크를 제안합니다. SSL은 레이블 없는 데이터로부터 일반화된 특징을 학습시켜 대규모 네트워크의 과적합 문제를 해결하며, 이후 메타 학습으로 새로운 클래스에 빠르게 적응합니다. 제안된 방법은 MiniImageNet 및 CUB 데이터셋에서 SOTA 성능을 달성했으며, 도메인 간 퓨샷 학습에서도 뛰어난 전이성과 견고함을 입증하여, 대규모 SSL 임베딩 네트워크가 퓨샷 분류의 핵심임을 보여주었습니다.
