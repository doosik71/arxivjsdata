# FlexKBQA: A Flexible LLM-Powered Framework for Few-Shot Knowledge Base Question Answering

Zhenyu Li, Sunqi Fan, Yu Gu, Xiuxing Li, Zhichao Duan, Bowen Dong, Ning Liu, Jianyong Wang

## 🧩 Problem to Solve

기존 지식 기반 질의 응답(KBQA) 시스템은 대규모의 수동으로 주석 처리된 데이터셋에 크게 의존하지만, 지식 베이스(KB)의 방대한 크기와 복잡성, 그리고 진화하는 내용으로 인해 이러한 데이터셋을 수집하고 유지하는 데 막대한 비용이 듭니다. 특히 소수 샘플(few-shot) 환경에서는 모델의 성능이 크게 저하되는 경향이 있습니다. 대규모 언어 모델(LLM)은 유망한 대안으로 떠올랐지만, 제한된 컨텍스트 윈도우, 높은 추론 비용, 도메인별 KB의 복잡성 처리의 어려움과 같은 고유한 제약에 직면합니다. 본 연구는 이러한 수동 주석의 부담을 줄이고 LLM의 한계를 극복하며, 제한된 수의 주석만으로도 다양한 KB에 효율적으로 적용할 수 있는 유연한 KBQA 프레임워크를 개발하는 것을 목표로 합니다.

## ✨ Key Contributions

* **LLM 기반 유연한 KBQA 프레임워크 제시**: LLM의 강력한 생성 능력을 활용하여 효율적이고 유연한 KBQA 프레임워크를 제안합니다.
* **실행-유도 자기 훈련(Execution-Guided Self-Training, EGST) 전략 도입**: 합성 데이터와 실제 사용자 질문 간의 분포 차이를 해결하기 위해, LLM의 내재적 추론 능력을 활용하여 이질적인 정보 간의 상호작용을 촉진하는 EGST를 제안합니다.
* **뛰어난 실험 결과**: 다양한 실제 데이터셋(GrailQA, WebQSP, KQA Pro)에서 FlexKBQA가 모든 이전 기준 모델들을 크게 능가하며, 심지어 소수의 주석만으로도 완전 지도 학습 모델에 근접하는 성능을 달성함을 입증했습니다.
* **제로샷 KBQA 탐색**: 소수의 주석조차 없는 제로샷 KBQA 시나리오를 탐색한 최초의 연구 중 하나입니다.

## 📎 Related Works

* **지식 기반 질의 응답 (KBQA)**: 자연어 질문을 SPARQL 쿼리 같은 형식 언어로 변환하는 의미 분석(semantic parsing) 접근법이 주류이며, 최근에는 검색 공간을 줄이고 오류를 줄이기 위한 단계별 판별 접근법이 발전했습니다. 하지만 이들은 대규모 주석 데이터에 의존합니다.
* **LLM을 활용한 소수 샘플 언어 이해**: LLM이 질문을 프로그램으로 변환하는 인컨텍스트 학습(in-context learning) 방식을 통해 소수 샘플 환경에서 강력한 성능을 보여주었습니다(Pangu, KB-BINDER). 그러나 LLM의 컨텍스트 윈도우 제한과 높은 비용이라는 한계가 있습니다.
* **LLM과 경량 모델의 결합**: LLM의 지식을 경량 모델로 증류하거나, LLM을 "교사(teacher)" 모델로 사용하여 합성 데이터를 생성하고 이를 "학생(student)" 모델 훈련에 사용하는 "데이터를 통한 교육(teaching via data, TvD)" 패러다임이 연구되었습니다. 본 연구는 LLM을 프로그램 번역기로 활용하여 KBQA 훈련 데이터 주석의 어려움을 해결하는 TvD 패러다임을 채택합니다.

## 🛠️ Methodology

FlexKBQA는 LLM의 생성 능력을 활용하여 합성 데이터를 생성하고 경량 모델을 훈련하는 유연한 KBQA 프레임워크입니다.

1. **자동 프로그램 샘플링 (Automatic Program Sampling)**:
    * **템플릿 수집**: SPARQL 쿼리 같은 구조화된 질의에서 엔티티와 관계를 변수로 대체하여 다양한 질문 유형을 커버하는 "템플릿"을 수집합니다.
    * **단계별 그라운딩 (Step-wise Grounding)**: 수집된 템플릿의 변수들을 KB에서 유효한 엔티티와 관계로 반복적으로 그라운딩하여 실행 가능한 프로그램을 대량으로 생성합니다. 이 과정은 검색 공간을 효율적으로 줄이면서도 다양성을 유지합니다.
2. **저자원 프로그램 번역 (Low-Resource Program Translation)**:
    * LLM을 프로그램 번역기($\text{Translator}$)로 활용하여, 생성된 프로그램($p^s_i$)을 자연어 질문($q^s_i$)으로 변환합니다. 이는 LLM이 자연어에 더 잘 훈련되어 있어 질문에서 프로그램으로의 변환보다 프로그램에서 질문으로의 변환이 더 효율적이라는 가정에 기반합니다.
    * 프롬프트는 변환 지침($\text{Inst}$)과 소수의 시드 프로그램-질문 쌍($\{ (p^f_1, q^f_1), \dots, (p^f_N, q^f_N) \}$)으로 구성되며, 제로샷($N=0$) 설정도 지원합니다.
    * 생성된 프로그램-질문 쌍은 경량 모델 파인튜닝을 위한 합성 데이터셋으로 사용됩니다.
3. **실행-유도 자기 훈련 (Execution-Guided Self-Training, EGST)**:
    * 합성 데이터와 실제 사용자 질문 간의 분포 불일치(distribution shift) 문제를 해결하기 위한 반복적인 교사-학생 학습 방식입니다.
    * **초기 모델 훈련**: LLM이 생성한 합성 데이터와 소수의 실제 레이블 데이터($D_s \cup D_f$)로 교사 모델($\theta_{tea}$)을 훈련합니다.
    * **가상 레이블 생성**: 교사 모델은 레이블이 없는 실제 사용자 질문($D_u$)에 대해 가상 프로그램($p^u_i$)을 생성합니다.
    * **실행-유도 필터링 (Execution-guided Filtering)**: 생성된 가상 프로그램에 대해 다음 필터링 규칙을 적용하여 노이즈 데이터를 제거하고 훈련 데이터셋의 순도를 높입니다.
        * **오류 필터링**: 실행 오류가 발생하거나 답변을 검색하지 못하는 쿼리-질문 쌍을 제거합니다.
        * **의미 필터링**: 문장 변환기(sentence-transformer)를 사용하여 자연어 질문과 예측된 프로그램 내 관계 간의 의미적 유사도를 계산하여 낮은 유사도를 가진 쌍을 제거합니다.
        * **내재적 추론 필터링**: 가상 답변이 내재적 추론(Inherent Reasoning) 결과와 일치하지 않는 샘플을 제외합니다.
    * **학생 모델 훈련 및 업데이트**: 필터링된 데이터셋을 포함한 모든 데이터를 사용하여 학생 모델($\theta_{stu}$)을 훈련하고, 이를 다음 반복의 교사 모델로 업데이트합니다. 이 과정은 수렴할 때까지 반복됩니다.
4. **내재적 추론 증강 (Inherent Reasoning Augmentation)**:
    * LLM이 자체 매개변수에 인코딩된 지식을 활용하여 복잡한 질문에 직접 답변하는 내재적 추론(IR)을 데이터 증강 기술로 사용합니다.
    * **EGST 단계에서의 활용**: 가상 프로그램을 통해 얻은 답변과 IR을 통해 얻은 답변이 일치하는 샘플만 선택하여 훈련 데이터셋의 노이즈를 추가로 줄입니다.
    * **보완적 접근 방식**: 의미 분석 방법이 답변을 검색하지 못할 때(예: 실행 오류), IR의 결과를 최종 답변으로 사용하여 시스템의 강건성(robustness)을 향상시킵니다.

이러한 핵심 구성 요소들을 통해 FlexKBQA는 데이터 효율성, 도메인 불가지론(domain-agnostic), 배포 용이성(경량 모델 사용)의 유연성을 달성합니다.

## 📊 Results

FlexKBQA는 소수 샘플(few-shot) 환경에서 이전 모델들보다 훨씬 우수한 성능을 보였습니다.

* **GrailQA**: 25개의 주석 샘플만으로 EM 62.8, F1 69.4를 달성하여, 더 많은 샷(100샷)을 사용한 이전 SOTA 모델인 Pangu를 F1 스코어에서 6.7점 차이로 능가했습니다. 심지어 ReTraCk와 같은 여러 지도 학습 모델을 능가하며, 완전 지도 학습 RnG-KBQA 모델 성능의 93%에 육박하는 성과를 보였습니다.
* **WebQSP**: 100샷 설정에서 Pangu 대비 F1 스코어를 6.1점 향상시켰으며, 몇몇 완전 지도 학습 모델과 비교 가능한 결과를 달성했습니다.
* **KQA Pro**: 엔티티 연결 단계가 없다는 점 때문에 성능 차이가 있었지만, LLM-ICL과 같은 인컨텍스트 학습 모델을 크게 앞섰습니다.
* **제로샷(Zero-Shot) KBQA**: 주석 샘플이 전혀 없는 더 어려운 제로샷 환경에서도 상당한 잠재력을 보여주었습니다.
* **EGST 및 IR의 기여**:
  * **EGST**: GrailQA에서 F1 스코어 10.3점, WebQSP에서 F1 스코어 7.1점, KQA Pro에서 정확도 10.2점을 향상시키며 분포 불일치 완화에 크게 기여했습니다.
  * **IR**: GrailQA에서 F1 스코어 1.4점, WebQSP에서 F1 스코어 2.4점, KQA Pro에서 정확도 13.5점을 향상시키며, 특히 KQA Pro처럼 엔티티 연결이 없는 경우 SPARQL 실행 오류 시 LLM의 직접 답변 능력이 크게 작용했습니다.
* **소수 샘플 이상의 시나리오**: 더 많은 훈련 데이터가 주어졌을 때도 FlexKBQA는 합성 데이터 사전 훈련을 통해 일관되게 더 나은 성능을 유지하며, 데이터 증강 기술로서의 가치를 입증했습니다.

## 🧠 Insights & Discussion

FlexKBQA의 뛰어난 성능은 크게 두 가지 요인에 기인합니다. 첫째, 인컨텍스트 학습 방식에 비해 LLM을 활용한 대량의 고품질 합성 데이터 생성 덕분에 데이터 분포에 더 잘 수렴할 수 있었습니다. 둘째, 혁신적인 EGST와 IR 접근 방식은 FlexKBQA가 레이블이 없는 실제 사용자 질문을 활용하고 LLM의 내재적 추론 능력을 통합할 수 있도록 했습니다. 이는 FlexKBQA를 다른 방법들과 차별화하는 핵심적인 특징입니다.

본 연구는 LLM을 프로그램 번역기로 사용하는 새로운 패러다임을 제시하며, 합성 데이터 생성, 실행-유도 자기 훈련, 내재적 추론 증강이라는 세 가지 핵심 전략을 통해 KBQA의 데이터 주석, 배포, 도메인 불가지론이라는 세 가지 측면에서 유연성을 제공합니다. 특히, 제로샷 KBQA를 개척하여 미래 연구의 새로운 방향을 제시했습니다.

**제한사항 및 향후 연구**: KQA Pro 데이터셋에서 엔티티 연결 단계의 부재는 모델이 훈련 중에 보지 못한 관계나 엔티티에 대해 의미적으로는 옳지만 실행 불가능한 프로그램을 생성하기 쉽게 만들어, 성능에 격차를 보였습니다. 향후 연구에서는 이 프레임워크를 더 광범위한 자연어 이해 및 추론 작업에 적용하는 것을 탐색할 수 있을 것입니다.

## 📌 TL;DR

FlexKBQA는 LLM을 프로그램 번역기로 활용하여 KBQA의 높은 수동 주석 비용 문제를 해결하는 유연한 프레임워크입니다. 자동 프로그램 샘플링과 LLM 기반 저자원 프로그램 번역으로 합성 데이터를 생성하고, 실행-유도 자기 훈련(EGST)과 내재적 추론(IR)을 통해 합성 데이터와 실제 데이터 간의 분포 차이를 줄이며 LLM의 추론 능력을 보강합니다. 그 결과, FlexKBQA는 소수 샘플 및 제로샷 환경에서 기존 기준 모델들을 뛰어넘고 지도 학습 모델에 근접하는 SOTA 성능을 달성하며, 데이터 주석, 배포, 도메인 불가지론 측면에서 높은 유연성을 제공합니다.
