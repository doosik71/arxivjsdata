{
  "title": "Meta-free few-shot learning via representation learning with weight\n  averaging",
  "authors": "Kuilin Chen, Chi-Guhn Lee",
  "year": 2022,
  "url": "http://arxiv.org/abs/2204.12466v2",
  "abstract": "Recent studies on few-shot classification using transfer learning pose\nchallenges to the effectiveness and efficiency of episodic meta-learning\nalgorithms. Transfer learning approaches are a natural alternative, but they\nare restricted to few-shot classification. Moreover, little attention has been\non the development of probabilistic models with well-calibrated uncertainty\nfrom few-shot samples, except for some Bayesian episodic learning algorithms.\nTo tackle the aforementioned issues, we propose a new transfer learning method\nto obtain accurate and reliable models for few-shot regression and\nclassification. The resulting method does not require episodic meta-learning\nand is called meta-free representation learning (MFRL). MFRL first finds\nlow-rank representation generalizing well on meta-test tasks. Given the learned\nrepresentation, probabilistic linear models are fine-tuned with few-shot\nsamples to obtain models with well-calibrated uncertainty. The proposed method\nnot only achieves the highest accuracy on a wide range of few-shot learning\nbenchmark datasets but also correctly quantifies the prediction uncertainty. In\naddition, weight averaging and temperature scaling are effective in improving\nthe accuracy and reliability of few-shot learning in existing meta-learning\nalgorithms with a wide range of learning paradigms and model architectures."
}