# Task Discrepancy Maximization for Fine-grained Few-Shot Classification

SuBeen Lee, WonJun Moon, Jae-Pil Heo

## 🧩 Problem to Solve

기존 딥러닝 모델은 분류 작업에서 뛰어난 성능을 보이지만, 이를 위해서는 방대한 양의 레이블링된 데이터가 필요합니다. 레이블링된 이미지가 부족할 경우 성능이 크게 저하되며, 이는 퓨샷 분류(few-shot classification) 문제의 핵심입니다. 특히, 미세-세분화(fine-grained) 퓨샷 분류는 각 클래스가 전체적으로 유사한 외형을 공유하므로, 눈이나 부리 등과 같은 **세부적인 식별 특징을 파악하는 것이 매우 중요**합니다. 하지만 기존의 퓨샷 분류 방법론들은 주로 일반적인 객체의 특징을 활용하거나 공간/채널 정렬에 초점을 맞춰 미세-세분화 데이터셋에서 만족할 만한 성능 향상을 이루지 못했습니다. 본 논문은 이러한 미세-세분화 퓨샷 분류에서 클래스별 식별 가능한 세부 영역을 효과적으로 찾아내고 활용하는 문제를 해결하고자 합니다.

## ✨ Key Contributions

* 미세-세분화 퓨샷 분류를 위해 **클래스별 채널 중요도를 정의하는 새로운 특징 정렬 방법인 TDM (Task Discrepancy Maximization)을 제안**합니다.
* 제안하는 TDM은 기존의 메트릭 기반 퓨샷 분류 모델에 쉽게 적용 가능하며, **높은 호환성**을 가집니다.
* 최신 퓨샷 분류 모델과 결합했을 때, TDM은 미세-세분화 퓨샷 분류 태스크에서 **최고 수준(state-of-the-art)의 성능**을 달성합니다.

## 📎 Related Works

* **퓨샷 분류 (Few-Shot Classification):**
  * **최적화 기반 방법 (Optimization-based methods):** MAML, Meta-LSTM, MetaOptNet 등이 있으며, 빠르게 새로운 클래스에 적응할 수 있는 초기 조건을 학습합니다.
  * **메트릭 기반 방법 (Metric-based methods):** MatchNet, ProtoNet, RelationNet 등이 있으며, 임베딩 공간에서 지원(support) 및 질의(query) 이미지 간의 거리를 학습하거나 활용하여 분류합니다. TDM은 이 메트릭 기반 방법들과 호환됩니다.
* **특징 정렬 (Feature Alignment):**
  * **공간 정렬 (Spatial alignment):** CAN, CTX, FRN 등이 있으며, 지원 및 질의 세트 간의 객체 위치 불일치를 해결하고자 합니다.
  * **채널 정렬 (Channel alignment):** FEAT, DMF, RENet 등이 있으며, 새로운 클래스의 의미론적 특징을 더 잘 나타내도록 특징 맵을 조작합니다. TDM도 채널 정렬의 일종이지만, 기존 방법들이 이미지 쌍 간의 관계에 초점을 맞추는 것과 달리 전체 태스크를 고려합니다.

## 🛠️ Methodology

본 논문은 미세-세분화 퓨샷 분류를 위해 **Task Discrepancy Maximization (TDM)**이라는 모듈을 제안합니다. TDM은 클래스별로 채널에 가중치를 부여하여 식별 가능한 영역을 강조하고 다른 채널의 기여를 억제함으로써 태스크 적응형 특징 맵을 생성합니다.

1. **채널별 대표성 점수 (Channel-wise Representativeness Scores) 계산:**
    * 주어진 에피소드(N-way K-shot)에서 특징 추출기 $g_{\theta}$를 통해 지원(support) 및 질의(query) 인스턴스의 특징 맵 $F \in \mathbb{R}^{C \times H \times W}$를 얻습니다.
    * 각 클래스 $i$의 프로토타입 $F^{P}_{i}$를 계산합니다.
    * **클래스 내 점수 ($R^{\text{intra}}_{i,c}$):** 클래스 $i$의 $c$-번째 채널 $f^{P}_{i,c}$가 해당 클래스의 평균 공간 특징 $M^{P}_{i}$와 얼마나 잘 일치하는지 나타냅니다.
        $$ R^{\text{intra}}_{i,c} = \frac{1}{H \times W} \|f^{P}_{i,c} - M^{P}_{i}\|_{2} $$
        이 점수는 작을수록 해당 채널이 클래스 내에서 일관성 있는 정보를 나타냄을 의미합니다.
    * **클래스 간 점수 ($R^{\text{inter}}_{i,c}$):** 클래스 $i$의 $c$-번째 채널 $f^{P}_{i,c}$가 다른 클래스 $j$의 평균 공간 특징 $M^{P}_{j}$와 얼마나 다른지 나타냅니다.
        $$ R^{\text{inter}}_{i,c} = \frac{1}{H \times W} \min_{1 \leq j \leq N, j \neq i} \|f^{P}_{i,c} - M^{P}_{j}\|_{2} $$
        이 점수는 클수록 해당 채널이 클래스 $i$의 독특한 정보를 담고 있음을 의미합니다.

2. **지원 주의 모듈 (Support Attention Module, SAM):**
    * 각 클래스 $i$의 $R^{\text{intra}}_{i}$와 $R^{\text{inter}}_{i}$ 점수를 별도의 Fully Connected Block (FCB)을 통과시켜 가중치 벡터 $w^{\text{intra}}_{i}$와 $w^{\text{inter}}_{i}$를 생성합니다.
    * 두 가중치 벡터를 하이퍼파라미터 $\alpha$를 사용하여 선형 결합하여 클래스 $i$의 지원 가중치 벡터 $w^{S}_{i}$를 정의합니다.
        $$ w^{S}_{i} = \alpha w^{\text{intra}}_{i} + (1-\alpha) w^{\text{inter}}_{i}, \quad \alpha \in [0,1] $$
    * $w^{S}_{i}$는 클래스 $i$의 식별 가능한 채널을 강조하고, 에피소드 내 다른 클래스와 공유되는 공통 정보 채널을 억제합니다.

3. **질의 주의 모듈 (Query Attention Module, QAM):**
    * 질의 인스턴스 $x^{Q}$의 특징 맵 $F^{Q}$로부터 채널별 평균 공간 특징 $M^{Q}$를 계산합니다.
    * 질의 인스턴스 $F^{Q}$의 $c$-번째 채널 $f^{Q}_{c}$와 $M^{Q}$를 이용하여 질의의 채널별 대표성 점수 $R^{\text{intra}}_{Q}$를 계산합니다.
        $$ R^{\text{intra}}_{Q} = \frac{1}{H \times W} \|f^{Q}_{c} - M^{Q}\|_{2} $$
    * $R^{\text{intra}}_{Q}$를 FCB $b_{Q}$에 통과시켜 질의 가중치 $w^{Q}$를 생성합니다.
        $$ w^{Q} = b_{Q}(R^{\text{intra}}_{Q}) $$
    * $w^{Q}$는 질의 인스턴스 내에서 객체와 관련된 채널을 강조하고 다른 채널을 억제하여 모델이 객체 관련 정보에 집중하도록 돕습니다.

4. **태스크 불일치 최대화 (TDM) 통합:**
    * SAM의 지원 가중치 $w^{S}_{i}$와 QAM의 질의 가중치 $w^{Q}$를 하이퍼파라미터 $\beta$를 사용하여 선형 결합하여 클래스 $i$의 최종 태스크 가중치 벡터 $w^{T}_{i}$를 정의합니다.
        $$ w^{T}_{i} = \beta w^{S}_{i} + (1-\beta) w^{Q}, \quad \beta \in [0,1] $$
    * 이 태스크 가중치 벡터 $w^{T}_{i}$를 원래 특징 맵 $F$에 채널별로 곱하여 태스크 적응형 특징 맵 $A$를 생성합니다.
        $$ A = w^{T}_{i} \odot F = [w^{T}_{i,1} f_{1}, w^{T}_{i,2} f_{2}, ..., w^{T}_{i,C} f_{C}] $$
    * 생성된 태스크 적응형 특징 맵은 분류에 사용되며, 예를 들어 ProtoNet에서는 이를 바탕으로 프로토타입을 계산하고 거리를 측정합니다.

## 📊 Results

TDM은 CUB-200-2011, Aircraft, meta-iNat, tiered meta-iNat, Stanford-Cars, Stanford-Dogs, Oxford-Pets 등 7가지 미세-세분화 데이터셋에 걸쳐 광범위한 실험을 통해 그 효과를 입증했습니다.

* **일관된 성능 향상:** TDM은 ProtoNet, DSN, CTX, FRN 등 다양한 기존 퓨샷 분류 모델의 성능을 모든 실험 설정에서 일관되게 향상시켰습니다. 특히, Conv-4 백본을 사용하는 CUB 데이터셋의 1-shot 시나리오에서 ProtoNet 대비 7% 이상의 큰 개선을 보였습니다.
* **최고 수준의 성능 달성:** 대부분의 벤치마크 데이터셋에서 TDM은 기존 모델들을 능가하며 최고 수준의 결과를 달성했습니다.
* **일반화 능력:** meta-iNat 및 tiered meta-iNat과 같은 일반화 능력이 중요한 데이터셋에서도 강건함을 보이며 일관된 성능 향상을 입증했습니다.
* **모듈별 효과 (Ablation Study):**
  * SAM과 QAM 두 서브모듈은 모두 분류 정확도를 향상시켰습니다. 특히 SAM은 baseline 대비 최대 11%의 큰 폭으로 성능을 개선하여, 클래스별 식별 가능한 채널 인식의 중요성을 확인했습니다.
  * 두 모듈을 결합했을 때 성능이 더욱 향상되어 상호 보완적인 관계임을 입증했습니다.
* **풀링 함수 선택:** 평균 풀링(average pooling)이 최대 풀링(max pooling)보다 더 효과적임을 확인했으며, 이는 평균 풀링이 객체의 세부 정보를 더 잘 포착하기 때문입니다.
* **메트릭 호환성:** TDM은 유클리드 거리뿐만 아니라 코사인 거리와 같은 다른 거리 측정법과도 호환되어 유연성을 보여주었습니다.

## 🧠 Insights & Discussion

* **미세-세분화 퓨샷 분류의 핵심:** TDM은 일반적인 분류 작업과 달리, 미세-세분화 클래스는 전체적인 외형이 유사하기 때문에 객체의 전체 정보를 활용하기보다는 **식별 가능한 세부 특징에 집중하는 것이 중요하다**는 통찰에 기반합니다.
* **동적 식별 영역 발견:** 퓨샷 설정에서 각 에피소드(task)의 구성에 따라 클래스의 식별 영역이 달라질 수 있습니다. TDM은 SAM과 QAM을 통해 이러한 **식별 영역을 동적으로 발견하고 강조**함으로써 모델이 태스크에 적응적으로 작동하도록 합니다. 예를 들어, 어떤 새 종의 경우 부리가 식별 특징이 될 수 있지만, 다른 새 종과의 비교에서는 날개가 더 중요할 수 있습니다. TDM은 이러한 상황적 유연성을 제공합니다.
* **제한 사항:** TDM은 미세-세분화 특징 강조를 위해 개발되었으므로, 일반적인(coarse-grained) 분류 작업에서는 그 효과가 제한적일 수 있습니다.

## 📌 TL;DR

본 논문은 미세-세분화 퓨샷 분류의 난제를 해결하기 위해 **Task Discrepancy Maximization (TDM)** 모듈을 제안합니다. TDM은 **Support Attention Module (SAM)**과 **Query Attention Module (QAM)**을 통해 클래스별 식별 가능한 세부 특징을 강조하는 채널 가중치를 동적으로 생성합니다. SAM은 클래스 내/간 대표성 점수를 활용하여 지원 세트에서 클래스별 식별 채널을 찾아내고, QAM은 질의 이미지 내에서 객체 관련 채널을 식별합니다. 이 두 모듈에서 얻은 가중치를 결합하여 태스크 적응형 특징 맵을 만들고, 이를 통해 분류 성능을 향상시킵니다. 다양한 미세-세분화 벤치마크 데이터셋에 대한 광범위한 실험을 통해 TDM이 기존 퓨샷 분류 모델들의 성능을 일관되게 향상시키며 최고 수준의 결과를 달성함을 입증했습니다.
