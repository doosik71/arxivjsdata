{
  "title": "Not End-to-End: Explore Multi-Stage Architecture for Online Surgical\n  Phase Recognition",
  "authors": "Fangqiu Yi, Tingting Jiang",
  "year": 2021,
  "url": "http://arxiv.org/abs/2107.04810v1",
  "abstract": "Surgical phase recognition is of particular interest to computer assisted\nsurgery systems, in which the goal is to predict what phase is occurring at\neach frame for a surgery video. Networks with multi-stage architecture have\nbeen widely applied in many computer vision tasks with rich patterns, where a\npredictor stage first outputs initial predictions and an additional refinement\nstage operates on the initial predictions to perform further refinement.\nExisting works show that surgical video contents are well ordered and contain\nrich temporal patterns, making the multi-stage architecture well suited for the\nsurgical phase recognition task. However, we observe that when simply applying\nthe multi-stage architecture to the surgical phase recognition task, the\nend-to-end training manner will make the refinement ability fall short of its\nwishes. To address the problem, we propose a new non end-to-end training\nstrategy and explore different designs of multi-stage architecture for surgical\nphase recognition task. For the non end-to-end training strategy, the\nrefinement stage is trained separately with proposed two types of disturbed\nsequences. Meanwhile, we evaluate three different choices of refinement models\nto show that our analysis and solution are robust to the choices of specific\nmulti-stage models. We conduct experiments on two public benchmarks, the\nM2CAI16 Workflow Challenge, and the Cholec80 dataset. Results show that\nmulti-stage architecture trained with our strategy largely boosts the\nperformance of the current state-of-the-art single-stage model. Code is\navailable at \\url{https://github.com/ChinaYi/casual_tcn}."
}