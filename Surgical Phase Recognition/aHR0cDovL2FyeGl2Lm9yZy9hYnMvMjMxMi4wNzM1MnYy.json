{
  "title": "CholecTrack20: A Multi-Perspective Tracking Dataset for Surgical Tools",
  "authors": "Chinedu Innocent Nwoye, Kareem Elgohary, Anvita Srinivas, Fauzan Zaid, JoÃ«l L. Lavanchy, Nicolas Padoy",
  "year": 2023,
  "url": "http://arxiv.org/abs/2312.07352v2",
  "abstract": "Tool tracking in surgical videos is essential for advancing computer-assisted\ninterventions, such as skill assessment, safety zone estimation, and\nhuman-machine collaboration. However, the lack of context-rich datasets limits\nAI applications in this field. Existing datasets rely on overly generic\ntracking formalizations that fail to capture surgical-specific dynamics, such\nas tools moving out of the camera's view or exiting the body. This results in\nless clinically relevant trajectories and a lack of flexibility for real-world\nsurgical applications. Methods trained on these datasets often struggle with\nvisual challenges such as smoke, reflection, and bleeding, further exposing the\nlimitations of current approaches. We introduce CholecTrack20, a specialized\ndataset for multi-class, multi-tool tracking in surgical procedures. It\nredefines tracking formalization with three perspectives: (i) intraoperative,\n(ii) intracorporeal, and (iii) visibility, enabling adaptable and clinically\nmeaningful tool trajectories. The dataset comprises 20 full-length surgical\nvideos, annotated at 1 fps, yielding over 35K frames and 65K labeled tool\ninstances. Annotations include spatial location, category, identity, operator,\nphase, and scene visual challenge. Benchmarking state-of-the-art methods on\nCholecTrack20 reveals significant performance gaps, with current approaches (<\n45\\% HOTA) failing to meet the accuracy required for clinical translation.\nThese findings motivate the need for advanced and intuitive tracking algorithms\nand establish CholecTrack20 as a foundation for developing robust AI-driven\nsurgical assistance systems."
}