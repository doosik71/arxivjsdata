{
  "title": "Surgical Temporal Action-aware Network with Sequence Regularization for\n  Phase Recognition",
  "authors": "Zhen Chen, Yuhao Zhai, Jun Zhang, Jinqiao Wang",
  "year": 2023,
  "url": "http://arxiv.org/abs/2311.12603v2",
  "abstract": "To assist surgeons in the operating theatre, surgical phase recognition is\ncritical for developing computer-assisted surgical systems, which requires\ncomprehensive understanding of surgical videos. Although existing studies made\ngreat progress, there are still two significant limitations worthy of\nimprovement. First, due to the compromise of resource consumption, frame-wise\nvisual features are extracted by 2D networks and disregard spatial and temporal\nknowledge of surgical actions, which hinders subsequent inter-frame modeling\nfor phase prediction. Second, these works simply utilize ordinary\nclassification loss with one-hot phase labels to optimize the phase\npredictions, and cannot fully explore surgical videos under inadequate\nsupervision. To overcome these two limitations, we propose a Surgical Temporal\nAction-aware Network with sequence Regularization, named STAR-Net, to recognize\nsurgical phases more accurately from input videos. Specifically, we propose an\nefficient multi-scale surgical temporal action (MS-STA) module, which\nintegrates visual features with spatial and temporal knowledge of surgical\nactions at the cost of 2D networks. Moreover, we devise the dual-classifier\nsequence regularization (DSR) to facilitate the training of STAR-Net by the\nsequence guidance of an auxiliary classifier with a smaller capacity. Our\nSTAR-Net with MS-STA and DSR can exploit visual features of surgical actions\nwith effective regularization, thereby leading to the superior performance of\nsurgical phase recognition. Extensive experiments on a large-scale gastrectomy\nsurgery dataset and the public Cholec80 benchmark prove that our STAR-Net\nsignificantly outperforms state-of-the-arts of surgical phase recognition."
}