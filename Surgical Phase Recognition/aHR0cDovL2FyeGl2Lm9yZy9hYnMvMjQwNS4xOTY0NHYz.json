{
  "title": "EgoSurgery-Phase: A Dataset of Surgical Phase Recognition from\n  Egocentric Open Surgery Videos",
  "authors": "Ryo Fujii, Masashi Hatano, Hideo Saito, Hiroki Kajita",
  "year": 2024,
  "url": "http://arxiv.org/abs/2405.19644v3",
  "abstract": "Surgical phase recognition has gained significant attention due to its\npotential to offer solutions to numerous demands of the modern operating room.\nHowever, most existing methods concentrate on minimally invasive surgery (MIS),\nleaving surgical phase recognition for open surgery understudied. This\ndiscrepancy is primarily attributed to the scarcity of publicly available open\nsurgery video datasets for surgical phase recognition. To address this issue,\nwe introduce a new egocentric open surgery video dataset for phase recognition,\nnamed EgoSurgery-Phase. This dataset comprises 15 hours of real open surgery\nvideos spanning 9 distinct surgical phases all captured using an egocentric\ncamera attached to the surgeon's head. In addition to video, the\nEgoSurgery-Phase offers eye gaze. As far as we know, it is the first real open\nsurgery video dataset for surgical phase recognition publicly available.\nFurthermore, inspired by the notable success of masked autoencoders (MAEs) in\nvideo understanding tasks (e.g., action recognition), we propose a gaze-guided\nmasked autoencoder (GGMAE). Considering the regions where surgeons' gaze\nfocuses are often critical for surgical phase recognition (e.g., surgical\nfield), in our GGMAE, the gaze information acts as an empirical semantic\nrichness prior to guiding the masking process, promoting better attention to\nsemantically rich spatial regions. GGMAE significantly improves the previous\nstate-of-the-art recognition method (6.4% in Jaccard) and the masked\nautoencoder-based method (3.1% in Jaccard) on EgoSurgery-Phase. The dataset is\nreleased at https://github.com/Fujiry0/EgoSurgery."
}