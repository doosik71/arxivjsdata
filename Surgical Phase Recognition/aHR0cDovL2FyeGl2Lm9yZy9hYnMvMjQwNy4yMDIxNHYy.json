{
  "title": "SANGRIA: Surgical Video Scene Graph Optimization for Surgical Workflow\n  Prediction",
  "authors": "Çağhan Köksal, Ghazal Ghazaei, Felix Holm, Azade Farshad, Nassir Navab",
  "year": 2024,
  "url": "http://arxiv.org/abs/2407.20214v2",
  "abstract": "Graph-based holistic scene representations facilitate surgical workflow\nunderstanding and have recently demonstrated significant success. However, this\ntask is often hindered by the limited availability of densely annotated\nsurgical scene data. In this work, we introduce an end-to-end framework for the\ngeneration and optimization of surgical scene graphs on a downstream task. Our\napproach leverages the flexibility of graph-based spectral clustering and the\ngeneralization capability of foundation models to generate unsupervised scene\ngraphs with learnable properties. We reinforce the initial spatial graph with\nsparse temporal connections using local matches between consecutive frames to\npredict temporally consistent clusters across a temporal neighborhood. By\njointly optimizing the spatiotemporal relations and node features of the\ndynamic scene graph with the downstream task of phase segmentation, we address\nthe costly and annotation-burdensome task of semantic scene comprehension and\nscene graph generation in surgical videos using only weak surgical phase\nlabels. Further, by incorporating effective intermediate scene representation\ndisentanglement steps within the pipeline, our solution outperforms the SOTA on\nthe CATARACTS dataset by 8% accuracy and 10% F1 score in surgical workflow\nrecognition"
}