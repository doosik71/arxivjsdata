{
  "url": "http://arxiv.org/abs/2406.17873v1",
  "title": "Improving Arithmetic Reasoning Ability of Large Language Models through\n  Relation Tuples, Verification and Dynamic Feedback",
  "authors": "Zhongtao Miao, Kaiyan Zhao, Yoshimasa Tsuruoka",
  "year": 2024,
  "abstract": "Current representations used in reasoning steps of large language models can\nmostly be categorized into two main types: (1) natural language, which is\ndifficult to verify; and (2) non-natural language, usually programming code,\nwhich is difficult for people who are unfamiliar with coding to read. In this\npaper, we propose to use a semi-structured form to represent reasoning steps of\nlarge language models. Specifically, we use relation tuples, which are not only\nhuman-readable but also machine-friendly and easier to verify than natural\nlanguage. We implement a framework that includes three main components: (1)\nintroducing relation tuples into the reasoning steps of large language models;\n(2) implementing an automatic verification process of reasoning steps with a\nlocal code interpreter based on relation tuples; and (3) integrating a simple\nand effective dynamic feedback mechanism, which we found helpful for\nself-improvement of large language models. The experimental results on various\narithmetic datasets demonstrate the effectiveness of our method in improving\nthe arithmetic reasoning ability of large language models. The source code is\navailable at https://github.com/gpgg/art.",
  "citation": 3
}