# Harnessing Multiple Large Language Models: A Survey on LLM Ensemble

Zhijun Chen, Jingzheng Li, Pengpeng Chen, Zhuoran Li, Kai Sun, Yuankai Luo, Qianren Mao, Ming Li, Likang Xiao, Dingqi Yang, Yikun Ban, Hailong Sun, Philip S. Yu

## 🧩 Problem to Solve

거대 언어 모델(LLM)은 높은 성능을 보이지만, 여전히 정확성, 환각 현상, 사용자 의도와의 불일치 등 여러 성능 우려를 안고 있습니다. 또한, 다양한 LLM들은 각기 다른 아키텍처, 파라미터 크기, 훈련 데이터 및 방법론으로 인해 고유한 강점과 약점, 그리고 추론 비용을 가집니다. 특정 작업에 단일 LLM에만 의존하기보다는, 여러 LLM의 개별적인 강점을 동시에 활용하여 이러한 한계를 극복하고 성능을 향상시키는 방안이 모색되어야 합니다. 빠르게 발전하는 LLM 앙상블 분야에 대한 체계적인 첫 번째 종합 리뷰가 부족하다는 점도 해결해야 할 문제였습니다.

## ✨ Key Contributions

* LLM 앙상블(LLM Ensemble) 분야에 대한 최초의 포괄적인 시스템 리뷰를 제공합니다.
* "앙상블-추론 전(Ensemble-before-inference)", "앙상블-추론 중(Ensemble-during-inference)", "앙상블-추론 후(Ensemble-after-inference)"의 세 가지 주요 범주를 포함하는 새로운 분류 체계를 제시합니다.
* 각 범주에 속하는 다양한 앙상블 방법론을 심층적으로 분류하고 분석합니다.
* 관련 벤치마크와 실제 애플리케이션을 소개하고, 기존 연구의 한계를 논의하며, 미래 연구 방향을 제안합니다.

## 📎 Related Works

* **LLM 병합 (LLM Merging / LLM Fusion)**: 여러 LLM의 파라미터를 통합하여 원본 훈련 데이터나 광범위한 계산 없이 단일 범용 모델을 구축합니다. 지식 융합 및 전달 측면에서 LLM 앙상블과 관련이 깊습니다.
* **LLM 협업 (LLM Collaboration)**: 각 LLM에 특정 역할을 할당하고 응답 정보를 교환하여 유연하게 작업을 해결합니다. LLM 앙상블에서 모델들이 동등한 지위로 직접 쿼리에 대응하는 것과는 차이가 있습니다.
* **약한 지도 학습 (Weak Supervision / Learning from Crowds)**: 여러 약한 어노테이션 소스에서 제공하는 약한 레이블을 사용하여 정보 집계(LLM 앙상블의 추론 후 비-캐스케이드 방식과 유사)를 수행하거나 분류기를 훈련합니다. 대부분 분류 작업에 초점을 맞춥니다.

## 🛠️ Methodology

본 논문은 LLM 앙상블 방법론을 크게 세 가지 범주로 나누어 체계적으로 분석합니다.

* **1. 앙상블-추론 전 (Ensemble-before-inference)**
  * 주어진 쿼리에 가장 적합한 단일 LLM을 추론이 시작되기 전에 선택(라우팅)하는 방식입니다.
  * **사전 훈련된 라우터 (Pretrained router)**:
    * **분류 기반 (Classification-based)**: 모델 선택을 여러 이진 분류 문제로 전환하여 각 LLM이 쿼리에 올바르게 응답할지 예측합니다.
    * **보상 기반 (Reward-based)**: 보상 모델의 점수를 감독 신호로 사용하여 라우팅 함수를 훈련합니다.
    * **할당 기반 (Assignment-based)**: 비용 및 성능의 균형을 맞추기 위해 다양한 할당 전략을 제공합니다.
  * **비-사전 훈련된 라우터 (Non-pretrained router)**:
    * 훈련 없이 ELO 랭킹, 강화 학습, 무작위 선택 등 미리 설계된 선택 전략을 사용합니다.

* **2. 앙상블-추론 중 (Ensemble-during-inference)**
  * 디코딩 과정 중에 여러 LLM의 불완전한 응답(예: 토큰 수준 정보)을 집계하고, 결합된 결과를 다시 모델에 피드백합니다.
  * **토큰 수준 (Token-level ensemble)**:
    * **집계 기반 (Aggregation-based)**: 여러 모델의 토큰별 확률 분포를 (가중)평균하여 최종 토큰 분포를 생성합니다. 서로 다른 LLM 간의 어휘 불일치를 해결하기 위해 union dictionary 또는 공유 공간으로의 투영 기법을 활용합니다.
    * **선택 기반 (Selection-based)**: 강화 학습 기반 라우터를 훈련하여 각 토큰 생성 단계에서 소형 모델 또는 더 큰 모델의 출력을 선택합니다.
  * **스팬 수준 (Span-level ensemble)**:
    * "생성-평가-선택" 파이프라인을 따릅니다. 여러 LLM이 텍스트 조각(span)을 생성하면, perplexity 공식(Equation 1)을 사용하여 각 모델의 응답을 평가하고 가장 높은 누적 점수를 가진 조각을 선택합니다. 스팬 길이를 고정하거나, 모든 LLM에 공통적인 단어 경계까지 생성하는 방식이 있습니다.
  * **프로세스 수준 (Process-level ensemble)**:
    * 복잡한 단계별 추론 작업에서 몬테카를로 트리 탐색(MCTS) 전략을 사용하여 여러 모델의 추론 출력 중 가장 높은 보상 값을 가진 출력을 선택합니다.

* **3. 앙상블-추론 후 (Ensemble-after-inference)**
  * 모든 LLM 또는 일부 LLM이 완전한 응답을 생성한 후 앙상블을 수행합니다.
  * **비-캐스케이드 (Non-cascade)**:
    * **선택 기반 (Selection-based)**: 여러 후보 응답 중 하나를 선택합니다. 주로 모델 응답 간의 유사성을 활용하여 가장 높은 유사도를 보이는 응답(다수결 투표)을 최종 답변으로 선택합니다.
    * **선택-재생성 (Selection-then-regeneration)**: 먼저 후보 응답의 부분집합을 선택한 후, 이 정제된 부분집합을 생성 모델에 입력하여 최종 출력을 재생성합니다.
  * **캐스케이드 (Cascade)**:
    * 성능과 추론 비용을 모두 고려하여, 현재 모델의 출력을 채택할지 또는 더 강력한 후속 모델을 호출할지를 결정하는 지연(deferral) 규칙을 중심으로 작동합니다.
    * **비지도 방식 (Unsupervised methods)**: 사용자 판단, 응답 일관성, 클래스 불확실성(confidence) 등을 주요 전략으로 사용하여 결정을 내립니다.
    * **지도 방식 (Supervised methods)**: 훈련 데이터를 사용하여 캐스케이드 관련 모듈(예: 포스트-혹 지연 학습, 스코어링 함수, 마르코프 의사 결정 프로세스(MDP))을 훈련하여 결정을 내립니다.

## 📊 Results

본 논문은 다양한 LLM 앙상블 방법론을 검토하며 다음과 같은 전반적인 결과와 벤치마크, 응용 분야를 제시합니다.

* **벤치마크**: LLM 앙상블 평가를 위해 특별히 고안된 두 가지 고전적인 벤치마크가 있습니다.
  * **MIXINSTRUCT**: 다양한 지시 따르기(instruction-following) 작업을 다루며 11개의 인기 LLM과 11,000개의 테스트 샘플을 포함합니다.
  * **ROUTERBENCH**: 성능과 추론 비용을 동시에 고려하는 방법, 특히 추론 전 앙상블 방법 평가에 적합합니다.
* **응용 분야**: LLM 앙상블 개념은 일반적인 작업 외에도 다양한 전문 작업 및 도메인에 적용됩니다.
  * **명령어 튜닝(Instruction-Tuning) 데이터 생성**: ROUGE-L 메트릭을 사용하여 생성된 텍스트의 유사성을 평가하고, 유사성 기반 선택 전략으로 앙상블하여 데이터를 생성합니다.
  * **기타**: 승률 평가(win rate evaluation), SQL 생성 등 다양한 분야에서 활용됩니다.
* **전반적인 관찰 (방법론 요약 분석)**:
  * **앙상블 전략**: 여러 모델 출력을 평균하는 **집계(aggregation) 방식**이 단일 출력을 선택하는 방식보다 정교합니다. **재생성(regeneration) 기반 방식**은 추가적인 대규모 모델 훈련 데이터 준비 및 모델 훈련 부담이 있습니다.
  * **앙상블 세분성**: 응답 수준 앙상블은 비교적 거친 세분성을 가지는 반면, **토큰 수준 앙상블**과 같이 더 미세한 세분성을 가진 방법은 디코딩 단계에서 각 모델의 분포 정보를 더 효과적으로 활용하여 성능 향상 잠재력이 더 큽니다.
  * **앙상블 목표**: 비용 제약이 없는 **추론 중 앙상블** 및 **비-캐스케이드 방식**은 선택 이상의 유연한 앙상블 전략과 미세한 세분성 접근 방식을 사용하여 더 큰 성능 향상 잠재력을 제공합니다.

## 🧠 Insights & Discussion

본 논문은 LLM 앙상블의 현재 한계점을 지적하고 미래 연구 방향을 제시합니다.

* **현재의 한계**:
  * **스팬 수준 추론 중 앙상블**: 현재의 스팬 분할 기법은 너무 단순하며(예: 고정된 단어 수), 더 원칙적인 세분화 방식이 필요합니다.
  * **비지도 비-캐스케이드 추론 후 앙상블**: 최적의 성능을 달성하려면, 현재 방법론은 단순한 출력 간 쌍별 유사성 측정에 의존하거나, 일반화 능력을 희생하는 생성 지향 지도 학습 구성 요소를 요구하는 한계가 있습니다.
  * **일반 캐스케이드 접근법**: 대부분의 기존 캐스케이드 방법은 생성 작업에 적합하지 않으며, 생성 지향적인 유일한 방법은 지도 학습에 의존하여 일반화 능력을 상실합니다.

* **미래 연구 방향**:
  * **원칙적인 스팬 수준 추론 중 앙상블 접근법**: 더 정교한 세그먼트 분할 기법을 개발하여 후속 앙상블 과정에 더 풍부하고 가치 있는 정보를 제공해야 합니다.
  * **고도화된 비지도 비-캐스케이드 추론 후 앙상블 접근법**: 단순한 유사성 측정이나 지도 학습에 의존하지 않으면서 최적의 성능을 달성하는 비지도 기반 방법 개발이 중요합니다.
  * **범용 캐스케이드 접근법**: 생성 작업을 포함한 다양한 작업에 적용 가능하며 일반화 능력을 갖춘 비지도 캐스케이드 접근법 개발이 필요합니다.

## 📌 TL;DR

LLM의 한계(정확도, 환각 등)와 다양한 LLM 간의 성능/비용 차이를 극복하기 위해, 본 논문은 여러 LLM의 강점을 활용하는 **LLM 앙상블**에 대한 최초의 체계적인 리뷰를 제공합니다. 논문은 LLM 앙상블 방법론을 쿼리 처리 시점에 따라 **추론 전, 추론 중, 추론 후**의 세 가지 주요 범주로 분류하고, 각 범주에 속하는 다양한 전략(예: 사전 훈련된/비-훈련된 라우팅, 토큰/스팬/프로세스 수준 집계 및 선택, 비-캐스케이드/캐스케이드 선택-재생성)을 심층적으로 분석합니다. 주요 발견은 **더 미세한 세분성(예: 토큰 수준)을 가진 앙상블이 모델 분포 정보를 효과적으로 활용하여 성능 향상 잠재력이 크며**, 향후 **더 정교하고 일반화 가능한 비지도 방식**의 스팬 수준 및 캐스케이드 앙상블 연구가 필요함을 강조합니다.
