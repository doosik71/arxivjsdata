# Gemini Robotics: Bringing AI into the Physical World

Gemini Robotics Team, Google DeepMind

## 🧩 Problem to Solve

최근 대규모 멀티모달 모델(LMM)은 디지털 영역에서 놀라운 일반화 능력을 보여주었지만, 이를 로봇과 같은 물리적 에이전트에 적용하는 것은 여전히 큰 과제입니다. 범용 로봇은 물리적 세계를 이해하고, 능숙하며 안전하게 상호작용할 수 있어야 합니다. 이는 3D 구조, 객체 간의 복잡한 관계, 직관적인 물리학 등 인간 수준의 '구현된 추론(embodied reasoning)' 능력을 요구합니다. 본 연구의 핵심 질문은 최첨단 디지털 AI 모델에 물리적 세계와 일반적이고 능숙하게 상호작용하는 데 필요한 구현된 추론 능력을 어떻게 부여할 것인가입니다.

## ✨ Key Contributions

* **ERQA 벤치마크 개발:** 멀티모달 모델의 구현된 추론 능력을 평가하기 위한 새로운 오픈소스 벤치마크인 ERQA를 도입했습니다.
* **Gemini Robotics-ER 모델:** Gemini 2.0을 기반으로 강화된 구현된 추론 능력을 갖춘 Vision-Language Model(VLM)을 제시했습니다. 이 모델은 공간 및 시간 이해를 강화하여 객체 감지, 포인팅, 궤적 및 그랩 예측, 3D 바운딩 박스 예측이 가능합니다.
* **Gemini Robotics 모델:** Gemini Robotics-ER을 기반으로 실제 로봇을 직접 제어할 수 있는 최첨단 Vision-Language-Action(VLA) 모델을 제안했습니다. 이 모델은 다양한 조작 작업을 처리하며, 객체 유형 및 위치 변화에 강건하고, 다양한 지시를 따를 수 있습니다.
* **다양한 적용 및 특화 능력 입증:**
  * 제로샷(코드 생성) 및 소량샷(in-context learning) 로봇 제어.
  * 긴 시야, 고도로 정교한 작업(예: 종이접기 여우, 카드 게임) 해결.
  * 100개 미만의 데모로 새로운 단기 작업 학습.
  * 이중 팔 플랫폼 및 고자유도 휴머노이드를 포함한 완전히 새로운 로봇 형태에 적응.
* **책임감 있는 개발:** 이러한 로봇 기반 모델과 관련된 중요한 안전 문제를 논의하고 해결 방안을 제시했습니다.

## 📎 Related Works

* **기존 로봇 제어 접근 방식:** 이전 연구들(Ahn et al., 2022; Kwon et al., 2024; Liang et al., 2023; Vemprala et al., 2023)은 로봇 제어를 위해 여러 모델을 조합해야 했으나, Gemini 2.0은 필요한 모든 기능을 단일 모델에 통합합니다.
* **소량샷 학습 (Few-shot learning):** (Di Palo and Johns, 2024)의 방법을 확장하여, Gemini Robotics-ER은 외부 모델 없이 시각적 키포인트와 객체 포즈를 직접 추출하여 소량샷 모방 학습을 수행합니다.
* **비전-언어-액션(VLA) 및 멀티태스크 학습:** 𝛑<sub>0</sub> (Beyer et al., 2024; Black et al., 2024) 및 ALOHA Unleashed (Zhao et al., 2025)에서 영감을 받은 멀티태스크 확산 정책(Chi et al., 2024)과 같은 최신 모델들을 성능 비교를 위한 베이스라인으로 사용했습니다.
* **로봇 안전 연구:** Google AI Principles (Google, 2025), Gemini 모델의 이전 안전 릴리스 (Gemini-Team et al., 2023; Kavukcuoglu et al., 2022)를 준수하며, ASIMOV-datasets (Sermanet et al., 2025a,b) 및 Constitutional AI (Ahn et al., 2024; Bai et al., 2022; Huang et al., 2024; Kundu et al., 2023; Sermanet et al., 2025a)를 활용한 안전성 평가 및 완화 노력을 언급했습니다.

## 🛠️ Methodology

1. **Gemini 2.0 기반 모델 개발:**
    * Google의 최신 멀티모달 기반 모델인 Gemini 2.0을 기반으로 합니다.
    * **ERQA 벤치마크:** 공간 추론, 궤적 추론, 행동 추론, 상태 추정, 포인팅, 다중 시점 추론, 작업 추론 등 다양한 구현된 추론 능력을 평가하기 위해 400개의 VQA(Visual Question Answering) 스타일 질문으로 구성된 ERQA 벤치마크를 자체 개발하여 Gemini 2.0의 성능을 검증했습니다.
2. **Gemini Robotics-ER (Embodied Reasoning) 모델:**
    * Gemini 2.0 Flash 버전을 기반으로 향상된 구현된 추론 능력(Enhanced Embodied Reasoning)을 위해 추가 학습을 수행합니다.
    * **능력:** 2D 객체 감지, 포인팅, 궤적 예측, 그랩 예측 (Gemini Robotics-ER에서 새로 도입), 다중 시점 대응, 3D 바운딩 박스 감지 등을 지원합니다.
    * **제로샷 제어 (Zero-shot Control):** Gemini 2.0의 코드 생성 능력과 구현된 추론 능력을 결합하여 로봇 API(객체 감지, 포인팅, 그랩 예측, 이동, 그리퍼 제어 등)를 통해 이중 팔 ALOHA 2 로봇을 제어하는 Python 코드를 생성합니다.
    * **소량샷 제어 (Few-shot Control / In-context learning):** 텍스트 토큰화된 로봇 행동 궤적(객체 및 말단 효과기 포즈)과 언어 설명을 프롬프트에 제공하여 모델이 새로운 행동을 모방하도록 유도합니다. Gemini Robotics-ER은 외부 모델 없이 시각적 키포인트 및 객체 포즈를 직접 추출합니다.
3. **Gemini Robotics 모델:**
    * Gemini Robotics-ER의 파생 모델로, 로봇 행동을 직접 예측하도록 미세 조정되었습니다.
    * **아키텍처:** 클라우드에서 호스팅되는 VLA 백본(Gemini Robotics-ER의 경량화 버전, 응답 지연 시간 160ms 미만)과 로봇 온보드 컴퓨터에서 실행되는 로컬 액션 디코더로 구성되어, 엔드-투-엔드 지연 시간을 250ms로 낮추고 50Hz의 제어 주파수를 달성합니다.
    * **데이터:** 12개월 동안 ALOHA 2 로봇에서 수집된 수천 시간 분량의 실제 로봇 텔레오퍼레이션 행동 데이터셋과 웹 문서, 코드, 멀티모달 콘텐츠(이미지, 오디오, 비디오), 구현된 추론 및 VQA 데이터 등 다양한 비행동 데이터를 사용해 훈련되었습니다.
    * **특화 (Specialization):** 일반화된 모델의 한계를 넘어, 종이접기, 카드 게임 등 고도로 정교한 긴 시야(long-horizon) 작업을 위해 2000~5000회 분량의 고품질 데모 데이터로 미세 조정되었습니다.
    * **강화된 추론 및 일반화:** 구현된 추론 능력(궤적 이해 및 생성)에 행동 예측을 연결하기 위해 재레이블링된 로봇 행동 데이터셋으로 미세 조정되었습니다.
    * **빠른 적응 (Fast adaptation):** 새로운 단기 작업에 5~100개의 제한된 데모로 빠르게 적응하도록 미세 조정되었습니다.
    * **새로운 형태(Embodiment)에 대한 적응:** 이중 팔 프랭카(Franka) 로봇 및 아폴로(Apollo) 휴머노이드 로봇과 같은 새로운 로봇 플랫폼에서 소량의 데이터로 모델을 미세 조정하여 제어 가능성을 입증했습니다.
4. **안전성 고려:**
    * Gemini AI Principles에 맞춰 개발되었으며, ASIMOV-datasets (Sermanet et al., 2025a,b)을 사용하여 의미론적 행동 안전성을 평가하고 개선하기 위한 사후 학습(post-training)을 수행했습니다.
    * 편향 유발 포인팅 쿼리에 대한 거부율을 96%로 달성하고, Constitutional AI 방법을 통해 안전성 성능을 향상시켰습니다.

## 📊 Results

* **ERQA 벤치마크:** Gemini 2.0 Flash (46.3%), Pro Experimental (48.3%)이 SOTA를 달성했으며, CoT(Chain-of-Thought) 프롬프팅을 통해 성능이 크게 향상되었습니다 (Flash 50.3%, Pro Experimental 54.8%). Gemini Robotics-ER은 SUN-RGBD 3D 객체 감지에서 새로운 SOTA를 기록했습니다.
* **제로샷 로봇 제어:** 시뮬레이션에서 Gemini 2.0 Flash는 평균 27%의 성공률을 보인 반면, Gemini Robotics-ER은 53%로 거의 두 배의 성능 향상을 보였습니다.
* **소량샷 로봇 제어:** Gemini 2.0 Flash는 시뮬레이션에서 51%, Gemini Robotics-ER은 시뮬레이션 및 실제 환경에서 65%의 성공률을 달성하여, 특히 섬세한 작업에서 큰 개선을 보여주었습니다.
* **Gemini Robotics (기본 성능):**
  * 다양하고 섬세한 조작 작업에서 SOTA 베이스라인(𝛑<sub>0</sub> re-implement, Multi-task diffusion)을 능가했으며, 특히 변형 가능한 객체 조작에서 탁월한 성능을 보였습니다.
  * 학습되지 않은 환경, 객체, 지시에서도 새로운 언어 지시를 정확하게 따르며 높은 일반화 능력을 입증했습니다.
* **긴 시야 작업 특화:** 종이접기 여우나 도시락 포장과 같은 6가지 긴 시야의 고도로 섬세한 작업에서 평균 79%의 성공률을 달성했으며, 도시락 포장 작업에서는 100% 성공률을 보이며 특화된 베이스라인을 크게 능가했습니다.
* **강화된 추론 및 일반화:** 추론 강화 버전의 Gemini Robotics는 단일 단계 추론, 의미론적 지식, 공간 이해를 요구하는 OOD(Out-of-Distribution) 시나리오에서 바닐라 모델보다 훨씬 높은 성공률을 기록했습니다.
* **빠른 작업 적응:** 8개의 새로운 단기 작업 중 7개에서 최대 100개의 데모만으로 70% 이상의 성공률을 달성했으며, 두 작업에서는 100% 성공률을 기록하여 베이스라인보다 우수한 성능을 보였습니다.
* **새로운 형태 적응:** 이중 팔 프랭카 로봇 및 아폴로 휴머노이드 로봇에 성공적으로 적응하여, 로봇 형태가 바뀐 후에도 강건성과 일반화 능력을 유지하며 싱글 태스크 확산 베이스라인을 능가했습니다.
* **안전성 평가:** 편향 유발 포인팅 쿼리에 대해 96%의 거부율을 달성했으며, ASIMOV 벤치마크에서 물리적 안전성에 대한 강력한 의미론적 이해를 보여주었고, Constitutional AI를 통해 성능이 더욱 향상되었습니다.

## 🧠 Insights & Discussion

* **성공 요인:** Gemini Robotics의 성공은 (1) 강화된 구현된 추론 능력을 갖춘 강력한 VLM 백본, (2) 방대한 로봇 행동 데이터와 다양한 비로봇 데이터를 결합한 로봇 특화 학습 방식, (3) 저지연 로봇 제어를 위한 독자적인 아키텍처의 결합에 기인합니다.
* **의미:** 본 연구는 물리적 세계에서 범용 자율 AI를 실현하기 위한 중요한 진전을 나타냅니다. 이는 로봇 시스템이 세계를 이해하고, 학습하며, 지시를 받는 방식에 패러다임 전환을 가져올 것입니다. Gemini Robotics는 로봇에게 세계 작동 방식에 대한 일반적인 이해를 제공하여 광범위한 작업에 적응할 수 있도록 합니다.
* **한계 및 향후 연구:**
  * Gemini 2.0 및 Gemini Robotics-ER은 긴 비디오에서 공간 관계를 이해하거나 미세한 로봇 제어에 필요한 정밀한 수치 예측에서 여전히 개선의 여지가 있습니다.
  * 향후 연구는 복잡한 다단계 추론과 정밀한 섬세한 움직임을 동시에 요구하는 시나리오를 처리하는 능력 향상에 집중할 것입니다.
  * 시뮬레이션을 활용하여 시각적으로 다양하고 접촉이 풍부한 데이터를 생성하고, 이를 통해 실제 세계로 전이 가능한 VLA 모델을 구축하는 기술을 개발할 계획입니다.
  * 다중 형태 실험을 확장하여 새로운 로봇 유형에 적응하는 데 필요한 데이터 양을 줄이고, 궁극적으로 제로샷 교차 형태(zero-shot cross-embodiment) 전이를 목표로 합니다.
* **사회적 영향 및 안전:** Gemini Robotics와 같은 강력한 로봇 모델은 사회에 긍정적인 영향을 미칠 잠재력이 크지만, 그 안전성과 광범위한 사회적 영향도 함께 고려해야 합니다. 본 연구는 안전을 염두에 두고 설계되었으며, 향후에도 이러한 기술의 잠재력이 안전하고 책임감 있게 활용될 수 있도록 지속적으로 노력할 것입니다.

## 📌 TL;DR

**문제:** 디지털 영역에서 성공적인 대규모 멀티모달 모델의 일반화 능력을 구현된 추론과 능숙한 행동이 필요한 물리적 로봇으로 확장하는 것입니다.
**방법:** Gemini 2.0을 기반으로 'Gemini Robotics' 제품군을 개발했습니다. 이 제품군은 구현된 추론 강화를 위한 VLM인 'Gemini Robotics-ER' (새로운 ERQA 벤치마크로 평가)과 실제 로봇의 직접적이고 섬세한 제어를 위한 VLA 모델인 'Gemini Robotics'로 구성됩니다. Gemini Robotics는 광범위한 로봇 행동 데이터와 다양한 멀티모달 데이터를 학습하며, 제로샷/소량샷 제어, 긴 시야 작업 특화, 새로운 로봇 형태 적응 능력을 보여줍니다.
**주요 결과:** Gemini Robotics는 다양한 섬세한 조작 작업에서 베이스라인을 크게 능가하며, 시각, 지시, 행동 변화에 대한 강력한 일반화 능력을 보입니다. 제한된 데이터로 새로운 작업과 로봇 형태에 빠르게 적응할 수 있으며, 강화된 추론 능력과 강력한 VLM 백본이 핵심임을 입증했습니다. 모델의 안전성 또한 평가되고 완화 조치가 통합되었습니다.
