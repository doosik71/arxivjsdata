# TidyBot: 대규모 언어 모델을 활용한 개인 맞춤형 로봇 지원

Jimmy Wu, Rika Antonova, Adam Kan, Marion Lepert, Andy Zeng, Shuran Song, Jeannette Bohg, Szymon Rusinkiewicz, Thomas Funkhouser

## 🧩 Problem to Solve

로봇이 개인화된 물리적 지원을 효과적으로 제공하기 위해서는 사용자의 선호를 일반화하여 미래의 다양한 시나리오에 재적용할 수 있도록 학습해야 합니다. 특히, 방을 정리하고 물건을 올바른 장소에 보관하는 가사 정리 작업에서, 각 물건의 "적절한 장소"는 개인의 취향이나 문화적 배경에 따라 크게 달라지므로 이를 결정하는 것이 핵심 과제입니다. 기존 방식들은 모든 물건의 목표 위치를 수동으로 지정해야 하거나, 일반적인(개인화되지 않은) 규칙을 학습하거나, 방대한 사용자 선호 데이터를 수집해야 하는 한계가 있습니다. 이 연구의 목표는 소수의 상호작용 예시로부터 사용자 선호를 학습하고, 이를 폭넓게 적용 가능한 일반화된 규칙으로 추론하는 시스템을 구축하는 것입니다.

## ✨ Key Contributions

* **LLM 요약 기반 일반화 아이디어:** 대규모 언어 모델(LLM)의 텍스트 요약 능력을 로봇 공학의 일반화 수단으로 활용하는 새로운 아이디어를 제시했습니다. 이는 적은 수의 예시만으로도 개인화된 규칙을 도출하여 미래 상호작용에 빠르게 적용 가능하게 합니다.
* **벤치마크 데이터셋 공개:** 물건 보관 장소 선택 선호도 일반화를 평가하기 위한 벤치마크 데이터셋을 공개하여 정량적 평가를 가능하게 했습니다.
* **실제 로봇 시스템 구현 및 평가:** 제안된 접근 방식을 실제 모바일 매니퓰레이터 시스템인 TidyBot에 구현하고, 실제 환경에서 성능을 평가했습니다.
* **확장된 연구 내용 (저널 버전):** 인간 선호도 사용자 연구, 실제 시스템의 인식 구성 요소에 대한 정량적 분석, 벤치마크 데이터셋의 추가 통계, 시스템의 한계 요약 등을 포함합니다.

## 📎 Related Works

* **가사 정리 (Household cleanup):** 기존 연구들은 주로 물건 보관 위치를 수동으로 지정하거나(Rasch et al., 2019; Yan et al., 2021) 여러 사용자의 평균적인 선호를 통해 일반적인 규칙을 학습했습니다(Taniguchi et al., 2021; Kant et al., 2022; Sarch et al., 2022). 개인화에 초점을 맞춘 연구들은 협력 필터링(Abdo et al., 2015), 공간 관계(Kang et al., 2018), 학습된 잠재 선호 벡터(Kapelyukh and Johns, 2022) 등을 사용했지만, 대규모 데이터셋 수집이 필요했습니다. 본 연구는 LLM을 추가 훈련이나 데이터 수집 없이 활용합니다.
* **객체 정렬 (Object sorting):** 로봇 공학에서 객체 정렬은 주로 색상, 모양, 크기, 재질 등 물리적 속성을 기반으로 클러스터링, 능동 학습, 휴리스틱 검색 등을 사용하여 수행되었습니다(Gupta and Sukhatme, 2012; Kujala et al., 2016; Herde et al., 2018). 최근에는 LLM을 활용하여 객체 분류를 개선하는 연구도 있었지만(Høeg and Tingelstad, 2022), 미리 정의된 분류 규칙에 기반했습니다.
* **로봇 공학의 LLM (LLMs for robotics):** LLM은 상식 추론 능력으로 로봇 시스템의 고수준 계획(Brohan et al., 2022; Huang et al., 2022; Zeng et al., 2022)이나 환경 상태에 대한 접지(grounding) 등에 활용되었습니다. 그러나 이러한 연구들은 주로 일반적인 계획에 중점을 두었으며, 다양한 사용자 선호도를 처리하는 개인 맞춤형 시스템에는 적합하지 않았습니다. 본 연구는 LLM의 요약 능력을 통해 로봇 공학에서 일반화를 가능하게 합니다.

## 🛠️ Methodology

본 연구는 LLM의 요약 기능을 활용하여 소수의 예시로부터 사용자 선호를 일반화합니다.

1. **개인 맞춤형 물건 보관 장소 선택 ($$Receptacle\ Selection$$):**
    * **사용자 예시 제공:** 사용자가 몇 가지 객체 배치 선호 예시(예: "노란색 셔츠는 서랍에, 짙은 보라색 셔츠는 옷장에")를 텍스트로 제공합니다.
    * **LLM 프롬프트 구성:** 이 예시들은 LLM이 학습한 대량의 코드 데이터에 유리하도록 Python 코드 형식으로 LLM 프롬프트에 전달됩니다. 프롬프트는 현장의 객체 목록, 잠재적 보관 장소 목록, 그리고 사용자 선호를 반영하는 `pickandplace` 명령으로 구성됩니다.
    * **규칙 요약:** LLM은 제공된 예시들을 종합하여 일반화된 규칙(예: "밝은 색 옷은 서랍에, 어두운 색 옷은 옷장에")을 요약합니다.
    * **새로운 객체 배치 예측:** 이 요약된 규칙을 바탕으로 LLM은 새로운, 미확인 객체들의 적절한 배치 위치를 예측하는 `pickandplace` 명령을 생성합니다.

2. **개인 맞춤형 조작 기본 동작 선택 ($$Primitive\ Selection$$):**
    * 물건 보관 장소 선택과 유사하게, LLM의 요약 기능을 활용하여 객체 조작 방식(예: `pickandplace` 대 `pickandtoss`)에 대한 일반화된 규칙을 추론합니다.
    * 사용자는 객체와 선호하는 조작 기본 동작에 대한 몇 가지 예시를 제공하고, LLM은 이를 요약합니다.
    * 요약된 규칙은 미확인 객체에 적용할 적절한 조작 기본 동작을 예측하는 데 사용됩니다.

3. **실제 로봇 시스템 ($$TidyBot$$):**
    * **초기 설정:** 새로운 사용자마다, LLM은 제공된 예시를 통해 사용자에게 개인화된 일반화된 객체 카테고리, 선호하는 보관 장소, 그리고 조작 기본 동작에 대한 규칙을 생성합니다.
    * **반복적인 정리 작업:** 로봇은 바닥에 더 이상 물건이 없을 때까지 다음 단계를 반복합니다.
        1. **객체 위치 파악:** 상단 카메라와 ViLD (Gu et al., 2021)를 사용하여 가장 가까운 객체를 2D로 파악합니다.
        2. **이동:** 로봇이 해당 객체로 이동합니다.
        3. **객체 분류:** 로봇에 장착된 카메라로 객체의 근접 이미지를 촬영한 후, CLIP (Radford et al., 2021)을 사용하여 객체를 LLM이 요약하여 생성한 일반화된 카테고리(예: "밝은 색 옷", "어두운 색 옷") 중 하나로 분류합니다. LLM 요약에서 추출된 명사(구)는 CLIP의 대상 레이블 세트로 사용됩니다.
        4. **조치 결정:** LLM은 요약된 규칙과 분류된 객체 카테고리를 사용하여 해당 객체의 적절한 보관 장소와 조작 기본 동작을 결정합니다.
        5. **조작 실행:** 로봇은 객체를 집어 들고 선택된 기본 동작(예: `pickandplace` 또는 `pickandtoss`)을 실행하여 지정된 보관 장소에 놓습니다.

    * **핵심 장점:** LLM의 요약은 지각 시스템에 적은 수의 일반화된 객체 카테고리를 자동으로 제공함으로써, 객체 분류기가 적은 수의 범주를 구분하도록 하여 시스템의 강건성과 유연성을 높입니다.

## 📊 Results

1. **벤치마크 데이터셋 평가:**
    * **미확인 객체 정확도:** 제안된 요약 방식은 벤치마크 데이터셋에서 미확인 객체에 대해 91.2%의 높은 정확도를 달성했습니다.
    * **기준선 비교 (미확인 객체 정확도):**
        * "예시만 사용" (요약 없음): 78.5%
        * WordNet 온톨로지: 67.5%
        * RoBERTa 임베딩: 77.8%
        * CLIP 임베딩: 83.7%
        * LLM 요약 방식이 모든 기준선보다 우수한 성능을 보였습니다.
    * **절제 연구:**
        * 상식 추론만 사용 (선호도 없음): 45.0% (개인화된 선호 학습의 중요성 강조).
        * 인간 작성 요약 (최적): 97.5% (LLM 요약의 잠재적 개선 여지 시사).
        * 다양한 LLM 비교: `text-davinci-003` (91.2%)이 `text-davinci-002`, `code-davinci-002`, PaLM 540B보다 뛰어났습니다.
    * **인간 평가:**
        * 사용자 연구 결과, 우리 LLM 요약 방식은 CLIP 임베딩 기준선보다 46.9% 더 선호되었으며 (CLIP은 19.1%, 동등 선호 34.1%), 통계적으로 유의미한 차이를 보였습니다 ($$p < 0.001$$).
        * 인간 선호 응답은 82.2%의 확률로 벤치마크 정답과 일치했습니다.

2. **실제 로봇 ($$TidyBot$$) 실험:**
    * **전체 성공률:** TidyBot은 8가지 실제 시나리오에서 85.0%의 객체를 올바른 보관 장소에 넣는 데 성공했습니다.
    * **성능 세부 지표:**
        * 객체 위치 파악 (상단 카메라): 92.5%
        * 객체 카테고리 분류 (CLIP): 95.5% (위치 파악된 객체 중)
        * LLM 보관 장소 및 조작 기본 동작 선택: 100% (분류된 객체에 대해)
        * 조작 기본 동작 실행: 96.2% (위치 파악된 객체 중)
    * **작업 속도:** 로봇은 각 객체를 집어 들고 정리하는 데 평균 15-20초가 소요되었습니다.
    * **시각-언어 모델 (VLM) 평가:** LLM 요약 카테고리를 사용했을 때, CLIP이 95.5%의 정확도로 ViLD (76.1%) 및 OWL-ViT (45.9%)보다 가장 우수한 객체 분류 성능을 보였습니다. 요약된 카테고리 사용이 시나리오 내 전체 객체 이름 사용 (CLIP 70.7%)이나 모든 객체 이름 사용 (CLIP 52.3%)보다 훨씬 효과적이었습니다.

## 🧠 Insights & Discussion

* **LLM 요약의 일반화 능력:** LLM의 요약 기능은 개인화된 로봇 공학에서 소수의 예시로부터 사용자 선호를 일반화하는 강력한 수단임을 입증했습니다. 이는 대규모 데이터 수집 및 모델 훈련의 필요성을 줄이고, 사전 훈련된 LLM의 방대한 지식을 직접 활용합니다.
* **인간 해석 가능한 규칙:** LLM이 생성하는 규칙은 텍스트 형태이므로 인간이 쉽게 이해할 수 있으며, CLIP과 같은 개방형 어휘 분류기를 통해 비전 시스템에 효과적으로 접목될 수 있습니다.
* **강건하고 유연한 인식:** LLM이 "밝은 색 옷"과 같은 일반화된 카테고리를 생성함으로써, 비전 시스템은 훨씬 적은 수의 레이블로 작동할 수 있어 견고성과 유연성을 확보하고, 새로운 객체나 다른 사용자 선호에 빠르게 적응할 수 있습니다.
* **한계점:**
  * **LLM 요약의 오류:** 때때로 LLM이 일반화된 카테고리 대신 개별 객체 이름을 나열하거나, 보관 장소를 부적절하게 그룹화하여 일반화 성능을 저해할 수 있습니다.
  * **실제 시스템의 간소화:** 현재 TidyBot 구현은 수동으로 작성된 조작 기본 동작, 상향식 파악 방식, 그리고 알려진 보관 장소 위치를 가정하는 등 일부 간소화가 이루어졌습니다.
  * **복잡한 환경 처리:** 로봇이 물건 위로 이동할 수 없으므로, 과도하게 어지럽혀진 환경에서는 효율적으로 작동하지 않습니다. 경로를 확보하기 위한 고수준 계획 통합이 필요합니다.

## 📌 TL;DR

본 논문은 대규모 언어 모델(LLM)의 요약 기능을 활용하여 사용자 선호를 소수의 예시로부터 학습하고 일반화하는 개인 맞춤형 로봇 정리 시스템인 TidyBot을 제시합니다. 로봇이 개인화된 방식으로 물건을 정리하기 위해 사용자 선호의 다양성이라는 핵심 문제를 해결합니다. TidyBot은 LLM 요약을 통해 객체 보관 장소와 조작 기본 동작(예: 집어 놓기 vs. 던지기)에 대한 일반화된 규칙을 추론하고, 이를 개방형 어휘 비전 시스템(CLIP)과 결합하여 LLM이 정의한 일반화된 객체 카테고리를 인식합니다. 이 접근 방식은 벤치마크 데이터셋에서 미확인 객체에 대해 91.2%의 정확도를, 실제 정리 시나리오에서는 85.0%의 성공률을 달성하여, LLM 요약이 개인 맞춤형 로봇 공학에서 빠르고 효과적인 적응을 위한 강력하고 유망한 방향임을 보여줍니다.
