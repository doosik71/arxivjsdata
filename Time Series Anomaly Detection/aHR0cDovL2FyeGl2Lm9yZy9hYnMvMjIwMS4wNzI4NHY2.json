{
  "title": "TranAD: Deep Transformer Networks for Anomaly Detection in Multivariate\n  Time Series Data",
  "authors": "Shreshth Tuli, Giuliano Casale, Nicholas R. Jennings",
  "year": 2022,
  "url": "http://arxiv.org/abs/2201.07284v6",
  "abstract": "Efficient anomaly detection and diagnosis in multivariate time-series data is\nof great importance for modern industrial applications. However, building a\nsystem that is able to quickly and accurately pinpoint anomalous observations\nis a challenging problem. This is due to the lack of anomaly labels, high data\nvolatility and the demands of ultra-low inference times in modern applications.\nDespite the recent developments of deep learning approaches for anomaly\ndetection, only a few of them can address all of these challenges. In this\npaper, we propose TranAD, a deep transformer network based anomaly detection\nand diagnosis model which uses attention-based sequence encoders to swiftly\nperform inference with the knowledge of the broader temporal trends in the\ndata. TranAD uses focus score-based self-conditioning to enable robust\nmulti-modal feature extraction and adversarial training to gain stability.\nAdditionally, model-agnostic meta learning (MAML) allows us to train the model\nusing limited data. Extensive empirical studies on six publicly available\ndatasets demonstrate that TranAD can outperform state-of-the-art baseline\nmethods in detection and diagnosis performance with data and time-efficient\ntraining. Specifically, TranAD increases F1 scores by up to 17%, reducing\ntraining times by up to 99% compared to the baselines.",
  "citation": 984
}