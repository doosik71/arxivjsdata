# TranAD: Deep Transformer Networks for Anomaly Detection in Multivariate Time Series Data

Shreshth Tuli, Giuliano Casale, Nicholas R. Jennings

## 🧩 Problem to Solve

다변량 시계열 데이터에서 효율적인 이상 감지 및 진단은 현대 산업 애플리케이션에 매우 중요합니다. 하지만 다음과 같은 문제들로 인해 빠르고 정확하게 이상 징후를 식별하는 시스템을 구축하는 것은 어렵습니다:

- 이상 레이블의 부족으로 인해 지도 학습 모델을 사용할 수 없습니다.
- 높은 데이터 변동성과 대규모 IoT 플랫폼의 증가하는 센서 수로 인해 정확한 추론을 위한 많은 데이터가 필요하지만, 분산 환경에서는 데이터 가용성이 제한됩니다.
- 최신 애플리케이션은 빠른 복구와 최적의 서비스 품질을 위해 초저속 추론 시간을 요구합니다.
- 시계열 데이터는 확률적 및 시간적 경향을 모두 보이므로, 단순히 확률적 요인으로 인한 이상치와 실제 시간적 경향에서 벗어나는 이상치를 구분하기 어렵습니다.
- 단순히 이상을 감지하는 것을 넘어, 이상 행동을 유발하는 특정 데이터 소스(근본 원인)를 진단하는 것도 필요합니다.
- 기존 딥러닝 접근 방식(특히 순환 모델)은 속도가 느리고 장기적인 시간적 경향을 효과적으로 모델링하는 데 어려움이 있으며, 고정된 크기의 입력 윈도우는 제한된 국소 컨텍스트 정보를 제공하여 성능을 저해합니다.

## ✨ Key Contributions

본 논문은 이러한 문제들을 해결하기 위해 TranAD를 제안하며, 주요 기여는 다음과 같습니다:

- **Transformer 기반 이상 감지 및 진단 모델 제안**: 어텐션 기반 시퀀스 인코더를 사용하여 데이터의 광범위한 시간적 경향을 파악하고 신속한 추론을 수행합니다.
- **포커스 스코어 기반 자기 조건화 (Self-Conditioning) 도입**: 재구성 손실을 포커스 스코어로 사용하여 이상 징후를 증폭하고 견고한 다중 모드 특징 추출을 가능하게 합니다. 이는 모델의 안정성을 높이고 미묘한 이상까지 감지할 수 있도록 돕습니다.
- **적대적 학습 (Adversarial Training) 적용**: 재구성 오류를 증폭하고 모델의 안정성과 일반화 능력을 향상시킵니다.
- **모델 불가지론적 메타 학습 (MAML) 활용**: 제한된 훈련 데이터만으로도 모델이 최적의 감지 성능을 유지하며 빠르게 적응할 수 있도록 합니다.
- **최첨단 성능 달성**: 6개의 공개 데이터셋에 대한 광범위한 실험을 통해, 기존 최첨단 모델 대비 F1 점수를 최대 17% 향상시키고 훈련 시간을 최대 99% 단축했음을 입증합니다.

## 📎 Related Works

- **고전적 방법론**:
  - `k-Mean 군집`, `SVM`, `회귀 모델`, `웨이블릿 이론`, `힐베르트 변환` 등을 사용하여 시계열 분포를 모델링하고 이상을 감지합니다.
  - `PCA`, `과정 회귀(process regression)`, `은닉 마르코프 연쇄(HMM)` 등을 사용하기도 합니다.
  - `GraphAn`은 시계열을 그래프로 변환하고 그래프 거리 측정 지표를 사용합니다. `Isolation Forest`는 여러 고립 트리를 사용하여 특성 공간을 재귀적으로 분할합니다.
  - `ARIMA` 계열 모델은 고차원 다변량 시계열에는 비효율적입니다.
  - `SAND`, `CPOD`, `Elle` 등은 군집 및 데이터베이스 읽기/쓰기 이력을 활용합니다.
  - `MERLIN`은 시계열 불일치(discords)를 탐지하는 최신 파라미터 없는 접근 방식입니다.
- **딥러닝 기반 방법론**:
  - **순환 신경망 (RNN) 기반**:
    - `LSTM-NDT`: LSTM 기반 모델과 비모수 동적 오류 임계값(NDT) 전략을 사용하지만, 긴 시퀀스에서 훈련이 느리고 장기 패턴 모델링에 비효율적입니다.
    - `DAGMM`: 딥 오토인코딩 가우시안 혼합 모델을 사용하지만, 속도가 느리고 모드 간 상관관계를 명시적으로 활용하지 못합니다.
    - `OmniAnomaly`: 확률적 순환 신경망과 플래너 정규화 흐름(planar normalizing flow)을 사용하며 높은 훈련 시간을 가집니다.
    - `MSCRED`: 입력 윈도우를 2D 이미지로 변환 후 ConvLSTM을 사용하지만, 훈련 데이터가 부족할 때 일반화하기 어렵습니다.
    - `MAD-GAN`: LSTM 기반 GAN을 사용하여 예측 오류와 판별자 손실을 이상 점수에 사용합니다.
    - `CAE-M`: CNN과 양방향 LSTM을 사용하여 장기적인 시간적 경향을 포착합니다. 이러한 RNN 기반 모델은 높은 계산 비용과 낮은 확장성을 가집니다.
  - **어텐션 기반 / 비순환 모델**:
    - `USAD`: 두 개의 디코더를 가진 오토인코더와 적대적 학습 프레임워크를 사용하여 훈련 시간을 크게 단축했습니다.
    - `GDN`: 데이터 모드 간 관계 그래프를 학습하고 어텐션 기반 예측을 사용합니다.
    - `openGauss`: 트리 기반 LSTM으로 메모리와 계산 비용이 낮습니다.
    - `HitAnomaly`: 일반적인 트랜스포머를 사용하지만, 자연어 로그 데이터에 특화되어 일반 시계열 데이터에는 적합하지 않습니다.

## 🛠️ Methodology

TranAD는 다음과 같은 단계와 구성요소로 동작합니다:

1. **문제 정의 ($3.1 Problem Formulation$)**:

   - 다변량 시계열 $T = \{x_1, \ldots, x_T\}$ ($x_t \in \mathbb{R}^m$)가 주어질 때, 테스트 시계열 $\hat{T}$에 대해 각 시점 $t$의 데이터 포인트 $y_t \in \{0,1\}$ (이상 감지) 또는 $y_t \in \{0,1\}^m$ (이상 진단)를 예측합니다.

2. **데이터 전처리 ($3.2 Data Preprocessing$)**:

   - **정규화**: 각 모드에 대해 최소-최대 정규화를 통해 데이터를 $[0,1)$ 범위로 조정합니다:
     $$x_t \leftarrow \frac{x_t - \min(T)}{\max(T) - \min(T) + \epsilon'}$$
   - **윈도우화**: 데이터 포인트 $x_t$의 국소 컨텍스트를 고려하기 위해 길이 $K$의 슬라이딩 윈도우 $W_t = \{x_{t-K+1}, \ldots, x_t\}$를 생성합니다. (초기 시점에는 복제 패딩 사용)

3. **트랜스포머 모델 ($3.3 Transformer Model$)**:

   - **아키텍처**: 인코더 2개와 디코더 2개로 구성된 인코더-디코더 네트워크입니다 (그림 1 참조).
     - **스케일드 닷-프로덕트 어텐션**: $Attention(Q,K,V) = \text{softmax}\left(\frac{QK^T}{\sqrt{m}}\right)V$
     - **멀티-헤드 셀프 어텐션**: 다양한 표현 부분 공간에서 여러 위치의 정보에 동시에 집중할 수 있도록 합니다.
     - **위치 인코딩**: 시퀀스의 순서 정보를 제공합니다.
   - **인코더 (Encoder)**:
     - 현재 시점까지의 전체 시퀀스 $C$와 입력 윈도우 $W$를 포커스 스코어 $F$ (초기에는 0 행렬)와 함께 인코딩하여 압축된 잠재 표현 $I^2_3$를 생성합니다.
     - 병렬 추론을 위해 각 시점에서 이전 시점의 출력에 의존하지 않습니다.
     - 윈도우 인코더는 미래 시점의 데이터를 보지 않도록 마스킹된 멀티-헤드 어텐션을 사용합니다.
   - **디코더 (Decoder)**:
     - 두 개의 동일한 디코더가 인코딩된 표현 $I^2_3$를 받아 입력 윈도우의 재구성 $O_1, O_2$를 생성합니다: $O_i = \text{Sigmoid}(\text{FeedForward}(I^2_3))$

4. **오프라인 2단계 적대적 학습 ($3.4 Offline Two-Phase Adversarial Training$, 알고리즘 1)**:

   - **1단계 - 입력 재구성 (Initial Reconstruction)**:
     - 모델은 초기 포커스 스코어 $F=0$를 사용하여 입력 윈도우 $W$의 근사 재구성 $O_1, O_2$를 생성합니다.
   - **2단계 - 포커스된 입력 재구성 (Self-Conditioning)**:
     - 1단계에서 생성된 첫 번째 디코더의 재구성 손실을 포커스 스코어 $F = \|O_1 - W\|^2_2$로 사용합니다.
     - 이 포커스 스코어는 트랜스포머 인코더 내의 어텐션 네트워크가 편차가 높은 부분 시퀀스에 집중하여 시간적 경향을 추출하도록 돕습니다.
     - 재실행된 모델 추론을 통해 두 번째 디코더의 출력 $\hat{O}_2$를 얻습니다. 이 과정은 재구성 오류를 증폭하고 단기 시간적 경향을 포착하며, 적대적 학습을 통해 모델의 일반화 능력을 강화합니다.
   - **진화하는 학습 목표 (Evolving Training Objective)**: 훈련 안정성을 위해 재구성 손실과 적대적 손실을 결합한 손실 함수를 사용합니다.
     - 초기 손실: $L_1 = \|O_1 - W\|^2_2$, $L_2 = \|O_2 - W\|^2_2$
     - 적대적 손실: 디코더 2는 $\|\hat{O}_2 - W\|^2_2$를 최대화하여 첫 번째 디코더의 재구성을 식별하려 하고, 디코더 1은 이를 최소화하려 합니다.
     - 결합된 손실 (알고리즘 1, 7-8행):
       $$L_1 = \epsilon^{-n}\|O_1 - W\|^2_2 + (1-\epsilon^{-n})\|\hat{O}_2 - W\|^2_2$$
       $$L_2 = \epsilon^{-n}\|O_2 - W\|^2_2 - (1-\epsilon^{-n})\|\hat{O}_2 - W\|^2_2$$
       여기서 $n$은 훈련 에포크, $\epsilon$은 훈련 파라미터입니다. 훈련 초기에는 재구성 손실에 높은 가중치를 주어 안정성을 확보하고, 점차 적대적 손실의 가중치를 높입니다.
   - **메타 학습 (MAML)**: 제한된 데이터로도 모델이 빠르게 적응할 수 있도록 각 훈련 에포크마다 메타 학습 단계를 수행합니다 (알고리즘 1, 11행).

5. **온라인 추론, 이상 감지 및 진단 ($3.5 Online Inference, Anomaly Detection and Diagnosis$, 알고리즘 2)**:
   - **이상 점수 계산**: 훈련된 모델을 사용하여 새로운 데이터 $\hat{W}$에 대한 이상 점수 $s$를 계산합니다:
     $$s = \frac{1}{2}\|O_1 - \hat{W}\|^2_2 + \frac{1}{2}\|\hat{O}_2 - \hat{W}\|^2_2$$
   - **임계값 설정**: Peak Over Threshold (POT) 방법을 사용하여 동적으로 이상 점수 임계값 $D$를 결정합니다.
   - **이상 감지 및 진단**:
     - 각 차원 $i$에 대해 $y_i = 1(s_i \ge POT(s_i))$이면 이상으로 레이블링합니다.
     - 전체 시점의 이상 여부는 $y = \bigvee_i y_i$로 정의합니다.

## 📊 Results

- **이상 감지 성능**:
  - TranAD는 9개의 공개 데이터셋에서 최첨단 기준선 모델을 크게 능가합니다.
  - F1 점수: 전체 훈련 데이터 사용 시 평균 0.8802, 20% 제한된 훈련 데이터 사용 시 평균 0.8012를 달성했습니다.
  - 최대 17.06%의 F1 점수 향상, 14.64%의 F1 점수 (제한된 데이터) 향상, 11.69%의 AUC 향상, 11.06%의 AUC\* 향상을 보였습니다.
  - 특히, WADI 데이터셋의 제한된 데이터 훈련과 MSL 데이터셋의 F1 점수 제외하고 모든 데이터셋에서 기준선보다 우수한 성능을 보였습니다.
  - Wilcoxon 쌍별 순위 검정 기반의 임계 차이 분석 결과, TranAD는 모든 모델 중 가장 높은 순위를 차지했습니다.
- **이상 진단 성능**:
  - SMD 및 MSDS 데이터셋에 대한 진단 결과에서 TranAD는 기준선 모델 대비 SMD에서 최대 6%, MSDS에서 최대 30%의 진단 점수 (HitRate 및 NDCG) 향상을 보였습니다.
  - 감지된 이상 징후에 대해 46.3%에서 75.3%에 이르는 근본 원인을 정확하게 식별했습니다.
- **훈련 시간 효율성**:
  - TranAD는 기준선 모델 대비 75%에서 99% 낮은 훈련 시간을 기록하여, 탁월한 시간 효율성을 입증했습니다. 이는 트랜스포머의 병렬 추론 능력 덕분입니다.

## 🧠 Insights & Discussion

- **모델 구성 요소의 중요성 (Ablation Study)**:
  - 트랜스포머 기반 인코더-디코더 아키텍처는 가장 중요한 구성 요소로, 이를 제거하면 F1 점수가 평균 약 11% (WADI 데이터셋에서는 56%) 하락했습니다.
  - 자기 조건화(self-conditioning)를 제거하면 F1 점수가 평균 6% 하락하여, 포커스 스코어의 중요성을 보여줍니다.
  - 적대적 학습을 제거하면 F1 점수가 평균 5% 하락했으며, 특히 미묘한 이상 징후가 많은 SMD 및 WADI 데이터셋에서 성능 저하가 컸습니다.
  - MAML을 제거하면 F1 점수에는 약 1%의 미미한 영향이 있었지만, 제한된 데이터에서의 F1\* 점수는 약 12% 하락하여, 제한된 데이터 학습 시 MAML의 핵심적인 역할을 확인했습니다.
- **훈련 데이터 크기 및 윈도우 크기에 대한 민감도**:
  - 훈련 데이터 크기가 증가할수록 F1 및 AUC 점수는 향상되고 훈련 시간은 증가합니다. TranAD는 모든 비율에서 더 높은 F1 점수와 낮은 훈련 시간을 유지합니다.
  - 윈도우 크기 10이 F1 점수와 훈련 시간 사이의 합리적인 균형을 제공합니다. 윈도우가 너무 작으면 국소 컨텍스트 정보를 잘 표현하지 못하고, 너무 크면 짧은 이상 징후가 가려질 수 있습니다.
- **의미 및 시사점**: TranAD는 트랜스포머의 장기적 경향 포착 능력, 적대적 학습을 통한 오류 증폭, MAML을 통한 제한된 데이터 적응 능력을 결합하여 빠르고 정확하며 진단 가능한 이상 감지 솔루션을 제공합니다. 이는 정확하고 신속한 이상 예측이 필요한 현대 산업 시스템에 이상적인 선택입니다.
- **향후 연구**: 양방향 신경망과 같은 다른 트랜스포머 모델로 방법을 확장하여 데이터의 다양한 시간적 경향에 대한 모델 일반화를 높이고, 배포 환경에 따른 각 모델 구성 요소의 비용-편익 분석을 탐색할 계획입니다.

## 📌 TL;DR

TranAD는 다변량 시계열 데이터에서 빠르고 정확하며 진단 가능한 이상 감지를 위한 딥 트랜스포머 네트워크입니다. 이 모델은 광범위한 시간적 경향을 포착하는 어텐션 기반 인코더, 재구성 오류를 증폭하고 안정성을 높이는 포커스 스코어 기반 자기 조건화 및 적대적 학습, 그리고 제한된 데이터로도 빠르게 학습할 수 있는 MAML을 통합합니다. 실험 결과, TranAD는 최첨단 모델 대비 F1 점수를 최대 17% 향상시키고 훈련 시간을 최대 99% 단축하며, 이상 징후의 근본 원인을 최대 75%까지 정확하게 진단하는 뛰어난 성능을 보였습니다.
