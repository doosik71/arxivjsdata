# Do Deep Neural Networks Contribute to Multivariate Time Series Anomaly Detection?

Julien Audibert, Pietro Michiardi, Fréderic Guyard, Sébastien Marti, Maria A. Zuluaga

## 🧩 Problem to Solve

최근 시계열 이상 탐지 분야에서 딥러닝(DNN) 기반의 학습 방법론들이 압도적으로 우세하다는 인식이 확산되며, 기존의 통계적/머신러닝 방법론들과의 비교가 소홀해지는 경향이 있습니다. 이 연구는 DNN 기반 방법론들의 복잡성이 실제 성능 향상으로 이어지는지에 대한 의문을 제기하며, 다변량 시계열 이상 탐지에서 기존 방법론들에 비해 DNN의 기여도가 진정으로 큰지 종합적으로 검증하고자 합니다.

## ✨ Key Contributions

- 다변량 시계열 이상 탐지를 위한 16가지 주요 방법론(기존, 머신러닝 기반, DNN 기반)들을 세 가지 범주로 분류하여 상세히 기술했습니다.
- 다섯 가지 실제 공개 데이터셋에 대해 이 방법론들의 성능을 비교 및 분석했습니다.
- DNN 기반 접근 방식의 필요성과 향후 다변량 시계열 이상 탐지 벤치마크에서 기존 방법론들의 중요성을 논의하며, 모든 범주의 방법론들을 벤치마크에 재포함할 것을 제안했습니다.

## 📎 Related Works

- **DNN의 한계**: Jiao et al. [13]은 광학 이미징 문제에서 기존 선형 회귀 방법이 DNN보다 우수함을 보였고, Antun et al. [11]과 Heaven [12]은 이미지 재구성 DNN의 불안정성과 입력 데이터에 대한 민감성을 지적했습니다. Fu et al. [15]는 의료 영상 분할에서 복잡한 DNN보다 단순한 DNN 구성이 더 나은 일반화 성능을 가짐을 보여 DNN의 복잡성 증가 추세에 도전했습니다.
- **시계열 분석 벤치마크의 부재**: Garg et al. [16]은 시계열 이상 탐지를 위한 다변량 방법들 간의 벤치마크가 부족하다고 언급하며 15개 방법 중 12개가 DNN인 벤치마크를 제안했습니다.
- **M3/M4 시계열 예측 대회**: Makridakis et al. [14, 17]의 M3 및 M4 대회 결과는 머신러닝 및 DNN 모델의 예측 정확도가 기존 통계적 접근 방식보다 낮거나, 계산 요구 사항이 훨씬 크다는 점을 시사했습니다.

## 🛠️ Methodology

이 연구는 세 가지 범주(기존, 머신러닝 기반, DNN 기반)에 속하는 총 16가지 다변량 시계열 이상 탐지 방법론들을 비교 평가했습니다.

1. **방법론 분류 및 선택**:
   - **기존(Conventional) 방법**: MCUSUM, MEWMA (제어 차트), VAR (예측), PCA, SSA, ICA (분해), Matrix-Profile (유사성 검색).
   - **머신러닝 기반(Machine Learning-based) 방법**: Isolation Forest (IF), Local Outlier Factor (LOF), DBSCAN (이웃 기반), One-Class Support Vector Machine (OC-SVM) (영역 기반).
   - **DNN 기반(DNN-based) 방법**: Auto-Encoder (AE), UnSupervised Anomaly Detection (USAD), Long Short-Term Memory Variational Auto-Encoders (LSTM-VAE), Deep Autoencoding Gaussian Mixture Model (DAGMM), OmniAnomaly (OA).
2. **데이터셋**: SWaT, WADI, SMD, SMAP, MSL의 다섯 가지 실제 공개 데이터셋을 사용했습니다. 이 데이터셋들은 포인트, 맥락적, 집단적 이상(point, contextual, collective anomalies)을 포함합니다.
3. **평가 지표**: F1 점수($F1 = 2 \cdot P \cdot R / (P+R)$)와 평균 정밀도(Average Precision, AP)를 사용하여 성능을 평가했습니다. F1 점수는 1000개의 임계값을 테스트하여 가장 높은 값을 선택했고, AP는 임계값 설정 없이 순위 매기기 능력을 평가했습니다.
4. **훈련 세트 크기 영향 분석**: WADI 및 SWaT 데이터셋에서 훈련 세트 크기(원본의 10%, 25%, 50%, 75%)가 방법론 성능에 미치는 영향을 분석했습니다.
5. **통계적 분석**: Kruskal–Wallis 테스트와 Dunn’s 테스트를 사용하여 방법론 범주 간의 통계적으로 유의미한 성능 차이를 검정했습니다.

## 📊 Results

- **전반적인 성능**: F1 및 AP 점수 측면에서 어떤 방법론 가족도 다른 가족을 일관되게 능가하지 못했습니다. F1 점수에서는 DNN 방법이 5개 데이터셋 중 4개에서 평균적으로 가장 우수했지만, AP 점수에서는 기존 방법이 MSL 데이터셋에서 가장 우수했고, 나머지 데이터셋에서는 DNN 다음으로 좋은 성능을 보였습니다.
- **통계적 유의미성**: Kruskal-Wallis 테스트 결과, F1 점수에서는 SMD에서만, AP 점수에서는 SWaT과 WADI에서만 방법론 가족 간의 유의미한 차이가 발견되었습니다. Dunn’s 테스트는 WADI에서 DNN과 기존 방법론 사이에 유의미한 차이가 있음을 보여주었습니다.
- **WADI 분석 (맥락적 이상 탐지)**: WADI 데이터셋에 대한 상세 분석 결과, DNN 방법론들이 기존 및 ML 방법론들이 놓친 맥락적 이상(contextual anomalies)들을 더 잘 탐지하는 경향이 있음을 시사했습니다.
- **훈련 세트 크기의 영향**: 훈련 세트 크기가 작을수록(원본의 50% 이하), 기존 방법론들이 DNN 및 ML 방법론들보다 전반적으로 더 나은 성능을 보였습니다. 훈련 세트가 50%를 넘어서야 DNN 방법론들이 기존 방법론들보다 우수한 성능을 나타내기 시작했습니다.
- **확장성**: 일부 기존 방법론들은 데이터셋이 너무 클 경우 수렴하지 못하는 확장성 문제를 보였습니다.

## 🧠 Insights & Discussion

- **DNN의 복잡성**: 다변량 시계열 이상 탐지에서 DNN 기반 방법론들의 복잡성이 항상 성능 향상으로 이어지는 것은 아니며, 최근 보고된 진전이 일부 환상일 수 있다는 점을 시사합니다.
- **맥락적 이상 탐지**: DNN은 맥락적 이상 탐지에서 강점을 보일 수 있지만, 이는 충분히 큰 데이터셋이 뒷받침될 때 유효합니다. 전문가가 시각적으로 맥락적 이상을 식별하기 어렵다는 점에서, DNN의 복잡한 패턴 학습 능력이 여기서 빛을 발할 수 있습니다.
- **훈련 데이터의 중요성**: 훈련 데이터셋의 크기는 방법론 선택의 중요한 기준이 됩니다. 데이터가 적을 때는 기존 방법론이 더 나은 선택일 수 있으며, DNN은 대규모 데이터에서 더 효과적입니다.
- **계산 자원 및 해석 가능성**: 기존 방법론은 훈련 단계가 필요 없거나 간결하여 계산 자원 소모가 적고 해석이 용이합니다. 반면 DNN은 훈련 비용이 높지만 추론 속도가 빠를 수 있습니다.
- **재현성 및 벤치마크의 필요성**: DNN 기반 방법론은 구현 및 설정이 어렵고 재현성이 낮을 수 있습니다. 따라서, 향후 벤치마크에서는 모든 범주의 방법론을 포함하고, 특히 맥락적 이상을 포함하는 다양한 실제 데이터셋을 확보하여 포괄적인 평가를 수행해야 합니다.

## 📌 TL;DR

다변량 시계열 이상 탐지에서 딥러닝(DNN)의 복잡성이 항상 기존 통계적/머신러닝 방법보다 우수한 성능으로 이어지는 것은 아닙니다. 16가지 방법론을 5개 데이터셋으로 비교한 결과, 어떤 방법론 가족도 전반적으로 압도적인 우위를 보이지 않았습니다. DNN은 대규모 데이터셋에서 맥락적 이상 탐지에 강점을 보일 수 있지만, 훈련 데이터가 충분하지 않거나 일반적인 이상 탐지 상황에서는 기존 방법론들이 더 효율적이고 효과적일 수 있습니다. 따라서, 시계열 이상 탐지 벤치마크에서 모든 범주의 방법론을 재평가하고 다양한 실제 데이터셋을 포함할 것을 권장합니다.
