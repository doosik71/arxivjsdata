{
  "url": "http://arxiv.org/abs/1711.06929v1",
  "title": "Deep Gaussian Mixture Models",
  "authors": "Cinzia Viroli, Geoffrey J. McLachlan",
  "year": 2017,
  "abstract": "Deep learning is a hierarchical inference method formed by subsequent\nmultiple layers of learning able to more efficiently describe complex\nrelationships. In this work, Deep Gaussian Mixture Models are introduced and\ndiscussed. A Deep Gaussian Mixture model (DGMM) is a network of multiple layers\nof latent variables, where, at each layer, the variables follow a mixture of\nGaussian distributions. Thus, the deep mixture model consists of a set of\nnested mixtures of linear models, which globally provide a nonlinear model able\nto describe the data in a very flexible way. In order to avoid\noverparameterized solutions, dimension reduction by factor models can be\napplied at each layer of the architecture thus resulting in deep mixtures of\nfactor analysers.",
  "citation": 200
}