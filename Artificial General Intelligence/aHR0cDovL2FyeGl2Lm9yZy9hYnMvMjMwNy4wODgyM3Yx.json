{
  "title": "Risk assessment at AGI companies: A review of popular risk assessment\n  techniques from other safety-critical industries",
  "authors": "Leonie Koessler, Jonas Schuett",
  "year": 2023,
  "url": "http://arxiv.org/abs/2307.08823v1",
  "abstract": "Companies like OpenAI, Google DeepMind, and Anthropic have the stated goal of\nbuilding artificial general intelligence (AGI) - AI systems that perform as\nwell as or better than humans on a wide variety of cognitive tasks. However,\nthere are increasing concerns that AGI would pose catastrophic risks. In light\nof this, AGI companies need to drastically improve their risk management\npractices. To support such efforts, this paper reviews popular risk assessment\ntechniques from other safety-critical industries and suggests ways in which AGI\ncompanies could use them to assess catastrophic risks from AI. The paper\ndiscusses three risk identification techniques (scenario analysis, fishbone\nmethod, and risk typologies and taxonomies), five risk analysis techniques\n(causal mapping, Delphi technique, cross-impact analysis, bow tie analysis, and\nsystem-theoretic process analysis), and two risk evaluation techniques\n(checklists and risk matrices). For each of them, the paper explains how they\nwork, suggests ways in which AGI companies could use them, discusses their\nbenefits and limitations, and makes recommendations. Finally, the paper\ndiscusses when to conduct risk assessments, when to use which technique, and\nhow to use any of them. The reviewed techniques will be obvious to risk\nmanagement professionals in other industries. And they will not be sufficient\nto assess catastrophic risks from AI. However, AGI companies should not skip\nthe straightforward step of reviewing best practices from other industries.",
  "citation": 41
}