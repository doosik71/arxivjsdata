{
  "title": "Large language models for artificial general intelligence (AGI): A\n  survey of foundational principles and approaches",
  "authors": "Alhassan Mumuni, Fuseini Mumuni",
  "year": 2025,
  "url": "http://arxiv.org/abs/2501.03151v1",
  "abstract": "Generative artificial intelligence (AI) systems based on large-scale\npretrained foundation models (PFMs) such as vision-language models, large\nlanguage models (LLMs), diffusion models and vision-language-action (VLA)\nmodels have demonstrated the ability to solve complex and truly non-trivial AI\nproblems in a wide variety of domains and contexts. Multimodal large language\nmodels (MLLMs), in particular, learn from vast and diverse data sources,\nallowing rich and nuanced representations of the world and, thereby, providing\nextensive capabilities, including the ability to reason, engage in meaningful\ndialog; collaborate with humans and other agents to jointly solve complex\nproblems; and understand social and emotional aspects of humans. Despite this\nimpressive feat, the cognitive abilities of state-of-the-art LLMs trained on\nlarge-scale datasets are still superficial and brittle. Consequently, generic\nLLMs are severely limited in their generalist capabilities. A number of\nfoundational problems -- embodiment, symbol grounding, causality and memory --\nare required to be addressed for LLMs to attain human-level general\nintelligence. These concepts are more aligned with human cognition and provide\nLLMs with inherent human-like cognitive properties that support the realization\nof physically-plausible, semantically meaningful, flexible and more\ngeneralizable knowledge and intelligence. In this work, we discuss the\naforementioned foundational issues and survey state-of-the art approaches for\nimplementing these concepts in LLMs. Specifically, we discuss how the\nprinciples of embodiment, symbol grounding, causality and memory can be\nleveraged toward the attainment of artificial general intelligence (AGI) in an\norganic manner.",
  "citation": 12
}