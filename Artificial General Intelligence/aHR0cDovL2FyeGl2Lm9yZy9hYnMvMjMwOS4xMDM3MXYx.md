# Generative AI vs. AGI: The Cognitive Strengths and Weaknesses of Modern LLMs

Ben Goertzel

## 🧩 Problem to Solve

이 논문은 2023년 중반의 ChatGPT, GPT-4, Bard, Llama 등 현대 대규모 언어 모델(LLM)을 인지 시스템으로 상세히 분석하고, 이들이 가진 인지적 강점과 약점을 탐구합니다. 주된 문제는 이러한 LLM이 인간 수준의 인공 일반 지능(AGI), 즉 인간과 유사한 모든 지능 기반 능력을 수행할 수 있는 "Human-Capable AGI (HCAGI)"와 얼마나 다른지, 그리고 현재의 LLM 아키텍처를 점진적으로 개선하는 것만으로는 현실적인 컴퓨팅 자원 내에서 HCAGI에 도달할 수 없다는 주장을 뒷받침하는 것입니다.

## ✨ Key Contributions

- **CILLM 및 HCAGI 개념 정의:** 상호작용 LLM을 "CILLM (Contemporary Interactive Large Language Models)"으로 정의하고, 인간 지능을 능가하는 잠재력을 포함하는 "HCAGI (Human-Capable AGI)" 개념을 도입하여 LLM과 AGI의 관계를 명확히 합니다.
- **LLM의 인지적 강점 분석:** CILLM이 일상적인 윤리적 딜레마를 해결하고 기업의 위선적인 PR을 모방하는 등 언어적 이해 및 추론에서 놀라운 능력을 보임을 사례를 통해 제시합니다. 이는 기존 AI 시스템의 예상을 뛰어넘는 성과입니다.
- **LLM의 인지적 약점 상세화:**
  - **만연한 환각 (Hallucination) 및 현실 판별 부족:** LLM이 존재하지 않는 사실이나 인물에 대한 정보를 그럴듯하게 날조하는 경향이 강하며, 자신이 생성한 내용의 사실 여부를 판별하는 능력이 결여되어 있음을 지적합니다.
  - **제한된 세계 모델링:** OthelloGPT와 같은 제한된 도메인에서는 암묵적 세계 모델을 학습할 수 있으나, 실제 세계의 복잡한 시공간적 관계나 물리적 추론(예: ASCII 아트, 물리학 문제)에서는 현저한 한계를 보입니다.
  - **제한된 마음 이론 (Theory of Mind, ToM):** 일부 ToM 퍼즐에서 성과를 보이더라도, 이는 훈련 데이터의 패턴을 모방한 것이며, 실제 ToM 능력은 매우 제한적임을 강조합니다.
  - **복잡한 다단계 추론 능력 부족:** SAT 수학 시험에서는 잘하지만, 더 복잡한 수학 및 논리 문제에서는 기본적인 실수를 반복하며, 추론 과정에서 "그럴듯한 헛소리"가 누적되는 문제가 있음을 밝힙니다.
  - **상투성과 근본적인 창의성 부족:** 시나 광고 문구 생성에서 매우 진부하고 상투적인 결과물을 내놓으며, 깊이 있는 개념적 이해보다는 표면적 패턴 모방에 그친다고 분석합니다.
  - **자기 주도성 및 자율성 결여:** LLM은 외부에서 주어진 목표를 추구할 수 있지만, 인간처럼 목표를 스스로 생성하고 관리하며, 복잡한 환경에서 장기적인 목표를 체계적으로 추구하는 능력이 없습니다.
- **인간 인지 모델과의 비교:** 인간 정신의 표준 모델(Standard Model of Mind)의 구성 요소(일화 기억, 작업 기억, 절차 기억, 추론, 학습, 지각, 운동, 목표 관리, 자기 이해 등)와 CILLM의 작동 방식을 비교하여, LLM의 근본적인 아키텍처가 인간 지능과 상당한 차이가 있음을 설명합니다.
- **AGI 달성을 위한 LLM의 한계 극복 방안 제시:** LLM을 단순히 개선하는 것을 넘어, 외부 메모리, 도구 통합, 지식 그래프 연결 등 "점진적 증강"이나, Bengio와 Hu의 RL/MDL 제안, OpenCog Hyperon과 같은 "광범위한 AGI 아키텍처"에 LLM을 보조적 구성 요소로 통합하는 하이브리드 접근 방식의 잠재력을 논의합니다.
- **사회적 및 윤리적 함의 분석:** LLM으로 인한 오정보 확산, 경제적 혼란 등의 사회적 위험을 인정하면서도, 현재 LLM이 HCAGI와는 거리가 멀기 때문에 AGI와 관련된 실존적 위협에 대한 과도한 우려는 경계해야 한다고 주장합니다.

## 📎 Related Works

- **LLM 기반 기술:** OpenAI의 GPT-4 [BCE+23], Google Brain의 Transformer [VSP+17]
- **AGI 개념 및 정의:** Goertzel [GP05], Gubrud [Gub97], Legg & Hutter [LH07a, LH07b], Hutter (AIXI) [Hut05], Solomonoff (귀납적 추론) [Sol64], Pei Wang (환경 적응) [Wan06], Weaver (개방형 지능) [WV17], Duch et al. (AI 패러다임) [DOP08]
- **인간 인지 과학:** Laird et al. (마음의 표준 모델) [LLR17], Madl et al. (인지 주기) [MBF11], Gardner (다중 지능) [Gar99], Bengio (의식 사전 지식) [Ben17]
- **LLM 약점 연구:**
  - **환각:** McKenna et al. [MLC+23], Azaria & Mitchell [AM23], msravi [msr22], Schmidhuber & Howard [JSH23], Verma & Oremus [VO23]
  - **세계 모델링:** Li et al. (OthelloGPT) [LHB+22], Nanda (OthelloGPT) [Nan22], Trencseni (공간 추론) [Tre23], Bang et al. (StepGame) [BCL+23], Perkowitz (물리학 문제) [Per23]
  - **마음 이론:** Kosinski [Kos23], Sap et al. [SLFC22]
  - **추론:** Lim (수학 문제) [Lim23], Bringsjord (논리 문제) [Bri23], Saparov & He (추론 체인) [SH22]
  - **계산적 한계:** Hahn (자기 주의) [Hah20], Schuurmans (메모리 증강) [Sch23]
- **LLM 개선 및 AGI 통합 시도:**
  - **도구 통합:** Lu et al. (Chameleon) [LPC+23], Gur et al. (WebAgent) [GFH+23]
  - **신경-상징 통합:** Bader & Hitzler [BH05], Zhang et al. (ERNIE) [ZHL+19], Yang et al. [YCL+23], Pan et al. [PLW+23], Sun et al. [SXT+23]
  - **하이브리드 AGI 아키텍처:** Bengio & Hu (RL/MDL) [BH23], Goertzel et al. (OpenCog Hyperon) [ea23], Zeng et al. (BrainCog) [ZZZ+22]

## 🛠️ Methodology

이 논문은 현대 LLM을 인지 시스템으로 평가하기 위해 **정성적 분석 및 비교 연구** 방법을 사용합니다.

1. **개념적 틀 마련:**
   - "CILLM" 및 "HCAGI"와 같은 핵심 용어를 정의하여 논의의 범위를 설정합니다.
   - 일반 지능(General Intelligence)에 대한 다양한 철학적, 심리학적, 수학적, 시스템 이론적 접근 방식을 검토하여 AGI의 복잡한 본질을 이해하기 위한 기반을 다집니다.
2. **인간 인지 아키텍처 분석:**
   - 인지 과학 분야의 "마음의 표준 모델(Standard Model of Mind)" [LLR17]을 주요 참조점으로 활용하여 인간의 지각, 기억(작업, 절차, 선언), 학습, 추론 등 핵심 인지 구성 요소와 그 상호작용(인지 주기)을 설명합니다. 이는 LLM과의 비교 기준이 됩니다.
3. **LLM의 강점 및 약점 실증 분석:**
   - **사례 연구:** ChatGPT 및 GPT-4와의 직접적인 상호작용을 통해 윤리적 딜레마 해결, 기업 PR 문구 생성 등의 **강점**을 시연하고, 가짜 참고문헌 생성, 사실 날조, 수학 문제 오류, 시 생성의 상투성 등 **약점**을 구체적인 대화 스크린샷이나 예시 텍스트를 통해 보여줍니다.
   - **기존 연구 검토:** LLM의 환각, 마음 이론 능력, 세계 모델링 한계 등에 대한 기존 학술 연구 및 사용자 보고서를 광범위하게 인용하고 비판적으로 분석합니다.
4. **LLM과 인간 인지의 비교:**
   - 마음의 표준 모델의 각 구성 요소(예: 일화 기억, 절차 기억, 자기 이해)에 대해 CILLM이 해당 기능을 얼마나 잘 수행하는지(또는 전혀 수행하지 못하는지)를 체계적으로 비교 분석합니다.
   - LLM의 작동 원리(예: 통계적 다음 토큰 예측)가 인간 뇌의 생물학적/인지적 역학(예: 추상적 표현, 목표 지향적 학습)과 어떻게 다른지 논의합니다.
5. **LLM의 한계 극복 방안 탐색:**
   - LLM 아키텍처에 대한 점진적 개선(예: 온라인 학습, 외부 메모리, 도구 통합)과 LLM을 더 큰 하이브리드 AGI 시스템의 구성 요소로 포함하는 방안(예: Bengio와 Hu의 RL/MDL, OpenCog Hyperon)을 개념적으로 설명합니다.
6. **사회적, 윤리적 함의 논의:**
   - LLM의 현재 인지적 한계를 바탕으로 AGI 관련 실존적 위험에 대한 논쟁에 참여하며, 오정보 확산 및 경제적 혼란과 같은 LLM의 직접적인 사회적 영향에 대해 토론합니다.

이 논문은 LLM의 현재 상태를 종합적으로 평가하고 AGI로 가는 경로에서 그들의 위치와 미래 가능성을 조명하기 위해 다양한 인지 과학 및 AI 이론적 관점을 통합하여 사용합니다.

## 📊 Results

이 논문은 현대 LLM(CILLM)의 인지적 강점과 약점을 정성적으로 분석하며, 인간 수준의 AGI(HCAGI)와의 근본적인 차이를 밝히는 데 중점을 둡니다.

- **LLM의 주요 강점:**
  - **능숙한 상식 윤리적 추론:** GPT-4는 제시된 윤리적 딜레마(예: 친구 간의 비밀 유지와 관련된 도덕적 선택)에 대해 인간과 유사한 미묘한 판단을 내리고 명확한 답을 제시할 수 있습니다.
  - **정교한 기업 윤리 모방:** 기업의 비윤리적 행위에 대한 PR 대응을 요청했을 때, LLM은 매우 설득력 있고 노련하게 위선적인 홍보 문구를 생성합니다. 이는 복잡한 맥락과 의도를 이해하고 반영하는 언어 생성 능력을 보여줍니다.
  - **효과적인 "Few-shot, in-context learning":** 소수의 예시만으로 새로운 텍스트 변환 패턴이나 스타일을 빠르게 학습하고 적용하는 능력이 탁월합니다.
  - **간단한 다중 모드 쿼리 처리:** 텍스트, 이미지, 오디오 등 여러 형태의 입력에 걸쳐 기본적인 상호작용 및 문제 해결이 가능합니다.
- **LLM의 주요 약점:**
  - **심각한 환각 (Hallucination) 현상:** 존재하지 않는 학술 참고문헌이나 허구의 사건(예: Juergen Schmidhuber에 대한 가짜 뉴스, Jonathan Turley 변호사에 대한 성희롱 스캔들 날조)을 사실처럼 생성합니다. 이는 LLM이 진실성보다는 "가장 그럴듯한" 출력을 생성하는 데 최적화되어 있음을 시사합니다.
  - **현실 판별 및 심볼 접지 (Symbol Grounding) 능력 미약:** LLM은 자신이 생성하는 정보의 사실 여부를 구별하지 못하며, 언어적 개념을 실제 세계의 경험이나 객관적 실체에 연결하는 능력이 현저히 부족합니다.
  - **제한된 세계 모델링:** OthelloGPT와 같이 구조가 단순하고 데이터가 풍부한 인공 도메인에서는 암묵적 세계 모델을 학습할 수 있지만, 실제 세계의 복잡한 시공간적 추론(예: ASCII 아트, StepGame)이나 물리적 문제 해결에서는 실패하거나 비논리적인 답변을 내놓습니다.
  - **매우 제한된 마음 이론 (Theory of Mind, ToM):** 일부 거짓 신념 퍼즐에서 성과를 보였으나, 표준 ToM 테스트에서는 GPT-4조차 60% 정도의 낮은 정확도를 보이며, 패턴 매칭 이상의 진정한 타인의 마음을 이해하는 능력이 부족합니다.
  - **복잡한 다단계 추론 능력 부족:** 고등학교 수준의 수학 문제나 논리적 추론(예: $GCD(n, 18)=5$ 같은 명백한 오류, 논리적 함의 문제)에서 일관성 없이 실패하며, 단계가 많아질수록 오류가 누적됩니다. "Chain-of-thought"나 코드 기반 자가 검증과 같은 전략이 성능을 향상시키지만, 여전히 심오한 과학적/수학적 추론에는 역부족입니다.
  - **상투적이고 근본적인 창의성 부족:** 시나 광고 문구 생성에서 "비트 시"와 같은 특정 스타일을 모방할 수는 있지만, 결과물은 대부분 진부하고 독창성이 결여되어 있습니다. 이는 깊은 개념적 이해 없이 표면적인 패턴을 조합하는 데서 기인합니다.
  - **자기 주도성 및 자율성 결여:** LLM은 사용자 지시를 따르지만, 인간처럼 내재적인 목표를 설정하고, 장기적인 계획을 수립하며, 이를 자율적으로 수행하는 능력이 없습니다.
- **LLM의 근본적인 계산적 한계:** 자기 주의(self-attention) 메커니즘이 특정 유형의 형식 언어 처리와 계층적 구조 모델링에서 한계를 보이며, 표준 방식으로는 "범용 계산 학습 기계"가 아닙니다. 외부 메모리(scratchpad)와 결합될 때 범용 튜링 머신을 모방할 수 있지만, 이는 LLM 자체의 아키텍처를 넘어서는 확장을 의미합니다.

결론적으로, LLM은 특정 언어 관련 작업에서 매우 인상적인 성능을 보이지만, 인간 지능의 핵심을 이루는 다양한 인지적 능력과 아키텍처적 특성에서 근본적인 한계를 가지며, 현재 형태로는 HCAGI와 큰 격차가 있다는 것이 논문의 주요 발견입니다.

## 🧠 Insights & Discussion

- **LLM은 AGI가 아니다:** 논문은 현대 LLM(CILLM)이 HCAGI (Human-Capable AGI)가 아니며, 현존하는 컴퓨팅 자원 내에서 단순히 LLM을 점진적으로 개선하는 것만으로는 HCAGI에 도달할 수 없다는 강력한 주장을 제시합니다.
- **아키텍처의 중요성:** LLM의 광범위한 인지적 약점(환각, 제한된 추론, 상투성, 자율성 부족 등)은 그들이 "가장 그럴듯한 다음 시퀀스 예측"에 초점을 맞춘 기본 인지 아키텍처의 한계에서 비롯됩니다. 지식을 주로 특수 사례의 방대한 저장소로 표현하기 때문에, 진실성, 독창성, 심층적 이해와 같은 속성은 부차적인 목표가 됩니다.
- **인간 인지와의 근본적 차이:** 인간의 마음은 "마음의 표준 모델"에서 제시된 다양한 형태의 기억(일화적, 절차적, 선언적), 복잡한 다단계 추론, 자기 성찰, 세계 모델링, 타인 이해 등 모듈화되고 상호 연결된 인지 구성 요소를 통해 작동합니다. LLM은 이러한 핵심 구성 요소 중 많은 부분을 결여하고 있거나, 매우 다른 방식으로 작동합니다. 특히, 인간은 추상적인 개념을 형성하고 이를 바탕으로 학습하고 합성하는 능력이 뛰어난 반면, LLM은 주로 표면적 패턴 인식과 조합에 의존합니다.
- **AGI를 향한 LLM의 역할:**
  - **LLM은 강력한 구성 요소:** LLM이 AGI 그 자체는 아니지만, 더 광범위한 AGI 아키텍처의 중요한 구성 요소로 활용될 수 있는 잠재력을 가집니다. 이는 LLM의 언어 처리 및 패턴 인식 능력을 다른 모듈(예: 심볼릭 추론, 지식 그래프, 외부 메모리)과 결합하는 하이브리드 접근 방식을 통해 가능할 것입니다.
  - **플러그인과 도구 통합의 의미:** ChatGPT의 Wolfram Alpha 연동이나 Microsoft의 Chameleon 시스템처럼, 외부 도구를 LLM과 통합하는 것은 LLM의 실용적 성능을 크게 향상시킵니다. 그러나 이는 LLM의 "일반 지능"이 도구를 스스로 조합하는 것이 아니라, 인간 설계자가 LLM의 한계를 우회하고 다른 소프트웨어의 강점을 활용하도록 "일반 지능"을 발휘하는 것에 가깝습니다.
- **사회적 및 윤리적 함의:** LLM은 HCAGI와는 거리가 멀기 때문에 AGI와 관련된 "실존적 위험"에 대한 과도한 우려는 경계해야 합니다. 하지만 LLM의 인지적 한계는 잘못된 정보 확산, 콘텐츠의 상투화, 직업 시장의 혼란 등 직접적인 사회적, 경제적 문제를 야기할 수 있습니다. 이러한 문제들은 LLM이 진실과 거짓을 구별하지 못하고 깊이 있는 이해 없이 그럴듯한 내용을 생성하는 경향과 직결됩니다.

요약하자면, 이 논문은 LLM의 현재 상태에 대한 현실적이고 비판적인 평가를 제공하며, AGI 달성을 위한 경로에서 LLM의 위치와 한계를 명확히 하고, LLM의 강점을 활용하면서도 근본적인 약점을 극복하기 위한 새로운 아키텍처적 접근 방식의 필요성을 강조합니다.

## 📌 TL;DR

현대 LLM(예: ChatGPT, GPT-4)은 언어 처리와 특정 추론에서 탁월하지만, 환각, 현실 판별 불가, 제한된 세계 모델링, 마음 이론 및 복잡한 다단계 추론 능력 부족, 창의성 결여 등 심각한 인지적 약점이 많다. 이는 LLM이 지식을 방대한 "특수 사례의 통계적 패턴"으로 표현하는 아키텍처 한계에 기인하며, 인간의 인지 작동 방식과 근본적으로 다르다. 단순한 LLM 개선만으로는 인간 수준 AGI(HCAGI) 달성이 어려우므로, 외부 도구 통합이나 OpenCog Hyperon과 같은 하이브리드 AGI 아키텍처에 LLM을 보조적 구성 요소로 활용하는 것이 더 유망한 접근법이다. LLM은 사회적 혼란과 오정보를 야기할 수 있지만, HCAGI의 실존적 위협과는 구분해야 한다.
