{
  "title": "BriLLM: Brain-inspired Large Language Model",
  "authors": "Hai Zhao, Hongqiu Wu, Dongjie Yang, Anni Zou, Jiale Hong",
  "year": 2025,
  "url": "http://arxiv.org/abs/2503.11299v8",
  "abstract": "We introduce BriLLM, a brain-inspired large language model that fundamentally\nredefines the foundations of machine learning through its implementation of\nSignal Fully-connected flowing (SiFu) learning. This work addresses the\ncritical bottleneck hindering AI's progression toward Artificial General\nIntelligence (AGI)--the disconnect between language models and \"world\nmodels\"--as well as the fundamental limitations of Transformer-based\narchitectures rooted in the conventional representation learning paradigm.\nBriLLM incorporates two pivotal neurocognitive principles: (1) static semantic\nmapping, where tokens are mapped to specialized nodes analogous to cortical\nareas, and (2) dynamic signal propagation, which simulates electrophysiological\ninformation dynamics observed in brain activity.\n  This architecture enables multiple transformative breakthroughs: natural\nmulti-modal compatibility, full model interpretability at the node level,\ncontext-length independent scaling, and the first global-scale simulation of\nbrain-like information processing for language tasks. Our initial 1-2B\nparameter models successfully replicate GPT-1-level generative capabilities\nwhile demonstrating stable perplexity reduction. Scalability analyses confirm\nthe feasibility of 100-200B parameter variants capable of processing\n40,000-token vocabularies.\n  The paradigm is reinforced by both Occam's Razor--evidenced in the simplicity\nof direct semantic mapping--and natural evolution--given the brain's\nempirically validated AGI architecture. BriLLM establishes a novel,\nbiologically grounded framework for AGI advancement that addresses fundamental\nlimitations of current approaches.",
  "citation": 1
}