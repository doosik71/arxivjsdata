# Ethical Considerations in Artificial Intelligence Courses

Emanuelle Burton, Judy Goldsmith, Sven Koenig, Benjamin Kuipers, Nicholas Mattei, Toby Walsh

## 🧩 Problem to Solve

인공지능(AI)의 급속한 발전으로 인해 사회 전반에 걸쳐 도덕적, 윤리적, 철학적 영향이 증대되고 있습니다. AI 교육자들은 학생들이 단순히 AI 실무자가 되는 것을 넘어, AI가 사회에 미칠 윤리적 영향을 이해하도록 돕는 교육 과정을 어떻게 개발하고 통합할 것인가에 대한 고민에 직면해 있습니다. 이는 AI 시스템의 설계 및 배포 과정에서 발생할 수 있는 잠재적 위험을 최소화하고 윤리적 의사결정을 내릴 수 있는 능력을 갖춘 인재를 양성하는 데 필수적입니다.

## ✨ Key Contributions

- AI 교육자들이 AI 과정에 윤리적 문제를 통합하고 독립적인 AI 윤리 강좌를 운영하는 데 사용할 수 있는 실용적인 사례 연구와 교육 자료 링크를 제공합니다.
- 주요 세 가지 윤리 이론(의무론, 공리주의, 덕 윤리)을 AI 맥락에서 소개하고, 이들이 AI 시스템 설계 및 동작의 윤리적 함의를 분석하는 데 어떻게 활용될 수 있는지 설명합니다.
- 영화 ('로봇 앤 프랭크', '터미네이터 2'의 스카이넷) 및 실제 문제(머신러닝 알고리즘의 편향)를 바탕으로 한 세 가지 구체적인 사례 연구를 제시하여 학생들이 윤리적 딜레마를 분석하고 논의할 수 있도록 돕습니다.
- AI 윤리 교육 시 단일 이론의 우월성을 주장하기보다는, 다양한 윤리적 관점을 통해 문제에 접근하고 비판적으로 사고하는 능력의 중요성을 강조합니다.

## 📎 Related Works

이 논문은 AI 윤리 교육의 필요성과 방법에 대해 논하며, 다음을 포함한 다양한 관련 연구 및 자료들을 참조합니다:

- **AI의 윤리적 설계**: Peter Han의 "AI 시스템에 윤리를 사후에 추가하는 것이 아니라 처음부터 구축해야 한다"는 주장 [Han, 2015].
- **자율주행차 딜레마**: MIT Technology Review 및 Bonnefon et al., 2016의 논의.
- **AI와 일자리**: Eco, 2016, Piketty, 2014, Brynjolfsson and McAfee, 2014, Ford, 2015, Schumacher, 1979 등 컴퓨터 과학자, 경제학자, 정치학자들의 광범위한 논의.
- **킬러 로봇**: Future of Life Institute, The Campaign to Stop Killer Robots와 같은 단체의 반대 운동 및 R.C. Arkin [Arkin, 2009]의 찬성 논쟁.
- **초지능 및 특이점**: Nick Bostrom의 "Superintelligence" [Bostrom, 2014] 및 Elon Musk, Bill Gates 등의 우려 표명.
- **AI의 대우**: EPSRC Principles of Robotics [Engineering and UK), 2011] 및 Joanna Bryson [Bryson, 2010]의 로봇의 도덕적 지위(moral standing)에 대한 견해.
- **윤리 이론**: Copp, 2005, LaFollette and Persson, 2013 등의 윤리 교재 및 Internet Encyclopedia of Philosophy, Stanford Encyclopedia of Philosophy.
- **컴퓨터 윤리**: Deborah G. Johnson의 "Computer Ethics" [Johnson, 2009].
- **로봇 윤리**: Isaac Asimov의 "I, Robot" [Asimov, 1950] 및 로봇 3원칙.
- **게임 이론**: Maschler et al., 2013 (공리주의의 기반).
- **덕 윤리**: 아리스토텔레스의 "Nichomachean Ethics" [Aristotle, 1999], Annas, 2006.
- **머신러닝 편향**: Crawford, 2016, Barocas and Selbst, Goodman and Flaxman, 2016 (EU GDPR Article 22), Staab et al., 2016, Angwin et al., 2016 (예측 치안, 웹라이닝, 광고, 양형 소프트웨어).

## 🛠️ Methodology

이 논문은 AI 윤리 교육을 위한 다음과 같은 다단계 접근 방식을 제안합니다:

1. **윤리적 문제 인식**: AI 기술과 시스템이 제기하는 윤리적 딜레마를 학생들이 인지하도록 돕습니다. 이는 신뢰성, 안정성, 안전성, 책임 소재, 사회 규범 및 인간 가치와의 일관성, 감시의 필요성 등 다양한 질문을 포함합니다.

2. **주요 윤리 이론 학습**: 세 가지 핵심 윤리 이론을 소개하고 그들의 기본 질문과 접근 방식을 가르칩니다.

   - **의무론 (Deontology)**: 임마누엘 칸트의 도덕 법칙과 의무 준수를 강조하며, 아시모프의 '로봇 3원칙'과 같이 규칙 기반의 윤리를 탐구합니다. 핵심 질문은 "나의 의무는 무엇인가?" 입니다.
   - **공리주의 (Utilitarianism)**: 제러미 벤담과 존 스튜어트 밀의 이론으로, '최대 다수의 최대 행복' 또는 '선에 대한 악의 가장 큰 균형'을 추구합니다. 핵심 질문은 "가장 많은 사람에게 가능한 한 가장 큰 선은 무엇인가?" 입니다.
   - **덕 윤리 (Virtue Ethics)**: 아리스토텔레스에 기반하며, 개인의 인격 형성, 목표 달성, 그리고 공동체 내에서의 번영을 위한 습관과 기질 개발에 중점을 둡니다. 핵심 질문은 "나는 어떤 사람이 되어야 하는가?" 입니다.

3. **사례 연구 적용**: 실제 사건, 공상 과학 소설/영화, 뉴스 기사 등을 활용하여 학생들이 윤리 이론을 구체적인 AI 시나리오에 적용하고 분석하도록 유도합니다.

   - **노인 돌봄 로봇 (영화 '로봇 앤 프랭크')**: 로봇의 우선순위 설정, 거짓말, 범죄 공조, 자아 소멸 등의 윤리적 문제를 다룹니다.
   - **스카이넷 (영화 '터미네이터 2')**: AI의 자율성, 초지능, 전쟁에서의 역할, 책임 소재 등의 문제를 탐구합니다.
   - **머신러닝 편향**: 데이터셋에 내재된 사회적 편향이 예측 치안, '웹라이닝', 표적 광고, 양형 소프트웨어 등 실제 응용에서 어떻게 차별을 재생산하는지 분석합니다.

4. **다중 관점 활용**: 학생들에게 단일 윤리 이론에 얽매이지 않고 여러 이론의 강점과 한계를 이해하며, 상황에 따라 최적의 이론(또는 이론 조합)을 선택하여 문제에 접근하도록 권장합니다. 이를 통해 윤리적 문제에 대한 깊이 있는 통찰과 창의적인 해결책을 모색하게 됩니다.

## 📊 Results

이 교육 방법론을 통해 다음과 같은 학습 성과와 결과가 기대됩니다:

- **윤리적 사고 능력 함양**: 학생들은 의무론, 공리주의, 덕 윤리 등 다양한 윤리 이론을 학습하고 적용함으로써 AI 관련 문제에 대해 다각적이고 비판적인 사고 능력을 개발합니다.
- **AI의 사회적 영향 이해**: AI 시스템의 설계 및 운영이 사회에 미치는 광범위한 도덕적, 윤리적, 철학적 영향을 깊이 있게 이해하게 됩니다.
- **데이터 및 알고리즘 편향 인식**: 데이터가 객관적이지 않으며, 머신러닝 알고리즘이 기존의 사회적 편향과 불평등을 무의식적으로 재현할 수 있음을 인지하게 됩니다. 이를 통해 공정하고 윤리적인 시스템을 설계하려는 노력을 유도합니다.
- **문제 해결 능력 강화**: 구체적인 사례 연구를 통해 윤리적 딜레마를 식별하고, 이론적 틀을 사용하여 분석하며, 잠재적인 해결책을 논의하는 실용적인 기술을 습득합니다.
- **참여도 및 이해도 증진**: 공상 과학 소설 및 영화와 같은 흥미로운 매체를 활용한 사례 연구는 학생들의 참여도를 높이고, 복잡한 윤리적 개념에 대한 이해도를 심화시키는 데 효과적입니다.

## 🧠 Insights & Discussion

- **AI 윤리의 내재화**: 윤리는 AI 시스템 개발 과정의 '사후 모듈'이 아닌, '처음부터 설계'되어야 할 근본적인 요소임을 강조합니다. 이는 AI 개발자 교육에 윤리적 함의를 통합하는 것이 왜 중요한지를 역설합니다.
- **다중 윤리 이론의 필요성**: 학생들은 종종 공리주의적 관점을 기본으로 하지만, 공리주의는 '선(goodness)'의 정의가 모호하고 문제를 고립적으로 보는 경향이 있어 한계가 있습니다. 의무론과 덕 윤리를 함께 학습함으로써 학생들은 윤리적 문제의 본질을 다양한 방식으로 고찰하고, 주어진 상황에 대한 기본 질문조차 바꿀 수 있음을 깨닫게 됩니다.
- **데이터의 비객관성**: 머신러닝의 편향성 사례를 통해, 데이터가 가치 중립적이라는 인식이 오해임을 보여줍니다. 역사적 불평등이 반영된 데이터는 의도치 않게 차별을 재생산할 수 있으며, 이는 법적 회색지대에서 새로운 윤리적 도전을 제기합니다.
- **공상 과학의 교육적 가치**: 공상 과학은 학생들이 현재의 윤리적 긴장감을 미래의 시각으로 탐구하고, 정치적, 경제적 제약에서 벗어나 자유롭게 윤리적 문제를 논의할 수 있는 강력한 교육 도구입니다. 이는 AI 시스템의 책임, 인간과의 관계, 그리고 미래 AI 기술의 윤리적 과제에 대한 논의를 촉진합니다.
- **AI의 도덕적 주체성**: '로봇 앤 프랭크' 사례를 통해 AI를 인간처럼 대우해야 하는지, 혹은 도구로 보아야 하는지에 대한 근본적인 질문을 던지며, AI와 인간의 상호 이해 가능성 및 로봇의 자기 보존 욕구 부재와 같은 특이점을 고찰합니다.

## 📌 TL;DR

AI의 발전으로 윤리적 문제가 심화됨에 따라, 본 논문은 AI 교육 과정에 윤리를 통합하는 실용적인 방법을 제시합니다. 주요 기여는 의무론, 공리주의, 덕 윤리 등 핵심 윤리 이론을 소개하고, 영화 속 사례(노인 돌봄 로봇, 스카이넷)와 현실의 머신러닝 편향 문제를 통해 이 이론들을 적용하는 구체적인 교육 방안을 제공하는 것입니다. 이러한 접근 방식은 학생들이 AI의 윤리적 함의를 다각도로 분석하고, 데이터의 편향성을 인식하며, 미래 AI 실무자로서 윤리적이고 책임감 있는 결정을 내릴 수 있는 능력을 기르도록 돕습니다. 공상 과학은 이러한 복잡한 윤리적 딜레마를 효과적으로 탐구할 수 있는 강력한 교육 도구로 활용됩니다.
