{
  "title": "Against racing to AGI: Cooperation, deterrence, and catastrophic risks",
  "authors": "Leonard Dung, Max Hellrigel-Holderbaum",
  "year": 2025,
  "url": "http://arxiv.org/abs/2507.21839v1",
  "abstract": "AGI Racing is the view that it is in the self-interest of major actors in AI\ndevelopment, especially powerful nations, to accelerate their frontier AI\ndevelopment to build highly capable AI, especially artificial general\nintelligence (AGI), before competitors have a chance. We argue against AGI\nRacing. First, the downsides of racing to AGI are much higher than portrayed by\nthis view. Racing to AGI would substantially increase catastrophic risks from\nAI, including nuclear instability, and undermine the prospects of technical AI\nsafety research to be effective. Second, the expected benefits of racing may be\nlower than proponents of AGI Racing hold. In particular, it is questionable\nwhether winning the race enables complete domination over losers. Third,\ninternational cooperation and coordination, and perhaps carefully crafted\ndeterrence measures, constitute viable alternatives to racing to AGI which have\nmuch smaller risks and promise to deliver most of the benefits that racing to\nAGI is supposed to provide. Hence, racing to AGI is not in anyone's\nself-interest as other actions, particularly incentivizing and seeking\ninternational cooperation around AI issues, are preferable.",
  "citation": 1
}