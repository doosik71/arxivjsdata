{
  "title": "AI Predicts AGI: Leveraging AGI Forecasting and Peer Review to Explore\n  LLMs' Complex Reasoning Capabilities",
  "authors": "Fabrizio Davide, Pietro Torre, Leonardo Ercolani, Andrea Gaggioli",
  "year": 2024,
  "url": "http://arxiv.org/abs/2412.09385v2",
  "abstract": "We tasked 16 state-of-the-art large language models (LLMs) with estimating\nthe likelihood of Artificial General Intelligence (AGI) emerging by 2030. To\nassess the quality of these forecasts, we implemented an automated peer review\nprocess (LLM-PR). The LLMs' estimates varied widely, ranging from 3% (Reka-\nCore) to 47.6% (GPT-4o), with a median of 12.5%. These estimates closely align\nwith a recent expert survey that projected a 10% likelihood of AGI by 2027,\nunderscoring the relevance of LLMs in forecasting complex, speculative\nscenarios. The LLM-PR process demonstrated strong reliability, evidenced by a\nhigh Intraclass Correlation Coefficient (ICC = 0.79), reflecting notable\nconsistency in scoring across the models. Among the models, Pplx-70b-online\nemerged as the top performer, while Gemini-1.5-pro-api ranked the lowest. A\ncross-comparison with external benchmarks, such as LMSYS Chatbot Arena,\nrevealed that LLM rankings remained consistent across different evaluation\nmethods, suggesting that existing benchmarks may not encapsulate some of the\nskills relevant for AGI prediction. We further explored the use of weighting\nschemes based on external benchmarks, optimizing the alignment of LLMs'\npredictions with human expert forecasts. This analysis led to the development\nof a new, 'AGI benchmark' designed to highlight performance differences in\nAGI-related tasks. Our findings offer insights into LLMs' capabilities in\nspeculative, interdisciplinary forecasting tasks and emphasize the growing need\nfor innovative evaluation frameworks for assessing AI performance in complex,\nuncertain real-world scenarios.",
  "citation": 1
}