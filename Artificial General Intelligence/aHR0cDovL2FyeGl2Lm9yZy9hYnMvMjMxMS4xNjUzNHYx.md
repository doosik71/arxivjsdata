# Graph Prompt Learning: A Comprehensive Survey and Beyond

Xiangguo Sun, Jiawen Zhang, Xixi Wu, Hong Cheng, Yun Xiong, Jia Li

## 🧩 Problem to Solve

인공 일반 지능(AGI)이 자연어 처리(NLP) 및 컴퓨터 비전(CV) 분야에서 혁명적인 발전을 이뤘음에도 불구하고, 상호 연결된 세상의 근간인 그래프 데이터와의 통합은 아직 초기 단계입니다. 기존 AGI 애플리케이션은 그래프 데이터의 교차-모달리티, 교차-도메인, 교차-태스크 적용에 있어 뚜렷한 한계와 도전에 직면해 있습니다. 또한, 기존 그래프 신경망(GNN) 기반 방법론은 표현력(expressiveness)과 유연성(flexibility) 사이의 만족스러운 균형을 달성하는 데 어려움을 겪으며, 대규모 사전 학습 모델의 효율적인 지식 추출과 반복적인 파인 튜닝의 필요성 감소가 중요한 문제로 대두됩니다. 현재 그래프 프롬프트 학습 분야에는 통일된 프레임워크나 체계적인 연구 경로가 부족하여 연구 발전에 상당한 장애가 됩니다.

## ✨ Key Contributions

- **통합 프레임워크 제안**: 그래프 프롬프트 학습 연구를 분석하기 위한 통합 프레임워크를 제안하며, 프롬프트 토큰, 토큰 구조, 삽입 패턴에 대한 포괄적인 이해를 제공합니다.
- **프롬프트-모델 상호작용에 대한 새로운 관점**: 그래프 프롬프트의 본질에 대한 신선한 통찰력을 제공합니다. 프롬프트를 단순히 다운스트림 태스크와 사전 학습 태스크 간의 간극을 메우는 '트릭'이 아닌, 기존 그래프 모델의 유연성과 표현력 문제와 상호작용하는 심층적인 관점에서 탐구합니다.
- **체계적인 분류법 구축**: 그래프 프롬프트 분야의 100개 이상의 최신 연구를 노드-레벨, 엣지-레벨, 그래프-레벨 태스크 및 사전 학습 태스크와 연계하여 체계적으로 분류하고 설명합니다.
- **그래프 프롬프트 생태계 강화**: 그래프 프롬프트 연구를 지원하는 Python 라이브러리 ProG와 최신 연구, 벤치마크 데이터셋, 코드 구현을 집대성한 웹사이트를 개발하여 연구자들의 접근성을 높이고 연구 발전을 촉진합니다.
- **미래 연구 로드맵 제시**: 현재의 과제와 미래 연구 방향에 대한 상세한 탐구를 통해 그래프 프롬프트 분야의 발전을 위한 포괄적인 로드맵을 제공합니다.

## 📎 Related Works

- **Liu et al.[48]**: 주로 그래프 파운데이션 모델(GFMs)에 초점을 맞추며, 그래프 프롬프트 관련 연구는 간략하게 다룹니다.
- **Li et al.[46]**: 그래프와 대규모 언어 모델(LLM) 통합에 대한 체계적인 분석을 제공하며, 본 논문의 6.1절 일부에 해당하는 내용입니다.
- **Surveys [105,113]**: 주로 그래프 신경망의 사전 학습 단계에 중점을 두며, 그래프 프롬프트 학습의 중요한 측면은 다루지 않습니다.
- **Wu et al.[102]**: 그래프 프롬프트 학습에 대한 이전 조사이지만, 본 논문은 더 포괄적인 관련 연구 분석, 통일된 프레임워크 내 체계적인 분석, 그래프 사전 학습과 프롬프트 간의 깊은 관계에 대한 통찰, 그리고 실제 애플리케이션을 위한 공학적 작업까지 포함하여 여러 면에서 이를 뛰어넘습니다.

## 🛠️ Methodology

본 논문은 그래프 프롬프트 학습을 분석하기 위한 **통합 프레임워크**를 제안합니다. 이 프레임워크는 그래프 프롬프트를 세 가지 핵심 구성 요소로 나눕니다.

1. **프롬프트 토큰 (Prompt Tokens)**:

   - 프롬프트 내용을 벡터로 보존합니다.
   - 예시: `learnable vector p`, `task token`, `structure token`, `semantic token`, `contextual token`, `type-specific feature token`.
   - 삽입 위치: 초기 피처 공간($X$)에 직접 추가($x_i + p$), 히든 레이어에 주입, 가상 노드의 피처로 사용.

2. **토큰 구조 (Token Structures)**:

   - 여러 프롬프트 토큰이 어떻게 조직되는지를 나타냅니다.
   - 예시: `All in One [80]`에서는 프롬프트 토큰들 간의 내부 링크와 프롬프트 그래프와 원본 그래프 간의 교차 링크를 포함하는 추가적인 서브그래프를 프롬프트로 정의합니다. `GPPT [78]`에서는 태스크 토큰과 구조 토큰의 결합을 통해 서브그래프 주변의 노드 레이블 예측을 수행합니다.

3. **삽입 패턴 (Inserting Patterns)**:
   - 그래프 프롬프트를 원본 그래프와 결합하는 방법을 정의합니다.
   - 예시:
     - **피처 추가 (Feature Adding)**: 모든 노드 피처에 프롬프트 벡터를 추가($\tilde{s}_i \leftarrow x_i + p$).
     - **연결 (Concatenating)**: 프롬프트 토큰을 원본 노드 세트에 연결 후 그래프 트랜스포머의 자기-어텐션으로 통합.
     - **교차 링크 (Cross-Links)**: 프롬프트 그래프를 원본 그래프에 교차 링크로 연결하거나, 프롬프트 토큰(클래스 정보)을 원본 그래프에 연결하여 새로운 그래프를 형성.
     - **가상 노드 (Virtual Node)**: 대상 노드마다 가상 노드를 생성하고 프롬프트 토큰을 피처로 사용하며 대상 노드에 연결.

**태스크 정렬 및 응답 함수**:

- **다양한 수준의 태스크 처리**: 노드, 엣지, 그래프 수준의 다운스트림 태스크를 유도된 서브그래프(induced subgraph) 개념을 통해 그래프 수준의 사전 학습 태스크로 통일합니다.
- **응답 함수 (Answering Function)**:
  - **학습 가능한 응답 함수**: MLP와 같은 학습 가능한 태스크 헤드를 사용하여 사전 학습된 모델의 출력(그래프 수준 표현)을 다운스트림 결과로 매핑합니다. 이 경우 프롬프트와 태스크 헤드 모두 튜닝 가능합니다.
  - **수제(Hand-crafted) 응답 함수**: 튜닝 부담을 줄이기 위해 사전 학습 태스크와 직접적으로 일치하는 수제 템플릿을 사용합니다 (예: 링크 예측을 통해 노드 분류 수행, 클래스 토큰과 노드 표현 간의 유사도 비교).

**프롬프트 튜닝 (Prompt Tuning)**:

- **메타 학습 기법**: MAML [15]과 같은 메타 학습을 활용하여 다양한 다운스트림 태스크에 일반화된 프롬프트 파라미터의 견고한 시작점을 얻습니다.
- **태스크 특정 튜닝**: 특정 다운스트림 태스크(예: 그래프 분류)에 초점을 맞춰 프롬프트 토큰과 태스크 헤드를 함께 튜닝합니다.
- **사전 학습 목표와 일치하는 튜닝**: 사전 학습 태스크와 동일한 목적 함수(예: Cross-Entropy, Contrastive Loss)를 사용하여 프롬프트를 튜닝합니다.

**ProG 라이브러리 개발**:

- PyTorch 기반의 오픈소스 라이브러리 `ProG`를 개발하여 단일 또는 다중 태스크 프롬프팅을 지원합니다.
- Cora, CiteSeer, Reddit 등 널리 사용되는 데이터셋과 Accuracy, F1 Score, AUC 등 핵심 평가 지표를 통합합니다.
- `All in One [80]`, `GPPT [78]`, `GPF [11]`, `GPF-Plus [12]` 등 최신 그래프 프롬프트 모델을 포함하며 지속적으로 확장 가능하도록 설계되었습니다.

## 📊 Results

본 논문은 설문 조사 논문으로서 새로운 실험 결과를 제시하기보다는 다음과 같은 주요 발견과 성과를 요약합니다.

- **종합적인 연구 분류**: 그래프 프롬프트 학습 분야의 100개 이상의 최신 연구를 노드, 엣지, 그래프 수준의 사전 학습 태스크 및 프롬프트 디자인 방식(토큰, 구조, 삽입 패턴)에 따라 체계적으로 분류하고 분석하는 데 성공했습니다. 이를 통해 파편화되어 있던 연구 분야에 통일된 관점을 제공했습니다.
- **프롬프트의 본질에 대한 새로운 통찰**: 그래프 프롬프트가 기존 그래프 표현 학습 방법론(얕은 임베딩, GNN)이 달성하기 어려웠던 유연성(flexibility)과 표현력(expressiveness) 사이의 균형을 효과적으로 제공하는 메커니즘임을 밝혀냈습니다. 이는 프롬프트가 단순한 태스크 간극 메우기를 넘어, 그래프 모델 자체의 한계를 보완하는 중요한 역할을 한다는 의미입니다.
- **연구 생태계 지원**: 그래프 프롬프트 학습 연구를 위한 Python 라이브러리 ProG와 관련 연구 자료, 벤치마크 데이터셋, 코드 구현을 집대성한 웹사이트를 구축하여, 연구자들이 이 빠르게 발전하는 분야에 더 쉽게 접근하고 기여할 수 있는 실질적인 인프라를 마련했습니다.
- **AGI로의 확장성 입증**: 그래프 프롬프트 기술이 교차-모달리티 융합(특히 텍스트-그래프), 교차-도메인 적응(의미론적 및 구조적 정렬), 교차-태스크 일반화와 같은 인공 일반 지능(AGI)의 핵심 과제를 해결하는 데 중요한 잠재력을 가지고 있음을 종합적으로 보여주었습니다.

## 🧠 Insights & Discussion

- **프롬프트의 본질: 유연성 및 표현력 균형**: 기존 그래프 표현 학습 방법론(얕은 임베딩 및 GNN)은 유연성과 표현력 중 하나에 치우쳐 있었으나, 프롬프트 메커니즘은 이 둘 사이의 균형을 제공하는 유망한 해결책으로 제시됩니다. 프롬프트는 경량의 학습 가능한 토큰을 통해 노드의 유연성을 유지하면서, 사전 학습된 GNN의 강력한 표현력을 활용하여 다양한 다운스트림 태스크에 효율적으로 적용될 수 있습니다.
- **기존 연구의 연결, 장점 및 한계**:
  - **GPF [11]**는 간단한 프롬프트 디자인으로 다양한 태스크에 쉽게 적용 가능하나, 단일 프롬프트 토큰은 표현력과 일반화에 한계가 있습니다. **GPF-Plus [12]**는 여러 토큰을 사용하여 이를 개선합니다.
  - **HetGPT [55]**는 이종 그래프에 대한 프롬프트 토큰을 제안하지만 노드 분류에 제한적이며, **GraphPrompt [52]**는 링크 예측을 그래프 쌍 유사도 태스크로 재구성하여 확장성을 높입니다.
  - **GPPT [78]**는 **All in One [80]** 프레임워크의 특정 인스턴스로 볼 수 있으며, 이진 엣지 예측에 기반한 노드 분류에 효과적이지만, 더 넓은 범위의 그래프 태스크에는 제한될 수 있습니다. **All in One**은 태스크별 모듈 튜닝 없이 입력 데이터 조작에 더 중점을 둡니다.
  - **PRODIGY [32]**는 튜닝 가능한 파라미터가 없는 프롬프트를 사용하여 효율성을 높이지만, 유연성이 떨어져 사전 학습 도메인과 다른 도메인의 다운스트림 태스크에는 일반화 능력이 제한될 수 있습니다.
  - **VNT [83]**는 프롬프트 토큰과 원본 노드 세트를 연결하여 그래프 트랜스포머에 적용하지만, 메시지 패싱 기반 GNN에는 적용하기 어렵고 명확한 삽입 링크가 없어 위치 임베딩 적용에 어려움이 있을 수 있습니다.
- **현재의 과제**:
  - **그래프 모델의 내재적 한계**: LLM에 비해 사전 학습된 그래프 모델의 파라미터 수가 적어 프롬프트의 잠재력을 최대한 활용하기 어렵습니다.
  - **직관적인 평가의 어려움**: 그래프 프롬프트가 학습 가능한 토큰이나 증강된 그래프 형태로 존재하여 직관적인 이해, 비교, 설명이 어렵습니다.
  - **더 많은 다운스트림 애플리케이션**: 실제 시나리오(예: 사기 탐지)에서의 활용이 제한적이며, 도메인 특정 사전 학습 모델과 적합한 프롬프트 설계가 필요합니다.
  - **전이 가능한 프롬프트 디자인**: 대부분의 연구가 단일 데이터셋/도메인 내에 머물러 있으며, 다양한 도메인과 태스크 간의 프롬프트 전이성 연구가 부족합니다.
- **미래 연구 방향**:
  - **대규모 그래프 모델(LGMs)에서 지식 학습**: LLM과 같은 대규모 그래프 모델을 활용하여 다양한 그래프 태스크에 대응하는 범용적인 지능형 도구를 개발합니다.
  - **전이 학습**: 다양한 태스크 공간, 의미론적 특징, 구조적 패턴을 정렬하여 도메인 간 지식 전이를 가능하게 하는 전이 가능한 그래프 프롬프트 기술을 구현합니다.
  - **더 많은 이론적 기반**: 경험적 설계에 그치지 않고 그래프 이론적 관점에서 그래프 프롬프트 학습의 견고한 이론적 기반을 구축합니다.
  - **더 설명 가능하고 이해하기 쉬운 디자인**: 프롬프트 벡터의 학습 모드(블랙박스)를 넘어, 프롬프트가 무엇을 학습하는지 명확히 이해하고 해석 가능성을 높이는 디자인을 탐구합니다.

## 📌 TL;DR

AGI가 그래프 데이터에 적용되는 과정에서 교차-모달리티, 교차-도메인, 교차-태스크 문제를 겪고 있으며, 기존 그래프 모델의 유연성-표현력 한계와 대규모 모델의 효율적 지식 추출 필요성이 존재합니다. 이 논문은 그래프 프롬프트 학습 분야에 대한 선구적인 조사로, 프롬프트 토큰, 토큰 구조, 삽입 패턴을 포함하는 **통합 프레임워크**를 제안합니다. 또한, 프롬프트가 사전 학습된 GNN의 **유연성과 표현력 균형**을 효과적으로 달성한다는 새로운 관점을 제시하며, 100개 이상의 관련 연구를 **체계적으로 분류**합니다. 연구 발전을 위해 Python 라이브러리 **ProG**와 웹사이트를 개발했고, 현재의 과제와 미래 연구 방향(대규모 그래프 모델, 전이 학습, 이론적 기반 강화, 설명 가능성)을 제시하여 그래프 프롬프트 학습 분야의 발전을 촉진하고자 합니다.
