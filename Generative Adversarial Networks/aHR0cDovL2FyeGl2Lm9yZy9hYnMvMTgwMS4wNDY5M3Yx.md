# Towards Imperceptible and Robust Adversarial Example Attacks against Neural Networks

Bo Luo, Yannan Liu, Lingxiao Wei, Qiang Xu

## 🧩 Problem to Solve

심층 신경망 기반의 기계 학습 시스템은 다양한 지각 작업에서 최첨단 성능을 보이지만, 입력에 미세한 교란을 추가하여 오분류를 유도하는 적대적 예제 공격에 취약합니다. 기존의 적대적 예제 생성 방법은 다음과 같은 두 가지 주요 한계를 가집니다:

1. **불충분한 지각 불가능성 (Imperceptibility)**: L$_p$ (L$_0$, L$_2$, L$_\infty$) 노름과 같은 단순한 거리 측정 지표를 사용하여 원본과 적대적 예제 간의 유사성을 평가합니다. 이 지표들은 인간의 지각 시스템을 고려하지 않아, 낮은 분산 영역의 픽셀에 큰 교란을 가하여 인간 눈에 쉽게 감지될 수 있습니다.
2. **낮은 강건성 (Robustness)**: 실제 물리적 환경에서 발생하는 노이즈와 편차(예: 이미지 압축, 전송 노이즈)로 인해 공격 성공률이 크게 떨어집니다. 기존 방법들은 특정 애플리케이션에 특화된 강건성 연구가 있었지만, 일반적인 시나리오에 적용하기 어렵습니다.

## ✨ Key Contributions

본 논문은 이러한 문제들을 해결하기 위해 지각 불가능성과 강건성을 동시에 고려한 새로운 적대적 예제 공격 생성 방법을 제안하며, 주요 기여는 다음과 같습니다:

* **인간 지각 시스템을 고려한 새로운 거리 측정 지표 제안**: 픽셀의 분산을 기반으로 `교란 민감도(perturbation sensitivity)`를 정의하고, 이를 통해 인간 눈에 덜 감지되는 방식으로 교란을 추가할 수 있는 거리 `D(X*, X)`를 계산합니다.
* **노이즈 허용 오차 최대화를 통한 강건성 향상**: 대상 클래스의 확률과 다른 클래스들의 최대 확률 간의 `확률 간격(probability gap)`을 최대화하여 적대적 예제의 노이즈 허용 오차를 증가시키고 실제 환경에서의 공격 성공률을 높입니다.
* **효율적인 탐욕 알고리즘 제안**: 미분 불가능한 목적 함수를 스무딩하고, `교란 우선순위(perturbation priority)`라는 새로운 지표를 도입하여 어떤 픽셀을 어느 정도의 크기로 교란할지 효율적으로 결정하는 탐욕 알고리즘을 제안합니다.
* **높은 지각 불가능성과 강건성 동시 달성**: 실험을 통해 제안된 방법이 기존 방법들보다 훨씬 지각 불가능하고 다양한 물리적 변형에 대해 강건함을 입증합니다.

## 📎 Related Works

* **초기 적대적 예제 공격**:
  * **L-BFGS (Szegedy et al. 2013)**: 적대적 공격이 성공하는 제약 하에 L$_2$ 노름을 최소화합니다.
  * **FGSM (Goodfellow, Shlens, and Szegedy 2014)**: 손실 함수의 그래디언트를 계산하여 모든 픽셀을 L$_\infty$ 제약 하에 동시에 수정합니다.
  * **JSMA (Papernot et al. 2016)**:  saliency 맵을 구축하여 각 픽셀이 분류에 미치는 영향을 모델링하고, L$_0$ 거리를 사용하여 가장 중요한 픽셀을 반복적으로 수정합니다.
  * 이러한 방법들은 인간 지각 시스템을 고려하지 않고 단순한 L$_p$ 노름을 사용합니다.
* **강건한 적대적 예제 공격 연구**:
  * **물리적 세계에서의 적대적 예제 (Kurakin, Goodfellow, and Bengio 2016)**: 물리적 세계에서 일부 적대적 예제가 생존함을 발견했으나, 성공률 향상 방안은 제시하지 않았습니다.
  * **애플리케이션 특정 공격**: 얼굴 인식 시스템 (Sharif et al. 2016) 및 도로 표지판 인식 시스템 (Evtimov et al. 2017)에 대한 물리적 공격이 연구되었지만, 일반적인 적용 가능성이 낮습니다.
* **다른 도메인의 적대적 공격**: 음성 인식 (Carlini et al. 2016) 및 악성코드 탐지 (Grosse et al. 2016) 시스템에 대한 적대적 공격 연구도 진행되었습니다.

## 🛠️ Methodology

본 논문은 지각 불가능하고 강건한 적대적 예제를 생성하기 위해 다음 단계를 따릅니다.

1. **지각 불가능성을 위한 새로운 거리 측정 지표**:
    * **픽셀 분산 계산**: 이미지 처리의 `대비 마스킹 이론(contrast masking theory)`에 따라 인간의 눈은 낮은 분산 영역의 픽셀 교란에 더 민감합니다. 픽셀 $x_i$의 분산은 $n \times n$ 영역에서의 표준 편차 $SD(x_i)$로 계산됩니다.
        $$SD(x_i) = \sqrt{\sum_{x_k \in S_i} (x_k - \mu)^2 / n^2}$$
    * **교란 민감도 정의**: $SD(x_i)$를 사용하여 `교란 민감도(perturbation sensitivity)`를 다음과 같이 정의합니다. 낮은 분산일수록 민감도가 높습니다.
        $$Sen(x_i) = 1 / SD(x_i)$$
    * **인간 지각 거리**: 원본 이미지 $X$와 적대적 예제 $X^*$ 사이의 지각 거리는 추가된 모든 교란의 효과를 합산하여 계산합니다.
        $$D(X^*, X) = \sum_{i=1}^{N} \delta_i \cdot Sen(x_i)$$
        여기서 $\delta_i$는 픽셀 $x_i$에 추가된 교란의 크기입니다.

2. **강건성을 위한 노이즈 허용 오차 최대화**:
    * 신경망 분류기는 모든 클래스의 확률을 출력하며, 가장 높은 확률을 최종 레이블로 선택합니다.
    * **확률 간격 최대화**: 공격의 강건성을 높이기 위해 대상 클래스 $P_t$의 확률과 다른 클래스들의 최대 확률 $max(P_i)(i \neq t)$ 사이의 `확률 간격(Gap)`을 최대화합니다.
        $$Gap(X^*) = P_t - \max(P_i) \quad (i \neq t)$$
        이 `Gap`이 클수록 적대적 예제가 노이즈에 더 강건하게 오분류 상태를 유지합니다.

3. **지각 불가능하고 강건한 공격 최적화 문제**:
    * 최적화 문제는 다음과 같이 공식화됩니다.
        $$\operatorname{argmax}_{X^*} Gap(X^*)$$
        $$s.t. \quad D(X^*, X) \le D_{max}$$
        여기서 $D_{max}$는 인간 눈에 감지되지 않도록 허용되는 최대 거리입니다.

4. **최적화 알고리즘**:
    * **목적 함수 스무딩**: $\max$ 함수는 미분 불가능하므로, `log-sum-exp` 트릭을 사용하여 미분 가능한 형태로 근사합니다.
        $$\max(x, y) \approx \log(e^{kx} + e^{ky}) / k$$
        이를 통해 목적 함수는 다음과 같이 근사됩니다.
        $$Gap(X^*) \approx P_t - \log(\sum e^{kP_i}) / k \quad (i \neq t)$$
    * **탐욕 알고리즘 (Greedy Algorithm)**: 각 반복에서 어떤 픽셀을 교란할지 효율적으로 결정하기 위해 `교란 우선순위(PerturbPriority)`를 정의합니다.
        $$PerturbPriority(x_i) = \frac{\frac{\partial}{\partial x_i} Gap(X^*)}{\operatorname{Sen}(x_i)}$$
        `PerturbPriority`는 단위 교란 당 확률 간격의 증가량을 나타내며, 픽셀을 교란할 우선순위를 반영합니다.
    * **알고리즘 절차**:
        1. $D(X, X^*) < D_{max}$인 동안 반복합니다.
        2. 각 픽셀의 `PerturbPriority`를 계산합니다.
        3. `PerturbPriority`가 높은 순으로 픽셀을 정렬합니다.
        4. 가장 높은 우선순위를 가진 $m$개 픽셀을 선택합니다.
        5. 선택된 픽셀들에 작은 크기 $\delta$의 교란을 추가하여 $X^*$를 업데이트합니다.
        6. 업데이트된 $X^*$와 $X$ 사이의 인간 지각 거리 $D(X^*, X)$를 계산합니다.
        7. $X$를 $X^*$로 업데이트합니다.

## 📊 Results

MNIST와 CIFAR10 데이터셋에 대해 제안된 방법을 L-BFGS, FGSM, JSMA와 비교 평가했습니다.

* **지각 불가능성 평가**:
  * **인간 지각**: 시각적 비교 (그림 3) 결과, 제안된 방법으로 생성된 적대적 예제가 원본과 거의 동일하게 보여 가장 지각 불가능했습니다. JSMA는 가장 성능이 좋지 않았으며, 교란된 픽셀이 쉽게 감지되었습니다.
  * **거리 측정 지표**: 제안된 `인간 지각 거리` 지표를 사용하여 평가한 결과 (그림 4), 본 방법이 생성한 적대적 예제의 거리가 MNIST에서 44.78, CIFAR10에서 51.98로 가장 작았습니다. 이는 JSMA (MNIST 80.34, CIFAR10 92.25)보다 훨씬 낮은 값입니다. 제안된 거리 측정 지표가 인간의 지각 유사성을 적절하게 반영함을 입증합니다.
  * **MNIST vs CIFAR10**: MNIST는 배경이 균일하여 픽셀의 인간 지각 민감도가 높고, 모델의 분류 정확도가 높아 공격이 더 어렵습니다.

* **강건성 평가**:
  * 모든 공격 방법은 동일한 `D_max = 70` (경험적으로 결정된 지각 임계값) 조건 하에서 비교되었습니다.
  * **이미지 변형**: JPEG 압축, 가우시안 블러링, 대비 및 밝기 조절과 같은 변형에 대한 공격 성공률 (그림 5)에서 제안된 방법이 가장 우수한 성능을 보였습니다 (예: JPEG 압축에서 본 방법 76% vs FGSM 52.3%).
  * **가우시안 노이즈**: 표준 편차를 0.05에서 0.25까지 변화시키며 가우시안 노이즈를 추가했을 때의 강건성 (표 2)에서도 제안된 방법이 일관되게 가장 높은 성공률을 달성했습니다. 노이즈 강도가 강할수록 본 방법의 이점이 더욱 두드러졌습니다 (표준 편차 0.25에서 본 방법 62% vs 베이스라인 평균 약 26%).
  * **관찰**: JSMA는 지각 불가능성 측면에서는 최악이었지만, 강건성 측면에서는 두 번째로 좋은 성능을 보였습니다. 이는 JSMA가 적은 수의 픽셀에 큰 교란을 가하여 노이즈에 대한 내성이 높기 때문입니다. FGSM은 전체 이미지에 작은 교란을 가하므로 노이즈에 가장 취약했습니다. 본 방법은 지각 불가능성과 강건성을 동시에 고려하여 두 가지 측면에서 뛰어난 결과를 달성했습니다.

## 🧠 Insights & Discussion

* **실용적 위협 증가**: 본 연구는 인간 눈에 거의 감지되지 않으면서도 실제 물리적 세계의 다양한 노이즈와 변형에 강건한 적대적 예제를 생성하는 방법을 제시하여, 딥러닝 시스템의 보안 위협이 더욱 현실적이고 심각해질 수 있음을 보여줍니다.
* **인간 지각의 중요성**: 기존의 L$_p$ 노름 기반 거리 지표가 인간의 시각적 인식을 제대로 반영하지 못한다는 점을 명확히 하고, 픽셀의 국소적 분산을 활용한 `교란 민감도` 개념이 지각 불가능한 공격 생성에 효과적임을 입증했습니다. 이는 적대적 예제 연구에서 인간 지각 시스템을 고려하는 것의 중요성을 강조합니다.
* **강건성 확보의 핵심**: 단순히 대상 클래스의 확률을 높이는 것을 넘어, `확률 간격`을 최대화함으로써 모델의 결정 경계를 명확히 하고, 이를 통해 노이즈에 대한 시스템의 '자신감'을 조작하여 강건성을 확보하는 것이 효과적임을 보였습니다.
* **제한 사항 및 향후 연구**: $D_{max}$ 값은 사용자가 입력 이미지에 따라 결정해야 하는 점, 그리고 미분 불가능한 목적 함수를 스무딩하고 탐욕 알고리즘을 사용하는 것이 근사적인 해결책이라는 점이 있습니다. 그럼에도 불구하고, 이는 적대적 예제 공격의 실용성을 크게 향상시켰으며, 향후 방어 메커니즘 개발에 중요한 시사점을 제공합니다.

## 📌 TL;DR

본 논문은 기존 적대적 예제 공격의 낮은 지각 불가능성과 강건성 문제를 해결하기 위해, 인간 지각 시스템을 고려한 새로운 거리 측정 지표와 확률 간격 최대화를 통한 노이즈 허용 오차 개선 방법을 제안합니다. 미분 불가능한 목적 함수를 스무딩하고 `교란 우선순위`를 활용하는 탐욕 알고리즘을 통해, 인간 눈에 감지되기 어렵고(낮은 인간 지각 거리) 다양한 물리적 변형 및 노이즈에 강건한(높은 공격 성공률) 적대적 예제를 효율적으로 생성할 수 있음을 실험적으로 입증했습니다.
