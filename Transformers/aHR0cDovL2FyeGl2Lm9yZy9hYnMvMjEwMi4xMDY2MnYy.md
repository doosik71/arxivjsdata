# Medical Transformer: Gated Axial-Attention for Medical Image Segmentation

Jeya Maria Jose Valanarasu, Poojan Oza, Ilker Hacihaliloglu, and Vishal M. Patel

## 🧩 Problem to Solve

- 기존 컨볼루션 신경망(ConvNets)은 의료 영상 분할에서 준수한 성능을 보였지만, 본질적인 귀납적 편향으로 인해 이미지 내 장거리 의존성(long-range dependencies)을 파악하는 데 한계가 있습니다. 이는 네트워크가 전역적인 맥락보다는 지역적인 패턴에 집중하게 만듭니다.
- 최근 도입된 트랜스포머(Transformer) 기반 아키텍처는 자기 어텐션(self-attention) 메커니즘을 활용하여 장거리 의존성을 인코딩하고 표현력이 풍부한 특징을 학습할 수 있습니다.
- 하지만 대부분의 트랜스포머 기반 모델은 대규모 데이터셋에서 훈련해야 효율적인 성능을 내는 반면, 의료 영상 데이터셋은 상대적으로 규모가 작아 트랜스포머를 효과적으로 학습시키기 어렵습니다. 특히, 적은 데이터로 인해 이미지의 위치 임베딩(positional encoding)을 학습하는 데 어려움이 있습니다.

## ✨ Key Contributions

- **게이팅된 축 방향 어텐션(Gated Axial-Attention) 메커니즘 제안**: 기존의 축 방향 어텐션(Axial-Attention)에 게이트 제어 메커니즘을 추가하여, 특히 데이터셋 규모가 작을 때 위치 임베딩의 영향을 조절하고 학습을 안정화합니다.
- **지역-전역(Local-Global, LoGo) 훈련 전략 도입**: 전체 이미지와 이미지 패치(patch)를 동시에 활용하는 이중 브랜치(branch) 네트워크를 통해 전역적인 특징과 세부적인 지역 특징을 모두 학습합니다. 이는 의료 영상 데이터의 특성을 고려한 효과적인 훈련 방식입니다.
- **의료 영상 분할을 위한 MedT(Medical Transformer) 개발**: 제안된 게이팅된 축 방향 어텐션과 LoGo 훈련 전략을 기반으로 한 트랜스포머 모델인 MedT를 선보였습니다.
- **향상된 성능 입증**: 3가지 다양한 의료 영상 분할 데이터셋에서 ConvNets 및 다른 트랜스포머 기반 아키텍처보다 우수한 성능을 달성했으며, 대규모 데이터셋에서의 사전 훈련(pre-training) 없이도 효과적임을 보여주었습니다.

## 📎 Related Works

- **컨볼루션 신경망(ConvNets)**: 의료 영상 분할 분야에서 U-Net [17], V-Net [15], 3D U-Net [4], Res-UNet [27], U-Net++ [31] 등 다양한 ConvNet 기반 모델들이 제안되어 뛰어난 성능을 보였습니다.
- **장거리 의존성 모델링(ConvNets)**: ConvNet의 한계를 보완하기 위해 이미지 피라미드 [29], atrous convolution [3], 어텐션 메커니즘 [9, 16, 26] 등이 연구되었지만, 여전히 개선의 여지가 있었습니다.
- **트랜스포머(Transformers)**: 자연어 처리(NLP) 분야에서 트랜스포머 [5]의 성공 이후, 컴퓨터 비전 분야 [6, 20]로 확장되었습니다.
- **영상 분할 트랜스포머**: Axial-Deeplab [24]은 축 방향 어텐션(axial attention)을 활용했고, SETR [30]은 트랜스포머를 인코더로, ConvNet을 디코더로 사용했습니다. 의료 영상 분야에서는 어텐션 메커니즘을 사용한 연구 [16, 26]가 있었으나, 여전히 ConvNet이 주된 구성 요소였습니다.
- **동시 연구**: 최근 TransUNet [2] (사전 훈련 필요) 및 TransFuse [28] (CNN과 트랜스포머 병렬 결합)와 같은 트랜스포머 기반 의료 영상 분할 연구가 등장했습니다.

## 🛠️ Methodology

- **자기 어텐션(Self-Attention) 개요**:
  - 입력 특징 맵 $x \in R^{C_{in} \times H \times W}$ 에 대해 자기 어텐션은 다음 식과 같이 계산됩니다:
    $$y_{ij} = \sum_{h=1}^{H} \sum_{w=1}^{W} \text{softmax}(q_{ij}^{T}k_{hw}) v_{hw}$$
    여기서 $q, k, v$는 각각 쿼리(query), 키(key), 값(value)으로 입력 $x$의 투영(projection)입니다. 이는 전체 특징 맵에서 비지역적(non-local) 정보를 포착하지만, 계산 비용이 높고 위치 정보가 고려되지 않습니다.
- **축 방향 어텐션(Axial-Attention)**:
  - 계산 효율성을 위해 2D 자기 어텐션을 높이(height) 축과 너비(width) 축을 따라 두 개의 1D 자기 어텐션 모듈로 분해합니다.
  - [24]에서 제안된 바와 같이, 위치 편향(positional bias)을 추가하기 위해 상대적 위치 인코딩(relative positional encodings) $r_q, r_k, r_v$를 쿼리, 키, 값에 적용합니다. 예를 들어, 너비 축을 따른 자기 어텐션은 다음과 같습니다:
    $$y_{ij} = \sum_{w=1}^{W} \text{softmax}(q_{ij}^{T}k_{iw} + q_{ij}^{T}r_{q_{iw}} + k_{iw}^{T}r_{k_{iw}}) (v_{iw} + r_{v_{iw}})$$
- **게이팅된 축 방향 어텐션(Gated Axial-Attention)**:
  - 데이터셋 규모가 작을 때 위치 편향 학습의 어려움을 해결하기 위해, 게이트 메커니즘을 추가하여 위치 임베딩이 쿼리, 키, 값에 미치는 영향을 제어합니다.
  - 학습 가능한 게이트 파라미터 $G_Q, G_K, G_{V1}, G_{V2} \in R$ 를 도입하여, 위치 임베딩의 정확도에 따라 그 영향을 조절합니다. 예를 들어, 너비 축을 따른 자기 어텐션은 다음과 같습니다:
    $$y_{ij} = \sum_{w=1}^{W} \text{softmax}(q_{ij}^{T}k_{iw} + G_Q q_{ij}^{T}r_{q_{iw}} + G_K k_{iw}^{T}r_{k_{iw}}) (G_{V1}v_{iw} + G_{V2}r_{v_{iw}})$$
    정확하게 학습된 위치 인코딩에는 높은 가중치를, 그렇지 않은 경우에는 낮은 가중치를 부여하도록 게이트가 학습됩니다.
- **지역-전역(Local-Global, LoGo) 훈련 전략**:
  - **전역 브랜치(Global Branch)**: 원본 해상도 이미지에서 작동하며, 장거리 의존성을 모델링하기 위해 적은 수의 게이팅된 축 방향 트랜스포머 레이어를 사용합니다.
  - **지역 브랜치(Local Branch)**: 이미지 패치(예: $I/4 \times I/4$ 크기의 16개 패치)에서 작동하며, 미세한 특징을 포착하기 위해 더 깊은 네트워크를 사용합니다.
  - 두 브랜치의 출력 특징 맵은 합산되어 1x1 컨볼루션 레이어를 통해 최종 분할 마스크를 생성합니다.
- **MedT(Medical Transformer)**: 제안된 게이팅된 축 방향 어텐션을 기본 빌딩 블록으로 사용하고, LoGo 훈련 전략을 채택한 아키텍처입니다.
- **훈련 세부 사항**: 이진 교차 엔트로피(Binary Cross-Entropy, BCE) 손실 함수를 사용하고, Adam 옵티마이저($\text{lr}=0.001$), 배치 크기 4, 400 에포크로 훈련합니다. 게이트는 처음 10 에포크 동안은 비활성화됩니다.

## 📊 Results

- **데이터셋**: Brain US (뇌 초음파), GlaS (선(腺) 분할), MoNuSeg (핵 분할) 등 3가지 의료 영상 데이터셋에서 성능을 평가했습니다.
- **정량적 결과 (표 1)**:
  - MedT는 F1 점수와 IoU 점수 모두에서 기존 ConvNet 기반 모델(FCN, U-Net, U-Net++, Res-UNet) 및 완전 어텐션 기반 모델(Axial Attention U-Net)보다 일관적으로 우수한 성능을 보였습니다.
  - 상대적으로 이미지 수가 많은 Brain US 데이터셋에서는 완전 어텐션 기반 모델이 ConvNet보다 성능이 좋았습니다.
  - 데이터 수가 적은 GlaS 및 MoNuSeg 데이터셋에서는 ConvNet이 완전 어텐션 기반 모델보다 성능이 좋았는데, 이는 트랜스포머의 데이터 부족 문제를 시사합니다. 제안된 게이팅된 축 방향 어텐션 및 LoGo 전략은 이 문제를 극복하여 개별적으로도 기존 모델보다 우수한 성능을 보였습니다.
  - MedT는 게이팅된 축 방향 어텐션 및 LoGo 개별 모델은 물론, 모든 기존 방법보다 뛰어난 성능을 달성했습니다.
  - F1 점수 기준으로 Axial Attention U-Net 대비 Brain US에서 0.92%, GlaS에서 4.76%, MoNuSeg에서 2.72%의 향상을 보였습니다.
  - 최고의 ConvNet 모델 대비 F1 점수 기준으로 Brain US에서 1.32%, GlaS에서 2.19%, MoNuSeg에서 0.06%의 향상을 달성했습니다.
- **정성적 결과 (그림 3)**: MedT는 장거리 의존성을 매우 잘 포착하는 것을 시각적으로 보여주었습니다. ConvNet 기반 모델이 놓치거나 오분류하는 영역(예: 배경을 뇌실로 잘못 분류)을 MedT는 더 정확하게 분할하며, 분할 마스크 근처의 픽셀도 정밀하게 처리합니다.
- **어블레이션 스터디 (보충 자료의 표 1)**: 게이팅된 어텐션과 LoGo 전략의 각 구성 요소가 성능 향상에 유의미하게 기여함을 확인했습니다. 특히, 게이팅 메커니즘이 장거리 의존성을 더 잘 학습하게 합니다.
- **파라미터 수 (보충 자료의 표 2)**: MedT는 ConvNet 기반의 일부 모델보다 적거나 유사한 수의 파라미터(1.4M)를 가지면서도 더 나은 성능을 달성하여, 성능 향상이 단순히 파라미터 수 증가에 기인한 것이 아님을 보여주었습니다.

## 🧠 Insights & Discussion

- **게이팅된 축 방향 어텐션의 함의**: 의료 영상 데이터셋의 규모가 작은 문제를 해결하기 위해, 게이팅 메커니즘을 통해 학습된 위치 임베딩의 신뢰도에 따라 그 영향을 조절할 수 있게 합니다. 이는 부정확할 수 있는 위치 정보를 맹목적으로 적용하는 것을 방지하여, 데이터가 부족한 환경에서도 트랜스포머의 안정적인 학습을 가능하게 합니다.
- **LoGo(Local-Global) 전략의 이점**: 전체 이미지에서 전역적인 맥락 특징을 학습하는 전역 브랜치와 이미지 패치에서 세부적인 지역 특징을 포착하는 지역 브랜치를 결합합니다. 이 이중 접근 방식은 이미지의 전반적인 구조와 미세한 디테일 모두를 포괄적으로 이해하게 하여 복잡한 의료 영상 분할 작업에서 특히 중요합니다.
- **MedT의 강점**: MedT는 게이팅된 축 방향 어텐션과 LoGo 훈련 전략을 통합함으로써, ConvNet의 장거리 의존성 모델링 한계와 일반 트랜스포머의 대규모 데이터 의존성 문제를 효과적으로 극복합니다. 이를 통해 픽셀 단위의 의존성과 전역적 맥락을 더 잘 학습하여 뛰어난 성능과 정밀도를 달성합니다.
- **사전 훈련 불필요**: 대규모 데이터셋에서의 사전 훈련 없이도 의료 영상 데이터에서 효과적으로 훈련될 수 있다는 점은 의료 영상 분야에서 중요한 장점입니다. 이는 관련 대규모 데이터셋을 확보하기 어려운 이 분야의 특성을 고려할 때 실용성이 높습니다.
- **제한 사항**: 본 논문은 MedT의 성능 우수성에 초점을 맞추고 있으며, 특정 실패 사례나 MedT가 어려움을 겪을 수 있는 데이터셋 유형에 대한 심층적인 논의는 부족합니다.

## 📌 TL;DR

ConvNets는 장거리 의존성 모델링에 한계가 있고, 트랜스포머는 대규모 데이터셋을 필요로 하지만 의료 영상 데이터는 부족합니다. 이러한 문제를 해결하기 위해, 본 논문은 게이팅된 축 방향 어텐션(작은 데이터셋에서도 위치 임베딩의 영향을 제어)과 지역-전역(LoGo) 훈련 전략(전역적 맥락과 미세한 지역적 디테일 학습)을 결합한 MedT(Medical Transformer)를 제안합니다. MedT는 대규모 사전 훈련 없이도 의료 영상 분할에서 ConvNets 및 다른 트랜스포머 기반 모델보다 우수한 성능을 달성합니다.
