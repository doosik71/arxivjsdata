{
  "url": "http://arxiv.org/abs/2407.00226v1",
  "title": "Transformer-based Image and Video Inpainting: Current Challenges and\n  Future Directions",
  "authors": "Omar Elharrouss, Rafat Damseh, Abdelkader Nasreddine Belkacem, Elarbi Badidi, Abderrahmane Lakas",
  "year": 2024,
  "abstract": "Image inpainting is currently a hot topic within the field of computer\nvision. It offers a viable solution for various applications, including\nphotographic restoration, video editing, and medical imaging. Deep learning\nadvancements, notably convolutional neural networks (CNNs) and generative\nadversarial networks (GANs), have significantly enhanced the inpainting task\nwith an improved capability to fill missing or damaged regions in an image or\nvideo through the incorporation of contextually appropriate details. These\nadvancements have improved other aspects, including efficiency, information\npreservation, and achieving both realistic textures and structures. Recently,\nvisual transformers have been exploited and offer some improvements to image or\nvideo inpainting. The advent of transformer-based architectures, which were\ninitially designed for natural language processing, has also been integrated\ninto computer vision tasks. These methods utilize self-attention mechanisms\nthat excel in capturing long-range dependencies within data; therefore, they\nare particularly effective for tasks requiring a comprehensive understanding of\nthe global context of an image or video. In this paper, we provide a\ncomprehensive review of the current image or video inpainting approaches, with\na specific focus on transformer-based techniques, with the goal to highlight\nthe significant improvements and provide a guideline for new researchers in the\nfield of image or video inpainting using visual transformers. We categorized\nthe transformer-based techniques by their architectural configurations, types\nof damage, and performance metrics. Furthermore, we present an organized\nsynthesis of the current challenges, and suggest directions for future research\nin the field of image or video inpainting."
}