{
  "url": "http://arxiv.org/abs/2207.09339v4",
  "title": "Vision Transformers: From Semantic Segmentation to Dense Prediction",
  "authors": "Li Zhang, Jiachen Lu, Sixiao Zheng, Xinxuan Zhao, Xiatian Zhu, Yanwei Fu, Tao Xiang, Jianfeng Feng, Philip H. S. Torr",
  "year": 2022,
  "abstract": "The emergence of vision transformers (ViTs) in image classification has\nshifted the methodologies for visual representation learning. In particular,\nViTs learn visual representation at full receptive field per layer across all\nthe image patches, in comparison to the increasing receptive fields of CNNs\nacross layers and other alternatives (e.g., large kernels and atrous\nconvolution). In this work, for the first time we explore the global context\nlearning potentials of ViTs for dense visual prediction (e.g., semantic\nsegmentation). Our motivation is that through learning global context at full\nreceptive field layer by layer, ViTs may capture stronger long-range dependency\ninformation, critical for dense prediction tasks. We first demonstrate that\nencoding an image as a sequence of patches, a vanilla ViT without local\nconvolution and resolution reduction can yield stronger visual representation\nfor semantic segmentation. For example, our model, termed as SEgmentation\nTRansformer (SETR), excels on ADE20K (50.28% mIoU, the first position in the\ntest leaderboard on the day of submission) and performs competitively on\nCityscapes. However, the basic ViT architecture falls short in broader dense\nprediction applications, such as object detection and instance segmentation,\ndue to its lack of a pyramidal structure, high computational demand, and\ninsufficient local context. For tackling general dense visual prediction tasks\nin a cost-effective manner, we further formulate a family of Hierarchical\nLocal-Global (HLG) Transformers, characterized by local attention within\nwindows and global-attention across windows in a pyramidal architecture.\nExtensive experiments show that our methods achieve appealing performance on a\nvariety of dense prediction tasks (e.g., object detection and instance\nsegmentation and semantic segmentation) as well as image classification."
}