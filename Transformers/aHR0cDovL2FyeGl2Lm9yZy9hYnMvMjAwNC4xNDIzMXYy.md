# Image Captioning through Image Transformer
Sen He, Wentong Liao, Hamed R. Tavakoli, Michael Yang, Bodo Rosenhahn, and Nicolas Pugeault

## 🧩 Problem to Solve
이미지 캡셔닝은 이미지 분석과 텍스트 생성을 결합한 복합적인 문제입니다. 기존 트랜스포머 기반 이미지 캡셔닝 모델들은 텍스트 기계 번역을 위해 설계된 아키텍처를 그대로 차용하는 경향이 있었습니다. 그러나 이미지 내의 의미 단위(객체 감지 모델에서 감지된 영역)와 문장 내의 단어(각 단어) 사이에는 근본적인 구조적 차이가 존재합니다. 텍스트는 일차원적인 좌우 관계를 가지는 반면, 이미지는 이차원적이며 영역 간에 부모, 이웃, 자식 관계와 같은 더욱 복잡한 상대적 공간 관계를 가집니다. 또한, 텍스트 번역이 주로 일대일 디코딩인 반면, 이미지 영역은 문맥, 속성, 다른 영역과의 관계 등 다양하고 풍부한 정보를 설명해야 하는 일대다 디코딩 특성을 가집니다. 이러한 이미지의 복잡한 구조에 트랜스포머의 내부 아키텍처를 적응시키려는 연구는 제한적이었습니다.

## ✨ Key Contributions
*   이미지 캡셔닝 작업에 적합하도록 변형된 어텐션 모듈을 포함하는 새로운 트랜스포머 계층 내부 아키텍처를 제안합니다.
*   이미지 영역 간의 상대적 공간 관계에서 영감을 받아, 수정된 인코딩 트랜스포머(Spatial Graph Encoding Transformer)와 암묵적 디코딩 트랜스포머(Implicit Decoding Transformer)로 구성된 **Image Transformer**를 소개합니다.
*   기존 트랜스포머 계층의 내부 아키텍처를 확장하여 이미지 구조에 적합하도록 만들었으며, 인코더에서는 부모, 자식, 이웃과 같은 공간 관계를 명시적으로 모델링하는 병렬 서브 트랜스포머들을 포함합니다. 디코더 또한 여러 서브 트랜스포머를 통해 영역의 다양한 정보를 디코딩할 수 있도록 확장되었습니다.
*   오직 영역 특징만을 입력으로 사용하여 MSCOCO 오프라인 및 온라인 테스트 벤치마크에서 새로운 State-of-the-Art (SOTA) 성능을 달성했습니다.
*   시각적 관계 감지 모델과 같은 보조 모델 없이 시각적 장면 그래프를 암묵적으로 결합하여, 기존 장면 그래프 기반 모델보다 계산 효율성을 높였습니다.

## 📎 Related Works
*   **단일 단계 어텐션 기반 모델**: 디코딩 단계에서 어텐션이 적용되어 가장 유익한 영역에 집중하며 단어를 생성합니다. (예: Att2all [29], Xu et al. [1]). 계산 효율적이지만 정보 영역의 정확한 위치 파악이 부족합니다.
*   **두 단계 어텐션 기반 모델**: 하향식(bottom-up) 어텐션(객체 감지 모델 사용)과 상향식(top-down) 어텐션으로 구성됩니다. (예: n-babytalk [4], up-down [3]). 단일 단계 모델보다 성능이 향상되었으나, 각 감지된 영역이 독립적으로 간주되어 다른 영역과의 관계 모델링이 부족합니다.
*   **시각적 장면 그래프 기반 모델**: 두 단계 어텐션 모델을 확장하여 그래프 합성곱 신경망(GCN) [6]을 주입하여 감지된 정보 영역을 연결하고 특징을 개선합니다. (예: GCN-LSTM [7], AUTO-ENC [8], ALV [9], GCN-LSTM-HIP [10]). 상당한 성능 향상을 가져왔으나, 장면 그래프 구성을 위해 보조 모델이 필요하며, 두 개의 병렬 스트림(의미적/공간적 그래프)을 사용하여 계산적으로 비효율적일 수 있습니다.
*   **트랜스포머 기반 모델**: 내적(dot-product) 어텐션 메커니즘을 사용하여 정보 영역을 암묵적으로 연결합니다. (예: Entangle-T [13], AoANet [12], VORN [14]). 보조 모델이 필요 없어 계산 효율적이지만, 텍스트에 최적화된 기존 트랜스포머의 내부 아키텍처를 그대로 사용한다는 한계가 있습니다. 본 논문은 이 한계를 극복하고자 트랜스포머의 *내부 아키텍처*를 이미지 데이터에 맞게 수정하는 데 중점을 둡니다.

## 🛠️ Methodology
본 논문은 기존 트랜스포머 계층을 확장하는 **Image Transformer** 아키텍처를 제안합니다.

1.  **공간 그래프 인코딩 트랜스포머 계층 (Spatial Graph Encoding Transformer Layer)**:
    *   **구조 확장**: 인코더의 각 트랜스포머 계층을 확장하여 세 가지 공간 관계(부모, 이웃, 자식)를 처리하는 병렬 서브 트랜스포머 계층을 추가합니다. 모든 서브 트랜스포머는 동일한 쿼리(Q)를 공유합니다.
    *   **공간 관계 정의**: 두 영역 $l$과 $m$ 사이의 상대적 공간 관계는 영역 중첩을 기반으로 정의됩니다. 인접 행렬 $\Omega_p, \Omega_n, \Omega_c$는 다음과 같이 계산됩니다:
        $$
        \Omega_p[l,m] = \begin{cases} 1, & \text{if } \frac{\text{Area}(l \cap m)}{\text{Area}(l)} > \epsilon \text{ and } \frac{\text{Area}(l \cap m)}{\text{Area}(l)} > \frac{\text{Area}(l \cap m)}{\text{Area}(m)} \\ 0, & \text{otherwise.} \end{cases}
        $$
        여기서 $\Omega_c[l,m] = \Omega_p[m,l]$ 이며, $\sum_{i \in \{p,n,c\}} \Omega_i[l,m] = 1$ 입니다. ($\epsilon = 0.9$ 사용)
    *   **어텐션 메커니즘**: 공간 그래프 인접 행렬을 각 서브 트랜스포머에 공간 하드 어텐션(Hadamard product $\circ$)으로 임베딩하여 활용합니다.
        $$
        \text{Attention}(Q,K_i,V_i) = \Omega_i \circ \text{Softmax}\left(\frac{QK_i^T}{\sqrt{d}}\right)V_i
        $$
        각 서브 트랜스포머의 MultiHead 출력은 합산되어 정규화됩니다.
        $$
        A_m = \text{Norm}\left(A + \sum_{i \in \{p,n,c\}} \text{MultiHead}(Q,K_i,V_i)\right)
        $$
    *   **효율성**: 기존 트랜스포머(6 스택)와 유사한 복잡도를 유지하기 위해 인코더 스택 수를 절반으로 줄였습니다(3 스택). 이 방식으로 공간 그래프와 의미론적 그래프를 하나의 트랜스포머 계층으로 통합합니다.

2.  **암묵적 디코딩 트랜스포머 계층 (Implicit Decoding Transformer Layer)**:
    *   **디코더 구성**: LSTM [28] 계층과 제안된 암묵적 트랜스포머 디코딩 계층으로 구성됩니다.
    *   **LSTM 입력**: LSTM은 인코딩 트랜스포머 출력의 평균($\bar{A}$), 이전 타임 스텝의 문맥 벡터($c_{t-1}$), 현재 단어 임베딩 특징 벡터($W_e \pi_t$)를 입력으로 받습니다.
        $$
        x_t = [W_e \pi_t, \bar{A} + c_{t-1}] \\
        h_t,m_t = \text{LSTM}(x_t,h_{t-1},m_{t-1})
        $$
    *   **구조 확장**: 디코딩 트랜스포머 계층도 여러 병렬 서브 트랜스포머($M$개, 실험을 통해 $M=3$이 최적)를 추가하여 확장합니다. 각 서브 트랜스포머는 영역의 다양한 측면을 암묵적으로 디코딩할 수 있습니다.
        $$
        A_{D_{t,i}} = \text{MultiHead}(W_{DQ}h_t, W_{DK_i}A', W_{DV_i}A')
        $$
    *   **문맥 벡터 생성**: 서브 트랜스포머들의 출력 평균은 Gated Linear Layer (GLU) [27]를 통과하여 현재 스텝의 새로운 문맥 벡터($c_t$)를 추출합니다.
        $$
        c_t = \text{GLU}\left(h_t, \frac{1}{M}\sum_{i=1}^{M} A_{D_{t,i}}\right)
        $$
    *   이 문맥 벡터는 단어 확률 예측에 사용됩니다.

3.  **학습 목표 (Training Objectives)**:
    *   먼저 교차 엔트로피 손실($L_{XE}$)로 모델을 25 epoch 동안 학습시킵니다.
    *   이후 CIDEr 스코어 [30]를 최적화하는 자기-비판 강화 학습(self-critical reinforced training) [29]을 35 epoch 동안 수행합니다.

## 📊 Results
*   **MSCOCO Karpathy 오프라인 테스트 셋 (표 1)**: CIDEr (130.8) 및 SPICE (22.8) 스코어에서 새로운 SOTA를 달성했습니다. 다른 평가 지표(Bleu, METEOR, ROUGE-L)에서도 기존 최상위 모델들과 필적하거나 능가하는 성능을 보였습니다. 특히, 공간 어텐션을 통합한 VORN [14]보다 모든 평가 지표에서 우수하여 제안된 공간 그래프 트랜스포머 계층의 우월성을 입증했습니다.
*   **MSCOCO 온라인 테스트 서버 (표 2)**: 여러 평가 지표에서 기존 트랜스포머 기반 모델들을 능가하는 성능을 보여주었습니다.
*   **Ablation Study (표 3)**:
    *   인코딩 트랜스포머 계층을 확장하면 모델 성능이 크게 향상됩니다.
    *   모든 인코더 계층에 제안된 공간 그래프 인코딩 트랜스포머를 적용할 때(layer1,2,3) 가장 좋은 성능을 보였습니다.
    *   인코더에서 공간 관계를 제거하면 성능이 감소하여, 설계에서 공간 관계의 중요성을 입증했습니다.
    *   디코딩 트랜스포머의 서브 트랜스포머 수($M$)는 3개일 때 최적의 성능을 보였습니다(CIDEr 119.1).
*   **정성적 분석 (그림 5)**: 잘못된 설명을 생성한 기존 모델(AoA [12])과 비교하여, 제안된 모델이 더 정확하고 상세한 캡션을 생성하는 것을 보여줍니다.
*   **암묵적 그래프 시각화 (그림 6)**: 제안된 공간 그래프 트랜스포머 계층이 정보 영역들을 더 논리적으로 연결하는 것을 시각화하여, 기존 트랜스포머가 잘못된 관계를 파악하는 것과 대조적으로 개선된 어텐션 학습 능력을 보여줍니다.
*   **디코딩 특징 공간 시각화 (그림 7)**: t-SNE 시각화 결과, 제안된 암묵적 디코딩 트랜스포머 계층의 출력이 원본 디코더보다 축소된 특징 공간에서 더 넓은 영역을 커버함을 보여줍니다. 이는 더 많은 정보를 디코딩함을 의미하며, 공분산 행렬의 트레이스 값 비교(원본: 30.40, 제안 모델: 454.57)로도 정량적으로 확인됩니다. 다만, 개별 서브 트랜스포머가 특징 공간에서 다른 요소들을 완전히 분리(disentangle)하지는 못했습니다.

## 🧠 Insights & Discussion
본 연구는 텍스트를 위해 설계된 기존 트랜스포머 계층의 내부 아키텍처를 이미지의 특성(복잡한 공간 관계, 다양한 디코딩 요구 사항)에 맞게 "확장"하는 것이 이미지 캡셔닝 성능 향상에 매우 효과적임을 성공적으로 입증했습니다. 인코더에서 이미지 영역 간의 복잡한 공간 관계를 명시적으로 모델링하고, 디코더에서 다양한 정보를 효과적으로 디코딩함으로써 기존 SOTA 모델들을 능가하는 성능을 달성했습니다. 특히, 보조 모델 없이 공간 및 의미론적 정보를 통합하는 방식은 계산 효율성 측면에서도 큰 이점을 가집니다. 한계점으로는 디코더 내 개별 서브 트랜스포머가 특징 공간에서 다른 요소들을 완전히 분리해내지 못한다는 점이 언급되며, 이는 향후 직접적인 지도(supervision)를 통해 개선될 수 있는 부분으로 제시됩니다. 본 연구는 이미지 캡셔닝뿐만 아니라 관계형 어텐션이 필요한 다른 컴퓨터 비전 태스크에서도 트랜스포머 기반 아키텍처 발전에 영감을 줄 수 있을 것으로 기대됩니다.

## 📌 TL;DR
*   **문제**: 기존 트랜스포머는 이미지 캡셔닝에서 이미지의 복잡한 2D/3D 공간 관계와 다중 정보 디코딩이라는 특성을 처리하는 데 한계가 있습니다.
*   **해결책**: "Image Transformer"를 제안하여 트랜스포머 계층의 내부 아키텍처를 "확장"합니다. 인코더는 부모/이웃/자식 공간 관계를 모델링하는 병렬 서브 트랜스포머와 하드 어텐션을 사용하는 '공간 그래프 인코딩 트랜스포머'를 포함합니다. 디코더는 여러 서브 트랜스포머를 통해 다양한 영역 정보를 디코딩하는 '암묵적 디코딩 트랜스포머'를 사용합니다.
*   **결과**: MSCOCO 데이터셋에서 CIDEr와 SPICE 스코어에서 새로운 State-of-the-Art를 달성했으며, 계산 효율성도 향상되었습니다. 이는 이미지 데이터의 고유한 특성에 트랜스포머 내부 아키텍처를 맞춤으로써 성능을 크게 개선할 수 있음을 보여줍니다.