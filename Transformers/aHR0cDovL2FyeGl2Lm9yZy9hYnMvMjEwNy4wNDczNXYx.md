# Local-to-Global Self-Attention in Vision Transformers

Jinpeng Li, Yichao Yan, Shengcai Liao, Xiaokang Yang, Ling Shao

## 🧩 Problem to Solve

최근 비전 트랜스포머(Vision Transformers) 모델들은 고해상도 시각 데이터에서 밀집된 셀프 어텐션 연산의 부담을 줄이기 위해 로컬 윈도우(local window) 내에서만 셀프 어텐션을 계산하는 계층적 설계를 채택합니다. 이러한 접근 방식은 효율성을 크게 향상시키지만, 초기 단계에서 전역적인 특징 추론 능력이 부족하여 트랜스포머 모델의 잠재력을 약화시킨다는 한계가 있습니다.

## ✨ Key Contributions

- **다중 경로(Multi-path) 구조 제안:** 각 단계에서 다중 세분화(multi-granularity)를 통해 지역-전역 추론(local-to-global reasoning)이 가능한 트랜스포머의 다중 경로 구조를 설계했습니다.
- **LG-트랜스포머(LG-Transformer) 개발:** 계산 효율적이면서도 매우 효과적인 프레임워크인 LG-트랜스포머를 제안했습니다.
- **성능 향상:** 미미한 계산 오버헤드 증가에도 불구하고, 이미지 분류와 시맨틱 분할 모두에서 주목할 만한 성능 향상을 달성했습니다.
- **새로운 LG-Attention 블록 도입:** 지역 및 전역 정보를 동시에 통합하는 새로운 LG-Attention 블록을 핵심 요소로 제시했습니다.

## 📎 Related Works

- **트랜스포머 및 비전 트랜스포머:** NLP 분야에서 시작된 트랜스포머(Transformer) [11]와 이를 시각 분야에 적용한 ViT [1] 등 초기 모델들은 전역 의존성을 활용했으나, 높은 계산 비용으로 인해 고해상도 출력에 한계가 있었습니다. 이를 해결하기 위해 PVT [4]는 공간 감소 어텐션(spatial-reduction attention)을 제안했고, Swin-Transformer [2], CvT [3], LocalViT [24] 등은 컨볼루션 또는 지역 윈도우를 활용하여 지역 정보를 통합했습니다.
- **CNN의 다중 세분화 연결:** Inception Networks [5,6,7]와 같이 다중 스케일 컨볼루션 커널을 사용한 CNN 모델들이나, HRNet [8,36], FPN [37,38,39], PSPNet [40], Hourglass [41] 등은 다양한 크기의 객체 감지나 시맨틱 분할을 위해 다중 세분화 정보를 활용했습니다. 이 연구는 CNN의 지역 연결성과 트랜스포머의 전역 연결성의 장점을 결합하고자 합니다.

## 🛠️ Methodology

- **전체 구조:** LG-트랜스포머는 효율적인 학습을 위해 최근 비전 트랜스포머 [2,3,4]의 계층적 설계를 따릅니다. 총 4단계로 구성되며, 첫 번째 단계에서는 패치 임베딩을 통해 입력 이미지를 토큰으로 변환하고, 이후 각 단계에서는 패치 병합(patch merging) 계층 [2]을 통해 특징 맵의 해상도를 줄이고 특징 차원을 늘립니다.
- **지역-전역 어텐션(LG-Attention) 블록 (핵심):**
  - 1단계부터 3단계까지 적용됩니다.
  - 여러 개의 병렬 어텐션 경로를 포함합니다.
  - 입력 특징 $z^{l-1}$ (예: $H/8 \times W/8$)은 이중 선형 다운샘플링(bilinear down-sampling)을 통해 더 낮은 해상도(예: $H/16 \times W/16$, $H/32 \times W/32$)의 특징 맵으로 변환됩니다.
  - 각 특징 맵은 SW-MSA (Window-based Multi-head Self-Attention with Shifted Window partitioning) [2]를 통해 처리됩니다.
  - 가장 낮은 해상도 경로(예: $H/32 \times W/32$)의 경우, 윈도우 크기는 해당 특징 맵 전체를 포괄하도록 설정되어 전역 셀프 어텐션을 가능하게 합니다.
  - SW-MSA 모듈을 거친 후, 다운샘플링된 특징 맵들은 원래 해상도로 업샘플링되어 결합됩니다.
  - 이 과정은 다음과 같이 표현됩니다:
    $$
    \hat{z}^l_o = \text{SW-MSA}(\text{LN}(z^{l-1})) \\
    \hat{z}^l_{d,1} = \text{SW-MSA}(\text{BD}_1(\text{LN}(z^{l-1}))) \\
    \hat{z}^l_{d,2} = \text{SW-MSA}(\text{BD}_2(\text{LN}(z^{l-1}))) \\
    \hat{z}^l = \hat{z}^l_o + \text{BU}_1(\hat{z}^l_{d,1}) + \text{BU}_2(\hat{z}^l_{d,2}) + z^{l-1} \\
    z^l = \text{MLP}(\text{LN}(\hat{z}^l)) + \hat{z}^l
    $$
    여기서 BD는 이중 선형 다운샘플링, BU는 이중 선형 업샘플링을 나타냅니다.
- **계산 복잡도:**
  - SW-MSA의 복잡도: $\Omega(\text{SW-MSA}) = 4hwC^2 + 2M^2hwC$
  - LG-Attention 블록의 복잡도 (다운샘플링 비율 2, 4 사용): $\Omega(\text{LG-Att}) = 5.25hwC^2 + 2.625M^2hwC$
  - SW-MSA 대비 약 0.3배 정도의 미미한 계산량 증가가 있으며, 전역 셀프 어텐션의 $O((hw)^2)$와 달리 $O(hw)$에 비례하여 효율성을 유지합니다.
- **아키텍처 변형:** LG-T (Tiny)와 LG-S (Small) 두 가지 변형 모델을 구축했습니다.

## 📊 Results

- **이미지 분류 (ImageNet-1K):**
  - LG-T는 82.1%의 Top-1 정확도를 달성하여 Swin-T보다 0.8%p 높은 성능을 보였습니다.
  - LG-S는 83.3%의 Top-1 정확도를 달성하며, Swin-B와 비슷한 성능을 보이면서도 훨씬 적은 파라미터와 FLOPs를 가졌습니다.
  - MobileNet, ResNet, DeiT, PVT 등 기존의 다양한 CNN 및 트랜스포머 모델들을 능가했습니다.
- **시맨틱 분할 (ADE20K):**
  - LG-T를 UperNet [57]과 결합했을 때 45.3%의 mIoU를 달성했습니다.
  - ResNet-101 (+0.4%p), DeiT-S (+1.3%p), Swin-T (+0.8%p) 대비 성능 향상을 보였습니다.
  - 더 큰 모델인 DeepLab V3 + ResNeSt-200 및 SETR에 비해 낮은 성능이지만, 파라미터 수와 계산 복잡도를 고려했을 때 성능과 효율성 간의 좋은 균형을 이루었습니다.
- **제거 연구 (Ablation Studies):**
  - LG-Attention 블록을 더 많은 단계(1단계~3단계)에 적용할수록 성능이 지속적으로 향상되었습니다 (78.4%에서 79.7%로).
  - 모든 어텐션 경로(1x, 16x, 32x 다운샘플링)를 결합했을 때 가장 좋은 성능을 보였습니다.
  - LG-T는 Swin-T보다 더 빠르게 수렴하고 더 낮은 훈련 손실과 더 높은 검증 정확도를 보였습니다.

## 🧠 Insights & Discussion

- **지역 및 전역 특징 학습의 시너지:** LG-트랜스포머의 다중 경로 구조는 CNN의 지역 특징 학습 메커니즘과 트랜스포머의 전역 특징 학습 메커니즘을 효과적으로 결합하여 성능을 향상시킵니다.
- **효율성 유지:** 다운샘플링 연산을 통해 계산 복잡도를 선형적으로 유지하여 높은 효율성을 유지합니다.
- **향상된 표현력:** 시각화된 특징 맵은 지역 어텐션 윈도우 경계에서 불연속성이 나타나는 반면, 전역 어텐션이 전체 이미지를 포괄하여 멀티-세분화 설계의 이점을 보여줍니다.
- **한계점:** 다중 경로 프레임워크로 인해 단일 경로 트랜스포머에 비해 추론 속도가 느리다는 한계가 있으며, 이는 향후 연구에서 개선될 예정입니다.

## 📌 TL;DR

- **문제:** 기존 비전 트랜스포머는 효율성을 위해 지역 어텐션을 사용하지만, 초기 단계에서 전역적 추론 능력이 부족합니다.
- **방법:** LG-트랜스포머는 다중 경로 LG-Attention 블록을 도입하여 다양한 스케일의 특징 맵에 윈도우 기반 셀프 어텐션을 적용합니다. 특히, 가장 낮은 해상도 경로에서는 전체 이미지에 대한 전역 어텐션을 수행하여 지역 및 전역 정보를 동시에 통합합니다.
- **결과:** 이 모델은 ImageNet 이미지 분류에서 Swin-T보다 0.8%p 높은 정확도를 달성하고, ADE20K 시맨틱 분할에서도 0.8%p mIoU를 향상시키는 등, 미미한 계산 오버헤드 증가로도 뛰어난 성능을 보여줍니다.
