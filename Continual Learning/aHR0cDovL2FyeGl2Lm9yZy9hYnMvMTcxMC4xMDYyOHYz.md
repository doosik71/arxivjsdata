# VARIATIONAL CONTINUAL LEARNING

Cuong V. Nguyen, Yingzhen Li, Thang D. Bui, Richard E. Turner

## π§© Problem to Solve

μ§€μ† ν•™μµ(continual learning)μ€ λ°μ΄ν„°κ°€ μμ°¨μ μΌλ΅ λ„μ°©ν•κ³ , νƒμ¤ν¬κ°€ μ‹κ°„μ— λ”°λΌ λ³€ν™”ν•λ©°, μƒλ΅μ΄ νƒμ¤ν¬κ°€ κ³„μ†ν•΄μ„ μ¶ν„ν•λ” μ¨λΌμΈ ν•™μµμ ν• ν•νƒλ΅, κΈ°κ³„ ν•™μµμ ν•µμ‹¬ κ³Όμ  μ¤‘ ν•λ‚μ…λ‹λ‹¤. μ‹¬μΈµ μ‹ κ²½λ§μ€ μƒλ΅μ΄ λ°μ΄ν„°μ— μ μ‘ν•λ©΄μ„λ„ μ΄μ „ νƒμ¤ν¬μ—μ„ ν•™μµν• μ§€μ‹μ„ μ μ§€ν•λ” λ° μ–΄λ ¤μ›€μ„ κ²μΌλ©°, μ΄λ” ν”ν **μΉλ…μ μΈ λ§κ°(catastrophic forgetting)** λ¬Έμ λ΅ μ΄μ–΄μ§‘λ‹λ‹¤. κΈ°μ΅΄μ μ§€μ† ν•™μµ λ°©λ²•λ“¤μ€ μ•μ •μ„±(stability)κ³Ό μ μ—°μ„±(plasticity) μ‚¬μ΄μ κ· ν•μ„ λ§μ¶”λ” λ° ν•κ³„κ°€ μκ±°λ‚, μλ™μ μΈ ν•μ΄νΌνλΌλ―Έν„° νλ‹μ„ ν•„μ”λ΅ ν•©λ‹λ‹¤.

## β¨ Key Contributions

* **λ³€λ¶„ μ§€μ† ν•™μµ(Variational Continual Learning, VCL) ν”„λ μ„μ›ν¬ μ μ•**: μ¨λΌμΈ λ³€λ¶„ μ¶”λ΅ (Variational Inference, VI)κ³Ό μ‹ κ²½λ§μ„ μ„ν• λ¬ν…μΉ΄λ¥Όλ΅ VI κΈ°λ²•μ„ κ²°ν•©ν•μ—¬ μΉλ…μ μΈ λ§κ°μ„ ν”Όν•κ³  μλ™μ μΌλ΅ μ§€μ‹μ„ μ μ§€ν•λ” μΌλ°μ μΈ μ§€μ† ν•™μµ λ°©λ²•λ΅ μ„ κ°λ°ν–μµλ‹λ‹¤.
* **λ‹¤λ©μ  μ μ© κ°€λ¥μ„±**: μ μ•λ VCL ν”„λ μ„μ›ν¬κ°€ μ‹¬μΈµ νλ³„ λ¨λΈ(deep discriminative models)κ³Ό μ‹¬μΈµ μƒμ„± λ¨λΈ(deep generative models) λ¨λ‘μ— μ„±κ³µμ μΌλ΅ μ μ©λ  μ μμμ„ μ…μ¦ν–μµλ‹λ‹¤.
* **μ†κ·λ¨ μ—ν”Όμ†λ“ λ©”λ¨λ¦¬(Episodic Memory) ν†µν•©**: Coreset λ°μ΄ν„° μ”μ•½ λ°©λ²•μ„ VIμ™€ κ²°ν•©ν•μ—¬ μ†κ·λ¨ μ—ν”Όμ†λ“ λ©”λ¨λ¦¬λ¥Ό VCLμ— ν¬ν•¨μ‹μΌ°μΌλ©°, μ΄λ” μ΄μ „ νƒμ¤ν¬μ ν•µμ‹¬ μ •λ³΄λ¥Ό μ μ§€ν•μ—¬ λ§κ°μ„ μ™„ν™”ν•λ” λ° κΈ°μ—¬ν•©λ‹λ‹¤.
* **μµμ²¨λ‹¨ μ„±λ¥ λ‹¬μ„±**: λ‹¤μ–‘ν• μ§€μ† ν•™μµ λ²¤μΉλ§ν¬ νƒμ¤ν¬μ—μ„ κΈ°μ΅΄μ μµμ²¨λ‹¨ λ°©λ²•(EWC, SI, LP)μ„ λ¥κ°€ν•λ” μ„±λ¥μ„ λ³΄μ€μΌλ©°, VCLμ€ ν•μ΄νΌνλΌλ―Έν„° νλ‹ μ—†μ΄λ„ μ°μν• κ²°κ³Όλ¥Ό μ–»μ—μµλ‹λ‹¤.

## π“ Related Works

* **μ‹¬μΈµ νλ³„ λ¨λΈμ„ μ„ν• μ§€μ† ν•™μµ**:
  * **μ •κ·ν™”λ μµλ€ μ°λ„ μ¶”μ •(Regularized Maximum Likelihood Estimation)**: $\mathcal{L}_t(\theta) = \sum_{n=1}^{N_t} \text{log}p(y^{(n)}_t|\theta,x^{(n)}_t) - \frac{1}{2}\lambda_t(\theta-\theta_{t-1})^{\text{T}}\Sigma^{-1}_{t-1}(\theta-\theta_{t-1})$ ν•νƒμ λ©μ  ν•¨μλ¥Ό μµμ ν™”ν•©λ‹λ‹¤.
    * **μµλ€ μ°λ„ μ¶”μ •(MLE) λ° MAP μ¶”μ •**: μ •κ·ν™” ν•­μ΄ μ—†κ±°λ‚(MLE), κ°€μ°μ‹μ• μ‚¬μ „ λ¶„ν¬λ΅ ν•΄μ„ν•μ—¬ MAP μ¶”μ •μ„ μν–‰ν•μ§€λ§, $\Sigma_t$ κ³„μ‚°μ΄ μ–΄λ µκ±°λ‚ λ§κ°μ— μ·¨μ•½ν•©λ‹λ‹¤.
    * **λΌν”λΌμ¤ μ „ν(Laplace Propagation, LP)**: κ° λ‹¨κ³„μ—μ„ λΌν”λΌμ¤ κ·Όμ‚¬λ¥Ό μ μ©ν•μ—¬ $\Sigma^{-1}_t$λ¥Ό μ¬κ·€μ μΌλ΅ μ—…λ°μ΄νΈν•©λ‹λ‹¤.
    * **νƒ„λ ¥μ  κ°€μ¤‘μΉ κ³ μ •(Elastic Weight Consolidation, EWC)**: ν”Όμ…” μ •λ³΄ ν–‰λ ¬(Fisher Information Matrix)μ„ μ‚¬μ©ν•μ—¬ μ΄μ „ νƒμ¤ν¬μ— μ¤‘μ”ν• νλΌλ―Έν„°λ¥Ό λ³΄νΈν•¨μΌλ΅μ¨ λ§κ°μ„ μ™„ν™”ν•©λ‹λ‹¤.
    * **μ‹λƒ…μ¤ μ§€λ¥(Synaptic Intelligence, SI)**: κ° νλΌλ―Έν„°κ°€ νƒμ¤ν¬μ— λ―ΈμΉλ” μ¤‘μ”λ„λ¥Ό μΈ΅μ •ν•μ—¬ μ •κ·ν™”μ— ν™μ©ν•©λ‹λ‹¤.
  * **λ² μ΄μ¦ μ‹ κ²½λ§ ν•™μµ**: ν™•μ¥ μΉΌλ§ ν•„ν„°λ§, λΌν”λΌμ¤ κ·Όμ‚¬, λ³€λ¶„ μ¶”λ΅ (VI), μμ°¨ λ¬ν…μΉ΄λ¥Όλ΅, κΈ°λ“κ°’ μ „ν(EP) λ“±μ΄ μμΌλ‚, λ€λ¶€λ¶„ λ°°μΉ ν•™μµμ— μ¤‘μ μ„ λ‘μ—μµλ‹λ‹¤.
  * **μ¨λΌμΈ λ³€λ¶„ μ¶”λ΅ **: μ΄μ „μ— μ—°κµ¬λμ—μΌλ‚, μ‹ κ²½λ§μ΄λ‚ λ³µμ΅ν• κ΄€λ ¨ νƒμ¤ν¬μ—λ” μ μ©λμ§€ μ•μ•μµλ‹λ‹¤.
* **μ‹¬μΈµ μƒμ„± λ¨λΈμ„ μ„ν• μ§€μ† ν•™μµ**:
  * **VAE (Variational Auto-Encoders)**: μΌλ°μ μΈ VAE μ•κ³ λ¦¬μ¦μ„ μƒλ΅μ΄ λ°μ΄ν„°μ…‹μ— μ§μ ‘ μ μ©ν•λ©΄ μΉλ…μ μΈ λ§κ°μ΄ λ°μƒν•©λ‹λ‹¤.
  * **EWC μ •κ·ν™”κ°€ μ¶”κ°€λ VAE**: EWC μ •κ·ν™” ν•­μ„ VAE λ©μ  ν•¨μμ— μ¶”κ°€ν•μ§€λ§, ν”Όμ…” μ •λ³΄ ν–‰λ ¬ κ³„μ‚°μ— μ–΄λ ¤μ›€μ΄ μμµλ‹λ‹¤.

## π› οΈ Methodology

VCLμ€ κ·Όμ‚¬ λ² μ΄μ¦ μ¶”λ΅ μ„ ν†µν•΄ μ§€μ† ν•™μµμ„ μν–‰ν•©λ‹λ‹¤.

1. **λ² μ΄μ¦ μ¶”λ΅ μ μ›λ¦¬**:
    * Bayes' ruleμ— λ”°λΌ ν„μ¬ λ°μ΄ν„° $D_T$λ¥Ό κ΄€μ°°ν• ν›„μ μ‚¬ν›„ λ¶„ν¬ $p(\theta|D_{1:T})$λ” μ΄μ „ μ‚¬ν›„ λ¶„ν¬ $p(\theta|D_{1:T-1})$μ™€ ν„μ¬ λ°μ΄ν„°μ μ°λ„ $p(D_T|\theta)$λ¥Ό κ³±ν•μ—¬ μ¬μ •κ·ν™”ν•¨μΌλ΅μ¨ μ–»μ–΄μ§‘λ‹λ‹¤. μ΄λ” μ¨λΌμΈ μ—…λ°μ΄νΈλ¥Ό μμ—°μ¤λ½κ² μ§€μ›ν•©λ‹λ‹¤.
    * $$p(\theta|D_{1:T}) \propto p(\theta|D_{1:T-1})p(D_T|\theta)$$
2. **λ³€λ¶„ μ§€μ† ν•™μµ(VCL)**:
    * μ •ν™•ν• λ² μ΄μ¦ μ¶”λ΅ μ€ λ€λ¶€λ¶„ λ‹¤λ£¨κΈ° μ–΄λ µκΈ° λ•λ¬Έμ—, VCLμ€ KL λ°μ‚° μµμ†ν™”λ¥Ό ν†µν•΄ κ·Όμ‚¬ μ‚¬ν›„ λ¶„ν¬ $q_t(\theta)$λ¥Ό μ°Ύμµλ‹λ‹¤.
    * $$q_t(\theta) = \text{arg min}_{q \in Q} \text{KL} \left( q(\theta) \middle\| \frac{1}{Z_t} q_{t-1}(\theta)p(D_t|\theta) \right)$$
    * μ—¬κΈ°μ„ $q_0(\theta)$λ” μ‚¬μ „ λ¶„ν¬ $p(\theta)$λ΅ μ •μλ©λ‹λ‹¤.
3. **μ—ν”Όμ†λ“ λ©”λ¨λ¦¬(Coreset) κ°•ν™” VCL (Algorithm 1)**:
    * λ°λ³µμ μΈ κ·Όμ‚¬λ΅ μΈν• μ¤λ¥ λ„μ  λ° λ§κ°μ„ μ™„ν™”ν•κΈ° μ„ν•΄ μ†κ·λ¨ μ½”μ–΄μ…‹ $C_t$ (μ΄μ „ νƒμ¤ν¬μ λ€ν‘ λ°μ΄ν„° ν¬μΈνΈ)λ¥Ό μ μ§€ν•©λ‹λ‹¤.
    * **μ½”μ–΄μ…‹ μ—…λ°μ΄νΈ**: ν„μ¬ νƒμ¤ν¬μ μƒλ΅μ΄ λ°μ΄ν„° ν¬μΈνΈμ™€ μ΄μ „ μ½”μ–΄μ…‹ $C_{t-1}$μ—μ„ μ„ νƒλ λ°μ΄ν„° ν¬μΈνΈλ΅ $C_t$λ¥Ό κµ¬μ„±ν•©λ‹λ‹¤ (λ¬΄μ‘μ„ μƒν”λ§ λλ” K-μ¤‘μ‹¬(K-center) μ•κ³ λ¦¬μ¦ μ‚¬μ©).
    * **λ³€λ¶„ λ¶„ν¬ μ—…λ°μ΄νΈ**:
        * μ½”μ–΄μ…‹μ— ν¬ν•¨λμ§€ μ•μ€ λ°μ΄ν„°λ¥Ό μ‚¬μ©ν•μ—¬ μ¤‘κ°„ λ³€λ¶„ λ¶„ν¬ $\tilde{q}_t(\theta)$λ¥Ό μ—…λ°μ΄νΈν•©λ‹λ‹¤.
        * $$\tilde{q}_t(\theta) \leftarrow \text{arg min}_{q \in Q} \text{KL} \left( q(\theta) \middle\| \frac{1}{\tilde{Z}} \tilde{q}_{t-1}(\theta)p(D_t \cup C_{t-1} \setminus C_t |\theta) \right)$$
        * μµμΆ… λ³€λ¶„ λ¶„ν¬ $q_t(\theta)$λ” μμΈ΅μ—λ§ μ‚¬μ©λλ©°, $\tilde{q}_t(\theta)$μ™€ μ½”μ–΄μ…‹ $C_t$μ μ°λ„λ¥Ό κ²°ν•©ν•μ—¬ μ—…λ°μ΄νΈν•©λ‹λ‹¤.
        * $$q_t(\theta) \leftarrow \text{arg min}_{q \in Q} \text{KL} \left( q(\theta) \middle\| \frac{1}{Z} \tilde{q}_t(\theta)p(C_t|\theta) \right)$$
4. **μ‹¬μΈµ νλ³„ λ¨λΈ μ μ©**:
    * **λ„¤νΈμ›ν¬ μ•„ν‚¤ν…μ²**: Multi-head λ„¤νΈμ›ν¬λ¥Ό μ‚¬μ©ν•©λ‹λ‹¤. μ…λ ¥μ— κ°€κΉμ΄ νλΌλ―Έν„°($\theta_S$)λ” κ³µμ ν•κ³ , κ° νƒμ¤ν¬($t$)μ— λ€ν• μ¶λ ¥ λ μ΄μ–΄($\theta_{H_t}$)λ” λ¶„λ¦¬ν•©λ‹λ‹¤.
    * **κ·Όμ‚¬ μ‚¬ν›„ λ¶„ν¬**: κ°€μ°μ‹μ• ν‰κ·  ν•„λ“(Gaussian mean-field) κ·Όμ‚¬λ¥Ό μ‚¬μ©ν•©λ‹λ‹¤: $q_t(\theta) = \prod_{d=1}^D \mathcal{N}(\theta_{t,d}; \mu_{t,d}, \sigma^2_{t,d})$.
    * **ν•™μµ λ©μ **: μ¨λΌμΈ λ³€λ¶„ μμ  μ—λ„μ§€(online variational free energy)μ μμ λλ” μ¨λΌμΈ μ£Όλ³€ μ°λ„(online marginal likelihood)μ λ³€λ¶„ ν•ν•μ„ μµλ€ν™”ν•©λ‹λ‹¤.
    * $$\mathcal{L}^{\text{VCL}}_t(q_t(\theta)) = \sum_{n=1}^{N_t} \mathbb{E}_{\theta \sim q_t(\theta)} [\text{log}p(y^{(n)}_t|\theta,x^{(n)}_t)] - \text{KL}(q_t(\theta)||q_{t-1}(\theta))$$
    * κΈ°μΈκΈ° κ³„μ‚°μ—λ” λ¬ν…μΉ΄λ¥Όλ΅ κ·Όμ‚¬μ™€ κµ­μ† μ¬λ§¤κ°λ³€μν™” νΈλ¦­(local reparameterization trick)μ„ μ‚¬μ©ν•©λ‹λ‹¤.
5. **μ‹¬μΈµ μƒμ„± λ¨λΈ μ μ© (VAE)**:
    * λ¨λΈ νλΌλ―Έν„° $\theta$μ™€ μΈμ½”λ”(λ³€λ¶„ νλΌλ―Έν„° $\phi$)μ— λ€ν• μ „μ²΄ λ³€λ¶„ ν•ν•(full variational lower bound)μ„ μµλ€ν™”ν•μ—¬ μ‚¬ν›„ λ¶„ν¬ $q_t(\theta)$λ¥Ό κ·Όμ‚¬ν•©λ‹λ‹¤.
    * $$\mathcal{L}^{\text{VCL}}_t(q_t(\theta),\phi) = \mathbb{E}_{q_t(\theta)} \left\{ \sum_{n=1}^{N_t} \mathbb{E}_{q_\phi(z^{(n)}_t|x^{(n)}_t)} \left[ \text{log}\frac{p(x^{(n)}_t|z^{(n)}_t,\theta)p(z^{(n)}_t)}{q_\phi(z^{(n)}_t|x^{(n)}_t)} \right] \right\} - \text{KL}(q_t(\theta)||q_{t-1}(\theta))$$
    * μƒμ„± λ¨λΈλ„ κ³µμ  λ° νƒμ¤ν¬λ³„ μ»΄ν¬λ„νΈλ΅ κµ¬μ„±λ  μ μμµλ‹λ‹¤.

## π“ Results

VCLμ€ μ„Έ κ°€μ§€ νλ³„ νƒμ¤ν¬μ™€ λ‘ κ°€μ§€ μƒμ„± νƒμ¤ν¬μ—μ„ ν‰κ°€λμ—μµλ‹λ‹¤. κ²½μ λ¨λΈ(EWC, SI, LP)μ€ ν•μ΄νΌνλΌλ―Έν„° νλ‹μ„ κ±°μ³¤μμ—λ„ λ¶κµ¬ν•κ³  VCLμ΄ λ” μΆ‹μ€ μ„±λ¥μ„ λ³΄μ€μµλ‹λ‹¤.

* **μ‹¬μΈµ νλ³„ λ¨λΈ (Permuted MNIST, Split MNIST, Split notMNIST)**:
  * **Permuted MNIST**: 10κ° νƒμ¤ν¬ ν›„ ν‰κ·  μ •ν™•λ„μ—μ„ VCL (90%)μ€ EWC (84%), SI (86%), LP (82%)λ¥Ό ν¬κ² μ•μ„°μµλ‹λ‹¤. Coresetμ„ VCLκ³Ό κ²°ν•©ν•λ©΄ (λ¬΄μ‘μ„ Coreset λ° K-center Coreset λ¨λ‘) 93%μ μ •ν™•λ„λ΅ μ„±λ¥μ΄ λ”μ± ν–¥μƒλμ—μµλ‹λ‹¤. Coreset ν¬κΈ°κ°€ μ»¤μ§μλ΅ μ„±λ¥μ€ λ” ν–¥μƒλμ–΄, 5,000κ° μμ  CoresetμΌλ΅ 95.5%μ— λ„λ‹¬ν–μµλ‹λ‹¤.
  * **Split MNIST**: VCL (97.0%)μ€ EWC (63.1%)μ™€ LP (61.2%)λ¥Ό ν¬κ² λ¥κ°€ν–μΌλ©°, SI (98.9%)μ™€λ” κ·Όμ†ν• μ°¨μ΄λ΅ λ’¤μ²μ΅μµλ‹λ‹¤. Coreset μ¶”κ°€ μ‹ VCLμ€ μ•½ 98.4% μ •ν™•λ„λ΅ SIμ— λ§¤μ° κ·Όμ ‘ν–μµλ‹λ‹¤.
  * **Split notMNIST**: VCL (92.0%)μ€ EWC (71%)μ™€ LP (63%)λ³΄λ‹¤ ν›¨μ”¬ μ°μν–μΌλ©°, SI (94%)μ™€ κ²½μμ μΈ μ„±λ¥μ„ λ³΄μ€μµλ‹λ‹¤. λ¬΄μ‘μ„ Coreset μ¶”κ°€ μ‹ VCLμ€ 96%μ μ •ν™•λ„λ΅ μ„±λ¥μ΄ ν–¥μƒλμ—μµλ‹λ‹¤.
* **μ‹¬μΈµ μƒμ„± λ¨λΈ (MNIST μ«μ μƒμ„±, notMNIST λ¬Έμ μƒμ„±)**:
  * μμ§„ν•(naive) μ¨λΌμΈ ν•™μµ λ°©μ‹μ€ μΉλ…μ μΈ λ§κ°μ„ κ²λ” λ°λ©΄, LP, EWC, SI, VCLμ€ μ΄μ „ νƒμ¤ν¬λ¥Ό κΈ°μ–µν–μµλ‹λ‹¤.
  * μƒμ„±λ μ΄λ―Έμ§€μ μ‹κ°μ  ν’μ§ μΈ΅λ©΄μ—μ„ SIμ™€ VCLμ΄ κ°€μ¥ μ°μν–μµλ‹λ‹¤.
  * μ •λ‰μ  ν‰κ°€(ν…μ¤νΈ λ΅κ·Έ-μ°λ„ λ° λ¶„λ¥κΈ° λ¶ν™•μ‹¤μ„±)μ—μ„ VCLμ€ SIμ™€ λ™λ“±ν•κ±°λ‚ μ•½κ°„ λ” λ‚μ€ μ„±λ¥μ„ λ³΄μ€μΌλ©°, LPμ™€ EWCλ” λ” λ‚®μ€ μ„±λ¥μ„ λ‚νƒ€λƒμµλ‹λ‹¤.
  * VCLμ€ λ©μ  ν•¨μμ— νλ‹λ ν•μ΄νΌνλΌλ―Έν„°κ°€ μ—†μμ—λ„ λ¶κµ¬ν•κ³ , λ¨λ“  μ§€ν‘μ—μ„ μ „λ°μ μΌλ΅ μ°μν• μ¥κΈ° κΈ°μ–µ μ„±λ¥μ„ μ…μ¦ν–μµλ‹λ‹¤.

## π§  Insights & Discussion

* **λ² μ΄μ¦ μ¶”λ΅ μ μ ν•©μ„±**: λ² μ΄μ¦ μ¶”λ΅ μ€ νλΌλ―Έν„°μ— λ€ν• λ¶„ν¬λ¥Ό μ μ§€ν•κ³ , μƒλ΅μ΄ λ°μ΄ν„°κ°€ λ„μ°©ν•  λ• μ΄μ „ μ‚¬ν›„ λ¶„ν¬λ¥Ό μ‚¬μ „ λ¶„ν¬λ΅ μ‚¬μ©ν•μ—¬ μ§€μ‹μ„ μμ—°μ¤λ½κ² ν†µν•©ν•¨μΌλ΅μ¨ μ§€μ† ν•™μµμ„ μ„ν• κ°•λ ¥ν•κ³  μ›μΉ™μ μΈ ν”„λ μ„μ›ν¬λ¥Ό μ κ³µν•©λ‹λ‹¤. μ΄λ” μΉλ…μ μΈ λ§κ°μ„ λ³Έμ§μ μΌλ΅ μ™„ν™”ν•©λ‹λ‹¤.
* **VCLμ μ¥μ **: VCLμ€ μ™„μ „ν• νλΌλ―Έν„° λ¶„ν¬λ¥Ό μ μ§€ν•μ—¬ λ¶ν™•μ‹¤μ„± μ¶”μ •μΉλ¥Ό μ κ³µν•λ©°, μ΄λ” κΈ°μ΅΄ μ§€μ‹μ μ¤‘μ”λ„λ¥Ό νλ‹¨ν•κ³  μƒλ΅μ΄ ν•™μµμ— μ μ ν λ°μν•λ” λ° μ¤‘μ”ν•©λ‹λ‹¤. λν•, MAP, EWC, SIμ™€ λ‹¬λ¦¬ κ²€μ¦ μ„ΈνΈμ—μ„ νλ‹ν•΄μ•Ό ν•λ” μμ  ν•μ΄νΌνλΌλ―Έν„°κ°€ μ—†μ–΄ μ¨λΌμΈ ν•™μµ ν™κ²½μ—μ„ μ λ¦¬ν•κ³ , λ”μ± μλ™μ μΈ ν•™μµμ„ κ°€λ¥ν•κ² ν•©λ‹λ‹¤.
* **μ—ν”Όμ†λ“ λ©”λ¨λ¦¬μ ν¨κ³Ό**: μ½”μ–΄μ…‹κ³Ό κ°™μ€ μ—ν”Όμ†λ“ λ©”λ¨λ¦¬λ” λ°λ³µμ μΈ κ·Όμ‚¬λ΅ μΈν• μ •λ³΄ μ†μ‹¤μ„ λ³΄μ™„ν•κ³  μ„±λ¥μ„ λ”μ± ν–¥μƒμ‹ν‚¤λ” ν¨κ³Όμ μΈ λ°©λ²•μ…λ‹λ‹¤. μ½”μ–΄μ…‹ λ‹¨λ…μΌλ΅λ” μ„±λ¥μ΄ μΆ‹μ§€ μ•λ”λΌλ„, VCLκ³Ό κ²°ν•©λ  λ• μ‹λ„μ§€ ν¨κ³Όλ¥Ό λƒ…λ‹λ‹¤.
* **ν•κ³„ λ° ν–¥ν›„ μ—°κµ¬**: ν„μ¬ VCLμ€ λ¨λΈ κµ¬μ΅°κ°€ μ‚¬μ „μ— μ•λ ¤μ Έ μλ‹¤λ” κ°€μ •μ„ ν•μ§€λ§, ν–¥ν›„μ—λ” μƒλ΅μ΄ νƒμ¤ν¬μ— λ”°λΌ λ¨λΈ κµ¬μ΅°λ¥Ό μλ™μΌλ΅ κµ¬μ¶•ν•λ” μ—°κµ¬κ°€ ν•„μ”ν•©λ‹λ‹¤. λν•, λ” μ •κµν• μ—ν”Όμ†λ“ λ©”λ¨λ¦¬ κΈ°λ²•κ³Ό λ‹¤λ¥Έ κ·Όμ‚¬ μ¶”λ΅  λ°©λ²•λ“¤μ„ νƒμƒ‰ν•  μ μμµλ‹λ‹¤. VCLμ€ μμ°¨μ  μμ‚¬ κ²°μ • λ¬Έμ (μ: κ°•ν™” ν•™μµ, λ¥λ™ ν•™μµ)μ—μ„ ν¨μ¨μ μΈ λ¨λΈ κ°μ„ μ— νΉν μ ν•©ν•©λ‹λ‹¤.

## π“ TL;DR

VCLμ€ μ¨λΌμΈ λ³€λ¶„ μ¶”λ΅ μ„ ν™μ©ν•μ—¬ μ‹ κ²½λ§μ μΉλ…μ μΈ λ§κ° λ¬Έμ λ¥Ό ν•΄κ²°ν•λ” μ§€μ† ν•™μµ ν”„λ μ„μ›ν¬μ…λ‹λ‹¤. μ΄ λ°©λ²•μ€ λ² μ΄μ¦ μ¶”λ΅ μ μ›λ¦¬λ¥Ό κΈ°λ°μΌλ΅ νλΌλ―Έν„° λ¶„ν¬λ¥Ό μ μ§€ν•κ³ , μ½”μ–΄μ…‹ κΈ°λ° μ—ν”Όμ†λ“ λ©”λ¨λ¦¬λ¥Ό ν†µν•΄ μ„±λ¥μ„ κ°•ν™”ν•©λ‹λ‹¤. νλ³„ λ° μƒμ„± λ¨λΈ λ¨λ‘μ—μ„ κΈ°μ΅΄ μµμ²¨λ‹¨ λ°©λ²•λ“¤μ„ λ¥κ°€ν•λ” μ„±λ¥μ„ λ³΄μ€μΌλ©°, ν•μ΄νΌνλΌλ―Έν„° νλ‹ μ—†μ΄λ„ κ°•λ ¥ν•κ³  μλ™μ μΈ ν•™μµμ„ κ°€λ¥ν•κ² ν•©λ‹λ‹¤.
