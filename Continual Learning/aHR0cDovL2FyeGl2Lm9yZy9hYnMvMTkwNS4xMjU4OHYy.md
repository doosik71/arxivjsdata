# Meta-Learning Representations for Continual Learning

Khurram Javed, Martha White

## 🧩 Problem to Solve

지속적인 학습(Continual Learning) 환경에서 지능형 에이전트는 새로운 데이터를 빠르게 학습하고 기존 지식을 잊지 않도록 재활용해야 합니다. 그러나 현재 신경망 기반 시스템은 정반대의 문제를 겪고 있습니다. 즉, 심각한 망각(catastrophic forgetting)에 취약하며, 미래 학습을 용이하게 하도록 훈련되지 않습니다. 이는 이러한 두 가지 목표에 명시적으로 훈련되지 않은 표현(representation)에서 학습하기 때문입니다.

## ✨ Key Contributions

- **OML (Online-aware Meta-Learning) 목적 함수 제안**: 온라인 업데이트 환경에서 미래 학습을 가속화하고 망각에 강인한 표현을 학습하여 치명적인 간섭(catastrophic interference)을 직접적으로 최소화하는 메타 목적 함수 OML을 제안합니다.
- **자연스러운 희소 표현 학습**: OML을 통해 온라인 업데이트에 더 효과적인 자연스럽게 희소한 표현(sparse representations)을 학습할 수 있음을 보여줍니다. 이 표현들은 데드 뉴런(dead neurons) 없이 높은 인스턴스 희소성(instance sparsity)을 가집니다.
- **기존 지속 학습 전략과의 시너지**: OML은 MER, GEM, EWC, ER-Reservoir와 같은 기존 지속 학습 전략들과 상호 보완적이며, 이들과 결합 시 성능을 크게 향상시킬 수 있음을 입증합니다.
- **경쟁력 있는 온라인 학습 성능**: OML이 학습한 표현에 대한 기본적인 온라인 업데이트 전략만으로도 기존의 리허설 기반(rehearsal-based) 지속 학습 방법들과 경쟁하거나 이를 능가하는 성능을 보여줍니다.

## 📎 Related Works

- **치명적인 간섭 완화 기법**:
  - **지식 유지(Knowledge Retention)**: 중요한 가중치 변경을 방지하기 위해 정규화 항을 도입 (예: EWC, Synaptic Intelligence, IMM)합니다.
  - **리허설(Rehearsal) 및 재생(Replay)**: 이전 데이터를 다시 학습하거나(경험 재생), 생성 모델을 통해 샘플을 생성하거나, 지식 증류(knowledge distillation)를 사용하여 망각을 줄입니다.
  - **반분산(Semi-distributed) 또는 희소(Sparse) 표현**: 초기 연구에서 치명적인 망각 완화를 위해 희소 표현의 유용성을 탐구했으나, 희소성만으로는 간섭에 대한 강인함을 보장하기 어렵습니다.
- **메타 학습(Meta-learning)**: 모델 초기화를 학습하여 빠른 적응(fast adaptation)을 가능하게 하는 MAML과 같은 접근 방식들이 제안되었으나, 치명적인 간섭 문제를 직접적으로 다루지는 않았습니다. 본 연구는 모델 초기화 대신 표현 자체를 메타 학습합니다.
- **명시적 간섭 완화**: 경사도(gradients) 간의 내적을 최대화하여 간섭을 줄이는 방법이 제안되기도 했으며, 본 연구는 이를 넘어 명시적으로 표현 자체를 최적화합니다.

## 🛠️ Methodology

1. **모델 아키텍처**:
   - 전체 모델 $f_{\text{W},\theta}(X)$는 두 가지 네트워크로 구성됩니다.
     - **표현 학습 네트워크 (Representation Learning Network, RLN)** $\phi_{\theta}(X)$: 입력 $X$를 표현 $R^d$로 매핑하는 심층 신경망입니다. $\theta$는 메타-파라미터(meta-parameters)로, 메타 학습 과정의 외부 루프에서만 업데이트되고 메타-테스트 시점에는 고정됩니다.
     - **예측 학습 네트워크 (Prediction Learning Network, PLN)** $g_{\text{W}}(R^d)$: RLN이 생성한 표현 $R^d$를 받아 최종 예측 $Y$를 수행하는 네트워크입니다. $W$는 PLN의 파라미터로, 메타 학습의 내부 루프 및 온라인 학습 시점에 업데이트됩니다.
2. **OML 메타-목적 함수**:
   - OML은 다음 목적 함수를 최소화하도록 설계되었습니다.
     $$ \min*{\text{W},\theta} \sum*{T*i \sim p(T)} \text{OML}(\text{W},\theta) \stackrel{\text{def}}{=} \sum*{T*i \sim p(T)} \sum*{S*j^k \sim p(S^k|T_i)} \left[ L*{\text{CLP},i}(U(\text{W},\theta,S_j^k)) \right] $$
   - 여기서 $T_i$는 지속 학습 문제의 분포 $p(T)$에서 샘플링된 문제이고, $S_j^k$는 길이 $k$의 데이터 궤적(trajectory)입니다.
   - $U(\text{W}_t,\theta,S_j^k) = (\text{W}_{t+k},\theta)$는 $k$단계의 확률적 경사 하강법(SGD)을 통해 PLN의 가중치 $W$를 업데이트하는 함수를 나타냅니다. 이 내부 루프에서 RLN의 $\theta$는 고정됩니다.
   - OML은 온라인 지속 학습의 효과(예: 치명적인 망각)를 고려하기 위해 $S_k$의 각 데이터 포인트에 대해 한 번의 내부 업데이트를 수행합니다 (MAML-Rep가 전체 배치를 사용하는 것과 대조적).
3. **최적화**:
   - OML 목적 함수는 경사 기반 메타 학습 방식으로 최적화됩니다. 즉, 온라인 업데이트 단계를 통해 계산된 경사도를 활용하여 $\theta$와 $W$를 업데이트합니다. 긴 궤적에 대해서는 시간 역전파(backpropagation through time)의 절단(truncated) 기법을 사용하여 계산 비용을 관리합니다.

## 📊 Results

- **증분 사인파(Incremental Sine Waves) 회귀**: OML은 새로운 함수를 학습할 때 평균 제곱 오차(MSE)의 증가가 거의 없었습니다. 반면, 사전 훈련(Pre-training) 및 SR-NN과 같은 기준선은 더 많은 함수를 학습할수록 간섭으로 인해 오류가 크게 증가했습니다. OML은 학습된 모든 함수에 걸쳐 견고한 성능을 보였습니다.
- **Split-Omniglot 분류**:
  - OML은 최소한의 망각으로 거의 완벽한 훈련 정확도를 달성했으며, 테스트 세트에서도 더 나은 일반화 성능을 보였습니다.
  - MAML-Rep와 OML은 IID(독립동일분포) 샘플링 환경에서 유사한 성능을 보였으나, 온라인 상관 데이터 스트림에서는 OML이 MAML-Rep를 크게 능가하여, OML이 학습한 표현이 증분 학습에 더 적합함을 입증했습니다.
  - OML은 Mini-Imagenet과 같은 더 복잡한 데이터셋에서도 효과적인 표현을 학습할 수 있음을 보여주었습니다.
- **표현의 특성(희소성)**: OML은 명시적으로 희소성을 장려하지 않았음에도 불구하고, 가장 높은 인스턴스 희소성(Omniglot에서 3.8%)을 보이는 동시에 데드 뉴런이 없는 표현을 자연스럽게 학습했습니다. 이는 다른 희소성 기반 방법(SR-NN)보다 우수했습니다.
- **기존 지속 학습 방법과의 결합**: OML은 EWC, MER, ER-Reservoir와 같은 기존 방법들과 결합했을 때, 모든 알고리즘의 성능을 크게 향상시켰습니다. 심지어 OML과 기본적인 온라인 업데이트 전략만으로도 OML을 사용하지 않은 기존의 모든 지속 학습 방법보다 우수한 성능을 보였습니다.

## 🧠 Insights & Discussion

- **간섭 감소 및 학습 가속화**: OML은 온라인 업데이트의 영향을 직접 최적화하여 치명적인 간섭을 성공적으로 완화하고 미래 학습을 가속화하는 표현을 학습합니다.
- **자연스러운 희소성**: OML이 학습한 표현은 명시적인 희소성 목표 없이도 높은 인스턴스 희소성을 가지며, 이는 업데이트가 소수의 가중치에만 영향을 미쳐 간섭을 줄이는 데 기여합니다. 또한, 데드 뉴런이 없어 표현 공간을 효율적으로 활용합니다.
- **보완적 접근 방식**: OML은 기존의 지속 학습 방법론과 상호 보완적으로 작동하여, 이들을 단독으로 사용하는 것보다 훨씬 뛰어난 성능을 달성할 수 있음을 보여줍니다.
- **RLN의 중요성**: 단순한 모델 초기화 학습(MAML과 같이 모든 파라미터를 업데이트하는 방식)으로는 부족하며, 고정된 표현 학습 네트워크(RLN)를 통해 입력 데이터를 더 바람직한(예: 희소한) 표현으로 변환하는 것이 증분 학습에 매우 중요함을 시사합니다.
- **향후 연구**: 별도의 메타 훈련 단계 없이 온라인으로 표현을 학습하는 방법(예: 최근 데이터 버퍼를 통한 주기적 최적화)과 OML 목적 함수를 사용하여 학습 과정의 다른 측면(예: 지역 학습 규칙, 어텐션 메커니즘)을 메타 학습하는 것이 흥미로운 방향으로 제시됩니다.

## 📌 TL;DR

**문제**: 신경망은 지속 학습 환경에서 치명적인 망각과 느린 적응이라는 난관에 직면합니다. 이는 이러한 목적에 최적화되지 않은 표현을 사용하기 때문입니다.

**방법**: 본 논문은 OML (Online-aware Meta-Learning)이라는 메타 목적 함수를 제안하여, 온라인 업데이트를 통해 미래 학습을 가속화하고 망각에 강인한 표현 학습 네트워크(RLN)를 학습합니다. 이 RLN의 출력은 예측 학습 네트워크(PLN)가 효율적으로 적응하도록 돕습니다.

**결과**: OML은 데드 뉴런이 없는 높은 인스턴스 희소성을 가진 표현을 자연스럽게 학습하며, 이는 치명적인 망각에 대한 견고성과 새로운 데이터에 대한 빠른 학습 능력을 제공합니다. OML 기반의 온라인 학습 전략은 기존의 리허설 기반 방법들과 경쟁하거나 그 이상의 성능을 보였으며, 기존 지속 학습 방법론들과 결합 시 성능을 크게 향상시킵니다.
