# 생성 모델에서의 지속 학습에 대한 종합적 조사 (A Comprehensive Survey on Continual Learning in Generative Models)
Haiyang Guo, Fanhu Zeng, Fei Zhu, Jiayi Wang, Xukai Wang, Jingang Zhou, Hongbo Zhao, Wenzhuo Liu, Shijie Ma, Da-Han Wang, Xu-Yao Zhang,Senior Member, IEEE, Cheng-Lin Liu,Fellow, IEEE

## 해결해야 할 문제 (Problem to Solve)

최신 AI 시스템을 가능하게 한 거대 언어 모델(LLMs), 다중 모달 거대 언어 모델(MLLMs), 시각-언어-행동 모델(VLA), 확산 모델(Diffusion Models)과 같은 **생성 모델**은 새로운 작업을 학습할 때 이전 작업에 대한 성능이 급격히 저하되는 **치명적인 망각(catastrophic forgetting)**이라는 근본적인 문제에 직면해 있습니다. 실제 세계의 언어, 데이터 분포, 사용자 요구가 끊임없이 변화하기 때문에, 미리 모든 미래 시나리오를 예측하여 모델을 학습시키는 것은 불가능합니다. 과거 데이터를 모두 저장하여 함께 학습하는 것은 막대한 저장 비용과 데이터 프라이버시 문제로 인해 비현실적입니다.

특히, 판별 모델이 주로 조건부 확률 $P(y|x)$을 모델링하고 분류 공간 내의 결정 경계 변화에 집중하는 반면, 생성 모델은 결합 확률 분포 $P(x,y)$를 학습하거나 자기회귀적 생성을 수행해야 합니다. 이는 지속 학습을 통해 **개방형 생성 공간 내에서 의미론적 일관성과 지식의 완전성을 유지**해야 하므로, 새로운 모달리티 입력이나 도메인 지식 등 더 다양하고 복잡한 작업 유형에 적응해야 합니다. 따라서 생성 모델의 실용적인 적용을 위해 치명적인 망각을 극복하고 인간처럼 지속적으로 지식을 습득하면서 이전 능력을 보존하는 것이 중요합니다.

## 주요 기여 (Key Contributions)

*   **생성 모델의 지속 학습에 대한 최초의 종합적 조사**: 거대 언어 모델, 다중 모달 거대 언어 모델, 시각-언어-행동 모델, 확산 모델을 포함한 주류 생성 모델에서의 지속 학습 방법을 체계적으로 검토합니다.
*   **체계적인 방법론 분류**: 인간 두뇌의 기억 메커니즘에서 영감을 받아 지속 학습 접근 방식을 **아키텍처 기반(architecture-based)**, **정규화 기반(regularization-based)**, **재생 기반(replay-based)**의 세 가지 패러다임으로 분류하고, 각 방법의 기본 방법론과 동기를 설명합니다.
*   **모델별 지속 학습 설정 분석**: 각 생성 모델 유형에 대한 훈련 목표, 벤치마크, 핵심 백본을 분석하여 분야에 대한 심층적인 통찰력을 제공합니다.
*   **통합적 관점 제시**: 생성 모델들의 공통적인 방법론적 차원을 식별하여 통합적인 관점을 제시합니다.
*   **향후 연구 방향 제시**: 생성 모델 기반 지속 학습 방법의 미래 연구 방향과 새로운 트렌드를 제시합니다.
*   **공개 GitHub 저장소 제공**: 관련 연구의 최신 진행 상황을 추적하기 위한 GitHub 저장소를 소개합니다.

## 방법론 (Methodology)

본 논문은 생성 모델의 지속 학습에 대한 **종합적인 서베이(survey)** 논문으로, 기존 연구들을 체계적으로 분류하고 분석하는 방법론을 따릅니다.

1.  **지속 학습 문제 공식화**:
    *   총 $T$개의 지속 학습 태스크가 순차적으로 주어지며, 태스크 $t$를 학습할 때 $D_t$ 데이터만 접근 가능합니다.
    *   훈련 목표는 $arg \min_{\theta} E_{(x,y) \sim D_t}[\ell(f_{\theta}(x),y))]$이며, LLM의 경우 자기회귀적인 다음 토큰 예측 $p(y|x) = \prod_{i=1}^L p_{\theta}(y_i|x,y_{<i})$을 최소화하는 토큰 단위 교차 엔트로피 손실 $\ell(\cdot, \cdot)$을 사용합니다.
    *   이전 태스크에 대한 손실 증가를 허용하는 슬랙 변수 $\varepsilon_i$를 포함한 제약 조건 하에 현재 태스크를 학습합니다:
        $$ \min_{\theta} \mathcal{L}(\theta) = E_{(x,y)\sim D_t}[\ell(f_{\theta_t}(x),y)] + \sum_{i=1}^{t-1} \varepsilon_i $$
        $$ s.t. E_{(x,y)\sim D_i}[\ell(f_{\theta_t}(x),y)-\ell(f_{\theta_{t-1}}(x),y)] \le \varepsilon_i, \varepsilon_i \ge 0; \forall i \in [1, \cdots, t-1] $$
2.  **평가 지표 정의**: 모델의 지속 학습 능력을 평가하기 위해 **전반적인 성능(Last Accuracy, Average Accuracy)**, **망각 정도(Forgetting Measure, Backward Transfer)**, **일반화 능력(Zero-shot Transfer)** 등 표준화된 지표를 사용합니다.
3.  **지속 학습 방법 분류 (인간 두뇌 메커니즘에서 영감)**:
    *   **아키텍처 기반 (Architecture-based)**:
        *   두뇌의 모듈형 구성을 모방합니다.
        *   동적 네트워크 확장 또는 모듈형 설계를 통해 태스크별 지식을 분리합니다.
        *   `Parameter-Efficient Fine-Tuning (PEFT)` (예: `LoRA`, `Prompt tuning`)를 활용하여 기존 파라미터 $\theta_{old}$를 고정하고 현재 태스크의 파라미터 $\theta_{new}$만 학습합니다. $arg \min_{\theta_{new}} E_{(x,y)\sim D_t}[\ell(f_{\theta_{old} \cup \theta_{new}}(x),y))]$.
        *   추론 시 적절한 서브 모듈 선택이 주요 과제입니다.
    *   **정규화 기반 (Regularization-based)**:
        *   신피질의 시냅스 안정성을 모방합니다.
        *   이전 태스크의 중요 파라미터나 특징 표현을 보존하기 위해 학습 시 제약을 가합니다.
        *   **파라미터 공간 정규화**: $\lambda \cdot \Omega(\theta, \theta_{old})$ 항을 추가하여 현재 파라미터 $\theta$와 이전 태스크 파라미터 $\theta_{old}$ 간의 제약을 강화합니다.
        *   **특징 공간 정규화**: $\lambda \cdot R(\phi, \phi_{old})$ 항을 추가하여 모델 출력 특징 또는 로짓 $\phi$를 통해 이전 지식을 보존합니다 (예: `지식 증류(Knowledge Distillation)`).
        *   새로운 지식 습득에 최소한의 영향을 주면서 이전 지식을 효과적으로 보존하는 정규화 항 설계가 핵심입니다.
    *   **재생 기반 (Replay-based)**:
        *   해마의 기억 재생 메커니즘을 모방합니다.
        *   이전 태스크의 원본 데이터 또는 합성 샘플(가상 샘플)을 보조 메모리 버퍼 $M$에 저장하고, 새로운 태스크 학습 시 이들을 재사용하여 함께 학습합니다: $arg \min_{\theta} E_{(x,y)\sim (D_t \cup M)}[\ell(f_{\theta}(x),y))]$.
        *   메모리 버퍼의 제한된 용량 내에서 대표적인 샘플을 선택하는 것과 데이터 프라이버시, 저장 오버헤드 문제 해결이 중요합니다.
4.  **모델별 적용 및 분석**: 위 분류 체계를 기반으로 각 주류 생성 모델(LLMs, MLLMs, VLAs, Diffusion Models)에 대한 세부적인 지속 학습 전략, 공통 벤치마크, 모델 백본, 기존 방법의 동기 및 구현을 심층적으로 논의합니다.

## 결과 (Results)

본 서베이는 각 생성 모델 유형에 대한 지속 학습 연구의 현황과 주요 경향을 종합적으로 분석합니다:

*   **거대 언어 모델 (LLMs)**:
    *   `아키텍처 확장(architectural expansion)` 및 `재생(replay)` 방법이 주류를 이룹니다. LLM의 태스크 다양성과 의미적 복잡성으로 인해 `플러그인 LoRA 어댑터(plug-in LoRA adapters)`와 같은 모듈형 경량 구성 요소를 도입하여 태스크 특화를 강화하고, LLM의 강력한 일반화 능력 덕분에 소량의 이전 샘플이나 특징으로도 망각을 효과적으로 완화하는 `재생 기반` 방법이 효과적입니다.
    *   `정규화`는 기존 네트워크에서는 효과적이었으나 LLM에서는 튜닝 및 안정성 문제로 채택이 제한적입니다. 하지만 `아키텍처 확장` 또는 `재생` 전략과 통합될 때 잠재력이 큽니다.
*   **다중 모달 거대 언어 모델 (MLLMs)**:
    *   `아키텍처 확장`, 특히 `전문가 혼합(mixture-of-experts)` 모델을 활용한 접근 방식이 계속해서 지배적입니다.
    *   그러나 기존 방법들이 일반적인 태스크에 초점을 맞추고 있어, **모달리티별 망각(modality-specific forgetting)**과 **모달리티 간 상호작용(inter-modal interactions)**이 지속 학습에 미치는 영향에 대한 탐구는 아직 부족합니다.
*   **시각-언어-행동 모델 (VLAs)**:
    *   `아키텍처 확장`, `재생 메커니즘`, `정규화 제약`을 통합하는 **하이브리드 전략**이 점차 채택되고 있습니다. 이러한 접근 방식은 적응성, 교차 태스크 일관성, 간섭 완화 사이의 균형을 맞추는 데 중요합니다.
    *   하지만 이러한 전략들을 동적으로 조율하고, 시각-언어 정렬 모듈보다 `행동 정책(action policy)` 구성 요소가 더 빠르게 망각하는 경향을 해결하는 것이 주요 과제로 남아 있습니다.
*   **확산 모델 (Diffusion Models)**:
    *   특히 **지속적인 개인화 생성(continual personalized generation)** 설정에서, 태스크당 제한된 훈련 데이터와 태스크 간 비교적 낮은 분산으로 인해 `정규화 기반` 접근 방식이 주로 사용됩니다.
    *   이 분야의 주요 한계점은 표준화된 평가 벤치마크와 견고한 정량적 측정 지표의 부재입니다. 확산 모델 내에서 더 광범위한 지속 학습 시나리오를 탐색하는 것이 유망한 연구 방향입니다.

**향후 연구 방향(Future Directions)**은 다음과 같습니다:

*   **효율적인 지속 학습 메커니즘**: 대규모 생성 모델의 저장 및 계산 오버헤드를 줄이기 위한 모델 압축, 가지치기, 양자화, 그리고 재생 데이터 압축 및 증류 기술.
*   **지속 학습을 위한 학습 패러다임**: SFT(Supervised Fine-tuning)의 패턴 암기 경향을 넘어, 구조적 이해와 일반화 능력이 뛰어난 RL(Reinforcement Learning) 기반 패러다임으로의 전환.
*   **지속 학습을 위한 자체 생성**: 생성 모델의 내재적 데이터 재구성 및 재생 능력을 활용하여 별도의 생성 모듈 없이 과거 태스크 분포를 자율적으로 재생하는 방법.
*   **대규모 모델에서의 지속 학습**: 모델 규모 증가에 따른 지속 학습 행동 차이를 연구하고, 정보 누출 위험을 완화하는 전문화된 벤치마크를 구축하며, `CoT`, `ICL`, `Agents`, `RAG`와 같은 파라미터 효율적인 지식 통합 전략을 탐색.
*   **시각 및 언어 외 다중 모달 생성 지속 학습**: 오디오, 3D 장면, 모션 데이터와 같은 더욱 풍부한 모달리티를 통합하고, 모달리티별 망각 문제를 해결하는 방법.
*   **생성 모델 지속 학습을 위한 통합 최적화 프레임워크**: 다양한 생성 모델 계열 전반에 걸쳐 일반화될 수 있는 지속 학습 전략을 설계하여 복잡하고 동적인 실제 시나리오에 생성 AI를 배포하는 데 기여.