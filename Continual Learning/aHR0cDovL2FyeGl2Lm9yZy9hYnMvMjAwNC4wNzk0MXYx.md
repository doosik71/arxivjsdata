# Continual Learning for Anomaly Detection in Surveillance Videos

Keval Doshi, Yasin Yilmaz

## 🧩 Problem to Solve

감시 영상에서 이상 행동을 감지하는 것은 중요한 문제이지만, 실시간 처리, 지속적인 학습, 재앙적 망각(catastrophic forgetting) 문제 등으로 인해 많은 어려움이 있습니다. 기존의 딥러닝 기반 접근 방식은 정적 데이터셋에서는 우수한 성능을 보이지만, 새로운 데이터가 계속 유입되는 실제 감시 환경에서는 컴퓨팅 및 저장 공간 제약으로 인해 지속적인 학습 프레임워크에 적용하기 어렵습니다. 또한, 정상 패턴의 정의는 변화할 수 있으므로, 제한된 수의 새로운 샘플로부터 온라인으로 지속 학습할 수 있는 능력이 필수적입니다.

## ✨ Key Contributions

- **전이 학습(Transfer Learning) 활용:** 전이 학습을 사용하여 훈련 복잡성을 크게 줄이면서도 최신 알고리즘보다 우수한 성능을 달성했습니다.
- **통계적 지속 학습 프레임워크 제안:** 비디오에서 지속적이고 소수 학습(few-shot learning)이 가능한 순차적 이상 감지(sequential anomaly detection)를 위한 통계적 프레임워크를 제안했습니다.
- **광범위한 평가:** 공개적으로 사용 가능한 비디오 이상 감지 데이터셋과 실제 감시 카메라 피드에서 제안된 프레임워크를 광범위하게 평가했습니다.

## 📎 Related Works

- **이상 감지 기법:**
  - **준지도 학습(Semi-supervised AD):** 정상 비디오에서 정상 패턴을 학습하고, 이로부터 벗어나는 것을 이상으로 분류합니다. 주석이 달린 이상 사례가 부족하기 때문에 널리 사용됩니다.
  - **지도 학습(Supervised AD):** 정상 및 이상 비디오 모두로 학습하지만, 새로운/알 수 없는 유형의 이상에 취약합니다.
- **특징 추출:**
  - **초기 기술:** 주로 궤적 특징(trajectory features)에 중점을 두어 움직이는 객체 관련 이상 감지로 적용이 제한적이었습니다 (예: [1], [11], [31]).
  - **전통적 방법:** 움직임 및 외형 특징(motion and appearance features)을 사용했으며, HOG(Histogram of Optical Flow) [3], HOG(Histogram of Oriented Gradients) [9] 등 수동 제작 특징(hand-crafted features)을 사용했습니다.
  - **최근 기술:** 딥 뉴럴 네트워크(DNN) 기반 방법 (예: [13, 14, 23, 28, 33, 36, 44])이 뛰어난 성능으로 지배적이며, CNN, CLSTM, GAN 등을 사용하여 외형 및 움직임 특징을 학습합니다.
- **DNN의 한계:** 해석 가능성, 분석 가능성, 의사결정의 신뢰성 면에서 단점이 있으며 [17], 특히 지속 학습 및 소수 학습에 어려움을 겪습니다(재앙적 망각 [19]).
- **통계 및 kNN 기반 방법:** 성능 분석 용이성, 계산 효율성, 강건성 등의 매력적인 특성으로 인해 최근 인기를 얻고 있습니다 [4, 12].

## 🛠️ Methodology

본 논문은 뉴럴 네트워크 기반의 특징 추출 모듈과 통계적 감지 모듈을 결합한 하이브리드 프레임워크를 제안합니다.

1. **특징 선택 (Feature Selection):**

   - 각 프레임 $X_t$의 객체 $i$에 대해 다음 세 가지 유형의 특징을 결합하여 특징 벡터 $F_{i}^{t}$를 구성합니다:
     $$F_{i}^{t} = [w_1 F_{\text{motion}}, w_2 F_{\text{location}}, w_3 F_{\text{appearance}}]$$
     여기서 $w_1, w_2, w_3$는 각 특징 범주의 상대적 중요도를 조절하는 가중치입니다.

2. **전이 학습 (Transfer Learning):**

   - **객체 감지 (Object Detection):** 미리 훈련된 YOLOv3 [34]를 사용하여 객체의 위치(바운딩 박스의 중심 좌표 및 면적 $C_x, C_y, \text{Area}$)와 외형(클래스 확률 $p(C_1), \dots, p(C_n)$) 특징을 실시간으로 추출합니다. YOLOv3는 속도와 정확도 면에서 다른 모델보다 유리합니다.
   - **광학 흐름 (Optical Flow):** 미리 훈련된 Flownet 2 [15] 모델을 사용하여 프레임 내 객체들의 맥락적 움직임을 모니터링합니다. 광학 흐름의 평균, 분산, 왜도(skewness), 첨도(kurtosis)를 추출하여 움직임 특징을 나타냅니다.

3. **특징 벡터 (Feature Vector):**

   - 위에 언급된 움직임, 위치, 외형 특징을 결합하여 각 객체 $i$에 대한 종합적인 특징 벡터 $F_{i}^{t}$를 생성합니다. 특징 벡터의 차원 수는 $m = n+7$ (n은 가능한 클래스 수)입니다.

4. **이상 감지 (Anomaly Detection):**

   - **훈련 (Training):**
     1. 전체 정상 데이터셋 $F_M$을 $F_{M_1}$과 $F_{M_2}$ 두 부분으로 무작위 분할합니다.
     2. $F_{M_1}$의 각 점 $F_i$에 대해 $F_{M_2}$의 점들에 대한 $k$NN 거리 $d_i$를 계산합니다.
     3. 유의 수준 $\alpha$ (예: 0.05)에 따라 $k$NN 거리 $\{d_1, \dots, d_{M_1}\}$의 $(1-\alpha)$-번째 백분위수 $d_{\alpha}$를 이상 증거 계산의 기준선으로 사용합니다.
   - **테스트 (Testing):**
     1. 시간 $t$에 감지된 각 객체 $i$에 대해 특징 벡터 $F_{i}^{t}$를 구성하고, $F_{M_2}$의 훈련 인스턴스에 대한 $k$NN 거리 $d_{i}^{t}$를 계산합니다.
     2. 순간적인 프레임 수준 이상 증거 $\delta_t$를 다음과 같이 계산합니다:
        $$\delta_t = (\max_i \{d_{i}^{t}\})^m - d_{\alpha}^m$$
     3. CUSUM(Cumulative Sum)과 유사한 절차를 따라 실행 결정 통계량 $s_t$를 업데이트합니다:
        $$s_t = \max\{s_{t-1} + \delta_t, 0\}, s_0 = 0$$
     4. 결정 통계량 $s_t$가 임계값 $h$를 초과하면 해당 비디오 프레임을 이상으로 판단합니다. 이후 미세 조정을 통해 이상 프레임 구간을 명확히 하고, 다음 탐지를 위해 $s_t$를 재설정합니다.
   - **지속 학습 (Continual Learning):**
     1. 테스트 통계량 $s_t$가 0인 경우(정상으로 간주), 해당 특징 벡터 $F_{i}^{t}$는 두 번째 정상 훈련 세트 $F_{M_2}$에 포함됩니다.
     2. $s_t$가 임계값 $h$를 넘으면 경보가 발생합니다. 인간 전문가가 이를 오탐(false alarm)으로 분류하면, $\tau_{\text{start}}$와 $t$ 사이의 모든 벡터 $\{F_{i}^{\tau}\}$를 $F_{M_2}$에 추가하여 유사한 미래 오탐을 방지합니다. $k$NN 기반 결정 규칙 덕분에, 모델을 처음부터 재훈련할 필요 없이 새로운 데이터로 순차적인 업데이트가 가능합니다.

5. **계산 복잡도 (Computational Complexity):**
   - **순차 이상 감지:** 훈련 단계의 시간 복잡도는 $O(M_1 M_2 m)$이고, 테스트 단계는 $O(M_2 m)$입니다. 공간 복잡도는 $O(M_2 m)$입니다.
   - **딥러닝 모듈:** YOLO는 약 83.33 fps, Flownet 2는 약 40 fps를 처리하며, 전체 프레임워크는 약 32 fps로 실시간 처리가 가능합니다. 기존 딥러닝 기반 방법은 재앙적 망각을 피하기 위해 전체 데이터를 저장하고 재훈련해야 하므로 시간 및 공간 복잡도가 훨씬 큽니다.

## 📊 Results

- **벤치마크 결과 (AuC):** CUHK Avenue 및 UCSD Ped2 데이터셋에서 각각 86.4%와 97.8%의 AuC로 기존 최신 알고리즘을 능가했으며, ShanghaiTech 데이터셋에서는 71.62%로 경쟁력 있는 성능을 보였습니다. 이는 실시간 온라인 의사결정 방식(미래 프레임에 대한 사전 정보 없이)으로 달성된 결과입니다.
- **순차 이상 감지의 영향:** 제안된 순차 통계량은 시간 경과에 따른 증거를 통합하여 순간적인 이상 증거보다 오탐을 효과적으로 제어합니다.
- **광학 흐름의 영향:** UCSD 데이터셋에서 자전거를 타는 사람이 보행자 도로를 지나는 이상 상황에서 광학 흐름 통계량(특히 왜도 및 첨도)에 상당한 변화가 관찰되어, 움직임 기반 이상 감지에서 광학 흐름의 효과를 입증했습니다.
- **지속 학습 결과:** 수정된 UCSD 데이터셋(자전거 타기가 정상 행동으로 간주)에서 제안된 알고리즘은 최신 딥러닝 기반 알고리즘(Liu et al. [23], Ionescu et al. [16])보다 훨씬 빠르게 새로운 정상 패턴에 적응했습니다. 모델 업데이트에 10초 미만이 소요된 반면, 최신 알고리즘은 재앙적 망각을 방지하기 위해 전체 데이터셋 재훈련에 수 시간이 걸렸습니다. 이는 소수 학습(few-shot learning) 능력을 입증합니다.
- **실시간 감시 결과:** 8시간 23분 길이의 실제 CCTV 감시 피드에 대한 실험에서, 지속 학습을 통해 오탐율이 크게 감소했습니다. 단 10분 데이터로 초기 훈련하고 20%의 오탐 이벤트만으로 모델을 업데이트했음에도 불구하고, 오탐율이 지속적으로 낮아지는 것을 확인했습니다.

## 🧠 Insights & Discussion

- **실용적인 비디오 감지 시스템의 필요성:** 실세계 감시 환경에서 이상 감지 시스템은 지속적으로 학습하고 변화하는 정상 패턴에 적응할 수 있어야 합니다. 이 연구는 이러한 요구 사항을 충족하는 실용적인 프레임워크를 제시합니다.
- **하이브리드 접근 방식의 강점:** 딥 뉴럴 네트워크의 강력한 특징 추출 능력과 통계적 $k$NN 방법의 지속 학습 및 소수 학습 능력을 결합하여 기존 딥러닝 모델의 주요 한계(재앙적 망각, 높은 재훈련 비용)를 효과적으로 극복했습니다.
- **온라인 의사결정의 중요성:** 실제 감시 시나리오에서 즉각적인 대응을 위해 중요한 온라인 및 실시간 의사결정 능력을 강조하며, 제안된 방법이 이를 지원함을 보여줍니다.
- **오탐 감소의 중요성:** 지속 학습을 통해 새로운 정상 행동을 빠르게 학습하고 오탐율을 줄이는 능력은 실제 감시 시스템의 효율성을 크게 향상시킬 수 있습니다.
- **향후 연구 방향:** 동적 날씨 조건, 회전하는 보안 카메라, 복잡한 시간적 관계 등 더욱 도전적인 시나리오에 대한 프레임워크 발전이 필요합니다. 또한, 새로운 이상 유형 레이블 및 온라인 객체 및 행동 인식과 같은 다른 비디오 처리 작업으로 지속 학습 프레임워크를 확장할 계획입니다.

## 📌 TL;DR

감시 비디오의 이상 감지에서 실시간 및 지속 학습의 어려움을 해결하기 위해, 본 논문은 전이 학습 기반 특징 추출 모듈과 통계적 순차 이상 감지 모듈을 결합한 하이브리드 프레임워크를 제안합니다. YOLOv3 및 Flownet 2를 활용하여 외형, 위치, 움직임 특징을 추출한 후, $k$NN 기반 통계적 방법을 통해 실시간으로 이상을 감지하고, 새로운 정상 패턴을 몇 초 만에 효율적으로 학습하여 재앙적 망각 없이 모델을 업데이트합니다. 이 방법은 공개 벤치마크 데이터셋에서 최신 딥러닝 모델보다 뛰어난 성능을 보였으며, 특히 새로운 정상 패턴 학습 능력과 오탐률 감소 측면에서 강력한 지속 학습 및 소수 학습 능력을 입증했습니다.
