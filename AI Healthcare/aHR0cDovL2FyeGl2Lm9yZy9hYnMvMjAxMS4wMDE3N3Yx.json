{
  "title": "Evaluation of Inference Attack Models for Deep Learning on Medical Data",
  "authors": "Maoqiang Wu, Xinyue Zhang, Jiahao Ding, Hien Nguyen, Rong Yu, Miao Pan, Stephen T. Wong",
  "year": 2020,
  "url": "http://arxiv.org/abs/2011.00177v1",
  "abstract": "Deep learning has attracted broad interest in healthcare and medical\ncommunities. However, there has been little research into the privacy issues\ncreated by deep networks trained for medical applications. Recently developed\ninference attack algorithms indicate that images and text records can be\nreconstructed by malicious parties that have the ability to query deep\nnetworks. This gives rise to the concern that medical images and electronic\nhealth records containing sensitive patient information are vulnerable to these\nattacks. This paper aims to attract interest from researchers in the medical\ndeep learning community to this important problem. We evaluate two prominent\ninference attack models, namely, attribute inference attack and model inversion\nattack. We show that they can reconstruct real-world medical images and\nclinical reports with high fidelity. We then investigate how to protect\npatients' privacy using defense mechanisms, such as label perturbation and\nmodel perturbation. We provide a comparison of attack results between the\noriginal and the medical deep learning models with defenses. The experimental\nevaluations show that our proposed defense approaches can effectively reduce\nthe potential privacy leakage of medical deep learning from the inference\nattacks.",
  "citation": 39
}