{
  "title": "Interpretable Medical Imagery Diagnosis with Self-Attentive\n  Transformers: A Review of Explainable AI for Health Care",
  "authors": "Tin Lai",
  "year": 2023,
  "url": "http://arxiv.org/abs/2309.00252v1",
  "abstract": "Recent advancements in artificial intelligence (AI) have facilitated its\nwidespread adoption in primary medical services, addressing the demand-supply\nimbalance in healthcare. Vision Transformers (ViT) have emerged as\nstate-of-the-art computer vision models, benefiting from self-attention\nmodules. However, compared to traditional machine-learning approaches,\ndeep-learning models are complex and are often treated as a \"black box\" that\ncan cause uncertainty regarding how they operate. Explainable Artificial\nIntelligence (XAI) refers to methods that explain and interpret machine\nlearning models' inner workings and how they come to decisions, which is\nespecially important in the medical domain to guide the healthcare\ndecision-making process. This review summarises recent ViT advancements and\ninterpretative approaches to understanding the decision-making process of ViT,\nenabling transparency in medical diagnosis applications."
}