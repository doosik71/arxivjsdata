# BEHRT: TRANSFORMER FOR ELECTRONIC HEALTH RECORDS

Yikuan Li, Shishir Rao, Jose Roberto Ayala Solares, Abdelaali Hassaine, Dexter Canoy, Yajie Zhu, Kazem Rahimi, Gholamreza Salimi-Khorshidi

## 🧩 Problem to Solve

전자 건강 기록(EHR)은 환자의 의료 여정에 대한 방대한 정보를 담고 있어 질병의 조기 발견 및 개인화된 의료 제공에 막대한 잠재력을 가지고 있습니다. 그러나 EHR 데이터는 **복잡하고 비선형적인 이벤트 상호작용, 장기적인 의존성, 다양한 형태와 크기의 이질적인 개념(진단, 약물 등), 불규칙한 방문 간격**과 같은 고유한 문제들을 가지고 있습니다. 기존의 딥러닝 모델들은 이러한 EHR의 미묘한 특성을 완전히 포착하는 데 한계가 있어 미래 질병 발생을 정확하게 예측하고 질병 궤적을 해석하기 어려웠습니다. 이 연구는 이러한 문제를 해결하여 미래 진단을 정확하게 예측하고 질병 궤적을 매핑하며, 개인화된 질병 진행 상황에 대한 통찰력을 제공하는 강력한 모델을 개발하는 것을 목표로 합니다.

## ✨ Key Contributions

- **BEHRT 모델 제안:** EHR(Electronic Health Records)을 위한 새로운 딥 신경 시퀀스 변환 모델인 BEHRT(BERT for EHR)를 소개합니다. 이 모델은 여러 태스크 예측 및 질병 궤적 매핑이 가능합니다.
- **최첨단 성능 달성:** 약 160만 명의 환자 데이터를 사용한 301개 질병 예측 태스크에서 기존 SOTA(State-of-the-Art) 딥 EHR 모델(DeepR, RETAIN) 대비 평균 정밀도(Average Precision Score)에서 8.0-10.8%의 현저한 성능 향상을 입증했습니다.
- **개인화된 질병 궤적 및 해석 가능성:** BEHRT의 어텐션(attention) 메커니즘을 통해 질병 궤적에 대한 개인화된 시각을 제공하며, 진단 간의 비시간적/비방향적 관계 및 장기 의존성을 파악할 수 있게 하여 해석 가능한 예측에 기여합니다.
- **유연한 아키텍처:** 진단 외에 약물, 측정값 등 다양한 이질적인 개념을 쉽게 통합하여 예측 정확도를 향상시킬 수 있는 유연한 구조를 갖추고 있습니다.
- **EHR 특화 임베딩 설계:** BERT의 Transformer 아키텍처에 나이(age) 및 방문 분리(segment) 임베딩을 추가하여 EHR 데이터의 시간적 특성과 방문 패턴을 효과적으로 모델링합니다.
- **질병 임베딩의 시각적 유효성:** 사전 학습 과정에서 학습된 질병 임베딩이 의학적 지식(예: 질병 간의 관련성, 성별 특이 질환의 분리)과 일치하는 패턴을 시각적으로 보여주었습니다.

## 📎 Related Works

- **초기 딥러닝 모델:**
  - Liang et al. [10]: 딥 신경망이 수동 특징 엔지니어링보다 우수함을 입증.
  - Tran et al. [11]: 제한된 볼츠만 머신(RBM)을 사용하여 EHR의 분산 표현 학습.
  - Miotto et al. [12]: 스택형 디노이징 오토인코더(SDA)를 통해 질병 발병 예측에 유용한 특징 학습.
- **시퀀스 및 어텐션 기반 모델:**
  - Nguyen et al. (Deepr) [13]: CNN 모델인 Deepr를 도입, 방문 간 시간 차이를 특별한 토큰으로 인코딩하여 재입원 확률 예측.
  - Choi et al. [14]: 순환 신경망(RNN)을 사용하여 다음 방문의 진단 및 약물 예측.
  - Pham et al. (DeepCare) [15]: 어텐션 메커니즘이 있는 LSTM 아키텍처를 도입하여 장기 의존성 포착.
  - Choi et al. (RETAIN) [16]: 역방향 시간 어텐션 메커니즘 기반의 RNN 모델 RETAIN을 제안, 과거 방문의 영향력을 통합하여 심부전 예측.
- **Transformer 아키텍처:** NLP 분야에서 뛰어난 성능을 보인 Transformer [29] 및 BERT [18] 아키텍처에서 영감을 받아 BEHRT를 설계했습니다.

## 🛠️ Methodology

1. **데이터 수집 및 전처리:**
   - 영국 CPRD(Clinical Practice Research Datalink)와 HES(Hospital Episode Statistics) 데이터를 활용했습니다.
   - 초기 800만 명의 환자 중 HES 연동 가능하고 CPRD 품질 기준을 충족하며 최소 5회 방문 기록이 있는 160만 명의 환자 데이터를 최종 분석에 사용했습니다.
   - 진단 코드는 Med Code, ICD-10 코드를 University College London에서 제공하는 Caliber 코드(총 $G=301$개 질병)로 통합했습니다.
   - 각 환자의 EHR은 방문($v_{j}^{p}$) 시퀀스 $V_{p} = \{\text{CLS}, v_{1}^{p}, \text{SEP}, v_{2}^{p}, \text{SEP}, ..., v_{n_p}^{p}, \text{SEP}\}$로 구성되며, 방문 순서대로 시간적으로 정렬됩니다. [CLS]는 의료 기록 시작, [SEP]는 방문 사이 간격을 나타냅니다.
2. **BEHRT 아키텍처:**
   - **Transformer 기반:** NLP의 BERT [18]와 유사하게 Transformer 아키텍처 [29]를 사용하여 딥 양방향 컨텍스트 표현을 학습합니다.
   - **임베딩 레이어:** 네 가지 임베딩의 합으로 환자의 EHR을 표현합니다:
     - **질병(Disease) 임베딩:** 질병 코드를 고차원 벡터 공간에 매핑합니다.
     - **위치(Position) 임베딩:** 시퀀스 내 각 이벤트의 상대적 위치 정보를 제공합니다.
     - **나이(Age) 임베딩:** 각 진단이 발생한 나이를 인코딩하여 시간의 흐름을 모델에 제공합니다. (BEHRT 고유)
     - **세그먼트(Segment) 임베딩:** 방문 구분을 위한 학습 가능한 두 개의 벡터(A/B)를 사용합니다. (BEHRT 고유)
   - **피드포워드 구조:** RNN의 exploding/vanishing gradient 문제와 CNN의 제한된 수용 필드 문제를 회피하며, 전체 시퀀스를 병렬로 처리하여 효율적인 학습을 가능하게 합니다.
3. **사전 학습 (Pre-training) - Masked Language Model (MLM):**
   - BERT와 유사하게, 시퀀스의 15% 질병 단어를 무작위로 선택하여 다음 규칙에 따라 수정합니다:
     - 80%는 [MASK] 토큰으로 대체.
     - 10%는 무작위 질병 단어로 대체.
     - 10%는 변경하지 않고 유지.
   - 이 과정을 통해 모델은 질병의 양방향 컨텍스트를 학습하고, 노이즈를 통한 일반화 능력을 향상시킵니다.
4. **하위 태스크 (Downstream Tasks) - 질병 예측:**
   - 사전 학습된 BEHRT는 범용 EHR 특징 추출기로 사용되며, 출력은 단일 피드포워드 분류기 레이어에 연결됩니다.
   - 세 가지 예측 태스크를 수행했습니다:
     - **T1:** 다음 방문의 개념 예측.
     - **T2:** 다음 6개월 이내 질병 발생 예측.
     - **T3:** 다음 12개월 이내 질병 발생 예측.
   - 각 태스크는 다중 레이블 분류 문제로 간주됩니다.
5. **평가 지표:** AUROC(Area Under the Receiver Operating Characteristic curve) 및 APS(Average Precision Score)를 사용하여 모델 성능을 평가하며, 각 환자별 점수를 계산 후 평균을 냅니다.

## 📊 Results

- **MLM 사전 학습:** Bayesian Optimization을 통해 최적의 하이퍼파라미터(6개 레이어, 12개 어텐션 헤드, 은닉층 크기 288, 중간층 크기 512)를 찾아 0.6597의 정밀도 점수를 달성했습니다.
- **질병 임베딩 분석 (그림 4):**
  - t-SNE를 이용한 2차원 시각화 결과, 의학적으로 관련성이 높은 질병들이 가깝게 군집을 형성했습니다.
  - 모델에 명시적인 성별 정보가 제공되지 않았음에도 불구하고, 여성 특이 질환(예: 자궁내막증)과 남성 특이 질환(예: 전립선 악성 종양)이 명확하게 구분되는 패턴을 보였습니다. 이는 BEHRT가 진단이 발생하는 컨텍스트를 이해하고 성별과 같은 요소를 추론할 수 있음을 시사합니다.
  - 대부분의 질병 군집이 Caliber 질병 챕터(그림의 색상)와 일치하거나 의학적으로 연관성이 높은 챕터들(예: 안과 질환과 신경계 질환) 간의 근접성을 보여주었습니다.
- **자체 어텐션 메커니즘 분석 (그림 5):**
  - BEHRT의 양방향 자체 어텐션 메커니즘은 질병 간의 비시간적/비방향적 관계를 포착할 수 있습니다.
  - 예시 환자의 경우, 류마티스 관절염과 힘줄병 및 윤활막 장애(환자의 먼 미래에 발생) 사이에 강력한 장거리 의존성 연결을 보여주어 모델이 단순한 시간적 인접성을 넘어 복잡한 관계를 학습함을 확인했습니다.
- **하위 태스크 예측 성능 (표 1):**
  - BEHRT는 모든 예측 태스크(T1: 다음 방문, T2: 다음 6개월, T3: 다음 12개월)에서 기존 SOTA 모델인 DeepR 및 RETAIN보다 현저히 우수한 성능을 보였습니다.
  - **평균 정밀도(APS):**
    - T1 (다음 방문): BEHRT 0.462 (DeepR 0.360, RETAIN 0.382)
    - T2 (다음 6개월): BEHRT 0.525 (DeepR 0.393, RETAIN 0.417)
    - T3 (다음 12개월): BEHRT 0.506 (DeepR 0.393, RETAIN 0.413)
  - APS 기준으로 기존 모델 대비 8.0-10.8%의 절대적인 성능 개선을 달성했습니다. AUROC 또한 모든 태스크에서 BEHRT가 가장 높았습니다.
- **질병별 예측 정밀도 분석 (그림 6, 표 5):**
  - 간질(0.016), 전립선 원발성 악성 종양(0.011), 류마티스성 다발성 근통(0.013), 갑상선 기능 저하/항진증(0.047), 우울증(0.0768)과 같이 유병률이 1% 이상인 질병들에서 높은 예측 정밀도와 재현율을 보였습니다.

## 🧠 Insights & Discussion

- **BEHRT의 강력함:** BEHRT는 대규모 EHR 데이터에 사전 학습될 수 있는 강력하고 유연한 딥 신경 모델로, 다양한 하위 질병 예측 태스크에서 뛰어난 성능을 입증했습니다. 질병, 나이, 방문 간격, 시퀀스 내 위치 등의 임베딩 조합을 통해 환자의 복잡한 건강 상태 및 진료 패턴을 세부적으로 학습할 수 있습니다.
- **EHR에 대한 심층적인 이해:** BEHRT는 단지 진단 시퀀스뿐만 아니라 진단이 발생한 나이, 환자가 방문한 패턴 등 EHR 생성 과정에 대한 통찰력까지 학습합니다. 이는 "이 환자는 어릴 때 X와 Y 질병을 앓았고, 갑자기 방문 빈도가 증가하며 새로운 진단이 나타났는데, 이는 다음 질병이 Z일 확률이 높다"와 같은 복잡한 개념을 포착하는 특징을 자동 생성합니다.
- **해석 가능성 및 활용성:** 모델에서 도출된 질병 임베딩은 질병 간의 단순한 동시 발생을 넘어 환자 집단의 질병 궤적을 기반으로 한 복합적인 관계를 보여주어 의학 연구에 중요한 통찰력을 제공할 수 있습니다. 또한, BEHRT의 어텐션 메커니즘 시각화 도구는 다중 질환 환자의 질병 궤적을 이해하고, 특정 과거 질병이 미래 질병에 미치는 컨텍스트적 영향을 파악하는 데 유용하게 활용될 수 있습니다.
- **향후 연구 방향:**
  - 모델 성능 향상을 위해 BEHRT의 앙상블 및 다양한 변형 모델을 탐색할 수 있습니다.
  - 현재 4가지 임베딩 외에 약물 기록, 검사 결과, 중재 기록, 인구통계학적 정보(지역, 민족성) 등 더 많은 의료 특징을 유연하게 추가하여 모델의 포괄성을 높일 계획입니다.
  - Caliber 코드 외에 CPRD의 포괄성을 유지하고 데이터 노이즈를 줄일 수 있는 더 안정적인 코드 매핑 방식을 모색해야 합니다.
  - 심부전이나 고혈압과 같은 특정 질병에 대한 BEHRT의 진단력을 심층적으로 분석하여 특정 질병 예측에 대한 활용도를 높일 수 있습니다.

## 📌 TL;DR

이 논문은 EHR(전자 건강 기록) 데이터를 활용하여 미래 질병을 정확하게 예측하고 질병 궤적을 이해하기 위한 새로운 Transformer 기반 딥러닝 모델인 BEHRT를 제안합니다. BEHRT는 진단, 나이, 방문 세그먼트, 위치 임베딩을 통합하여 EHR의 복잡한 시간적 및 컨텍스트적 특성을 효과적으로 모델링합니다. Masked Language Model(MLM) 방식으로 사전 학습된 BEHRT는 약 160만 명의 환자 데이터에 대한 평가에서 기존 최첨단 모델들 대비 평균 정밀도(APS)에서 8.0-10.8%의 현저한 성능 향상을 달성했습니다. 또한, BEHRT의 어텐션 메커니즘은 질병 간의 비시간적, 장거리 의존성을 밝혀내어 개인화된 질병 궤적에 대한 해석 가능한 통찰력을 제공하며, 더 많은 EHR 개념을 통합하여 확장 가능한 유연한 아키텍처를 갖추고 있습니다.
