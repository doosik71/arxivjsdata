# From Explainable to Interpretable Deep Learning for Natural Language Processing in Healthcare: How Far from Reality?

Guangming Huang, Yingya Li, Shoaib Jameel, Yunfei Long, Giorgos Papanastasiou

## 🧩 Problem to Solve

헬스케어 분야에서 딥러닝(DL) 기반 자연어 처리(NLP) 모델의 성능이 크게 향상되었지만, 모델 복잡성 증가로 인해 의사 결정의 신뢰성을 확보하기 위한 투명한 모델 해석 가능성(interpretability) 또는 설명 가능성(explainability)이 필수적입니다. 이 논문은 헬스케어 NLP에서 설명 가능하고 해석 가능한 딥러닝(XIAI)의 현황을 종합적으로 검토하고, 현재의 역량과 실제 임상 구현 사이의 격차를 파악하는 것을 목표로 합니다.

## ✨ Key Contributions

- **XIAI 용어 정의 및 구분:** "eXplainable and Interpretable Artificial Intelligence" (XIAI)라는 용어를 도입하고, 본질적으로 해석 가능한 모델을 설계하는 IAI(Interpretable AI)와 사후(post hoc) 설명을 제공하는 XAI(Explainable AI)를 구분합니다.
- **XIAI 방법론 분류:** XIAI 모델을 기능(모델 기반, 입력 기반, 출력 기반) 및 범위(지역적, 전역적)에 따라 분류합니다.
- **주목 메커니즘의 부상:** 주목(attention) 메커니즘이 가장 널리 사용되는 IAI 기법으로 부상하고 있으며, IAI의 활용이 XAI를 능가하여 증가하고 있음을 밝힙니다.
- **주요 과제 식별:** 대부분의 XIAI가 전역적 모델링 프로세스를 탐색하지 못하고, 모범 사례 및 체계적인 평가/벤치마크가 부족하다는 점을 지적합니다.
- **주요 기회 제시:** 주목 메커니즘을 활용한 다중 모달 XIAI를 통해 맞춤형 의료를 강화하고, DL과 인과적 논리(causal logic) 결합이 유망하다는 점을 강조합니다.
- **미래 방향 제안:** 대규모 언어 모델(LLMs)과 도메인 특화 소규모 모델에 XIAI 통합을 장려하고, 임상 환경에서 XIAI의 성공적인 적용을 위해 도메인 전문가, 최종 사용자, 정책 입안자와의 협력이 필요함을 역설합니다.

## 📎 Related Works

이 논문은 헬스케어 NLP 분야에서 딥러닝의 성능 향상에 기여한 RNN, LSTM, CNN, 트랜스포머와 같은 다양한 DL 모델들의 발전을 언급합니다. 또한, 기존의 설명 가능하고 해석 가능한 DL 연구들([23, 24], [25, 26])의 중요성을 강조하고, Rudin의 통계적 정의([30])를 따라 XAI와 IAI를 명확히 구분합니다. LLM의 부상과 관련하여 데이터 및 모델 복잡성 증가에 따른 XIAI 방법론 평가의 중요성도 다룹니다.

## 🛠️ Methodology

이 연구는 헬스케어 분야의 설명 가능하고 해석 가능한 딥러닝 기반 NLP 기술에 대한 포괄적인 **스코핑 리뷰**를 수행했습니다.

1. **문헌 검색 및 선정:**
   - 기간: 2018년 1월 1일 ~ 2022년 12월 31일.
   - 데이터베이스: Scopus, Web of Science, PubMed, ACM (PRISMA 가이드라인 준수).
   - 키워드: ("natural language processing" OR "NLP") AND ("healthcare" OR "medic" OR "clinic" OR "EHR" OR "EMR").
   - 초기 검색 결과 4,147편 중 XIAI 관련성 및 중복 제거를 통해 146편 선정.
   - 제목 및 초록 검토, 전문 검토를 거쳐 최종적으로 42편의 논문 선정. (DL 미사용, XIAI 무관, 의학적 초점 부족, 리뷰 논문, 범위 외 논문 제외)
2. **검토 측면:** 선정된 논문들을 다음 측면에서 평가했습니다.
   - 게시일, 딥러닝 모델, IAI vs. XAI 구분, XIAI 방법론의 범위(지역적/전역적), XIAI 방법론 유형(모델 기반/입력 기반/출력 기반), 의료 작업, NLP 작업, 데이터 소스(공개/비공개), 소스 코드 가용성, XIAI 평가 여부.
3. **심층 분석:** XAI/IAI 방법론을 DL 모델, NLP 작업, 의료 작업과의 조합을 분석하여 도전 과제, 기회, 장점, 단점을 파악했습니다.

## 📊 Results

- **연구 동향:** 2021-2022년에 XIAI 연구 수가 급증했으며, 이는 트랜스포머 DL 모델의 지배 및 주목 메커니즘의 급속한 증가와 일치합니다.
- **IAI vs. XAI:** IAI 방법론(29건)이 XAI 방법론(15건)보다 더 많이 활용되었으며, 2020-2022년에 이러한 경향이 두드러졌습니다.
  - **XAI 주요 방법:** t-SNE (4건), LIME (3건), SHAP (3건).
  - **IAI 주요 방법:** 주목 메커니즘 (11건), 특징 중요도 (8건), 지식 기반/그래프 (5건).
- **XIAI 범위:** 대부분의 연구(37건)가 지역적(local) XIAI 방법을 사용했으며, 전역적(global) XIAI는 5건에 불과했습니다.
- **XIAI 방법론 패러다임:** 모델 기반(18건), 입력 기반(13건), 출력 기반(13건)으로 분류되었으며, 출력 기반에서는 주목 메커니즘이 가장 많이 사용되었습니다.
- **딥러닝 모델:** CNN/RNN/GRU/LSTM 기반 모델이 가장 빈번하게 사용되었으나, 2021-2022년에는 트랜스포머/BERT 기반 모델이 가장 지배적인 아키텍처였습니다.
- **NLP 및 의료 작업:** 텍스트 분류가 주요 NLP 작업이었으며, IAI는 XAI보다 더 다양한 NLP 및 의료 작업에 적용되었습니다.
- **평가 및 코드 가용성:** 42개 논문 중 3개만이 XIAI 방법론에 대한 전용 평가 프로세스와 지표를 포함했으며, 단 5개만이 소스 코드를 제공했습니다.
- **데이터셋:** 대부분의 논문(32건)이 비공개 데이터(주로 EHR)를 사용했으며, 공개 데이터셋을 분석한 논문은 10건(MIMIC이 가장 널리 사용됨)에 불과했습니다.

## 🧠 Insights & Discussion

- **주요 도전 과제:**
  - 대부분의 XIAI는 전역적(global) 모델링 프로세스가 아닌 지역적(local) 통찰력에 집중되어, 최종 사용자에게 필요한 "전체 모델 투명성" 제공에 한계가 있습니다.
  - XIAI 방법론에 대한 체계적인 평가 지표와 고품질 벤치마크의 부족으로 모범 사례 수립 및 재현성 평가가 어렵습니다.
  - 비공개 데이터 사용과 코드 미제공이 XIAI 기술의 민주화와 재현성을 저해합니다.
  - 주목 메커니즘은 "무엇을 보는가"를 보여주지만 "어떻게 해석하는가"를 설명하지 못하며, 주목 가중치와 모델 결과 간의 비선형적 관계는 해석에 모호성을 더합니다.
  - 현재의 XIAI 방법은 고도의 전문 기술을 요구하여 임상 및 산업 시스템에의 적용이 어렵습니다.
- **주요 기회:**
  - 주목 메커니즘은 다양한 DL 구조(CNN, RNN, BERT, 트랜스포머) 및 텍스트, 이미지, 유전체 등 다중 모달 데이터 통합에 유연하게 적용되어 맞춤형 의료 분야에서 XIAI 발전을 이끌 수 있습니다.
  - IAI와 XAI를 결합하여 결과를 상호 평가하는 접근 방식이 유용할 수 있습니다.
  - 인과성(causality)은 모델 해석 가능성, 공정성, 일반화 능력을 향상시키는 유망한 분야로, DL과 인과적 모델링의 결합은 헬스케어 NLP의 IAI를 크게 발전시킬 수 있습니다.
  - "DL 루프에 인간 참여"를 통해 도메인 전문가, 최종 사용자, 정책 입안자, 환자들이 XIAI 설계, 개발, 평가에 기여하여 실용적이고 강력한 XIAI 방법을 만들 수 있습니다.
- **미래 방향:** LLM의 "환각" 문제 해결을 위해 인과적 추론을 통합하는 "Go Large" 접근 방식과, 개인 정보 보호 및 효율성을 위해 도메인 특화 소규모 언어 모델을 사용하는 "Go Small" 접근 방식 모두에 XIAI 통합이 장려됩니다.

## 📌 TL;DR

헬스케어 NLP 분야에서 딥러닝 모델의 복잡성 증가로 인한 신뢰성 문제를 해결하기 위해, 본 스코핑 리뷰는 설명 가능하고 해석 가능한 AI(XIAI)의 현황을 분석했습니다. 연구 결과, 해석 가능한 AI(IAI)의 활용이 설명 가능한 AI(XAI)보다 증가하고 있으며, 특히 주목 메커니즘이 가장 지배적인 IAI 기법으로 부상하고 있음을 발견했습니다. 주요 과제로는 전역적 모델링 프로세스 부족, 평가 지표 및 벤치마크 미비, 비공개 데이터 사용이 지적되었으나, 주목 메커니즘을 통한 다중 모달 데이터 해석 및 인과적 모델링과의 결합이 맞춤형 의료를 위한 XIAI의 주요 기회로 제시되었습니다. 최종적으로, XIAI의 임상 적용을 위해서는 도메인 전문가 등 "인간을 DL 루프에 참여"시키는 것이 중요하며, LLM과 소규모 도메인 특화 모델 모두에 XIAI 통합이 필요합니다.
