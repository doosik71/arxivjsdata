{
  "url": "http://arxiv.org/abs/2307.15208v1",
  "title": "Generative AI for Medical Imaging: extending the MONAI Framework",
  "authors": "Walter H. L. Pinaya, Mark S. Graham, Eric Kerfoot, Petru-Daniel Tudosiu, Jessica Dafflon, Virginia Fernandez, Pedro Sanchez, Julia Wolleb, Pedro F. da Costa, Ashay Patel, Hyungjin Chung, Can Zhao, Wei Peng, Zelong Liu, Xueyan Mei, Oeslle Lucena, Jong Chul Ye, Sotirios A. Tsaftaris, Prerna Dogra, Andrew Feng, Marc Modat, Parashkev Nachev, Sebastien Ourselin, M. Jorge Cardoso",
  "year": 2023,
  "abstract": "Recent advances in generative AI have brought incredible breakthroughs in\nseveral areas, including medical imaging. These generative models have\ntremendous potential not only to help safely share medical data via synthetic\ndatasets but also to perform an array of diverse applications, such as anomaly\ndetection, image-to-image translation, denoising, and MRI reconstruction.\nHowever, due to the complexity of these models, their implementation and\nreproducibility can be difficult. This complexity can hinder progress, act as a\nuse barrier, and dissuade the comparison of new methods with existing works. In\nthis study, we present MONAI Generative Models, a freely available open-source\nplatform that allows researchers and developers to easily train, evaluate, and\ndeploy generative models and related applications. Our platform reproduces\nstate-of-art studies in a standardised way involving different architectures\n(such as diffusion models, autoregressive transformers, and GANs), and provides\npre-trained models for the community. We have implemented these models in a\ngeneralisable fashion, illustrating that their results can be extended to 2D or\n3D scenarios, including medical images with different modalities (like CT, MRI,\nand X-Ray data) and from different anatomical areas. Finally, we adopt a\nmodular and extensible approach, ensuring long-term maintainability and the\nextension of current applications for future features.",
  "citation": 141
}