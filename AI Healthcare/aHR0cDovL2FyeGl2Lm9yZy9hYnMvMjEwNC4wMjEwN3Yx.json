{
  "title": "Jekyll: Attacking Medical Image Diagnostics using Deep Generative Models",
  "authors": "Neal Mangaokar, Jiameng Pu, Parantapa Bhattacharya, Chandan K. Reddy, Bimal Viswanath",
  "year": 2021,
  "url": "http://arxiv.org/abs/2104.02107v1",
  "abstract": "Advances in deep neural networks (DNNs) have shown tremendous promise in the\nmedical domain. However, the deep learning tools that are helping the domain,\ncan also be used against it. Given the prevalence of fraud in the healthcare\ndomain, it is important to consider the adversarial use of DNNs in manipulating\nsensitive data that is crucial to patient healthcare. In this work, we present\nthe design and implementation of a DNN-based image translation attack on\nbiomedical imagery. More specifically, we propose Jekyll, a neural style\ntransfer framework that takes as input a biomedical image of a patient and\ntranslates it to a new image that indicates an attacker-chosen disease\ncondition. The potential for fraudulent claims based on such generated 'fake'\nmedical images is significant, and we demonstrate successful attacks on both\nX-rays and retinal fundus image modalities. We show that these attacks manage\nto mislead both medical professionals and algorithmic detection schemes.\nLastly, we also investigate defensive measures based on machine learning to\ndetect images generated by Jekyll.",
  "citation": 55
}