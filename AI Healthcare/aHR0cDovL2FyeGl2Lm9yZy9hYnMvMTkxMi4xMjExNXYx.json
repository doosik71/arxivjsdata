{
  "title": "Split Learning for collaborative deep learning in healthcare",
  "authors": "Maarten G. Poirot, Praneeth Vepakomma, Ken Chang, Jayashree Kalpathy-Cramer, Rajiv Gupta, Ramesh Raskar",
  "year": 2019,
  "url": "http://arxiv.org/abs/1912.12115v1",
  "abstract": "Shortage of labeled data has been holding the surge of deep learning in\nhealthcare back, as sample sizes are often small, patient information cannot be\nshared openly, and multi-center collaborative studies are a burden to set up.\nDistributed machine learning methods promise to mitigate these problems. We\nargue for a split learning based approach and apply this distributed learning\nmethod for the first time in the medical field to compare performance against\n(1) centrally hosted and (2) non collaborative configurations for a range of\nparticipants. Two medical deep learning tasks are used to compare split\nlearning to conventional single and multi center approaches: a binary\nclassification problem of a data set of 9000 fundus photos, and multi-label\nclassification problem of a data set of 156,535 chest X-rays. The several\ndistributed learning setups are compared for a range of 1-50 distributed\nparticipants. Performance of the split learning configuration remained constant\nfor any number of clients compared to a single center study, showing a marked\ndifference compared to the non collaborative configuration after 2 clients (p <\n0.001) for both sets. Our results affirm the benefits of collaborative training\nof deep neural networks in health care. Our work proves the significant benefit\nof distributed learning in healthcare, and paves the way for future real-world\nimplementations.",
  "citation": 212
}