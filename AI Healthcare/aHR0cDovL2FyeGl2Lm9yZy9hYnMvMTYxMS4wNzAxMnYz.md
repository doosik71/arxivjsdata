# GRAM: Graph-based Attention Model for Healthcare Representation Learning

Edward Choi, Mohammad Taha Bahadori, Le Song, Walter F. Stewart, Jimeng Sun

## 🧩 Problem to Solve

의료 분야의 예측 모델링에서 딥러닝 방법론은 유망한 성능을 보이지만, 두 가지 중요한 난제를 가지고 있습니다.

- **데이터 부족**: 딥러닝 모델이 만족스러운 결과를 얻기에는 헬스케어 예측 모델링에서 샘플 크기가 불충분한 경우가 많습니다. 특히 희귀 질환 예측에 있어서는 더욱 그렇습니다.
- **해석 가능성**: 딥러닝 모델이 학습한 표현(representation)은 의학적 지식과 일치하여 해석 가능해야 합니다.

## ✨ Key Contributions

- 의료 온톨로지의 계층적 정보를 EHR(전자 건강 기록) 데이터에 보강하는 **GRAM (GRaph-based Attention Model)**을 제안합니다.
- 데이터 볼륨과 온톨로지 구조를 기반으로, 어텐션 메커니즘을 통해 의료 개념을 해당 개념의 조상들과 조합하여 표현합니다.
- 기존 RNN에 비해 훈련 데이터에서 거의 관찰되지 않는 질병 예측에서 **최대 10% 더 높은 정확도**를 달성했습니다.
- 심부전 예측 작업에서 **10배 적은 훈련 데이터를 사용하여 ROC 곡선 아래 면적(AUC)에서 3% 향상된 성능**을 보였습니다.
- GRAM이 학습한 의료 개념 표현은 의료 온톨로지와 잘 부합하여 **높은 해석 가능성**을 제공합니다.
- 하위 수준 개념에서 데이터 부족에 직면했을 때, 상위 수준 개념으로 **적응적으로 일반화하는 직관적인 어텐션 행동**을 보여줍니다.

## 📎 Related Works

- **어텐션 메커니즘**: 신경망 학습의 일반적인 프레임워크(Bahdanau et al., 2014)로 음성 인식(Chorowski et al., 2014), 컴퓨터 비전(Ba et al., 2014), 헬스케어(Choi et al., 2016b) 등 다양한 분야에서 사용되었으나, 지식 온톨로지 기반의 어텐션 모델은 GRAM이 처음입니다.
- **그래프 표현 학습**: DeepWalk(Perozzi et al., 2014), node2vec(Grover and Leskovec, 2016), LINE(Tang et al., 2015) 등은 이웃 정보를 활용하여 그래프 정점의 표현을 학습하는 데 중점을 둡니다. 그래프 컨볼루션 방식(Yang et al., 2016; Kipf and Welling, 2016)도 정점 분류에 주로 사용됩니다. GRAM은 지식 DAG를 보조 정보로 사용하여 임상 예측 모델링 문제를 해결하는 데 집중합니다.
- **지식 그래프 모델링**: WordNet(Miller, 1995) 또는 Freebase(Bollacker et al., 2008)와 같은 지식 DAG를 모델링하려는 연구(Bordes et al., 2013; Socher et al., 2013; Wang et al., 2014; Lin et al., 2015; Xie et al., 2016; Li et al., 2016)들은 주로 엔티티 및 관계 임베딩을 통해 링크 예측, 트리플 분류 등의 작업을 수행합니다. GRAM은 데이터 부족 문제를 해결하고 의학적으로 해석 가능한 표현을 학습하기 위한 지식 사전으로 지식 DAG에 직관적인 어텐션 메커니즘을 설계하는 데 차이가 있습니다.
- **그래프 라플라시안 정규화**: 예측 모델에 보조 정보를 통합하는 고전적인 접근 방식이지만, 그래프의 적절한 거리 정의에 의존하며 이는 종종 어렵습니다.

## 🛠️ Methodology

GRAM은 의료 온톨로지(Knowledge DAG)의 부모-자식 관계를 활용하여 데이터 제약 조건에서 강력한 표현을 학습합니다.

1. **기본 표기법 정의**:
   - 전체 의료 코드 집합을 $C = \{c_1, \dots, c_{|C|}\}$로 정의합니다.
   - 각 환자의 임상 기록은 방문 시퀀스 $V_1, \dots, V_T$로 표현되며, 각 방문 $V_t$는 이진 벡터 $x_t \in \{0,1\}^{|C|}$로 나타냅니다.
   - 의료 온톨로지 $G$는 방향성 비순환 그래프(DAG)이며, $C$는 리프 노드, $C'$는 비(非)리프 노드(조상)입니다.
2. **Knowledge DAG 및 어텐션 메커니즘**:
   - 각 노드 $c_j$에는 기본 임베딩 벡터 $e_j \in \mathbb{R}^m$가 할당됩니다.
   - 리프 노드 $c_i$의 최종 표현 $g_i$는 자신 및 조상들의 기본 임베딩의 볼록 결합(convex combination)으로 계산됩니다:
     $$g_i = \sum_{j \in A(i)} \alpha_{ij} e_j$$
     여기서 $A(i)$는 코드 $c_i$와 그 조상들의 인덱스 집합입니다.
   - 어텐션 가중치 $\alpha_{ij}$는 다음 소프트맥스(Softmax) 함수를 통해 계산됩니다:
     $$\alpha_{ij} = \frac{\exp(f(e_i, e_j))}{\sum_{k \in A(i)} \exp(f(e_i, e_k))}$$
   - 호환성 함수 $f(e_i, e_j)$는 단일 은닉층을 가진 MLP(다층 퍼셉트론)를 사용하여 계산됩니다:
     $$f(e_i, e_j) = u_a^T \tanh(W_a [e_i; e_j] + b_a)$$
3. **예측 모델과의 End-to-End 학습**:
   - 모든 의료 코드의 최종 표현 $g_1, \dots, g_{|C|}$를 연결하여 임베딩 행렬 $G \in \mathbb{R}^{m \times |C|}$를 생성합니다.
   - 방문 $V_t$는 임베딩 행렬 $G$와 멀티-핫 벡터 $x_t$를 곱하여 방문 표현 $v_t = \tanh(G x_t)$로 변환됩니다.
   - $v_t$는 신경망(이 논문에서는 RNN, 구체적으로 GRU)에 입력되어 다음 방문 $V_{t+1}$의 질병 코드인 목표 레이블 $y_t$를 예측합니다:
     $$\hat{y}_t = \text{Softmax}(W h_t + b)$$
     $$h_1, \dots, h_t = \text{RNN}(v_1, \dots, v_t; \theta_r)$$
   - 모든 시간 단계에 대한 예측 손실은 이진 교차 엔트로피(binary cross entropy)를 사용하여 계산되며, 모든 파라미터(기본 임베딩, 어텐션 파라미터, RNN 파라미터 등)는 역전파를 통해 종단 간(end-to-end) 방식으로 학습됩니다.
4. **기본 임베딩 초기화**:
   - GloVe(Pennington et al., 2014)를 사용하여 의료 코드와 그 조상들의 기본 임베딩 $e_i$를 초기화합니다.
   - 각 방문 $V_t$를 방문 내 코드의 모든 조상들을 포함하도록 확장하여 증강된 방문 $V'_t$를 생성합니다.
   - $V'_t$ 내에서 코드 쌍의 동시 발생 빈도를 계산하여 동시 발생 행렬 $M$을 만듭니다. 상위 조상일수록 더 자주 나타나므로 더 일반적인 개념으로 간주됩니다.
   - GloVe 손실 함수를 최소화하여 임베딩을 학습합니다:
     $$J = \sum_{i,j=1}^{|D|} f(M_{ij})(e_i^T e_j + b_i + b_j - \log M_{ij})^2$$
   - 초기화된 기본 임베딩은 모델 훈련 중 역전파를 통해 추가로 세부 조정됩니다.

## 📊 Results

- **순차 진단 예측 (Sutter PAMF, MIMIC-III)**:
  - GRAM+ (GloVe 초기화 적용)는 데이터 부족이 심한 레이블(희귀 진단) 예측에서 다른 모델들을 능가했습니다. 특히 MIMIC-III 데이터셋에서는 기본 RNN보다 최대 10% 더 높은 Accuracy@20을 달성했습니다.
  - 기본 임베딩 초기화 기법(GRAM+ vs GRAM)은 순차 진단 예측에서 중요한 성능 향상을 가져왔습니다.
- **심부전 발병 예측 (Sutter HF 코호트)**:
  - GRAM과 GRAM+는 다른 기준선 모델들(RNN+ 제외)보다 AUC에서 3~4%, RNN+보다 최대 1.8% 높은 성능을 보였습니다.
  - 데이터 부족 상황(훈련 데이터 크기 조절)에서도 일관되게 우수한 예측 성능을 입증했습니다.
  - 이 작업에서는 GloVe 초기화의 이점이 순차 진단 예측만큼 크지 않았는데, 이는 두 예측 작업의 본질적 차이(동시 발생 정보의 중요도) 때문으로 분석됩니다.
- **확장성**: GRAM은 어텐션 가중치 및 최종 표현 $g_i$ 계산과 추가 MLP 모델 최적화로 인해 일반 RNN보다 **단일 에포크당 훈련 시간이 약 50% 더 소요**되며, 최소 검증 손실에 도달하기까지 **약 50% 더 많은 에포크**가 필요했습니다. 이러한 오버헤드는 관리 가능한 수준으로 평가됩니다.
- **해석 가능한 표현**: t-SNE 시각화 결과(Figure 3), GRAM+와 GRAM이 학습한 의료 개념 표현은 다른 기준선 모델들(RNN, GloVe, Skip-gram 등)에 비해 의료 온톨로지와 훨씬 더 일관되고 구조화된 모습을 보였습니다.

## 🧠 Insights & Discussion

- **의학적으로 의미 있는 표현**: GRAM은 의료 온톨로지를 효과적으로 활용하여 해석 가능한 표현을 학습하며, 이는 데이터 부족 문제를 해결하고 예측 정확도를 향상시키는 데 필수적입니다.
- **적응형 어텐션 동작**: GRAM의 어텐션 메커니즘은 데이터 가용성과 지식 DAG 구조에 따라 직관적으로 작동합니다.
  - 데이터에서 거의 관찰되지 않는 희귀 개념의 경우, 대부분의 정보를 상위 조상(더 일반적인 개념)에서 가져와 일반화합니다.
  - 자주 관찰되는 개념의 경우, 해당 리프 노드에 강한 어텐션을 부여하여 높은 확신도를 반영합니다.
  - 드물지만 많은 형제 노드를 가진 개념의 경우, 부모 노드에 어텐션을 주어 충분한 샘플을 집계하고 리프 노드에도 어텐션을 주어 구별 능력을 유지합니다.
- **초기화의 영향**: GloVe 초기화(GRAM+)는 방문 내 코드들의 동시 발생 정보에 크게 의존하는 순차 진단 예측과 같은 작업에서 더 큰 이점을 제공합니다. 반면 전체 시퀀스에 대한 이진 분류(예: 심부전 예측)에서는 그 이점이 상대적으로 적었습니다.

## 📌 TL;DR

**문제**: 의료 딥러닝은 데이터 부족(특히 희귀 질환)과 해석 가능성 부족이라는 문제에 직면합니다.
**방법**: GRAM은 의료 온톨로지(Knowledge DAG)를 활용한 그래프 기반 어텐션 모델로, 데이터 가용성을 고려하여 의료 개념의 조상들을 적응적으로 조합하여 해석 가능한 표현을 학습합니다. 이 모델은 예측 RNN과 함께 종단 간 학습되며, 초기 임베딩은 GloVe를 사용하여 수행됩니다.
**결과**: GRAM은 희귀 질환 예측에서 최대 10%의 정확도 향상과 함께 적은 훈련 데이터로도 우수한 성능을 보였고, 의학적으로 해석 가능한 개념 표현을 학습하며 직관적인 어텐션 동작을 입증했습니다.
