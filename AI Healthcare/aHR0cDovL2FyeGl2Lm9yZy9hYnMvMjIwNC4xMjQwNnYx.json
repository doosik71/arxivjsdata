{
  "title": "A survey on attention mechanisms for medical applications: are we moving\n  towards better algorithms?",
  "authors": "Tiago Gonçalves, Isabel Rio-Torto, Luís F. Teixeira, Jaime S. Cardoso",
  "year": 2022,
  "url": "http://arxiv.org/abs/2204.12406v1",
  "abstract": "The increasing popularity of attention mechanisms in deep learning algorithms\nfor computer vision and natural language processing made these models\nattractive to other research domains. In healthcare, there is a strong need for\ntools that may improve the routines of the clinicians and the patients.\nNaturally, the use of attention-based algorithms for medical applications\noccurred smoothly. However, being healthcare a domain that depends on\nhigh-stake decisions, the scientific community must ponder if these\nhigh-performing algorithms fit the needs of medical applications. With this\nmotto, this paper extensively reviews the use of attention mechanisms in\nmachine learning (including Transformers) for several medical applications.\nThis work distinguishes itself from its predecessors by proposing a critical\nanalysis of the claims and potentialities of attention mechanisms presented in\nthe literature through an experimental case study on medical image\nclassification with three different use cases. These experiments focus on the\nintegrating process of attention mechanisms into established deep learning\narchitectures, the analysis of their predictive power, and a visual assessment\nof their saliency maps generated by post-hoc explanation methods. This paper\nconcludes with a critical analysis of the claims and potentialities presented\nin the literature about attention mechanisms and proposes future research lines\nin medical applications that may benefit from these frameworks.",
  "citation": 73
}