{
  "url": "http://arxiv.org/abs/2503.04163v1",
  "title": "VLA Model-Expert Collaboration for Bi-directional Manipulation Learning",
  "authors": "Tian-Yu Xiang, Ao-Qun Jin, Xiao-Hu Zhou, Mei-Jiang Gui, Xiao-Liang Xie, Shi-Qi Liu, Shuang-Yi Wang, Sheng-Bin Duang, Si-Cheng Wang, Zheng Lei, Zeng-Guang Hou",
  "year": 2025,
  "abstract": "The emergence of vision-language-action (VLA) models has given rise to\nfoundation models for robot manipulation. Although these models have achieved\nsignificant improvements, their generalization in multi-task manipulation\nremains limited. This study proposes a VLA model-expert collaboration framework\nthat leverages a limited number of expert actions to enhance VLA model\nperformance. This approach reduces expert workload relative to manual operation\nwhile simultaneously improving the reliability and generalization of VLA\nmodels. Furthermore, manipulation data collected during collaboration can\nfurther refine the VLA model, while human participants concurrently enhance\ntheir skills. This bi-directional learning loop boosts the overall performance\nof the collaboration system. Experimental results across various VLA models\ndemonstrate the effectiveness of the proposed system in collaborative\nmanipulation and learning, as evidenced by improved success rates across tasks.\nAdditionally, validation using a brain-computer interface (BCI) indicates that\nthe collaboration system enhances the efficiency of low-speed action systems by\ninvolving VLA model during manipulation. These promising results pave the way\nfor advancing human-robot interaction in the era of foundation models for\nrobotics. (Project website: https://aoqunjin.github.io/Expert-VLA/)",
  "citation": 2
}