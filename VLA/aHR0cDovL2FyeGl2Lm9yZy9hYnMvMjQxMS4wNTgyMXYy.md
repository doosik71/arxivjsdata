# BENCHMARKINGVISION, LANGUAGE, & ACTIONMODELS ON ROBOTICLEARNINGTASKS

Pranav Guruprasad, Harshvardhan Sikka, Jaewoo Song, Yangyue Wang, Paul Pu Liang

## 🧩 Problem to Solve

로봇 시스템은 훈련 환경을 벗어나는 경우 일반화 능력이 현저히 제한되어, 낯선 작업 설명, 객체 구성의 공간적 변화, 다양한 조명 조건, 새로운 객체와의 상호작용 등 실제 비제약 환경에서 배포하는 데 큰 어려움을 겪는다. 비전-언어-행동(VLA) 모델이 시각 이해, 언어 이해, 행동 생성을 결합하여 범용 로봇 시스템 개발에 유망한 방향을 제시하지만, 다양한 로봇 작업에 걸쳐 이러한 모델들을 체계적으로 평가하는 프레임워크와 벤치마크가 부족하다. 특히 파운데이션 모델의 추상적 추론 능력과 로봇 제어의 물리적 정밀 행동 사이의 간극을 메우고, 대규모 실제 로봇 데이터를 기반으로 학습된 VLA 모델의 일반화 능력과 한계를 포괄적으로 평가하는 것이 시급하다.

## ✨ Key Contributions

- 초기 VLM, VLA 및 새로운 "제너럴리스트" 모델(GPT-4o, OpenVLA, JAT)에 대한 심층적인 성능 프로파일링 결과를 제공하여 이들의 능력과 한계에 대한 통찰력을 제시한다.
- 다양한 실제 로봇 데이터셋(Open-X-Embodiment 컬렉션의 20가지 데이터셋)에 대한 모델의 일반화 능력을 분석한다.
- 널리 사용되는 OpenX 데이터셋의 로봇 학습 작업을 위해 특별히 고안된 체계적인 평가 분할 및 메트릭(Mean Squared Error, Normalized AMSE, 완료율)을 제시한다.
- VLM을 다른 모달리티 클래스, 특히 행동 공간에 매핑하기 위한 범용 프레임워크를 개발한다.
- 벤치마크 데이터 다운로드, 관리 및 활용을 위한 오픈 소스 소프트웨어 인프라를 제공한다.
- 새로운 대규모 제너럴리스트 행동 모델 벤치마크인 MultiNet v0.1에 대한 첫 시도를 소개한다.

## 📎 Related Works

- **일반 멀티모달 벤치마크:** MultiBench [25]는 다양한 도메인을 포괄하지만 로봇 평가 범위가 제한적이며, MMMU [50]는 대학 수준의 멀티모달 이해에 중점을 두지만 로봇 제어 태스크는 다루지 않는다.
- **멀티모달 언어 모델 평가:** VQA [4], OK-VQA [31]와 같은 단일 태스크 벤치마크부터 LAMM [48], MMBench [51]와 같은 포괄적인 프레임워크 및 MathVista [28], GAIA [32]와 같은 전문 벤치마크들이 존재한다.
- **로봇 특화 벤치마크:** THE COLOSSEUM [35], FactorWorld [45], KitchenShift [46]는 일반화 능력 평가에 중점을 두며, RLBench [18], RAVENS [16], FurnitureBench [14]는 특정 시뮬레이션 또는 실제 조작 태스크를 다룬다. LIBERO [27]와 FMB [29]는 지식 전이 및 일반화 가능한 로봇 학습에 초점을 맞추었다.
- **본 연구의 차별점:** 본 연구는 시뮬레이션 환경이나 정적인 비전-언어 태스크가 아닌 **실제 로봇 궤적**에 대한 모델의 행동 생성 능력을 평가하고, OpenX 데이터셋을 활용하여 다양한 로봇 플랫폼 및 태스크에 걸쳐 평가한다. 특히, 다른 행동 공간과 로봇 형태에 대한 **제로샷 일반화 능력**을 측정한다.

## 🛠️ Methodology

- **데이터:**
  - 가장 큰 오픈소스 실제 로봇 궤적 저장소인 Open X-Embodiment Dataset (OpenX)을 활용한다. 이 데이터셋은 22가지 로봇 형태에서 수집된 100만 개 이상의 궤적을 포함하며, 이질적인 로봇 데이터 처리에 효율적인 RLDS(Reinforcement Learning Datasets) 포맷을 사용한다.
  - 벤치마크 v0.1을 위해 53개의 OpenX 데이터셋 중 20개를 선정하여 세 가지 모델 모두를 평가했으며, JAT 모델의 경우 53개 데이터셋 전체를 평가했다.
  - 데이터 품질 및 다양성을 보장하기 위해 체계적인 큐레이션 과정을 거쳤으며, 불필요한 중복을 최소화했다.
- **평가 모델:**
  - **JAT [12]:** Transformer 기반의 모델로, 순차적 의사 결정 및 다중 모달 데이터를 처리하도록 최적화되었다. 넓은 주의(attention) 창을 통해 장기 로봇 작업에 적합하다.
  - **GPT-4o [1]:** 옴니모달 모델로서 텍스트, 오디오, 이미지, 비디오 입력을 받아 다중 모달 출력을 생성한다. 새로운 객체 및 환경에 대한 일반화가 필요한 로봇 조작 작업에서 강력한 성능을 보여준다.
  - **OpenVLA [22]:** 97만 개의 OpenX 로봇 에피소드에서 훈련된 7B 파라미터 오픈소스 비전-언어-행동 모델이다. SigLIP 및 DinoV2 시각 인코더와 7B Llama 2 언어 모델 백본을 결합하여, 일반화된 로봇 조작 작업에서 뛰어난 성능을 보인다.
- **평가 지표:**
  - **평균 제곱 오차 (MSE):** 오프라인 로봇 궤적 평가의 주된 지표로 사용된다. 예측 행동과 실제 행동 간의 편차를 제곱하여 계산한다.
    $$ MSE = \frac{1}{n} \sum\_{i=1}^{n} (y_i - \hat{y}\_i)^2 $$
        여기서 $y_i$는 실제 행동, $\hat{y}_i$는 예측 행동, $n$은 관측치 수이다.
  - **평균 MSE (AMSE):** 데이터셋의 모든 타임스텝에 걸친 평균 MSE로, 모델 성능을 직접 비교하는 데 사용된다.
  - **정규화 AMSE (NAMSE):** min-max 정규화된 MSE의 평균으로, 모델 출력 및 데이터셋 행동 공간의 스케일 차이를 보정하여 모델 간 비교의 공정성을 높인다.
  - **완료율 (Completion Rate):** 데이터셋의 모든 에피소드에서 최종 예측 행동과 실제 최종 행동을 비교하여 태스크 완료 성공률을 근사적으로 측정한다.
- **실험 설정 (제로샷):**
  - **JAT:** 현재 타임스텝 정보만을 사용하여 예측하는 제로샷 설정으로 평가되었다. 4채널 이미지 입력, 모든 부동 소수점 관측치를 단일 텐서로 연결하는 전처리를 수행한다.
  - **GPT-4o:** 포괄적인 프롬프트를 구성하여 평가했다. 여기에는 부동 소수점 관측 상태, 기본 이미지 관측치, 자연어 지시, 각 행동 공간 차원에 대한 설명, 행동 공간 통계(최소, 최대, 평균) 및 환경/작업 설명이 포함된다.
  - **OpenVLA:** 그리퍼 명령 표준화(이진, 삼진 이산화, 연속 정규화: $y= 2 \cdot (x - orig_{low}) / (orig_{high} - orig_{low}) - 1$)에 중점을 두었다. 특정 데이터셋에 대한 스케일링 및 변환 프로토콜을 구현했으며, OpenVLA는 위치 기반 예측에 주력하므로 속도나 토크 기반 행동 공간과의 호환성 문제를 명시했다.
- **추론 인프라:** JAT 및 GPT 평가를 위해 GCP e2-standard-8 인스턴스(8 vCPU, 32 GB 메모리)를 사용했으며, GPT는 API 엔드포인트를 통해 추론이 이루어졌다. OpenVLA 추론은 NVIDIA L4 GPU(24 GB GDDR6 메모리)를 갖춘 GCP g2-standard-8 인스턴스에서 수행되었다.

## 📊 Results

- **전반적인 AMSE 성능 분석:**
  - JAT는 대부분의 데이터셋에서 일관적으로 높은 AMSE(성능이 좋지 않음)를 보였다.
  - OpenVLA와 GPT-4o는 더 유사한 성능 수준을 보였으며, 대부분의 데이터셋에서 AMSE가 0.5 미만이었다.
  - OpenVLA는 훈련 분포 내의 작업에서 가장 좋은 성능을 포함하여 대부분의 데이터셋에서 AMSE 0.1-0.5 범위의 일관된 성능을 보였다.
  - GPT-4o는 `berkeley_autolab_ur5` (AMSE: 0.074), `columbia_cairlab_pusht_real` (AMSE: 0.030), `imperialcollege_sawyer_wrist_cam` (AMSE: 0.073) 등 정밀 조작 작업에서 특히 뛰어난 성능을 보였다.
  - 모든 모델은 대규모 움직임이나 다단계 시퀀스를 요구하는 복잡한 조작 작업(예: 주방 조작 작업)과 상당한 시간적 추론이 필요한 작업에서 어려움을 겪었다.
- **정규화된 성능 분석 (NAMSE):**
  - **GPT-4o:** NAMSE가 일반적으로 0.2 미만을 유지하며 데이터셋 전반에 걸쳐 놀라울 정도로 일관된 정규화 성능을 보였다. 이는 행동 공간 통계, 차원별 설명, 환경 및 작업 설명과 같은 상세한 정보를 제공하는 정교한 프롬프트 엔지니어링 덕분으로 분석된다.
  - **OpenVLA:** NAMSE에서 가장 큰 변동성을 보였다. `columbia_cairlab_pusht_real`에서 가장 높은 정규화 오류(NAMSE: 0.82)를 보였지만, 사전 훈련된 작업(`toto`의 NAMSE: 0.003)에서는 탁월한 성능을 나타내며 강한 작업 특화를 시사했다.
  - **JAT:** NAMSE가 일반적으로 0.2에서 0.4 사이로 중간 정도의 변동성을 보였다. `stanford_mask_vit`에서 성능이 크게 저하되는 경향(NAMSE ~ 0.57)을 보였지만, 유사한 작업 유형에서는 비교적 일관된 성능을 유지했다.
- **완료율:** 대부분의 작업에서 모든 모델의 완료율이 매우 낮게 나타났다(예: `Jaco Play`에서 OpenVLA 29.358%, GPT-4o 0.917%). 이는 제로샷 설정에서 정밀한 태스크 완료를 달성하는 것이 매우 어렵다는 것을 보여준다.

## 🧠 Insights & Discussion

- **프롬프트 엔지니어링의 영향:** GPT-4o가 다양한 작업에서 일관된 정규화 성능을 보인 것은 구조화된 프롬프트의 중요성을 강조한다. 명시적인 행동 공간 정보와 환경적 맥락을 프롬프트를 통해 제공하는 것이 아키텍처 선택만큼 중요할 수 있으며, 이는 미래 VLA 모델 개발 시 구조화된 태스크 표현을 핵심 설계 원칙으로 통합해야 함을 시사한다.
- **특화 vs. 일반화의 상충 관계:** OpenVLA는 훈련 분포 내 작업에서 우수한 성능을 보이지만 다른 작업에서는 성능 변동이 크다(특화). 반면 GPT-4o는 광범위한 작업에서 더 일관된, 그러나 때로는 최적이 아닌 성능을 유지한다(일반화). 이러한 특화와 일반화 사이의 균형 문제는 범용 로봇 시스템 개발의 지속적인 과제로 남아있다.
- **태스크 복잡성 한계:** 모든 모델은 아키텍처에 관계없이 다단계 계획이나 정밀 제어가 필요한 복잡한 조작 작업에서 공통적으로 어려움을 겪는다. 이는 현재 VLA 접근 방식이 강력한 시간적 추론이나 계층적 계획과 같은 고급 로봇 작업을 위한 핵심 기능이 부족함을 의미한다.
- **행동 공간 민감성:** 모델 성능은 행동 공간 특성 및 로봇 형태에 매우 민감하게 반응한다. 다양한 제어 시나리오를 보다 견고하게 처리할 수 있는 방법론 개발이 필요하다.
- **향후 연구 방향 (MultiNet v0.1 맥락):** 제어 능력 통합 시 다른 도메인(순수 비전-언어 및 언어 작업)에서의 성능 저하 여부를 평가해야 한다. 또한 OpenX를 넘어선 완전히 새로운 분포 외(out-of-distribution) 데이터에 대한 평가를 통해 진정한 일반화 능력을 파악하고, 소수샷 학습(few-shot learning) 및 미세 조정 시나리오를 연구해야 한다. VLA 모델의 비로봇 도메인(예: 디지털 에이전트를 위한 소프트웨어 환경)으로의 전이 가능성 탐색과 더불어, 구성적 일반화, 긴 시퀀스 신뢰성, 교차 형태 전이, 기억 및 장기 계획, 다중 에이전트 상호작용 등의 새로운 연구 방향이 제안된다. 최종적으로는 시뮬레이션 환경을 통한 온라인 평가 기능 개발이 계획되어 있다.

## 📌 TL;DR

현재 로봇 시스템은 일반화 능력이 부족하며, 새로운 비전-언어-행동(VLA) 모델에 대한 체계적인 평가 프레임워크가 필요하다. 이 연구는 GPT-4o, OpenVLA, JAT 세 가지 최신 VLA 모델을 20가지 OpenX 실제 로봇 데이터셋에 대해 벤치마킹했다. 평가 지표로는 평균 제곱 오차(AMSE), 정규화 AMSE(NAMSE), 완료율을 사용했다. 주요 결과에 따르면 모델 성능은 작업과 로봇 플랫폼에 따라 크게 달라지며, GPT-4o는 정교한 프롬프트 엔지니어링을 통해 가장 일관된 성능을 보였다. 그러나 모든 모델은 복잡한 다단계 조작 작업과 다양한 행동 공간 처리에서 공통적인 한계를 드러냈다.
