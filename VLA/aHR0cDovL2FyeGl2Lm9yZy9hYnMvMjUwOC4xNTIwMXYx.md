# Survey of Vision-Language-Action Models for Embodied Manipulation

LI Hao-Ran, CHEN Yu-Hui, CUI Wen-Bo, LIU Wei-Heng, LIU Kai, ZHOU Ming-Cai, ZHANG Zheng-Tao, ZHAO Dong-Bin

## 🧩 Problem to Solve

로봇 공학 분야에서 환경과의 지속적인 상호작용을 통해 에이전트의 능력을 향상시키는 구현 지능(Embodied Intelligence) 시스템은 학계와 산업계 모두에서 큰 주목을 받고 있습니다. 특히 대규모 파운데이션 모델의 발전으로부터 영감을 받은 시각-언어-행동(Vision-Language-Action, VLA) 모델은 보편적인 로봇 제어 프레임워크로서 구현 지능 시스템에서 에이전트-환경 상호작용 능력을 크게 향상시키며, 응용 시나리오를 확장하고 있습니다.

이 논문은 VLA 모델이 빠르게 발전함에 따라, 연구자들이 이 복잡하고 진화하는 분야의 최신 동향과 도전 과제를 포괄적으로 이해할 수 있도록 체계적인 개요를 제공하는 것을 목표로 합니다. 구체적으로, VLA 아키텍처의 발전 궤적, 주요 구성 요소, 훈련 패러다임, 평가 방법 등을 심층적으로 분석하여 현황과 미래 방향을 제시하고자 합니다.

## ✨ Key Contributions

이 논문은 구현 조작(embodied manipulation)을 위한 VLA 모델에 대한 포괄적인 조사를 통해 다음과 같은 핵심 기여를 합니다.

- **발전 궤적 분석:** VLA 아키텍처의 초기부터 최신에 이르는 발전 궤적을 체계적으로 정리하고, 주요 변곡점들을 강조합니다.
- **다차원적 심층 분석:** VLA 모델의 구조, 훈련 데이터셋, 사전 훈련 방법, 사후 훈련 방법, 그리고 모델 평가라는 5가지 핵심 연구 차원에 걸쳐 현재 연구 동향을 상세히 분석합니다.
- **주요 과제 및 미래 방향 제시:** VLA 모델의 개발 및 실제 배포에서 직면하는 주요 도전 과제들을 종합적으로 정리하고, 유망한 미래 연구 방향을 제시합니다.

## 📎 Related Works

이 논문은 VLA 모델에 대한 포괄적인 설문조사로서, 다른 VLA 관련 설문조사 및 기초 연구들을 폭넓게 참고하고 있습니다. 주요 관련 연구들은 다음과 같습니다.

- **기존 VLA 설문조사:**
  - Ma et al. \[1] (2024), Sapkota et al. \[2] (2025), Zhong et al. \[3] (2025), Xiang et al. \[4] (2025), Din et al. \[5] (2025) 등 최근 발표된 VLA 모델 관련 설문조사들을 언급하며, 이 논문이 다루는 VLA 모델의 핵심 요소와 깊이를 차별점으로 강조합니다. 예를 들어, Ma et al. \[1]은 일반적인 VLA 개요를 제공하고, Sapkota et al. \[2]는 응용 및 과제에 초점을 맞추며, Zhong et al. \[3]은 행동 토큰화 관점에서 VLA를 분석합니다.
- **기초 파운데이션 모델:**
  - Transformer \[6]와 같은 대규모 언어 모델(LLM) 및 시각-언어 모델(VLM)의 기초가 되는 아키텍처들을 VLA 모델의 핵심 구성 요소로서 언급합니다.
- **대표적인 VLA 모델:**
  - RT-1 \[20], RT-2 \[9], VIMA \[23], GATO \[24] 등 VLA 분야의 발전에 중요한 영향을 미친 대표적인 모델들을 소개하며, 이 모델들이 각각 어떤 기여를 했는지 설명합니다.

이 논문은 이러한 기존 연구들을 바탕으로 VLA 모델의 기술적 세부 사항과 발전 단계를 더욱 체계적이고 심층적으로 분석하여, 분야의 전체적인 그림을 제시하고자 합니다.

## 🛠️ Methodology

이 논문은 구현 조작을 위한 VLA 모델에 대한 체계적인 문헌 검토 및 분석을 방법론으로 채택합니다. VLA 모델의 다양한 측면을 포괄적으로 다루기 위해 다음과 같은 구조화된 접근 방식을 사용합니다.

1. **발전 궤적 추적 (Section 2):**
   - 초기 언어 조건부 모방 학습(language-conditioned imitation learning)부터 CLIPort \[15]와 같은 픽셀 기반 방법, Transporter Networks \[17], 그리고 GATO \[24] 및 Transformer \[6] 기반의 통합 에이전트 모델에 이르기까지 VLA 모델의 역사적 발전을 연대기적으로 분석합니다.
   - 특히 2023년 이후 VLA 모델이 대규모 언어/시각-언어 모델(LLM/VLM)을 활용하며 범용 로봇 제어 프레임워크로 발전하는 과정을 조명합니다.
2. **VLA 모델 구조 분석 (Section 3):**
   - **관측 인코더 (Observation Encoder):** CNN, Vision Transformer (ViT) (예: DINOv2 \[73], SigLIP \[32], PaliGemma \[77]), 3D 입력(예: PointVLA \[78]), 다중 모달 입력(예: Tactile-VLA \[87], ForceVLA \[11]) 처리 방식을 분석합니다.
   - **특징 추론 백본 (Feature Reasoning Backbone):** Transformer 아키텍처(인코더-디코더, Diffusion Transformer \[31]), MoE(Mixture of Experts), 그리고 Mamba \[90]와 같은 최신 상태 공간 모델(SSM) 기반의 접근 방식을 검토합니다.
   - **행동 디코더 (Action Decoder):** 원-핫 인코딩(one-hot encoding)을 사용하는 이산 행동, k-평균(k-means) 클러스터링 기반의 행동 토큰화(예: VQ-BeT \[93]), 그리고 확산 모델(Diffusion Policy \[26]) 및 흐름 매칭(Flow Matching)을 사용하는 연속 행동 디코딩 방법을 다룹니다.
   - **계층적 시스템 (Hierarchical System):** 빠른 반응을 위한 System 1 (S1)과 고수준 추론 및 계획을 위한 System 2 (S2)를 결합하는 계층적 VLA 아키텍처(예: Hi Robot \[49], TriVLA \[51])를 분석합니다.
3. **훈련 데이터셋 분석 (Section 4):**
   - **웹 데이터:** 이미지-텍스트 쌍(예: COCO \[96], VQAv2 \[98]), 인간 비디오 데이터(예: Ego-4D \[103], Something-Something V2 \[101]) 등 대규모 웹 데이터셋의 중요성을 강조합니다.
   - **로봇 데이터:** 로봇 데모 데이터셋(예: Bridge Data \[113], OXE \[29], RoboMIND \[116]), 그리고 시뮬레이션 환경에서 생성된 합성 데이터(예: RoboCasa \[108], SynGrasp-1B \[109])를 분석합니다.
4. **사전 훈련 및 사후 훈련 방법 분석 (Section 5, 6):**
   - **사전 훈련:** 스크래치(from scratch) 훈련, LLM/VLM 지식 전이(예: RT-2 \[9], PaLM-E \[33]), 비디오 생성 기반 사전 훈련(예: GR-1 \[44]), 통합 정책 학습(예: UniPi \[42]) 등을 다룹니다.
   - **사후 훈련:** SFT(Supervised Fine-Tuning), DPO(Direct Preference Optimization), RL(Reinforcement Learning) 기반 미세 조정(예: PPO, GRPO), 인컨텍스트 학습(In-context Learning), 추론 능력 향상(Chain-of-Thought), 효율성 최적화(양자화, 가지치기) 등을 분석합니다.
5. **모델 평가 (Section 7):**
   - 성공률, 작업 완료 시간, 궤적 품질, 강건성 등의 평가 지표를 설명합니다.
   - CALVIN \[157], LIBERO \[160], SimplerEnv \[159] 등 다양한 시뮬레이션 및 실제 로봇 벤치마크 환경을 소개하고, 현재 VLA 모델의 성능과 한계를 평가합니다.

## 📊 Results

이 설문조사는 VLA 모델 분야의 광범위한 문헌 분석을 통해 다음과 같은 주요 "결과" 또는 "발견"을 종합합니다.

- **아키텍처 진화:** VLA 모델은 초기 단순한 시각-행동 매핑에서 Transformer 기반의 복잡한 구조로 발전했으며, 최근에는 MoE(Mixture of Experts) 및 Mamba와 같은 새로운 아키텍처 요소들이 통합되어 효율성과 성능을 향상시키고 있습니다.
- **LLM/VLM의 핵심 역할:** 대규모 언어 모델(LLM)과 시각-언어 모델(VLM)은 웹 스케일 지식을 로봇 제어에 전이하는 핵심 수단이 되었으며, RT-2 \[9]와 같은 모델들이 이를 성공적으로 입증했습니다. 이는 로봇의 범용성과 추론 능력을 크게 확장시킵니다.
- **데이터의 중요성 및 다양화:** 대규모 웹 데이터와 로봇 데모 데이터(OXE \[29], Bridge Data \[114])의 결합이 VLA 모델의 학습에 필수적이며, 합성 데이터 생성(RoboCasa \[108])과 인간 비디오 데이터(Ego-4D \[103])의 활용이 중요해지고 있습니다.
- **훈련 패러다임의 발전:** 스크래치 훈련, LLM/VLM 기반 전이 학습, 비디오 생성 기반 사전 훈련 등 다양한 사전 훈련 전략이 탐색되고 있습니다. 사후 훈련에서는 미세 조정(SFT, DPO), 강화 학습(RL), 인컨텍스트 학습, 그리고 추론 능력을 강화하는 Chain-of-Thought (CoT) 같은 방법들이 효과를 보이고 있습니다.
- **계층적 제어 시스템의 부상:** 반응성 제어(System 1)와 고수준 추론 및 계획(System 2)을 결합한 계층적 VLA 시스템이 복잡한 장기 작업을 처리하는 데 유망한 접근 방식으로 부상하고 있습니다.
- **평가 벤치마크의 표준화:** CALVIN \[157], LIBERO \[160] 등과 같은 표준화된 벤치마크는 VLA 모델의 성능 비교 및 발전 방향 제시를 위한 필수 도구로 자리매김했습니다. 하지만 여전히 시뮬레이션-실제 간의 격차(sim-to-real gap)와 실제 환경에서의 일반화 능력 평가가 중요한 과제로 남아 있습니다.
- **다중 모달 통합:** 시각 및 언어 외에 촉각, 힘, 청각 등 다양한 감각 정보의 통합이 로봇의 환경 이해와 섬세한 조작 능력을 향상시키는 데 중요함이 부각되고 있습니다.

이러한 발견들은 VLA 모델이 단순한 제어를 넘어 더욱 지능적이고 범용적인 로봇 시스템으로 발전하고 있음을 보여줍니다.

## 🧠 Insights & Discussion

이 설문조사는 VLA 모델의 발전과 함께 다음과 같은 심층적인 통찰과 주요 과제를 제시합니다.

### 통찰 (Insights)

- **파운데이션 모델의 강력한 힘:** LLM과 VLM은 VLA 모델에 웹 스케일의 방대한 지식과 추론 능력을 부여하여, 로봇이 이전에 불가능했던 개방형(open-ended) 지시를 이해하고 복잡한 작업을 수행할 수 있게 하는 핵심 동력이 되고 있습니다.
- **계층적 추론의 필요성:** 단순한 반응형 제어로는 복잡한 현실 세계의 문제를 해결하기 어렵기 때문에, 빠른 저수준 행동(System 1)과 느리고 깊은 추론 및 계획(System 2)을 결합하는 계층적 아키텍처가 VLA 모델의 효율성과 강건성을 높이는 데 필수적입니다.
- **데이터 스케일의 중요성:** 대규모 데이터셋(웹 데이터, 로봇 데모, 합성 데이터)은 VLA 모델의 일반화 능력 향상에 결정적인 역할을 하며, 데이터의 다양성과 품질이 모델 성능의 상한선을 결정합니다.
- **다중 모달리티의 잠재력:** 시각-언어 외에 촉각, 힘, 오디오 등 추가적인 감각 정보를 통합하는 것은 로봇이 환경을 더 풍부하게 이해하고 미묘한 조작을 수행하는 데 필수적인 다음 단계입니다.

### 도전 과제 및 한계 (Limitations & Challenges)

- **일반화 및 전이 학습:**
  - **도메인 격차(Domain Gap):** 시뮬레이션에서 학습한 정책을 실제 로봇에 성공적으로 전이하는 sim-to-real 문제는 여전히 해결해야 할 큰 과제입니다.
  - **과제 일반화(Task Generalization):** 새로운 환경이나 미지의 작업에 대한 VLA 모델의 일반화 능력은 아직 제한적입니다. 복잡한 다단계 작업이나 구성적(compositional)인 과제에 대한 강건한 일반화는 쉽지 않습니다.
- **데이터 효율성 및 확장성:**
  - **데이터 부족:** 실제 로봇 데모 데이터는 수집 비용이 매우 높고 양이 부족하며, 라벨링도 어렵습니다.
  - **데이터 품질:** 다양한 출처의 데이터를 통합할 때 발생하는 불일치와 편향은 모델 학습에 악영향을 미칠 수 있습니다.
- **모델 효율성:**
  - **계산 비용:** 대규모 VLA 모델은 학습 및 추론에 막대한 계산 자원을 요구하여 실제 로봇에 실시간 배포하는 데 어려움이 있습니다.
  - **실시간성:** 복잡한 추론 과정으로 인해 로봇의 반응 속도가 느려질 수 있으며, 이는 동적 환경에서의 조작에 한계를 초래합니다.
- **강건성 및 안전성:**
  - **불확실성 처리:** 예측할 수 없는 환경 변화나 오류에 대한 VLA 모델의 강건한 처리 능력은 아직 미흡합니다.
  - **안전성:** 로봇이 자율적으로 행동할 때 발생할 수 있는 잠재적 위험을 최소화하고 안전하게 제어하는 메커니즘이 중요합니다.
- **추론 및 인지 능력:**
  - **깊은 추론의 한계:** 현재 VLA 모델의 "추론"은 주로 패턴 매칭에 기반하며, 인간과 같은 깊은 인과적 추론, 상식 추론, 장기 계획 능력은 여전히 제한적입니다.

### 미래 연구 방향 (Future Research Directions)

- **스케일링 법칙과 새로운 아키텍처:** 모델 크기, 데이터 크기, 연산 자원 간의 스케일링 법칙을 더 깊이 이해하고, Mamba와 같은 새로운 효율적인 아키텍처와 MoE 구조를 탐색하여 VLA 모델의 성능과 효율성을 동시에 향상시키는 것이 중요합니다.
- **고품질 데이터 생성 및 활용:** 시뮬레이션에서의 합성 데이터 생성 기술을 고도화하고, 능동 학습(active learning) 및 인간-로봇 협업을 통해 실제 로봇 데이터의 효율적인 수집 및 활용 방법을 개발해야 합니다.
- **고급 훈련 패러다임:** 모방 학습, 강화 학습, 자기 지도 학습, 세계 모델(world model) 학습을 효과적으로 통합하여 더 일반화되고 효율적인 VLA 정책을 학습하는 방법을 연구해야 합니다.
- **다중 모달 인지 및 통합:** 시각, 언어뿐만 아니라 촉각, 힘, 청각 등 다양한 감각 정보를 더욱 긴밀하게 통합하고, 이러한 정보들을 기반으로 로봇이 환경을 종합적으로 이해하고 상호작용할 수 있도록 해야 합니다.
- **심층 인지 및 추론 능력 강화:** VLA 모델이 인간과 유사한 인과적 추론, 계획, 문제 해결 능력을 갖추도록 하기 위해 더 정교한 추론 체인(chain-of-thought) 및 인지 아키텍처를 개발해야 합니다.
- **강건한 평가 벤치마크:** 실제 세계의 복잡성, 장기적인 작업, 안전성 등을 고려한 새로운 벤치마크를 개발하고, 모델의 일반화 능력을 포괄적으로 측정할 수 있는 평가 방법론을 구축해야 합니다.

## 📌 TL;DR

VLA(Vision-Language-Action) 모델은 대규모 파운데이션 모델의 발전에 힘입어 구현 조작 로봇의 보편적 제어 프레임워크로 급부상하고 있습니다. 이 설문조사는 VLA 모델의 발전 궤적, 핵심 구조(관측 인코더, 특징 추론 백본, 행동 디코더, 계층적 시스템), 훈련 데이터셋(웹, 로봇, 합성 데이터), 사전/사후 훈련 방법(LLM/VLM 전이, RL 미세 조정, 추론 강화), 그리고 평가 방법론을 포괄적으로 분석합니다. VLA 모델은 웹 지식 전이와 계층적 추론을 통해 로봇의 범용성을 크게 확장하고 있으나, 여전히 일반화, 데이터 효율성, 계산 비용, 강건성, 깊은 추론 능력 등의 과제를 안고 있습니다. 미래 연구는 스케일링 가능한 아키텍처, 효율적인 데이터 생성, 다중 모달 통합, 심층 인지 및 강건한 실제 세계 평가에 초점을 맞출 것으로 예상됩니다.
