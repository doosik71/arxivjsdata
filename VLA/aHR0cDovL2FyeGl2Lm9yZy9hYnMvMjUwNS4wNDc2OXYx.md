# Vision-Language-Action Models: Concepts, Progress, Applications and Challenges

Ranjan Sapkota, Yang Cao, Konstantinos I. Roumeliotis, Manoj Karkee

## 🧩 Problem to Solve

기존의 인공지능 및 로봇 공학 시스템은 시각, 언어, 행동 영역이 파편화되어 각기 독립적으로 발전했으며, 이로 인해 복잡하고 예측 불가능한 실제 환경에서 데이터를 통합하고 유연하게 적응하는 데 어려움을 겪었습니다. 비전-언어 모델(VLM)은 다중 모달 데이터를 이해할 수 있었지만, 이를 기반으로 일관된 물리적 행동을 생성하거나 실행하는 능력은 부족했습니다. 즉, 로봇은 시각 정보를 인식하고, 언어 지시를 이해하며, 미리 정의된 행동을 수행할 수 있었으나, 이러한 능력을 유연하고 적응적인 방식으로 통합하여 새로운 작업이나 환경에 대처하는 데 한계가 있었습니다. 이러한 지각, 이해, 행동의 통합 부족은 로봇이 일반화된 지능을 갖춘 자율 에이전트가 되는 데 있어 핵심적인 병목 현상이었습니다.

## ✨ Key Contributions

- **VLA 모델의 포괄적 개념 정리:** VLA(Vision-Language-Action) 시스템의 개념적 기반, 진화, 다중 모달 통합 메커니즘, 토큰화 및 인코딩 전략, 적응형 제어 등 핵심 구성 요소를 체계적으로 분석하고 합성합니다.
- **최신 VLA 모델의 발전 및 효율성 분석:** 지난 3년간 발표된 80개 이상의 VLA 모델을 검토하며, 아키텍처 혁신(예: 초기 융합, 듀얼 시스템, 자가 교정 프레임워크), 매개변수 효율적인 훈련 전략(예: LoRA, 양자화), 실시간 추론 가속화 기술(예: FAST 토큰화, 병렬 디코딩) 등 주요 기술적 진보를 제시합니다.
- **다양한 실제 응용 분야 탐색:** 휴머노이드 로봇 공학, 자율주행 차량, 산업 로봇, 의료 로봇, 정밀 농업, 증강 현실(AR) 내비게이션 등 VLA 모델의 광범위한 적용 사례와 각 분야에서의 변혁적 잠재력을 조명합니다.
- **주요 과제 식별 및 해결책 제안:** 실시간 추론 제약, 다중 모달 액션 표현 및 안전성 확보, 데이터셋 편향 및 일반화 부족, 시스템 통합 복잡성, 계산 요구량, 환경 변화에 대한 견고성 및 윤리적 문제 등 VLA 모델이 직면한 핵심 과제를 명확히 하고, 이에 대한 잠재적 기술적 해결책과 예상되는 영향을 제시합니다.
- **미래 연구 로드맵 제시:** VLM, VLA 아키텍처, 에이전트 AI 시스템의 융합을 통해 사회적으로 조화롭고, 적응적이며, 범용적인 로봇 에이전트를 향한 미래 비전과 연구 방향을 제안합니다.

## 📎 Related Works

본 검토 논문은 VLA 모델의 등장 이전의 여러 기술적 기반과 관련 연구들을 언급하고 있습니다.

- **개별 모달리티 시스템:**
  - **비전 시스템:** 객체 감지 및 분류를 위한 컨볼루션 신경망(CNN) [44, 69] 등 특정 시각 작업에 특화되어 있었습니다.
  - **언어 시스템:** 대규모 언어 모델(LLM) [164, 137]이 텍스트 기반 이해와 생성에 혁명을 가져왔지만, 물리적 세계를 인지하거나 추론하는 능력은 부족했습니다.
  - **액션 시스템:** 수작업 정책 또는 강화 학습 [122]에 의존하여 특정 동작을 가능하게 했지만, 스크립트화된 시나리오를 넘어 일반화하기 어려웠습니다.
- **비전-언어 모델(VLM):**
  - **CLIP [149, 25, 148] 및 Flamingo [3]:** 비전과 언어를 결합하여 인상적인 다중 모달 이해를 달성했지만, 이러한 이해를 기반으로 일관된 행동을 생성하거나 실행하는 능력(integration gap)이 부족했습니다.
  - **CLIPort [157]:** CLIP 임베딩을 시맨틱 접지(semantic grounding)에 사용하고 컨볼루션 디코더를 픽셀 수준 조작에 사용하여 언어 파싱 없이 시각-운동 정책을 자연어에 직접 조건화하는 초기 시도를 했습니다.
- **초기 VLA 선구자들 (2021-2022년경):**
  - **RT-1 (Robotics Transformer 1) [18]:** 이산화된 액션을 통해 여러 주방 작업 조작을 위한 트랜스포머 아키텍처를 처음 도입했습니다.
  - **Gato [141]:** 통합된 토큰화를 통해 Atari 게임, 캡션 생성, 로봇 공학 등 다양한 작업을 처리하는 범용 에이전트의 가능성을 보여주었습니다.
  - **VIMA [86]:** 객체 중심 시각 토큰과 지시 토큰을 공동으로 처리하는 트랜스포머 인코더를 사용하여 소수점 학습(few-shot) 일반화를 가능하게 했습니다.
  - **RT-2 (Robotics Transformer 2) [224]:** Google DeepMind에서 개발한 모델로, 지각, 추론, 제어를 단일 프레임워크로 통합하여 VLA 개념을 확립하고, 로봇 제어를 자동 회귀 시퀀스 예측 작업으로 처리했습니다.
  - **Diffusion Policy [34]:** 확산 기반 시각-운동 정책 학습을 통해 다중 모달 액션 분포를 처리하는 방법을 제시했습니다.
  - **VoxPoser [78]:** 3D 객체 선택의 모호성을 해결하기 위해 복셀(voxel) 수준 추론을 사용했습니다.
  - **Octo [167]:** 대규모 로봇 시연 데이터셋(OpenX-Embodiment Dataset)에 기반하여 오픈 소스 범용 로봇 정책을 제안했습니다.

## 🛠️ Methodology

본 검토 논문은 VLA 모델이 실제 환경에서 시각, 언어, 행동을 통합하는 방식에 대한 방법론을 다음과 같이 제시합니다.

- **개념적 기반 확립:**
  - VLA 모델은 시각 인코더(예: CNN, ViT), 언어 모델(예: LLM, 트랜스포머), 정책 모듈 또는 플래너를 결합하여 작업에 따라 제어를 수행하는 지능형 시스템입니다.
  - 진화는 기초 통합(2022-2023)에서 도메인 전문화 및 추론(2024)을 거쳐 일반화 및 안전성(2025)으로 진행되었습니다.
- **다중 모달 통합:**
  - **종단 간 융합:** 전통적인 로봇 시스템의 분리된 모듈 방식과 달리, VLA는 대규모 사전 학습된 인코더와 트랜스포머 기반 아키텍처를 사용하여 시각적 관찰과 언어적 지시를 동일한 계산 공간에서 공동 처리합니다.
  - **융합 기술:** 교차-어텐션(cross-attention), 연결 임베딩(concatenated embeddings), 토큰 통합(token unification) 등을 활용하여 센서 관찰과 텍스트 명령을 정렬합니다.
- **토큰화 및 표현 (VLA가 세상을 인코딩하는 방식):**
  - **통합 토큰 스트림:** VLA는 비전, 언어, 로봇 내부 상태, 액션을 모두 이산적인 토큰으로 인코딩하여 공유 임베딩 공간에서 종합적으로 추론합니다.
    - **접두사(Prefix) 토큰:** ViT 또는 ConvNeXt와 같은 비전 인코더가 환경 이미지(예: 어수선한 탁상)를 처리하고, T5 또는 LLaMA 같은 언어 모델이 자연어 지시(예: "녹색 블록을 쌓아라")를 임베딩하여 모델의 목표와 환경 레이아웃에 대한 초기 이해를 형성합니다.
    - **상태(State) 토큰:** 로봇의 실시간 내부 물리적 상태(관절 위치, 힘-토크, 그리퍼 상태, 종단 효과기 포즈 등)를 MLP 인코더를 통해 인코딩하여 상황 인식을 가능하게 합니다.
    - **액션(Action) 토큰:** 모델이 자동 회귀 방식으로 생성하는 모터 제어 명령으로, 관절 각도 업데이트, 토크 값, 휠 속도 등 저수준 제어 신호 또는 고수준 운동 기본 요소에 해당합니다. (예: RT-2는 액션 생성을 텍스트 생성으로 처리)
  - **파이프라인:** 다중 모달 입력(RGB-D 프레임, 텍스트 명령, 관절 각도)은 각각 시각 토큰, 언어 토큰, 상태 토큰으로 독립적으로 토큰화됩니다. 이 토큰들은 교차-모달 어텐션 메커니즘을 통해 융합되고, 융합된 임베딩은 자동 회귀 디코더(트랜스포머)를 통해 액션 토큰으로 변환되어 실행 루프에 전달됩니다.
- **학습 패러다임:**
  - **하이브리드 학습:** 대규모 인터넷 기반 코퍼스(예: COCO, LAION-400M)에서 얻은 의미론적 지식(사전 학습)과 로봇 궤적 데이터셋(예: RoboNet, BridgeData, RT-X)에서 수집된 작업 기반 정보(모방 학습, 강화 학습, 행동 복제)를 통합합니다.
  - **다단계/다중 작업 훈련:** 마스크 언어 모델링 등으로 사전 학습한 후, 로봇 시연 데이터로 토큰 수준 자동 회귀 손실을 사용하여 미세 조정하거나 커리큘럼 학습을 적용합니다.
- **적응형 제어 및 실시간 실행:** 센서로부터의 실시간 피드백(상태 토큰 업데이트)을 사용하여 동작을 즉석에서 조정하고, 동적이고 비구조적인 환경에서의 예상치 못한 변화에 동적으로 적응합니다.

## 📊 Results

본 검토 논문은 VLA 모델의 주요 발전 사항과 다양한 응용 분야에서의 성과를 다음과 같이 요약합니다.

- **아키텍처 혁신 및 효율성 증대:**
  - **초기 융합 모델 (EF-VLA [74]):** CLIP 사전 학습의 의미론적 일관성을 유지하면서 합성 조작 작업에서 20% 성능 향상, 미정의 목표 설명에서 85% 성공률을 달성했습니다.
  - **듀얼 시스템 아키텍처 (Groot N1 [13]):** 고수준 계획(LLM)과 저수준 제어(확산 정책)를 결합하여 다단계 가정 조작에서 성공률을 17% 높이고 충돌 실패를 28% 줄였습니다.
  - **자가 교정 프레임워크 (SC-VLA):** 실패 조건을 감지하고 복구하여 작업 실패율을 35% 감소시키고, 복잡한 환경에서의 복구 가능성을 크게 향상시켰습니다.
- **훈련 및 효율성 향상:**
  - **데이터 효율성:** OpenVLA는 7B 매개변수로 55B 매개변수 RT-2보다 16.5% 높은 성공률을 보이며, 대규모 웹 스케일 데이터셋과 로봇 궤적 데이터셋에 대한 공동 미세 조정을 통해 강력한 일반화를 달성했습니다 [94, 152]. UniSim과 같은 합성 데이터 생성은 모델의 견고성을 20% 이상 개선했습니다 [200].
  - **매개변수 효율성:** LoRA(Low-Rank Adaptation)는 훈련 가능한 가중치를 최대 70%까지 줄이면서 성능을 유지하며, Pi-0 Fast [133]는 1,000만 개의 어댑터 매개변수로 200Hz의 연속 제어를 제공했습니다.
  - **추론 가속화:** 압축된 액션 토큰(FAST)과 병렬 디코딩(Groot N1 [13])은 정책 단계를 2.5배 빠르게 하여 5ms 미만의 지연 시간을 달성하며, 하드웨어 최적화는 엣지 GPU에서 8GB 미만의 메모리 공간으로 실시간 추론을 가능하게 합니다 [93].
- **다양한 응용 분야에서의 성공적인 배포:**
  - **휴머노이드 로봇 공학:** Figure AI의 Helix [figure.ai]와 RoboNurse-VLA [103]는 실시간 추론과 안전 인지 제어를 통해 가정 작업 및 수술 지원에서 높은 성능을 보였습니다.
  - **자율주행 시스템:** CoVLA [5], OpenDriveVLA [220], ORION [56]은 복잡한 도시 환경에서 다중 모달 입력을 통합하여 투명하고 적응적인 주행 결정을 가능하게 했습니다.
  - **산업 로봇 공학:** CogACT [102]는 다단계 조립, 나사 조임 등 고정밀 작업에서 이전 모델보다 59% 이상 높은 성공률을 기록했습니다.
  - **의료 로봇 공학:** RoboNurse-VLA [103]는 수술 기구 인계와 같은 정밀한 절차에서 도구의 다양성, 조명 조건, 노이즈에 강한 견고성을 보여주었습니다.
  - **정밀 농업:** VLA 로봇은 이미지 기반의 숙성 감지, 언어 지시 해석을 통해 정밀한 과일 수확 및 관개 관리 등에서 작물 손상을 최소화하고 생산성을 최적화했습니다.
  - **대화형 AR 내비게이션:** VLA 모델은 증강 현실 장치에서 실시간 시각 데이터와 자연어 쿼리를 처리하여 동적인 내비게이션 안내를 제공하여 사용자 경험을 향상시켰습니다.

## 🧠 Insights & Discussion

VLA 모델은 지각, 언어 이해, 물리적 행동을 단일 프레임워크로 통합함으로써 기존 AI 및 로봇 시스템의 근본적인 한계를 극복하는 변혁적인 발전을 가져왔습니다. 이는 로봇이 인간과 유사하게 복잡한 환경을 이해하고, 지시에 따라 유연하게 행동하며, 예측 불가능한 상황에 적응할 수 있는 길을 열었습니다.

그러나 VLA 모델은 여전히 다음과 같은 중대한 과제에 직면해 있습니다.

- **실시간 추론 제약:** 자동 회귀 디코딩은 로봇의 정밀하고 유동적인 제어(100Hz 이상)에 필요한 실시간 추론 속도(현재 3-5Hz)를 달성하기 어렵습니다. 병렬 디코딩과 같은 해결책은 궤적의 부드러움을 희생할 수 있으며, 고차원 시각 임베딩 처리는 엣지 디바이스의 하드웨어 메모리 대역폭을 초과합니다.
- **다중 모달 액션 표현의 복잡성 및 안전성:** 이산 토큰화는 정밀 작업에서 정확도를 떨어뜨리고, 연속형 MLP는 모드 붕괴 위험이 있습니다. 확산 기반 정책은 더 풍부한 액션 표현을 제공하지만 높은 계산 비용이 따릅니다. 또한, 동적이고 예측 불가능한 환경에서 충돌 예측 정확도는 낮고(약 82%), 비상 정지 메커니즘에 상당한 지연이 있어 안전 보장에 어려움이 있습니다.
- **데이터셋 편향, 접지 문제 및 일반화 부족:** 웹 기반 훈련 데이터셋의 내재적 편향(약 17%가 고정관념에 치우침)은 모델이 맥락에 맞지 않는 응답을 생성하게 합니다. 새로운 작업이나 익숙하지 않은 상황에 대한 일반화 능력은 여전히 제한적이며(성능 40% 저하), 제로샷/소수점 학습 성능도 부족합니다.
- **시스템 통합 복잡성 및 계산 요구사항:** 고수준 인지 계획(LLM 기반)과 저수준 물리적 제어(밀리초 단위) 간의 시간적 불일치는 동기화 문제를 야기합니다. 비전 인코더와 액션 디코더 간의 특징 공간 불일치도 통합을 어렵게 합니다. 70억 개 이상의 매개변수를 가진 VLA 모델은 28GB 이상의 VRAM을 필요로 하여 엣지 컴퓨팅 환경에서의 배포를 제약합니다.
- **환경 변화에 대한 견고성 및 윤리적 과제:** 동적인 조명, 날씨, 부분적 가려짐과 같은 환경 변화에 대한 VLA의 시각 모듈 정확도는 20-30% 감소하며, 소음 환경에서 언어 이해도 저하됩니다. 또한 데이터 편향, 프라이버시, 사회경제적 영향 등 윤리적 고려 사항이 모델의 신뢰성 높은 배포를 위해 필수적입니다.

**미래 로드맵:** VLM, VLA, 에이전트 AI의 융합은 진정한 범용 지능을 갖춘 로봇의 핵심이 될 것입니다. 이는 대규모 다중 모달 기반 모델을 공유 "피질"로 활용하여 정적 장면뿐 아니라 동역학, 물리, 상식적 세계 지식을 인코딩하고, 에이전트 AI 프레임워크를 통해 자율적인 자기 주도적 평생 학습을 가능하게 할 것입니다. 또한, 저수준 운동 기본 요소에서 고수준 추론에 이르는 계층적 신경-상징 계획, 내부 세계 모델을 통한 실시간 적응, 로봇 형태에 구애받지 않는 교차 구현 전이 학습, 그리고 안전성, 윤리, 인간 중심적 가치 정렬에 중점을 둔 시스템 개발이 이루어질 것입니다.

## 📌 TL;DR

VLA(Vision-Language-Action) 모델은 기존 AI 및 로봇 시스템의 파편화된 한계를 극복하고, 시각 지각, 자연어 이해, 물리적 행동을 단일 프레임워크로 통합하는 혁신적인 접근 방식입니다. 이 검토 논문은 지난 3년간 80개 이상의 VLA 모델에 대한 포괄적인 분석을 통해, 다중 모달 통합, 토큰화 기반의 세계 인코딩, 하이브리드 학습 패러다임, 적응형 실시간 제어와 같은 핵심 개념과 방법론을 제시합니다. 주요 발전으로는 듀얼 시스템 아키텍처(Groot N1), 매개변수 효율적인 훈련(LoRA), 추론 가속화(FAST 토큰화) 등이 있으며, 휴머노이드 로봇부터 자율주행, 산업, 의료, 농업, AR 내비게이션에 이르는 광범위한 실제 응용 분야에서 변혁적 잠재력을 보여줍니다. 하지만 VLA 모델은 실시간 추론 제약, 정밀한 다중 모달 액션 표현 및 안전성 확보, 데이터 편향 및 일반화 부족, 높은 계산 요구사항, 시스템 통합 복잡성, 환경 변화에 대한 견고성, 윤리적 문제 등 여전히 중대한 과제에 직면해 있습니다. 이러한 한계 극복을 위해 하드웨어 가속기, 하이브리드 정책, 편향 완화 데이터셋, 모듈형 설계, 윤리적 감독 프레임워크 등의 잠재적 해결책이 제안되며, 궁극적으로 VLM, VLA, 에이전트 AI의 융합을 통해 사회적으로 조화롭고 적응력 있으며 범용적인 로봇 지능의 미래를 제시합니다.
