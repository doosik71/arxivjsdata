# Accelerating Vision-Language-Action Model Integrated with Action Chunking via Parallel Decoding

Wenxuan Song, Jiayi Chen, Pengxiang Ding, Han Zhao, Wei Zhao, Zhide Zhong, Zongyuan Ge, Jun Ma, Haoang Li

## 🧩 Problem to Solve

Vision-Language-Action (VLA) 모델은 로봇 조작에 뛰어난 잠재력을 보이지만, 효과적인 제어를 위한 핵심 기술인 **액션 청킹(Action Chunking)**을 통합할 경우 문제가 발생합니다. 액션 청킹은 예측할 액션의 차원(길이)을 선형적으로 증가시켜, 기존의 자기회귀(Autoregressive, AR) 디코딩 방식에서는 각 토큰을 순차적으로 예측하므로 추론 효율성이 크게 저하됩니다. 이로 인해 VLA 모델의 제어 주파수가 낮아지고 액션의 일관성과 효율성이 제한됩니다. 따라서 액션 청킹이 통합된 VLA 모델의 디코딩 프로세스를 가속화하는 것이 시급한 과제입니다.

## ✨ Key Contributions

- 액션 청킹이 통합된 VLA 모델을 위한 최초의 **병렬 디코딩 프레임워크인 PD-VLA**를 제안합니다. 이 프레임워크는 액션 성능을 유지하면서 자기회귀 디코딩의 효율성 병목 현상을 해결합니다.
- VLA 추론을 위한 **디코딩 프로세스 전용 가속 전략**을 설계했습니다. 이는 기존 VLA 모델에 친화적인 배포(모델 재설계, 추가 학습, 수정 불필요)를 가능하게 하며, 다른 가속 방법들과 원활하게 결합될 수 있습니다.
- 시뮬레이션 및 실제 환경에서 PD-VLA의 성능 트레이드오프를 특징화하는 **포괄적인 경험적 검증 및 어블레이션 연구**를 수행했습니다.

## 📎 Related Works

- **Vision-Language-Action (VLA) 모델:** `RT-1` [4], `RT-2` [5], `Octo` [6], `OpenVLA` [9] 등은 대규모 로봇 데이터셋으로 학습된 멀티모달 대규모 모델을 기반으로 하며, 강력한 시각-언어 이해 능력을 로봇 제어에 적용하지만, 파라미터 수가 많아 추론 속도가 느립니다.
- **Action Chunking:** `T. Z. Zhao et al. (2023)` [15] 연구와 같이 여러 시간 단계에 걸쳐 액션 시퀀스를 예측하고 일부 또는 전체를 실행하는 방식입니다. 조작 성능을 향상시키지만, 예측 액션 시퀀스의 길이를 늘려 추론 시간을 증가시킵니다.
- **VLA 모델 가속화:** `DeeR-VLA` [19], `QAIL` [18]과 같은 아키텍처 수정 방법, `RoboMamba` [17], `TinyVLA` [16]와 같이 경량 모델을 개발하는 방법, `VLA-Cache` [22], `FAST` [13]와 같이 토큰 캐싱이나 압축 기반 토큰화를 사용하는 방법들이 있습니다. 본 논문의 PD-VLA는 기존 방법들과 달리 모델 재설계, 학습, 수정 없이 디코딩 과정만 가속화하여 배포 친화적입니다.

## 🛠️ Methodology

PD-VLA는 `LLaVA-VLA`라는 기본 VLA 모델(`LLaVA` [32] 기반)에 액션 청킹을 통합하고, 이를 병렬 디코딩으로 가속화합니다.

1.  **VLA 모델 아키텍처:**
    - `LLaVA-VLA`는 LLM 백본과 시각 인코더($f_{encoder}$)로 구성됩니다.
    - 입력으로 정적 이미지($I_{static}$), 그리퍼 이미지($I_{gripper}$), 텍스트 명령어($S$)를 받습니다.
    - 시각 인코더는 이미지를 시각 토큰 $h_{img}$로 처리하고, 텍스트 토크나이저 $T$는 명령어를 텍스트 토큰 $h_{S}$로 변환합니다.
    - LLM은 $h_{img}$와 $h_{S}$를 받아 자기회귀적으로 액션 토큰 $h_{act}$를 생성하고, 이는 7차원 액션 $a$로 역토큰화됩니다.
    - 액션 $a$는 $[X, Y, Z, \phi, \theta, \psi, G]$ (위치, 회전, 그리퍼 상태)로 구성되며, 각 차원은 256개의 균일한 간격의 빈으로 이산화되어 정수 인덱스로 표현됩니다.
2.  **액션 청킹 통합:**
    - 현재 시점 $t$에서 청크 크기 $m$ (기본값 $m=5$)을 사용하여 $A_t = [a_t, a_{t+1}, ..., a_{t+m-1}]$와 같이 여러 단계의 액션 시퀀스를 예측합니다. 이는 액션의 일관성과 안정성을 높이지만, 단일 추론에 더 긴 시간이 소요됩니다.
3.  **병렬 디코딩 (PD-VLA):**
    - **자기회귀(AR) 디코딩의 재정의:** 기존 AR 디코딩 ($y_i = \text{arg max}_y p(y|Y_i, x)$)은 $n$개의 토큰을 얻기 위해 $n$번의 LLM 순방향 전달을 필요로 하는 순차적 프로세스입니다.
    - **Jacobi 디코딩 기반 가속:** 이 논문에서는 LLM의 추론 과정을 비선형 방정식 시스템을 푸는 것으로 재정의하고, **병렬 고정점 반복(fixed-point iteration)** 방법을 활용합니다.
    - **양방향 어텐션 메커니즘:** 기존 VLA 모델의 인과적 어텐션 메커니즘을 **양방향 어텐션(bidirectional attention) 메커니즘**으로 대체하여 순차적 종속성을 깨뜨립니다.
    - **병렬 업데이트:** 모든 액션 토큰 $y_i$는 각 반복마다 병렬로 업데이트됩니다 ($y^{(j+1)}_i = \text{arg max}_y p(y|Y^{(j)}, x)$).
    - **수렴:** 반복은 $Y^{(k)} = Y^{(k-1)}$일 때 종료되며, $k \le n$이므로 AR 디코딩보다 적은 반복으로 완료될 수 있습니다.
    - **디코딩 길이($n$) 설정:** 총 액션 차원 $l$은 $7m+2$ (시작 및 종료 토큰 포함)입니다. $m=5$일 때 $l=37$입니다. $n=7$ (액션 차원별), $n=16$, $n=37$ (전체 액션 시퀀스)과 같은 다양한 $n$ 값을 실험합니다. 특히 $n=l$로 설정하면 단일 Jacobi 디코딩으로 추론이 완료됩니다.
    - **가속 현상 (고정 토큰, Fixed Tokens):** 병렬 디코딩 중 PD-VLA는 앞선 토큰이 틀렸더라도 정확한 액션 토큰을 선제적으로 예측하는 능력을 보여줍니다. 이렇게 `고정(fixed)`된 토큰(예: 그리퍼 상태 토큰)은 디코딩의 빠른 수렴에 기여하여 상당한 속도 향상을 가져옵니다.

## 📊 Results

- **시뮬레이션 (CALVIN 벤치마크):**
  - **성능 비교:** PD-VLA는 LLaVA-VLA에 비해 성공률을 크게 향상시켰습니다 (LLaVA-VLA 72.0% → PD-VLA 94.1%). 다른 최신 모델들과도 경쟁력 있는 성능을 보였습니다.
  - **가속 방법 비교:** `FastV` [21]나 `SparseVLM` [20]과 같은 다른 가속 방법들은 추론 속도를 실제로 개선하지 못하거나 오히려 저하시켰습니다. 반면 PD-VLA는 기본 VLA 모델 대비 **2.52배 높은 실행 주파수**를 달성했습니다.
  - **어블레이션 연구:** 액션 청킹(AC)은 액션 일관성과 안정성을 크게 향상시키지만, 추론 시간을 증가시킵니다. 병렬 디코딩(PD)은 평균 디코딩 속도를 1.28배 높여 추론 시간을 줄이고 고주파 추론을 가능하게 합니다. AC와 PD는 상호 보완적으로 작용하여 성능과 고주파 추론 간의 균형을 이룹니다.
  - **디코딩 길이($n$) 분석:** $n=37$ (전체 액션 시퀀스 길이)일 때 가장 강력한 조작 능력과 가장 빠른 디코딩 속도(52.84 토큰/초, 4.56 Hz)를 보였습니다. $n$이 증가함에 따라 `고정 토큰(fixed tokens)`의 수가 늘어나 디코딩 속도 향상에 기여합니다. $n=37$일 때 최대 속도가 $n=7$ 또는 AR 디코딩의 약 2배에 달했습니다.
- **실제 환경 실험 (Unitree Z1-Pro 로봇 팔):**
  - `푸쉬 버튼`, `블록 들어올리기`, `물 붓기` 세 가지 작업에서 PD-VLA는 LLaVA-VLA보다 높은 성공률을 보였습니다.
  - 특히 `물 붓기`와 같이 유연하고 정교한 조작이 필요한 작업에서 PD-VLA는 LLaVA-VLA가 실패한 반면 60%의 성공률을 달성했습니다. 이는 PD-VLA의 높은 실행 주파수와 실시간 이미지에 따른 액션 조정 능력 덕분입니다.
  - PD-VLA는 방해물이 있는 환경에서도 일관되고 부드러운 액션을 보여주어, 실제 로봇 애플리케이션에 적합함을 입증했습니다.

## 🧠 Insights & Discussion

PD-VLA는 액션 청킹이 통합된 VLA 모델의 비효율성 문제를 성공적으로 해결했습니다. 자기회귀 디코딩을 병렬 고정점 반복으로 재구성하고 양방향 어텐션 메커니즘을 도입함으로써, 모델의 성능을 유지하면서 디코딩 속도를 크게 향상시켰습니다. 특히, `고정 토큰`의 존재와 디코딩 길이($n$)의 적절한 선택이 가속화에 중요한 역할을 한다는 것을 밝혔습니다. PD-VLA는 기존 VLA 모델의 아키텍처나 학습 과정을 변경할 필요 없이 디코딩 과정만 최적화하므로, 배포가 용이하고 기존 가속 기술과도 시너지 효과를 낼 수 있다는 장점이 있습니다. 향후 연구에서는 병렬 디코딩 과정에서의 불필요한 반복을 줄여 고정점으로의 수렴을 더욱 빠르게 하는 디코딩 알고리즘 및 모델 최적화에 초점을 맞출 계획입니다.

## 📌 TL;DR

액션 청킹이 통합된 VLA 모델은 조작 성능은 좋지만 자기회귀 디코딩으로 인해 추론 속도가 느리다는 문제가 있습니다. 이 논문은 이러한 문제를 해결하기 위해 병렬 디코딩 프레임워크인 **PD-VLA**를 제안합니다. PD-VLA는 자기회귀 디코딩을 병렬 고정점 반복으로 재정의하고 양방향 어텐션 메커니즘을 사용하여 모든 액션 토큰을 동시에 예측합니다. 그 결과, 모델 성능을 유지하면서 시뮬레이션에서 **2.52배 높은 실행 주파수**를 달성했으며, 실제 로봇 조작 작업에서도 성공률이 크게 향상됨을 입증했습니다. 특히, PD-VLA는 기존 모델을 수정하거나 추가 학습 없이 배포 가능한 **학습 불필요(training-free) 가속화** 방식을 제공합니다.
