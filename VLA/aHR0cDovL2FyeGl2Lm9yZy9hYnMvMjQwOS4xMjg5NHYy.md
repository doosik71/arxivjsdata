# VLATest: Testing and Evaluating Vision-Language-Action Models for Robotic Manipulation

ZHIJIE WANG, ZHEHUA ZHOU, JIAYANG SONG, YUHENG HUANG, ZHAN SHU, LEI MA

## 🧩 Problem to Solve

로봇 조작을 위한 Vision-Language-Action (VLA) 모델은 상당한 잠재력을 보여주지만, 현재는 제한된 수의 수동으로 제작된 씬으로만 평가되어, 다양한 시나리오에서의 일반적인 성능과 강건성이 충분히 탐구되지 못하고 있습니다. 특히, VLA 모델은 자연어뿐만 아니라 시각적 입력을 모두 처리하므로, 교란 객체, 조명 조건, 카메라 각도와 같은 환경적 요인들이 성능에 크게 영향을 미칠 수 있습니다. 이 연구는 이러한 시각적 요인에 대한 VLA 모델의 강건성 부족을 해결하고, 실제 환경 배포에 필요한 신뢰성과 안전성 평가를 위한 포괄적인 테스트 프레임워크와 심층적인 이해를 제공하는 것을 목표로 합니다.

## ✨ Key Contributions

- **대규모 실증 연구**: 다양한 조건(교란 객체 수, 조명, 카메라 포즈 변화, 학습된/학습되지 않은 객체 조작)에서 7가지 인기 VLA 모델의 성능과 강건성을 4가지 로봇 조작 작업에 대해 평가하는 대규모 실증 연구를 수행했습니다.
- **테스트 프레임워크**: 로봇 조작 작업에서 다양한 연산자를 통합하여 VLA 모델을 테스트하기 위한 생성 기반 퍼징 프레임워크인 VLATest를 설계하고 구현했습니다.
- **시사점**: 현재 VLA 모델의 도전 과제와 한계를 논의하고, 강건성 및 신뢰성 향상을 위한 실질적인 시사점과 미래 연구 기회를 제시했습니다.
- **아티팩트**: 연구 재현을 위한 패키지와 생성된 테스트 씬을 GitHub 저장소에 공개했습니다.

## 📎 Related Works

- **로봇 공학을 위한 파운데이션 모델**: LLM(예: Zhou et al. [98], Song et al. [68])과 VLM(예: RT-1 [7], RT-2 [8], Octo [75], OpenVLA [40])을 활용하여 로봇 조작, 시각적 질의응답, 시각 상태 표현 등 다양한 로봇 공학 작업을 발전시키려는 노력이 이루어졌습니다. 본 연구는 특히 VLA 모델에 중점을 둡니다.
- **사이버-물리 시스템(CPS) 테스트**: CPS의 안전성 및 신뢰성을 보장하기 위해 MOTIF [43], ARIsTEO [53]와 같은 테스트 프레임워크와 능동 퍼징 [12] 방법론이 개발되었습니다. 그러나 이러한 기존 접근 방식은 VLA 모델의 멀티모달 특성, 자기회귀적 생성 메커니즘, 대규모 모델 크기로 인해 직접 적용하기에는 한계가 있습니다.
- **파운데이션 모델 벤치마킹 및 테스트**: LLM의 정확성 [49], 사실성 [50], 강건성 [79], 공정성 [72], 프라이버시 [29] 및 코드 관련 능력 [10,52]을 평가하는 많은 연구가 진행되었습니다. 또한 규칙 기반 [78], 변성 테스트 [31,73], 돌연변이 기반 [85]과 같이 테스트 케이스를 동적으로 생성하는 방법도 있습니다. 본 연구는 멀티모달 입력과 3D 환경에서의 복잡한 로봇 조작을 다루는 VLA 모델에 특화된 테스트 프레임워크를 제공하여 기존 연구와 차별화됩니다.

## 🛠️ Methodology

VLATest는 로봇 조작 작업을 위한 테스트 씬을 자동으로 생성하는 퍼징(fuzzing) 프레임워크이며, Maniskill2 시뮬레이션 환경 [26] 내에 구현되었습니다.

**1. 테스트 연산자 (Operators)**:
VLATest는 4가지 범주에 걸쳐 총 10가지 테스트 연산자를 고려합니다.

- **대상 객체 (Target object(s))**: 조작 대상 또는 참조 객체 (유형, 위치, 방향).
- **교란 객체 (Confounding objects)**: 조작 시 로봇이 피해야 할 객체 (유형, 위치, 방향, 개수).
- **조명 (Lighting)**: 환경 조명 조건 (강도).
- **카메라 (Camera)**: 시각 입력 캡처 카메라 (위치, 방향).

**2. 테스트 씬 생성 알고리즘 (Algorithm 1)**:
VLATest는 다음 4단계로 테스트 씬을 생성합니다.

- **의미론적으로 유효한 대상 객체 샘플링**: 주어진 로봇 조작 작업 $T$에 대해 객체 데이터베이스 $O$에서 대상 객체 $N_{target}$개를 무작위로 샘플링하고, 작업 요구 사항에 따라 의미론적으로 유효한지 확인합니다. 객체 간 충돌을 피하기 위해 충분한 거리($safe\_dist$)를 유지하며 위치와 방향을 할당합니다.
- **교란 객체 샘플링 (선택 사항)**: $N_{confound}$가 0보다 크면 $O$에서 추가로 교란 객체를 무작위로 샘플링하고 위치와 방향을 할당합니다.
- **조명 조건 변이 (선택 사항)**: 조명 변이 옵션($lighting\_flag$)이 활성화된 경우, 기본 조명 강도에 임의의 계수 $\alpha \in [1/20, 20]$를 곱하여 변이시킵니다.
- **카메라 포즈 변이 (선택 사항)**: 카메라 변이 옵션($camera\_flag$)이 활성화된 경우, 카메라의 위치를 $0 \sim 5 \text{ cm}$ 이동하고 각 축을 중심으로 $-5^\circ \sim 5^\circ$ 회전시켜 포즈를 변경합니다.

**3. 실증 연구 설정**:

- **연구 질문**: 기본 성능 (RQ1), 작업 복잡성 (RQ2), 인식 강건성 (RQ3, RQ4), OOD 강건성 (RQ5), 언어 모델 강건성 (RQ6)의 6가지 연구 질문을 설정했습니다.
- **대상 VLA 모델**: RT-1 (1k, 58k, 400k), RT-1-X, Octo (small, base), OpenVLA-7b의 7가지 공개 VLA 모델을 평가했습니다.
- **로봇 조작 작업**: 다음 4가지 인기 작업을 사용했습니다: (1) 객체 집기, (2) 객체 A를 객체 B 근처로 옮기기, (3) 객체 A를 객체 B 위에 놓기, (4) 객체 A를 객체 B 안에 넣기.
- **프롬프트 템플릿**: 각 작업에 대해 표준 프롬프트 템플릿을 사용하고, RQ6에서는 GPT-4o로 생성된 변형 프롬프트를 활용했습니다.
- **실험 규모**: 총 18,604개의 테스트 씬을 생성하고 78,604회 시뮬레이션 실행 (총 580 GPU 시간)을 수행했습니다.

## 📊 Results

- **RQ1: VLA 모델의 기본 성능**: VLA 모델은 4가지 로봇 조작 작업에서 전반적으로 저조한 성능을 보였습니다. 특히 여러 단계의 추론이 필요한 Task 2(옮기기), Task 3(위에 놓기), Task 4(안에 넣기)에서 성공률이 급격히 낮아졌습니다(최고 모델 성공률도 12.7% 미만). 이는 모델이 복잡한 다단계 자연어 지시를 정확히 해석하는 데 어려움을 겪음을 시사합니다.
- **RQ2: 교란 객체 수가 VLA 모델 성능에 미치는 영향**: 교란 객체 수가 증가할수록 Task 1(집기)과 Task 2(옮기기)의 VLA 모델 성공률이 감소했습니다(예: Task 1에서 0개일 때 17.3% $\to$ 4개일 때 8.3%). 이는 모델이 복잡한 환경에서 조작할 올바른 객체를 식별하는 데 큰 어려움을 겪기 때문입니다. 교란 객체와 대상 객체의 시각적 유사성은 성능에 큰 영향을 미치지 않았습니다.
- **RQ3: 조명 조건 변화가 VLA 모델 성능에 미치는 영향**: 무작위 조명 변이는 VLA 모델의 성능을 크게 저하시켰으며, 기본 조건에서 성공한 테스트 케이스 중 평균 61.3%만이 성공했습니다. OpenVLA-7b가 77.9%로 가장 강건했으며, 대규모 사전 훈련된 비전 모델의 이점이 작용한 것으로 분석됩니다. 조명 강도를 증가시키는 것이 감소시키는 것보다 성능 저하에 더 큰 영향을 미쳤습니다.
- **RQ4: 카메라 포즈 변화가 VLA 모델 성능에 미치는 영향**: 카메라 포즈를 변경했을 때 VLA 모델의 성능은 크게 저하되어, 기본 조건에서 성공한 테스트 케이스 중 평균 34.0%만이 성공했습니다. RT-1-400k가 45.6%로 가장 강건했지만, Octo 모델들은 10% 미만의 성공률로 현저히 낮은 강건성을 보였는데, 이는 훈련 데이터셋의 크기 차이 때문으로 추정됩니다.
- **RQ5: VLA 모델의 미학습 객체에 대한 강건성**: 미학습 객체를 조작할 때 VLA 모델의 성능은 학습된 객체에 비해 크게 감소했으며(20.0% ~ 74.2% 감소), 주요 실패 원인은 미학습 객체를 정확하게 인식하고 위치를 파악하는 능력의 부족이었습니다.
- **RQ6: VLA 모델의 작업 지시 변형에 대한 강건성**: VLA 모델은 작업 지시 변형에 대해 제한적인 강건성을 보였습니다. 그러나 Llama 2와 같은 대규모 언어 모델을 통합한 OpenVLA-7b 모델은 지시 변형에 대해 훨씬 더 강건했으며, 일부 작업에서는 오히려 성능이 향상되기도 했습니다.

## 🧠 Insights & Discussion

- **VLA 모델의 신뢰성 부족**: 현재 VLA 모델은 로봇 조작에 있어 아직 실용적인 배포를 고려하기에는 신뢰성이 부족합니다. 이는 복잡한 작업 지시 해석 능력과 대상 객체를 정확하게 위치 파악하는 능력의 부족에서 기인합니다.
- **성능 향상 방향**:
  - **모델 스케일업**: 현재 VLA 모델의 규모는 다른 도메인의 SOTA 모델보다 훨씬 작으므로, 모델 크기를 확장하면 새로운 능력이 나타날 수 있습니다.
  - **효과적인 프롬프트 전략**: 'Chain-of-Thought'와 같이 복잡한 작업을 단계별로 분해하여 프롬프트를 구성하는 전략이 VLA 모델의 성능을 크게 향상시킬 수 있습니다.
  - **멀티 에이전트 시스템**: 여러 VLA 에이전트가 작업을 분담하는 접근 방식도 고려할 수 있습니다.
- **강건성 도전 과제 해결**:
  - **훈련 데이터 강화**: 대규모 사전 훈련과 풍부한 로봇 시연 데이터가 강건성을 높이는 데 중요하며, 데이터 증강 기술이나 Sim2Real 전환을 통해 훈련 데이터의 양과 다양성을 늘려야 합니다.
  - **환경 요인 고려**: 데이터셋 수집 시 조명 조건, 카메라 각도 등 다양한 외부 환경 요인 변화를 적극적으로 반영하여 더욱 강건한 VLA 모델을 훈련해야 합니다.
- **VLA 모델 기능 평가**:
  - VLA 모델의 실제 적용을 위해서는 모델의 한계를 정확히 이해하고 사용 지침을 마련하는 것이 필수적입니다.
  - **오프라인 벤치마킹**: 본 연구에서 생성된 18,604개의 테스트 씬은 VLA 모델의 초기 벤치마크 역할을 할 수 있으며, 향후 더 다양한 작업과 환경 요인을 포함하도록 확장되어야 합니다.
  - **온라인 위험 평가**: 불확실성 추정 및 안전 모니터링 기술을 로봇 조작 분야에 적용하여 VLA 모델의 실시간 의사 결정 품질과 신뢰성을 평가하는 연구가 필요합니다.
- **VLA 모델의 효율적인 테스트**:
  - VLATest는 테스트 생성에 상당한 시간 비용이 소요되므로, 변성 기반 또는 검색 기반 방법과 같은 최적화된 퍼징 전략을 통해 테스트 씬 생성의 효율성을 높여야 합니다.
  - 테스트 우선순위 지정 또는 테스트 선택 연구도 효율적인 VLA 모델 테스트에 기여할 수 있으며, 모델 발전 속도에 맞춰 테스트 전략도 진화해야 합니다.

## 📌 TL;DR

본 논문은 로봇 조작을 위한 VLA (Vision-Language-Action) 모델의 강건성과 성능을 평가하는 VLATest라는 퍼징 프레임워크를 제안합니다. VLATest는 10가지 연산자를 사용하여 다양한 테스트 씬(교란 객체, 조명, 카메라 포즈, 미학습 객체, 지시 변형 등)을 자동으로 생성합니다. 7가지 대표 VLA 모델에 대한 대규모 실증 연구 결과, 현재 VLA 모델은 복잡한 다단계 작업, 교란 객체가 많은 환경, 조명 및 카메라 포즈 변화, 미학습 객체, 그리고 지시문 변형에 대해 전반적으로 신뢰할 수 없고 강건성이 부족함을 발견했습니다. 특히 객체 인식 및 지시문 해석에 어려움을 겪으며, 대규모 사전 학습을 받은 모델(예: OpenVLA-7b)이 강건성 측면에서 우수했습니다. 본 연구는 VLA 모델 개발의 초기 단계임을 강조하며, 신뢰성 향상을 위한 모델 확장, 프롬프트 전략, 데이터 강화, 효율적인 테스트 방법론 등의 미래 연구 방향을 제시합니다.
