# VLA 모델-전문가 협업을 통한 양방향 조작 학습

Tian-Yu Xiang, Ao-Qun Jin, Xiao-Hu Zhou, Mei-Jiang Gui, Xiao-Liang Xie, Shi-Qi Liu, Shuang-Yi Wang, Sheng-Bin Duang, Si-Cheng Wang, Zheng Lei, Zeng-Guang Hou

## 🧩 Problem to Solve

로봇 조작을 위한 VLA(Vision-Language-Action) 모델은 상당한 발전을 이루었지만, 고품질 조작 데이터셋의 부족, 조작 작업의 높은 이질성 및 추상성, 그리고 단일 작업에 대한 다양한 전략으로 인해 다중 작업 조작에서의 일반화 능력에 한계가 있습니다. 기존의 VLA 모델 미세 조정 방식은 추가 데이터 수집의 어려움이 있고, 전문가 개입(expert-in-the-loop) 프레임워크는 VLA 모델과의 통합이 아직 미해결 과제로 남아 있습니다. 이 연구는 제한된 전문가 행동을 활용하여 VLA 모델의 성능을 향상시키면서 전문가의 작업 부담을 줄이고, 지속적인 학습을 가능하게 하는 협업 시스템을 개발하는 것을 목표로 합니다.

## ✨ Key Contributions

- **VLA 모델-전문가 협업 프레임워크 제안:** VLA 모델과 전문가 간의 협업을 통해 준자율 조작을 달성하는 선구적인 연구를 제시합니다.
- **양방향 학습 루프 구현:** 협업 과정에서 수집된 조작 데이터로 VLA 모델이 지속적으로 미세 조정될 수 있도록 하며, 동시에 인간 전문가도 시스템에 적응하고 조작 기술을 향상시킬 수 있도록 합니다.
- **성능 향상 및 전문가 부담 감소 입증:** MetaWorld 환경(MT10/MT50 벤치마크) 실험을 통해 제안된 시스템의 효과를 검증했습니다.
  - VLA 모델:전문가 액션 비율이 $4:1$일 때, VLA 모델의 성공률이 MT10에서 $6.2\%$, MT50에서 $13.5\%$ 향상되었습니다.
  - 인간 전문가의 액션 단계 수가 $82.24\%$ 감소하여 작업 부담이 크게 줄었습니다.
- **뇌-컴퓨터 인터페이스(BCI) 시스템과의 통합 가능성 확인:** 저속 액션 시스템인 BCI와 결합하여 전체 시스템의 효율성을 높일 수 있음을 시사하며, 인간-로봇 상호작용 발전의 길을 열었습니다.

## 📎 Related Works

- **로봇 학습을 위한 VLA 모델:** 비전 및 언어 기반의 파운데이션 모델 성공에 힘입어 VLA 모델이 범용 로봇 정책 개발의 유망한 접근 방식으로 부상했습니다. 이들은 입력-출력 구조에 따라 One-Step input with Discrete-Action output (OSDA), Historical-Step input with Discrete-Action output (HSDA), One-Step input with Continuous-Action output (OSCA), Historical-Step input with Continuous-Action output (HSCA)의 네 가지 유형으로 분류됩니다. 본 연구에서는 OpenVLA [4], Octo [5], $\pi_0$ [14]와 같은 대표적인 VLA 모델들을 평가에 활용했습니다.
- **로봇 조작 모델을 위한 미세 조정 기법:** 사전 훈련된 로봇 모델을 다운스트림 애플리케이션에 적용하는 데 중요한 역할을 합니다.
  - **직접 미세 조정:** 제한된 목표 조작 데이터로 모델을 미세 조정하는 가장 직접적인 방법입니다.
  - **자체 개선(Self-improvement):** 모델이 생성한 합성 데이터를 사용하여 미세 조정을 수행하지만, 잘못된 조작으로 인해 성능이 저하될 수 있습니다.
  - **강화 학습(Reinforcement Learning, RL):** 설계된 보상을 사용하여 정책을 최적화하지만, 환경과의 광범위한 상호작용이 필요합니다.
  - 본 연구는 전문가의 상호작용을 최적의 정책으로 활용하여 VLA 모델이 협업 중 수집된 과거 조작 데이터를 통해 성능을 개선하는 새로운 미세 조정 패러다임을 제안합니다.

## 🛠️ Methodology

본 연구는 VLA 모델과 전문가 간의 협업을 통해 조작 및 학습을 수행하는 프레임워크를 제안합니다.

1. **VLA 모델의 일반적인 구조:**
   - VLA 모델은 시각 입력 $v_i$와 언어 명령 $l_i$를 조건부 상태로 받아 로봇의 액션 $a_i$를 예측합니다. 이는 $\pi_{VLA}(l_i, v_i)$로 표현됩니다.
   - 이산 액션 헤드를 사용하는 VLA 모델의 경우, 예측된 이산 액션 $\hat{a_i}$는 다음 수식을 통해 연속적인 액션 공간으로 다시 매핑됩니다:
     $$a_i = \frac{\hat{a_i}}{\text{vocabsize}-1}(a_{\text{max}} - a_{\text{min}}) + a_{\text{min}}$$
     여기서 $\text{vocabsize}$는 어휘 크기, $a_{\text{max}}$와 $a_{\text{min}}$은 액션의 상한 및 하한을 나타냅니다.
2. **전문가 정책:**
   - **규칙 기반 정책:** MetaWorld 시뮬레이션 환경에서 구현되며, 로봇이 작업 목표와 대상 위치를 알고 있어 거의 최적의 솔루션을 제공합니다.
   - **인간 사용자 정책:** 참가자가 로봇 팔을 직접 제어하며, 숙련도와 2D-3D 환경 간의 불일치로 인해 최적이 아닐 수 있지만 목표를 달성할 수 있습니다.
3. **전문가-VLA 협업:** 조작(Manipulation)과 학습(Learning)의 두 가지 핵심 과정으로 구성됩니다.
   - **협업 조작 (Collaborated Manipulation):**
     - VLA 모델이 $N$단계 동안 자율적으로 액션을 실행한 후, 전문가 정책이 1단계 액션을 수행하는 주기를 반복합니다.
     - 이 과정은 작업이 완료되거나 실패 임계값에 도달할 때까지 계속됩니다.
     - 예시로 VLA:전문가 액션 비율을 $4:1$로 설정하여 VLA 모델이 대부분의 루틴 작업을 처리하고 전문가의 개입을 최소화합니다.
   - **협업 학습 (Collaborated Learning, 양방향 학습):**
     - 협업 조작 과정에서 생성된 새로운 조작 데이터(전문가 액션 및 해당 시각/언어 상태)를 버퍼에 수집합니다.
     - 실패한 경우에도 전문가 액션은 거의 최적의 액션으로 간주되어 학습 데이터로 활용됩니다.
     - 수집된 데이터셋 $D$를 사용하여 VLA 모델 $\pi_{VLA}$를 지도 학습 패러다임으로 미세 조정합니다 (Algorithm 1 참조).
     - 인간 전문가도 시스템과의 상호작용을 통해 조작 숙련도를 향상시킵니다.

## 📊 Results

- **VLA 모델 성공률 향상:**
  - MT10 및 MT50 벤치마크에서 규칙 기반 또는 인간 전문가 정책의 작은 비율만 통합하더라도 VLA 모델의 성공률이 일관되게 향상되었습니다 (표 III).
  - 전문가 액션 비율이 높을수록 성능이 더 크게 향상되었습니다.
  - MT50 벤치마크에서 절대적인 성공률은 낮았지만, 상대적인 개선 효과는 더 두드러졌습니다.
  - 인간-VLA 협업(V-H)은 규칙 기반(V-R)보다 더 나은 성능 향상을 보였는데, 이는 인간 입력의 유연성과 다양성이 VLA 모델 정책을 보완하기 때문으로 분석됩니다 (표 II).
- **인간 전문가의 조작 단계 감소:**
  - VLA:인간 액션 비율 $4:1$ 설정에서 인간 전문가가 수행한 액션 단계가 $82.24\%$ 감소했습니다 (표 II). 이는 예상치인 $80\%$와 일치하거나 약간 상회하는 수치입니다.
- **협업 학습을 통한 VLA 모델 개선:**
  - 규칙 기반 전문가와의 협업 데이터(N=4)로 Octo 모델을 재조정(re-tuning)한 결과, VLA 모델의 평균 성공률이 $0.692$에서 $0.730$으로 $0.038$ 증가했습니다 (그림 3).
  - 협업 학습 후 협업 조작으로 인한 성공률 향상이 훨씬 커졌습니다 ($0.122$ vs $0.024$).
- **인간 전문가의 숙련도 향상:**
  - MT10의 어려운 작업에서 인간 사용자의 평균 성공률이 상호작용 라운드 수와 강한 양의 상관관계(Pearson 상관계수: $0.95$)를 보이며 향상되었습니다 (그림 4).
  - 인간 사용자가 작업을 완료하는 데 필요한 액션 단계 수는 상호작용 라운드 수와 음의 선형 상관관계(Pearson 상관계수: $-0.63$)를 보이며 감소했습니다 (그림 4). 이는 VLA 모델의 변화 없이 참가자들의 학습에 기인합니다.

## 🧠 Insights & Discussion

제안된 전문가-VLA 협업 시스템은 저주파수 인간 액션 입력 시스템의 효율성을 높이는 데 효과적임을 보여줍니다. 특히, SSVEP 기반 BCI(뇌-컴퓨터 인터페이스) 시스템에 적용했을 때, BCI의 느린 액션 신호에도 불구하고 VLA 모델의 빠른 조작 능력을 활용하여 전체 시스템의 시간 효율성을 크게 향상시키고 사용자 작업 부담을 줄였습니다 (그림 5, 표 IV). 이는 인간-기계 상호작용에 대한 새로운 관점을 제시하며, 실제 적용을 통해 VLA 모델 성능을 지속적으로 개선할 수 있는 가능성을 보여줍니다. 비록 BCI의 순수 제어가 일부 작업에서 더 적은 단계를 필요로 할 수 있지만, VLA와의 협업은 훨씬 빠른 속도로 대부분의 작업을 수행하여 시간 절약 효과가 큽니다.

## 📌 TL;DR

이 논문은 VLA(Vision-Language-Action) 모델의 다중 작업 조작 일반화 한계를 극복하기 위해 VLA 모델과 전문가 간의 양방향 협업 학습 프레임워크를 제안한다. 제한된 전문가 액션(예: VLA:전문가 = $4:1$)을 통해 VLA 모델의 성공률을 향상시키고(MT10에서 $6.2\%$, MT50에서 $13.5\%$ 개선), 인간 전문가의 작업 부담을 크게 줄였다($82.24\%$ 액션 감소). 협업 과정에서 수집된 데이터를 사용하여 VLA 모델을 지속적으로 미세 조정할 수 있으며, 인간 전문가 또한 시스템과의 상호작용을 통해 조작 기술을 향상시키는 양방향 학습이 가능하다. 또한, 저속 인간 입력 시스템인 BCI와의 통합을 통해 시스템 효율성을 높일 수 있음을 입증하여 인간-로봇 상호작용 및 로봇 파운데이션 모델의 실제 적용 가능성을 확장했다.
