# From Intention to Execution: Probing the Generalization Boundaries of Vision-Language-Action Models

Irving Fang, Juexiao Zhang, Shengbang Tong, Chen Feng

## 🧩 Problem to Solve

Vision-Language-Action (VLA) 모델이 대규모 Vision-Language Models (VLM)의 폭넓은 일반화 능력을 활용하여 다재다능하고 '제너럴리스트' 로봇 정책을 생산할 수 있다는 잠재력에도 불구하고, 현재 VLA 모델 평가가 불충분하다는 점이다. 기존 모방 학습 벤치마크는 언어 지침이 부족하여 부적합하며, 최근 등장한 VLA 벤치마크는 평가 작업이 제한적이고 VLM 사전 학습이 하위 로봇 정책의 일반화 능력에 얼마나 기여하는지 충분히 조사하지 않는다. 또한, 실제 로봇 설정은 재현성 및 접근성 측면에서 장벽이 커 체계적인 평가가 어렵다. 이로 인해 VLA 모델이 내장된 VLM의 강력한 일반화 능력을 활용하여 학습 데이터셋을 넘어 얼마나 잘 일반화할 수 있는지 불분명하다.

## ✨ Key Contributions

- **INT-ACT 개발 및 공개**: 객체 다양성, 언어 복잡성, 시각-언어 사고 등 3가지 주요 범주 및 10가지 하위 범주에 걸쳐 50개 작업을 포함하는 포괄적인 VLA 일반화 탐색 스위트 INT-ACT를 소개하고 오픈 소스로 공개했습니다. 이는 기존 VLA 벤치마크의 범위를 대폭 확장합니다.
- **주요 실패 모드 발견**: 최신 VLA 모델에서 두 가지 핵심 실패 모드를 밝혀냈습니다.
  - **의도-행동 간극 (Intention-Action Gap)**: VLM 백본이 강력한 의미론적 이해와 높은 수준의 계획, 즉 '좋은 의도'를 부여하지만, 이는 분포 변화(distribution shift) 상황에서 정밀한 모터 실행으로 안정적으로 이어지지 않습니다.
  - **취약한 다중 모드 일반화**: 특히 언어 변형 및 시각-언어 분포 변화가 복합적으로 작용할 때 일반화 능력이 취약합니다.

## 📎 Related Works

- **로봇 파운데이션 모델 (Robotic Foundation Models)**: BERT, GPT, CLIP, DINOv2와 같은 대규모 사전 학습 모델의 성공을 바탕으로 로봇 분야에서도 RT-1, Octo, RDT 등이 등장하여 다양한 로봇 데이터셋으로 일반화된 에이전트를 구축하려 합니다. 이들은 주로 분리된 인코더(예: 언어용 T5, 시각용 SigLIP)를 사용하여 다중 모드 입력을 인코딩한 후 모방 학습 정책을 훈련합니다.
- **시각-언어-행동 (Vision-Language-Action, VLA) 모델**: 강력한 사전 학습된 VLM을 직접 통합하는 것을 목표로 합니다. 예를 들어, RT-2는 PaLM-E 및 PaLI-X를 시각-언어 및 로봇 데이터에 미세 조정하고, OpenVLA는 Prismatic VLM을 사용합니다. SpatialVLA 및 FAST는 액션 토큰화 전략을 개선했으며, $\pi_0$는 액션 토큰화를 우회하여 VLM(예: PaliGemma)과 특수 트랜스포머를 결합합니다. 이러한 모델은 제로샷 추론을 목표로 하지만, 실제 배포를 위해서는 미세 조정이 필요합니다.
- **VLA 모델을 위한 벤치마크**:
  - **전통적인 벤치마크**: RLBench, RoboMimic 등은 주로 언어 지침 없이 낮은 수준의 로봇 조작 작업에 초점을 맞춥니다.
  - **언어 통합 벤치마크**: CALVIN, LIBERO 등은 언어 지침을 포함하나, 작업 다양성과 시각적 복잡성이 제한적입니다.
  - **SimplerEnv**: 시스템 식별과 그린스크린 합성으로 실제 세계 성능과 밀접하게 일치하도록 설계되었지만, 제한된 작업 수로 인해 VLA의 광범위한 일반화 평가에는 부족합니다.
  - **실제 로봇 환경**: $\pi_0$, OpenVLA 등 실제 로봇 설정은 높은 유효성을 제공하지만, 물류, 재정, 시간적 제약으로 인해 체계적인 평가의 재현성과 접근성이 낮습니다.
    본 연구는 이러한 한계를 극복하기 위해 SimplerEnv를 확장하여 언어 복잡성, 객체 다양성, 시각적 변이 측면에서 일반화를 탐색하는 종합적인 평가 스위트를 제시합니다.

## 🛠️ Methodology

- **테스트베드 선택**: 배포 장벽을 최소화하기 위해 ManiSkill2 시뮬레이터에 구축된 SimplerEnv 벤치마크를 확장하여 INT-ACT 스위트를 개발했습니다. SimplerEnv는 실제 세계 성능과 밀접하게 일치하도록 설계되어 이상적인 테스트베드입니다. BridgeV2 데이터셋을 위해 원래 4개였던 SimplerEnv 작업을 50개로 대폭 확장했습니다.
- **설계 원칙 (3가지 범주)**: 일반화 가능한 VLA 정책이 VLM의 시각-언어 이해 및 폭넓은 일반화 능력을 계승해야 한다는 원칙에 따라, 탐색 작업을 세 가지 주요 범주로 구성했습니다.
  1. **객체 다양성 (Object Diversity)**: BridgeV2 데이터셋에 없던 OOD(Out-of-Distribution) 객체(가정용품, 산업 도구 등)와 OOD 객체 간 관계를 도입하여 VLA 정책이 사전 학습된 시각적 표현의 일반화 한계를 테스트합니다. 예를 들어 "PUT {Source} ON {Target}" 작업에서 소스, 타겟 또는 둘 다 OOD 객체로 대체합니다.
  2. **언어 복잡성 (Language Complexity)**: BridgeV2 데이터셋의 지침을 언어 변화(행동 동사 재구성, 의미론적 부정, 지시적 외형, 상식적 단서)를 추가하여 증강함으로써 VLA가 VLM의 고급 언어 이해 능력을 계승하는지 탐색합니다.
  3. **시각-언어 사고 (Vision-Language Thinking)**: 작업과 무관한 방해물 객체(일반적인 잡동사니, 의미론적으로 도전적인 방해물)를 추가하여 VLA 모델이 복잡하고 어수선한 시각 환경과 모호성에 강건한지 테스트합니다.
- **모델 선정 및 훈련 프로토콜**: $\pi_0$ (fine-tune, scratch), SpatialVLA, Magma, Octo (Small, Base) 등 4가지 주요 VLA 아키텍처 및 그 변형을 평가했습니다. 모든 미세 조정 실험은 BridgeV2에서 수행되었으며, 각 논문의 훈련 및 미세 조정 프로토콜을 따랐습니다.
- **평가 절차**: 각 작업에 대해 ManiSkill2에 사전 정의된 모든 가능한 장면 및 객체 구성에 해당하는 24개의 에피소드를 평가하며, 각 구성은 3개의 랜덤 시드로 반복되었습니다.
- **평가 지표**: 세 가지 주요 지표를 사용했습니다.
  - **그랩 성공률 (Grasp Success Rate)**: 로봇 그리퍼가 에피소드 중 언제든 올바른 원천 객체를 성공적으로 잡았는지 여부.
  - **의도 정확률 (Intention Correct Rate)**: (새로운 지표) 그리퍼가 어떤 프레임에서든 올바른 원천 객체의 작은 반경 내로 이동했는지 여부. 이는 잡기 실패와 관계없이 정책의 의도를 포착합니다.
  - **작업 성공률 (Task Success Rate)**: 작업이 성공적으로 완료되었는지 여부.

## 📊 Results

- **의도-행동 간극 (Intention-Action Gap)**: 대부분의 VLM으로 초기화된 VLA 모델은 모든 범주에서 높은 의도 정확률(80-100%)을 보였으나, 작업 성공률은 급격히 하락했습니다. 특히 $\pi_0$-scratch 모델이 가장 좋은 성능을 보였지만, 의도와 실행 간의 상당한 간극을 나타냈습니다. 이는 VLM이 "무엇을 해야 하는지"에 대한 일반화된 개념을 부여하지만, 이를 강건한 낮은 수준의 제어로 변환하는 데 어려움이 있음을 확인시켜 줍니다.
- **OOD 객체에 대한 일반화**: VLA 모델은 OOD 객체에 대해 견고한 의도를 보였다. 그러나 잡기 성공률은 목표 객체만 OOD일 때도 크게 달라지는 등 의미 있는 차이를 보였습니다. 흥미롭게도 일부 OOD 원천 객체(예: 콜라 캔)가 BridgeV2의 일반 객체(예: 당근)보다 더 높은 잡기 성공률을 보일 때도 있어, 지각과 행동 간의 취약한 결합을 시사합니다.
- **언어 능력 보존**: 언어 변화(Lang. Action, Lang. Negation, Lang. Appearance)가 있을 때 모든 모델에서 성능 하락이 나타났다. 작업 지침을 재구성하여 미세 조정하는 것은 `Lang. Action`의 의도를 개선했지만, 실행으로 이어지지 않았다. 이는 VLA 학습 후 VLM의 언어 능력이 완전히 보존되지 않음을 나타냅니다. Magma는 공동 시각-언어 공동 훈련 덕분에 `Lang. Action` 범주에서 가장 우수한 강건성을 보였지만, 전반적인 언어 일반화 능력 상실은 유의미했습니다.
- **시각-언어 사고**: VLA 모델은 다중 모드 모호성(예: 상식 + 방해물)에 취약했다. "토끼가 가장 좋아하는 야채" 작업에 토끼 인형이 추가되었을 때, `잘못된 객체 시도율 (Wrong Object Attempt Rate)`이 급증했습니다. "오렌지 주스" 작업에 실제 오렌지가 방해물로 추가되었을 때는 모델이 완전히 무너지는 경향을 보였는데, 이는 언어적 선험 지식이 시각적 접지(visual grounding)를 압도하여 체계적인 오작동을 유발할 수 있음을 나타냅니다.
- PaliGemma (VLM 백본)는 VLA 미세 조정 전 VQA 작업에서 복잡한 언어/상식 변화에 대해서도 우수한 이해도를 보여, VLA 학습이 VLM의 내재적 능력을 저해할 수 있음을 시사합니다.

## 🧠 Insights & Discussion

- **시사점**: VLM 백본은 인상적인 의미론적 이해와 높은 수준의 계획(우수한 "의도")을 부여하지만, 이러한 능력을 분포 변화 상황에서 정밀한 모터 실행으로 안정적으로 전환하는 것은 여전히 주요 과제로 남아있습니다. 로봇 행동 데이터에 대한 미세 조정 과정에서 원래 VLM의 일반주의적 추론 능력이 저해될 수 있음이 밝혀졌습니다. 이는 VLM의 '좋은 의도'가 '정확한 행동'으로 이어지지 못하는 본질적인 간극을 시사하며, 로봇 시스템에 VLM을 통합하기 위한 개선된 아키텍처 설계의 필요성을 강조합니다.
- **한계**:
  - 현재 INT-ACT는 BridgeV2 데이터셋 및 특정 로봇, 센서 구성에 기반하므로, 더 많은 로봇 구현체로 확장하여 결과의 설득력을 높일 필요가 있습니다.
  - 가능한 객체 및 언어 분포 변화가 이론적으로 무한하므로, LLM 또는 3D 생성 모델과 같은 기술을 통합하여 OOD 작업 생성 프로세스를 자동화하고 통계적 신호를 더욱 강화하는 것이 바람직합니다.
  - INT-ACT는 SimplerEnv를 기반으로 시뮬레이션 환경에서 개발되었기 때문에 접근성이 높지만, SimplerEnv가 실제 세계 성능과 일치하도록 구축되었음에도 불구하고 심투리얼(sim2real) 간극을 완전히 해소하지 못했습니다. 실제 세계로의 확장은 향후 가치 있는 단계가 될 것입니다.
- **향후 연구**: VLM의 내재적 능력을 더 잘 활용하기 위한 VLA 아키텍처 설계를 개선하고, 접지(grounding) 또는 모듈화된 접근 방식(예: [15, 38, 41])을 통합하며, 더 강력하고 시각적 접지 능력이 뛰어난 VLM을 백본으로 사용하는 것을 탐색해야 합니다.

## 📌 TL;DR

본 논문은 Vision-Language-Action (VLA) 모델의 일반화 능력을 탐색하기 위한 50개 작업으로 구성된 새로운 시뮬레이션 벤치마크 INT-ACT를 소개합니다. 연구 결과, VLM 백본은 강력한 상위 수준의 이해("의도")를 제공하지만, OOD(out-of-distribution) 객체, 복잡한 언어, 또는 다중 모드 모호성 하에서 정밀한 액션을 안정적으로 실행하지 못하는 심각한 "의도-행동 간극 (Intention-Action Gap)"을 발견했습니다. 또한, 액션 데이터에 대한 미세 조정은 VLM의 원래 언어 및 추론 능력을 저해할 수 있음을 보여줍니다. 본 연구는 이러한 지각-행동 간극을 해소하기 위한 더 나은 VLA 아키텍처 설계를 촉구합니다.
