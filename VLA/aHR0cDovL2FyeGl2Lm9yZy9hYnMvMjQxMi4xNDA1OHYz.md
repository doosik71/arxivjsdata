# Towards Generalist Robot Policies: What Matters in Building Vision-Language-Action Models

Xinghang Li, Peiyan Li, Minghuan Liu, Dong Wang, Jirong Liu, Bingyi Kang, Xiao Ma, Tao Kong, Hanbo Zhang, Huaping Liu

## 🧩 해결하고자 하는 문제

기존의 비전-언어-행동(VLA) 모델들이 로봇 작업을 수행하는 데 유망한 성능을 보였음에도 불구하고, VLM(Vision-Language Model)을 VLA로 전환하는 과정에는 백본, 행동 예측 공식, 데이터 분포, 훈련 방식 등 다양한 설계 선택 사항들이 존재하며, 이들에 대한 체계적인 이해가 부족합니다. 이 연구는 VLA의 성능에 결정적인 영향을 미치는 주요 요인들을 밝히고, 다음 세 가지 핵심 질문에 답하는 것을 목표로 합니다:

- 어떤 VLM 백본을 선택해야 하는가?
- VLA 아키텍처를 어떻게 구성해야 하는가?
- 교차-구현체(cross-embodiment) 데이터를 언제 추가해야 하는가?

## ✨ 주요 기여

- **VLA의 효과성 및 효율성 입증:** 사전 학습된 VLM을 기반으로 구축된 VLA가 일반 로봇 정책(generalist robot policies)에 효과적이고 효율적인 경로임을 시뮬레이션 및 실제 환경 실험에서 SOTA(State-of-the-Art) 모델들을 능가하는 성능으로 입증했습니다.
- **최적의 VLM 백본 식별:** 8가지 VLM 백본에 대한 광범위한 연구를 통해 KosMos와 Paligemma 백본이 가장 우수한 성능을 보이며, 이는 대규모 비전-언어 데이터셋에 대한 충분한 사전 학습이 VLA 성능에 필수적임을 강조합니다.
- **최적의 VLA 아키텍처 제안:** 연속적인 행동 공간이 이산적인 행동 공간보다 일관되게 우수하며, 과거 관찰 이력(historical context)을 통합하는 것이 성능 향상에 중요함을 발견했습니다. 특히, "정책 헤드(policy head)"를 통해 이력을 융합하는 구조가 다른 방식보다 더 효과적이고 효율적임을 보였습니다.
- **교차-구현체 데이터 활용 전략:** 교차-구현체 데이터로 사전 학습하는 것이 최종 성능을 크게 향상시키지는 않지만, 교차-구현체 사전 학습 모델을 목표 데이터셋으로 후속 미세 조정(post-training)하는 것이 성능 향상에 유의미하며, 도메인 내(in-domain) 데이터 사용도 도움이 됨을 확인했습니다. 사전 학습은 특히 소수샷(few-shot) 학습 성능을 개선합니다.
- **RoboVLMs 프레임워크 공개:** 모든 VLM을 VLA로 쉽게 전환할 수 있는 유연하고 사용하기 쉬운 오픈소스 프레임워크인 RoboVLMs를 제안하고 공개했습니다. 이는 새로운 VLM 통합 및 다양한 설계 선택의 자유로운 조합을 지원합니다.

## 📎 관련 연구

- **일반 로봇 정책:** 인간의 지시에 따라 물리적 환경을 인지, 추론, 상호작용하는 일반화 가능한 로봇 정책 구축은 오랜 난제입니다. VLM을 로봇 데이터에 미세 조정하여 VLA를 형성하는 방식이 활발히 탐구되고 있습니다.
- **VLA 외의 일반 정책:** 비디오 모델 기반 정책, 혹은 처음부터 학습하는 다양한 일반 정책들이 존재합니다.
- **기존 VLA 분류:** 기존 연구들을 행동 공간(연속/이산) 및 이력 정보 통합 방식(단일 단계/이력 모델링, 정책 헤드/인터리브드)에 따라 분류하여 분석합니다. (예: RT-1, RT-2, Octo, GR-1, RoboFlamingo 등)
- **대규모 데이터 활용:** Open X-Embodiment (OXE) [35]와 같은 대규모 교차-구현체 로봇 조작 데이터셋을 활용하여 VLA 성능을 향상시키려는 노력이 있습니다.

## 🛠️ 방법론

이 연구는 VLA 설계의 핵심 질문들에 답하기 위해 RoboVLMs라는 통일된 프레임워크를 사용하여 체계적인 실험을 수행합니다.

1. **RoboVLMs 프레임워크:**
   - 어떤 VLM이든 최소한의 노력으로 VLA로 전환할 수 있는 유연하고 오픈소스인 프레임워크를 제공합니다.
   - 4가지 VLA 구조, 8가지 VLM 백본, 3가지 훈련 데이터 레시피를 실험하여 공정한 비교를 가능하게 합니다.
2. **행동 전처리 및 예측:**
   - **행동 정규화:** 그리퍼의 6D 포즈와 개폐 상태를 포함하는 7-DoF 행동의 각 차원을 학습 데이터의 1사분위수 및 99사분위수를 사용하여 $[-1, 1]$ 범위로 정규화합니다.
     $$ \tilde{a}\_i = 2 \times (a_i' - a_i^{1st}) / (a_i^{99th} - a_i^{1st}) - 1 $$
        여기서 $a_i'$는 클램프된 값입니다.
   - **행동 이산화 (이산 행동 공간용):** 정규화된 행동 $\tilde{a}$를 각 차원별로 256개의 구간으로 이산화하여 VLM의 토크나이저에 사용될 이산 토큰으로 매핑합니다.
   - **연속 행동 예측:** 예측된 행동 시퀀스 $\hat{a}_{t:t+L-1}$와 실제 값 $\tilde{a}_{t:t+L-1}$ 사이의 MSE(위치/방향) 및 BCE(그리퍼 개폐) 손실을 최소화합니다.
     $$ \ell*{VLA} = \sum*{i=t}^{t+L-1} \left( MSE(\hat{a}_{i,pose}, \tilde{a}_{i,pose}) + \lambda \cdot BCE(a*{i,gripper}, \tilde{a}*{i,gripper}) \right) $$
   - **이산 행동 예측:** 각 행동 차원 $j$에 대해 행동 토큰 $ACT_i$를 예측하며, VLM 훈련과 유사하게 교차 엔트로피(CE) 손실을 사용합니다.
     $$ \ell*{VLA} = \sum*{i=t}^{t+L-1} \sum*{j=1}^{7} CE([ACT]*{j}^i, \tilde{a}\_j^i) $$
3. **VLA 구조 분류 및 구현:**
   - **단일 단계 모델 (One-step Models):** 현재 시점 $t$의 관찰 $o_t$와 언어 지시 $l_{prompt}$만을 사용하여 미래 행동 시퀀스 $\hat{a}_{t:t+L-1}$를 예측합니다.
     - **연속 행동 모델:** VLM 백본이 학습 가능한 토큰 $[LRN]$을 예측하고, MLP가 이를 이용해 행동 벡터를 예측합니다.
     - **이산 행동 모델:** VLM이 텍스트처럼 이산화된 행동 토큰을 직접 예측합니다.
   - **인터리브드 연속 행동 모델 (Interleaved-Continuous-Action Models):** 과거 관찰-행동 시퀀스 $O_t$를 VLM 입력 토큰 시퀀스로 구성하고, VLM이 이력을 융합한 후 마지막 행동 토큰을 기반으로 MLP를 통해 행동을 예측합니다.
   - **정책 헤드 연속 행동 모델 (Policy-Head-Continuous-Action Models):** VLM은 각 시점 $t$에서 단일 단계 멀티모달 표현 $[LRN]_t$만 제공하며, RNN, 트랜스포머 또는 확산 모델과 같은 추가적인 정책 헤드 $h$가 이력 정보를 모델링하여 행동을 예측합니다.
4. **벤치마크 환경:**
   - **시뮬레이션:** CALVIN [32] (다중 작업 테이블탑 조작), SimplerEnv [40] (실제-시뮬레이션 환경).
   - **실제 환경:** 7-DoF Kinova Gen3 로봇 팔과 Robotiq 2F-85 그리퍼, 헤드 및 손목 카메라로 구성된 플랫폼에서 105가지 조작 작업의 실제 데이터셋을 활용합니다. 모델은 20가지 작업에 대해 각각 5가지 설정(단순, 새로운 스킬 설명, 미확인 방해물, 미확인 대상 객체, 미확인 배경)으로 평가됩니다.

## 📊 결과

- **VLA의 우수성:**

  - RoboVLMs로 구축된 최적의 VLA(KosMos P.H.)는 CALVIN 벤치마크에서 기존 SOTA 모델인 GR-1을 크게 능가하며, 특히 5개 연속 작업 성공률에서 30.3%p의 절대적 성능 향상을 보였습니다.
  - SimplerEnv에서도 WidowX + Bridge 및 Google Robot 환경 모두에서 가장 높은 평균 성능을 달성했습니다.
  - 실제 로봇 시나리오에서 모든 평가 설정(단순, 새로운 스킬 설명, 미확인 방해물, 미확인 배경, 미확인 객체)에서 기존 VLA(Octo-Base, OpenVLA)를 능가하는 효과성과 견고성을 보였으며, 훈련 데이터셋에 없는 자기 수정(self-correction) 능력까지 나타냈습니다.

- **VLM 백본의 영향:**

  - KosMos [36] 및 Paligemma [3] 백본이 다른 백본들에 비해 월등히 우수한 성능을 보였습니다. 이는 대규모 비전-언어 데이터셋에 대한 충분한 사전 학습이 VLA 성능에 결정적임을 시사합니다.

- **VLA 구조의 영향:**

  - **연속 행동 공간:** 이산 행동 공간보다 일관되게 우수하며, 특히 작업 시간이 길어질수록 성능 차이가 두드러집니다.
  - **이력 관찰:** 이력 관찰을 입력으로 통합하는 모델이 단일 단계 모델보다 훨씬 높은 성공률을 보이며, 이력 길이를 늘리면 성능이 향상됩니다.
  - **정책 헤드:** 이력 통합 방식 중 "정책 헤드"를 통한 융합이 "인터리브드" 방식보다 우수하며, 이는 VLM의 비전-언어 융합 능력을 유지하면서 이력 정보를 효과적으로 통합하기 때문으로 분석됩니다.
  - **확장성:** 더 큰 VLM 모델은 데이터 효율성을 향상시켜, 더 적은 데이터로 더 높은 성능을 달성합니다.

- **교차-구현체 데이터 활용 전략:**
  - **사전 학습 (Pre-train):** 교차-구현체 데이터로만 사전 학습하는 것은 최종 성능에 일관되게 유의미한 개선을 가져오지 않았습니다.
  - **도메인 내 데이터:** 다른 작업이라도 도메인 내 데이터를 추가하는 것이 모델 성능 향상에 더 효과적이었습니다.
  - **후속 학습 (Post-train):** 교차-구현체 데이터로 사전 학습한 모델을 목표 데이터셋으로 후속 미세 조정하는 것이 주목할 만한 성능 향상(예: Google Robot에서 48% → 52%)을 가져왔습니다.
  - **소수샷 학습:** 교차-구현체 사전 학습은 CALVIN 벤치마크의 소수샷 학습 설정에서 단일 작업 실행 성공률을 17.2%p 향상시키는 등 효과적인 표현 학습에 기여했습니다.

## 🧠 통찰 및 논의

- **VLA의 필요성:** VLM 기반 VLA는 기존 방법론을 훨씬 뛰어넘는 성능과 일반화 능력을 보여주며, 일반 로봇 정책을 위한 유망한 경로임이 입증되었습니다.
- **VLM 백본 선택의 중요성:** 대규모 비전-언어 데이터셋에서 충분히 사전 학습된 VLM은 강력한 시각-언어 정렬을 제공하여 로봇 조작 기술 학습을 위한 견고한 기반을 마련합니다.
- **VLA 구조 설계의 최적화:** 다단계 이력 관찰 및 연속 행동 공간을 사용하고, 특히 정책 헤드를 통한 이력 융합이 성능, 일반화, 데이터 효율성 측면에서 가장 효과적인 구조입니다.
- **데이터 전략:** 교차-구현체 데이터는 사전 학습만으로는 한계가 있지만, 목표 데이터셋으로 후속 학습하거나 소수샷 학습 환경에서 일반화 능력을 향상시키는 데 기여합니다. 도메인 내 데이터의 중요성도 확인되었습니다.

**한계점:**

- VLM 내 멀티모달 상호작용 구조(예: 어텐션 마스크, MoE)는 기존 VLM을 빠르게 확장하기 위해 유지되었으나, 행동과의 특화된 상호작용 설계가 더 나은 성능을 낼 수 있습니다.
- VLA의 분류 및 공식화는 단순화되고 제한적입니다.
- 행동 토큰화, 정책 헤드, 훈련 목표(예: VQ-VAE, 확산 모델, flow matching)에 대한 탐색이 충분하지 않았습니다.
- 고려된 VLM 백본의 종류가 제한적입니다.
- 대규모 모델의 실시간 로봇 제어 배포는 여전히 중요한 과제입니다.

**향후 연구:**

- VLM 내부 구조, 정책 헤드, 훈련 목표에 대한 더 세분화된 설계 탐색.
- 긴 시간 스케일, 복잡한 작업 지시(예: 아침 식사 만들기), 단계별 추론, 의미 있는 물리적 상호작용을 처리할 수 있는 정책 개발.

## 📌 TL;DR

이 논문은 VLM 기반 VLA(Vision-Language-Action) 모델을 구축하는 데 있어 핵심적인 설계 요소를 체계적으로 분석합니다. 저자들은 RoboVLMs라는 유연한 오픈소스 프레임워크를 개발하여 광범위한 실험을 수행했으며, 그 결과 VLA가 일반 로봇 정책을 위한 효과적이고 효율적인 접근 방식임을 입증했습니다. 특히, KosMos 및 Paligemma와 같이 충분히 사전 학습된 VLM 백본, 연속 행동 공간과 이력 융합을 위한 정책 헤드 아키텍처, 그리고 교차-구현체 데이터로 후속 학습하는 전략이 시뮬레이션 및 실제 로봇 작업에서 SOTA 성능을 달성하는 데 가장 중요함을 밝혀냈습니다. 이는 로봇 커뮤니티에 VLA 설계에 대한 실용적인 가이드라인을 제공합니다.
