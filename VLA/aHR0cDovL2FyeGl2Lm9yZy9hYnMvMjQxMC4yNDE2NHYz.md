# $\pi_0$: A Vision-Language-Action Flow Model for General Robot Control

Kevin Black, Noah Brown, Danny Driess, Adnan Esmail, Michael Equi, Chelsea Finn, Niccolo Fusai, Lachy Groom, Karol Hausman, Brian Ichter, Szymon Jakubczak, Tim Jones, Liyiming Ke, Sergey Levine, Adrian Li-Bell, Mohith Mothukuri, Suraj Nair, Karl Pertsch, Lucy Xiaoyang Shi, James Tanner, Quan Vuong, Anna Walling, Haohuan Wang, Ury Zhilinsky

## 🧩 Problem to Solve

로봇 학습은 유연하고 범용적이며 정교한 로봇 시스템의 잠재력을 실현하고 인공지능의 심오한 질문에 답할 수 있는 큰 가능성을 가지고 있습니다. 그러나 현실 세계에서 효과적인 로봇 시스템을 위한 범용성을 달성하는 데는 데이터, 일반화 및 견고성 측면에서 주요한 난관에 직면해 있습니다. 기존의 비전-언어 모델(VLM)은 추상적인 물리적 상호작용에 기반을 두므로, 실제 물리적 세계에 기반을 둔 다재다능한 AI 시스템으로 발전하려면 실제 로봇 에이전트로부터 얻은 데이터를 통해 학습해야 합니다. 범용 로봇 정책(로봇 파운데이션 모델)을 개발하기 위해서는 매우 큰 규모의 데이터, 다양한 데이터 소스를 효과적으로 활용할 수 있는 적절한 모델 아키텍처, 그리고 정교하고 미묘한 동작을 표현할 수 있는 능력, 마지막으로 올바른 학습 레시피가 필요합니다.

## ✨ Key Contributions

- **새로운 범용 로봇 정책 아키텍처 ($\pi_0$) 제안:** 사전 학습된 비전-언어 모델(VLM) 백본과 흐름 매칭(Flow Matching) 기법을 기반으로 하는 새로운 범용 로봇 정책인 `$\pi_0$`를 제안합니다.
- **VLM 기반의 인터넷 규모 지식 계승:** PaliGemma와 같은 사전 학습된 VLM을 활용하여 인터넷 규모의 시맨틱 지식, 일반 지식, 시맨틱 추론 및 문제 해결 능력을 로봇 제어 모델에 통합합니다.
- **흐름 매칭을 통한 정교한 연속 액션 생성:** 액션 익스퍼트(Action Expert)와 흐름 매칭(확산 모델의 변형)을 사용하여 고주파수(최대 50Hz)의 연속적인 액션 분포를 모델링함으로써, 기존의 자기회귀 방식 VLA 모델의 한계를 극복하고 정교하고 유창한 조작 기술을 가능하게 합니다.
- **대규모 및 크로스-엠바디먼트 데이터 학습:** 7가지 로봇 구성과 68가지 작업에서 수집된 10,000시간 이상의 정교한 조작 데이터를 포함하여, 다양한 단일/양팔 로봇 및 모바일 조작기를 아우르는 대규모의 다양한 크로스-엠바디먼트 데이터셋으로 모델을 학습시킵니다. 이는 로봇 조작 모델에 사용된 데이터 중 가장 큰 규모입니다.
- **사전 학습/후속 학습(Pre-training/Post-training) 레시피:** 대규모 언어 모델(LLM)과 유사하게, 광범위한 지식과 일반화를 위한 사전 학습과 특정 작업에 대한 숙련도와 견고성을 위한 고품질 데이터 기반의 후속 학습 단계를 포함하는 효과적인 학습 레시피를 제안합니다.
- **정교한 조작 및 일반화 능력 입증:** 언어 명령 따르기, 새로운 작업에 대한 미세 조정, 빨래 접기 및 상자 조립과 같은 복잡한 다단계 작업 수행 능력 등 다양한 실제 로봇 실험에서 `$\pi_0$`의 우수한 성능을 입증하며, 기존 로봇 파운데이션 모델을 능가하는 정교함과 범용성을 보여줍니다.

## 📎 Related Works

- **비전-언어-액션(VLA) 모델:** RT-2 [7], OpenVLA [24], TinyVLA [55]와 같이 사전 학습된 VLM을 로봇 제어에 미세 조정하는 최근 연구와 밀접하게 관련되어 있습니다. `$\pi_0$`는 자기회귀 이산화(autoregressive discretization) 대신 흐름 매칭을 사용하여 연속적인 액션을 처리한다는 점에서 차이가 있습니다.
- **액션 생성을 위한 확산 모델:** Diffusion Policy [9], [60] 등 확산 모델을 액션 생성에 사용하는 연구가 있습니다. `$\pi_0$`는 사전 학습된 VLM 백본을 사용한다는 점에서 차별화됩니다.
- **확산 모델과 언어 모델의 하이브리드:** Transfusion [59], Liu et al. [29]와 같이 사전 학습된 언어 모델을 확산 모델과 결합하여 이미지 생성을 수행하는 연구들이 있습니다. `$\pi_0$`는 이러한 개념을 VLA 모델에 적용하여 고주파수 액션 청크를 생성하는 최초의 흐름 매칭 VLA 모델을 제시합니다.
- **대규모 로봇 학습:** 초기 연구는 로봇 그립 [18, 37]이나 푸싱 [56]과 같은 간단한 작업을 위해 자율 데이터 수집을 활용했습니다. 최근 OXE [10], Bridge v2 [52], DROID [23]와 같은 고품질 데이터셋이 수집되었지만, 주로 객체 재배치 및 간단한 가구 조작에 초점을 맞춥니다. `$\pi_0$`는 훨씬 더 큰 10,000시간 이상의 데이터셋을 활용하여 복잡하고 정교한 동작을 학습합니다.
- **복잡하고 정교한 행동:** 신발끈 묶기 [58] 또는 새우 요리 [17]와 같은 정교한 행동을 다룬 이전 연구들이 있지만, `$\pi_0$`는 물리적 정교함과 조합적 복잡성을 결합한 훨씬 긴 작업들을 수행할 수 있습니다.

## 🛠️ Methodology

1. **모델 아키텍처 (`$\pi_0$`)**
   - **백본:** PaliGemma [5] VLM을 기반으로 하는 언어 모델 트랜스포머 백본으로, 이미지 인코더는 로봇의 시각적 관측값($I_{1}^{t}, ..., I_{n}^{t}$)을 언어 토큰과 동일한 임베딩 공간으로 임베딩합니다.
   - **로봇 특화 입력 및 출력:** 로봇의 고유 수용 감각 상태($q^t$)와 로봇 액션($A_t = [a_t, a_{t+1}, ..., a_{t+H-1}]$)을 추가하여 백본을 확장합니다. 여기서 $H=50$으로 미래 액션 청크(action chunk)를 예측합니다.
   - **액션 전문가(Action Expert):** VLM 백본에 추가된 별도의 소규모 가중치 집합(약 300M 파라미터)으로, 로봇 특화 입력과 노이즈가 추가된 액션 청크($A^t_\tau$)를 처리하는 데 사용됩니다.
   - **연속 액션 모델링:** 조건부 흐름 매칭(Conditional Flow Matching) [28, 32]을 사용하여 액션의 연속적인 분포를 모델링합니다. 이는 높은 정밀도와 다중 모달 모델링 기능을 제공하여 고주파수 정교한 작업에 특히 적합합니다.
   - **학습 목표:** 액션 토큰은 조건부 흐름 매칭 손실 `$L_{\tau}(\theta) = E_{p(A_t|o_t),q(A^t_\tau|A_t)} ||v_{\theta}(A^t_\tau,o_t) - u(A^t_\tau|A_t)||^2$`로 감독됩니다. 여기서 `$A^t_\tau = \tau A_t + (1-\tau)\epsilon$` (노이즈 액션)이고, `$u(A^t_\tau|A_t) = \epsilon - A_t$` (디노이징 벡터 필드)입니다.
   - **추론:** `$A^0_t \sim N(0,I)$`의 무작위 노이즈에서 시작하여 학습된 벡터 필드를 `$\tau=0$`에서 `$\tau=1$`까지 통합하여 액션을 생성합니다. `$A^{\tau + \delta}_{t} = A^{\tau}_{t} + \delta v_{\theta}(A^t_\tau,o_t)$`와 같은 전방 오일러(Forward Euler) 통합 규칙을 사용하며, 실험에서는 10단계 통합을 사용합니다.
   - **어텐션 마스크:** 3개의 블록(VLM 입력, 로봇 상태, 노이즈 액션)으로 구성된 블록 단위 인과적(blockwise causal) 어텐션 마스크를 사용하여 VLM 사전 학습의 분포 변화를 최소화하고 추론 효율성을 높입니다.
2. **데이터 수집 및 학습 레시피**
   - **사전 학습 단계:**
     - **데이터셋:** 자사의 정교한 조작 데이터셋(7개 로봇 구성, 68개 작업, 903M 타임스텝)과 OXE [10], Bridge v2 [52], DROID [23]를 포함한 오픈 소스 데이터셋을 가중 조합한 대규모 혼합 데이터(약 10,000시간, 10억 개 이상 타임스텝)를 사용합니다.
     - **언어 라벨:** 작업 이름과 약 2초 길이의 하위 궤적에 대한 세분화된 세그먼트 주석을 활용합니다.
     - **목표:** 광범위하고 일반적인 물리적 기능을 습득하고, 다양한 상황과 오류 복구 능력을 갖춘 기본 모델을 훈련합니다.
   - **후속 학습 단계:**
     - **데이터셋:** 특정 하위 작업에 맞춰 모델을 전문화하기 위해 더 작고 고품질로 선별된 작업별 데이터셋을 사용합니다.
     - **목표:** 모델이 원하는 하위 작업을 숙련되고 유창하게 수행할 수 있도록 합니다.
     - **언어 및 고수준 정책:** 테이블 정리와 같은 복잡한 시맨틱 추론 및 고수준 전략이 필요한 경우, 고수준 VLM 정책이 상위 작업을 하위 언어 명령으로 분해하고 `$\pi_0$`가 이를 따르도록 합니다.

## 📊 Results

- **아웃-오브-박스(Out-of-Box) 평가:**
  - `$\pi_0$`는 사전 학습만 완료된 상태에서도 셔츠 접기, 테이블 정리(쉬움/어려움), 식료품 포장, 토스트 꺼내기 등 5가지 작업에서 OpenVLA [24], Octo [50] 및 `$\pi_0$`-small (VLM 사전 학습 없는 소규모 버전)을 포함한 모든 기준 모델보다 월등히 뛰어난 성능을 보였습니다.
  - 특히 셔츠 접기와 쉬운 테이블 정리 작업에서는 거의 완벽한 성공률을 달성했습니다. `$\pi_0$`-small도 OpenVLA와 Octo를 능가하여 `$\pi_0$` 아키텍처의 강점을 보여주었습니다.
- **언어 명령 따르기:**
  - `$\pi_0$`는 테이블 정리, 테이블 세팅, 식료품 포장 작업에서 `$\pi_0$`-small보다 훨씬 높은 언어 명령 따르기 정확도를 보여주었습니다.
  - 인간 전문가가 제공하는 중간 명령(`$\pi_0$`-human)과 고수준 VLM 정책이 제공하는 명령(`$\pi_0$`-HL)을 통해 성능이 크게 향상되었으며, 이는 VLM 사전 학습이 로봇 작업의 언어 이해 능력을 향상시킴을 시사합니다.
- **새로운 정교한 작업 학습 (미세 조정):**
  - `$\pi_0$`는 그릇 쌓기, 수건 접기, 전자레인지에 용기 넣기, 페이퍼 타월 교체, 서랍에 물품 넣기 등 사전 학습 데이터와 다른 새로운 정교한 작업에서도 OpenVLA, Octo, ACT [57], Diffusion Policy [9] 등 다른 방법론보다 전반적으로 우수한 성능을 보였습니다.
  - 사전 학습은 사전 학습 데이터와 유사한 작업에서 큰 성능 향상을 가져왔지만, 새로운 작업에서도 종종 미세 조정만으로 학습하는 경우보다 최대 2배의 성능 향상을 보였습니다.
- **복잡한 다단계 작업 마스터링:**
  - `$\pi_0$`는 빨래 접기(정지/모바일 로봇), 건조기 비우기, 테이블 정리, 상자 조립, 즉석식품 용기 포장, 계란 포장 등 다른 방법론으로는 해결하기 어려웠던 광범위하고 도전적인 다단계 작업들을 성공적으로 수행했습니다.
  - 완전한 사전 학습 및 미세 조정 레시피가 전반적으로 최고의 성능을 보였으며, 특히 어려운 작업에서 사전 학습의 중요성을 강조하며 "아웃-오브-박스" 및 "스크래치(from scratch)" 버전 대비 상당한 개선을 이루었습니다.
  - 이러한 도전적인 작업에서 평균 50% 이상의 최고 점수를 달성하며, 학습된 정책을 통한 정교한 로봇 조작 분야에서 새로운 최첨단 성능을 제시했습니다.

## 🧠 Insights & Discussion

- **파운데이션 모델 패러다임의 유효성:** `$\pi_0$`는 VLM 사전 학습과 흐름 매칭을 결합한 로봇 파운데이션 모델 프레임워크가 정교하고 일반적이며 시간적으로 확장되는 로봇 제어에 매우 효과적임을 입증합니다.
- **사전 학습/후속 학습의 중요성:** LLM과 유사하게, 대규모의 다양한 데이터로 사전 학습하여 광범위한 지식과 오류 복구 능력을 습득하고, 고품질의 선별된 데이터로 후속 학습하여 숙련되고 유창한 작업 실행 능력을 확보하는 것이 로봇 학습에서도 중요합니다. 고품질 데이터만으로 학습하면 취약한 모델이 되고, 사전 학습만으로는 정교함이 부족할 수 있습니다.
- **한계점 및 향후 연구:**
  - 사전 학습 데이터셋의 최적 구성(어떤 유형의 데이터가 가장 유용하며 어떻게 가중치를 부여해야 하는지)에 대한 포괄적인 이해가 필요합니다.
  - 거의 완벽한 성능을 달성하기 위해 필요한 데이터의 양과 종류를 예측하는 것은 여전히 미해결 문제입니다.
  - 자율 주행, 내비게이션, 다리 달린 로봇 보행과 같이 훨씬 더 이질적인 영역에까지 이러한 "보편성"이 확장되는지에 대한 추가 연구가 필요합니다.

## 📌 TL;DR

`$\pi_0$`는 일반적인 로봇 제어를 위한 새로운 비전-언어-액션(VLA) 흐름 모델입니다. 이 모델은 사전 학습된 VLM 백본(PaliGemma)을 활용하여 인터넷 규모의 시맨틱 지식을 통합하고, 흐름 매칭(Flow Matching) 기법을 사용하여 연속적이고 고주파수(최대 50Hz)의 액션 청크(Action Chunk)를 생성함으로써 복잡하고 정교한 조작 작업을 가능하게 합니다. 10,000시간 이상의 로봇 데이터를 포함하는 대규모의 다양한 크로스-엠바디먼트(Cross-embodiment) 데이터셋으로 사전 학습하고, 특정 작업에 대해 후속 학습(Post-training)을 수행하는 투-스테이지(Two-stage) 학습 방식을 사용합니다. 실험 결과, `$\pi_0$`는 기존의 로봇 파운데이션 모델 및 특화된 조작 방법에 비해 다양한 아웃-오브-박스(Out-of-box) 작업, 언어 지시 따르기, 새로운 정교한 작업 학습 및 복잡한 다단계 작업(예: 세탁물 접기, 상자 조립)에서 월등히 뛰어난 성능을 보였습니다. 이는 사전 학습을 통해 로봇이 광범위한 지식을 습득하고, 후속 학습을 통해 특정 작업의 숙련도를 높이는 것이 효과적임을 시사합니다.
