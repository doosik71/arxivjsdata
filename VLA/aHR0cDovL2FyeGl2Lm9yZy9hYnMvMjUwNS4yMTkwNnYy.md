# ChatVLA-2: Vision-Language-Action Model with Open-World Embodied Reasoning from Pretrained Knowledge

Zhongyi Zhou, Yichen Zhu, Junjie Wen, Chaomin Shen, Yi Xu

## 🧩 Problem to Solve

비전-언어-액션(VLA) 모델은 강력한 사전 훈련된 비전-언어 모델(VLM)을 활용함에도 불구하고, 특정 로봇 작업을 위한 미세 조정을 거치면서 핵심 역량을 상실하는 경향이 있습니다. 기존의 VLA 시스템은 VLM이 인식할 수 있는 모든 것을 인식하고, 수학 문제를 해결하며, 시각-공간 지능을 갖추는 것과 같은 "개방형 세상 실체화된 추론(Open-world embodied reasoning)" 능력이 부족합니다. 또한, 이러한 개방형 추론을 로봇의 실행 가능한 단계로 효과적으로 전환하는 "추론 따르기(Reasoning following)" 능력에도 어려움이 있습니다.

주요 과제는 다음과 같습니다:

- VLA 모델이 VLM의 사전 지식을 온전히 유지하고 이를 로봇 제어에서 뛰어난 일반화 능력을 달성하는 데 적극적으로 활용하는 방법입니다.
- 멀티모달 이해와 로봇 제어 간의 기능 공간 중첩으로 인해 발생하는 매개변수 공간 내의 충돌을 해결하여 사전 훈련된 지식의 손실을 방지해야 합니다.
- VLA 모델이 생성하는 로봇 동작이 내부 추론 과정과 정확하게 일치하는지 확인해야 합니다.

## ✨ Key Contributions

- **동적 전문가 혼합(Dynamic Mixture-of-Experts, MoE) 아키텍처:** VLM 백본 내에 동적 MoE를 도입하여 멀티모달 이해와 로봇 동작 간의 충돌하는 기능 공간을 효과적으로 분리하고 상호 이로운 표현을 보존합니다.
- **추론 따르기 강화 모듈(Reasoning Following Enhancement Module):** 모델의 내부 추론 과정과 동작 전문가의 출력을 더 밀접하게 정렬하도록 설계된 모듈을 제안합니다.
- **이단계 훈련 전략:**
  - 1단계: 사전 훈련된 멀티모달 지식을 보존하고 로봇 동작을 훈련하며 구성 요소 간의 연결을 설정하는 공동 훈련(co-training)을 수행합니다.
  - 2단계: VLM 백본을 고정하고 동작 전문가만 훈련하여 모델의 상위 계층에서 도출된 내부 추론과 일치하는 동작을 생성하도록 명시적으로 학습시킵니다.
- **개방형 세상 추론 및 일반화 능력 입증:** 수학 매칭 게임(수학 추론 및 OCR)과 장난감 배치 실험(공간 추론, 이전에 보지 못한 객체 및 방향 지시 해석)을 통해 모델이 사전 훈련된 VLM 지식을 효과적으로 활용하여 미세 조정 데이터의 한계를 뛰어넘는 추론 및 이해 능력을 보여주었습니다.
- **최첨단 성능 능가:** OpenVLA, DexVLA, $\pi_{0}$와 같은 기존 모방 학습 방법을 크게 능가하는 추론 및 이해 능력을 입증하여 진정으로 일반화 가능한 로봇 파운데이션 모델 개발에 상당한 진전을 이뤘습니다.

## 📎 Related Works

- **로봇 학습의 VLA 모델:** 모방 학습 분야에서 사전 훈련된 VLM을 활용하여 언어 이해와 관찰 이해를 가능하게 합니다.
  - DexVLA [2]: 본 연구의 기반 모델 아키텍처로 사용되었습니다.
  - ChatVLA [7]: 로봇 제어에 VLA 모델을 적용할 때 일반 지식이 크게 저하될 수 있음을 보여주었습니다.
  - OpenVLA [10], DexVLA [2], $\pi_{0}$ [1]: 최신 모방 학습 방법으로 본 연구의 성능 비교 대상입니다.
- **VLA 모델의 실체화된 추론:** 대규모 언어 모델(LLM)의 성공에서 영감을 받아 Chain-of-Thought (CoT) 방법론을 VLA 모델에 통합하여 로봇 시스템의 복잡한 추론 및 의사 결정 능력을 향상시킵니다.
  - Embodied-CoT [57], CoA-VLA [58], CoT-VLA [59]/VPP [60], DiffusionVLA [61], DexVLA [2], $\pi_{0.5}$ [3]: 이러한 모델들의 추론은 주로 훈련 데이터셋 내의 지식에 국한되어 일반화 능력에 한계가 있습니다. 본 연구는 VLM의 사전 훈련된 지식을 활용하여 이 한계를 극복합니다.

## 🛠️ Methodology

1. **기반 모델 아키텍처:**
   - DexVLA [2]를 기반으로 Qwen2-VL [62,6]을 핵심 VLM으로 채택합니다.
   - 로봇의 시각적 관찰을 언어 토큰과 동일한 임베딩 공간으로 투영하는 이미지 인코더를 사용합니다.
   - 사전 훈련된 1B ScaleDP [63] 모듈을 동작 전문가(action expert)로 활용합니다.
2. **동적 전문가 혼합(Dynamic Mixture-of-Experts, MoE):**
   - 다양한 멀티모달 입력을 효과적으로 처리하기 위해 동적 MoE 아키텍처를 통합합니다.
   - 시각 및 텍스트 입력의 특성에 따라 전문가 모듈을 동적으로 선택하는 적응형 라우팅 전략을 사용합니다.
   - 일부 전문가는 멀티모달 이해 및 로봇 제어와 같은 작업별 기능에 특화되고, 다른 전문가는 공간 추론과 같이 여러 작업에서 공유되는 상호 이로운 기능을 포착합니다.
   - LLM의 기존 아키텍처를 그대로 유지하면서 전문가 모듈을 선택적으로 활성화하여 VLM의 사전 훈련된 지식 손실을 방지합니다.
   - 실제로는 총 8개의 전문가를 사용하며, 추론 시 2개의 전문가를 동적으로 선택합니다.
3. **추론 따르기 강화 모듈(Reasoning Following Enhancement Module):**
   - 모델이 주어진 지시를 따를 뿐만 아니라 생성된 추론에 로봇 동작을 밀접하게 정렬하도록 합니다.
   - 원래의 관찰 임베딩을 MLP를 통해 투영된 추론 토큰으로 대체합니다.
   - 이 추론 표현을 현재 타임스텝 임베딩과 결합하여 스케일(scale) 및 시프트(shift) 매개변수 생성을 조건화함으로써 추론 맥락을 모델에 효과적으로 주입합니다.
   - 이 메커니즘은 동작 전문가의 *후반부 계층(latter-half layers)*에만 선택적으로 통합하여 개방형 세상 추론 시나리오를 견고하게 처리합니다.
4. **이단계 훈련 전략:**
   - **1단계: 개방형 세상 실체화된 추론 및 이해 능력 강화 (Co-training).**
     - 이미지-텍스트 데이터(COCO, TextVQA, GQA, 로봇 관련 이미지-텍스트 쌍, RoboPoint, 실제 환경 샘플)와 로봇 데이터(수학 매칭 게임 600개 궤적, 장난감 배치 300개 궤적)를 공동 훈련합니다.
     - 이미지-텍스트 데이터 대 로봇 데이터 비율은 1:3으로 유지합니다.
     - VLM의 사전 훈련된 멀티모달 지식과 로봇 동작 간의 연결을 설정하는 데 중점을 둡니다.
   - **2단계: VLA의 추론 따르기 능력 강화.**
     - 사전 훈련된 VLM 백본을 고정하고 동작 전문가만 훈련합니다.
     - 이를 통해 동작이 모델의 상위 계층에서 생성된 추론 결과를 정확하게 따르고 실행하여 일반화 가능한 로봇 제어를 보장합니다.

## 📊 Results

- **수학 추론 (수학 매칭 게임 - 개방형 세상):**
  - ChatVLA-2는 OCR 정확도 3.58/4, 수학 추론 정확도 1.73/2, 조작 성공률 **82.7%**를 달성했습니다.
  - 비교 대상인 최첨단 모델들(OpenVLA, DexVLA, $\pi_{0}$, ChatVLA)은 개방형 세상 시나리오에서 조작 작업 성공률이 거의 0에 가까웠습니다.
  - 훈련 내(in-domain) 설정에서는 ChatVLA-2가 다른 모델들과 비슷한 최첨단 수준의 성능을 보였습니다.
- **공간 추론 (장난감 배치 - 개방형 세상):**
  - ChatVLA-2는 객체 인식(타겟 객체 바운딩 박스 식별) 0.94, 평균 조작 성공률 **81.4%**를 달성했습니다.
  - 다른 최첨단 모델들은 객체 인식 및 조작 성공률에서 훨씬 낮은 성능을 보였습니다. 예를 들어, DexVLA는 0.12, ChatVLA는 0.35를 기록했습니다.
  - 훈련 내(in-domain) 설정에서는 ChatVLA-2가 다른 모델들과 비슷한 성능을 보였습니다.
- **어블레이션 연구:**
  - **전문가 혼합(MoE)의 중요성:** 동적 MoE가 개방형 세상 추론 및 이해를 위한 VLA 모델의 일반화에 결정적임을 확인했습니다. MoE가 없는 3B, 7B 밀집(dense) 모델은 개방형 세상 시나리오에서 OCR/수학 점수와 성공률이 크게 떨어졌습니다. 전문가의 수를 늘리는 것이 일반화 능력을 향상시키는 데 도움이 됩니다.
  - **이단계 훈련 전략:** 두 단계 모두 중요합니다. 2단계를 제거하면 개방형 세상 로봇 제어 성공률이 23%로 하락하여 1단계에서 생성된 추론이 동작 실행에 효과적으로 주입되지 않았음을 시사합니다. 1단계를 제거하면 OCR 및 수학 작업 모두에서 개방형 세상 추론 능력이 거의 0에 가까워져 이미지-텍스트 데이터와의 공동 훈련의 중요성을 강조합니다.
  - **추론-따르기 강화 모듈 주입 계층:** 추론 정보를 동작 전문가의 *후반부 계층*에 주입하는 것이 가장 효과적이며, 전반부 계층에 주입하면 동작 생성의 불안정성이 증가하여 작업 성공률이 감소하는 것을 발견했습니다.

## 🧠 Insights & Discussion

- ChatVLA-2는 사전 훈련된 VLM 지식을 성공적으로 활용하여 개방형 세상에서 실체화된 추론 및 동작을 가능하게 합니다. 이는 미세 조정된 VLA 모델에서 지식 손실이 발생하는 일반적인 문제를 해결합니다.
- 동적 MoE 아키텍처는 멀티모달 이해와 로봇 제어 간의 충돌하는 기능 공간을 효과적으로 분리하여, 두 영역 모두에서 뛰어난 성능을 발휘할 수 있도록 합니다.
- 이단계 훈련 전략은 일반적인 추론 능력을 먼저 습득하고, 로봇 동작이 이 추론을 충실히 따르도록 보장하는 데 필수적입니다.
- 모델은 명시적으로 훈련되지 않은 미지의 수학 문제, 손글씨 텍스트, 새로운 객체, 새로운 공간 지시에 대해 강력한 일반화 능력을 보여줍니다.
- **제한 사항:**
  - VLM의 사전 훈련된 지식을 완전히 유지하지 못하며, 로봇 데이터로 미세 조정하는 동안 일부 역량 손실은 불가피합니다.
  - 현재 방법은 주로 테이블탑 작업에 중점을 두고 있으며, 향후 모바일 매니퓰레이터 및 더 복잡한 실제 작업으로 확장하는 것을 목표로 합니다.

## 📌 TL;DR

**문제:** 기존 VLA 모델은 로봇 작업에 미세 조정하는 동안 VLM의 개방형 세상 추론 능력을 상실하는 경향이 있습니다.
**방법:** ChatVLA-2는 동적 전문가 혼합(MoE)을 도입하여 충돌하는 기능을 관리하고, 이단계 훈련 전략(1단계: 추론을 위한 공동 훈련, 2단계: 추론 따르기를 위한 동작 전문가 훈련)을 사용하여 이 문제를 해결합니다.
**결과:** ChatVLA-2는 사전 훈련된 VLM 지식을 효과적으로 활용하여 미지의 작업에서 강력한 개방형 세상 수학 추론, OCR, 공간 이해 능력을 달성하며, 최첨단 방법을 크게 능가하는 성능을 보였습니다.
