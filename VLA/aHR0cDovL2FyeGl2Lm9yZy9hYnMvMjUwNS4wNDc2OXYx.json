{
  "url": "http://arxiv.org/abs/2505.04769v1",
  "title": "Vision-Language-Action Models: Concepts, Progress, Applications and\n  Challenges",
  "authors": "Ranjan Sapkota, Yang Cao, Konstantinos I. Roumeliotis, Manoj Karkee",
  "year": 2025,
  "abstract": "Vision-Language-Action (VLA) models mark a transformative advancement in\nartificial intelligence, aiming to unify perception, natural language\nunderstanding, and embodied action within a single computational framework.\nThis foundational review presents a comprehensive synthesis of recent\nadvancements in Vision-Language-Action models, systematically organized across\nfive thematic pillars that structure the landscape of this rapidly evolving\nfield. We begin by establishing the conceptual foundations of VLA systems,\ntracing their evolution from cross-modal learning architectures to generalist\nagents that tightly integrate vision-language models (VLMs), action planners,\nand hierarchical controllers. Our methodology adopts a rigorous literature\nreview framework, covering over 80 VLA models published in the past three\nyears. Key progress areas include architectural innovations,\nparameter-efficient training strategies, and real-time inference accelerations.\nWe explore diverse application domains such as humanoid robotics, autonomous\nvehicles, medical and industrial robotics, precision agriculture, and augmented\nreality navigation. The review further addresses major challenges across\nreal-time control, multimodal action representation, system scalability,\ngeneralization to unseen tasks, and ethical deployment risks. Drawing from the\nstate-of-the-art, we propose targeted solutions including agentic AI\nadaptation, cross-embodiment generalization, and unified neuro-symbolic\nplanning. In our forward-looking discussion, we outline a future roadmap where\nVLA models, VLMs, and agentic AI converge to power socially aligned, adaptive,\nand general-purpose embodied agents. This work serves as a foundational\nreference for advancing intelligent, real-world robotics and artificial general\nintelligence. >Vision-language-action, Agentic AI, AI Agents, Vision-language\nModels",
  "citation": 24
}