# A Survey on Vision-Language-Action Models for Embodied AI

Yueen Ma, Zixing Song, Yuzheng Zhuang, Jianye Hao, Irwin King,Fellow, IEEE

## 🧩 Problem to Solve

로봇을 물리적 세계에서 움직여 작업을 수행하는 것은 인공 일반 지능(AGI)의 핵심 요소인 Embodied AI의 중요한 부분입니다. 기존 대규모 언어 모델(LLM)과 비전-언어 모델(VLM)의 성공을 바탕으로, 언어 조건부 로봇 작업을 해결하기 위해 행동 생성 능력을 갖춘 비전-언어-액션 모델(VLA)이라는 새로운 멀티모달 모델이 등장했습니다. 급변하는 VLA 연구 환경을 종합적으로 정리하고, VLA의 구성 요소를 분류하며, 주요 도전 과제와 미래 방향을 제시하는 포괄적인 조사가 필요합니다.

## ✨ Key Contributions

- **종합적인 검토:** Embodied AI 분야에서 새롭게 떠오르는 VLA 모델에 대한 최초의 포괄적인 설문조사를 제공합니다. VLA의 구성 요소, 아키텍처, 훈련 목표, 로봇 작업 등 다양한 측면을 다룹니다.
- **분류법:** 현재 로봇 시스템의 계층적 프레임워크(하위 수준 제어 정책, 상위 수준 작업 플래너)를 기반으로 VLA의 분류 체계를 제시하고, VLA의 다양한 필수 구성 요소를 논의합니다.
- **자원 요약:** VLA 훈련 및 평가에 필요한 실제 및 시뮬레이션 환경의 최근 데이터셋, 시뮬레이터, 벤치마크를 요약하고, 데이터 부족 및 불일치와 같은 현재 과제 해결을 위한 접근 방식을 논의합니다.
- **미래 방향:** 안전, 파운데이션 모델, 실제 배포 등 이 분야가 직면한 현재 과제와 유망한 미래 기회를 제시합니다.

## 📎 Related Works

이 조사는 VLA 모델에 초점을 맞춰 Embodied AI 분야의 기존 연구를 보완하고 확장합니다. 주요 관련 연구는 다음과 같습니다:

- **Foundation Models in Robotics:** 로봇 공학의 파운데이션 모델에 대한 이전 조사(예: [12], [14]) 및 LLM의 로봇 공학 적용에 대한 조사(예: [13]).
- **Unimodal Models:** 컴퓨터 비전(AlexNet, ResNet, ViT, SAM), 자연어 처리(RNN, LSTM, Transformer, BERT, GPT, LLaMA, ChatGPT), 강화 학습(DQN, PPO, Decision Transformer) 분야의 기반 모델들.
- **Vision-Language Models (VLM):** BLIP-2, LLaVA, Flamingo, PaLM-E 등 이미지와 텍스트를 연계하는 모델들. RT-2는 "VLA"라는 용어를 처음 사용하며 VLM을 로봇 작업에 적용했습니다.
- **World Models & Planning:** Dreamer와 같은 월드 모델, LLM을 활용한 계획(SayCan, Inner Monologue, ProgPrompt, ChatGPT for Robotics, CaP), 확산 모델(Diffusion Policy) 등.
- **Pretrained Visual Representations (PVRs):** CLIP, R3M, MVP, DINOv2, I-JEPA, Theia 등 시각 인코더의 품질을 높이는 방법론.

## 🛠️ Methodology

이 논문은 VLA를 비전 및 언어 멀티모달 입력을 처리하여 로봇 작업을 수행하는 로봇 액션을 생성할 수 있는 모든 모델로 정의하고, 세 가지 주요 연구 분야로 분류하여 포괄적으로 분석합니다.

### 1. VLA의 구성 요소 (Components of VLA)

- **강화 학습 (Reinforcement Learning):** Embodied AI의 기반을 다지고 VLA 발전을 돕습니다. DQN, Decision Transformer, Trajectory Transformer와 같은 모델은 Transformer 기반 VLA에 직접 영감을 주었습니다. RLHF(인간 피드백으로부터의 강화 학습)는 LLM을 로봇 학습에 적용하고, Reflexion 및 Eureka는 LLM을 활용한 새로운 RL 방법을 제시합니다.
- **사전 훈련된 시각 표현 (Pretrained Visual Representations, PVRs):** VLA 성능에 중요한 시각 인코더의 품질 향상에 중점을 둡니다.
  - **CLIP [25]:** 대규모 이미지-텍스트 쌍으로 훈련된 비전 인코더.
  - **R3M [26]:** 시간 대비 학습 및 비디오-언어 정렬을 통해 비디오 시퀀스 내 시간적 관계와 의미론적 관련성을 포착합니다.
  - **MVP [28]:** MAE(Masked Autoencoder)를 로봇 데이터셋에 적용하여 자기지도 학습을 수행합니다.
  - **Voltron [35]:** MAE 목표에 언어 조건화 및 언어 생성을 통합하여 언어-비전 정렬을 강화합니다.
  - **DINOv2 [36]:** 자기 증류 프레임워크를 통해 이미지-레벨 및 픽셀-레벨 특징을 학습합니다.
  - **I-JEPA [39]:** 공동 임베딩 예측 아키텍처를 기반으로 마스크드 패치 임베딩을 비교하여 저수준 이미지 특징을 효과적으로 포착합니다.
  - **Theia [40]:** 다양한 비전 파운데이션 모델(ViT, CLIP, SAM, DINOv2 등)을 단일 모델로 증류하여 성능을 향상시킵니다.
- **동역학 학습 (Dynamics Learning):** 모델이 전방 동역학($\hat{s}_{t+1} \leftarrow f_{fwd}(s_t, a_t)$) 또는 역동역학($\hat{a}_t \leftarrow f_{inv}(s_t, s_{t+1})$)을 이해하도록 하는 목표를 포함합니다.
  - **Vi-PRoM [48]:** 비디오를 구별하는 대비 자기지도 학습과 셔플된 비디오 프레임을 복구하는 시간적 동역학 학습을 포함합니다.
  - **MIDAS [50]:** 관찰로부터 액션을 예측하는 역동역학 예측 작업을 사전 훈련의 일부로 도입합니다.
  - **SMART [51]:** 전방/역동역학 예측과 마스크드 후행 제어(randomly masked hindsight control)를 포함하는 사전 훈련 방식을 제시합니다.
  - **MaskDP [49]:** 상태 및 액션 토큰을 모두 마스킹하여 재구성하는 마스크드 의사 결정 예측을 통해 전방 및 역동역학을 학습합니다.
- **월드 모델 (World Models):** 주어진 액션에 대한 미래 상태($\hat{s}_{t+1} \sim P(\hat{s}_{t+1}|s_t, a_t)$)를 예측하여 Embodied 에이전트의 모델 기반 제어 및 계획을 가능하게 합니다.
  - **Dreamer [55], DreamerV2 [56], DreamerV3 [57]:** 잠재 동역학 모델을 구축하기 위해 표현, 전환, 보상 모델을 사용하며 상상력을 통해 행동을 학습합니다.
  - **LLM 유도 월드 모델:** LLM의 상식적 지식을 활용하여 추상적 월드 모델(DECKARD [61]), PDDL(LLM-DM [62]), 또는 정책이자 월드 모델 역할(RAP [64], LLM-MCTS [66])을 생성합니다.
  - **시각 월드 모델:** 미래 상태의 이미지, 비디오 또는 3D 장면을 생성하여 새로운 궤적을 샘플링합니다 (Genie [69], 3D-VLA [70], UniSim [71]).
- **추론 (Reasoning):** LLM의 CoT(Chain-of-Thought) 추론 능력을 활용하여 Embodied AI에서 의사 결정 과정을 정교화합니다 (ThinkBot [75], ReAct [76], RAT [77], ECoT [78]).

### 2. 하위 수준 제어 정책 (Low-level Control Policies)

VLA 모델($\hat{a}_t \sim \pi_{\theta}(\hat{a}_t|p, s_{\le t}, a_{\lt t})$)은 시각 인코더와 언어 인코더를 액션 디코더와 통합하여 언어 지시를 실행하는 제어 정책 역할을 합니다. (Table III 참조)

- **비-트랜스포머 제어 정책:**
  - **CLIPort [31]:** CLIP과 Transporter 네트워크를 통합하여 언어 조건부 집기-놓기(pick-and-place) 기능을 제공합니다.
  - **BC-Z [79]:** 언어 지시 또는 인간 시연 비디오를 처리하여 zero-shot 작업 일반화를 달성합니다.
  - **UniPi [83]:** 의사 결정 문제를 텍스트 조건부 비디오 생성 문제로 간주하여, 생성된 비디오에서 역동역학을 통해 액션을 추출합니다.
- **트랜스포머 기반 제어 정책:**
  - **Gato [19]:** 단일 모델 파라미터 세트로 아타리 게임, 이미지 캡셔닝, 블록 쌓기 등 멀티모달, 멀티태스크, 멀티-embodiment 작업을 수행합니다.
  - **RT-1 [94]:** EfficientNet 기반 비전 인코더와 Transformer 디코더를 사용하여 이산화된 액션을 생성하고 과거 이미지를 참조하여 성능을 향상시킵니다.
  - **Q-Transformer [95]:** RT-1을 확장하여 Q-학습 방법론을 도입하고, 성공적인 시연뿐만 아니라 실패한 궤적도 학습에 활용합니다.
- **멀티모달 지시를 위한 제어 정책:**
  - **VIMA [126]:** 멀티모달 프롬프트(텍스트, 이미지, 비디오, 포인트)를 통해 복잡한 작업을 정의하고 모델의 일반화 능력을 향상시킵니다.
  - **MOO [93]:** RT-1에 OWL-ViT를 통합하여 멀티모달 프롬프트를 처리하고, 새로운 객체에 대한 일반화 능력을 강화합니다.
- **3D 비전 기반 제어 정책:**
  - **PerAct [87]:** 복셀 표현을 활용하여 적은 시연으로 효율적인 작업 학습을 가능하게 합니다.
  - **Act3D [88]:** 연속 해상도 3D 피처 필드를 도입하여 복셀화의 계산 비용 문제를 해결합니다.
- **확산 기반 제어 정책:**
  - **Diffusion Policy [104]:** 로봇 정책을 DDPM(Denoising Diffusion Probabilistic Model)로 공식화하여 멀티모달 액션 분포, 고차원 액션 공간 및 훈련 안정성을 달성합니다.
  - **Octo [107]:** 모듈식 오픈 프레임워크 디자인의 Transformer 기반 확산 정책으로, OXE 데이터셋을 활용하여 다양한 로봇 및 작업에 대한 일반화 능력을 보여줍니다.
  - **RDT-1B [110]:** DiT(Diffusion Transformer) 기반의 양손 조작을 위한 확산 파운데이션 모델로, 이기종 멀티-로봇 데이터셋을 통합하여 zero-shot 일반화를 달성합니다.
- **모션 플래닝을 위한 제어 정책:**
  - **VoxPoser [103]:** LLM과 VLM을 사용하여 어포던스 및 제약 조건의 3D 복셀 맵을 생성하고, 모델 예측 제어를 통해 로봇 팔의 실행 가능한 궤적을 생성합니다. 훈련 없이 LLM과 VLM을 직접 연결합니다.
- **점 기반 액션 제어 정책:**
  - **RoboPoint [91]:** VLM을 공간 어포던스 예측 작업으로 미세 조정하여 이미지에서 액션 위치를 가리키고, 이를 3D 공간으로 투영하여 로봇 액션을 생성합니다.
- **대규모 VLA (Large VLA, LVLA):** LLM 또는 대규모 VLM을 기반으로 하는 VLA로, 기존 VLA 정의에 해당합니다.
  - **RT-2 [2]:** 인터넷 규모 VQA(Visual Question Answering) 데이터와 로봇 데이터를 공동 미세 조정하여 모델의 일반화와 새로운 기능(emergent capabilities)을 강화합니다.
  - **OpenVLA [37]:** RT-2-X의 오픈 소스 모델로, LoRA 및 모델 양자화와 같은 효율적인 미세 조정 방법을 탐구합니다.
  - **π$_0$ [115]:** Flow Matching 아키텍처를 제안하여 VLM을 VLA로 변환하며, 액션 전문가(action expert)를 통합하여 VLM의 인터넷 규모 지식을 로봇 작업에 확장합니다.
  - **WorldVLA [122] & UniVLA [123]:** 멀티모달 데이터를 이산 토큰으로 양자화하여 공유된 어휘를 형성하고, 모든 모달리티를 자기회귀적으로 모델링하여 액션, 텍스트, 이미지 생성을 가능하게 합니다.

### 3. 상위 수준 작업 플래너 (High-level Task Planners)

복잡한 작업($\ell$)을 하위 작업($p_i$) 시퀀스([$p_1, p_2, ..., p_N$])로 분해하여 하위 수준 제어 정책($\pi_{\theta}$)을 안내합니다 (Figure 4 참조).

- **모놀리식 작업 플래너 (Monolithic Task Planners):** 단일 LLM 또는 멀티모달 LLM(MLLM)이 작업 계획을 생성합니다.
  - **종단 간 작업 플래너:** PaLM-E [11]는 ViT와 PaLM을 통합하여 고수준 Embodied 추론 작업을 수행하고, 텍스트 계획을 생성하여 하위 수준 로봇 정책에 지시로 제공합니다.
  - **접지된 작업 플래너:** SayCan [10]은 LLM 플래너의 계획과 로봇 정책의 실행 가능성(어포던스)을 결합하여 최적의 기술을 선택합니다.
- **모듈형 작업 플래너 (Modular Task Planners):** 기성 LLM과 VLM을 조합하여 작업 플래너를 구성하며, 도구 사용(tool-use) 아키텍처를 따릅니다 (Figure 6 참조).
  - **언어 기반 작업 플래너:** Inner Monologue [9]는 LLM을 사용하여 하위 수준 제어 정책을 위한 언어 지시를 생성하고, 정책으로부터 받은 피드백을 기반으로 지시를 동적으로 업데이트합니다.
  - **코드 기반 작업 플래너:** ProgPrompt [144] 및 ChatGPT for Robotics [145]는 LLM의 코딩 능력을 활용하여 API 호출을 통해 지각 모듈 및 제어 API를 호출하는 프로그램 형태의 작업 계획을 생성합니다.

## 📊 Results

VLA는 Embodied AI에서 언어 조건부 로봇 작업을 수행하는 데 있어 뛰어난 성능을 입증했습니다.

- **일반화 및 적응성:** VLA는 초기 심층 강화 학습 접근 방식보다 훨씬 뛰어난 다재다능함, 민첩성, 일반화 가능성을 보여주며, 공장과 같은 제어된 환경뿐만 아니라 일상적인 가정 환경 작업에도 적합합니다.
- **파운데이션 모델의 역할:** 대규모 VLM 및 LLM을 기반으로 하는 RT-2, OpenVLA와 같은 Large VLA(LVLA)는 인터넷 규모의 지식을 로봇 제어로 전이시켜 새로운 기능(emergent capabilities)과 향상된 일반화 능력을 보여줍니다.
- **아키텍처 효과:** Transformer 기반 아키텍처는 대규모 로봇 데이터셋을 흡수하는 데 RNN 기반 아키텍처보다 뛰어난 성능을 보여주며, 확산 모델은 고차원 액션 공간 및 훈련 안정성에 강점을 가집니다.
- **3D 비전 및 멀티모달리티:** 3D 비전 정보와 멀티모달 프롬프트(VIMA, MOO)의 통합은 더욱 정확한 작업 정의와 일반화를 가능하게 합니다.
- **계층적 계획:** 상위 수준 작업 플래너와 하위 수준 제어 정책을 결합한 계층적 프레임워크는 복잡하고 장기적인 작업을 성공적으로 처리하는 데 효과적입니다. LLM 기반 플래너는 상식적 지식과 추론을 통해 계획 생성 및 오류 복구에 뛰어난 능력을 보입니다.
- **데이터 스케일 및 효율성:** OXE와 같은 대규모 데이터셋을 활용한 훈련(RT-X)은 모델 성능을 크게 향상시키며, LoRA, 양자화, Mamba 모델(RoboMamba)과 같은 효율적인 미세 조정 및 아키텍처는 속도와 용량의 균형을 찾아 실시간 응답성을 개선할 잠재력을 보여줍니다.

## 🧠 Insights & Discussion

### 강점

- **PVRs:** MAE 기반 자기지도 학습은 픽셀 수준의 정밀한 정보(분할 마스크, 객체 위치, 깊이)를 제공하여 고정밀 로봇 조작에 유용합니다. DINOv2와 Theia는 픽셀/이미지 수준 특징 학습 및 여러 비전 파운데이션 모델(VFM) 증류를 통해 기존 PVRs를 능가하는 성능을 입증했습니다.
- **동역학 학습:** 전방 동역학 학습은 예측이 더 복잡하지만, 모델 성능 향상에 크게 기여할 수 있습니다. 역동역학 모델은 상태만 포함된 데이터셋에 액션 레이블을 생성하는 데 활용될 수 있습니다.
- **월드 모델 및 추론:** 월드 모델은 주어진 저수준 액션에 대한 즉각적인 다음 상태를 생성하는 데 탁월하며 제어 정책과 상호작용합니다. CoT(Chain-of-Thought) 기반 추론은 텍스트로 사고 과정을 표현하므로 텍스트 기반 작업 계획을 정교화하는 데 적합합니다.
- **다양한 아키텍처:** FiLM, 교차 어텐션, 연결, 양자화 및 도구 사용(Tool Use)과 같은 다양한 VLA 아키텍처가 있으며, 각각 모델 크기, 구현 복잡성, 성능에서 트레이드오프를 가집니다. 양자화는 멀티모달 토큰을 통합하여 월드 모델과의 통합을 가능하게 합니다.
- **스케일링 법칙:** LLM과 유사하게 로봇 공학에서도 스케일링 법칙이 관찰되어, 모델 크기, 데이터 품질, 환경 및 객체의 다양성이 일반화 능력에 중요함을 시사합니다.

### 제한 및 미래 방향

- **안전 (Safety first):** 로봇은 물리적 세계와 직접 상호작용하므로 안전이 최우선입니다. 강력한 안전 장치, 위험 평가, 인간-로봇 상호작용 프로토콜, 그리고 의사 결정 과정의 해석 가능성이 필수적입니다.
- **데이터셋 및 벤치마크 (Datasets & Benchmarks):** 광범위한 기술, 객체, 구현체, 환경을 포괄하는 포괄적인 벤치마크와 성공률 이상의 세분화된 진단 측정 지표가 필요합니다.
- **파운데이션 모델 및 일반화 (Foundation Models & Generalization):** Embodied AI를 위한 VLA 파운데이션 모델은 LLM 수준의 일반화에 미치지 못하며, 구현체, 환경, 작업의 다양성으로 인해 여전히 개방형 연구 주제입니다.
- **멀티모달리티 (Multimodality):** 유용한 임베딩을 얻고 다른 모달리티를 정렬하는 것은 여전히 과제입니다. 오디오, 촉각, 시선과 같은 추가 모달리티를 통합하면 성능이 향상될 수 있지만, 모델 설계의 복잡성을 증가시킵니다.
- **장기 작업 프레임워크 (Framework for Long-Horizon Tasks):** 현재의 계층적 프레임워크는 시스템 복잡성과 잠재적 실패 지점을 증가시킵니다. 장기적인 작업을 종단 간 저수준 제어 신호로 직접 변환하는 통합 프레임워크 개발이 필요합니다.
- **실시간 응답성 (Real-Time Responsiveness):** 동적 환경에 대한 실시간 의사 결정은 많은 로봇 애플리케이션에 필수적이지만, 현재 VLA 모델(특히 LVLA 및 작업 플래너)은 속도와 용량 사이에 트레이드오프가 있습니다.
- **다중 에이전트 시스템 (Multi-agent Systems):** 협력적 다중 에이전트 시스템은 분산 인지 및 협업적 오류 복구의 이점을 제공하지만, 효과적인 통신, 조정, 이질성 문제가 존재합니다.
- **윤리 및 사회적 함의 (Ethical and Societal Implications):** 개인 정보 보호, 일자리 대체, 의사 결정 편향, 사회적 규범 및 인간 관계에 미치는 영향 등 로봇 공학은 항상 다양한 윤리적, 사회적, 법적 우려를 제기합니다.
- **응용 분야 (Applications):** 가상 비서, 자율 주행, 농업 로봇, 의료 로봇 등 광범위한 응용 분야와 민첩한 손, 드론, 사족보행 로봇, 휴머노이드 로봇 등 다양한 구현체를 위한 특화된 VLA가 필요합니다.

## 📌 TL;DR

이 논문은 로봇 작업에서 언어 지시를 이해하고 행동을 생성하는 Vision-Language-Action (VLA) 모델의 급성장하는 분야를 종합적으로 정리한 최초의 설문 조사입니다. 주요 문제: 실제 세계에서 언어 조건부 로봇 작업을 수행하는 다재다능하고 일반화 가능한 로봇 정책 개발. 제안 방법: VLA를 핵심 구성 요소, 하위 수준 제어 정책, 상위 수준 작업 플래너의 세 가지 주요 연구 분야로 분류하고, 각 분야의 기술적 세부 사항, 아키텍처, 훈련 전략을 분석. 특히 대규모 언어/비전 모델(LLM/VLM)을 로봇 제어로 확장하는 Large VLA와 확산 모델의 역할을 강조. 주요 결과: VLA는 복잡한 환경에서 뛰어난 성능을 보이며, 계층적 프레임워크는 장기적인 작업을 해결하는 데 효과적입니다. 스케일링 법칙이 관찰되며, 데이터셋 확장 및 효율적인 파인튜닝 기법이 성능 향상에 기여합니다. 통찰 및 논의: 안전성, 데이터셋/벤치마크, 파운데이션 모델의 일반화, 멀티모달리티의 복잡성, 실시간 응답성, 통합 프레임워크의 필요성, 다중 에이전트 시스템, 윤리적 문제 등 VLA의 현재 과제와 미래 방향을 제시합니다.
