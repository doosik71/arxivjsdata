# GR00T N1: An Open Foundation Model for Generalist Humanoid Robots

NVIDIA

## 🧩 Problem to Solve

다목적 로봇, 특히 휴머노이드 로봇을 인간 세상의 다양한 작업을 수행할 수 있도록 만드는 것은 흥미롭지만 상당한 기술적 도전 과제입니다. 이 논문은 다음의 주요 연구 문제를 해결하고자 합니다:

- **다용도성 및 일반화:** 광범위한 작업 목표를 처리하고 다양한 작업에 걸쳐 강력한 일반화 능력을 갖춘 '제너럴리스트 로봇 모델'을 개발해야 합니다.
- **데이터 희소성 및 다양성:** 대규모 사전 학습을 위한 방대한 양의 다양하고 일관된 휴머노이드 로봇 데이터셋이 부족합니다. 실제 휴머노이드 데이터는 수집 비용과 시간이 많이 듭니다. 이는 "데이터 아일랜드" 문제로 이어집니다.
- **AI와 로봇 행동의 연결:** 시각 및 언어와 같은 일반 AI 모델의 추론 능력과 로봇의 구체적인 물리적 행동 생성 사이의 간극을 연결해야 합니다.

## ✨ Key Contributions

이 논문은 일반 휴머노이드 로봇을 위한 개방형 파운데이션 모델인 GR00T N1을 소개하며 다음과 같은 주요 기여를 합니다.

- **이중 시스템 아키텍처:** 추론을 위한 Vision-Language Model (VLM, System 2)과 실시간 동작 생성을 위한 Diffusion Transformer (DiT, System 1)를 통합한 구성 모델을 제안합니다. 두 모듈은 긴밀하게 연결되어 종단간(end-to-end)으로 함께 훈련됩니다.
- **이질적인 데이터 피라미드 전략:** 웹 데이터 및 인간 비디오 (피라미드 하단), 합성 데이터 (중간), 실제 로봇 궤적 (상단)의 혼합을 사용하여 데이터 희소성 문제를 완화하고 일반화 및 견고성을 향상시킵니다.
- **효과적인 공동 훈련 전략:** 행동 정보가 없는 데이터(예: 인간 비디오)에서 VQ-VAE를 통해 "잠재 행동(latent actions)"을 추출하고, Inverse Dynamics Model (IDM)을 통해 의사 행동(pseudo-actions)을 추론하여 활용합니다.
- **다중 로봇 형태 지원:** 단일 팔 로봇부터 양팔 휴머노이드 로봇까지 다양한 로봇 형태(embodiments)에 걸쳐 지원하며, 이를 통해 광범위한 조작 행동을 생성할 수 있습니다.
- **최고 수준의 성능 달성:** 표준 시뮬레이션 벤치마크에서 최첨단 모방 학습(imitation learning) 베이스라인을 능가하며, 실제 GR-1 휴머노이드 로봇의 언어 조건부 양팔 조작 작업에서 높은 데이터 효율성과 강력한 성능을 보여줍니다.
- **오픈 소스 공개:** GR00T-N1-2B 모델 체크포인트, 훈련 데이터, 시뮬레이션 벤치마크를 공개하여 커뮤니티의 발전을 가속화합니다.

## 📎 Related Works

GR00T N1은 다음과 같은 선행 연구들의 흐름 위에 구축되었습니다.

- **로봇 공학의 파운데이션 모델:**
  - 고수준 추론 모듈(예: LLM)을 저수준 로봇 정책과 함께 사용하는 방식 (Brohan et al., 2023; Driess et al., 2023).
  - 사전 훈련된 파운데이션 모델을 로봇 데이터에 미세 조정하여 Vision-Language-Action (VLA) 모델을 구축하는 방식 (Black et al., 2024; Brohan et al., 2022). GR00T N1은 NVIDIA Eagle-2 VLM (Li et al., 2025)을 백본으로 사용하는 후자의 접근 방식을 따릅니다.
  - 액션 청킹(action chunking) (Zhao et al., 2023)과 함께 흐름 매칭(flow-matching) (Hu et al., 2024; Lipman et al.)을 활용하며, Black et al. (2024)과 달리 간단한 교차 어텐션 메커니즘을 사용합니다.
  - Octo Model Team et al. (2024)과 유사하게 형태(embodiment)별 상태 및 행동 프로젝터 모듈을 사용합니다.
- **로봇 학습을 위한 데이터셋:**
  - **로봇 원격 조작:** 인간 조작자가 로봇을 제어하여 데이터를 수집하는 방식 (Aldaco et al., 2024; Mandlekar et al., 2018). 대규모 로봇 조작 데이터셋 (AgiBot-World-Contributors et al., 2025; Open X-Embodiment Collaboration et al., 2024).
  - **인간 시연 데이터:** 특수 하드웨어를 사용하여 인간의 움직임을 로봇 행동으로 리타게팅하는 방식 (Chi et al., 2024; Kareer et al., 2024).
  - **인간 비디오 데이터셋:** 풍부한 인간 행동 정보를 담고 있는 Ego4D (Grauman et al., 2022)와 같은 데이터셋을 활용 (Ye et al., 2025). GR00T N1은 실제 로봇 데이터, 인간 비디오, 합성 데이터를 효과적으로 학습하기 위한 기술을 개발했습니다.
- **로봇 공학의 합성 데이터 생성:**
  - 시뮬레이션을 통한 자동화된 데이터 생성 파이프라인 (Mandlekar et al., 2023; Jiang et al., 2024)은 시뮬레이션-현실 간극(sim-to-real gap) 문제에도 불구하고 대규모 데이터 생성을 가능하게 합니다. GR00T N1은 MimicGen 및 DexMimicGen으로 생성된 대규모 시뮬레이션 데이터셋을 활용합니다.
  - 신경 생성 모델을 사용하여 로봇 시연을 확장하는 연구 (Chen et al., 2023). GR00T N1은 비디오 생성 모델 (Agarwal et al., 2025; Wan Team, 2025)을 활용하여 전례 없는 규모의 신경 궤적(neural trajectories)을 생성합니다.

## 🛠️ Methodology

GR00T N1은 다양한 데이터 소스에서 훈련된 휴머노이드 로봇을 위한 Vision-Language-Action (VLA) 모델입니다.

- **모델 아키텍처:** 이중 시스템 디자인을 채택합니다 (그림 2 참조).
  - **System 2 (Vision-Language Module, VLM):** NVIDIA Eagle-2 VLM (Li et al., 2025)을 백본으로 사용합니다. 인터넷 규모 데이터에 사전 훈련되었으며, 로봇의 시각적 관찰과 언어 지시를 해석합니다. GR00T-N1-2B는 총 2.2B 파라미터 중 1.34B 파라미터가 VLM에 해당합니다. 추론 속도는 NVIDIA L40 GPU에서 10Hz로 동작합니다.
    - 이미지(224x224)와 텍스트를 VLM에 입력하여 시각-언어 토큰 임베딩 $\phi_t$를 추출합니다. LLM의 중간 레이어(12번째 레이어) 임베딩을 사용하여 추론 속도와 정책 성공률을 높입니다.
  - **System 1 (Diffusion Transformer Module, DiT):** DiT (Peebles and Xie, 2023)의 변형을 사용하여 동작을 생성합니다. VLM 출력 토큰에 교차 어텐션(cross-attention)하고, 형태(embodiment)별 인코더 및 디코더를 사용하여 가변 상태 및 동작 차원을 처리합니다.
    - **상태 및 행동 인코더/디코더:** MLP를 사용하여 다양한 로봇 형태의 상태 $q_t$와 행동 $a_t$를 공유 임베딩 차원으로 투영합니다. 행동 인코더 MLP는 노이즈가 추가된 행동 벡터와 확산 시간 단계 $\tau$를 인코딩합니다.
    - **흐름 매칭(Flow-matching):** 반복적인 노이즈 제거를 통해 행동을 샘플링하는 데 사용됩니다. 노이즈가 추가된 행동 $A_t^{\tau} = \tau A_t + (1-\tau)\epsilon$ (여기서 $A_t$는 실제 행동 청크, $\epsilon$는 샘플링된 노이즈)와 VLM 임베딩 $\phi_t$, 로봇 상태 $q_t$를 입력받아 노이즈 제거 벡터 필드 $\epsilon - A_t$를 예측합니다. 손실 함수는 다음과 같습니다:
      $$ \mathcal{L}_{\text{fm}}(\theta) = \mathbb{E}_{\tau} [\|V_{\theta}(\phi_t, A_t^{\tau}, q_t) - (\epsilon - A_t)\|^2] $$
    - 추론 시 $K=4$ 단계의 노이즈 제거를 통해 행동 청크 $A_t = [a_t, a_{t+1}, \dots, a_{t+H-1}]$ ($H=16$)를 생성하며, 120Hz의 고주파수로 작동합니다.
- **훈련 데이터 생성 (데이터 피라미드):** (그림 1 참조)
  - **기반 (인간 비디오 데이터):** Ego4D, Ego-Exo4D, EPIC-KITCHENS 등 대규모 인간 비디오 데이터셋을 활용합니다.
    - **잠재 행동 (Latent Actions):** 행동 정보가 없는 비디오에서 VQ-VAE 모델을 훈련하여 연속된 이미지 프레임($x_t, x_{t+H}$)으로부터 잠재 행동 $z_t$를 추출합니다. 이 잠재 행동을 "LAPA" 형태의 행동 레이블로 사용합니다.
  - **중간 (합성 데이터):**
    - **신경 궤적 (Neural Trajectories):** 사전 훈련된 이미지-비디오 생성 모델 (예: WAN2.1-I2V-14B)을 실제 로봇 원격 조작 데이터에 미세 조정하여 88시간의 데이터를 827시간으로 약 10배 증강합니다. 생성된 비디오는 새로운 언어 프롬프트에 따른 반사실적 시나리오를 포함합니다. 행동 레이블은 IDM(Inverse Dynamics Model) 또는 잠재 행동을 통해 얻습니다.
    - **시뮬레이션 궤적 (Simulation Trajectories):** DexMimicGen (Jiang et al., 2024)을 사용하여 RoboCasa 시뮬레이션 환경에서 대규모 로봇 조작 궤적을 합성합니다. 수십 개의 인간 시연에서 78만 개의 시뮬레이션 궤적 (6,500시간 분량)을 생성합니다.
  - **정점 (실제 로봇 데이터):**
    - **GR00T N1 휴머노이드 사전 훈련 데이터셋:** VIVE Ultimate Tracker, Xsens Metagloves 등을 사용하여 Fourier GR-1 로봇으로 내부에서 수집한 원격 조작 데이터입니다.
    - **Open X-Embodiment:** RT-1, Bridge-v2 등 널리 사용되는 크로스-형태 데이터셋을 포함합니다.
    - **AgiBot-Alpha:** 100대의 로봇에서 수집된 대규모 궤적 데이터셋입니다.
- **훈련 상세:**
  - **사전 훈련:** 위 데이터 피라미드의 모든 데이터 소스에 대해 흐름 매칭 손실을 사용하여 종단간 훈련됩니다. VLM의 언어 구성 요소는 고정하고 모델의 나머지 부분을 미세 조정합니다.
  - **사후 훈련 (미세 조정):** 사전 훈련된 모델을 각 단일 형태에 해당하는 데이터셋에 미세 조정합니다. 데이터가 부족한 시나리오에서 신경 궤적을 사용하여 데이터를 증강하고 실제 궤적과 1:1 샘플링 비율로 공동 훈련합니다.
- **표준화된 행동 공간:** 일관성을 위해 행동 및 상태 공간을 통일합니다 (예: 6D 회전 표현, 축-각(axis-angle) 표현, Min-max 정규화, 일관된 순서).

## 📊 Results

GR00T N1은 시뮬레이션 및 실제 로봇 벤치마크에서 강력한 성능과 높은 데이터 효율성을 보여주었습니다.

- **사전 훈련 평가 (실제 GR-1 휴머노이드 로봇):**
  - 언어 조건부 조정 양팔 조작 (예: 왼손에서 오른손으로 물건 건네기): 76.6% 성공률 (15회 중 11.5회).
  - 새로운 물체, 미지의 용기 조작: 73.3% 성공률 (15회 중 11회).
  - 대규모 사전 훈련의 효과와 일반화 능력을 입증합니다.
- **사후 훈련 평가 (시뮬레이션 벤치마크):**
  - RoboCasa, DexMimicGen, GR-1 Tabletop 등 세 가지 벤치마크에서 GR00T N1은 BC-Transformer와 Diffusion Policy 베이스라인을 일관되게 능가합니다. (표 2 참조)
  - 특히 GR-1 태스크에서 GR00T N1 (50.0%)은 Diffusion Policy (32.7%)보다 17% 이상 높은 성능을 달성했습니다.
- **사후 훈련 평가 (실제 GR-1 휴머노이드 로봇):**
  - 제한된 데이터 (10% 데이터) 및 전체 데이터 조건에서 GR00T-N1-2B는 Diffusion Policy를 크게 능가했습니다. (표 3 참조)
  - **평균 성공률 (전체 데이터):** GR00T-N1-2B (76.8%) vs. Diffusion Policy (46.4%).
  - **데이터 효율성:** GR00T-N1-2B는 10%의 데이터만으로 42.6%의 성공률을 달성하여, Diffusion Policy가 전체 데이터로 달성한 46.4%와 비교하여 불과 3.8% 낮은 성능을 보였습니다.
- **신경 궤적을 이용한 사후 훈련:**
  - 신경 궤적과의 공동 훈련은 RoboCasa 벤치마크에서 평균 4.2% ~ 8.8%, 실제 GR-1 휴머노이드 태스크에서 평균 5.8%의 상당한 성능 향상을 가져왔습니다.
  - 낮은 데이터 환경에서는 잠재 행동(LAPA) 레이블이 IDM 레이블보다 약간 우수했지만, 데이터 양이 증가함에 따라 IDM 레이블이 더 나은 성능을 보였습니다.
- **정성적 결과:**
  - 사전 훈련된 GR00T N1은 낯선 상황에서도 양팔 간의 핸드오버와 같은 복잡한 행동을 보였지만 다소 불안정한 움직임을 보였습니다 (그림 11).
  - 사후 훈련된 GR00T N1은 베이스라인인 Diffusion Policy에 비해 훨씬 부드러운 움직임과 높은 파악 정확도를 보여주었습니다. Diffusion Policy는 초기 프레임에서 움직이지 않거나 부정확한 파악으로 실패하는 경우가 많았습니다 (그림 12).

## 🧠 Insights & Discussion

- **제너럴리스트 로봇 모델의 가능성:** GR00T N1의 성공적인 개발과 배포는 휴머노이드 로봇을 위한 제너럴리스트 파운데이션 모델의 강력한 잠재력을 보여줍니다. 특히, 추론과 행동을 결합한 이중 시스템 아키텍처와 다양한 데이터 소스를 활용하는 "데이터 피라미드" 전략이 중요한 역할을 합니다.
- **높은 데이터 효율성:** 대규모 사전 훈련 덕분에 GR00T N1은 제한된 실제 데이터로도 새로운 작업에 빠르게 적응하고 강력한 성능을 발휘할 수 있음을 입증했습니다. 이는 실제 로봇 배포의 현실적 제약을 극복하는 데 중요합니다.
- **일반화 능력:** 모델은 사전 훈련에서 보지 못한 새로운 물체, 미지의 용기, 복잡한 양팔 협동 작업에 대해서도 뛰어난 일반화 능력을 보였습니다.
- **합성 데이터의 가치:** 신경 궤적을 활용한 훈련 데이터 증강은 실제 데이터 부족 문제를 해결하는 효과적인 방법이며, 특히 IDM 기반의 의사 행동 레이블링은 데이터가 풍부할수록 시너지를 발휘합니다.
- **제한 사항:**
  - 현재 모델은 주로 짧은 시간 범위의 탁상 조작 작업에 초점을 맞추고 있습니다. 장기적인 이동 조작(loco-manipulation)으로 확장하려면 하드웨어, 모델 아키텍처, 훈련 코퍼스에 대한 추가 발전이 필요합니다.
  - 비디오 생성 모델을 활용한 합성 데이터 생성 기술은 다양하고 반사실적인 데이터를 생성하는 데 강점이 있지만, 물리 법칙을 준수하면서 고품질의 데이터를 생성하는 데 여전히 어려움이 있습니다.
- **향후 연구:** 모델의 견고성과 일반화 능력을 향상시키기 위해 새로운 모델 아키텍처와 사전 훈련 전략을 탐색하고, 합성 데이터 생성 기술을 더욱 발전시켜 데이터 피라미드를 풍부하게 할 계획입니다. 장기적이고 복잡한 작업 환경으로의 확장이 목표입니다.

## 📌 TL;DR

GR00T N1은 다목적 휴머노이드 로봇을 위한 개방형 파운데이션 모델입니다. 이 모델은 환경을 해석하는 Vision-Language Model (System 2)과 실시간으로 유동적인 동작을 생성하는 Diffusion Transformer (System 1)의 이중 시스템 아키텍처를 특징으로 합니다. 실제 로봇 궤적, 인간 비디오, 합성 데이터를 포함하는 이질적인 "데이터 피라미드"로 모델을 공동 학습시킵니다. GR00T N1은 시뮬레이션 벤치마크에서 최첨단 모방 학습 모델을 능가하며, 제한된 데이터로도 실제 GR-1 휴머노이드 로봇의 이족 조작 작업에서 높은 데이터 효율성과 강력한 성능을 보여 일반화 및 적응 능력을 입증합니다.
