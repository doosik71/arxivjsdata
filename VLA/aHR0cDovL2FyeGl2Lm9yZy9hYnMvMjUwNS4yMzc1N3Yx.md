# Impromptu VLA: Open Weights and Open Data for Driving Vision-Language-Action Models

Haohan Chi, Huan-ang Gao, Ziming Liu, Jianing Liu, Chenyu Liu, Jinwei Li, Kaisen Yang, Yangcheng Yu, Zeda Wang, Wenyi Li, Leichen Wang, Xingtao Hu, Hao Sun, Hang Zhao, Hao Zhao

## 🧩 Problem to Solve

자율주행을 위한 비전-언어-액션(VLA) 모델은 상당한 발전을 이루었지만, 명확하지 않은 도로 경계, 비정형 동적 장애물, 임시 교통 규칙 변경, 열악한 노면 등 실제와 같이 예측 불가능한 '비구조적 코너 케이스 시나리오'에서 큰 어려움을 겪습니다. 이러한 문제의 주된 원인은 이처럼 도전적인 상황을 다루는 전문적이고 대규모의 벤치마크 데이터셋이 극히 부족하기 때문입니다. 기존 데이터셋은 주로 구조화되고 일반적인 교통 상황에 초점을 맞춰 비구조적 환경의 다양성과 독특한 도전을 반영하지 못합니다.

## ✨ Key Contributions

- **Impromptu VLA 데이터셋:** 기존 데이터 자원의 중요한 공백을 메우기 위해 다양하고 도전적인 비구조적 주행 시나리오에 세심하게 초점을 맞춘 공개적으로 사용 가능한 대규모의 풍부한 주석 데이터셋을 구축했습니다.
- **체계적인 분류 체계 및 데이터 큐레이션 파이프라인:** 비구조적 도로 조건에 대한 체계적인 분류법과 VLM(Vision-Language Model) 기반의 확장 가능한 데이터 큐레이션 파이프라인을 제시하여, 고급 VLM 훈련에 적합한 다중 작업 Q&A 주석을 포괄적으로 생성합니다.
- **모델 성능 향상 및 진단 도구:** Impromptu VLA 데이터셋으로 훈련한 VLM이 표준 자율주행 벤치마크에서 폐쇄 루프(closed-loop) 안전성 및 주행 점수, 개방 루프(open-loop) 궤적 예측 정확도 등 성능을 크게 향상시켰음을 입증했습니다. 또한, 이 데이터셋은 비구조적 환경에서 VLM의 역량을 평가하고 개선하는 효과적인 진단 도구로 활용될 수 있음을 보여줍니다.

## 📎 Related Works

- **자율주행 분야의 비전-언어 모델(VLM):** GPT-4o, Qwen-VL, LLaVA와 같은 VLM을 자율주행에 적용하여 기존 프레임워크를 보완하거나 독립적인 의사결정자로 활용하는 연구들이 있습니다(예: DriveGPT4, ELM, DriveVLM, EMMA). 운전 특정 Q&A 데이터와 벤치마크(예: nuScenes-QA)를 활용하여 훈련을 다운스트림 계획 작업과 연계하는 노력도 이루어지고 있습니다.
- **자율주행을 위한 특수 기술 및 데이터셋:** 지각, 시뮬레이션, 매핑, 예측 분야의 발전을 위한 다양한 연구가 진행되고 있습니다. Mars(인스턴스 인식 시뮬레이터), Challenger(적대적 주행 비디오 생성), AVD2(사고 비디오 설명), Steps(야간 이미지 향상 및 깊이 추정), P-MapNet(원거리 지도 생성), MonoOcc(단안 시맨틱 점유 예측), Int2(교차로 대화형 궤적 예측), UniScene(운전 장면 생성), SCP-Diff(시맨틱 이미지 합성) 등이 그 예입니다.
- **종단 간(End-to-end) 자율주행 데이터셋 및 벤치마크:** 대규모 모방 학습을 위한 실제 세계 데이터셋(KITTI, nuScenes, Waymo, Argoverse, Mapillary Vistas, ONCE, IDD)과 시뮬레이션 기반 벤치마크(Bench2Drive, NAVSIM, NeuroNCAP)로 나뉩니다. 본 연구는 합성 요소나 이상 징후를 도입하는 대신 실제 비구조적 시나리오의 수집 및 필터링에 중점을 둡니다.

## 🛠️ Methodology

1. **데이터 수집 및 정제:**
   - 8개의 주요 공개 대규모 데이터셋(2백만 개 이상의 원본 클립, 10TB 이상의 저장 공간)에서 약 80,000개의 비디오 클립을 선별하여 Impromptu VLA 데이터셋을 구축했습니다.
   - 모든 시퀀스는 2Hz의 균일한 시간 비율로 표준화되었으며, 과거 1.5초 및 미래 5초를 포함하는 핵심 클립을 선택했습니다. 시간적 안정성 필터링 메커니즘을 사용하여 안정적인 장면 특성을 식별했습니다.
2. **비구조적 시나리오 분류 체계 정의:**
   - 데이터 기반 접근 방식을 통해 `Qwen2.5-VL 72B` 모델의 상세한 텍스트 설명을 활용하여 비구조적 환경의 도전을 정량화했습니다.
   - 다음 4가지 핵심 비구조적 시나리오를 정의했습니다.
     - **경계가 불분명한 도로 (Roads with unclear boundaries):** 농촌 비포장도로, 차선 표시가 없거나 희미한 도로 등 주행 가능한 경로가 모호하거나 정의되지 않은 시나리오.
     - **임시 교통 규칙 변경 (Temporary traffic rule changes):** 공사 구역, 임시 표지판 등으로 표준 교통 규칙이 일시적으로 변경되어 특이한 지시에 적응해야 하는 상황.
     - **비정형 동적 장애물 (Unconventional dynamic obstacles):** 일반적인 도심 주행에서 흔치 않은 동적 행위자나 장애물(예: 예상치 못한 위치의 취약 도로 사용자, 동물)이 나타나는 상황.
     - **까다로운 도로 조건 (Challenging road conditions):** 움푹 들어간 곳, 진흙, 눈, 얼음 등 열악한 노면이나 안개, 폭우, 저조도 등 환경 조건이 시야를 심각하게 저해하거나 차량 역학에 영향을 미치는 시나리오.
3. **VLM 기반 데이터 큐레이션:**
   - Qwen2.5-VL 72B와 CoT(Chain-of-Thought) 프롬프팅을 활용한 고급 파이프라인을 사용하여 상세한 주석을 생성했습니다.
     - **장면 분류 및 구조화된 정보 추출:** CoT 프롬프팅을 통해 전반적인 장면 문맥(설명), 정적 도로 특징, 움직이는 객체 등을 분석하고 정의된 4가지 비구조적 장면 범주 중 하나로 분류했습니다.
     - **다중 작업 주석 생성:** 추출된 정보를 기반으로 다음을 포함한 풍부한 작업별 주석을 생성했습니다: 장면 설명, 교통 신호 감지, 취약 도로 사용자(VRU) 식별, 동작 의도 예측, 메타 액션 플래닝, 플래닝 설명, 종단 간 궤적 예측.
4. **종합적인 사람 검증:**
   - 생성된 모든 주석(기본 비구조적 장면 범주 및 다중 작업 레이블)은 사람 검증을 거쳐 높은 정확도와 신뢰성을 보장했습니다. VLM의 장면 분류 성능은 NuScenes 데이터셋의 부분 집합에서 $F_1$ 점수로 평가되어 높은 신뢰도를 보였습니다.

## 📊 Results

- **폐쇄 루프(Closed-loop) 성능 (NeuroNCAP):**
  - Impromptu VLA 데이터셋으로 사전 훈련한 모델(Base+Impromptu+nuScenes)은 베이스라인(Base+nuScenes) 대비 평균 NeuroNCAP 점수를 1.77에서 2.15로 크게 향상시켰습니다.
  - 또한, 평균 충돌률을 72.5%에서 65.5%로 감소시켰습니다. 이는 모델이 복잡한 도로 상호작용을 더 잘 이해하여 더 견고하고 안전한 주행 정책을 개발했음을 시사합니다.
- **개방 루프(Open-loop) 궤적 예측 (nuScenes):**
  - Impromptu VLA 데이터셋으로 사전 훈련한 모델은 nuScenes 벤치마크에서 궤적 예측 $L_2$ 오류를 크게 줄였습니다(예: 3B 모델에서 평균 0.34m에서 0.30m로 감소).
  - 이러한 성능 향상은 EMMA+ (평균 $L_2$ 오류 0.29m)와 같은 최첨단 전문 방법론에 근접하는 수준으로, Impromptu VLA 데이터셋의 궤적 예측 능력 향상에 대한 효과를 입증합니다.
- **Impromptu VLA 진단 평가:**
  - Impromptu VLA 검증 세트의 Q&A 작업을 통한 정량적 평가는 우리 데이터셋으로 미세 조정된 모델이 인지(취약 도로 사용자, 교통 신호 감지), 예측(동적 객체 의도 예측), 메타 플래닝 및 계획된 궤적 정확도 등 자율주행의 모든 핵심 측면에서 성능이 향상되었음을 분명히 보여줍니다.

## 🧠 Insights & Discussion

- **데이터 희소성 해결:** Impromptu VLA 데이터셋은 기존 자율주행 데이터셋에서 간과되었던 비구조적 환경 시나리오의 중요한 데이터 희소성 문제를 효과적으로 해결합니다.
- **모델 성능 향상:** 본 데이터셋을 활용한 훈련은 VLM의 인지, 예측, 계획 능력 등 자율주행의 핵심 역량을 실제 환경에서 크게 향상시킬 수 있음을 입증했습니다. 이는 NeuroNCAP 점수 향상 및 충돌률 감소, 궤적 예측 정확도 개선으로 나타났습니다.
- **진단적 가치:** 데이터셋에 포함된 다중 작업 Q&A 스위트는 모델의 특정 역량을 진단하고 개선하는 데 효과적인 도구 역할을 하여, 개발자들이 모델의 강점과 약점을 파악하고 목표에 맞춰 훈련 전략을 조정할 수 있도록 돕습니다.
- **한계점:** 주석 생성 과정에서 Qwen2.5-VL 모델에 주로 의존했기 때문에, 잠재적으로 모델 특정 편향이 발생할 수 있다는 한계가 있습니다. 그러나 포괄적인 사람 검증과 비구조적 시나리오에서 VLM 성능 향상에 대한 실증된 유용성은 이 데이터셋의 연구 자원으로서의 중요한 가치를 뒷받침합니다.
- **미래 영향:** Impromptu VLA 데이터셋은 실제 도로의 복잡성에 대비할 수 있는 더욱 견고하고 적응력 있으며 유능한 자율주행 시스템 개발을 촉진하는 데 귀중한 새로운 자원을 제공합니다.

## 📌 TL;DR

- **문제:** 자율주행 VLA 모델은 명확하지 않은 도로 경계, 비정형 동적 장애물 등 '비구조적 코너 케이스 시나리오'를 처리하는 데 필요한 특화된 대규모 훈련 데이터가 부족하여 어려움을 겪습니다.
- **해결책:** 본 논문은 8개의 대규모 공개 데이터셋에서 80,000개 이상의 비디오 클립을 선별하여 **Impromptu VLA 데이터셋**을 제안합니다. 이 데이터셋은 경계가 불분명한 도로, 임시 교통 규칙 변경, 비정형 동적 장애물, 까다로운 도로 조건과 같은 4가지 도전적인 비구조적 시나리오에 초점을 맞추며, VLM(Vision-Language Model) 기반 큐레이션 파이프라인과 사람 검증을 통해 풍부한 다중 작업 Q&A 주석 및 주행 궤적을 제공합니다.
- **주요 성과:** Impromptu VLA 데이터셋으로 훈련된 VLM은 NeuroNCAP 벤치마크에서 폐쇄 루프 안전성(충돌률 감소) 및 주행 점수를 크게 향상시켰고, nuScenes 데이터셋에서 개방 루프 궤적 예측 $L_2$ 오류를 크게 개선하여 최첨단 성능에 근접하는 결과를 보였습니다. 또한, 데이터셋의 Q&A 검증 스위트는 비구조적 환경에서 모델의 인지, 예측, 계획 역량 발전을 진단하는 효과적인 도구임을 입증했습니다.
