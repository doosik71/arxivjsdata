# DISCRETEDIFFUSIONVLA: BRINGINGDISCRETEDIFFUSIONTOACTIONDECODINGINVISION-LANGUAGE-ACTIONPOLICIES

Zhixuan Liang, Yizhuo Li, Tianshuo Yang, Chengyue Wu, Sitong Mao, Liuao Pei, Xiaokang Yang, Jiangmiao Pang, Yao Mu, Ping Luo

## 🧩 Problem to Solve

기존의 비전-언어-액션(VLA) 모델의 액션 디코딩 방식은 두 가지 주요 한계를 가지고 있습니다.

1. **자기회귀(Autoregressive, AR) 방식**: 고정된 좌측-우측 순서로 액션을 순차적으로 생성하며, 이는 추론 시 병목 현상을 유발하고 전체 문맥을 활용한 유연한 디코딩을 방해합니다.
2. **연속 확산(Continuous Diffusion) 방식**: 전체 액션 궤적을 연속적인 신호로 간주하여 반복적으로 노이즈를 제거하지만, VLM(Vision-Language Model) 백본과 독립적으로 작동하여 특수 훈련과 반복적인 샘플링을 요구하며, 진정한 통합 아키텍처를 구현하지 못합니다.

이 논문은 VLM 백본의 이산 토큰 인터페이스와 기본적으로 호환되는, 단일의 확장 가능한 아키텍처 내에서 액션 디코딩을 수행하는 통일된 방법을 제시하여 이러한 한계를 극복하고자 합니다.

## ✨ Key Contributions

- **이산 확산 액션 헤드 도입**: VLA를 위한 최초의 이산 확산 액션 헤드를 제시하여, 비전, 언어, 액션 생성을 단일 트랜스포머 내에서 통합하면서도 강력한 성능을 유지합니다.
- **"쉬운 것 먼저, 어려운 것 나중에" 적응형 디코딩 전략 개발**: 반복적인 재마스킹(re-masking)을 통해 액션 토큰을 병렬로 디코딩하고 불확실한 예측을 재검토하여 오류를 수정하고 일관성을 개선합니다.
- **다양한 로봇 벤치마크에서 검증**: LIBERO, SimplerEnv-Fractal, SimplerEnv-Bridge 등 여러 로봇 환경에서 Discrete Diffusion VLA의 성능을 검증했으며, 자기회귀 및 연속 확산 기반 베이스라인보다 일관되게 우수한 결과를 달성했습니다.

## 📎 Related Works

- **자기회귀(Autoregressive) VLA 모델**: RT-1, RT-2, OpenVLA 등은 로봇 액션을 토큰 시퀀스로 이산화하고 다음 토큰 예측을 통해 액션을 생성하는 방식을 사용합니다. OpenVLA-OFT와 SpatialVLA는 병렬 디코딩 및 액션 청크(action chunk) 등의 개선을 시도했습니다.
- **확산 기반(Diffusion-based) VLA 모델**: Diffusion Policy, $\pi_0$ (파이 제로), RDT-1B 등은 시각-언어 백본에 확산 또는 플로우 매칭(flow-matching) 액션 생성기를 추가하여 연속 공간에서 액션을 생성하며, 섬세한 제어가 가능합니다.
- **이산 확산(Discrete Diffusion) 모델**: D3PM, VQ-Diffusion, MaskGIT 등은 이산 데이터(예: 토큰화된 이미지, 자연어)에 대한 이산 확산 모델을 제안하여 높은 충실도 생성을 달성했습니다. LLaDA, DiffuLLaMA, MMaDA는 이산 확산을 대규모 언어 모델(LM) 및 멀티모달 생성으로 확장했습니다. 이 연구는 이산 확산의 개념을 로봇 액션 모달리티에 적용합니다.

## 🛠️ Methodology

Discrete Diffusion VLA는 단일 트랜스포머를 사용하여 멀티모달 문맥에서 고정 길이의 미래 액션 청크를 예측하는 VLA 정책입니다.

1. **액션 토큰화 및 청킹(Chunking)**:

   - 각 연속 제어 차원(위치, 방향, 그리퍼)은 기존 VLA 모델과 유사하게 빈(bin)을 통해 토큰으로 이산화됩니다 (예: 256개 빈).
   - 그리퍼는 이진 토큰으로 처리됩니다.
   - 단일 시간 단계의 액션은 $D_{\text{act}} = 7$개의 토큰(이동 3개, 회전 3개, 그리퍼 1개)으로 구성됩니다.
   - 미래 $H$개 시간 단계의 토큰들을 고정된 길이 $L = H \times D_{\text{act}}$의 액션 시퀀스인 액션 청크로 묶습니다.
   - 특수 마스크 토큰 `[MASK]`를 액션 어휘에 추가합니다.

2. **통합 VLA 아키텍처**:

   - OpenVLA(Prismatic-7B VLM) 백본을 기반으로 구축됩니다.
   - SigLIP + DINOv2 ViT 시각 인코더와 Llama 2 LM 백본을 사용합니다.
   - 모든 모달리티(시각, 언어, 액션)는 단일 트랜스포머에 의해 처리됩니다.
   - 입력 시퀀스는 `[시각 토큰; 언어 토큰; 액션 토큰]`으로 구성됩니다.
   - 액션 토큰은 양방향 어텐션 마스크를 사용하여 모든 시각-언어 토큰에 접근할 수 있습니다.

3. **액션 토큰에 대한 이산 확산**:

   - **정방향(노이즈 추가) 과정**: 각 토큰 $a_{t,i}$를 확률 $\beta_t$로 `[MASK]` 토큰으로 변환하고 $1-\beta_t$로 유지합니다. 이 과정을 반복하여 $a_0$에서 $a_T$로 노이즈가 추가됩니다.
     $$Q_t e_{a_{t,i}} = (1-\beta_t)e_{a_{t,i}} + \beta_t e_M$$
     $a_t$의 분포는 $q(a_t|a_0) = \prod_{i=1}^L \text{Categorical}(a_{t,i}|\bar{Q}_t e_{a_{0,i}})$로 정의됩니다.
   - **역방향(노이즈 제거) 과정 및 훈련**:
     - 멀티모달 문맥 $c$하에서 $p_{\theta}(a_{t-1}|a_t,c)$를 예측합니다.
     - 훈련 시, 액션 포지션의 부분 집합을 `[MASK]` 토큰으로 대체하고 마스크된 인덱스에 대해 교차 엔트로피(cross-entropy) 목적 함수를 최적화하여 원본 토큰을 복구하도록 트랜스포머 $f_{\theta}$를 훈련합니다:
       $$\mathcal{L}_{\text{CE}}(\theta) = -\sum_{i \in \mathcal{M}_{\gamma_t}} \log p_{\theta}(a_{0,i} | \tilde{a}_t, c)$$
       여기서 $\gamma_t$는 마스크 비율을 나타냅니다.

4. **적응형 디코딩 메커니즘**:

   - 추론 시, 모든 액션 포지션은 `[MASK]`로 초기화되고, 소수의 병렬 정제(refinement) 라운드를 수행합니다.
   - 각 라운드 $t$에서, 모델은 현재 마스크된 모든 위치에 대한 토큰 사후 분포를 예측합니다.
   - 코사인 스케줄 $\gamma_t = \cos(\frac{\pi}{2}t)$에 따라 마스크 비율을 설정하고, 이 비율로 얼마나 많은 위치가 마스크된 상태로 남을지 결정합니다.
   - 데이터 의존적 점수(최대 신뢰도(Max Confidence) $s_{t,i} = \max_k p_{\theta}(k|a_t,c)$ 또는 신뢰도 차이(Confidence Gap) $g_{t,i} = p_{\theta}(k^{(1)}|\cdot) - p_{\theta}(k^{(2)}|\cdot)$ 중 하나)에 따라 마스크된 위치의 순위를 매깁니다.
   - 가장 높은 점수를 받은 $(1-\gamma_{t+1})L$개의 위치에 샘플링된 토큰을 확정하고, 나머지는 다음 라운드를 위해 마스크된 상태로 둡니다. 이 "쉬운 것 먼저, 어려운 것 나중에" 방식은 디코딩 순서를 인스턴스에 따라 적응시킵니다.

5. **2차 재마스킹(Secondary Re-Masking)**:
   - 초기 오류가 지속되는 것을 방지하기 위해, 이전에 확정된 토큰에 대해 두 가지 경량 검사를 실행합니다.
   - **임계값(Threshold) 검사**: 현재 예측 신뢰도가 단조 증가하는 단계 의존적 임계값 $\eta_{\text{abs}_t}$ 아래로 떨어지면 토큰을 재마스킹합니다.
     $$R_{\text{abs}_t} = \{i \in K_t : s_{t,i} < \eta_{\text{abs}_t}\}$$
   - **잔여 감소(Residual-drop) 검사**: 토큰이 처음 확정되었을 때의 신뢰도 $s^{\text{ref}}_i$와 현재 신뢰도 $s_{t,i}$ 사이의 감소 $\Delta_{t,i} = s^{\text{ref}}_i - s_{t,i}$가 큰 경우 (임계값을 초과하거나 상위 $Q$개), 토큰을 재마스킹합니다.
     $$R_{\text{drop}_t} = \{i \in K_t : \Delta_{t,i} > \eta_{\text{drop}_t}\} \text{ or } R_{\text{drop}_t} = \text{arg top}_Q \Delta_{t,i}$$
   - 이러한 검사를 통과하지 못한 토큰은 다음 단계에서 `[MASK]`로 설정됩니다.

## 📊 Results

- **LIBERO 벤치마크**: Discrete Diffusion VLA는 96.3%의 평균 성공률(SR)을 달성하여, OpenVLA-OFT (Discrete)의 95.4% 대비 0.9%p 향상된 성능을 보였습니다. 이는 이산 확산 디코딩이 병렬 디코딩보다 일관된 이점을 제공함을 시사합니다. 자기회귀 방식인 OpenVLA(76.5%)보다 훨씬 우수합니다.
- **SimplerEnv–Fractal (Google Robot)**: Visual Matching 평균에서 71.2%를 기록하여 $\pi_0$ (58.8%), $\pi_0$+FAST (61.9%), OpenVLA-OFT (63.0%)와 같은 베이스라인을 명확히 능가했습니다. Variant Aggregation에서는 56.9%로 RT-2-X (64.3%) 및 $\pi_0$+FAST (59.0%)와 경쟁력 있는 성능을 보였습니다. 전체 평균은 64.1%로 최고치를 달성했습니다.
- **SimplerEnv–Bridge (WidowX Robot)**: 49.3%의 최고 전체 평균을 달성하여 $\pi_0$ (27.8%), $\pi_0$+FAST (39.5%)와 같은 확산/플로우 매칭 정책 및 Octo-Small (34.5%)과 같은 AR 기반 베이스라인을 능가했습니다.
- **추론 효율성**: AR 디코더가 액션 청크 길이 $L$에 비례하는 $L$번의 순차적 함수 평가(NFE)를 요구하는 반면, Discrete Diffusion VLA는 고정된 적은 수의 정제 단계 $T$를 통해 $T$번의 NFE만으로 액션 청크 전체를 노이즈 제거합니다. LIBERO 실험 ( $L=56$ )의 경우, 기본 $T=12$로 NFE를 4.7배 감소시켰습니다.

## 🧠 Insights & Discussion

- **통합 아키텍처의 이점**: Discrete Diffusion VLA는 액션 생성을 단일 트랜스포머 내에서 이산 확산으로 처리함으로써, 사전 훈련된 VLM의 비전-언어 사전 지식(prior)을 보존하고, 모델 크기에 따른 확장성(scaling behavior)을 상속할 수 있는 길을 열었습니다. 이는 대규모 VLA 연구의 기반이 됩니다.
- **자기회귀 병목 현상 해소**: "쉬운 것 먼저, 어려운 것 나중에" 적응형 디코딩과 2차 재마스킹을 통해 자기회귀 모델의 좌측-우측 디코딩 병목 현상을 해결하고, 병렬 디코딩과 견고한 오류 수정을 가능하게 합니다. 전체 멀티모달 문맥을 활용하여 불확실한 예측을 반복적으로 개선합니다.
- **성능 우위**: 세 가지 다른 로봇 환경에서 AR 및 연속 확산 베이스라인 대비 일관되게 우수한 성능을 보여, 이산 확산 액션 디코더가 정밀한 액션 모델링과 일관된 훈련을 지원함을 입증했습니다.
- **한계점**: 고정된 빈(bin)을 사용한 액션 토큰화는 연속 제어에 비해 거칠 수 있으며, 이로 인해 서브-빈(sub-bin) 정밀도 손실이 발생할 수 있습니다. 보다 표현력이 풍부한 액션 인코딩을 개발하거나, 연속 공간 손실 메커니즘을 이산 확산 VLA와 통합하는 것이 향후 연구 방향이 될 수 있습니다.

## 📌 TL;DR

Discrete Diffusion VLA는 로봇 액션을 이산 토큰 청크로 모델링하고 단일 트랜스포머 내에서 이산 확산 방식으로 디코딩하는 VLA 정책입니다. 이는 자기회귀 모델의 순차적 병목 현상과 연속 확산 모델의 VLM 비통합 문제를 해결합니다. "쉬운 것 먼저, 어려운 것 나중에" 적응형 디코딩과 2차 재마스킹을 통해 병렬 액션 토큰 디코딩과 견고한 오류 수정을 가능하게 하며, LIBERO 및 SimplerEnv 벤치마크에서 기존 자기회귀 및 연속 확산 베이스라인을 능가하는 최신 성능을 달성합니다. 적은 함수 평가(NFE)로 효율적인 추론을 제공하며, 대규모 VLA 모델 개발을 위한 통합되고 확장 가능한 아키텍처를 제시합니다.
