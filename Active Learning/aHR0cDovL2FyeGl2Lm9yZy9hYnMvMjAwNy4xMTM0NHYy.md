# DEAL: Deep Evidential Active Learning for Image Classification

Patrick Hemmer, Niklas Kühls, Jakob Schöffer

## 🧩 Problem to Solve

이미지 분류와 같은 지도 학습 컴퓨터 비전 태스크에서 CNN(Convolutional Neural Networks)은 최신 성능을 달성했지만, 모델 학습 및 검증을 위해 대량의 레이블링된 데이터셋을 필요로 합니다. 많은 도메인에서 레이블이 없는 데이터는 풍부하지만, 특히 전문가 지식이 필요한 경우 데이터 레이블링은 비용이 많이 듭니다. 기존의 능동 학습(Active Learning, AL) 방법들은 CNN에 적용될 때 일관된 성능을 보이지 않거나 계산 비용이 많이 드는 경향이 있어, 제한된 레이블링 예산으로 모델 성능을 효율적으로 향상시키는 새로운 AL 접근 방식이 필요합니다.

## ✨ Key Contributions

- **새로운 AL 알고리즘 제안:** CNN의 Softmax 출력 대신 디리클레 밀도(Dirichlet density)의 파라미터를 사용하여 예측 불확실성을 효과적으로 포착하는 DEAL(Deep Evidential Active Learning)을 제안합니다. 이는 모델이 가장 정보력이 높은 샘플에 대해 더 정확한 판단을 내리도록 돕습니다.
- **일관된 최첨단 성능:** MNIST 및 CIFAR-10 데이터셋에 대한 광범위한 실험에서 DEAL이 다른 최첨단 AL 접근 방식들을 일관되게 능가함을 입증했습니다.
- **효율적인 레이블링 감소 및 빠른 획득 시간:** 특정 성능 수준(예: 90% 정확도)을 달성하는 데 필요한 레이블링된 이미지 수를 크게 줄이며(예: 소아 폐렴 진단에서 34.52% 감소), MC-Dropout이나 Deep Ensemble과 같은 방법에 비해 데이터 획득(acquisition) 단계의 계산 비용이 훨씬 적습니다.
- **실제 의료 영상 활용 사례 적용:** 소아 흉부 X-ray 이미지에서 폐렴의 시각적 신호를 자동 탐지하는 실제 의료 사용 사례에 DEAL을 적용하여 그 이점을 확인했습니다.

## 📎 Related Works

- **생성형(Generative) AL:** GAN(Generative Adversarial Networks)을 활용하여 정보성 샘플을 생성하거나(예: cGAN [27], ASAL [28]), 실제 이미지와 유사한 데이터를 검색하여 학습 세트에 추가합니다.
- **풀 기반(Pool-based) AL:** 다양한 획득 전략을 사용하여 가장 정보성이 높은 데이터를 샘플링합니다.
  - **다양성 기반(Diversity-based):** 레이블이 없는 데이터 풀을 가장 적절하게 대표하는 샘플을 선택합니다. 예: core-set [33] (유클리드 거리 최소화).
  - **불확실성 기반(Uncertainty-based):** 모델이 예측에 대해 더 불확실할수록 해당 데이터가 더 정보성이 높다는 가정에 기반합니다.
    - 표준 Softmax 출력 사용: 최소 마진, 엔트로피 등의 획득 함수 [41]. (단점: 높은 Softmax 출력에서도 모델이 불확실할 수 있음 [10]).
    - 베이즈적 접근: MC-Dropout [12] (추론 시 다중 순방향 통과로 불확실성 추정), Deep Ensemble [4] (여러 모델 앙상블로 불확실성 근사).
    - 손실 예측 모델 추가: 네트워크에 추가 손실 예측 모델을 부착하여 레이블 없는 샘플의 손실을 예측 [42].
  - **다양성-불확실성 결합:** 배치 단위로 데이터를 쿼리할 때 불확실성 기반만으로는 중복이 발생할 수 있어 다양성을 함께 고려합니다. 예: BatchBALD [21], BADGE [3].
- **DEAL의 위치:** **uncertainty-based** AL 접근 방식에 속하며, Softmax 확률 대신 디리클레 분포를 사용하여 고품질 불확실성 추정치를 단일 순방향 통과로 얻는다는 점에서 기존 방법들과 차별화됩니다.

## 🛠️ Methodology

DEAL은 CNN의 표준 Softmax 출력 계층을 디리클레 밀도 파라미터를 출력하는 계층으로 대체하여 예측 불확실성을 직접 모델링합니다.

1. **증거 이론 기반 불확실성 정량화:**
   - 일반적인 Softmax 함수는 클래스 확률에 대한 점 추정치를 제공하지만, 특정 클래스에 대해 높은 Softmax 출력이 있어도 모델은 예측에 불확실할 수 있습니다.
   - DEAL은 Softmax 함수를 Softsign과 같은 비선형 활성화 함수로 대체하고, 그 출력을 디리클레 분포의 증거 벡터($e_k$)로 사용합니다.
   - $K$개의 클래스에 대해, 각 클래스 $k$에 대한 믿음 질량 $b_k$와 전체 불확실성 $u$는 다음 관계를 가집니다:
     $$u + \sum_{k=1}^{K} b_k = 1.$$
   - 증거 $e_k \ge 0$를 기반으로 믿음 질량 $b_k$와 불확실성 $u$를 정의합니다. 여기서 $S = \sum_{i=1}^{K} (e_i + 1)$입니다:
     $$b_k = \frac{e_k}{S}, \quad u = \frac{K}{S}.$$
   - 디리클레 분포의 파라미터 $\alpha_k$는 $e_k + 1$로 정의되며, 이를 통해 주관적인 의견을 형성합니다. 예상되는 클래스 확률 $\hat{p}_k$는 디리클레 분포의 평균으로 계산됩니다:
     $$\hat{p}_k = \frac{\alpha_k}{S}.$$
   - **손실 함수:** 출력 손실과 KL(Kullback-Leibler) 발산 형태의 정규화 항을 포함하도록 손실 함수가 조정됩니다. KL 발산은 예측 분포를 정규화하여 올바르게 분류할 수 없는 샘플에 대한 총 증거가 0으로 감소하도록 보장합니다.
     $$L(\Theta) = \sum_{i=1}^{N} L_i(\Theta) + \lambda_t \sum_{i=1}^{N} \text{KL} \left( D(p_i | \tilde{\alpha}_i) \left| D(p_i | 1) \right. \right),$$
     여기서 $L_i(\Theta)$는 표준 분류 손실 항이며, $\text{KL}(\cdot)$은 디리클레 분포 간의 KL 발산입니다.
2. **불확실성 기반 능동 학습 프레임워크:**
   - **획득 함수(Acquisition Function):** 모델 $M$과 레이블이 없는 데이터 풀 $D_{l=0}$가 주어졌을 때, 획득 함수 $a(x, M)$를 사용하여 쿼리할 다음 데이터 샘플을 선택합니다.
   - **최소 마진(Minimal Margin):** DEAL은 $p(y=k_1|x, D_{l=1}) - p(y=k_2|x, D_{l=1})$이 가장 작은 샘플을 선택하는 **minimal margin** 불확실성 척도를 사용합니다. 여기서 $k_1$과 $k_2$는 각각 샘플에 대한 가장 확률이 높은 클래스 레이블과 두 번째로 확률이 높은 클래스 레이블입니다. 이 때, CNN의 예상 클래스 확률은 위의 식 (4)에서 도출된 것을 사용합니다.
   - **AL 알고리즘 (Algorithm 1):**
     - 작은 레이블링된 데이터셋 $D_{l=1}$으로 모델을 초기 학습합니다.
     - 주어진 레이블링 예산이 소진될 때까지 반복합니다:
       - 획득 함수 **minimal margin**을 기반으로 $A$개의 레이블 없는 샘플을 선택합니다.
       - 전문가로부터 레이블을 획득하고 $D_{l=1}$에 추가합니다.
       - 모델을 처음부터 다시 학습합니다.

## 📊 Results

- **MNIST 및 CIFAR-10 성능:**
  - LeNet 및 ResNet-18 아키텍처를 사용하여 MNIST 및 CIFAR-10 데이터셋에서 실험했습니다.
  - DEAL은 모든 획득 라운드에서 다른 모든 최첨단 AL 접근 방식(Minimal Margin Softmax, core-set, MC-Dropout, Deep Ensemble)을 일관되게 능가했습니다.
  - MNIST에서 DEAL은 두 번째로 우수한 방법에 비해 평균 1.01% (LeNet) 및 1.06% (ResNet) 더 높은 정확도를 보였습니다.
  - CIFAR-10에서 DEAL은 무작위 샘플링(LeNet에서 다른 모든 방법보다 우수)보다 평균 1.51% 더 높았고, Deep Ensemble(ResNet에서 두 번째)보다 평균 0.51% 더 높았습니다.
  - 모든 결과는 0.01 수준에서 통계적 유의미성(paired t-test)을 가집니다.
- **레이블링 노력 감소:**
  - 미리 정의된 모델 성능(예: MNIST 95%, CIFAR-10 87%)을 달성하는 데 필요한 이미지 수가 크게 줄었습니다.
  - MNIST에서 무작위 샘플링 대비 34.15%, CIFAR-10에서 24.29% 레이블링 노력을 절감했습니다.
  - 두 번째로 우수한 방법(Minimal Margin Softmax)과 비교해도 MNIST에서 12.91%, CIFAR-10에서 5.78% 추가 절감이 가능했습니다.
- **획득 시간 분석:**
  - DEAL의 획득 단계는 무작위 샘플링 및 Minimal Margin Softmax와 유사하게 가장 시간이 적게 소요되는 방법 중 하나입니다.
  - MC-Dropout ($n_{fp}=25$ 순방향 통과) 및 Deep Ensemble ($n_{en}=5$ 앙상블 멤버)과 같은 방법보다 훨씬 빠릅니다. 예를 들어, CIFAR-10에서 DEAL은 139.51초가 소요된 반면, Deep Ensemble은 11,410.28초가 소요되었습니다.
  - core-set 방법은 고차원 데이터(CIFAR-10)에서 DEAL보다 상당히 느려질 수 있습니다 (931.28초 차이).
- **실제 의료 데이터셋(폐렴 진단) 적용:**
  - 소아 흉부 X-ray 이미지 폐렴 진단 데이터셋에 DEAL을 적용한 결과, 다른 모든 방법을 일관되게 능가했습니다.
  - 90% 테스트 정확도를 달성하기 위해 무작위 샘플링 대비 243개의 이미지(34.52%)의 레이블링 노력을 절감했습니다.

## 🧠 Insights & Discussion

- **고품질 불확실성 추정의 중요성:** DEAL은 디리클레 분포를 사용하여 고품질의 불확실성 추정치를 제공함으로써, 적은 수의 레이블링된 데이터로도 빠르게 모델 성능을 향상시킬 수 있음을 입증했습니다. 이는 특히 의료 분야와 같이 전문가의 레이블링 비용이 높은 분야에서 큰 이점이 있습니다.
- **효율성과 성능의 균형:** DEAL은 뛰어난 AL 성능을 달성하면서도, 기존의 복잡하거나 계산 비용이 많이 드는 베이즈적 접근 방식(예: MC-Dropout, Deep Ensemble)에 비해 획득 단계가 훨씬 효율적입니다. 이는 실용적인 적용 가능성을 높입니다.
- **제한 사항 및 향후 연구:** DEAL은 순수하게 불확실성 기반의 데이터 선택을 사용합니다. 이는 획득된 배치에 중복성을 유발하여 최적이 아닌 솔루션으로 이어질 위험이 있습니다. 따라서 향후 연구에서는 다양성 기준을 DEAL 접근 방식에 통합하여 이러한 한계를 극복할 수 있습니다.

## 📌 TL;DR

DEAL(Deep Evidential Active Learning)은 비용이 많이 드는 CNN 데이터 레이블링 문제를 해결하기 위해, Softmax 출력 대신 디리클레 밀도 파라미터를 사용하여 예측 불확실성을 정량화하는 새로운 AL 알고리즘을 제안합니다. 이 방법은 최소 마진 획득 함수와 결합하여 정보력이 높은 샘플을 효율적으로 선택하며, MNIST, CIFAR-10, 소아 폐렴 X-ray 데이터셋에서 최첨단 AL 방법들을 일관되게 능가하는 성능을 보였습니다. DEAL은 필요한 레이블링 데이터 양을 크게 줄이고(예: 폐렴 진단에서 34.52% 감소), 획득 시간 또한 효율적이어서 실용적인 응용 가능성이 높습니다. 향후 연구는 다양성 기준을 통합하여 중복성 문제를 해결할 수 있습니다.
