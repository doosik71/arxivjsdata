# ACTIVE LEARNING FOR CONVOLUTIONAL NEURAL NETWORKS: A CORE-SET APPROACH

Ozan Sener, Silvio Savarese

## 🧩 Problem to Solve

컨볼루션 신경망(CNN)은 뛰어난 성능을 보이지만, 대규모의 레이블링된 데이터셋을 필요로 합니다. 이러한 데이터셋을 수집하는 것은 매우 비용이 많이 들고 시간 소모적인 작업입니다. 액티브 러닝(Active Learning)은 제한된 예산 내에서 모델 정확도를 극대화하기 위해 어떤 데이터 포인트를 레이블링할지 '스마트하게' 선택하는 것을 목표로 합니다.

그러나 기존의 액티브 러닝 휴리스틱은 CNN의 '배치(batch)' 설정(한 번에 여러 샘플을 쿼리하는 경우)에 적용될 때 효과적이지 못하다는 문제가 있습니다. 이는 단일 샘플로는 CNN 모델에 통계적으로 유의미한 영향을 주기 어렵고, 각 샘플마다 전체 모델을 재학습하는 것이 비현실적이기 때문에 배치 쿼리가 필수적이며, 이로 인해 쿼리된 샘플들 간에 상관관계가 발생하기 때문입니다.

## ✨ Key Contributions

- 액티브 러닝 문제를 "코어-셋(core-set) 선택" 문제로 재정의하여, 선택된 서브셋으로 학습된 모델이 전체 데이터셋에 대해 경쟁력 있는 성능을 갖도록 합니다.
- 데이터 포인트들의 기하학적 구조를 이용하여 모든 선택된 서브셋의 성능을 특징화하는 이론적 결과를 제시하며, 이는 CNN에도 적용 가능합니다.
- 이러한 특징화에 따라 최상의 결과를 낼 것으로 예상되는 서브셋을 선택하는 새로운 액티브 러닝 알고리즘을 제안합니다. 이 문제는 k-Center 문제와 동등합니다.
- 조합 최적화 문제인 k-Center 문제에 대한 효율적인 근사 해법과 견고한(robust) MIP(Mixed Integer Program) 접근 방식을 채택합니다.
- 광범위한 이미지 분류 실험(CIFAR-10, CIFAR-100, SVHN)을 통해 제안된 방법이 기존 액티브 러닝 접근 방식을 크게 능가하는 최첨단 성능을 달성함을 입증합니다.

## 📎 Related Works

- **액티브 러닝**: 정보 이론(information theoretical) 기반, 앙상블(ensemble) 기반, 불확실성(uncertainty) 기반 등 다양한 휴리스틱이 연구되어 왔습니다. 베이지안 액티브 러닝(Bayesian active learning)은 대규모 CNN에는 확장성이 부족하며, 배치 샘플링 시 효과적이지 않음이 지적됩니다. 최적화 기반 접근 방식은 데이터 포인트 수($n$)에 대해 $n^2$ 변수를 사용하여 대규모 데이터셋에는 적용하기 어렵습니다.
- **코어-셋 선택**: 전체 레이블링된 데이터셋에서 일부 서브셋을 선택하여, 이 서브셋으로 학습된 모델이 전체 데이터셋으로 학습된 모델과 최대한 유사하게 성능을 내도록 하는 문제입니다. SVM, k-Means 등 특정 학습 알고리즘을 위한 코어-셋 방법은 존재하지만, CNN을 위한 방법은 없었습니다. 본 논문은 기존의 비지도 서브셋 선택(unsupervised subset selection) 방법과 유사하지만, facility location 문제의 min-sum 형태 대신 minimax(k-Center) 형태를 사용하고 CNN에 대한 이론적 보장을 제공합니다.
- **준지도 딥 러닝(Weakly-Supervised Deep Learning)**: Ladder networks, 적대적 생성 신경망(GANs)과 같은 방법들이 있으며, 본 연구에서는 Ladder networks를 활용하여 준지도 학습 환경에서의 액티브 러닝 성능을 실험합니다.

## 🛠️ Methodology

1. **액티브 러닝 재정의**: CNN의 배치 샘플링 환경에 맞춰 액티브 러닝 문제를 "코어-셋 선택"으로 재정의합니다. 이는 전체 데이터셋($[n]$)에 대한 평균 손실과 레이블링된 서브셋($s$)에 대한 평균 손실 간의 차이, 즉 **코어-셋 손실(Core-Set Loss)**을 최소화하는 것을 목표로 합니다:
   $$ \min*{s_1 : |s_1| \le b} \left| \frac{1}{n} \sum*{i \in [n]} l(x*i,y_i;A*{s*0 \cup s_1}) - \frac{1}{|s_0+s_1|} \sum*{j \in s*0 \cup s_1} l(x_j,y_j;A*{s_0 \cup s_1}) \right| $$
2. **CNN을 위한 코어-셋 이론**: 레이블 정보 없이 최적화할 수 있도록 코어-셋 손실의 상한(upper bound)을 도출합니다. 이 상한은 데이터 포인트의 기하학적 구조, 특히 데이터셋의 커버링 반경(covering radius) $\delta_s$에 따라 결정됩니다.
   - **Theorem 1**: 손실 함수 $l(\cdot,y,w)$가 $\lambda_l$-Lipschitz 연속이고 회귀 함수 $\eta_c(x)$가 $\lambda_\eta$-Lipschitz 연속이며 $s$가 $[n]$의 $\delta_s$-커버일 때, 코어-셋 손실은 $O(\delta_s) + O(\sqrt{\frac{1}{n}})$으로 바운드됩니다.
   - **Lemma 1**: ReLU 및 Max-Pool 비선형성을 사용하는 CNN의 손실 함수(softmax 출력과 원하는 클래스 확률 간의 $L_2$ 거리)는 입력에 대해 Lipschitz 연속임을 증명하여, Theorem 1이 CNN에 적용됨을 보입니다.
3. **k-Center 문제 해결**: 코어-셋 손실의 상한을 최소화하는 문제는 k-Center 문제(minimax facility location)와 동등합니다. 즉, $b$개의 중심점을 선택하여 데이터 포인트와 가장 가까운 중심점 사이의 최대 거리를 최소화하는 것입니다.
   - **Greedy k-Center (Algorithm 1)**: NP-Hard 문제인 k-Center 문제에 대해 2-OPT 해법을 제공하는 그리디 알고리즘을 사용하여 초기 해를 구합니다. 이는 기존에 선택된 점들로부터 가장 멀리 떨어진 점을 반복적으로 선택합니다.
   - **Robust k-Center (Algorithm 2)**: 최적값을 반복적으로 쿼리하여 2-OPT 해법을 개선합니다. 최적값 $\delta$의 상한을 확인하기 위해 MIP(Mixed Integer Program)를 사용하여 $\max_i \min_{j \in s_1 \cup s_0} \Delta(x_i, x_j) \le \delta$의 만족 여부를 이진 탐색합니다. 또한, 견고성을 위해 최대 $\Xi$개의 아웃라이어를 허용합니다.
4. **구현 세부 사항**:
   - **거리 측정**: 최종 완전 연결(fully-connected) 레이어의 활성화 값 간의 $L_2$ 거리를 $\Delta(\cdot,\cdot)$로 사용합니다.
   - **CNN 아키텍처**: 모든 실험에서 VGG-16을 사용하고 He et al. (2016)에 따라 필터를 초기화합니다.
   - **최적화**: RMSProp, 학습률 $1e^{-3}$을 사용하며, 각 반복 후 CNN을 처음부터 다시 훈련합니다.
   - **MIP 솔버**: Gurobi를 사용합니다.

## 📊 Results

- **성능 우위**: CIFAR-10, CIFAR-100, SVHN 데이터셋의 이미지 분류 태스크에서 제안하는 방법이 모든 기존 액티브 러닝 기준선(Random, Empirical Uncertainty, Oracle Uncertainty, DBAL, BMDR, CEAL, k-Median)을 크게 능가하는 최상위 성능을 달성했습니다 (그림 3, 4).
- **준지도 학습 환경에서의 효과**: 특히 준지도 학습 모델(Ladder networks)을 사용할 때 제안된 방법이 훨씬 더 큰 폭으로 성능이 향상되었습니다. 이는 더 나은 특징 학습이 정확한 데이터 기하학적 구조를 제공하여, 기하학적 특성을 활용하는 본 방법의 성능을 극대화하기 때문입니다.
- **CIFAR-100에서의 한계**: CIFAR-100(클래스 수가 많음)에서는 CIFAR-10 및 SVHN에 비해 효과가 다소 덜했습니다. 이는 이론적 분석에서 코어-셋 손실의 상한이 클래스 수에 비례하여 스케일링되기 때문입니다.
- **k-Center 솔루션의 최적성**: MIP 기반의 최적 k-Center 솔루션은 그리디 2-OPT 솔루션에 비해 작지만 중요한 정확도 개선을 보여주었습니다 (그림 6). MIP 솔루션의 런타임은 5만 개 이미지 데이터셋에서도 현실적인 수준으로 측정되었습니다 (표 1).

## 🧠 Insights & Discussion

- **기존 방법의 한계**: 기존의 불확실성 기반 방법들은 소프트맥스 확률이 불확실성에 대한 좋은 대리 지표가 아니며, 배치 샘플링으로 인한 샘플 간 상관관계를 효과적으로 다루지 못하여 성능이 제한적임을 확인했습니다. 순수한 클러스터링 기반 방법(k-Medians) 역시 초기 i.i.d. 샘플로 잘 커버되는 지점만 샘플링하여 데이터 분포의 "꼬리(tails)" 부분을 놓칠 수 있습니다.
- **기하학적 접근의 강점**: tSNE 임베딩을 통한 시각화(그림 5)는 불확실성 기반 방법들이 샘플 상관관계로 인해 데이터 공간의 넓은 부분을 커버하지 못하는 반면, 제안된 코어-셋 방법은 공간을 보다 균등하게 커버함을 보여줍니다. 이는 제안 방법의 강점이 데이터의 기하학적 구조를 효과적으로 활용하는 데 있음을 시사합니다.
- **향후 연구 방향**: 불확실성 정보를 본 방법론에 원칙적인 방식으로 통합하는 것은 유망한 미래 연구 방향입니다.

## 📌 TL;DR

CNN 훈련 시 높은 레이블링 비용 문제를 해결하기 위해, 본 논문은 액티브 러닝을 **코어-셋(core-set) 선택** 문제로 재정의합니다. 데이터 포인트의 기하학적 구조를 활용하여 코어-셋 손실의 이론적 상한을 제시하고, 이를 최소화하는 문제를 **k-Center 문제**로 해결합니다. 제안된 방법은 그리디 2-OPT 근사 알고리즘과 견고한 MIP(Mixed Integer Program)를 사용하여 효율적이고 최적화된 데이터 서브셋을 선택합니다. 실험 결과, 이 코어-셋 접근 방식은 CIFAR, SVHN과 같은 이미지 분류 벤치마크에서 기존 액티브 러닝 방법론들을 **크게 능가하는** 최신 성능을 달성했습니다. 특히, 준지도 학습 환경에서 향상된 특징 학습과 결합될 때 더욱 강력한 성능을 보였으며, 이는 기존 불확실성 기반 방법이 배치 샘플링으로 인한 샘플 상관관계를 효과적으로 처리하지 못하는 한계를 극복했음을 시사합니다.
