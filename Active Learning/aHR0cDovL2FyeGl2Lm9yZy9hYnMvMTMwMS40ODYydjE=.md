# Active Learning of Inverse Models with Intrinsically Motivated Goal Exploration in Robots

Adrien Baranes, Pierre-Yves Oudeyer

## 🧩 Problem to Solve

로봇이 실제 환경에서 강건하고 적응적으로 작동하려면 행동의 결과를 예측하는 순방향 모델(forward model)과 원하는 효과를 생성하는 데 필요한 행동 정책을 계산하는 역방향 모델(inverse model)을 학습해야 합니다. 그러나 이러한 모델의 학습은 다음과 같은 여러 가지 심각한 기술적 문제에 직면합니다:

- **모델링의 복잡성:** 로봇의 물리적 특성(예: 유연한 몸체)이나 상호작용할 수 있는 모든 환경 요소를 사전에 정확히 모델링하는 것은 불가능합니다.
- **고차원성 및 비정상성:** 로봇의 센서모터 공간은 종종 고차원적이고 연속적이며, 공간적 또는 시간적으로 비정상적입니다.
- **자율적 데이터 수집의 한계:** 로봇은 제한된 수명 내에 방대한 센서모터 공간에서 학습 예제를 자율적으로, 점진적으로 수집해야 하므로 훈련 데이터 수가 제한됩니다.
- **기존 활성 학습의 비효율성:** 기존의 활성 학습(active learning) 방법은 최대 불확실성이나 예측 오류를 탐색하는 데 초점을 맞추지만, 이는 실세계 로봇의 개방형 환경에서 쉽게 함정에 빠지거나 비효율적일 수 있습니다. 특히, 액츄에이터 공간(actuator space)에서 직접 정책을 샘플링하는 방식은 중복성이 높은 로봇의 경우 동일한 효과를 내는 다양한 행동 정책을 배우는 데 많은 시간을 소모하여 다양한 작업을 학습하는 데 비효율적입니다.

이 논문은 고차원, 중복 로봇에서 이러한 문제를 극복하고 효율적으로 역방향 모델을 자율적으로 학습하는 방법을 제안합니다.

## ✨ Key Contributions

이 논문에서 제안하는 SAGG-RIAC(Self-Adaptive Goal Generation - Robust Intelligent Adaptive Curiosity) 아키텍처는 다음을 포함한 여러 핵심적인 기여를 합니다:

- **중복 로봇의 역방향 모델 능동 학습:** 고차원 중복 로봇에서 본질적으로 동기 부여된 목표 탐색을 통해 역방향 모델을 효율적으로 능동 학습하는 SAGG-RIAC 아키텍처를 도입합니다.
- **매개변수화된 작업 공간 탐색:** 매개변수화된 작업(task/goal) 분포를 해결하는 데 필요한 매개변수화된 모터 기술/정책 분포를 로봇이 효율적이고 능동적으로 학습하도록 합니다. 이는 액츄에이터 공간이 아닌 작업 공간에서 목표를 능동적으로 샘플링하여 중복성을 활용합니다.
- **능동적 목표 탐색의 효율성:** 중복 로봇의 역방향 모델 학습에서 매개변수화된 작업의 능동 샘플링(능동 목표 탐색)이 매개변수화된 정책의 직접적인 능동 샘플링보다 훨씬 빠르다는 것을 입증합니다.
- **역량 진전 기반 발달적 탐색:** 역량 진전(competence progress) 측정에 기반한 능동 발달적 탐색은 로봇이 점진적으로 학습 복잡도가 증가하는 작업에 집중하도록 자율적으로 유도합니다.
- **도달 가능성 한계 자율 발견:** 로봇이 작업 공간의 어떤 부분을 학습하여 도달할 수 있고 어떤 부분을 도달할 수 없는지 능동적으로 발견할 수 있도록 합니다.
- **학습 속도 및 일반화 성능 향상:** 기존 문헌의 여러 방법과 비교하여 학습된 역방향 모델의 품질(학습 속도 및 목표 도달 일반화 성능)을 크게 향상시킵니다.
- **다양한 로봇 설정에서의 검증:** 3가지 로봇 설정(고도로 중복된 로봇 팔의 역운동학 학습, 4족 보행 로봇의 전방향 보행 학습, 유연한 낚싯대를 제어하는 팔 학습)에서 아키텍처의 유효성을 실험적으로 증명합니다.

## 📎 Related Works

이 논문은 로봇의 모터 학습 및 탐색을 제한하고 유도하는 다양한 기존 접근 방식들을 검토합니다:

- **탐색 제한(Constraining the Exploration):**
  - **사회적 유도 (Social guidance):** 시연/모방 학습을 통해 외부 시연자가 로봇 학습을 돕는 방식 (예: [1, 63, 18, 24, 59, 26, 60]).
  - **강화 학습 (Reinforcement Learning, RL):** 외부 보상 함수로 목표가 미리 정의되어야 하며, 고차원/광범위한 공간에서는 탐색을 제한해야 함 (예: [114, 84, 117]).
  - **쉬프팅 세트포인트 알고리즘 (Shifting Setpoint Algorithm, SSA):** 고정된 목표를 향해 현재 위치 주변의 지역 모델을 구축하며 점진적으로 탐색하는 방식 [92].
  - 이러한 방법들은 특정 작업을 위해 인간의 개입을 필요로 합니다.
- **자율 탐색 유도(Driving Autonomous Exploration):**
  - **활성 학습 (Active Learning):** 샘플 복잡성을 최소화하면서 모델을 학습하기 위해 "흥미" 개념(예: 예상 정보 이득)을 사용하여 탐색을 유도합니다 (예: [41, 30, 89, 105, 60]). 최대 예측 오류, 지역 밀도, 모델 분산 감소, 최대 불확실성 등을 기준으로 합니다.
  - **본질적 동기 (Intrinsic Motivation) / 호기심 기반 학습 (Curiosity-Driven Learning):** 로봇이 외부 보상 없이 자율적으로 기술을 연습하고 새로운 작업을 학습하도록 유도하는 메커니즘 (예: [115, 96, 12, 100], 개발 로봇 공학 [48, 21, 75, 77, 95]). 최대 예측 오류 감소, 최대 압축 진전, 최대 역량 진전 등 다양한 기준을 사용합니다.
    - **RIAC (Robust-Intelligent Adaptive Curiosity):** 센서모터 하위 공간에서 로봇이 행동 결과를 예측하는 오류 감소 속도를 기반으로 흥미도를 정의하며, 점진적으로 복잡도가 증가하는 하위 공간을 탐색하도록 유도 [8, 77].
- **고수준 탐색 유도 (Driving the Exploration at a Higher Level):**
  - RIAC와 같은 "지식 기반" 접근 방식은 행동 정책의 고차원 공간에서 탐색하여 순방향 모델을 학습하기 때문에, 역방향 모델 학습 및 중복 로봇에서 비효율적입니다. 동일한 작업을 수행하는 여러 방법을 탐색하는 데 시간을 너무 많이 소비할 수 있습니다.
  - **목표/작업 공간 탐색:** 유아의 모터 탐색 행동에서 영감을 받아, 목표를 작업 공간 내에 명시적으로 도입하고 이 목표 수준에서 탐색을 유도하는 것이 더 효율적인 접근 방식입니다 [126, 87, 124, 123].
  - **역량 기반 본질적 동기 (Competence Based Intrinsic Motivation):** 로봇이 액츄에이터 공간의 모터 재잘거림(motor babbling)이 아닌 목표/작업 공간에서 능동적인 탐색을 수행하도록 유도합니다 [74].
  - 이러한 방향으로, 이론 컴퓨터 과학 관점 [98, 99, 102], 이산 세계에서의 역량 진전 사용 [111], 수동적으로 목표를 미리 정의된 그리드에 도달시키는 방식 [85, 86] 등의 연구가 진행되었습니다.

SAGG-RIAC는 RIAC 및 SSA의 아이디어를 다중 레벨 활성 학습 아키텍처로 통합하여, 액츄에이터 공간이 아닌 작업 공간에서 역방향 모델 학습을 위한 능동 샘플링을 수행하며 역량 진전을 주요 동기 부여 메커니즘으로 사용합니다.

## 🛠️ Methodology

SAGG-RIAC는 로봇이 고차원 중복 공간에서 역방향 모델을 능동적으로 학습할 수 있도록 하는 본질적으로 동기 부여된 목표 탐색 메커니즘입니다. 이 아키텍처는 두 가지 시간 규모로 정의된 두 가지 수준의 능동 학습으로 구성됩니다:

1. **고수준 능동 학습 (Longer Time Scale):** 매개변수화된 작업 공간 $Y$에서 목표($y_g$)를 능동적으로 자율 생성하고 선택합니다. 이는 이전에 생성된 목표에 도달하는 역량 수준(예: 역량 진전)에 기반한 흥미 측정에 따라 결정됩니다.
2. **저수준 능동 학습 (Shorter Time Scale):** 고수준에서 선택된 목표에 도달하기 위한 저수준 행동($\pi_\theta$)을 목표 지향적으로 능동 선택하고 탐색합니다. 이는 학습된 순방향 및/또는 역방향 모델 품질의 진화와 관련된 지역적 흥미 측정에 따라 달라집니다.

### 모델 공식화

- **로봇 시스템:** 상태/맥락 공간 $S$, 매개변수화된 작업/목표 필드 $Y$.
- **행동:** 매개변수화된 모터 시너지 $\pi_\theta: S \to A$에 의해 생성되는 행동 시퀀스 $a$.
- **학습 목표:** 시작 맥락 $s \in S$와 원하는 목표 $y_g \in Y$가 주어졌을 때 목표에 도달하는 방법을 탐색하고 학습합니다. 이는 $\pi_{\theta(\text{Data})}(s_{\text{start}}, y_g, \rho)$와 같이 표현될 수 있습니다.
- **강화 학습 옵션 프레임워크와의 유사성:** 목표 자율 생성은 매개변수화된 옵션의 자율 생성 및 자율 선택으로, 목표 도달 시도는 특정 옵션의 학습으로 설명될 수 있습니다.

### 저수준 능동 학습 (Goal Directed Exploration and Learning)

고수준에서 목표가 선택되면, 저수준 목표 지향 탐색 및 학습 메커니즘은 다양한 방식으로 수행될 수 있습니다 (SAGG-RIAC는 구체적인 방법에 대해 적은 가정을 합니다):

- **점진적 학습 및 일반화:** 수집된 데이터를 기반으로 지역 순방향 및 역방향 모델을 점진적으로 구축하고 재사용할 수 있어야 합니다 (예: [20, 8, 55, 108]의 작업 공간 회귀 기술).
- **목표 지향 최적화:** 목표가 설정되면, 행동 정책 매개변수를 최적화하여 목표에 도달할 수 있어야 합니다 (예: 정책 경사 방법 [78, 112] 또는 확률적 최적화 [45]).
- **능동 최적화 (선택 사항):** 학습 피드백 메커니즘을 통해 탐색이 능동적이고 새로운 행동 선택이 학습된 모델의 품질에 대한 지역 측정에 의존해야 합니다.
- **회귀 기술:** 실험에서는 지역 선형 역방향 모델을 위해 Moore-Penrose 유사 역행렬을 사용한 메모리 기반 접근 방식을 사용합니다.

### 고수준 목표 자율 생성 및 자율 선택 (Goal Self-Generation and Self-Selection)

이는 역량 개념, 특히 지역 역량 진전 모니터링에 기반한 피드백에 의존합니다.

- **역량 측정 (Measure of Competence, $\Gamma_{y_g}$):**
  - 목표 도달 시도 종료 조건: 최대 반복 횟수 초과 또는 목표 도달.
  - 측정 기준: 도달된 지점 $y_f$와 실제 목표 $y_g$ 간의 유사성, 그리고 제약 $\rho$ 준수 여부.
  - 예시: $C(y_g, y_f, \emptyset) = -\|y_g - y_f\|^2$ (RIAC의 예측 오류를 작업 공간으로 확장).
  - 목표 도달 시도 중에도 모델 개선을 위해 역량 측정치를 계산할 수 있습니다.
- **지역 역량 진전 (Definition of Local Competence Progress):**
  - 작업 공간 $Y$를 영역 $R_i$로 나눕니다.
  - 영역 $R_i$의 역량 $Γ$는 최근 $\zeta$개의 시도된 목표에 대한 역량 측정값의 평균입니다 (식 1).
  - 영역 $R_i$의 흥미 $interest_i$는 해당 영역 내에서 지역 역량 진전의 절댓값으로 정의됩니다 (식 2). 이는 역량의 *변화*를 고려하며, 증가 및 감소하는 역량 모두를 포함합니다.
- **목표 자율 생성 (Goal Self-Generation):**
  - **공간 분할 (Splitting):** 흥미 수준에 따라 $Y$를 하위 공간으로 분할합니다. 각 분할은 미리 정의된 최대 목표 수 $g_{max}$에 도달하면 트리거됩니다. 분할은 두 결과 하위 공간의 흥미도 차이를 최대화하도록 수행됩니다.
  - **다음 목표 선택 (Selection):** 확률적 분포에 따라 다음 목표를 선택합니다:
    1. **모드 1 (70%):** 흥미도에 비례하는 확률로 선택된 영역 내에서 무작위 목표를 선택합니다.
    2. **모드 2 (20%):** 전체 공간 $Y$ 내에서 무작위 목표를 선택합니다.
    3. **모드 3 (10%):** 흥미도에 따라 영역을 선택한 후, 해당 영역에서 가장 낮은 역량 추정치를 받은 기존 목표 근처에 새로운 목표를 생성합니다.
- **시작 상태 감소 (Reduction of the Initiation Set):** $r$번의 도달 시도마다 로봇을 고정된 휴식 자세($s_{\text{rest}}, y_{\text{rest}}$)로 재설정하여, 학습에 사용되는 시작 상태의 수를 줄입니다.
- **알 수 없는 작업 공간 한계 해결 (New Challenges of Unknown Limits of the Task Space):**
  - **도달된 모든 지점 보존:** 목표 $y_g$를 향한 시도에서 $y_f \neq y_g$인 경우에도 $y_f$를 최대 역량으로 도달된 목표로 간주하여 기록합니다.
  - **하위 목표 추가 (Addition of subgoals):** 시작 위치와 목표 사이에 중간 지점들을 하위 목표로 추가하여 역량 측정 횟수를 늘립니다.
  - 이러한 휴리스틱은 필요한 무작위 탐색 횟수를 줄이고 도달 가능한 영역의 발견을 돕습니다.

### 실험 설정별 세부 구현

- **역운동학 학습 (중복 팔):** 진화하는 맥락을 다루며, SSA에서 영감을 받은 저수준 최적화 알고리즘을 사용합니다. 목표를 향한 경로에 하위 목표를 설정하고, 각 미세 행동 후 Jacobian $J(\alpha)$의 유사 역행렬을 이용해 $\Delta\alpha$를 계산하여 목표 방향으로 이동합니다. 예측 오류가 너무 크면 무작위 탐색을 수행합니다.
- **전방향 4족 보행 및 낚싯대 제어 (모터 시너지):** 고정된 맥락을 다루며, 매개변수화된 모터 시너지 $\pi_\theta$를 사용합니다. 저수준에서는 목표 $y_g$에 대한 모터 시너지 $\theta_g$를 추정하기 위해 지역 회귀(ANN 기반의 $l$개 최근접 이웃 선택 후 유사 역행렬 사용)를 사용합니다. 탐색은 목표에 가장 가까운 지점의 시너지에 무작위 노이즈를 추가하여 수행됩니다. 목표 도달 실패 시 특정 조건(예: $w$번 연속 탐색에도 목표에 가까워지지 못함)에 따라 시도를 중단하는 타임아웃을 사용합니다.

## 📊 Results

SAGG-RIAC 아키텍처는 세 가지 다른 로봇 설정에서 평가되었습니다.

### 1. 15자유도(DOF) 시뮬레이션 팔의 역운동학 학습

- **정성적 결과:**
  - **역량의 시간적 진화:** SAGG-RIAC는 로봇이 도달 가능한 공간의 한계를 자율적으로 발견하고, 초기에는 도달 가능한 공간의 한계 근처 영역에 집중하다가 점진적으로 학습 복잡도가 증가하는 작업(예: 휴식 자세에서 더 먼 영역)에 초점을 맞추는 발달 궤적을 생성합니다.
  - **전역 탐색의 시간적 진화:** 로봇은 도달 가능한 영역과 도달 불가능한 영역을 효율적으로 구별하며, 대부분의 탐색 기간 동안 도달 가능한 영역 내에서 목표 자율 생성을 집중시킵니다.
  - **하위 목표 및 모든 도달 지점 활용의 효과:** 하위 목표와 모든 엔드이펙터 위치를 역량 측정에 사용하는 휴리스틱은 도달 가능한 영역의 초기 발견을 가속화하고, 시스템이 흥미로운 영역을 빠르게 식별하도록 돕습니다.
  - **대용량 작업 공간에서의 강건성:** SAGG-RIAC는 목표까지의 거리뿐만 아니라 진행 여부를 판단하는 "블로킹 기준"을 포함한 새로운 타임아웃 정의를 사용하여, 도달 가능한 영역이 극히 작은 대용량 작업 공간에서도 효율적으로 도달 가능한 영역을 구별합니다.
- **정량적 결과 (SAGG-RANDOM, ACTUATOR-RANDOM, ACTUATOR-RIAC와 비교):**
  - **도달 가능 공간 탐색:** SAGG-RIAC는 액츄에이터 공간 탐색 방법(ACTUATOR-RANDOM, ACTUATOR-RIAC)보다 역방향 운동학 학습에 훨씬 효율적입니다. 또한, SAGG-RIAC는 SAGG-RANDOM보다 학습 속도와 일반화 성능 면에서 우수합니다.
  - **대형 작업 공간에서의 강건성:** SAGG-RIAC는 도달 가능한 공간의 100배에 달하는 대형 작업 공간에서도 효과적인 학습을 유도하는 유일한 방법입니다. 그러나, 이보다 훨씬 큰 공간에서는 성능이 저하되어, 작업 공간의 대략적인 한계 정의가 여전히 필요함을 시사합니다.
  - **다른 DOF 및 지오메트리:** 7, 15, 30 DOF 및 다양한 팔 형태(동일/감소 길이)의 로봇에서도 SAGG-RIAC는 높은 효율성과 강건성을 보였으며, 특히 고차원 시스템에서 다른 방법들을 능가합니다.

### 2. 4족 보행 로봇의 전방향 보행 학습 (모터 시너지)

- **정성적 결과:**
  - SAGG-RIAC는 ACTUATOR 기반 방법이나 SAGG-RANDOM보다 작업 공간에서 훨씬 넓은 범위의 탐색(u, v축에서 2~3배의 커버리지)을 달성하여 우연히 발견하기 어려운 영역들을 탐색합니다. 이는 도달 가능성 한계를 예측하기 어려운 상황에서 특히 중요합니다.
- **정량적 결과:**
  - SAGG-RIAC는 1000회 반복 후 다른 모든 방법보다 월등히 높은 효율성(낮은 도달 오류)을 보였으며, 점근적 성능 또한 더 우수합니다. ACTUATOR-RANDOM 및 ACTUATOR-RIAC보다 SAGG-RANDOM도 효율적이지만, SAGG-RIAC에는 미치지 못합니다.

### 3. 낚싯대 제어 학습 (모터 시너지)

- **정성적 결과:**
  - SAGG-RIAC는 ACTUATOR-RANDOM과 비교하여 낚싯대 플로트가 물에 닿는 위치에서 훨씬 다양하고 이전에 탐색되지 않은 영역을 탐색하여 실제 도달 가능한 공간 전체를 더 철저하게 커버합니다. 이는 유연한 와이어, 비대칭성, 중복성 등 시스템의 복잡성에도 불구하고 효율적인 탐색을 가능하게 합니다.
- **정량적 결과:**
  - SAGG-RIAC는 1000번의 성공적인 시도 후에 ACTUATOR-RANDOM보다 현저히 낮은 도달 오류를 기록했습니다. 6000번의 시도 이후 일시적인 오류 증가는 이미 숙달된 목표 위치에 대한 새로운 모터 시너지를 발견하여 일시적으로 일반화 능력을 저하시켰지만, 이후 역모델의 모호성이 해소되면서 다시 개선됩니다.

## 🧠 Insights & Discussion

이 논문은 SAGG-RIAC 아키텍처가 본질적으로 동기 부여된 목표 탐색을 통해 로봇의 역방향 모델 능동 학습에 있어 매우 효율적임을 입증했습니다.

- **목표 공간 탐색의 이점:** 전통적인 저수준 제어 공간에서의 모터 재잘거림(motor babbling) 대신, 매개변수화된 작업 공간에서 고수준 목표를 능동적으로 자율 생성하여 탐색하는 것이 역방향 모델 학습에 매우 효과적입니다. 이 전략은 센서모터 로봇 공간의 중복성을 활용하여, 동일한 작업을 수행하는 여러 방법(액션 정책)을 배우기보다 다양한 종류의 작업(효과)을 최대한 많이 생성하고 제어하는 방법을 학습하도록 유도합니다.
- **발달 궤적 및 도달 가능성 자율 발견:** 목표 재잘거림(goal babbling)과 정교한 본질적으로 동기 부여된 능동 학습의 결합은 로봇이 도달 가능성의 한계를 효율적으로 자율 학습하고, 점진적으로 복잡도가 증가하는 작업을 학습하며 불가능한 작업을 시도하는 데 많은 탐색 시간을 소비하지 않도록 합니다.
- **일반성 및 유연성:** SAGG-RIAC는 하위 수준의 학습 메커니즘에 대한 가정을 최소화하므로, 다양한 회귀 및 최적화 기법과 호환됩니다.

**한계 및 향후 연구 방향:**

현재 SAGG-RIAC는 연속적이고 고차원적인 행동 공간에서 효율적인 학습을 보여주었지만, **저차원 작업 공간이 초기부터 제공된다는 가정**을 합니다. 이는 많은 로봇 공학 문제에서 공학자가 수동으로 작업 공간을 설계하는 방식으로 해결될 수 있지만, 개발 로봇 공학 프레임워크에서는 이러한 가정이 비현실적입니다. 이를 해결하기 위한 다음과 같은 추가 메커니즘이 필요합니다:

- **저차원 작업 공간 자율 발견:** 작업 공간의 고차원성은 '역량 진전' 평가에 차원의 저주를 유발하므로, 로봇이 스스로 의미 있는 저차원 작업 공간을 찾아야 합니다.
- **다중 작업 공간 능동 탐색:** 잠재적으로 무한한 수의 다양한 종류의 기술 필드를 학습할 수 있도록, 여러 작업 공간을 능동적으로 탐색해야 합니다.

이러한 문제 해결을 위한 잠재적 접근 방식은 다음과 같습니다:

- **3단계 능동 학습 아키텍처:** 작업 공간의 공간 내에서 작업 공간을 능동적으로 선택하고, 선택된 작업 공간 내에서 목표를 능동적으로 선택하며, 선택된 목표에 도달하기 위한 행동을 능동적으로 선택하는 메타-레벨 메커니즘을 추가합니다.
- **사회적 유도 및 상호작용을 통한 학습:** 비전문가 사용자가 물리적 유도 또는 인간-로봇 인터페이스를 통해 로봇의 주의를 특정 작업 공간으로 유도하거나, 역강화 학습을 통해 인간 시연에서 흥미로운 작업 공간을 추론할 수 있습니다.
- **성숙 제약 (Maturational constraints):** 유아의 발달 과정에서 영감을 받아, 센서모터 장치의 한계나 뇌의 진화하는 능력과 같은 생리학적/인지적 제약을 통해 초기 학습을 단순화하고 탐색 과정을 더욱 제한하는 것입니다. 이는 무한하거나 고차원적인 작업 공간에서 평생 학습을 고려할 때 매우 중요할 수 있습니다.

## 📌 TL;DR

고차원, 중복 로봇에서 역방향 모델(행동을 통해 원하는 효과를 달성하는 방법)을 자율적이고 효율적으로 학습하는 것이 핵심 문제입니다. 기존 방법들은 액츄에이터 공간에서 비효율적으로 탐색하거나 인간의 목표 정의에 의존했습니다. 이 논문은 **SAGG-RIAC**라는 두 단계의 본질적 동기 부여 능동 학습 아키텍처를 제안합니다. 고수준에서는 로봇의 _역량 진전_ (특정 목표를 얼마나 잘 달성하는지)에 기반하여 작업 공간에서 새로운 목표를 자율 생성합니다. 저수준에서는 이러한 목표를 달성하기 위해 회귀 및 최적화 기법을 사용하여 목표 지향적인 행동을 학습합니다. SAGG-RIAC는 기존 액츄에이터 공간 탐색 방법보다 **훨씬 빠르게 역방향 모델을 학습하고, 더 나은 일반화 성능**을 보입니다. 또한, 로봇이 스스로 **도달 가능한 작업 공간의 한계를 발견**하고, **점진적으로 복잡도가 증가하는 작업을 학습**하도록 유도하며, 대용량 작업 공간에서도 강건한 성능을 보여줍니다.
