# Deep Bayesian Active Learning with Image Data

Yarin Gal, Riashat Islam, Zoubin Ghahramani

## 🧩 Problem to Solve

많은 머신러닝 애플리케이션에서 레이블링된 데이터를 확보하는 것은 비용이 많이 들고 노동 집약적인 과정입니다. 액티브 러닝(Active Learning, AL)은 필요한 레이블의 양을 줄이는 데 효과적이지만, 다음 두 가지 주요 문제로 인해 고차원 이미지 데이터에 딥 러닝(Deep Learning, DL)을 적용하는 데 어려움이 있었습니다.

1. **소량 데이터 학습의 어려움:** AL은 적은 양의 데이터로 모델을 학습하고 업데이트해야 하지만, 최신 딥 러닝 모델은 대규모 데이터셋에 의존하는 경향이 있습니다.
2. **모델 불확실성 표현 부재:** 많은 AL 획득 함수(acquisition function)가 모델의 불확실성에 의존하지만, 일반적인 딥 러닝 방법은 이러한 모델 불확실성을 거의 표현하지 못합니다.

결과적으로 고차원 데이터, 특히 이미지 데이터에 대한 액티브 러닝 연구는 매우 제한적이었습니다.

## ✨ Key Contributions

이 논문은 베이지안 딥 러닝(Bayesian Deep Learning)의 최신 발전을 액티브 러닝 프레임워크와 결합하여 고차원 이미지 데이터에 대한 새로운 접근 방식을 제시하며 다음을 기여합니다.

- **베이지안 딥 러닝 기반 액티브 러닝 프레임워크 개발:** 고차원 이미지 데이터에 대한 액티브 러닝을 위한 실용적인 프레임워크를 개발했습니다.
- **베이지안 컨볼루션 신경망(BCNN) 활용:** 베이지안 컨볼루션 신경망을 사용하여 이미지 데이터의 예측 불확실성을 효과적으로 표현합니다.
- **획득 함수의 실용적인 근사:** 기존 획득 함수를 BCNN에서 사용하기 위한 계산적으로 다루기 쉬운 근사 방법을 제시합니다.
- **기존 방법 대비 상당한 성능 향상:** MNIST 데이터셋과 실제 피부암 진단(ISIC2016) 태스크에서 기존 액티브 러닝 접근 방식보다 월등한 성능 향상을 입증했습니다.
- **모델 불확실성의 중요성 입증:** 액티브 러닝에서 모델 불확실성을 포착하는 것이 중요함을 보여주었습니다.

## 📎 Related Works

- **커널 기반 이미지 액티브 러닝:**
  - Joshi et al. (2009): SVM(Support Vector Machine)의 마진 기반 불확실성을 활용.
  - Li & Guo (2013): RBF 커널을 사용한 가우시안 프로세스(Gaussian Process)로 모델 불확실성을 얻었으나, 저차원 특징을 사용.
  - Zhu et al. (2003): 가우시안 랜덤 필드 모델과 RBF 커널을 사용하여 레이블 없는 데이터도 활용. (본 논문에서 비교 대상인 MBR)
- **세미-지도 학습(Semi-supervised learning) for 이미지 데이터:**
  - Weston et al. (2012), Kingma et al. (2014), Rasmus et al. (2015): 고정된 레이블 데이터와 레이블 없는 데이터셋을 사용하여 모델 학습. (본 논문에서 비교 대상)

## 🛠️ Methodology

본 논문은 베이지안 컨볼루션 신경망(Bayesian CNN)을 활용하여 이미지 데이터의 모델 불확실성을 정량화하고 이를 액티브 러닝 획득 함수에 적용합니다.

1. **모델 불확실성 표현:**

   - CNN 모델의 파라미터 $\omega = \{W_1, ..., W_L\}$에 사전 확률 분포 $p(\omega)$를 부여합니다.
   - 베이지안 CNN에서 근사 추론(approximate inference)을 위해 드롭아웃(Dropout)을 활용합니다. 특히, 테스트 시에도 드롭아웃을 적용하여 근사 사후분포에서 샘플링(Monte Carlo Dropout, MC Dropout)함으로써 모델 불확실성을 추정합니다.
   - 이는 변분 추론(Variational Inference)의 한 형태로, 드롭아웃 분포 $q_{\theta}(\omega)$가 실제 사후분포 $p(\omega|D_{train})$를 근사합니다.
   - 예측 확률은 MC 샘플링을 통해 다음과 같이 근사됩니다:
     $$p(y=c|x,D_{train}) \approx \frac{1}{T} \sum_{t=1}^{T} p(y=c|x, \hat{\omega}_t)$$
     여기서 $\hat{\omega}_t \sim q^*_{\theta}(\omega)$ 입니다.

2. **획득 함수 및 근사:**

   - 다양한 불확실성 기반 획득 함수를 사용합니다:
     - **Max Entropy:** 예측 엔트로피 $H[y|x,D_{train}]$를 최대화하는 샘플을 선택.
     - **BALD (Bayesian Active Learning by Disagreement):** 예측과 모델 파라미터 간의 상호 정보량 $I[y,\omega|x,D_{train}]$를 최대화. 이는 모델이 평균적으로 불확실하지만, 특정 모델 파라미터에서는 높은 확신으로 다른 예측을 내놓는 지점을 찾습니다.
     - **Variation Ratios:** $1 - \max_y p(y|x,D_{train})$로, 확신 부족을 측정.
     - **Mean STD:** 각 클래스 확률의 평균 표준 편차를 최대화.
     - **Random:** 무작위 샘플링 (기준선).
   - 위 획득 함수들은 MC Dropout을 통해 얻은 $\hat{p}^t_c = \text{softmax}(f_{\hat{\omega}_t}(x))$를 사용하여 계산적으로 다루기 쉬운 형태로 근사됩니다. 예를 들어, BALD는 다음과 같이 근사됩니다:
     $$\hat{I}[y,\omega|x,D_{train}] \approx -\sum_{c} (\frac{1}{T}\sum_t \hat{p}^t_c) \log(\frac{1}{T}\sum_t \hat{p}^t_c) + \frac{1}{T}\sum_{c,t} \hat{p}^t_c \log\hat{p}^t_c$$

3. **액티브 러닝 절차:**
   - 소량의 초기 훈련 데이터로 BCNN을 훈련합니다.
   - 레이블이 없는 데이터 풀에서 획득 함수를 사용하여 가장 정보가 많은 데이터를 선택합니다.
   - 선택된 데이터는 오라클(인간 전문가)에 의해 레이블링되고 훈련 세트에 추가됩니다.
   - 모델을 업데이트된 훈련 세트로 다시 훈련하며 이 과정을 반복합니다. 각 획득 단계마다 모델은 초기 사전 훈련된 가중치로 재설정됩니다(지역 최적화 회피 목적).

## 📊 Results

- **MNIST 데이터셋:**

  - **획득 함수 비교 (그림 1):** BALD, Variation Ratios, Max Entropy는 Random 및 Mean STD보다 훨씬 우수한 성능을 보였습니다. Variation Ratios가 BALD, Max Entropy보다 약간 더 빠른 속도로 정확도를 달성했습니다.
  - **데이터 효율성 (표 1):** Variation Ratios는 295개의 레이블링된 이미지로 5%의 테스트 오류를 달성했으며, Random 샘플링은 동일한 정확도를 위해 835개의 이미지가 필요했습니다 (2배 이상 효율적). 1000개의 이미지로 1.64% 오류율을 달성했습니다.
  - **모델 불확실성의 중요성 (그림 2):** 베이지안 CNN(불확실성 전파)은 초기 단계에서 더 높은 정확도를 달성하고 전체적으로 더 높은 정확도로 수렴하여, 결정론적 CNN(불확실성 없음)보다 뛰어났습니다.
  - **기존 AL 기술과의 비교 (그림 3):** 베이지안 CNN 기반 획득 함수는 커널 기반 MBR (Zhu et al., 2003)보다 훨씬 뛰어난 성능을 보였으며, 심지어 CNN과 결합된 Random 샘플링도 MBR을 능가했습니다.
  - **세미-지도 학습과의 비교 (표 2):** 1000개 레이블 샘플 사용 시, Variation Ratios (1.64% 오류)는 레이블 없는 전체 훈련 세트를 사용하는 Ladder Network $\Gamma$-model (1.53% 오류)과 비슷한 성능을 보였습니다. 이는 AL 모델이 훨씬 적은 데이터를 사용함에도 불구하고 경쟁력 있음을 보여줍니다.

- **피부암 진단 (ISIC2016) 데이터셋:**
  - **BALD vs. Uniform (그림 5):** BALD 획득 함수는 균일(Uniform) 샘플링보다 더 빠르게 더 높은 AUC(Area Under the Curve)를 달성했습니다. 또한, 각 획득 단계에서 더 많은 양성(악성) 샘플을 획득했습니다.
  - **실제 성능:** 4단계 획득 후 BALD의 수렴된 AUC는 ISIC2016 챌린지 2위 모델(전체 풀셋으로 훈련)의 성능(AUC 0.71-0.75)보다 우수했습니다. 이는 BALD가 노이즈가 많은(aleatoric uncertainty가 높은) 점들을 피하고 epistemic uncertainty를 줄이는 정보성 있는 점들을 효과적으로 선택했기 때문으로 분석됩니다.

## 🧠 Insights & Discussion

- **베이지안 딥 러닝의 핵심 역할:** 이 연구는 베이지안 딥 러닝, 특히 MC Dropout을 통한 모델 불확실성 정량화가 고차원 이미지 데이터의 액티브 러닝에서 핵심적인 역할을 한다는 것을 강력하게 보여줍니다. 이 불확실성은 모델이 "무엇을 모르는지"를 파악하게 하여 가장 정보성 높은 샘플을 효과적으로 선택할 수 있게 합니다.
- **데이터 효율성 및 비용 절감:** 제안된 방법은 기존 액티브 러닝 및 일부 세미-지도 학습 기법에 비해 레이블링된 데이터의 필요량을 크게 줄여, 레이블링 비용과 시간을 절감하는 데 큰 의미가 있습니다. 이는 의료 진단과 같이 전문가 레이블링이 비싸고 희소한 분야에서 특히 중요합니다.
- **에피스테믹 불확실성 활용:** BALD와 같은 획득 함수는 모델 파라미터에 대한 불확실성(epistemic uncertainty)을 줄이는 데 집중하며, 이는 액티브 러닝의 목표와 직접적으로 일치합니다. 이는 데이터 자체의 노이즈(aleatoric uncertainty)와 구별되어, 모델이 학습을 통해 해소할 수 있는 불확실성을 줄이는 데 기여합니다.
- **한계점:** 각 획득 단계마다 모델을 초기 가중치로 재설정하고 수렴까지 다시 훈련하는 방식은 계산 비용이 매우 높습니다(예: 피부암 진단 실험당 20시간). 이는 획득 함수의 효과를 명확히 분리하기 위함이었지만, 실용적인 측면에서는 개선이 필요합니다. 재설정하지 않고 훈련을 이어가는 방식은 지역 최적화에 빠질 위험이 있어 향후 연구 과제로 남겨져 있습니다.

## 📌 TL;DR

이 논문은 액티브 러닝(AL)이 고차원 이미지 데이터와 딥 러닝(DL)의 결합에서 겪는 어려움, 특히 DL의 대규모 데이터 의존성과 모델 불확실성 표현 부족 문제를 해결합니다. 저자들은 베이지안 딥 러닝(BCNNs와 MC Dropout)을 활용하여 모델 불확실성을 효과적으로 정량화하고, 이를 기반으로 BALD, Variation Ratios 등의 획득 함수를 통해 가장 정보성 높은 레이블 없는 이미지를 선택하는 프레임워크를 제안합니다. MNIST와 피부암 진단 데이터셋에서 실험한 결과, 제안된 방법은 기존 AL 및 일부 세미-지도 학습 기법보다 훨씬 적은 수의 레이블된 데이터로 높은 정확도를 달성하며, 액티브 러닝에서 모델 불확실성의 중요성을 입증했습니다. 이는 고비용의 전문가 레이블링이 필요한 분야에 큰 잠재력을 제시합니다.
