{
  "title": "Foundation Model Transparency Reports",
  "authors": "Rishi Bommasani, Kevin Klyman, Shayne Longpre, Betty Xiong, Sayash Kapoor, Nestor Maslej, Arvind Narayanan, Percy Liang",
  "year": 2024,
  "url": "http://arxiv.org/abs/2402.16268v1",
  "abstract": "Foundation models are critical digital technologies with sweeping societal\nimpact that necessitates transparency. To codify how foundation model\ndevelopers should provide transparency about the development and deployment of\ntheir models, we propose Foundation Model Transparency Reports, drawing upon\nthe transparency reporting practices in social media. While external\ndocumentation of societal harms prompted social media transparency reports, our\nobjective is to institutionalize transparency reporting for foundation models\nwhile the industry is still nascent. To design our reports, we identify 6\ndesign principles given the successes and shortcomings of social media\ntransparency reporting. To further schematize our reports, we draw upon the 100\ntransparency indicators from the Foundation Model Transparency Index. Given\nthese indicators, we measure the extent to which they overlap with the\ntransparency requirements included in six prominent government policies (e.g.,\nthe EU AI Act, the US Executive Order on Safe, Secure, and Trustworthy AI).\nWell-designed transparency reports could reduce compliance costs, in part due\nto overlapping regulatory requirements across different jurisdictions. We\nencourage foundation model developers to regularly publish transparency\nreports, building upon recommendations from the G7 and the White House."
}