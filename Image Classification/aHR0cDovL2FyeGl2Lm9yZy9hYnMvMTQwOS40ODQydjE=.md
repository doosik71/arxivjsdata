# Going deeper with convolutions

Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, Andrew Rabinovich

## 🧩 Problem to Solve

기존 심층 컨볼루션 신경망(CNN)은 성능 향상을 위해 네트워크의 깊이와 너비를 늘리는 경향이 있었습니다. 그러나 이는 다음과 같은 주요 문제점을 야기했습니다:

- **과적합(Overfitting) 위험 증가:** 파라미터 수가 크게 증가하여 특히 학습 데이터가 제한적일 경우 과적합에 취약해집니다.
- **막대한 계산 자원 소모:** 네트워크 크기 증가가 계산 비용을 기하급수적으로 늘려, 실세계 적용에 제약을 줍니다. 예를 들어, 두 컨볼루션 레이어가 연결될 때 필터 수를 균일하게 늘리면 계산량이 이차적으로 증가합니다.
  이 논문은 계산 비용을 일정하게 유지하면서 네트워크의 깊이와 너비를 늘릴 수 있는 효율적인 아키텍처를 설계하여 이러한 문제를 해결하고자 합니다. 이는 Hebbian 원리(함께 발화하는 뉴런은 함께 연결된다)와 다중 스케일 처리의 직관에 기반하여 최적의 희소 구조를 조밀한(dense) 구성 요소로 근사하는 방식으로 이루어집니다.

## ✨ Key Contributions

- **Inception 아키텍처 제안:** 계산 자원을 효율적으로 활용하여 네트워크의 깊이와 너비를 확장할 수 있는 새로운 심층 컨볼루션 신경망 아키텍처인 Inception을 소개했습니다.
- **GoogLeNet 구현 및 ILSVRC14 SOTA 달성:** ILSVRC 2014 이미지 분류 및 탐지 챌린지에서 최고 성능을 달성한 22개 레이어의 Inception 아키텍처 구현인 GoogLeNet을 제시했습니다.
- **$1 \times 1$ 컨볼루션을 통한 차원 축소:** $1 \times 1$ 컨볼루션을 계산 병목 현상을 제거하고 네트워크의 효율성을 높이는 차원 축소 모듈로 활용하여, 네트워크를 더 깊고 넓게 만들 수 있도록 했습니다.
- **다중 스케일 특징 학습:** Inception 모듈 내에서 다양한 크기의 필터($1 \times 1, 3 \times 3, 5 \times 5$)와 풀링을 병렬로 적용하여, 다양한 스케일의 시각적 정보를 효과적으로 포착하고 통합합니다.
- **보조 분류기(Auxiliary Classifiers) 도입:** 깊은 네트워크에서 그래디언트 소실 문제를 완화하고 정규화 효과를 제공하기 위해 중간 레이어에 보조 분류기를 추가했습니다.
- **파라미터 효율성:** 기존 SOTA 모델인 AlexNet보다 12배 적은 파라미터를 사용하면서도 훨씬 높은 정확도를 달성하여 뛰어난 효율성을 입증했습니다.

## 📎 Related Works

- **LeNet-5 [10]:** 컨볼루션 신경망(CNN)의 기본적인 구조를 확립한 초기 모델로, Inception 아키텍처의 이름인 GoogLeNet도 LeNet-5에 대한 오마주입니다.
- **AlexNet (Krizhevsky et al. [9]):** ImageNet 대회에서 획기적인 성능을 보여주며 딥러닝의 부흥을 이끈 모델. 이 논문은 Inception이 AlexNet보다 적은 파라미터로 더 높은 정확도를 달성했음을 강조합니다.
- **Network in Network (Lin et al. [12]):** $1 \times 1$ 컨볼루션을 사용하여 표현 능력을 향상시키는 아이디어를 제시했으며, Inception 아키텍처의 설계에 중요한 영감을 주었습니다. 특히 전역 평균 풀링(Global Average Pooling) 사용도 이 연구에서 영감을 받았습니다.
- **R-CNN (Girshick et al. [6]):** 컨볼루션 신경망을 활용한 객체 탐지 분야의 선구적인 작업으로, Inception 기반의 탐지 시스템은 R-CNN의 아이디어를 확장하고 개선했습니다.
- **Arora et al. [2]:** 희소(sparse) 심층 신경망 학습의 이론적 기반을 제공하여 Inception 아키텍처가 최적의 희소 구조를 근사하려는 동기에 영향을 주었습니다.

## 🛠️ Methodology

Inception 아키텍처의 핵심은 'Inception 모듈'이라는 빌딩 블록에 있으며, 이는 네트워크의 깊이와 너비를 늘리면서도 계산 효율성을 유지하도록 설계되었습니다.

- **Inception 모듈의 설계:**
  - **병렬 연산:** 입력 피처 맵에 대해 다음의 여러 연산을 병렬로 수행한 후 그 결과들을 채널 차원으로 연결($\text{concatenate}$)합니다:
    - $1 \times 1$ 컨볼루션
    - $1 \times 1$ 컨볼루션 후 $3 \times 3$ 컨볼루션
    - $1 \times 1$ 컨볼루션 후 $5 \times 5$ 컨볼루션
    - $3 \times 3$ 맥스 풀링 후 $1 \times 1$ 컨볼루션
  - **차원 축소 ($1 \times 1$ 컨볼루션):** 특히 비용이 많이 드는 $3 \times 3$ 및 $5 \times 5$ 컨볼루션 이전에 $1 \times 1$ 컨볼루션을 적용하여 입력 채널 수를 줄입니다. 이는 계산 비용을 크게 절감하고 병목 현상을 방지하는 핵심적인 역할입니다. 맥스 풀링 후에도 $1 \times 1$ 컨볼루션을 사용하여 출력 차원을 조절합니다.
- **GoogLeNet 아키텍처:**
  - 총 22개(파라미터 있는 레이어만 계산 시)의 레이어로 구성되며, 여러 Inception 모듈이 쌓여 있습니다.
  - **보조 분류기 (Auxiliary Classifiers):** 깊은 네트워크에서 그래디언트 소실 문제를 해결하고 정규화 효과를 강화하기 위해 중간 레이어(Inception (4a) 및 (4d) 모듈의 출력)에 작은 분류기를 추가했습니다. 이 보조 분류기들의 손실은 전체 손실에 가중치($0.3$)를 곱하여 더해지며, 추론 시에는 제거됩니다.
  - **전역 평균 풀링 (Global Average Pooling):** 네트워크의 마지막에는 완전 연결(Fully Connected) 레이어 대신 $7 \times 7$ 전역 평균 풀링 레이어를 사용하여 파라미터 수를 줄이고 과적합을 방지합니다.
- **훈련 방법론:**
  - DistBelief 분산 머신러닝 시스템을 사용하여 여러 CPU에서 훈련했습니다.
  - $0.9$ 모멘텀을 사용하는 비동기식 확률적 경사 하강법(SGD)을 적용했으며, 8 에포크마다 학습률을 $4\%$씩 감소시키는 스케줄을 사용했습니다.
  - 과적합 방지를 위해 다양한 크기의 이미지 패치 샘플링 (이미지 영역의 $8\%$에서 $100\%$ 사이)과 광학적 왜곡(photometric distortions)을 포함한 데이터 증강 기법을 사용했습니다.
- **추론 방법론:**
  - 동일한 GoogLeNet 모델의 7가지 버전을 훈련하고, 앙상블 예측을 통해 최종 정확도를 높였습니다.
  - 테스트 시에는 여러 스케일(짧은 변을 256, 288, 320, 352 픽셀로 조절)에서 이미지를 크롭하고, 각 스케일에서 144개의 다양한 크롭(예: 모서리, 중앙, 미러링 등)을 추출하여 Softmax 확률을 평균하는 공격적인 크롭 전략을 사용했습니다.

## 📊 Results

- **ILSVRC 2014 이미지 분류 챌린지:**
  - **Top-5 오류율 6.67% 달성:** ILSVRC 2014 대회에서 압도적으로 1위를 차지했습니다. 이는 이전 SOTA(Clarifai, 2013) 대비 약 $40\%$의 상대적 감소이며, 2012년 SOTA(SuperVision) 대비 $56.5\%$ 감소한 수치입니다.
  - **효율성 입증:** 이전 2년 전 우승 모델인 AlexNet보다 12배 적은 파라미터를 사용하면서도 훨씬 높은 정확도를 달성하여 Inception 아키텍처의 계산 효율성을 입증했습니다.
  - **앙상블 및 크롭 효과:** 앙상블 모델과 공격적인 크롭 전략이 최종 성능 향상에 크게 기여했습니다 (예: 단일 모델 1크롭 사용 시 Top-5 오류율 10.07% $\rightarrow$ 7개 모델 144크롭 사용 시 6.67%).
- **ILSVRC 2014 객체 탐지 챌린지:**
  - **mAP(mean Average Precision) 43.9% 달성:** 이 분야에서도 1위를 차지했습니다.
  - **R-CNN 개선:** R-CNN 프레임워크에 Inception 모델을 영역 분류기로 통합하고, Selective Search와 Multi-box [5] 예측을 결합하여 영역 제안(region proposal) 단계를 개선했습니다.
  - **견고성:** 바운딩 박스 회귀(bounding box regression) 및 컨텍스트 모델을 사용하지 않았음에도 불구하고 경쟁력 있는 성능을 보여 Inception 아키텍처의 강력함을 입증했습니다.

## 🧠 Insights & Discussion

- **희소 구조 근사의 성공:** 이 연구는 이론적으로 최적의 희소 네트워크 구조를 조밀한(dense) 빌딩 블록(Inception 모듈)으로 근사하는 방법이 컴퓨터 비전 분야의 신경망 성능 향상에 매우 효과적임을 입증했습니다.
- **계산 효율성과 품질의 균형:** Inception 아키텍처는 네트워크의 깊이와 너비를 크게 확장하면서도 계산 요구 사항을 최소한으로 유지하여, 상당한 품질 향상을 가져왔습니다. 이는 특히 모바일 및 임베디드 장치와 같이 계산 자원과 메모리가 제한적인 환경에서의 딥러닝 모델 배포 가능성을 열었습니다.
- **다중 스케일 처리의 중요성 재확인:** Inception 모듈의 병렬 구조를 통한 다중 스케일 정보 처리는 복잡한 시각적 특징을 효과적으로 학습하는 데 필수적임을 보여주었습니다.
- **깊은 네트워크의 그래디언트 전파 개선:** 보조 분류기는 깊은 네트워크에서 그래디언트 소실 문제를 완화하고 훈련 안정성을 높이는 데 중요한 역할을 합니다. 중간 레이어에서 이미 판별적인 특징이 학습되고 있음을 시사합니다.
- **미래 연구 방향 제시:** Inception 아키텍처의 성공은 Arora et al. [2]의 이론적 기반을 바탕으로 희소하고 정교한 네트워크 구조를 자동화된 방식으로 생성하는 미래 연구에 강력한 동기를 부여합니다. 이는 현재 수동 설계에 의존하는 아키텍처 탐색 과정을 혁신할 잠재력이 있습니다.

## 📌 TL;DR

이 논문은 ILSVRC 2014에서 분류 및 탐지 부문 1위를 차지한 **Inception**이라는 심층 컨볼루션 신경망 아키텍처와 그 구현인 **GoogLeNet**을 제안합니다. 기존 심층 네트워크의 문제점인 과도한 계산 비용과 과적합 문제를 해결하기 위해, Inception은 다양한 크기의 컨볼루션 필터($1 \times 1, 3 \times 3, 5 \times 5$)와 풀링을 병렬로 적용하고 그 결과들을 연결하는 'Inception 모듈'을 사용합니다. 특히, $1 \times 1$ 컨볼루션은 차원 축소를 통해 계산 병목 현상을 효과적으로 제거하여 네트워크를 더 깊고 넓게 확장할 수 있도록 합니다. 또한, 깊은 네트워크에서 그래디언트 소실을 완화하고 정규화하기 위해 보조 분류기(auxiliary classifiers)를 도입했습니다. GoogLeNet은 AlexNet보다 12배 적은 파라미터로 $6.67\%$의 Top-5 오류율을 달성하며 이미지 분류에서 1위를 차지했으며, 객체 탐지에서도 $43.9\%$ mAP로 1위를 기록하여, 희소 아키텍처를 조밀한 빌딩 블록으로 근사하는 방법이 높은 성능과 탁월한 계산 효율성을 동시에 달성할 수 있음을 성공적으로 입증했습니다.
