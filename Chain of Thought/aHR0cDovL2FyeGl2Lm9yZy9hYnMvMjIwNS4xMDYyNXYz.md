# LEAST-TO-MOST PROMPTING ENABLES COMPLEX REASONING IN LARGE LANGUAGE MODELS

Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei, Nathan Scales, Xuezhi Wang, Dale Schuurmans, Claire Cui, Olivier Bousquet, Quoc Le, Ed Chi

## 🧩 Problem to Solve

최근 Chain-of-Thought (CoT) 프롬프팅은 다양한 자연어 추론 작업에서 뛰어난 성능을 보였지만, 프롬프트에서 제시된 예시보다 더 어려운 문제를 해결해야 하는 작업(쉬운 것에서 어려운 것으로 일반화하는 능력)에서는 성능이 저하되는 한계가 있었습니다. 인간은 이전에 본 적 없는 더 어려운 문제도 해결할 수 있지만, 기존 기계 학습 모델은 학습 예시와 테스트 예시의 난이도가 비슷할 때만 잘 작동하는 경향이 있었습니다.

## ✨ Key Contributions

- **새로운 프롬프팅 전략 제안:** "Least-to-Most 프롬프팅"을 도입하여 이지-투-하드(easy-to-hard) 일반화 문제를 해결했습니다.
- **핵심 아이디어:** 복잡한 문제를 일련의 더 간단한 하위 문제들로 분해하고, 이전 하위 문제의 해답을 활용하여 순차적으로 해결하는 방식입니다.
- **쉬운 것에서 어려운 것으로의 일반화 달성:** 기호 조작, 구성적 일반화(compositional generalization), 수학적 추론과 관련된 작업에서 프롬프트에 제시된 예시보다 더 어려운 문제로 일반화하는 능력을 입증했습니다.
- **SCAN 벤치마크에서의 뛰어난 성능:** GPT-3의 `code-davinci-002` 모델과 Least-to-Most 프롬프팅을 사용했을 때, 단 14개의 예시만으로 SCAN 벤치마크(길이 분할(length split) 포함)에서 최소 99%의 정확도를 달성했습니다. 이는 Chain-of-Thought 프롬프팅의 16% 정확도와 대조적이며, SCAN 해결에 특화된 기존 신경-기호 모델들이 15,000개 이상의 훈련 예시로 훈련된다는 점을 고려할 때 주목할 만한 성과입니다.
- **훈련 또는 미세 조정 불필요:** 두 단계 모두 퓨샷(few-shot) 프롬프팅으로 구현되어 별도의 모델 훈련이나 미세 조정이 필요 없습니다.

## 📎 Related Works

- **Chain-of-Thought (CoT) 프롬프팅:** Wei et al., 2022; Chowdhery et al., 2022. 자연어 추론(Ling et al., 2017; Cobbe et al., 2021)과 퓨샷 프롬프팅(Brown et al., 2020)의 결합.
- **자기-일관성 디코딩 (Self-consistency decoding):** Wang et al., 2022b.
- **구성적 일반화:** SCAN (Lake & Baroni, 2018; Keysers et al., 2020). 이전 연구로는 신경-기호 아키텍처(Chen et al., 2020; Liu et al., 2020), 문법 유도 기법(Nye et al., 2020; Shaw et al., 2021; Kim, 2021), 데이터 증강 기법(Andreas, 2020; Akyürek et al., 2021; Lake, 2019), 신경망 아키텍처(Russin et al., 2019; Li et al., 2019; Herzig & Berant, 2021; Gordon et al., 2020) 등이 있습니다.
- **이지-투-하드 일반화:** Neural Logic Machines (NLMs) (Dong et al., 2019), 순환 신경망(Schwarzschild et al., 2021) 등이 있습니다.
- **태스크 분해 (Task decomposition):** 다중 홉 질문 응답(Perez et al., 2020; Wang et al., 2022a), 자연어-SQL 변환(Yang et al., 2022), 대규모 언어 모델 단계 연결(Wu et al., 2022) 등.

## 🛠️ Methodology

Least-to-Most 프롬프팅은 복잡한 문제를 일련의 더 간단한 하위 문제로 분해하여 언어 모델이 해결하도록 가르칩니다. 이 과정은 두 가지 순차적인 단계로 구성되며, 두 단계 모두 퓨샷 프롬프팅으로 구현되어 훈련이나 미세 조정이 필요 없습니다.

1. **분해 (Decomposition):**
   - 이 단계의 프롬프트는 문제 분해 방법을 시연하는 몇 가지 예시와 분해할 특정 질문을 포함합니다.
   - 언어 모델은 원래의 복잡한 문제를 해결 가능한 하위 문제 목록으로 분해합니다.
2. **하위 문제 해결 (Subproblem Solving):**
   - 이 단계의 프롬프트는 다음 세 부분으로 구성됩니다:
     - 하위 문제 해결 방법을 시연하는 몇 가지 예시.
     - 이전에 답변된 하위 질문 및 생성된 솔루션 목록 (비어 있을 수 있음).
     - 다음에 답변할 질문.
   - 하위 문제들은 순차적으로 해결되며, 이전에 해결된 하위 문제들의 해답이 다음 하위 문제 해결에 활용됩니다.
   - 예를 들어, 수학 문제의 경우, 먼저 "각 여행에 얼마나 걸리나요?"와 같은 하위 문제로 분해하고, 그 다음 이 하위 문제의 답을 사용하여 "총 사과 수는 얼마인가요?"와 같은 다음 하위 문제를 해결합니다.

이 방법은 Chain-of-Thought (CoT) 및 자기-일관성(self-consistency)과 같은 다른 프롬프팅 기법과 결합될 수 있지만, 필수는 아닙니다. 또한, 일부 작업의 경우 두 단계를 단일 패스(single-pass) 프롬프트로 병합하여 사용할 수도 있습니다.

## 📊 Results

- **기호 조작 (Last-letter-concatenation):**
  - `code-davinci-002` 모델 사용 시, Least-to-Most 프롬프팅은 리스트 길이가 길어질수록 Chain-of-Thought 프롬프팅보다 훨씬 뛰어난 성능을 보였습니다.
  - 길이 12의 리스트에서 Least-to-Most는 74.0%의 정확도를 기록한 반면, Chain-of-Thought는 31.8%에 그쳤습니다.
  - 표준 프롬프팅은 모든 테스트 케이스에서 0%의 정확도로 완전히 실패했습니다.
- **구성적 일반화 (SCAN):**
  - `code-davinci-002` 모델과 Least-to-Most 프롬프팅은 길이 분할에서 99.7%의 정확도를 달성했으며, 이는 단 14개의 예시로 얻은 결과입니다.
  - Chain-of-Thought 프롬프팅은 16.2%, 표준 퓨샷 프롬프팅은 16.7%의 정확도를 보였습니다.
  - 이는 15,000개 이상의 예시로 훈련되는 기존 특화 모델들의 성능에 필적하는 결과입니다.
- **수학적 추론 (GSM8K, DROP):**
  - **GSM8K:** Least-to-Most 프롬프팅은 Chain-of-Thought 프롬프팅(60.87%)보다 약간 더 높은 62.39%의 전체 정확도를 보였습니다. 특히 5단계 이상이 필요한 어려운 문제에서 45.23% 대 39.07%로 더 큰 개선 효과를 보였습니다.
  - **DROP:** Least-to-Most 프롬프팅은 Chain-of-Thought 프롬프팅을 크게 앞섰습니다 (비축구(Non-football) 서브셋에서 82.45% 대 74.77%, 축구(Football) 서브셋에서 73.42% 대 59.56%).
- **모델 비교:** `code-davinci-002`는 `text-davinci-002` 및 `code-davinci-001`보다 모든 방법론에서 일관되게 우수한 성능을 보였습니다.

## 🧠 Insights & Discussion

- Least-to-Most 프롬프팅은 복잡한 문제를 관리 가능한 단계로 분해함으로써 '쉬운 것에서 어려운 것으로의 일반화'라는 핵심 과제를 효과적으로 해결합니다. 이는 교육 심리학에서 영감을 받은 접근 방식이며, 하위 솔루션을 바탕으로 새로운 솔루션을 구축하는 재귀적 특성이 Last-letter-concatenation 및 SCAN과 같은 작업에서 핵심적인 성능 향상 요인입니다.
- **한계점:**
  - 분해 프롬프트는 일반적으로 다른 도메인(예: 수학 문제와 상식 추론 문제) 간에 잘 일반화되지 않습니다. 새로운 유형의 문제에는 새로운 분해 프롬프트 디자인이 필요합니다.
  - 심지어 GSM8K와 같은 동일 도메인 내에서도, 언어 모델이 스스로 정확한 분해를 생성하는 것이 어려울 수 있습니다. 수동으로 올바른 분해를 제공하면 거의 모든 문제를 정확하게 해결할 수 있다는 것이 관찰되었습니다.
  - Last-letter-concatenation 작업과 SCAN 벤치마크에서의 뛰어난 결과는 해당 작업의 분해 과정이 비교적 간단하다는 점에 기인합니다.
- **향후 방향:** 프롬프팅을 언어 모델에게 즉각적인 피드백을 제공할 수 있는 완전한 양방향 대화 형태로 발전시켜 더 효율적인 학습을 가능하게 하는 것이 자연스러운 다음 단계입니다. Least-to-Most 프롬프팅은 이러한 양방향 상호작용을 통해 언어 모델을 가르치는 방향으로 나아가는 한 걸음을 대표합니다.

## 📌 TL;DR

- **문제:** 기존 Chain-of-Thought (CoT) 프롬프팅은 학습 예시보다 어려운 문제에 대한 "이지-투-하드 일반화" 능력이 부족했습니다.
- **방법:** 이 논문은 "Least-to-Most 프롬프팅"이라는 새로운 퓨샷 프롬프팅 전략을 제안합니다. 이 방법은 (1) 복잡한 문제를 더 간단한 하위 문제로 분해하고, (2) 이전에 해결된 하위 문제의 답을 활용하여 하위 문제들을 순차적으로 해결하는 두 단계로 구성됩니다. 이 과정에 별도의 훈련은 필요 없습니다.
- **주요 결과:** Least-to-Most 프롬프팅은 기호 조작, 구성적 일반화(SCAN), 수학적 추론(GSM8K, DROP) 등 다양한 작업에서 CoT 및 표준 프롬프팅보다 훨씬 뛰어난 성능을 보였습니다. 특히 SCAN 벤치마크에서는 단 14개의 예시로 99% 이상의 정확도를 달성하여, 기존 특화 모델들이 수만 개의 데이터로 훈련되는 것과 대조적으로 뛰어난 일반화 능력을 입증했습니다. 이는 더 많은 추론 단계가 필요한 문제에 대한 모델의 일반화 능력을 크게 향상시킵니다.
