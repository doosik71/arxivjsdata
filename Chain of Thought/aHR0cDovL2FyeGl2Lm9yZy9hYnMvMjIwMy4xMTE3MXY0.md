# SELF-CONSISTENCY IMPROVES CHAIN OF THOUGHT REASONING IN LANGUAGE MODELS

Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed H. Chi, Sharan Narang, Aakanksha Chowdhery, Denny Zhou

## 🧩 Problem to Solve

사전 훈련된 대규모 언어 모델(LLM)과 결합된 CoT(Chain-of-Thought) 프롬프팅은 복잡한 추론 작업에서 유망한 결과를 보여왔습니다. 그러나 CoT 프롬프팅은 일반적으로 '탐욕스러운(greedy) 디코딩' 전략을 사용하며, 이는 최적의 추론 경로를 하나만 선택하여 모델이 잠재적으로 다양한 관점이나 더 정확한 해결책을 놓칠 수 있게 합니다. 본 논문은 이러한 탐욕스러운 디코딩의 한계를 극복하고, LLM의 추론 성능을 더욱 향상시키는 새로운 디코딩 전략을 모색합니다.

## ✨ Key Contributions

- CoT 프롬프팅을 위한 새로운 디코딩 전략인 "**Self-Consistency(자기 일관성)**"를 제안합니다.
- 탐욕스러운 디코딩 대신 언어 모델의 디코더에서 **다양한 추론 경로(reasoning paths)를 샘플링**합니다.
- 샘플링된 추론 경로들을 주변화(marginalizing out)하여 가장 일관성 있는(most consistent) 최종 답변을 선택합니다(예: 다수결 투표).
- 복잡한 추론 문제에는 하나의 정확한 답으로 이어지는 여러 가지 사고 방식이 존재한다는 직관을 활용합니다.
- 다양한 산술 및 상식 추론 벤치마크(GSM8K, SVAMP, AQuA, StrategyQA, ARC-challenge 등)에서 CoT 프롬프팅의 성능을 크게 향상시켰습니다. 특히 PaLM-540B 및 GPT-3에서 새로운 최첨단(state-of-the-art) 성능을 달성했습니다.
- **비지도(unsupervised)** 방식으로, 사전 훈련된 언어 모델에 즉시 적용 가능하며, 추가적인 사람 주석, 훈련 또는 미세 조정이 필요 없습니다.
- 단일 언어 모델에서 작동하는 "자기 앙상블(self-ensemble)"과 유사하게 동작하여, 탐욕스러운 디코딩의 반복성과 국소 최적성을 피하고 단일 샘플링 생성의 확률적 특성을 완화합니다.
- CoT가 성능을 저해할 수 있는 일부 NLP 작업에서도 성능을 견고하게 향상시킬 수 있음을 보여주었으며, sample-and-rank, 빔 서치(beam search), 기존 앙상블 기반 접근 방식보다 뛰어난 성능을 보였습니다.

## 📎 Related Works

- **Chain-of-Thought(CoT) 프롬프팅:** Wei et al. (2022)의 연구는 본 논문의 직접적인 기반이 되며, CoT 프롬프팅이 다단계 추론 작업에서 모델 성능을 크게 향상시킴을 보였습니다.
- **언어 모델의 추론 능력:** 기존 연구들은 산술, 논리 및 상식 추론과 같은 '유형 2(Type 2)' 작업에서 언어 모델의 한계를 극복하기 위해 종종 특정 작업에 특화된 접근 방식(Andor et al., 2019; Ran et al., 2019; Geva et., 2020)에 초점을 맞췄습니다.
- **샘플링 및 재랭킹:** temperature sampling (Ackley et al., 1985), top-$k$ sampling (Fan et al., 2018), nucleus sampling (Holtzman et al., 2020) 등 다양한 디코딩 전략이 제안되었습니다. 생성 품질 향상을 위한 재랭킹(re-ranking) 기법은 추가 검증자(verifier) 훈련(Cobbe et al., 2021)이나 추가 사람 주석을 활용한 재랭커 훈련(Thoppilan et al., 2022) 등을 포함합니다. 본 논문의 Self-consistency는 이러한 추가 훈련이나 데이터 수집 없이 동작합니다.
- **추론 경로 추출:** 작업별로 추론 경로를 식별하는 접근 방식(Chen et al., 2019; Xu et al., 2021a)이나, 추론 과정의 다양성을 활용하는 방법(Yu et al., 2022)도 있었으나, Self-consistency는 추가 훈련 없이 디코더 샘플링만으로 이를 달성합니다.
- **언어 모델의 일관성:** 언어 모델의 대화(Adiwardana et al., 2020), 설명 생성(Camburu et al., 2020), 사실 지식 추출(Elazar et al., 2021) 등에서 발생할 수 있는 불일치 문제를 다룬 연구들이 있었습니다. 본 논문은 답변의 일관성을 활용하여 정확도를 개선하는 데 중점을 둡니다.

## 🛠️ Methodology

Self-consistency 방법은 크게 세 단계로 구성됩니다:

1. **CoT(Chain-of-Thought) 프롬프팅**: 언어 모델에 수동으로 작성된 CoT 예제(exemplars) 세트를 프롬프트로 제공하여, 모델이 질문에 대한 추론 과정을 생성하도록 유도합니다.
2. **다양한 추론 경로 샘플링**: CoT 프롬프팅에서 일반적으로 사용되는 탐욕스러운 디코딩 대신, 언어 모델의 디코더에서 여러 개의(예: $m$개) 후보 출력을 샘플링합니다. 각 출력은 추론 경로 $r_i$와 최종 답변 $a_i$로 구성됩니다. 이를 위해 온도 샘플링($T$), top-$k$ 샘플링($k$), nucleus 샘플링($p$) 등 다양한 기존 샘플링 알고리즘이 활용됩니다.
3. **답변 집계 (주변화)**: 샘플링된 모든 추론 경로를 주변화(marginalizing out)하고, 생성된 최종 답변들 중에서 **가장 일관성 있는 답변**을 선택합니다. 이는 주로 **다수결 투표(majority vote)** 방식으로 이루어집니다:
   $$ \text{arg max}_a \sum_{i=1}^{m} \mathbf{1}(a_i = a) $$
    여기서 $\mathbf{1}(a_i = a)$는 $a_i$가 특정 답변 $a$와 일치하면 1, 아니면 0인 지시 함수입니다. 논문에서는 확률 $P(r_i, a_i | \text{프롬프트, 질문})$를 기반으로 가중치를 부여하는 방법도 탐색했으나, 단순 다수결 투표와 유사한 높은 정확도를 보였습니다. 이 방법은 여러 가지 다른 사고방식이 동일한 답에 도달할수록 최종 답에 대한 신뢰도가 높아진다는 인간의 경험과 유사합니다.

## 📊 Results

- **현저한 성능 향상**: Self-consistency는 평가된 모든 4가지 언어 모델(UL2-20B, GPT-3-175B, LaMDA-137B, PaLM-540B)에서 추론 정확도를 크게 향상시켰습니다.
  - **산술 추론**: GSM8K에서 절대 정확도 17.9%, SVAMP에서 11.0%, AQuA에서 12.2%, MultiArith에서 4.6%, ASDiv에서 7.9% 향상.
  - **상식 추론**: StrategyQA에서 6.4%, ARC-challenge에서 3.9%, CommonsenseQA에서 1.7% 향상.
  - 거의 모든 작업에서 새로운 최첨단(state-of-the-art) 성능을 달성했으며, 작업별 훈련이나 미세 조정이 필요한 기존 방법론을 능가했습니다.
- **샘플링 경로 수의 영향**: 샘플링된 추론 경로의 수가 많을수록(예: 40개까지) 추론 정확도가 지속적으로 향상됨을 확인했습니다.
- **강건성(Robustness)**:
  - CoT 프롬프팅이 일반적으로 성능을 저해할 수 있는 일부 NLP 작업(예: ANLI-R1, e-SNLI, RTE, BoolQ, HotpotQA)에서도 강건한 성능을 유지하며, 종종 표준 프롬프팅보다 뛰어났습니다.
  - 다양한 샘플링 전략(온도, top-$k$, nucleus 샘플링) 및 매개변수에 강건함을 보였습니다.
  - 불완전한 프롬프트에도 불구하고 효과적으로 작동했습니다.
  - 자연어가 아닌 추론 경로(예: 방정식) 및 Zero-shot CoT(Kojima et al., 2022)에도 적용 가능하며, 상당한 성능 향상을 가져왔습니다.
- **다른 접근 방식과의 비교**: sample-and-rank, 빔 서치(beam search) 및 프롬프트 순서 변경 또는 여러 프롬프트 세트를 사용하는 기존의 앙상블 기반 접근 방식보다 훨씬 뛰어난 성능을 보였습니다.
- **불확실성 추정**: 일관성이 모델의 정확도와 높은 상관관계를 보였는데, 이는 Self-consistency를 모델의 불확실성 추정 지표로 활용할 수 있음을 시사합니다.

## 🧠 Insights & Discussion

- **함의**: Self-consistency는 대규모 언어 모델의 추론 정확도를 크게 향상시키는 동시에, 더 나은 추론 과정을 수집하고, 모델 출력의 불확실성 추정 및 개선된 보정(calibration)을 제공하는 간단하면서도 효과적인 방법입니다. 복잡한 추론 문제에서 다양한 사고 방식이 동일한 정답으로 귀결될 때, 그 답에 대한 신뢰도가 높아진다는 인간의 직관을 잘 활용합니다.
- **한계**: 주요 한계점은 여러 추론 경로를 샘플링해야 하므로 **계산 비용이 증가한다**는 것입니다. 그러나 적은 수의 경로(예: 5개 또는 10개)만으로도 대부분의 성능 향상을 얻을 수 있어 비용 부담을 줄일 수 있습니다.
- **향후 연구**:
  - Self-consistency를 활용하여 모델 미세 조정을 위한 더 나은 지도 학습 데이터(supervised data)를 생성함으로써, 단일 추론 실행에서도 더 정확한 예측을 할 수 있도록 합니다.
  - 언어 모델이 때때로 잘못되거나 무의미한 추론 경로(예: 비사실적인 정보)를 생성할 수 있다는 점을 개선하여, 모델의 추론 근거(rationales)를 더 잘 확립하고 사실성 및 안전성을 향상시키는 연구가 필요합니다.

## 📌 TL;DR

본 논문은 Chain-of-Thought 프롬프팅의 탐욕스러운 디코딩을 대체하는 **Self-consistency**라는 새로운 디코딩 전략을 제안합니다. 이 방법은 대규모 언어 모델에서 다양한 추론 경로를 샘플링한 후, 샘플링된 경로들을 주변화하여 가장 일관성 있는 최종 답변(대부분 다수결 투표)을 선택합니다. 그 결과, 산술 및 상식 추론 벤치마크에서 LLM의 성능을 비약적으로 향상시키며 새로운 최첨단 결과를 달성했습니다. 추가 훈련 없이 바로 적용 가능하며 모델의 불확실성 추정에도 활용될 수 있지만, 계산 비용 증가라는 한계가 있습니다.
