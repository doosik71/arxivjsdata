# PAL: Program-aided Language Models

Luyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan, Graham Neubig

## 🧩 Problem to Solve

최근 대규모 언어 모델(LLM)은 "사고의 사슬(Chain-of-Thought, COT)"과 같은 프롬프트 방법을 통해 문제 분해 능력은 향상되었으나, 복잡한 산술 및 논리 추론 작업에서 종종 계산 오류나 잘못된 추론을 저지릅니다. LLM이 문제를 단계별로 이해하고 분해하는 데는 능숙하지만, 각 단계를 정확하게 '해결'하는 부분에서 오류가 발생하는 것이 주요 문제입니다. 특히 큰 숫자를 다룰 때 이러한 오류가 두드러집니다.

## ✨ Key Contributions

- **프로그램 기반 추론 도입:** LLM이 자연어 문제를 중간 추론 단계로 "프로그램"을 생성하도록 하고, 이 프로그램의 실행은 외부 런타임(예: Python 인터프리터)에 위임하는 Program-Aided Language Models (PAL)이라는 새로운 접근 방식을 제안합니다.
- **LLM 역할 재정의:** LLM의 역할을 문제 이해 및 프로그래밍 가능한 단계로의 분해에 집중하고, 실제 계산 및 해결은 결정론적인 인터프리터에 맡김으로써 LLM의 추론 오류를 보완합니다.
- **최고 성능 달성:** 13가지 수학, 상징, 알고리즘 추론 작업에서 기존 COT 기반의 훨씬 더 큰 모델들을 능가하며 새로운 소수점샷(few-shot) 최고 정확도(state-of-the-art)를 달성했습니다. 특히 GSM8K 벤치마크에서 PaLM-540B보다 15%p 높은 정확도를 보였습니다.
- **강력한 견고성:** GSM-HARD와 같이 큰 숫자가 포함된 문제에서 기존 COT 방식이 크게 성능이 저하되는 반면, PAL은 훨씬 더 견고한 성능을 보여줍니다.
- **신경-기호(Neuro-Symbolic) AI 시너지:** 신경망 기반 LLM과 기호 기반 인터프리터 간의 효과적인 시너지를 입증하여 일반적이고 견고한 AI 추론자 개발의 가능성을 제시합니다.

## 📎 Related Works

- **Few-shot Prompting (Brown et al., 2020):** 소수의 예시만으로 모델의 성능을 향상시키는 방법.
- **Chain-of-Thought (COT) Prompting (Wei et al., 2022):** LLM이 문제 해결 과정을 단계별 자연어 추론으로 생성하게 하여 복잡한 추론 작업을 개선하는 방법. (PAL은 COT의 계산 정확도 문제를 해결)
- **Scratchpads (Nye et al., 2021) 및 Least-to-Most (Zhou et al., 2022):** LLM이 명시적인 중간 추론 단계를 생성하도록 요구하는 다른 프롬프트 기법. (PAL은 Least-to-Most 프롬프트에서도 개선 효과를 보임)
- **LLM with External Tools (Cobbe et al., 2021; Demeter & Downey, 2020; Chowdhery et al., 2022):** 계산기 등 외부 모듈을 LLM에 통합하여 특정 작업을 보조하는 연구. (PAL은 범용 Python 인터프리터를 사용하여 전문화된 모듈이나 임시방편 없이 다양한 계산을 처리)
- **Program of Thoughts Prompting (Chen et al., 2022):** PAL과 유사하게 프로그램 생성을 통해 수치 추론을 개선하는 동시 연구. (PAL은 수학 외 상징적/알고리즘 벤치마크에서도 효과 입증)
- **Semantic Parsing (Shin & Van Durme, 2021; Shin et al., 2021):** 자연어를 도메인 특화 언어나 코드와 같은 형식적 표현으로 파싱하는 연구. (PAL은 CFG 같은 제약 없이 자유 형식 Python 코드를 생성하며, 대규모로 사전 학습된 Python LLM의 이점을 활용)

## 🛠️ Methodology

PAL의 핵심 방법론은 다음과 같습니다:

1. **프롬프트 구성:**
   - PAL은 기존 Few-shot 프롬프트를 활용하되, 각 인컨텍스트 예시 $\{ (x_{i}, t_{i}) \}_{i=1}^{k}$ 에서 출력 $y_{i}$를 직접 제공하지 않습니다.
   - $t_{i}$는 자연어(NL)와 프로그래밍 언어(PL) 문장이 번갈아 나타나는(interleaved) 형태로 구성됩니다. 예를 들어, 문제 설명을 Python 변수로 정의하고, 중간 계산을 Python 코드로 표현합니다.
   - Python 주석(`\# ...`)을 사용하여 자연어 설명을 프로그램 코드에 포함시켜 LLM이 문맥을 이해하고 프로그램을 생성하는 데 도움을 줍니다.
   - 변수 이름은 문제의 엔티티를 의미 있게 반영하도록 작성됩니다 (예: `num_apples_in_basket`). 이는 코드의 가독성을 높이고 LLM의 추론을 돕습니다.
2. **LLM 추론:**
   - 테스트 질문 $x_{\text{test}}$가 프롬프트에 추가되어 LLM에 입력됩니다.
   - LLM은 입력된 자연어 질문을 Python 코드를 포함하는 중간 추론 단계 $t_{\text{test}}$로 변환하여 생성합니다.
3. **외부 인터프리터 실행:**
   - LLM이 생성한 프로그램 $t_{\text{test}}$는 표준 Python 인터프리터(또는 다른 솔버)로 전달되어 실행됩니다.
   - 인터프리터는 프로그램 코드를 실행하여 최종 결과 $y_{\text{test}}$를 계산합니다.

이 과정에서 LLM은 문제의 논리적 분해와 코드 생성에 집중하고, 실제 계산은 Python 인터프리터가 수행하여 LLM의 계산 오류를 방지합니다.

## 📊 Results

- **수학 추론 (Table 1):**

  - 8가지 수학 단어 문제 데이터셋(GSM8K, SVAMP, ASDIV 등)에서 PAL(Codex 사용)은 모든 벤치마크에서 새로운 소수점샷 최고 정확도를 달성했습니다.
  - 특히 GSM8K에서 PAL은 72.0%의 정확도를 기록하여 COT를 사용한 PaLM-540B(56.9%) 및 Minerva 540B(58.8%)를 크게 능가했습니다.
  - **GSM-HARD (큰 숫자):** GSM8K의 숫자를 크게 바꾼 GSM-HARD에서 COT의 정확도는 65.6%에서 20.1%로 급락한 반면, PAL은 72.0%에서 61.2%로 비교적 안정적인 성능을 유지하며 견고성을 입증했습니다.
  - **다중 샘플 생성:** GSM8K에서 40개의 샘플을 생성하고 다수결 투표를 사용했을 때, PAL은 80.4%의 정확도로 Minerva-540B(78.5%)를 뛰어넘었습니다.

- **상징적 추론 및 알고리즘 작업 (Table 2):**
  - **Colored Objects:** PAL은 95.1%의 정확도로 COT(86.3%)보다 8.8%p, Direct Prompting(75.7%)보다 19.4%p 향상되었습니다. 질문의 복잡도(객체 수)가 증가해도 PAL은 COT보다 훨씬 안정적인 성능을 보였습니다 (Figure 6).
  - **Penguins:** PAL은 93.3%로 COT(79.2%)보다 14.1%p 높은 정확도를 보였습니다.
  - **Date:** PAL은 76.2%로 COT(64.8%)보다 11.4%p 높은 정확도를 보였습니다.
  - **Object Counting:** PAL은 96.7%로 COT(73.0%)보다 23.7%p 크게 향상되었습니다.
  - **Repeat Copy:** PAL은 90.6%로 COT(68.8%)보다 21.8%p 향상되었습니다.

## 🧠 Insights & Discussion

- **견고성 및 일반화:** PAL은 LLM의 산술 및 논리 추론 한계를 외부 인터프리터에 위임하여 해결함으로써, 복잡한 계산이나 큰 숫자가 포함된 문제에 대해 COT보다 훨씬 견고한 성능을 보여줍니다. 이는 LLM이 "생각"하는 능력과 "해결"하는 능력을 분리하여 최적화할 수 있음을 시사합니다.
- **LLM의 "계산 능력" 한계:** GSM-HARD 분석 결과, COT의 실패 원인이 주로 LLM의 산술 연산 능력 부족에 있으며, 큰 숫자가 LLM의 추론 과정을 "혼란스럽게" 하기보다는 단순히 계산을 틀리게 함을 보여줍니다.
- **코드 LLM 및 자연어 LLM 적용 가능성:** PAL은 Codex와 같은 코드 기반 LLM뿐만 아니라, 충분히 강력한 `text-davinci-002`, `text-davinci-003`과 같은 자연어 LLM에서도 효과적임을 입증했습니다. 이는 PAL 접근 방식이 특정 모델 유형에 국한되지 않음을 시사합니다.
- **인터프리터의 중요성:** Python 코드를 생성하되 LLM이 직접 "실행"하게 했을 때(인터프리터 없이), 성능이 크게 저하되었습니다. 이는 PAL의 핵심 이점이 단순히 "더 나은 프롬프트"가 아니라, 결정론적 외부 인터프리터와의 시너지에서 온다는 것을 강조합니다.
- **의미 있는 변수 이름의 중요성:** PAL 프롬프트에서 의미 있는 변수 이름을 사용하지 않고 임의의 문자로 대체했을 때, 성능이 크게 감소했습니다. 이는 LLM이 코드 내의 엔티티와 변수를 연결하는 데 있어 변수 이름이 중요한 역할을 하며, 모델의 "접지(grounding)"를 돕는다는 것을 보여줍니다.

## 📌 TL;DR

PAL(Program-aided Language Models)은 LLM의 추론 오류 문제를 해결하기 위해, 자연어 문제를 중간 단계의 "프로그램"으로 변환하고, 그 실행을 Python 인터프리터에 맡기는 새로운 접근 방식입니다. 이 신경-기호(Neuro-Symbolic) 시너지는 LLM의 문제 분해 능력과 외부 인터프리터의 정확한 계산 능력을 결합하여, 13가지 수학, 상징, 알고리즘 추론 작업에서 기존 Chain-of-Thought(COT) 방식 및 더 큰 모델들을 능가하는 최고 수준의 성능과 견고성을 달성했습니다.
