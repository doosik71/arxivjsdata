# Deep Metric Learning with Hierarchical Triplet Loss

Weifeng Ge, Weilin Huang, Dengke Dong, and Matthew R. Scott

## 🧩 Problem to Solve

기존의 딥 메트릭 러닝(Deep Metric Learning, DML)에서 트립렛 손실(triplet loss)은 훈련 샘플(트립렛)을 무작위로 샘플링하는 주요 한계를 가지고 있습니다. 이는 모델이 수렴하기 시작하면 대부분의 트립렛이 이미 마진을 만족하는 "쉬운" 샘플이 되어 그래디언트를 생성하지 못하고, 이는 학습 속도 저하와 성능 저하로 이어집니다. 또한, 미니 배치 단위로 학습이 이루어지기 때문에 전체 데이터셋의 전역적인 데이터 분포를 고려하기 어렵고, 이로 인해 지역 최적해에 빠질 위험이 있습니다. 이 논문은 이러한 샘플링 문제를 해결하고, 전역적인 문맥 정보를 활용하여 더 효과적인 트립렛 샘플을 자동으로 수집하는 것을 목표로 합니다.

## ✨ Key Contributions

- **새로운 계층적 트립렛 손실(Hierarchical Triplet Loss, HTL) 제안:** 전역 문맥 정보를 인코딩하는 적응적으로 업데이트되는 계층적 트리를 통해 정보성 훈련 샘플(트립렛)을 자동으로 수집합니다.
- **계층적 클래스 레벨 트리 구축:** 시각적으로 유사한 클래스들을 재귀적으로 병합하여 전체 데이터셋의 본질적인 데이터 분포를 자연스럽게 포착합니다.
- **동적 위반 마진(violate margin) 도입:** 구축된 계층적 트리를 기반으로 동적으로 계산되는 새로운 위반 마진을 도입하여 트립렛 수집 문제를 공식화합니다. 이를 통해 전역 문맥의 안내를 받아 의미 있는 "어려운" 샘플들을 자동으로 선택합니다.
- **판별 특징 학습 촉진:** 시각적으로 유사하지만 의미론적으로 다른 클래스들로부터 더 판별적인 특징을 학습하도록 유도하여 더 빠른 수렴과 더 나은 성능을 달성합니다.
- **우수한 성능 및 광범위한 적용 가능성:** 이미지 검색 및 얼굴 인식 태스크에서 표준 트립렛 손실보다 1%~18% 더 우수한 성능을 보이며, 더 적은 학습 반복으로 여러 벤치마크에서 새로운 최첨단(state-of-the-art) 성능을 달성합니다. 기존의 컨트라스티브 손실(contrastive loss), 쿼드러플렛 손실(quadruplet loss) 등 다른 DML 방법론에도 쉽게 통합될 수 있습니다.

## 📎 Related Works

- **딥 메트릭 러닝(Deep Metric Learning):** 컨트라스티브 손실 [27,6], 트립렛 손실 [22], 쿼드러플렛 손실 [5]과 같이 널리 사용되는 손실 함수들을 언급하며, DML의 목표가 동일 클래스 샘플은 가깝게, 다른 클래스 샘플은 멀리 떨어뜨리는 것임을 설명합니다.
- **정보성 샘플 선택(Informative Sample Selection):** $O(N^3)$개의 방대한 트립렛 중에서 정보성 샘플을 선택하는 것의 어려움을 지적합니다. 하드 네거티브 마이닝(hard negative mining) [4]이 널리 사용되지만, 미니 배치 내의 지역적 정보에 한정되는 문제를 언급합니다. [35,7]에서 거리 분포를 사용하여 트립렛 샘플링을 안내한 연구에서 영감을 받았으며, 본 논문은 계층적 트리를 통해 전역 문맥 정보를 통합하여 이를 발전시켰다고 설명합니다.

## 🛠️ Methodology

제안된 계층적 트립렛 손실(HTL)은 두 가지 주요 구성 요소로 이루어집니다.

1. **계층적 클래스 트리 구축 (Manifold Structure in Hierarchy):**

   - **거리 행렬 계산:** 먼저 기존 트립렛 손실로 사전 훈련된 신경망 $\phi_t(\cdot, \theta)$의 특징 임베딩 $r_i = \phi_t(x_i, \theta)$를 사용하여 전체 데이터셋의 클래스 간 거리 행렬 $d(p,q)$를 계산합니다.
     $$d(p,q) = \frac{1}{n_p n_q} \sum_{i \in p, j \in q} \|r_i - r_j\|^2$$
     여기서 $n_p$와 $n_q$는 각각 클래스 $p$와 $q$의 샘플 수입니다.
   - **계층적 트리 생성:** 계산된 클래스 간 거리를 기반으로 $L$개의 레벨을 가진 계층적 트리 $H$를 구축합니다. 0번째 레벨의 리프 노드는 원본 이미지 클래스를 나타냅니다.
   - **재귀적 병합:** 각 레벨 $l$에서 노드 병합을 위한 임계값 $d_l$을 $d_l = \frac{l(4-d_0)}{L} + d_0$로 설정합니다 (여기서 $d_0$는 평균 클래스 내 거리). 거리가 $d_l$보다 작은 두 클래스는 다음 레벨의 단일 노드로 병합됩니다.
   - **트리 업데이트:** 이 계층적 트리 $H$는 전체 데이터셋의 클래스 관계를 포착하며, 학습 과정에서 특정 반복마다 대화식으로 업데이트됩니다.

2. **새로운 위반 마진을 사용한 계층적 트립렛 손실 공식화:**
   - **앵커-이웃 샘플링 (Anchor-Neighbor Sampling, A-N sampling):**
     - 구축된 계층적 트리 $H$의 0번째 레벨에서 $l'$개의 노드(원본 클래스)를 무작위로 선택하여 미니 배치 내 훈련 샘플의 다양성을 확보합니다.
     - 각 선택된 노드에 대해, 특징 공간에서 가장 가까운 $m-1$개의 클래스를 선택하여 시각적으로 유사한 클래스들로부터 판별 특징을 학습하도록 유도합니다.
     - 각 클래스에서 $t$개의 이미지를 무작위로 수집하여 총 $n = l'mt$개의 이미지를 가진 미니 배치 $M$을 구성합니다.
   - **트립렛 생성 및 동적 위반 마진:** 미니 배치 $M$에서 계산되는 계층적 트립렛 손실은 다음과 같습니다.
     $$L_M = \frac{1}{2Z_M} \sum_{T_z \in T_M} [\left\|x_a^z - x_p^z\right\| - \left\|x_a^z - x_n^z\right\| + \alpha_z]_+$$
     여기서 $T_z = (x_a, x_p, x_n)$는 앵커, 포지티브, 네거티브 샘플로 구성된 트립렛입니다.
     $\alpha_z$는 동적 위반 마진으로, 앵커 클래스 $y_a$와 네거티브 클래스 $y_n$의 관계에 따라 계층적 클래스 트리에서 계산됩니다.
     $$\alpha_z = \beta + d_{H(y_a, y_n)} - s_{y_a}$$
     - $\beta$: 상수 파라미터 (0.1로 설정)
     - $H(y_a, y_n)$: 클래스 $y_a$와 $y_n$이 다음 레벨에서 단일 노드로 병합되는 계층적 레벨입니다.
     - $d_{H(y_a, y_n)}$: 해당 레벨의 병합 임계값입니다.
     - $s_{y_a}$: 클래스 $y_a$ 내 샘플들의 평균 거리입니다.
       이 동적 마진은 전역 클래스 구조를 인코딩하여 최적화 목표에 맞춰 각각의 트립렛에 대한 문맥 정보를 제공합니다.

## 📊 Results

- **In-Shop Clothes Retrieval 데이터셋:** Recall@1에서 80.9%를 달성하여 기본 트립렛 손실보다 18.6%포인트, 기존 최첨단(BIER, HDC)보다 4.0%포인트 및 18.8%포인트 높은 성능을 기록했습니다.
- **Caltech-UCSD Birds 200-2011 데이터셋:** Recall@1에서 57.1%를 달성하여 기본 트립렛 손실(55.9%)보다 1.2%포인트 높은 성능을 보였습니다.
- **Cars-196 데이터셋:** Recall@1에서 81.4%를 달성하여 기본 트립렛 손실보다 2.2%포인트, 기존 최첨단보다 3.4%포인트 높은 성능을 기록했습니다.
- **Stanford Online Products 데이터셋:** Recall@1에서 74.8%를 달성하여 기본 트립렛 손실보다 2.2%포인트, 기존 최첨단보다 2.1%포인트 높은 성능을 기록했습니다.
- **LFW 얼굴 인식 데이터셋:** 99.2%의 정확도를 달성하여 최첨단 결과와 유사한 수준을 보였으나, SphereFace (99.42%) 및 FaceNet (99.65%)보다는 약간 낮았습니다. 이는 트립렛 기반 방법의 노이즈 민감성 때문으로 분석됩니다.
- **수렴 속도:** HTL은 In-Shop Clothes Retrieval에서 무작위 샘플링보다 약 2배 빠르게 수렴하며, CUB-200-2011에서 HDC보다 훨씬 빠르게 (1000회 반복 vs 60000회 반복) 수렴합니다.
- **어블레이션 연구:** 앵커-이웃 샘플링이 성능 향상에 크게 기여했으며, 동적 위반 마진은 이를 더욱 개선했습니다. 계층 깊이 16이 최적의 성능을 보였고, HTL이 컨트라스티브 손실 (HDC+)에도 통합되어 상당한 성능 향상을 이끌어낼 수 있음을 보여주었습니다.

## 🧠 Insights & Discussion

- 전통적인 트립렛 손실은 모델이 수렴함에 따라 대부분의 트립렛이 손실에 기여하지 않는 "쉬운" 샘플이 되어 학습 효율이 저하되고 지역 최적해에 빠질 위험이 있습니다.
- HTL은 계층적 클래스 트리를 통해 전역적인 데이터 분포와 클래스 간의 관계를 모델에 통합함으로써, 시각적으로 유사하지만 의미론적으로 다른 "어려운" 정보성 샘플들을 효과적으로 식별하고 학습에 활용합니다.
- 특히, 동적 위반 마진은 트리의 계층 구조에 따라 적절하게 조절되어, 기존의 고정 마진에서는 간과될 수 있었던 트립렛들도 그래디언트를 생성하도록 유도하여 모델의 판별력을 크게 향상시킵니다.
- 앵커-이웃 샘플링 전략은 미니 배치 내에서 다양하고 의미 있는 "어려운" 샘플들을 수집하는 데 중요한 역할을 합니다.
- 제한 사항으로는 트립렛 기반 방법론의 노이즈 민감성이 여전히 존재하며, 클래스 수가 적은 데이터셋에서는 과적합 위험으로 인해 성능 향상 폭이 상대적으로 작을 수 있다는 점이 언급되었습니다.

## 📌 TL;DR

- **문제:** 기존 딥 메트릭 러닝의 트립렛 손실은 무작위 샘플링으로 인해 정보성이 낮은 트립렛이 많아 학습이 비효율적이고, 전역 데이터 분포를 고려하지 못해 수렴 속도가 느리며 성능이 저하되는 문제가 있습니다.
- **해결책:** 이 논문은 **계층적 트립렛 손실(HTL)**을 제안합니다. HTL은 먼저 시각적으로 유사한 클래스들을 묶어 전역 데이터 문맥을 포착하는 **동적 계층적 클래스 트리**를 구축합니다. 다음으로, 이 트리를 기반으로 한 **앵커-이웃 샘플링** 전략을 사용하여 미니 배치에 다양하고 시각적으로 유사한 클래스들을 포함합니다. 가장 중요한 기여는 앵커 클래스와 네거티브 클래스가 병합되는 계층적 레벨에 따라 **동적 위반 마진($\alpha_z$)**을 계산하는 것입니다. 이 동적 마진은 모델이 "쉬운" 트립렛을 무시하지 않고, 시각적으로 유사하지만 의미론적으로 다른 "어려운" 정보성 트립렛으로부터 그래디언트를 학습하도록 유도합니다.
- **주요 결과:** HTL은 이미지 검색(In-Shop Clothes, CUB-200-2011, Cars-196, Stanford Online Products) 및 얼굴 인식(LFW) 벤치마크에서 표준 트립렛 손실보다 1%~18% 우수한 새로운 최첨단 성능을 달성했으며, 더 빠른 수렴 속도를 보였습니다. 이는 전역 문맥 정보를 효과적으로 활용하여 정보성 샘플을 선택하는 HTL의 강력한 판별 능력을 입증합니다.
