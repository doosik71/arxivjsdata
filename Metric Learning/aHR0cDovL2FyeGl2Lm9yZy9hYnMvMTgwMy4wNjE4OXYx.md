# Triplet-Center Loss for Multi-View 3D Object Retrieval

Xinwei He, Yang Zhou, Zhichao Zhou, Song Bai, Xiang Bai

## 🧩 Problem to Solve

기존의 3D 객체 인식 알고리즘 대부분은 3D 데이터 분류를 위해 딥 러닝 모델의 강력한 판별 능력과 소프트맥스(softmax) 손실 함수를 활용하는 데 초점을 맞추었습니다. 반면, 3D 객체 검색을 위한 딥 메트릭 러닝(deep metric learning)을 통한 판별 특징 학습은 상대적으로 간과되어 왔습니다. 특히, 트립렛 손실(triplet loss)은 복잡한 트립렛 구성과 어려운 샘플 마이닝에 어려움을 겪고, 센터 손실(center loss)은 클래스 내 응집력을 높이지만 클래스 간 분리 가능성을 명시적으로 고려하지 않는다는 한계가 있었습니다.

## ✨ Key Contributions

- **3D 객체 검색을 위한 대표적인 손실 함수 도입 및 탐구:** 트립렛 손실과 센터 손실을 3D 객체 검색에 적용하고, 검색 성능에 미치는 영향을 심층적으로 분석했습니다.
- **새로운 트립렛-센터 손실(Triplet-Center Loss, TCL) 함수 제안:** 트립렛 손실과 센터 손실의 장점을 결합하여 특징의 판별력을 더욱 강화하는 새로운 손실 함수인 TCL을 개발했습니다.
- **최첨단 성능 달성:** 동일한 CNN 모델을 사용하여 TCL 기반 방법론이 기존 대안들보다 우수하며, ModelNet40 및 ShapeNet Core55와 같은 두 가지 주요 3D 객체 검색 벤치마크와 SHREC'13 및 SHREC'14 스케치 기반 3D 형상 검색 벤치마크에서 일관되게 최첨단 성능을 달성함을 입증했습니다.
- **효율적인 특징 학습:** TCL은 각 클래스에 대한 센터를 학습하고, 동일 클래스 내 샘플과 센터 간의 거리가 다른 클래스의 샘플과 센터 간의 거리보다 가깝도록 요구함으로써 특징의 클래스 내 응집력과 클래스 간 분리 가능성을 동시에 향상시킵니다. 또한, 기존 트립렛 손실의 복잡한 트립렛 구성 및 하드 샘플 마이닝의 필요성을 없애 학습 효율성을 높였습니다.

## 📎 Related Works

- **3D 형상 분석:** ShapeNet [7]과 같은 대규모 3D 데이터셋과 딥 러닝의 발전으로 활발히 연구되고 있습니다. [34, 13]에서 포괄적인 조사를 제공합니다.
- **3D 모델 기반 방법:** 3D 메시, 복셀 그리드, 포인트 클라우드 등 3D 데이터 형식에서 직접 특징을 학습합니다 (예: DLAN [11], Kd-network [15], VoxNet [21], PointNet [24]).
- **뷰 기반 방법:** 3D 형상을 여러 2D 뷰로 렌더링한 후 2D CNN을 사용하여 특징을 추출하고 통합합니다 (예: MVCNN [33], GIFT [1, 2], DeepPano [31]). 이 방법들은 일반적으로 3D 모델 기반 방법보다 우수한 성능을 보입니다.
- **딥 메트릭 러닝 (2D 이미지 검색/재식별 분야):**
  - **콘트라스티브 손실 (Contrastive Loss) [8]**
  - **트립렛 손실 (Triplet Loss) [29]:** 동일한 정체성을 가진 데이터 포인트의 특징이 다른 정체성을 가진 포인트보다 더 가깝게 모이도록 학습합니다. [19, 23, 37]과 같은 변형과 하드 트립렛 마이닝을 개선한 배치-하드 트립렛 손실 (BHL) [12]이 있습니다.
  - **센터 손실 (Center Loss) [39]:** 각 클래스의 특징에 대한 센터를 학습하고, 같은 클래스의 특징을 해당 센터에 가깝게 끌어당깁니다. 주로 소프트맥스 손실의 보조 손실로 사용됩니다.
- **유사한 선행 연구:** Wang et al. [36]은 얼굴 인증 문제에 유사한 손실을 제안했지만, 본 논문의 TCL은 다른 직관에서 출발하며 특징 및 가중치에 대한 정규화가 필요 없다는 차이가 있습니다.

## 🛠️ Methodology

본 논문은 뷰 기반 3D 객체 검색을 위해 MVCNN [33] 프레임워크를 기반으로 하며, 여기에 제안하는 트립렛-센터 손실(TCL)을 주요 감독 손실로 적용합니다. 종종 소프트맥스 손실과 결합하여 사용됩니다.

1. **동기:** 소프트맥스 손실은 클래스 분리 경계를 찾는 데 중점을 두어 클래스 내 분산이 클 수 있습니다. 센터 손실은 클래스 내 분산을 줄이지만 클래스 간 분리 가능성을 명시적으로 고려하지 않아 클래스 간 중첩을 야기할 수 있습니다. 트립렛 손실은 직접적으로 메트릭 학습을 최적화하지만 트립렛 구성의 복잡성이 큽니다. TCL은 이들의 장점을 결합하여 효율적으로 판별 특징을 학습하는 것을 목표로 합니다.
2. **트립렛-센터 손실 (TCL) 정의:**
   - 목표: 심층 학습된 특징의 클래스 내 거리를 효율적으로 최소화하고 클래스 간 거리를 동시에 최대화합니다.
   - 각 클래스 $y_i$에 대해 학습 가능한 센터 $c_{y_i} \in \mathbb{R}^d$를 유지합니다.
   - 샘플 $x_i$의 특징 $f_i$와 레이블 $y_i$에 대한 손실은 다음과 같이 정의됩니다:
     $$ L*{tc} = \sum*{i=1}^{M} \max \left( D(f*i, c*{y*i}) + m - \min*{j \neq y_i} D(f_i, c_j), 0 \right) $$
        여기서 $D(f_i, c_k) = \frac{1}{2} \|f_i - c_k\|_2^2$는 제곱 유클리드 거리 함수이고, $m$은 마진(margin)이며, $M$은 미니 배치 크기입니다.
   - 이 정의는 샘플과 해당 클래스 센터($c_{y_i}$) 간의 거리가 가장 가까운 음성 클래스 센터(negative center, $j \neq y_i$인 $c_j$)와의 거리보다 적어도 마진 $m$만큼 더 가깝도록 강제합니다.
3. **기울기 계산:** TCL의 특징 임베딩 $f_i$와 센터 $c_j$에 대한 미분은 역전파를 위해 제공됩니다.
   - $\frac{\partial L_{tc}}{\partial f_i} = (c_{q_i} - c_{y_i}) \cdot \mathbf{1}[\tilde{L}_i > 0]$ (여기서 $q_i$는 가장 가까운 음성 센터의 인덱스입니다).
4. **소프트맥스 손실과의 공동 감독:** 더 나은 성능을 위해 TCL은 종종 소프트맥스 손실과 결합됩니다:
   $$ L*{total} = \lambda L*{tc} + L\_{softmax} $$
   - $\lambda$는 두 손실 간의 균형을 조절하는 하이퍼파라미터입니다.
   - 소프트맥스 손실은 TCL의 파라메트릭 센터가 미니 배치 기반으로 업데이트될 때 더 나은 클래스 센터를 찾는 좋은 가이드 역할을 합니다.
5. **트립렛 손실과의 비교:** TCL은 $N$개의 트립렛(샘플, 해당 센터, 가장 가까운 음성 센터)만 형성하는 반면, 기존 트립렛 손실은 $O(N^3)$개의 트립렛을 요구하여 복잡한 트립렛 구성과 하드 샘플 마이닝 문제를 피할 수 있습니다.
6. **센터 손실과의 비교:** TCL은 소프트맥스 손실 없이 독립적으로 사용될 수 있습니다(센터 손실은 그렇지 않음). 또한, TCL은 클래스 간 분리 가능성을 명시적으로 최대화하는 반면, 센터 손실은 이를 간과합니다. TCL은 힌지-스타일(hinge-style) 손실을 사용하여 상대적 거리를 페널티하여 학습이 더 쉽고 유연합니다.

## 📊 Results

- **일반 3D 형상 검색 (ModelNet40, ShapeNet Core55):**
  - **ModelNet40:** TCL+softmax는 88.0% mAP와 89.0% AUC를 달성하여 기본 소프트맥스 손실(80.2% mAP)뿐만 아니라 MVCNN (80.2% mAP), GIFT (81.9% mAP), DLAN (85.0% mAP)과 같은 최첨단 방법들을 능가합니다.
  - **ShapeNet Core55 (교란된 데이터셋):** TCL+softmax는 MVCNN의 73.4%, GIFT의 81.1%에 비해 마이크로-평균 mAP 84.0%를 달성하는 등 상당한 개선을 보였습니다. F1, NDCG 등 다른 지표에서도 우수한 성능을 기록했습니다.
  - **파라미터 영향:** TCL은 $\lambda$ 값(0.01~10)에 대해 매우 강건하지만, 마진 $m$ 값에 민감하여 $m=5$일 때 최적의 결과를 얻었습니다.
  - **학습된 표현의 시각화 (t-SNE):** TCL+softmax는 학습된 특징들이 가장 조밀하고 분리된 클러스터를 형성하여 우수한 판별 능력을 입증했습니다.
- **스케치 기반 3D 형상 검색 (SHREC’13, SHREC’14):**
  - TCL+softmax는 LWBR과 같은 기존 최첨단 방법(SHREC'13에서 LWBR의 75.2% mAP 대비 80.7% mAP 달성)보다 최소 5% 이상 높은 mAP를 달성하며 일관되게 최첨단 성능을 보였습니다. 이는 교차 도메인 검색 작업에서도 TCL의 효과를 보여줍니다.
- **뷰 기반 vs. 모델 기반:** VoxNet 및 PointNet과 같은 모델 기반 접근 방식에 TCL을 통합했을 때, 기본 방법 대비 3~4% mAP 향상을 가져왔지만, 전체 성능은 뷰 기반 방법보다 낮았습니다.

## 🧠 Insights & Discussion

- **TCL의 강점:** TCL은 클래스 내 분산을 최소화하고 클래스 간 분리 가능성을 센터를 통해 명시적으로 최대화함으로써, 검색 작업에 매우 중요하고 견고한 판별 특징 임베딩을 학습합니다.
- **보완적인 손실 함수:** TCL과 소프트맥스 손실의 결합은 소프트맥스 손실이 클래스 분리를 위한 좋은 초기 가이드를 제공하고 TCL이 메트릭 학습을 위한 특징 공간을 정제하기 때문에 매우 효과적입니다.
- **효율성:** TCL은 기존 트립렛 손실의 주요 단점인 복잡한 트립렛 구성과 하드 샘플 마이닝을 피함으로써 학습 과정을 더 실용적이고 효율적으로 만듭니다.
- **일반화 가능성:** TCL의 효과는 일반 3D 형상 검색을 넘어 스케치 기반 3D 검색과 같은 도전적인 교차 도메인 작업에까지 확장되며, 심지어 모델 기반 3D 인식 방법의 성능도 향상시킵니다.
- **한계 및 향후 연구:** 모델 기반 방법에서 TCL이 개선을 가져오긴 하지만, 뷰 기반 방법보다 기본 성능이 낮은 경향이 있습니다. 향후 연구에서는 TCL을 인물 재식별, 얼굴 인식, 콘텐츠 기반 이미지 검색과 같은 다른 검색 작업에 적용할 계획입니다.

## 📌 TL;DR

이 논문은 3D 객체 검색에서 딥 메트릭 러닝이 간과되어 온 문제를 해결합니다. 트립렛 손실과 센터 손실의 장점을 결합한 새로운 **트립렛-센터 손실(TCL)**을 제안합니다. TCL은 각 클래스의 센터에 대한 클래스 내 거리를 최소화하고 다른 클래스 센터와의 클래스 간 거리를 최대화함으로써 판별적인 특징을 효율적으로 학습합니다. MVCNN 프레임워크 내에서 (종종 소프트맥스 손실과 함께) 적용된 TCL은 기존 트립렛 손실의 계산 오버헤드 없이 다양한 3D 객체 및 스케치 기반 3D 형상 검색 벤치마크에서 최첨단 성능을 달성하여 우수한 판별 특징 학습 능력을 입증했습니다.
