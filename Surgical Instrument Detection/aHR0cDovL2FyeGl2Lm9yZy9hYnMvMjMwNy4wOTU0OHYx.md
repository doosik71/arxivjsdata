# SURGICAL ACTION TRIPLET DETECTION BY MIXED SUPERVISED LEARNING OF INSTRUMENT-TISSUE INTERACTIONS

Saurav Sharma, Chinedu Innocent Nwoye, Didier Mutter, Nicolas Padoy

## 🧩 해결하고자 하는 문제

수술 행동 트리플렛(surgical action triplets)은 `<instrument, verb, target>` 조합으로 수술 도구-조직 상호작용을 상세하게 설명하며, 수술 장면 활동 및 워크플로우 분석을 지원합니다. 이 연구는 수술 행동 트리플렛 검출에 중점을 둡니다. 이는 전통적인 트리플렛 인식(recognition) 작업보다 훨씬 정밀하지만, 다음과 같은 도전 과제가 있습니다:

- 수술 도구의 위치 파악과 각 도구에 연결된 수술 행동 트리플렛의 인식이 동시에 요구됩니다.
- 공간 트리플렛 주석(spatial triplet annotation)의 부족으로 인해 복잡성이 매우 높습니다.
- 정확한 도구 위치 파악만으로는 동사(verb) 및 대상(target)과의 잘못된 연결 위험 때문에 더 나은 트리플렛 검출을 보장하지 못합니다.

## ✨ 주요 기여

- **MCIT-IG 네트워크 제안**: 수술 행동 트리플렛 검출을 위한 2단계 네트워크인 Multi-Class Instrument-aware Transformer - Interaction Graph (MCIT-IG)를 제안합니다.
- **MCIT 스테이지**: MCIT는 도구-인식 대상 클래스 임베딩(instrument-aware target class embeddings)을 학습하여 트리플렛 오인식 위험을 줄입니다.
- **IG 스테이지**: IG는 이분 동적 그래프(bipartite dynamic graph)를 구축하여 도구와 대상 간의 상호작용을 동사로 모델링합니다.
- **혼합 감독 학습 전략**: MCIT 학습을 위해 약한 대상 존재 레이블(weak target presence labels)을 사용하고, IG 학습을 위해 의사 트리플렛 레이블(pseudo triplet labels)을 사용하여 네트워크를 훈련합니다.
- **성능 향상**: 최소한의 도구 공간 주석에 대상 임베딩을 보완함으로써 더 나은 트리플렛 검출 성능을 달성함을 입증했습니다.
- **최고 성능 달성**: CholecT50 데이터셋에서 도구 위치 파악 및 트리플렛 검출 모두에서 향상된 성능을 보이며 MICCAI 2022 CholecTriplet 챌린지 리더보드에서 1위를 차지했습니다.

## 📎 관련 연구

- **수술 워크플로우 분석**: 내시경 수술 데이터 분석을 통해 문맥 인식 시스템을 구축하고 의사 결정 및 계획을 지원하는 기존 연구들이 있습니다.
- **조대-세분화 인식**: 수술 단계 인식, 도구 공간 위치 파악, 기술 평가 등 조대(coarse-grained) 인식 작업에 중점을 둔 시스템들이 많습니다.
- **수술 행동 트리플렛 도입**: `<instrument, verb, target>`과 같은 수술 행동 트리플렛은 내시경 장면 요소의 세분화된(fine-grained) 모델링을 도입했습니다.
- **기존 트리플렛 인식 연구**: 기존 접근 방식들은 공간 위치 정보 없이 트리플렛의 존재 여부만 예측하는 트리플렛 인식(recognition) 작업에 주로 초점을 맞췄습니다.
- **CholecTriplet 챌린지**: 최근 CholecTriplet 챌린지 [13]는 도구 위치 파악 및 트리플렛과의 연관성을 요구하는 트리플렛 검출(detection) 작업을 도입했습니다. 이전 챌린지에서는 CAM 기반의 약한 감독 방식이 정밀도 저하를 겪었습니다.

## 🛠️ 방법론

MCIT-IG는 완전히 미분 가능한(fully differentiable) 2단계 파이프라인으로 구성됩니다.

1. **백본 및 도구 검출**:
    - 시각적 특징 추출을 위해 ResNet50 [17]을 백본으로 사용합니다.
    - MMDetection [16] 프레임워크 기반의 Deformable DETR [14]를 사용하여 도구 바운딩 박스를 얻습니다.
    - ResNet50 특징과 도구 바운딩 박스 좌표 및 예측된 도구 클래스 임베딩을 융합하여 최종 도구 특징 $F_i$를 생성합니다.
2. **MCIT (Multi-Class Instrument-aware Transformer)** - 도구-인식 대상 클래스 임베딩 학습:
    - 표준 트랜스포머의 단일 클래스 불가지 토큰(class-agnostic token)의 한계를 극복하기 위해 $N$개의 클래스 토큰 $N_t \in R^{N \times d}$를 사용하여 각 대상 클래스에 대한 임베딩을 학습합니다.
    - 도구 특징 $F_i$를 사용하여 클래스 임베딩이 장면 내 도구를 인식하도록 만듭니다.
    - MCIT는 약한 감독으로 대상 이진 존재 레이블(binary presence labels)을 사용하여 학습됩니다.
3. **IG (Interaction Graph)** - 도구-대상 상호작용 학습:
    - 도구 인스턴스 특징 $F_i$와 대상 클래스 임베딩 $N_t$를 사용하여 단방향 완전 이분 그래프(unidirectional complete bipartite graph) $G=(U,V,E)$를 생성합니다. 여기서 $U$는 도구, $V$는 대상입니다.
    - GAT [20]를 사용하여 메시지 전달(message passing)을 적용하여 도구 특징을 집계하고 대상 클래스 임베딩을 업데이트합니다.
    - 모든 엣지 $E$의 소스 및 대상 노드 특징을 연결하여 엣지 특징 $E_f$를 구성합니다.
    - 엣지 특징에 선형 계층 $\Phi_e$를 적용하여 엣지 신뢰도 점수 $E_s$를 계산하고, 임계값을 통해 활성 엣지(interaction이 있는 엣지)를 식별합니다.
    - 활성 엣지에 선형 계층 $\Phi_v$를 적용하여 동사 로짓(verb logits) $y_v \in R^{V+1}$를 생성합니다.
4. **트리플렛 검출**:
    - 각 도구 인스턴스에 대해 활성 엣지 중 가장 높은 신뢰도를 가진 엣지를 선택하여 대상 클래스를 결정합니다.
    - 선택된 엣지의 동사 로짓에 소프트맥스를 적용하여 동사 클래스를 얻습니다.
    - 최종 트리플렛 `<i, k, j>`의 점수는 대상 엣지의 확률과 동사 확률의 곱으로 계산됩니다.
5. **혼합 감독 학습**:
    - **1단계(MCIT)**: 대상 로짓 $y_t$에 가중치 이진 교차 엔트로피 손실(weighted binary cross entropy loss) $L_t$를 적용하여 대상 이진 존재 레이블로 학습합니다.
    - **2단계(IG)**: 각 검출된 도구 인스턴스에 대해 의사 트리플렛 레이블을 생성합니다. 엣지 세트 $E_i^s$에 대한 범주형 교차 엔트로피 손실 $L_e^G$와 동사 로짓 $y_{e'v}$에 대한 $L_v^G$를 적용합니다.
    - 최종 손실은 $L = L_t + \alpha \times L_e^G + \beta \times L_v^G$ 입니다.

## 📊 결과

- **베이스라인 비교**: RDV (Rendezvous) [10] 베이스라인 대비 MCIT 모델은 도구-인식 대상 특징을 활용하여 더 나은 도구-대상 상호작용 의미론을 포착했습니다. IG를 추가함으로써 트리플렛 검출 성능이 +0.89 mAP 증가 (베이스라인 대비 13.8% 향상)했습니다.
- **공간 주석의 필요성 분석**: 도구 위치 파악 mAP가 증가함에 따라 트리플렛 검출 mAP도 증가하는 경향을 보였습니다. MCIT-IG는 제한된 바운딩 박스 인스턴스에서도 다른 약한 감독 방식들을 능가하며, 더 적은 프레임으로 ResNet-CAM-YOLOv5보다 +1.42 mAP 높은 성능을 보였습니다.
- **MCIT-IG 구성 요소 분석**: ROI 및 박스 특징을 모두 사용하는 것이 트리플렛 검출 성능에 가장 유리하며, 도구 인식이 없는 대상 클래스 임베딩은 트리플렛과의 연관성을 포착하는 능력을 저해했습니다. 메시지 전달(message passing)은 IG에서 상호작용하는 쌍을 구별하는 데 필수적임을 확인했습니다.
- **최신 기술(SOTA) 비교**: CholecTriplet 2022 챌린지 [13]의 모든 기존 방법론을 능가하여 도구 위치 파악 및 트리플렛 검출의 모든 평가 지표에서 가장 높은 점수를 달성했습니다.

## 🧠 통찰 및 논의

- **정밀한 도구 검출의 중요성**: 이 연구는 정밀한 도구 검출이 더 많은 도구 인스턴스를 드러내어 추가적인 도구-대상 상호작용을 포착하게 함으로써 트리플렛 검출 성능 향상과 직접적인 연관이 있음을 보여주었습니다.
- **도구-인식 대상 임베딩의 효과**: MCIT를 통해 학습된 도구-인식 대상 클래스 임베딩은 대상 인스턴스 레이블이 없는 상황에서도 시각적 및 위치 의미론이 풍부한 대상 특징을 학습하는 데 효과적입니다.
- **그래프 기반 동적 연결의 강점**: IG의 그래프 기반 동적 연결은 도구 인스턴스와 대상/동사 간의 정확한 연관성을 포착하는 데 탁월하며, 복잡한 다중 인스턴스 및 다중 상호작용 시나리오에서 오인식 위험을 줄입니다.
- **혼합 감독 학습의 실용성**: 제한된 공간 주석 문제를 해결하기 위해 약한 감독과 의사 레이블 생성을 결합한 혼합 감독 전략은 실제 수술 데이터셋의 주석 비용 문제를 완화할 수 있는 실용적인 방법입니다.
- **제한점 및 시사점**: 본 연구는 CholecT50 데이터셋에서 우수한 성능을 보였지만, 다른 수술 유형이나 더 다양한 시나리오에 대한 일반화 가능성은 추가 연구가 필요할 수 있습니다. 수술 데이터 과학 분야에서 세분화된 상호작용 분석을 위한 강력한 기반을 제공합니다.

## 📌 TL;DR

본 논문은 수술 장면에서 `<instrument, verb, target>` 형태의 행동 트리플렛을 검출하는 **MCIT-IG**라는 2단계 딥러닝 파이프라인을 제안합니다. 주요 문제는 도구 위치 파악과 트리플렛 인식을 동시에 수행해야 하며, 공간 트리플렛 주석이 부족하다는 점입니다. 제안된 방법은 **MCIT** (Multi-Class Instrument-aware Transformer)를 통해 도구-인식 대상 클래스 임베딩을 학습하고, **IG** (Interaction Graph)를 통해 도구와 대상 간의 상호작용을 동적 그래프로 모델링하여 동사를 학습합니다. 약한 대상 존재 레이블과 의사 트리플렛 레이블을 활용하는 **혼합 감독 학습** 전략을 사용합니다. CholecT50 데이터셋에서 도구 위치 파악 및 트리플렛 검출 모두에서 최신 방법론을 능가하며 MICCAI 2022 챌린지에서 1위를 차지하여, 정밀한 도구 검출과 그래프 기반 동적 상호작용 모델링이 수술 행동 트리플렛 검출에 효과적임을 입증했습니다.
