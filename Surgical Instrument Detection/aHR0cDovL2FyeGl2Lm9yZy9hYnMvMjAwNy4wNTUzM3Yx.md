# ISINet: An Instance-Based Approach for Surgical Instrument Segmentation

Cristina Gonz ́alez, Laura Bravo-S ́anchez, and Pablo Arbelaez

## 🧩 Problem to Solve

이 논문은 로봇 보조 수술 장면에서 수술 도구의 의미론적 분할, 특히 도구 유형을 정밀하게 식별하는 문제를 다룹니다. 기존 픽셀 단위 의미론적 분할 방법들은 다음과 같은 한계를 가집니다:

* **공간적 레이블 일관성 부족:** 하나의 도구에 여러 도구 유형이 할당되는 등 객체 내에서 클래스 레이블의 공간적 일관성이 부족합니다.
* **시간적 레이블 일관성 부족:** 이전 프레임의 분할 레이블을 고려하지 않고 프레임별로 독립적으로 예측하여 시간에 따른 도구의 레이블 일관성을 유지하기 어렵습니다.
* **주석 데이터 부족:** 정밀한 도구 유형 분할을 위한 주석된 데이터가 상대적으로 부족합니다.

## ✨ Key Contributions

* **ISINet 제안:** 수술 도구 분할을 위한 인스턴스 기반 방법인 ISINet(Instance-based Surgical Instrument Segmentation Network)을 제시합니다.
* **새로운 시간적 일관성 모듈:** 데이터의 순차적 특성을 활용하여 도구 인스턴스의 클래스 예측 정확도를 높이는 새로운 시간적 일관성 모듈을 제안합니다.
* **추가 데이터 제공 및 필요성 입증:** 도구 분할 연구를 위한 EndoVis 2018 데이터셋에 대한 추가 도구 유형 주석을 제공하고, 이러한 추가 데이터가 알고리즘 성능에 미치는 긍정적인 영향을 경험적으로 입증합니다.

## 📎 Related Works

* **초기 데이터셋:** Endoscopic Vision 2015 [3]는 도구 분할 및 추적을 위한 최초의 데이터셋이었으나, 주석 품질 및 배경 변화의 제한이 있었습니다.
* **EndoVis 2017:** 2015년 데이터셋의 단점을 개선하여 도구 유형 및 부위 주석을 포함했으나, 데이터 양, 비현실적인 수술 내용, 드문 샘플링으로 인해 시간적 일관성 분석에 한계가 있었습니다 [2].
* **EndoVis 2018:** 해부학적 객체와 실제 수술 장면을 포함하여 배경의 다양성을 높였지만, 도구 클래스를 일반적인 'instrument'로 단순화하여 정밀한 도구 유형 분할 작업에는 직접 사용할 수 없었습니다 [1]. (본 논문에서 2018 데이터셋에 대한 도구 유형 주석을 확장했습니다.)
* **기존 방법론:** 대부분의 기존 최첨단 방법 [2,10,4,28,15]은 U-Net [26] 및 FCN [22]을 기반으로 한 픽셀 단위 의미론적 분할 패러다임을 따랐습니다. 이들은 경계 [9], 깊이 [24], 후처리 [8], 돌출 지도 [14], 자세 추정 [19] 등을 사용하여 개선을 시도했지만, 공간적 레이블 일관성 문제를 해결하지 못했습니다.
* **인스턴스 기반 접근법:** [18]은 산부인과 도구에 대해 인스턴스 기반 분할을 시도했지만, 비공개 데이터셋에 대한 연구였습니다.
* **시간적 정보 활용:** MF-TAPNet [15]은 광학 흐름을 이용한 시간적 우선순위를 포함한 최초의 방법입니다. 다른 시간적 단서 활용 방법들은 주로 도구 추적 [31,32,5,17]에 중점을 두었으며, [27]은 분할 개선 또는 데이터 증강에 시간 정보를 사용했습니다.

## 🛠️ Methodology

ISINet은 인스턴스 기반 수술 도구 분할을 위해 Mask R-CNN [11]을 기반으로 하며, 이 아키텍처를 도구 유형 클래스에 맞게 수정하고 시간적 일관성 모듈을 추가합니다. 시간적 일관성 모듈은 다음 두 단계로 구성됩니다.

1. **매칭 단계 (Matching Step):**
    * **후보 객체 추출:** Mask R-CNN($M$)을 사용하여 이미지 시퀀스 $I$의 각 프레임 $t$에서 스코어 $S_{i,t}$, 객체 후보 $O_{i,t}$, 클래스 예측 $C_{i,t}$를 얻습니다.
        $$ (\{S_{i,t}\}_{i=1}^{n})_{t=1}^{T}, (\{O_{i,t}\}_{i=1}^{n})_{t=1}^{T}, (\{C_{i,t}\}_{i=1}^{n})_{t=1}^{T}) = M(\{I_t\}_{t=1}^{T}) $$
    * **광학 흐름 계산:** FlowNet2($F$) [13]를 사용하여 연속된 프레임 ($I_t$, $I_{t-1}$) 사이의 역방향 광학 흐름 $OF_{t \to t-1}$을 계산합니다.
    * **워핑 및 매칭:** 이전 $f$개 프레임의 후보 객체들을 광학 흐름을 이용하여 현재 프레임 $t$로 워핑($\text{Warp}$)합니다.
        $$ \hat{O}_{i,t-1} = \text{Warp}_{t-1 \to t}(O_{i,t-1}, OF_{t \to t-1}) $$
    * 워핑된 객체 후보들과 현재 프레임의 후보들 간의 IoU(Intersection over Union)를 기반으로 상호 매칭을 찾아 하나의 도구 인스턴스를 시간에 걸쳐 추적합니다. IoU가 임계값 $U$보다 큰 경우에만 매칭으로 간주합니다.

2. **할당 단계 (Assignment Step):**
    * 매칭 단계를 통해 추적된 각 인스턴스 $k$에 대해, 이전 $f$개 프레임의 클래스 예측 $C_{k,t-f}, \dots, C_{k,t}$ 및 해당 스코어 $S_{k,t-f}, \dots, S_{k,t}$를 고려하여 현재 프레임 $t$의 최종 클래스 예측을 업데이트합니다.
    * $A$ 함수는 입력 클래스들을 스코어에 따라 가중치를 부여한 최빈값(mode)으로 정의합니다.
        $$ C_{k,t} = A([C_{k,t-f}, \dots, C_{k,t}],[S_{k,t-f}, \dots, S_{k,t}]) $$
    * 최종 구현에서는 $f=6$으로 설정하고, $U$는 2017 데이터셋에 대해 0, 2018 데이터셋에 대해 0.5로 설정합니다.

## 📊 Results

* **SOTA 대비 우수성:** ISINet의 기준 모델(시간적 일관성 모듈 및 추가 데이터 미사용)은 EndoVis 2017 및 2018 데이터셋 모두에서 TernausNet [28] 및 MF-TAPNet [15]과 같은 기존 SOTA 픽셀 기반 분할 방법보다 모든 전반적인 IoU 지표에서 뛰어난 성능을 보였습니다. 특히, 이전 방법들의 IoU를 **두 배 또는 세 배까지 향상**시켰습니다. 일부 도구 클래스에서는 IoU가 30.0% 이상 개선되었습니다.
* **추가 데이터의 효과:** EndoVis 2018 데이터셋에 대한 추가 도구 유형 주석(총 15개 시퀀스, 각 149프레임)을 통해 데이터를 증강한 결과, 단일 데이터셋으로 훈련했을 때보다 더 나은 성능을 달성했습니다. 두 데이터셋 모두에서 여러 클래스에서 최대 20.0 IoU 포인트 증가를 보였으며, 이는 이 과제를 해결하는 데 **추가 데이터가 필수적**임을 확인시켜 줍니다.
* **시간적 일관성 모듈의 효과:** 시간적 일관성 모듈은 추가 데이터 사용 여부와 관계없이 두 데이터셋 모두에서 전반적인 지표를 향상시켰습니다. Ultrasound Probe를 제외한 모든 클래스에서 이상치 예측(outlier predictions)을 수정했으며, 2017 데이터셋에서는 일부 클래스에서 거의 8% 포인트 증가를 가져왔습니다. 2018 데이터셋에서는 전반적인 이득이 있었으나, 2017 데이터셋에 비해 증가 폭이 적었습니다.

## 🧠 Insights & Discussion

* **인스턴스 기반 접근법의 성공:** 픽셀 단위 분할의 고질적인 문제였던 객체 내 레이블 불일치 문제를 인스턴스 기반 분할을 통해 성공적으로 해결하여, 수술 도구 분할의 정확도를 크게 향상시킬 수 있음을 입증했습니다.
* **시간적 정보의 가치:** 수술 영상의 순차적 특성을 활용한 시간적 일관성 모듈은 도구 인스턴스의 예측 정확도를 높이고, 시간에 따른 객체의 일관성을 유지하는 데 중요한 역할을 합니다. 이는 비디오 데이터 처리에서 시간 정보를 통합하는 것이 중요함을 보여줍니다.
* **데이터의 중요성:** 정밀한 도구 유형 분할과 같은 의료 영상 처리에서 고품질의 주석 데이터가 얼마나 중요한지 다시 한번 확인했습니다. EndoVis 2018 데이터셋에 대한 추가 주석은 이 분야의 발전을 위한 귀중한 자원이 될 것입니다.
* **한계점:** ISINet의 주요 오류 모드로는 도구 누락, 잘못된 도구 레이블링, 그리고 거친 분할(coarse segmentations)이 있습니다. 특히 2018 데이터셋과 같이 변동성이 높은 환경에서는 시간적 일관성 모듈의 효과가 상대적으로 제한될 수 있음을 시사합니다. 향후 연구에서는 이러한 오류 모드를 줄이고 모델의 강건성을 높이는 데 초점을 맞출 수 있습니다.

## 📌 TL;DR

이 논문은 로봇 보조 수술 장면에서 수술 도구의 정밀한 유형 분할 문제를 해결하기 위해 인스턴스 기반 분할 네트워크인 ISINet을 제안합니다. ISINet은 Mask R-CNN을 기반으로 하며, 영상 시퀀스의 시간적 정보를 활용하여 도구 인스턴스의 클래스 예측 일관성을 높이는 독창적인 모듈을 포함합니다. EndoVis 2017 및 2018 데이터셋에 대한 실험 결과, ISINet은 기존 픽셀 기반 최첨단 방법들보다 IoU 성능을 최대 3배까지 크게 향상시켰습니다. 추가 주석 데이터가 모델 일반화에 중요하며, 제안된 시간적 일관성 모듈이 예측 정확도를 더욱 높임을 입증했습니다.
