# Learning Motion Flows for Semi-supervised Instrument Segmentation from Robotic Surgical Video

Zixu Zhao, Yueming Jin, Xiaojie Gao, Qi Dou, and Pheng-Ann Heng

## 🧩 Problem to Solve

로봇 수술 영상에서 수술 도구를 분할하는 것은 로봇 보조 최소 침습 수술에서 중요한 역할을 하지만, 고주파수 영상의 픽셀 단위 주석은 막대한 비용과 노동력을 필요로 합니다. 기존의 준지도(semi-supervised) 방법들은 레이블이 없는 프레임을 개별적으로 처리하여 수술 영상의 본질적인 시간적(temporal) 특성을 제대로 활용하지 못했습니다. 또한, 일부 광학 흐름(optical flow) 기반 방법은 부정확한 흐름 추정으로 인해 신뢰할 수 없는 준지도를 제공하는 한계가 있었습니다. 이 연구는 희소하게 주석이 달린 수술 영상에서 효율적인 준지도 수술 도구 분할을 달성하고 시간적 일관성을 활용하는 방법을 목표로 합니다.

## ✨ Key Contributions

* **듀얼 모션 기반 프레임워크 제안**: 희소한 주석이 달린 수술 영상의 내재된 시퀀스 정보를 활용하여 준지도 도구 분할을 위한 듀얼 모션 기반 프레임워크를 제안합니다.
* **플로우 예측기 설계**: 비디오 재구성 태스크를 통해 두 프레임 간의 모션 플로우를 학습하는 플로우 예측기(flow predictor)를 설계하고, 오정렬 문제를 완화하기 위해 프레임-레이블 쌍을 공동으로 전파하는 전략을 도입합니다.
* **플로우 보상기 및 비지도 사이클 학습**: 빠른 도구 모션을 보상하고 중간 모션 플로우를 학습하기 위해 프레임 보간 태스크를 사용하는 플로우 보상기(flow compensator)를 도입하며, 비지도 사이클 학습(unsupervised cycle learning) 전략을 통해 모델을 최적화합니다.
* **시간적 일관성 복구 및 향상**: 생성된 데이터 쌍을 활용하여 훈련 시퀀스의 시간적 일관성을 복구하고 강화하여 분할 성능을 향상시킵니다.
* **최신 기술 대비 우월한 성능**: MICCAI EndoVis 2017 데이터셋에서 최신 준지도 방법들을 크게 능가하며, 특정 태스크에서는 완전 지도(fully supervised) 훈련 성능까지 초과 달성합니다.

## 📎 Related Works

* **CNN 기반 수술 도구 분할**: 효과적인 데이터 기반 학습 덕분에 수술 도구 분할에서 최신 성능을 달성한 CNN 기반 방법들 [7,13,21,10].
* **추가 신호 활용**: 로봇 운동학 모델 [3,16], 객체 스트라이프 및 골격의 약한 주석 [6], 시뮬레이션된 수술 장면 [15]과 같은 추가 신호를 사용하여 마스크를 생성하는 연구들.
* **의료 영상 분석을 위한 준지도 학습**: 대규모 레이블 없는 데이터를 활용하여 분할 성능을 개선하려는 노력 (예: 심장 분할을 위한 자기 훈련 전략 [2], 3D 좌심방 분할을 위한 불확실성 인식 평균 교사 프레임워크 [23]). 복강경 영상의 일관성 손실을 계산하여 적용된 평균 교사 프레임워크 [5], 개별 레이블 없는 내시경 프레임에 GAN 기반 재색상화를 사용하여 모델 사전 훈련 [20].
* **시간적 일관성 활용**: 수술 비디오의 시간적 일관성을 활용하여 준지도 분할에 도움이 되는 접근법 [10].

## 🛠️ Methodology

제안된 프레임워크는 원본 주석 분포를 복구하는 플로우 예측 브랜치와 빠른 도구 모션을 보상하는 플로우 보상 브랜치, 두 가지 모션 플로우를 학습합니다.

1. **플로우 예측을 위한 공동 전파 (Flow Prediction for Joint Propagation)**:
    * **모션 플로우 추정**: 현재 프레임 $I_t$와 다음 프레임 $I_{t+1}$ 사이의 모션 플로우 $\hat{F}_{t \to t+1}$을 예측합니다. $G$는 2D CNN 기반 플로우 예측기이며, FlowNet2.0 [8]을 사용하여 연속적인 프레임 간의 광학 흐름을 계산합니다.
        $$ \hat{F}_{t \to t+1} = G(I_{t:t+1}, F_{t+1:t+1}) $$
    * **프레임 및 레이블 전파**: 학습된 플로우 $\hat{F}_{t \to t+1}$를 사용하여 $I_t$에서 미래 프레임 $\hat{I}_{t+1}$을 합성하고 $L_t$에서 레이블 $\hat{L}_{t+1}$을 전파합니다. $T$는 bilinear interpolation [25]을 통해 구현된 워핑 함수입니다.
        $$ \hat{I}_{t+1} = T(I_t, \hat{F}_{t \to t+1}), \quad \hat{L}_{t+1} = T(L_t, \hat{F}_{t \to t+1}) $$
    * **공동 전파 전략**: 예측된 프레임 $\hat{I}_{t+1}$과 전파된 레이블 $\hat{L}_{t+1}$을 $(\hat{I}_{t+1}, \hat{L}_{t+1})$ 쌍으로 묶어, 원본 프레임 $I_{t+1}$과 전파된 레이블 $\hat{L}_{t+1}$을 직접 묶을 때 발생할 수 있는 오정렬 문제를 방지합니다. 다단계 전파 ($k=1,2,4$)를 통해 희소한 주석에서 누적 오류를 완화합니다.
    * **손실 함수**: L1 손실 $L_1$, 구조적 세부 사항을 유지하는 지각 손실(perceptual loss) $L_p$ [11], 인접 픽셀의 유사한 흐름 값을 장려하는 스무스 손실(smooth loss) $L_s$ [9]로 구성됩니다.
        $$ L_{\text{Pred}} = \lambda_1 L_1 + \lambda_p L_p + \lambda_s L_s $$

2. **비지도 사이클 학습을 통한 플로우 보상 (Flow Compensation via Unsupervised Cycle Learning)**:
    * **중간 플로우 학습**: 연속적인 두 프레임 $I_0$와 $I_1$ 사이의 중간 모션 플로우 $\hat{F}_{0 \to i}$를 학습하여 중간 프레임-레이블 쌍 $(\hat{I}_i, \hat{L}_i)$을 공동으로 전파하는 것을 목표로 합니다.
    * **초기 플로우 근사**: FlowNet2.0으로 양방향 광학 흐름 $(F_{0 \to 1}, F_{1 \to 0})$을 계산하고 이를 사용하여 중간 광학 흐름을 근사합니다.
    * **플로우 보상기**: 5단계 U-Net 기반 플로우 보상기가 두 프레임, 4개의 초기 근사 흐름, 4개의 워핑된 프레임을 입력으로 받아 4개의 정제된 흐름 $\hat{F}$를 출력합니다. 이 중 $\hat{F}_{0 \to i}$는 공동 프레임-레이블 쌍 생성에 사용됩니다.
    * **비지도 사이클 손실**: 시간 도메인에서 모델이 사이클 일관성(cycle consistency)을 만족하도록 모션 플로우를 학습합니다. 예측된 $\hat{I}_1$이 $I_1$과, 재구성된 $\hat{I}_0$이 $I_0$과 잘 겹치고, 두 중간 프레임 $\hat{I}_i^0$과 $\hat{I}_i^1$이 유사하도록 L1 손실과 지각 손실을 적용합니다.
        $$ L_{\text{cycle}} = L_{c1} + \lambda_p L_{cp}, \quad L_{c1} = \lambda_0 \Vert \hat{I}_0 - I_0 \Vert_1 + \lambda_i \Vert \hat{I}_i^0 - \hat{I}_i^1 \Vert_1 + \lambda_1 \Vert \hat{I}_1 - I_1 \Vert_1 $$

3. **준지도 분할 (Semi-supervised Segmentation)**:
    * 레이블이 있는 데이터셋 $D_L$, 플로우 예측을 통해 생성된 재-레이블 데이터셋 $D_R$, 플로우 보상을 통해 생성된 보상 데이터셋 $D_C$를 모두 사용하여 준지도 분할 모델을 훈련합니다.
    * 네트워크 아키텍처는 VGG11 [22]에서 사전 훈련된 인코더를 가진 U-Net11 [19] 백본을 사용하며, 시간적 일관성을 높이기 위해 병목 구간에 ConvLSTM 레이어를 추가할 수 있습니다.

## 📊 Results

* **데이터셋**: 2017 MICCAI EndoVis 챌린지의 로봇 수술 도구 분할 공개 데이터셋에서 이진(binary), 부분(part), 유형(type) 분할 세 가지 서브 태스크에 대해 검증되었습니다.
* **성능 우위**: 20% 프레임 주석 설정에서 제안된 방법(`Our Dual MF`)은 IoU 및 Dice 계수에서 Self-training [2], Re-color [20], MF-TAPNet [10], UA-MT [23]를 포함한 모든 최신 준지도 방법들을 크게 능가했습니다 (예: UA-MT보다 평균 IoU 2.68%, Dice 2.24% 향상).
* **완전 지도 능가**: ConvLSTM을 추가한 `Our Dual MF*` 버전은 이진 태스크에서 완전 지도 U-Net11*보다 0.91% Dice, 유형 태스크에서 3.23% Dice를 능가하여, 완전 지도 훈련보다 더 나은 결과를 보여주었습니다.
* **어노테이션 비율에 따른 분석**: 30%, 20%, 10%의 주석 비율에서도 제안된 플로우 기반 프레임워크는 레이블링된 데이터 $D_L$만으로 훈련된 U-Net11에 비해 점진적으로 준지도 성능을 향상시켰습니다. 특히 10% 레이블링의 가장 어려운 조건에서 `Our Single MF`는 이진 태스크에서 IoU 6.12%, Dice 4.14%를 크게 개선했습니다.
* **시간적 일관성 강화**: `Our Dual MF`와 `Our Dual MF*` 간의 성능 향상은 특히 가장 어려운 유형 분할에서 두드러졌습니다 (예: 20% 레이블링 경우 IoU 6.65%, Dice 6.25% 증가). 이는 제안된 방법이 원본 비디오의 모션 불일치를 복구하고 조정하여 모델의 시간적 단서 학습 능력을 향상시킴을 보여줍니다.
* **시각적 결과**: `Our Dual MF*`는 이진 및 부분 태스크에서 초음파 탐침의 오분류된 영역을 크게 억제하고, 더 완전하고 일관된 유형 분할을 달성합니다.

## 🧠 Insights & Discussion

* **시간적 역동성의 효과적인 활용**: 본 연구는 수술 영상의 희소한 주석 문제에 대한 새로운 관점을 제시하며, 모션 플로우 학습을 통해 시간적 역동성을 효과적으로 활용하는 방법을 제안합니다. 이는 기존의 개별 프레임 기반 준지도 방법론의 한계를 극복합니다.
* **어노테이션 부담 경감**: 낮은 주석 빈도(예: 10%만 레이블링)에서도 우수한 성능을 달성함으로써, 수술 영상의 고비용/고노동력 어노테이션 부담을 크게 줄일 수 있는 실용적인 가치를 제공합니다.
* **데이터 증강 효과**: 플로우 예측을 통한 공동 전파와 플로우 보상을 통한 중간 프레임 생성은 효과적인 데이터 증강(data augmentation) 전략으로 작용하여, 모델이 더욱 견고하게 학습하고 시간적 일관성을 유지하도록 돕습니다.
* **완전 지도 학습 능가**: ConvLSTM과 같은 시간적 유닛과 결합했을 때, 일부 태스크에서 완전 지도 학습을 능가하는 결과는 제안된 방법이 단순히 레이블 없는 데이터를 활용하는 것을 넘어, 영상의 본질적인 동적 특성을 학습하여 모델의 일반화 능력을 향상시킬 수 있음을 시사합니다.
* **한계**: 논문에서 명시적인 한계를 언급하지는 않았으나, FlowNet2.0과 같은 외부 모델에 대한 의존성과 모션 플로우 학습의 정확도에 대한 민감성은 잠재적인 고려사항이 될 수 있습니다.

## 📌 TL;DR

이 논문은 희소한 주석이 달린 로봇 수술 영상에서 수술 도구 분할을 위한 **듀얼 모션 기반 준지도 프레임워크**를 제안합니다. **플로우 예측기**를 통해 레이블링된 프레임에서 모션 플로우를 학습하고, 오정렬을 피하기 위해 프레임과 레이블을 공동으로 전파합니다. 또한, **플로우 보상기**와 **비지도 사이클 학습 전략**을 사용하여 연속 프레임 간의 중간 모션을 추정하고 보상하여 시간적 일관성을 강화합니다. 제안된 방법은 MICCAI EndoVis 2017 데이터셋에서 기존의 최신 준지도 방법들을 크게 능가하며, 특정 태스크에서는 **완전 지도 훈련보다 더 나은 성능**을 달성하여 수술 영상 분석의 어노테이션 부담을 획기적으로 줄일 수 있음을 입증했습니다.
