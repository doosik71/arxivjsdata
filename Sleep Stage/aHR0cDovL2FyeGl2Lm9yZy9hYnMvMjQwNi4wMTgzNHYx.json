{
  "title": "Multi-Task Learning for Arousal and Sleep Stage Detection Using Fully\n  Convolutional Networks",
  "authors": "Hasan Zan, Abdulnasir Yildiz",
  "year": 2024,
  "url": "http://arxiv.org/abs/2406.01834v1",
  "abstract": "Objective. Sleep is a critical physiological process that plays a vital role\nin maintaining physical and mental health. Accurate detection of arousals and\nsleep stages is essential for the diagnosis of sleep disorders, as frequent and\nexcessive occurrences of arousals disrupt sleep stage patterns and lead to poor\nsleep quality, negatively impacting physical and mental health. Polysomnography\nis a traditional method for arousal and sleep stage detection that is\ntime-consuming and prone to high variability among experts. Approach. In this\npaper, we propose a novel multi-task learning approach for arousal and sleep\nstage detection using fully convolutional neural networks. Our model,\nFullSleepNet, accepts a full-night single-channel EEG signal as input and\nproduces segmentation masks for arousal and sleep stage labels. FullSleepNet\ncomprises four modules: a convolutional module to extract local features, a\nrecurrent module to capture long-range dependencies, an attention mechanism to\nfocus on relevant parts of the input, and a segmentation module to output final\npredictions. Main results. By unifying the two interrelated tasks as\nsegmentation problems and employing a multi-task learning approach,\nFullSleepNet achieves state-of-the-art performance for arousal detection with\nan area under the precision-recall curve of 0.70 on Sleep Heart Health Study\nand Multi-Ethnic Study of Atherosclerosis datasets. For sleep stage\nclassification, FullSleepNet obtains comparable performance on both datasets,\nachieving an accuracy of 0.88 on the former and an accuracy of 0.83 on the\nlatter. Significance. Our results demonstrate that FullSleepNet offers improved\npracticality, efficiency, and accuracy for the detection of arousal and\nclassification of sleep stages using raw EEG signals as input.",
  "citation": 14
}