# SeqSleepNet: End-to-End Hierarchical Recurrent Neural Network for Sequence-to-Sequence Automatic Sleep Staging

Huy Phan, Fernando Andreotti, Navin Cooray, Oliver Y. Ch ́en, and Maarten De Vos

## 🧩 Problem to Solve

수면 단계 분류는 수면 장애 진단에 필수적이지만, 수작업은 노동 집약적이고 시간이 많이 소요되며 오류 발생 가능성이 높습니다. 기존의 자동 수면 단계 분류 방법들은 주로 개별 에포크(30초 단위의 PSG 데이터)를 분류하는 `one-to-one`, 주변 에포크를 포함하는 `many-to-one`, 또는 단일 에포크로 여러 에포크의 레이블을 예측하는 `one-to-many` 방식으로 이루어졌습니다. 이러한 방법들은 장기적인 맥락(long context), 즉 수십 개의 에포크에 걸친 시퀀스 간의 의존성을 모델링하는 데 한계가 있으며, 모델링의 모호성 및 높은 계산 오버헤드와 같은 단점을 가집니다. 본 연구는 이러한 한계를 극복하고 수면 단계 분류 작업을 **시퀀스-투-시퀀스(sequence-to-sequence) 분류 문제**로 해결하여, 여러 에포크 시퀀스를 동시에 분류하는 것을 목표로 합니다.

## ✨ Key Contributions

- **종단 간 계층적 순환 신경망(End-to-End Hierarchical Recurrent Neural Network)인 SeqSleepNet 제안**: 여러 에포크 시퀀스를 입력으로 받아 모든 타겟 레이블 시퀀스를 한 번에 분류하는 `many-to-many` 접근 방식을 제시했습니다.
- **계층적 네트워크 아키텍처**:
  - **주파수 도메인 필터뱅크 계층**: 전처리 단계에서 주파수 도메인 필터를 학습하여 신호 특성에 맞는 주파수 대역을 강조하고 차원을 축소합니다.
  - **에포크 수준 주의 기반 양방향 RNN**: 단기(에포크 내) 시퀀스 모델링을 위해 주의(attention) 메커니즘이 결합된 양방향 RNN을 사용하여 각 에포크의 특징을 효과적으로 인코딩합니다.
  - **시퀀스 수준 양방향 RNN**: 에포크별 특징 시퀀스의 장기(에포크 간) 의존성을 모델링합니다.
- **종단 간 훈련(End-to-End Training) 전략**: 계층적 구조에도 불구하고 네트워크 전체를 한 번에 훈련하여 전역 최적해를 찾도록 합니다.
- **최첨단 성능 달성**: 공개된 200명의 피험자 데이터셋(MASS)에서 87.1%의 전체 정확도, 83.3%의 Macro F1-score, 0.815의 Cohen's kappa를 달성하여 기존 방법들을 능가했습니다. 특히 N1 및 REM 수면 단계 분류 성능을 크게 향상시켰습니다.

## 📎 Related Works

- **심층 학습(Deep Learning) 기반 접근법**: 기존의 특징 기반 기계 학습 방법을 대체하며, CNNs [8, 10, 11, 13-15], DBNs [22], Auto-encoder [23], DNNs, RNNs [24] 등이 수면 단계 분류에 활용되었습니다. DNN+RNN [25] 및 CNN+RNN [9, 12]과 같은 조합도 연구되었습니다.
- **기존 분류 스키마**:
  - **One-to-one**: 단일 PSG 에포크를 입력으로 받아 하나의 레이블을 생성합니다 [14, 15, 24, 26]. 에포크 간 의존성을 고려하지 못하는 한계가 있습니다.
  - **Many-to-one**: 주변 에포크를 `contextual input`으로 활용하여 타겟 에포크를 분류합니다 [9-11, 13, 23, 25, 29, 30]. `contextual input`의 모델링 모호성과 높은 계산 오버헤드가 단점입니다.
  - **One-to-many**: 단일 에포크를 입력으로 받아 `contextual output`으로 타겟 에포크와 주변 에포크의 레이블을 동시에 결정합니다 [8]. 다중 결정 앙상블이 가능하지만, `many-to-one`과 마찬가지로 긴 맥락을 처리하기 어렵습니다.
- **DeepSleepNet [9]**: CNN으로 에포크별 특징을 학습하고 Bi-RNN으로 단계 전환을 포착하는 모델로, 일반적으로 두 단계로 분리 훈련됩니다.
- **멀티태스크 네트워크 [8, 25]**: 여러 출력을 통해 결정 앙상블을 제공하지만, 장기 맥락을 수용하거나 종단 간 훈련하기 어려운 경우가 있었습니다.

## 🛠️ Methodology

SeqSleepNet은 계층적 RNN 구조로 설계되었으며, 다채널 PSG 데이터를 입력으로 받아 시퀀스-투-시퀀스 방식으로 수면 단계를 분류합니다.

1. **시계열-주파수 이미지 표현($S$**: 30초 PSG 에포크(EEG, EOG, EMG)를 단시간 푸리에 변환(STFT) 및 로그 스케일링을 통해 $F \times T \times C$ 차원의 로그-파워 스펙트럼 이미지로 변환합니다. 여기서 $F=129$ (주파수 빈), $T=29$ (시간 인덱스), $C=3$ (채널 수)입니다.

2. **필터뱅크 계층**:

   - $C$개의 채널별 필터뱅크 계층은 각 채널의 이미지 $S_c \in \mathbb{R}^{F \times T}$에 대해 주파수 도메인 필터뱅크를 학습합니다.
   - 필터는 비음수(non-negative), 대역 제한(band-limited), 주파수 순서(ordered in frequency) 특성을 가지도록 제약 조건을 적용합니다: $W^{c}_{fb} = f^{+}(W) \odot T$. 여기서 $f^{+}$는 시그모이드 함수, $T$는 선형-주파수 삼각 필터뱅크 행렬입니다.
   - 필터링 결과 $X_c \in \mathbb{R}^{M \times T}$ ($M < F$)를 얻고, 모든 채널의 $X_c$를 주파수 방향으로 연결하여 $MC \times T$ 크기의 단일 채널 이미지 $X$를 생성합니다.

3. **에포크 수준(단기) 시퀀스 모델링**:

   - 필터뱅크 계층을 통과한 이미지 $X$를 $T$개의 특징 벡터 시퀀스 $X \equiv (x_1, x_2, \dots, x_T)$로 해석합니다.
   - **양방향 GRU RNN**: 이 특징 벡터 시퀀스를 처리하여 순방향($h^{f}_t$) 및 역방향($h^{b}_t$) 은닉 상태 벡터 시퀀스를 계산합니다. GRU 셀 [38]을 사용하여 효율적인 시퀀스 모델링을 수행합니다.
   - **주의(Attention) 계층**: RNN의 출력 벡터($a_t$)들을 가중치 벡터($\alpha_t$)로 결합하여 단일 주의 특징 벡터 $\bar{a}$를 생성합니다. $\alpha_t = \frac{\exp(f(a_t))}{\sum_{i=1}^{T} \exp(f(a_i))}$ 이며, $f(a) = a^T W_{att}$입니다. 이 $\bar{a}$는 다음 시퀀스 수준 모델링에서 에포크의 표현으로 사용됩니다.

4. **시퀀스 수준(장기) 시퀀스 모델링**:

   - 입력 에포크 시퀀스 $(S_1, S_2, \dots, S_L)$에서 얻은 주의 특징 벡터 시퀀스 $\bar{A} = (\bar{a}_1, \bar{a}_2, \dots, \bar{a}_L)$를 입력으로 사용합니다.
   - **양방향 GRU RNN**: $\bar{A}$를 모델링하여 에포크 간의 장기적인 시퀀스 정보를 인코딩합니다.
   - **Softmax 계층**: 각 출력 벡터 $o_l$에 소프트맥스 계층을 적용하여 모든 수면 단계에 대한 출력 확률 분포 $\hat{y}_l$을 포함하는 분류 출력 시퀀스 $\hat{Y} = (\hat{y}_1, \hat{y}_2, \dots, \hat{y}_L)$를 생성합니다.

5. **시퀀스 손실 및 종단 간 훈련**:

   - 네트워크는 시퀀스 손실 $E_s(\theta) = -\frac{1}{L} \sum_{l=1}^{L} y_l \log(\hat{y}_l(\theta))$을 최소화하도록 훈련됩니다. 여기에는 $L_2$-norm 정규화 항이 포함됩니다.
   - 미니배치 훈련 시, 네트워크 계층의 여러 수준에서 입력 데이터를 `folding` 및 `unfolding`하는 전략을 사용하여 종단 간 훈련을 가능하게 합니다.

6. **결정 앙상블 및 확률적 집계**: 테스트 시, 입력 시퀀스를 한 에포크씩 이동하며 평가하여 각 에포크에 대해 여러 결정(앙상블)을 생성합니다. 최종 확률은 승법 집계(multiplicative aggregation)를 통해 $\log P(y_t) = \frac{1}{L_t} \sum_{i=t-L+1}^{t} \log P(y_t | S_i)$로 계산됩니다.

## 📊 Results

- **전반적인 성능**: SeqSleepNet은 MASS 데이터셋(200명 피험자)에서 87.1%의 전체 정확도(Accuracy), 83.3%의 Macro F1-score, 0.815의 Cohen's kappa($\kappa$)를 달성하여 최첨단 성능을 보였습니다.
- **단기 시퀀스 모델링의 영향**: E2E-ARNN (에포크 수준만 사용한 단일 출력 모델)은 1-max CNN [8]보다 0.9%p 높은 정확도를 보여, 에포크 내 단기 시퀀스 모델링의 효율성을 입증했습니다.
- **장기 시퀀스 모델링의 이점**: SeqSleepNet은 에포크 수준 처리만 수행하는 E2E-ARNN에 비해 평균 3.4%p 더 높은 정확도를, E2E-DeepSleepNet은 단일 CNN 버전(DeepSleepNet1)에 비해 평균 5.6%p 높은 정확도를 보였습니다. 이는 장기적인 에포크 간 의존성 모델링이 성능 향상에 매우 중요함을 시사합니다.
- **N1 단계 분류 개선**: 장기 시퀀스 모델링은 N1 수면 단계의 정확도를 17.2%p 크게 향상시켰습니다. N1 단계는 다른 단계와 유사한 특성 때문에 분류하기 어려운 것으로 알려져 있습니다.
- **경쟁 모델과의 비교**:
  - SeqSleepNet은 최고의 경쟁 모델인 E2E-DeepSleepNet (종단 간 훈련된 DeepSleepNet)보다 0.7%p 높은 정확도(87.1% vs 86.4%)를 달성했습니다.
  - SeqSleepNet과 E2E-DeepSleepNet은 Wake 및 N2 단계에서 유사한 성능을 보였으나, SeqSleepNet은 N1 및 REM 단계에서 더 뛰어난 성능을 보였습니다.
- **시퀀스 길이 및 네트워크 깊이의 영향**:
  - 시퀀스 길이 $L \ge 10$ 에포크는 네트워크 성능에 최소한의 영향을 미쳤습니다.
  - RNN 계층의 깊이를 1에서 2로 늘려도 성능 향상은 미미하거나, $L=10$일 경우 약간의 정확도 감소(0.2%p)가 관찰되었습니다. 이는 다중 작업이 더 큰 시퀀스 길이에서 네트워크를 더 잘 정규화한다는 것을 시사합니다.
- **오분류 에포크**: 오분류된 에포크 중 44.0%가 수면 단계 전환기(transitioning)에 속했습니다. 전환기 에포크의 오류율은 34.5%로, 비전환기 에포크(8.7% 오류율)에 비해 약 4배 높았습니다. 이는 전환기 에포크가 여러 수면 단계의 정보를 포함하여 분류하기 훨씬 어렵다는 것을 나타냅니다.
- **주의 가중치 시각화**: 학습된 주의 가중치는 각 수면 단계의 특징적 영역에 집중되어 있음을 보여주었습니다 (예: Wake에서 높은 뇌 활동, REM에서 안구 활동, N2/N3에서 K-복합체 및 서파 활동).

## 🧠 Insights & Discussion

- **임상적 유용성**: SeqSleepNet의 N1 및 REM 수면 단계에서의 우수한 성능은 기면증(narcolepsy) [56] 및 REM 수면 행동 장애(RBD) [57]와 같은 특정 수면 장애의 진단 및 평가에 잠재적으로 유용할 수 있습니다.
- **전이 학습 가능성**: 건강한 피험자 코호트(MASS 데이터셋)로 사전 훈련된 SeqSleepNet은 수면 병리 코호트에 대한 미세 조정(fine-tuning)을 위한 좋은 시작점이 될 수 있습니다.
- **제한 사항**: 시퀀스-투-시퀀스 모델의 특성상 전체 에포크 시퀀스에 접근해야 하므로, 실시간 온라인 모니터링 애플리케이션에서는 지연이 발생할 수 있습니다.
- **향후 연구**: SeqSleepNet과 DeepSleepNet이 N3 및 REM 단계에서 상반된 성능을 보이는 점을 고려할 때, 두 모델의 조합을 탐색하여 각자의 장점을 활용하는 것이 가능합니다.

## 📌 TL;DR

SeqSleepNet은 기존 자동 수면 단계 분류 방법의 장기적 맥락 모델링 한계를 극복하기 위해 제안된 **종단 간 계층적 순환 신경망**입니다. 이 모델은 입력 PSG 에포크 시퀀스를 **시퀀스-투-시퀀스** 방식으로 한 번에 분류합니다. 세 가지 주요 구성 요소(필터뱅크 계층, 에포크 수준 주의 기반 Bi-RNN, 시퀀스 수준 Bi-RNN)를 통해 각 에포크 내의 단기적 특징과 에포크 간의 장기적 의존성을 모두 학습합니다. MASS 데이터셋에서 87.1%의 전체 정확도를 달성하며 **최첨단 성능**을 보였고, 특히 분류가 어려운 N1 및 REM 수면 단계에서 성능을 크게 향상시켜 **임상적 유용성**을 입증했습니다.
