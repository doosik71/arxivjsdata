{
  "title": "RobustSleepNet: Transfer learning for automated sleep staging at scale",
  "authors": "Antoine Guillot, Valentin Thorey",
  "year": 2021,
  "url": "http://arxiv.org/abs/2101.02452v2",
  "abstract": "Sleep disorder diagnosis relies on the analysis of polysomnography (PSG)\nrecords. As a preliminary step of this examination, sleep stages are\nsystematically determined. In practice, sleep stage classification relies on\nthe visual inspection of 30-second epochs of polysomnography signals. Numerous\nautomatic approaches have been developed to replace this tedious and expensive\ntask. Although these methods demonstrated better performance than human sleep\nexperts on specific datasets, they remain largely unused in sleep clinics. The\nmain reason is that each sleep clinic uses a specific PSG montage that most\nautomatic approaches cannot handle out-of-the-box. Moreover, even when the PSG\nmontage is compatible, publications have shown that automatic approaches\nperform poorly on unseen data with different demographics. To address these\nissues, we introduce RobustSleepNet, a deep learning model for automatic sleep\nstage classification able to handle arbitrary PSG montages. We trained and\nevaluated this model in a leave-one-out-dataset fashion on a large corpus of 8\nheterogeneous sleep staging datasets to make it robust to demographic changes.\nWhen evaluated on an unseen dataset, RobustSleepNet reaches 97% of the F1 of a\nmodel explicitly trained on this dataset. Hence, RobustSleepNet unlocks the\npossibility to perform high-quality out-of-the-box automatic sleep staging with\nany clinical setup. We further show that finetuning RobustSleepNet, using a\npart of the unseen dataset, increases the F1 by 2% when compared to a model\ntrained specifically for this dataset. Therefore, finetuning might be used to\nreach a state-of-the-art level of performance on a specific population.",
  "citation": 126
}