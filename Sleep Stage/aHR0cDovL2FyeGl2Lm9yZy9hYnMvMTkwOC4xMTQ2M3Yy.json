{
  "title": "Sleep Staging from Electrocardiography and Respiration with Deep\n  Learning",
  "authors": "Haoqi Sun, Wolfgang Ganglberger, Ezhil Panneerselvam, Michael J. Leone, Syed A. Quadri, Balaji Goparaju, Ryan A. Tesh, Oluwaseun Akeju, Robert J. Thomas, M. Brandon Westover",
  "year": 2019,
  "url": "http://arxiv.org/abs/1908.11463v2",
  "abstract": "Study Objective: Sleep is reflected not only in the electroencephalogram but\nalso in heart rhythms and breathing patterns. Therefore, we hypothesize that it\nis possible to accurately stage sleep based on the electrocardiogram (ECG) and\nrespiratory signals. Methods: Using a dataset including 8,682 polysomnographs,\nwe develop deep neural networks to stage sleep from ECG and respiratory\nsignals. Five deep neural networks consisting of convolutional networks and\nlong short-term memory networks are trained to stage sleep using heart and\nbreathing, including the timing of R peaks from ECG, abdominal and chest\nrespiratory effort, and the combinations of these signals. Results: ECG in\ncombination with the abdominal respiratory effort achieve the best performance\nfor staging all five sleep stages with a Cohen's kappa of 0.600 (95% confidence\ninterval 0.599 -- 0.602); and 0.762 (0.760 -- 0.763) for discriminating awake\nvs. rapid eye movement vs. non-rapid eye movement sleep. The performance is\nbetter for young participants and for those with a low apnea-hypopnea index,\nwhile it is robust for commonly used outpatient medications. Conclusions: Our\nresults validate that ECG and respiratory effort provide substantial\ninformation about sleep stages in a large population. It opens new\npossibilities in sleep research and applications where electroencephalography\nis not readily available or may be infeasible, such as in critically ill\npatients.",
  "citation": 133
}