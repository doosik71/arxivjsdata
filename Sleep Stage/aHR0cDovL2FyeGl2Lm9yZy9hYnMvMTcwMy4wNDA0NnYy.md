# DeepSleepNet: a Model for Automatic Sleep Stage Scoring based on Raw Single-Channel EEG

Akara Supratak, Hao Dong, Chao Wu, and Yike Guo

## 🧩 Problem to Solve

자동 수면 단계 채점은 수면 연구 및 의료 분야에서 중요한 역할을 하지만, 기존 방법들은 다음과 같은 문제에 직면해 있습니다:

- 대부분 수동으로 설계된 특징(hand-engineered features)에 의존하여 수면 분석에 대한 사전 지식이 요구됩니다. 이는 복잡하고 시간이 많이 소요되는 과정입니다.
- 다음 수면 단계를 식별하는 데 중요한 시간적 정보(예: 수면 단계 전환 규칙)를 추출된 특징에 제대로 인코딩하는 경우가 드뭅니다.
- 다양한 피험자 및 기록 하드웨어 간의 이질성 때문에 기존의 수동 특징 기반 방법론이 다양한 데이터셋에 걸쳐 잘 일반화되지 못할 수 있습니다.
- 딥러닝 모델이 적용되었을 때도, raw 신호 대신 수동으로 설계된 특징을 사용했을 때 더 나은 성능을 보이는 경우가 있었는데, 이는 모델이 시간적 정보를 충분히 고려하지 못했기 때문일 수 있습니다.

## ✨ Key Contributions

본 연구는 다음과 같은 주요 기여를 통해 위에서 언급된 문제들을 해결합니다:

- **새로운 모델 아키텍처 개발:** raw 단일 채널 EEG에서 시간 불변(time-invariant) 특징을 추출하기 위한 두 개의 CNN(서로 다른 필터 크기 사용)과 수면 단계 간 전환 규칙과 같은 시간적 정보를 자동으로 학습하는 양방향-LSTM(bidirectional-LSTM)을 결합한 DeepSleepNet을 제안합니다.
- **효과적인 2단계 훈련 알고리즘 구현:** 클래스 불균형 문제를 겪는 대규모 수면 데이터셋에서도 모델이 특정 수면 단계에만 과적합되지 않도록 방지하면서, 역전파를 통해 모델을 엔드투엔드로 효율적으로 훈련시키는 알고리즘을 제시합니다.
- **모델의 일반화 능력 입증:** 모델 아키텍처 및 훈련 알고리즘 변경 없이, DeepSleepNet이 다양한 속성(예: 샘플링 속도)과 채점 기준(AASM 및 R&K)을 가진 두 가지 공개 데이터셋의 서로 다른 raw 단일 채널 EEG에서 수면 단계 채점을 위한 특징을 자동으로 학습할 수 있음을 보여주며, 수동으로 설계된 특징의 필요성을 제거합니다.

## 📎 Related Works

수면 단계 채점 분야의 관련 연구들은 크게 두 가지 범주로 나눌 수 있습니다:

- **수동 특징 추출 기반 방법:**
  - EEG, EOG, EMG 등 다중 신호 또는 단일 채널 EEG에서 시간 도메인, 주파수 도메인, 시간-주파수 도메인 특징을 추출한 후 분류기(예: SVM, 결정 트리)를 사용하는 방식이 주를 이룹니다 ([4]–[6], [7]–[9]).
  - 이러한 방법들은 데이터셋 특성에 기반한 수동 특징 설계에 의존하며, 이로 인해 일반화에 어려움이 있습니다.
- **딥러닝 기반 방법:**
  - **DBNs (Deep Belief Networks):** 전처리된 raw PSG에서 확률적 표현을 학습하는 데 사용되었습니다 ([10]).
  - **CNNs (Convolutional Neural Networks):** raw Fpz-Cz EEG 채널에서 시간 불변 특징을 추출하는 데 적용되었습니다 ([11]). 그러나 당시 연구에서는 딥러닝을 수동 특징에 적용하는 것이 raw 신호에 직접 적용하는 것보다 성능이 더 좋다는 결과가 있었습니다.
  - **RNNs (Recurrent Neural Networks):**
    - Elman RNN은 Fpz-Cz EEG 채널의 에너지 특징에 적용되었습니다 ([12]).
    - LSTM은 시간-주파수 도메인 특징에 적용되기도 했습니다 (본 연구 저자들의 이전 연구 [13]).
  - 대부분의 딥러닝 연구조차 수동으로 설계된 특징에 여전히 의존하며, 수면 전문가가 사용하는 중요한 시간적 정보(수면 단계 전환 규칙)를 모델에 통합하는 데 한계가 있었습니다.

## 🛠️ Methodology

DeepSleepNet은 **표현 학습(Representation Learning)** 부분과 **순차 잔차 학습(Sequence Residual Learning)** 부분으로 구성됩니다 (Fig. 1 참조).

### 1. 표현 학습 (Representation Learning)

- **두 개의 CNN 사용:** raw 30초 단일 채널 EEG 에포크에서 시간 불변 특징을 추출하기 위해 두 개의 CNN이 활용됩니다.
  - 하나는 작은 필터 크기를 사용하여 EEG 패턴의 **시간적 정보(temporal information)**를 포착하는 데 효과적입니다 (예: Fs/2 크기의 필터, Fs/16 스트라이드).
  - 다른 하나는 큰 필터 크기를 사용하여 EEG의 **주파수 구성 요소(frequency components)**를 더 잘 포착합니다 (예: Fs$\times$4 크기의 필터, Fs/2 스트라이드).
- **CNN 구조:** 각 CNN은 4개의 컨볼루션 레이어와 2개의 최대 풀링(max-pooling) 레이어로 구성됩니다. 각 컨볼루션 레이어는 1D-컨볼루션, 배치 정규화(Batch Normalization) [$15$], ReLU 활성화(activation) 함수를 순차적으로 수행합니다.
- **특징 추출:** $i$-번째 EEG 에포크 $x_i$로부터 두 CNN을 통해 특징 $h_{s}^{i}$와 $h_{l}^{i}$를 추출하고, 이들을 연결하여 최종 특징 벡터 $a_i$를 생성합니다:
  $$h_{s}^{i} = \text{CNN}_{\theta_{s}}(x_{i})$$
  $$h_{l}^{i} = \text{CNN}_{\theta_{l}}(x_{i})$$
  $$a_{i} = h_{s}^{i} || h_{l}^{i}$$
  여기서 $\theta_{s}$와 $\theta_{l}$은 각각 작은 필터와 큰 필터 CNN의 매개변수이고, $||$는 연결(concatenate) 연산입니다.

### 2. 순차 잔차 학습 (Sequence Residual Learning)

- **양방향-LSTM 활용:** 두 층의 양방향-LSTM을 사용하여 수면 전문가가 사용하는 수면 단계 전환 규칙과 같은 시간적 정보를 학습합니다. 양방향-LSTM은 과거와 미래 정보 모두를 활용하여 시퀀스 데이터를 처리할 수 있습니다. 피플홀(peephole) 연결도 사용됩니다 [$19, 20$].
- **잔차 학습 프레임워크:** ResNet [$16$]에서 영감을 받아 숏컷 연결(shortcut connection)을 적용하여 CNN에서 추출된 특징에 LSTM이 학습한 시간적 정보를 효과적으로 추가할 수 있도록 합니다. 숏컷 연결에는 완전 연결(fully-connected) 레이어가 포함되어 특징 벡터의 차원을 조정합니다.
- **수학적 표현:** 순차적으로 배열된 CNN 특징 $\{a_1, \dots, a_N\}$에 대해 순차 잔차 학습은 다음과 같이 정의됩니다:
  $$h_{f}^{t}, c_{f}^{t} = \text{LSTM}_{\theta_{f}}(h_{f}^{t-1}, c_{f}^{t-1}, a_{t})$$
  $$h_{b}^{t}, c_{b}^{t} = \text{LSTM}_{\theta_{b}}(h_{b}^{t+1}, c_{b}^{t+1}, a_{t})$$
  $$o_{t} = h_{f}^{t} || h_{b}^{t} + \text{FC}_{\theta}(a_{t})$$
  여기서 $h_{f}^{t}, c_{f}^{t}$ 및 $h_{b}^{t}, c_{b}^{t}$는 각각 순방향 및 역방향 LSTM의 은닉 및 셀 상태이며, $\text{FC}_{\theta}(a_{t})$는 완전 연결 레이어를 통한 변환입니다. 학습 및 테스트 시 각 환자 데이터의 시작에서 LSTM 셀 상태는 0으로 초기화되어 현재 피험자 데이터의 시간적 정보만 활용하도록 합니다.

### 3. 2단계 훈련 알고리즘 (Algorithm 1)

클래스 불균형 문제를 해결하고 효율적인 학습을 위해 개발된 알고리즘입니다.

1. **사전 훈련 (Pre-training):**
   - 모델의 표현 학습 부분(두 CNN)을 클래스 균형(class-balance) 훈련 세트(소수 클래스 오버샘플링을 통해 생성)로 지도 학습합니다.
   - 이는 모델이 다수 수면 단계에 과적합되는 것을 방지합니다.
2. **미세 조정 (Fine-tuning):**
   - 사전 훈련된 CNN 매개변수를 전체 모델에 통합한 후, 전체 모델을 순차 훈련 세트(sequential training set)로 미세 조정합니다.
   - CNN 부분에는 낮은 학습률($\text{lr}_1=10^{-6}$)을, 순차 잔차 학습 부분(LSTM 및 softmax 레이어)에는 높은 학습률($\text{lr}_2=10^{-4}$)을 적용하여 사전 훈련된 CNN 매개변수가 과도하게 조정되는 것을 방지합니다.
   - RNN의 그래디언트 폭발(exploding gradients) 문제를 방지하기 위해 휴리스틱 그래디언트 클리핑(gradient clipping) 기술을 사용합니다.

### 4. 정규화 (Regularization)

과적합 방지를 위해 다음과 같은 기술을 사용합니다.

- **드롭아웃 (Dropout):** 훈련 중 입력 값의 50%를 무작위로 0으로 설정하여 모델 전반에 걸쳐 적용됩니다.
- **L2 가중치 감쇠 (L2 weight decay):** 두 CNN의 첫 번째 레이어에만 적용하여 매개변수 값의 폭발을 방지하고, 노이즈나 아티팩트에 대한 필터의 과적합을 줄여 더 부드러운 필터를 학습하도록 돕습니다.

## 📊 Results

DeepSleepNet의 성능은 두 가지 공개 데이터셋(MASS 및 Sleep-EDF)의 서로 다른 단일 채널 EEG(F4-EOG(Left), Fpz-Cz, Pz-Oz)를 사용하여 평가되었습니다.

- **성능 요약:**
  - **MASS (F4-EOG(Left) 채널):** 전체 정확도(ACC) 86.2%, 매크로 F1-점수(MF1) 81.7%, 코헨의 카파 계수($\kappa$) 0.80.
  - **Sleep-EDF (Fpz-Cz 채널):** 전체 정확도(ACC) 82.0%, 매크로 F1-점수(MF1) 76.9%, 코헨의 카파 계수($\kappa$) 0.76.
- **최첨단(State-of-the-Art) 방법과의 비교:**
  - DeepSleepNet은 두 데이터셋 모두에서 기존의 최첨단 수동 특징 기반 방법론(MASS: ACC 85.9%-MF1 80.5; Sleep-EDF: ACC 78.9%-MF1 73.7)과 유사하거나 더 나은 성능을 달성했습니다.
  - 특히, 가장 분류하기 어려운 수면 단계인 N1 단계의 성능을 희생하지 않으면서 유사한 성능을 달성하여, 모델이 다수 클래스에 편향되지 않았음을 시사했습니다.
- **수면 단계별 성능:** N1 단계는 F1-점수가 46.6%에서 59.8%로 가장 낮았지만, 다른 수면 단계(W, N2, N3, REM)에서는 81.5%에서 90.3%에 이르는 높은 F1-점수를 보였습니다. 오분류는 주로 N2와 N3 단계 사이에서 발생했습니다.
- **순차 잔차 학습의 중요성:** 순차 잔차 학습 부분이 없는 DeepSleepNet(즉, 사전 훈련된 CNN만 사용)은 N3를 제외한 모든 수면 단계에서 F1-점수가 더 낮게 나타났습니다. 이는 순차 잔차 학습이 분류 성능 향상에 기여했음을 명확히 보여줍니다.
- **모델 분석 (Insights):**
  - **CNN 필터:** 표현 학습 부분의 첫 번째 컨볼루션 레이어에서 학습된 필터 중 일부는 특정 수면 단계(예: N2-N3 또는 W-N1-REM)에 대해 주로 활성화되었습니다. 이는 모델이 수면 방추(sleep spindles, N2/N3)나 안구 움직임 특징(W/N1/REM)과 같이 AASM 매뉴얼과 일치하는 패턴을 인식했음을 시사합니다.
  - **LSTM 메모리 셀:** 양방향-LSTM 내부에서 기상(W) 또는 수면 시작(N1)을 추적하는 셀, 시간 경과에 따라 값이 증감하는 셀, N3 및 REM 단계의 연속적인 시퀀스를 감지하는 셀과 같이 해석 가능한 메모리 셀들이 발견되었습니다. 이는 LSTM이 수면 단계 전환 규칙을 학습하여 피험자의 현재 상태를 이해하고 다음 단계를 예측하는 데 활용함을 나타냅니다.

## 🧠 Insights & Discussion

DeepSleepNet은 수면 단계 채점 분야에 대한 중요한 통찰력과 잠재력을 제시합니다.

- **수동 특징 엔지니어링의 제거:** DeepSleepNet은 raw 단일 채널 EEG에서 수면 단계 채점을 위한 특징을 자동으로 학습함으로써, 수면 분석에 대한 사전 지식과 수동 특징 엔지니어링의 필요성을 없앱니다. 이는 기존 방법론 대비 상당한 이점입니다.
- **높은 일반화 및 견고성:** 모델 아키텍처나 훈련 알고리즘 변경 없이 다양한 EEG 채널(F4-EOG(Left), Fpz-Cz, Pz-Oz) 및 다양한 특성(샘플링 속도, 채점 기준)을 가진 데이터셋(MASS, Sleep-EDF)에서 최첨단 성능을 달성했습니다. 이는 DeepSleepNet의 강력한 일반화 능력을 입증합니다.
- **임상적 유의미성:** 모델 분석을 통해 DeepSleepNet이 AASM 매뉴얼과 일치하는 수면 방추, 안구 움직임 등과 같은 임상적으로 유의미한 특징들을 학습했음을 확인했습니다. 또한, LSTM 메모리 셀은 수면 단계 전환 규칙을 효과적으로 파악하고 적용하고 있음을 보여줍니다.
- **원격 수면 모니터링 잠재력:** 수동 특징 없이 raw EEG에서 학습하는 능력은 웨어러블 기기를 통한 원격 수면 모니터링 시스템 구현에 이상적인 접근 방식을 제공합니다.

그러나 본 모델은 몇 가지 한계를 가집니다:

- **데이터 요구량:** 딥러닝 모델의 특성상 유용한 표현을 학습하기 위해 충분한 양의 훈련 데이터(약 54,000 에포크 이상)가 필요합니다.
- **채널 특이성:** 훈련된 모델이 훈련 데이터와 속성이 다른 EEG 채널 데이터에 적용될 경우 성능이 저하될 수 있으며, 재훈련 또는 미세 조정이 필요할 수 있습니다.
- **예측 지연:** 양방향-LSTM을 사용하기 때문에, 일정 길이의 EEG 에포크 시퀀스(예: 25 에포크, 즉 12.5분)가 수집될 때까지 기다려야 해당 에포크들을 채점할 수 있어 실시간 응용에 지연이 발생할 수 있습니다.

## 📌 TL;DR

**문제:** 기존의 자동 수면 단계 채점 방법은 수동 특징 추출에 의존하고 수면 단계 전환과 같은 시간적 정보를 충분히 활용하지 못하여 일반화 및 효율성이 제한되었습니다.

**제안 방법:** DeepSleepNet은 raw 단일 채널 EEG에서 시간 불변 특징을 추출하는 CNN과 수면 단계 전환 규칙을 학습하는 양방향-LSTM을 결합한 딥러닝 모델입니다. 클래스 불균형을 완화하는 사전 훈련 단계와 시간적 정보를 인코딩하는 미세 조정 단계로 구성된 2단계 훈련 알고리즘을 사용합니다.

**주요 발견:** DeepSleepNet은 모델 아키텍처나 훈련 알고리즘 변경 없이 다양한 EEG 채널(F4-EOG, Fpz-Cz, Pz-Oz) 및 데이터셋(MASS, Sleep-EDF)에서 최첨단 방법론에 필적하거나 그 이상의 정확도(ACC 82.0%-86.2%)와 F1-점수(MF1 76.9%-81.7%)를 달성했습니다. 수동으로 설계된 특징 없이도 AASM 매뉴얼과 일치하는 유의미한 수면 특징과 전환 규칙을 자동으로 학습함을 입증하여, 원격 수면 모니터링 시스템 구현의 가능성을 열었습니다.
