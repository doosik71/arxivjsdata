{
  "title": "Multi-View Spatial-Temporal Graph Convolutional Networks with Domain\n  Generalization for Sleep Stage Classification",
  "authors": "Ziyu Jia, Youfang Lin, Jing Wang, Xiaojun Ning, Yuanlai He, Ronghao Zhou, Yuhan Zhou, Li-wei H. Lehman",
  "year": 2021,
  "url": "http://arxiv.org/abs/2109.01824v1",
  "abstract": "Sleep stage classification is essential for sleep assessment and disease\ndiagnosis. Although previous attempts to classify sleep stages have achieved\nhigh classification performance, several challenges remain open: 1) How to\neffectively utilize time-varying spatial and temporal features from\nmulti-channel brain signals remains challenging. Prior works have not been able\nto fully utilize the spatial topological information among brain regions. 2)\nDue to the many differences found in individual biological signals, how to\novercome the differences of subjects and improve the generalization of deep\nneural networks is important. 3) Most deep learning methods ignore the\ninterpretability of the model to the brain. To address the above challenges, we\npropose a multi-view spatial-temporal graph convolutional networks (MSTGCN)\nwith domain generalization for sleep stage classification. Specifically, we\nconstruct two brain view graphs for MSTGCN based on the functional connectivity\nand physical distance proximity of the brain regions. The MSTGCN consists of\ngraph convolutions for extracting spatial features and temporal convolutions\nfor capturing the transition rules among sleep stages. In addition, attention\nmechanism is employed for capturing the most relevant spatial-temporal\ninformation for sleep stage classification. Finally, domain generalization and\nMSTGCN are integrated into a unified framework to extract subject-invariant\nsleep features. Experiments on two public datasets demonstrate that the\nproposed model outperforms the state-of-the-art baselines.",
  "citation": 249
}