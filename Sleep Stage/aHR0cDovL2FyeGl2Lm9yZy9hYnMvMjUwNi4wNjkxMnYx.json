{
  "title": "Sleep Stage Classification using Multimodal Embedding Fusion from EOG\n  and PSM",
  "authors": "Olivier Papillon, Rafik Goubran, James Green, Julien Larivière-Chartier, Caitlin Higginson, Frank Knoefel, Rébecca Robillard",
  "year": 2025,
  "url": "http://arxiv.org/abs/2506.06912v1",
  "abstract": "Accurate sleep stage classification is essential for diagnosing sleep\ndisorders, particularly in aging populations. While traditional polysomnography\n(PSG) relies on electroencephalography (EEG) as the gold standard, its\ncomplexity and need for specialized equipment make home-based sleep monitoring\nchallenging. To address this limitation, we investigate the use of\nelectrooculography (EOG) and pressure-sensitive mats (PSM) as less obtrusive\nalternatives for five-stage sleep-wake classification. This study introduces a\nnovel approach that leverages ImageBind, a multimodal embedding deep learning\nmodel, to integrate PSM data with dual-channel EOG signals for sleep stage\nclassification. Our method is the first reported approach that fuses PSM and\nEOG data for sleep stage classification with ImageBind. Our results demonstrate\nthat fine-tuning ImageBind significantly improves classification accuracy,\noutperforming existing models based on single-channel EOG (DeepSleepNet),\nexclusively PSM data (ViViT), and other multimodal deep learning approaches\n(MBT). Notably, the model also achieved strong performance without fine-tuning,\nhighlighting its adaptability to specific tasks with limited labeled data,\nmaking it particularly advantageous for medical applications. We evaluated our\nmethod using 85 nights of patient recordings from a sleep clinic. Our findings\nsuggest that pre-trained multimodal embedding models, even those originally\ndeveloped for non-medical domains, can be effectively adapted for sleep\nstaging, with accuracies approaching systems that require complex EEG data.",
  "citation": 0
}